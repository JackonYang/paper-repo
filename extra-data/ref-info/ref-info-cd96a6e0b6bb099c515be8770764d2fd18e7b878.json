{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2617020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "isKey": false,
            "numCitedBy": 5025,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance."
            },
            "slug": "A-unified-architecture-for-natural-language-deep-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "A unified architecture for natural language processing: deep neural networks with multitask learning"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work describes a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense using a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1864353"
                        ],
                        "name": "Edward Grefenstette",
                        "slug": "Edward-Grefenstette",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Grefenstette"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784777"
                        ],
                        "name": "M. Sadrzadeh",
                        "slug": "M.-Sadrzadeh",
                        "structuredName": {
                            "firstName": "Mehrnoosh",
                            "lastName": "Sadrzadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sadrzadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326718"
                        ],
                        "name": "B. Coecke",
                        "slug": "B.-Coecke",
                        "structuredName": {
                            "firstName": "Bob",
                            "lastName": "Coecke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Coecke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50419262"
                        ],
                        "name": "S. Pulman",
                        "slug": "S.-Pulman",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pulman",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pulman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 170
                            }
                        ],
                        "text": "\u2026into account such features but are limited to phrases of a specific syntactic type (Baroni and Zamparelli, 2010) and structured models that fully capture such features (Grefenstette et al., 2011) and are embedded within a deep neural architecture (Socher et al., 2012; Hermann and Blunsom, 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 512,
                                "start": 485
                            }
                        ],
                        "text": "With regard to modelling the meaning of sentences and sentential compositionality, recent proposals have included simple additive and multiplicative models that do not take into account sentential features such as word order or syntactic structure (Mitchell and Lapata, 2010), matrix-vector based models that do take into account such features but are limited to phrases of a specific syntactic type (Baroni and Zamparelli, 2010) and structured models that fully capture such features (Grefenstette et al., 2011) and are embedded within a deep neural architecture (Socher et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2411818,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3cd32f1a3d8a090a75658528eeecc38cba8a2bf1",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Coecke, Sadrzadeh, and Clark [3] developed a compositional model of meaning for distributional semantics, in which each word in a sentence has a meaning vector and the distributional meaning of the sentence is a function of the tensor products of the word vectors. Abstractly speaking, this function is the morphism corresponding to the grammatical structure of the sentence in the category of finite dimensional vector spaces. In this paper, we provide a concrete method for implementing this linear meaning map, by constructing a corpus-based vector space for the type of sentence. Our construction method is based on structured vector spaces whereby meaning vectors of all sentences, regardless of their grammatical structure, live in the same vector space. Our proposed sentence space is the tensor product of two noun spaces, in which the basis vectors are pairs of words each augmented with a grammatical role. This enables us to compare meanings of sentences by simply taking the inner product of their vectors."
            },
            "slug": "Concrete-Sentence-Spaces-for-Compositional-Models-Grefenstette-Sadrzadeh",
            "title": {
                "fragments": [],
                "text": "Concrete Sentence Spaces for Compositional Distributional Models of Meaning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper provides a concrete method for implementing a linear meaning map, by constructing a corpus-based vector space for the type of sentence, based on structured vector spaces whereby meaning vectors of all sentences, regardless of their grammatical structure, live in the same vector space."
            },
            "venue": {
                "fragments": [],
                "text": "IWCS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570381"
                        ],
                        "name": "Brody Huval",
                        "slug": "Brody-Huval",
                        "structuredName": {
                            "firstName": "Brody",
                            "lastName": "Huval",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brody Huval"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 202
                            }
                        ],
                        "text": "With regard to discourse compositionality, most of the proposals aimed at capturing semantic aspects of paragraphs or longer texts have focused on bag of n-grams or sentence vector averaging approaches (Wang and Manning, 2012; Socher et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 59
                            }
                        ],
                        "text": ", 2011) and are embedded within a deep neural architecture (Socher et al., 2012; Hermann and Blunsom, 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 806709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27e38351e48fe4b7da2775bf94341738bc4da07e",
            "isKey": false,
            "numCitedBy": 1265,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Single-word vector space models have been very successful at learning lexical information. However, they cannot capture the compositional meaning of longer phrases, preventing them from a deeper understanding of language. We introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to every node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the meaning of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying sentiment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syntactic path between them."
            },
            "slug": "Semantic-Compositionality-through-Recursive-Spaces-Socher-Huval",
            "title": {
                "fragments": [],
                "text": "Semantic Compositionality through Recursive Matrix-Vector Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A recursive neural network model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length and can learn the meaning of operators in propositional logic and natural language is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758841"
                        ],
                        "name": "K. Ries",
                        "slug": "K.-Ries",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Ries",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ries"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145632116"
                        ],
                        "name": "N. Coccaro",
                        "slug": "N.-Coccaro",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Coccaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Coccaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70422141"
                        ],
                        "name": "Elizabeth Shriberg",
                        "slug": "Elizabeth-Shriberg",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Shriberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elizabeth Shriberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057063782"
                        ],
                        "name": "R. Bates",
                        "slug": "R.-Bates",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Bates",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122297135"
                        ],
                        "name": "P. Taylor",
                        "slug": "P.-Taylor",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Taylor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46776641"
                        ],
                        "name": "Rachel Martin",
                        "slug": "Rachel-Martin",
                        "structuredName": {
                            "firstName": "Rachel",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rachel Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403242564"
                        ],
                        "name": "C. V. Ess-Dykema",
                        "slug": "C.-V.-Ess-Dykema",
                        "structuredName": {
                            "firstName": "Carol",
                            "lastName": "Ess-Dykema",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. V. Ess-Dykema"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227843"
                        ],
                        "name": "M. Meteer",
                        "slug": "M.-Meteer",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Meteer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meteer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215825908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22d45dadde6b5837eff11dc031045754bc5901c3",
            "isKey": false,
            "numCitedBy": 1015,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We describe a statistical approach for modeling dialogue acts in conversational speech, i.e., speech-act-like units such as STATEMENT, Question, BACKCHANNEL, Agreement, Disagreement, and Apology. Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence. The dialogue model is based on treating the discourse structure of a conversation as a hidden Markov model and the individual dialogue acts as observations emanating from the model states. Constraints on the likely sequence of dialogue acts are modeled via a dialogue act n-gram. The statistical dialogue grammar is combined with word n-grams, decision trees, and neural networks modeling the idiosyncratic lexical and prosodic manifestations of each dialogue act. We develop a probabilistic integration of speech recognition with dialogue modeling, to improve both speech recognition and dialogue act classification accuracy. Models are trained and evaluated using a large hand-labeled database of 1,155 conversations from the Switchboard corpus of spontaneous human-to-human telephone speech. We achieved good dialogue act labeling accuracy (65% based on errorful, automatically recognized words and prosody, and 71% based on word transcripts, compared to a chance baseline accuracy of 35% and human accuracy of 84%) and a small reduction in word recognition error."
            },
            "slug": "Dialogue-act-modeling-for-automatic-tagging-and-of-Stolcke-Ries",
            "title": {
                "fragments": [],
                "text": "Dialogue act modeling for automatic tagging and recognition of conversational speech"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A probabilistic integration of speech recognition with dialogue modeling is developed, to improve both speech recognition and dialogue act classification accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2910877"
                        ],
                        "name": "K. Hermann",
                        "slug": "K.-Hermann",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Hermann",
                            "middleNames": [
                                "Moritz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685771"
                        ],
                        "name": "P. Blunsom",
                        "slug": "P.-Blunsom",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Blunsom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Blunsom"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17981782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79c0b2f44bbc2bc51de554b88ebe46204413f884",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Modelling the compositional process by which the meaning of an utterance arises from the meaning of its parts is a fundamental task of Natural Language Processing. In this paper we draw upon recent advances in the learning of vector space representations of sentential semantics and the transparent interface between syntax and semantics provided by Combinatory Categorial Grammar to introduce Combinatory Categorial Autoencoders. This model leverages the CCG combinatory operators to guide a non-linear transformation of meaning within a sentence. We use this model to learn high dimensional embeddings for sentences and evaluate them in a range of tasks, demonstrating that the incorporation of syntax allows a concise model to learn representations that are both effective and general."
            },
            "slug": "The-Role-of-Syntax-in-Vector-Space-Models-of-Hermann-Blunsom",
            "title": {
                "fragments": [],
                "text": "The Role of Syntax in Vector Space Models of Compositional Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This model leverages the CCG combinatory operators to guide a non-linear transformation of meaning within a sentence and is used to learn high dimensional embeddings for sentences and evaluate them in a range of tasks, demonstrating that the incorporation of syntax allows a concise model to learn representations that are both effective and general."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2245567"
                        ],
                        "name": "M. Karafi\u00e1t",
                        "slug": "M.-Karafi\u00e1t",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Karafi\u00e1t",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Karafi\u00e1t"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816892"
                        ],
                        "name": "L. Burget",
                        "slug": "L.-Burget",
                        "structuredName": {
                            "firstName": "Luk\u00e1\u0161",
                            "lastName": "Burget",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Burget"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1899242"
                        ],
                        "name": "J. Cernock\u00fd",
                        "slug": "J.-Cernock\u00fd",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Cernock\u00fd",
                            "middleNames": [
                                "Honza"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cernock\u00fd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803071"
                        ],
                        "name": "S. Khudanpur",
                        "slug": "S.-Khudanpur",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Khudanpur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khudanpur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 117
                            }
                        ],
                        "text": "The discourse model is based on a recurrent neural network (RNN) architecture that is a powerful model for sequences (Sutskever et al., 2011; Mikolov et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17048224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9819b600a828a57e1cde047bbe710d3446b30da5",
            "isKey": false,
            "numCitedBy": 4902,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model. Speech recognition experiments show around 18% reduction of word error rate on the Wall Street Journal task when comparing models trained on the same amount of data, and around 5% on the much harder NIST RT05 task, even when the backoff model is trained on much more data than the RNN LM. We provide ample empirical evidence to suggest that connectionist language models are superior to standard n-gram techniques, except their high computational (training) complexity. Index Terms: language modeling, recurrent neural networks, speech recognition"
            },
            "slug": "Recurrent-neural-network-based-language-model-Mikolov-Karafi\u00e1t",
            "title": {
                "fragments": [],
                "text": "Recurrent neural network based language model"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34902160"
                        ],
                        "name": "Jeff Mitchell",
                        "slug": "Jeff-Mitchell",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26901423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "745d86adca56ec50761591733e157f84cfb19671",
            "isKey": false,
            "numCitedBy": 930,
            "numCiting": 253,
            "paperAbstract": {
                "fragments": [],
                "text": "Vector-based models of word meaning have become increasingly popular in cognitive science. The appeal of these models lies in their ability to represent meaning simply by using distributional information under the assumption that words occurring within similar contexts are semantically similar. Despite their widespread use, vector-based models are typically directed at representing words in isolation, and methods for constructing representations for phrases or sentences have received little attention in the literature. This is in marked contrast to experimental evidence (e.g., in sentential priming) suggesting that semantic similarity is more complex than simply a relation between isolated words. This article proposes a framework for representing the meaning of word combinations in vector space. Central to our approach is vector composition, which we operationalize in terms of additive and multiplicative functions. Under this framework, we introduce a wide range of composition models that we evaluate empirically on a phrase similarity task."
            },
            "slug": "Composition-in-Distributional-Models-of-Semantics-Mitchell-Lapata",
            "title": {
                "fragments": [],
                "text": "Composition in Distributional Models of Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article proposes a framework for representing the meaning of word combinations in vector space in terms of additive and multiplicative functions, and introduces a wide range of composition models that are evaluated empirically on a phrase similarity task."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145704247"
                        ],
                        "name": "James Martens",
                        "slug": "James-Martens",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Martens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 117
                            }
                        ],
                        "text": "The discourse model is based on a recurrent neural network (RNN) architecture that is a powerful model for sequences (Sutskever et al., 2011; Mikolov et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8843166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de",
            "isKey": false,
            "numCitedBy": 1255,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent Neural Networks (RNNs) are very powerful sequence models that do not enjoy widespread use because it is extremely difficult to train them properly. Fortunately, recent advances in Hessian-free optimization have been able to overcome the difficulties associated with training RNNs, making it possible to apply them successfully to challenging sequence problems. In this paper we demonstrate the power of RNNs trained with the new Hessian-Free optimizer (HF) by applying them to character-level language modeling tasks. The standard RNN architecture, while effective, is not ideally suited for such tasks, so we introduce a new RNN variant that uses multiplicative (or \"gated\") connections which allow the current input character to determine the transition matrix from one hidden state vector to the next. After training the multiplicative RNN with the HF optimizer for five days on 8 high-end Graphics Processing Units, we were able to surpass the performance of the best previous single method for character-level language modeling \u2013 a hierarchical non-parametric sequence model. To our knowledge this represents the largest recurrent neural network application to date."
            },
            "slug": "Generating-Text-with-Recurrent-Neural-Networks-Sutskever-Martens",
            "title": {
                "fragments": [],
                "text": "Generating Text with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The power of RNNs trained with the new Hessian-Free optimizer by applying them to character-level language modeling tasks is demonstrated, and a new RNN variant that uses multiplicative connections which allow the current input character to determine the transition matrix from one hidden state vector to the next is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143978026"
                        ],
                        "name": "S. Calhoun",
                        "slug": "S.-Calhoun",
                        "structuredName": {
                            "firstName": "Sasha",
                            "lastName": "Calhoun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Calhoun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694130"
                        ],
                        "name": "J. Carletta",
                        "slug": "J.-Carletta",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Carletta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carletta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31983004"
                        ],
                        "name": "Jason M. Brenier",
                        "slug": "Jason-M.-Brenier",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Brenier",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason M. Brenier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32498452"
                        ],
                        "name": "N. Mayo",
                        "slug": "N.-Mayo",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Mayo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Mayo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332819"
                        ],
                        "name": "Mark Steedman",
                        "slug": "Mark-Steedman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Steedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153937601"
                        ],
                        "name": "D. Beaver",
                        "slug": "D.-Beaver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beaver",
                            "middleNames": [
                                "Ian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beaver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5176936,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "95174b77e4a5856fb0b0283bb0cb8acd3429d946",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a recently completed common resource for the study of spoken discourse, the NXT-format Switchboard Corpus. Switchboard is a long-standing corpus of telephone conversations (Godfrey et\u00a0al. in SWITCHBOARD: Telephone speech corpus for research and development. In Proceedings of ICASSP-92, pp. 517\u2013520, 1992). We have brought together transcriptions with existing annotations for syntax, disfluency, speech acts, animacy, information status, coreference, and prosody; along with substantial new annotations of focus/contrast, more prosody, syllables and phones. The combined corpus uses the format of the NITE XML Toolkit, which allows these annotations to be browsed and searched as a coherent set (Carletta et\u00a0al. in Lang Resour Eval J 39(4):313\u2013334, 2005). The resulting corpus is a rich resource for the investigation of the linguistic features of dialogue and how they interact. As well as describing the corpus itself, we discuss our approach to overcoming issues involved in such a data integration project, relevant to both users of the corpus and others in the language resource community undertaking similar projects."
            },
            "slug": "The-NXT-format-Switchboard-Corpus:-a-rich-resource-Calhoun-Carletta",
            "title": {
                "fragments": [],
                "text": "The NXT-format Switchboard Corpus: a rich resource for investigating the syntax, semantics, pragmatics and prosody of dialogue"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The approach to overcoming issues involved in such a data integration project is discussed, relevant to both users of the corpus and others in the language resource community undertaking similar projects."
            },
            "venue": {
                "fragments": [],
                "text": "Lang. Resour. Evaluation"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3295137"
                        ],
                        "name": "William Blacoe",
                        "slug": "William-Blacoe",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Blacoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Blacoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11567084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7988ef10dc9770e5fa4dc40d5d2f3693fd2ed917",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of modeling compositional meaning for phrases and sentences using distributional methods. We experiment with several possible combinations of representation and composition, exhibiting varying degrees of sophistication. Some are shallow while others operate over syntactic structure, rely on parameter learning, or require access to very large corpora. We find that shallow approaches are as good as more computationally intensive alternatives with regards to two particular tests: (1) phrase similarity and (2) paraphrase detection. The sizes of the involved training corpora and the generated vectors are not as important as the fit between the meaning representation and compositional method."
            },
            "slug": "A-Comparison-of-Vector-based-Representations-for-Blacoe-Lapata",
            "title": {
                "fragments": [],
                "text": "A Comparison of Vector-based Representations for Semantic Composition"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "Shallow approaches to modeling compositional meaning for phrases and sentences using distributional methods are found to be as good as more computationally intensive alternatives with regards to two particular tests: phrase similarity and paraphrase detection."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775432"
                        ],
                        "name": "Christian Scheible",
                        "slug": "Christian-Scheible",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Scheible",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Scheible"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7788178,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "682b3dc0f4c46f96aa28358203c5013649e8dc62",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Learning models enjoy considerable success in Natural Language Processing. While deep architectures produce useful representations that lead to improvements in various tasks, they are often difficult to interpret. This makes the analysis of learned structures particularly difficult. In this paper, we rely on empirical tests to see whether a particular structure makes sense. We present an analysis of the Semi-Supervised Recursive Autoencoder, a well-known model that produces structural representations of text. We show that for certain tasks, the structure of the autoencoder can be significantly reduced without loss of classification accuracy and we evaluate the produced structures using human judgment."
            },
            "slug": "Cutting-Recursive-Autoencoder-Trees-Scheible-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Cutting Recursive Autoencoder Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that for certain tasks, the structure of the autoencoder can be significantly reduced without loss of classification accuracy and the produced structures are evaluated using human judgment."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2713535"
                        ],
                        "name": "Roberto Zamparelli",
                        "slug": "Roberto-Zamparelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Zamparelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Zamparelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8360910,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "37efe2ef1b9d27cc598361a8013ec888a6f7c4d8",
            "isKey": false,
            "numCitedBy": 519,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to adjective-noun composition (AN) for corpus-based distributional semantics that, building on insights from theoretical linguistics, represents nouns as vectors and adjectives as data-induced (linear) functions (encoded as matrices) over nominal vectors. Our model significantly outperforms the rivals on the task of reconstructing AN vectors not seen in training. A small post-hoc analysis further suggests that, when the model-generated AN vector is not similar to the corpus-observed AN vector, this is due to anomalies in the latter. We show moreover that our approach provides two novel ways to represent adjective meanings, alternative to its representation via corpus-based co-occurrence vectors, both outperforming the latter in an adjective clustering task."
            },
            "slug": "Nouns-are-Vectors,-Adjectives-are-Matrices:-in-Baroni-Zamparelli",
            "title": {
                "fragments": [],
                "text": "Nouns are Vectors, Adjectives are Matrices: Representing Adjective-Noun Constructions in Semantic Space"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This work proposes an approach to adjective-noun composition (AN) for corpus-based distributional semantics that represents nouns as vectors and adjectives as data-induced (linear) functions over nominal vectors, and shows that the model significantly outperforms the rivals on the task of reconstructing AN vectors not seen in training."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689647"
                        ],
                        "name": "Peter D. Turney",
                        "slug": "Peter-D.-Turney",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Turney",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter D. Turney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990190"
                        ],
                        "name": "P. Pantel",
                        "slug": "P.-Pantel",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Pantel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pantel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1500900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a0e788268fafb23ab20da0e98bb578b06830f7d",
            "isKey": false,
            "numCitedBy": 2724,
            "numCiting": 208,
            "paperAbstract": {
                "fragments": [],
                "text": "Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term-document, word-context, and pair-pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field."
            },
            "slug": "From-Frequency-to-Meaning:-Vector-Space-Models-of-Turney-Pantel",
            "title": {
                "fragments": [],
                "text": "From Frequency to Meaning: Vector Space Models of Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs, and to provide pointers into the literature for those who are less familiar with the field."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8729431"
                        ],
                        "name": "Sida I. Wang",
                        "slug": "Sida-I.-Wang",
                        "structuredName": {
                            "firstName": "Sida",
                            "lastName": "Wang",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sida I. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 217537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc0975ae518a5b30e60fde23a41c74bafd7c6f8c",
            "isKey": false,
            "numCitedBy": 1090,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/dataset. We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the opposite result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets. Based on these observations, we identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level."
            },
            "slug": "Baselines-and-Bigrams:-Simple,-Good-Sentiment-and-Wang-Manning",
            "title": {
                "fragments": [],
                "text": "Baselines and Bigrams: Simple, Good Sentiment and Topic Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that the inclusion of word bigram features gives consistent gains on sentiment analysis tasks, and a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111787388"
                        ],
                        "name": "Jason Williams",
                        "slug": "Jason-Williams",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 114
                            }
                        ],
                        "text": "The automated recognition of dialogue acts is crucial for dialogue state tracking within spoken dialogue systems (Williams, 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7534990,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "65b8fbe4ef37b30348dd592076ccd35b46dac29d",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief tracking is a promising technique for adding robustness to spoken dialog systems, but current research is fractured across different teams, techniques, and domains. This paper amplifies past informal discussions (Raux, 2011) to call for a belief tracking challenge task, based on the Spoken dialog challenge corpus (Black et al., 2011). Benefits, limitations, evaluation design issues, and next steps are presented."
            },
            "slug": "A-belief-tracking-challenge-task-for-spoken-dialog-Williams",
            "title": {
                "fragments": [],
                "text": "A belief tracking challenge task for spoken dialog systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Past informal discussions are amplified to call for a belief tracking challenge task, based on the Spoken dialog challenge corpus, and benefits, limitations, evaluation design issues, and next steps are presented."
            },
            "venue": {
                "fragments": [],
                "text": "SDCTD@NAACL-HLT"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746371"
                        ],
                        "name": "R. Mitkov",
                        "slug": "R.-Mitkov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Mitkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mitkov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1722622,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6ebad228afdc36686b2258921e5d040705270ae3",
            "isKey": false,
            "numCitedBy": 610,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This collection of invited papers covers a lot of ground in its nearly 800 pages, so any review of reasonable length will necessarily be selective. However, there are a number of features that make the book as a whole a comparatively easy and thoroughly rewarding read. Multiauthor compendia of this kind are often disjointed, with very little uniformity from chapter to chapter in terms of breadth, depth, and format. Such is not the case here. Breadth and depth of treatment are surprisingly consistent, with coherent formats that often include both a little history of the field and some thoughts about the future. The volume has a very logical structure in which the chapters flow and follow on from each other in an orderly fashion. There are also many cross-references between chapters, which allow the authors to build upon the foundation of one another's work and eliminate redundancies. Specifically, the contents consist of 38 survey papers grouped into three parts: Fundamentals; Processes, Methods, and Resources; and Applications. Taken together, they provide both a comprehensive introduction to the field and a useful reference volume. In addition to the usual author and subject matter indices, there is a substantial glossary that students will find invaluable. Each chapter ends with a bibliography, together with tips for further reading and mention of other resources, such as conferences , workshops, and URLs. Part I covers the full spectrum of linguistic levels of analysis from a largely theoretical point of view, including phonology, morphology, lexicography, syntax, semantics, discourse, and dialogue. The result is a layered approach to the subject matter that allows each new level to take the previous level for granted. However, the authors do not typically restrict themselves to linguistic theory. For example, Hanks's chapter on lexicography characterizes the deficiencies of both hand-built and corpus-based dictionaries , as well as discussing other practical problems, such as how to link meaning and use. The phonology and morphology chapters provide fine introductions to these topics, which tend to receive short shrift in many NLP and AI texts. Part I ends with two chapters, one on formal grammars and one on complexity, which round out the computational aspect. This is an excellent pairing, with Mart\u00edn-Vide's thorough treatment of regular and context-free languages leading into Carpen-ter's masterly survey of problem complexity and practical efficiency. Part II is more task based, with a focus on such activities as text segmentation, \u2026"
            },
            "slug": "The-Oxford-handbook-of-computational-linguistics-Mitkov",
            "title": {
                "fragments": [],
                "text": "The Oxford handbook of computational linguistics"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This collection of invited papers covers a lot of ground in its nearly 800 pages, so any review of reasonable length will necessarily be selective, but there are a number of features that make the book as a whole a comparatively easy and thoroughly rewarding read."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 206
                            }
                        ],
                        "text": "The hierarchy of feature-wise convolution operations followed by sigmoid non-linear activation functions results in a hierarchical convolutional neural network (HCNN) based on a convolutional architecture (LeCun et al., 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35282,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144494993"
                        ],
                        "name": "R. Jones",
                        "slug": "R.-Jones",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068774701"
                        ],
                        "name": "Benjamin Rey",
                        "slug": "Benjamin-Rey",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Rey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Rey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734627"
                        ],
                        "name": "Omid Madani",
                        "slug": "Omid-Madani",
                        "structuredName": {
                            "firstName": "Omid",
                            "lastName": "Madani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omid Madani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153688898"
                        ],
                        "name": "W. Greiner",
                        "slug": "W.-Greiner",
                        "structuredName": {
                            "firstName": "Wiley",
                            "lastName": "Greiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Greiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 238
                            }
                        ],
                        "text": "To this end much work has been done on modelling the meaning of single words by way of semantic vectors (Turney and Pantel, 2010; Collobert and Weston, 2008) and the latter have found applicability in areas such as information retrieval (Jones et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207159138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0fd30ce8d311cb97725670b5a176cec8ac71677",
            "isKey": false,
            "numCitedBy": 707,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the notion of query substitution, that is, generating a new query to replace a user's original search query. Our technique uses modifications based on typical substitutions web searchers make to their queries. In this way the new query is strongly related to the original query, containing terms closely related to all of the original terms. This contrasts with query expansion through pseudo-relevance feedback, which is costly and can lead to query drift. This also contrasts with query relaxation through boolean or TFIDF retrieval, which reduces the specificity of the query. We define a scale for evaluating query substitution, and show that our method performs well at generating new queries related to the original queries. We build a model for selecting between candidates, by using a number of features relating the query-candidate pair, and by fitting the model to human judgments of relevance of query suggestions. This further improves the quality of the candidates generated. Experiments show that our techniques significantly increase coverage and effectiveness in the setting of sponsored search."
            },
            "slug": "Generating-query-substitutions-Jones-Rey",
            "title": {
                "fragments": [],
                "text": "Generating query substitutions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A model for selecting between candidates is built, by using a number of features relating the query-candidate pair, and by fitting the model to human judgments of relevance of query suggestions, which improves the quality of the candidates generated."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2599162"
                        ],
                        "name": "E. Zalta",
                        "slug": "E.-Zalta",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Zalta",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Zalta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2687250"
                        ],
                        "name": "U. Nodelman",
                        "slug": "U.-Nodelman",
                        "structuredName": {
                            "firstName": "Uri",
                            "lastName": "Nodelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Nodelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30308222"
                        ],
                        "name": "C. Allen",
                        "slug": "C.-Allen",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Allen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48525894"
                        ],
                        "name": "Jack Perry",
                        "slug": "Jack-Perry",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Perry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jack Perry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality, pages 119\u2013126, Sofia, Bulgaria, August 9 2013. c\u00a92013 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 102344678,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "29826ea86aff3025a9b4baaba47ea3e2772c006d",
            "isKey": false,
            "numCitedBy": 4746,
            "numCiting": 1618,
            "paperAbstract": {
                "fragments": [],
                "text": "Evolutionary psychology is one of many biologically informed approaches to the study of human behavior. Along with cognitive psychologists, evolutionary psychologists propose that much, if not all, of our behavior can be explained by appeal to internal psychological mechanisms. What distinguishes evolutionary psychologists from many cognitive psychologists is the proposal that the relevant internal mechanisms are adaptations\u2014products of natural selection\u2014that helped our ancestors get around the world, survive and reproduce. To understand the central claims of evolutionary psychology we require an understanding of some key concepts in evolutionary biology, cognitive psychology, philosophy of science and philosophy of mind. Philosophers are interested in evolutionary psychology for a number of reasons. For philosophers of science \u2014mostly philosophers of biology\u2014evolutionary psychology provides a critical target. There is a broad consensus among philosophers of science that evolutionary psychology is a deeply flawed enterprise. For philosophers of mind and cognitive science evolutionary psychology has been a source of empirical hypotheses about cognitive architecture and specific components of that architecture. Philosophers of mind are also critical of evolutionary psychology but their criticisms are not as all-encompassing as those presented by philosophers of biology. Evolutionary psychology is also invoked by philosophers interested in moral psychology both as a source of empirical hypotheses and as a critical target."
            },
            "slug": "Stanford-Encyclopedia-of-Philosophy-Zalta-Nodelman",
            "title": {
                "fragments": [],
                "text": "Stanford Encyclopedia of Philosophy"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "To understand the central claims of evolutionary psychology the authors require an understanding of some key concepts in evolutionary biology, cognitive psychology, philosophy of science and philosophy of mind."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 61
                            }
                        ],
                        "text": "The derivatives are efficiently computed by back-propagation (Rumelhart et al., 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19357,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102157754"
                        ],
                        "name": "G. Frege",
                        "slug": "G.-Frege",
                        "structuredName": {
                            "firstName": "Gottlob",
                            "lastName": "Frege",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Frege"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 161
                            }
                        ],
                        "text": "The first level is that of sentential compositionality, where the meaning of words composes to form the meaning of the sentence or utterance that contains them (Frege, 1892)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 170163815,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "d7667992907417ee46c7a5ff541006cf6e6a7748",
            "isKey": false,
            "numCitedBy": 1706,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Die Gleichheit fordert das Nachdenken heraus durch Fragen, die sich daran knupfen und nicht ganz leicht zu beantworten sind. Ist sie eine Beziehung? eine Beziehung zwischen Gegenstanden? oder zwischen Namen oder Zeichen fur Gegenstande? Das letzte hatte ich in meiner Begriffsschrift angenommen. Die Grunde, die dafur zu sprechen scheinen, sind folgende: a=a und a=b sind offenbar Satze von verschiedenem Erkenntniswerte: a=a gilt a priori und ist nach Kant analytisch zu nennen, wahrend Satze von der Form a=b oft sehr wertvolle Erweiterungen unserer Erkenntnis enthalten und a priori nicht immer zu begrunden sind. Die Entdeckung, das nicht jeden Morgen eine neue Sonne aufgeht, sondern immer dieselbe, ist wohl eine der folgenreichsten in der Astronomie gewesen. Noch jetzt ist die Wiedererkennung eines kleinen Planeten oder eines Kometen\nnicht immer etwas Selbstverstandliches."
            },
            "slug": "\u00dcber-Sinn-und-Bedeutung-Frege",
            "title": {
                "fragments": [],
                "text": "\u00dcber Sinn und Bedeutung"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1892
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50521580"
                        ],
                        "name": "J. Austin",
                        "slug": "J.-Austin",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Austin",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Austin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 107
                            }
                        ],
                        "text": "A dialogue act specifies the pragmatic role of an utterance and helps identifying the speaker\u2019s intentions (Austin, 1962; Korta and Perry, 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 170896069,
            "fieldsOfStudy": [
                "Chemistry",
                "Physics"
            ],
            "id": "8f8344fc2f4edd7cb4bc042c7de1dfbebb09793f",
            "isKey": false,
            "numCitedBy": 9707,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "* Lecture I * Lecture II * Lecture III * Lecture IV * Lecture V * Lecture VI * Lecture VII * Lecture VIII * Lecture IX * Lecture X * Lecture XI * Lecture XII"
            },
            "slug": "How-to-do-things-with-words-Austin",
            "title": {
                "fragments": [],
                "text": "How to do things with words"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69547851"
                        ],
                        "name": "\u6728\u6751 \u548c\u592b",
                        "slug": "\u6728\u6751-\u548c\u592b",
                        "structuredName": {
                            "firstName": "\u6728\u6751",
                            "lastName": "\u548c\u592b",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u6728\u6751 \u548c\u592b"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 200
                            }
                        ],
                        "text": "The meaning of discourse - and of words and utterances within it - is often a result of a rich ensemble of context, of speakers\u2019 intentions and actions and of other relevant surrounding circumstances (Korta and Perry, 2012; Potts, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 233
                            }
                        ],
                        "text": "The second level extends beyond the first and involves general discourse compositionality, where the meaning of multiple sentences or utterances composes to form the meaning of the paragraph, document or dialogue that comprises them (Korta and Perry, 2012; Potts, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 211814011,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "eed21ec2be5278a929f03bbbd82a719a2715f270",
            "isKey": false,
            "numCitedBy": 3777,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "\u8a9e\u7528\u8ad6(Pragmatics)\u3092\u8003\u3048\u308b-\u6728\u6751",
            "title": {
                "fragments": [],
                "text": "\u8a9e\u7528\u8ad6(Pragmatics)\u3092\u8003\u3048\u308b"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35001952"
                        ],
                        "name": "P. Kleingeld",
                        "slug": "P.-Kleingeld",
                        "structuredName": {
                            "firstName": "Pauline",
                            "lastName": "Kleingeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kleingeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115047421"
                        ],
                        "name": "E. Brown",
                        "slug": "E.-Brown",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brown",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brown"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 157111066,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "f6c6b101b4d4e34fc13079300e7f013bb82511ab",
            "isKey": false,
            "numCitedBy": 2936,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stanford-Encyclopedia-of-Philosophy-Kleingeld-Brown",
            "title": {
                "fragments": [],
                "text": "Stanford Encyclopedia of Philosophy"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48990536"
                        ],
                        "name": "Csr Young",
                        "slug": "Csr-Young",
                        "structuredName": {
                            "firstName": "Csr",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Csr Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 107
                            }
                        ],
                        "text": "A dialogue act specifies the pragmatic role of an utterance and helps identifying the speaker\u2019s intentions (Austin, 1962; Korta and Perry, 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64687852,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "82973e55983f57b9cdd165f9318f7dedc9cee8ae",
            "isKey": false,
            "numCitedBy": 8391,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "How-to-Do-Things-With-Words-Young",
            "title": {
                "fragments": [],
                "text": "How to Do Things With Words"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3215185"
                        ],
                        "name": "G. Sampson",
                        "slug": "G.-Sampson",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Sampson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sampson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 223
                            }
                        ],
                        "text": "The meaning of discourse - and of words and utterances within it - is often a result of a rich ensemble of context, of speakers\u2019 intentions and actions and of other relevant surrounding circumstances (Korta and Perry, 2012; Potts, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality, pages 119\u2013126, Sofia, Bulgaria, August 9 2013. c\u00a92013 Association for Computational Linguistics"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 257
                            }
                        ],
                        "text": "The second level extends beyond the first and involves general discourse compositionality, where the meaning of multiple sentences or utterances composes to form the meaning of the paragraph, document or dialogue that comprises them (Korta and Perry, 2012; Potts, 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12112985,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "7c7d92f5b791069b67749f6203b08f88d1c82ad8",
            "isKey": false,
            "numCitedBy": 260,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Oxford-Handbook-of-Computational-Linguistics-Sampson",
            "title": {
                "fragments": [],
                "text": "The Oxford Handbook of Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "Lit. Linguistic Comput."
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 182
                            }
                        ],
                        "text": "In addition, the recognition of dialogue acts within dialogues has largely been treated in non-compositional ways by way of language models coupled to hidden Markov sequence models (Stolcke et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 21
                            }
                        ],
                        "text": "The LM-HMM model of (Stolcke et al., 2000) learns a language model for each dialogue act and a Hidden Markov Model for the sequence of dialogue acts and it requires all the utterances in a dialogue in order to predict the dialogue act of any one of the utterances."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 87
                            }
                        ],
                        "text": "We adopt the same data split of 1115 train dialogues and 19 test dialogues as used in (Stolcke et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dialog act modeling for automatic tagging and recognition of conversational"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Frege1892] Gottlob Frege. 1892. \u00a8 Uber Sinn und Bedeutung"
            },
            "venue": {
                "fragments": [],
                "text": "Zeitschrift f\u00fcr Philosophie und philosophische Kritik"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 181
                            }
                        ],
                        "text": "In addition, the recognition of dialogue acts within dialogues has largely been treated in non-compositional ways by way of language models coupled to hidden Markov sequence models (Stolcke et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 20
                            }
                        ],
                        "text": "The LM-HMM model of (Stolcke et al., 2000) learns a language model for each dialogue act and a Hidden Markov Model for the sequence of dialogue acts and it requires all the utterances in a dialogue in order to predict the dialogue act of any one of the utterances."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 86
                            }
                        ],
                        "text": "We adopt the same data split of 1115 train dialogues and 19 test dialogues as used in (Stolcke et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dialog act modeling for automatic tagging"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cutting recursive autoencoder trees. CoRR, abs/1301.2811"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cutting recursive autoencoder trees. CoRR, abs/1301"
            },
            "venue": {
                "fragments": [],
                "text": "Cutting recursive autoencoder trees. CoRR, abs/1301"
            },
            "year": 2013
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Recurrent-Convolutional-Neural-Networks-for-Kalchbrenner-Blunsom/cd96a6e0b6bb099c515be8770764d2fd18e7b878?sort=total-citations"
}