{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 127
                            }
                        ],
                        "text": "The consistency of the matches found is tested using semi-local constraints, followed by a test on the epipolar geometry using RANSAC."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 144
                            }
                        ],
                        "text": "\u2026rejected most false matches among the region correspondences using the geometric and photometric constraints described above, we apply RANSAC (Fischler and Bolles, 1981) (a robust method based on random sampling) to find a consistent epipolar geometry and to reject the remaining false\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 148
                            }
                        ],
                        "text": "After having rejected most false matches among the region correspondences using the geometric and photometric constraints described above, we apply RANSAC (Fischler and Bolles, 1981) (a robust method based on random sampling) to find a consistent epipolar geometry and to reject the remaining false correspondences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 109
                            }
                        ],
                        "text": "The best known constraint is checking for a consistent epipolar geometry in a robust way, e.g. using RANSAC (Fischler and Bolles, 1981), and rejecting all correspondences not conform with the epipolar geometry found."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 44
                            }
                        ],
                        "text": "Finally, we applied the epipolar test using RANSAC to automatically select the good matches, and verified these matches visually, subdividing them into three different categories: correct, symmetric and false."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 75
                            }
                        ],
                        "text": "Checking these constraints first before testing the epipolar geometry with RANSAC can considerably improve the results under the hard conditions of wide baseline stereo."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "RANSAC is then applied to the resulting set of point correspondences."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 199
                            }
                        ],
                        "text": "Each time, the upper part of the figure shows the regions that contributed to the epipolar geometry, i.e. those that were matched and survived both the geometric and photometric filtering as well as RANSAC."
                    },
                    "intents": []
                }
            ],
            "corpusId": 972888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278c9a78d4505cfaf6b709df364dbd1206a017c1",
            "isKey": true,
            "numCitedBy": 15951,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing"
            },
            "slug": "Random-sample-consensus:-a-paradigm-for-model-with-Fischler-Bolles",
            "title": {
                "fragments": [],
                "text": "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "New results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form that provide the basis for an automatic system that can solve the Location Determination Problem under difficult viewing."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 433,
                                "start": 348
                            }
                        ],
                        "text": "In summary, our system differs from other wide baseline stereo methods in that we do not apply a search between images but process each image and each local feature individually (Gruen, 1985; Super and Klarquist, 1997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997; Dufournaud et al., 2000) and in that we can deal with general 3D objects without assuming specific structures to be present in the image (Pritchett and Zisserman, 1998; Tell and Carlsson, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 14
                            }
                        ],
                        "text": "For instance, Lowe (1999) uses extrema of a difference of Gaussians filter."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1248,
                                "start": 80
                            }
                        ],
                        "text": "The consistency of the matches found is tested using semi-local constraints, followed by a test on the epipolar geometry using RANSAC. As shown in the experimental results, the feasibility of affine invariance even on a local scale has been demonstrated. Robust matching is quite a generic problem in vision and several other applications can be considered. Object recognition is one, where images of an object can be matched against a small set of reference images of the same object. The sample set can be kept small because of the invariance. Moreover, as the features are local, recognition against variable backgrounds and under occlusion is supported by this method. Another application is grouping, where symmetries can be found as repeated structures. Image database retrieval can also benefit from these regions, where other pictures of the same scene or object can be found. Here, the viewpoint and illumination invariance gives the system the capacity to generalize to a great extent from a single query image. Finally, being able to match a current view against learned views can allow robots to roam extended spaces, without the need for a 3D model. Initial results for such applications can be found in Tuytelaars and Van Gool (1999), Tuytelaars et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 148
                            }
                        ],
                        "text": "\u2026Klarquist, 1997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997; Dufournaud et al., 2000) and in that we can deal with general 3D objects without assuming\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Lowe (1999) has extended these ideas to real scale-invariance, using circular regions that maximize the output of a difference of gaussian filters in scale space, while Hall et al. (1999) not only applied automatic scale selection (based on Lindeberg (1998)), but also retrieved the orientation of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1274,
                                "start": 80
                            }
                        ],
                        "text": "The consistency of the matches found is tested using semi-local constraints, followed by a test on the epipolar geometry using RANSAC. As shown in the experimental results, the feasibility of affine invariance even on a local scale has been demonstrated. Robust matching is quite a generic problem in vision and several other applications can be considered. Object recognition is one, where images of an object can be matched against a small set of reference images of the same object. The sample set can be kept small because of the invariance. Moreover, as the features are local, recognition against variable backgrounds and under occlusion is supported by this method. Another application is grouping, where symmetries can be found as repeated structures. Image database retrieval can also benefit from these regions, where other pictures of the same scene or object can be found. Here, the viewpoint and illumination invariance gives the system the capacity to generalize to a great extent from a single query image. Finally, being able to match a current view against learned views can allow robots to roam extended spaces, without the need for a 3D model. Initial results for such applications can be found in Tuytelaars and Van Gool (1999), Tuytelaars et al. (1999) and Turina et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1299,
                                "start": 80
                            }
                        ],
                        "text": "The consistency of the matches found is tested using semi-local constraints, followed by a test on the epipolar geometry using RANSAC. As shown in the experimental results, the feasibility of affine invariance even on a local scale has been demonstrated. Robust matching is quite a generic problem in vision and several other applications can be considered. Object recognition is one, where images of an object can be matched against a small set of reference images of the same object. The sample set can be kept small because of the invariance. Moreover, as the features are local, recognition against variable backgrounds and under occlusion is supported by this method. Another application is grouping, where symmetries can be found as repeated structures. Image database retrieval can also benefit from these regions, where other pictures of the same scene or object can be found. Here, the viewpoint and illumination invariance gives the system the capacity to generalize to a great extent from a single query image. Finally, being able to match a current view against learned views can allow robots to roam extended spaces, without the need for a 3D model. Initial results for such applications can be found in Tuytelaars and Van Gool (1999), Tuytelaars et al. (1999) and Turina et al. (2001)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": true,
            "numCitedBy": 16255,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 404,
                                "start": 208
                            }
                        ],
                        "text": "Nevertheless, they obtained remarkable results in the context of short baseline stereo, object recognition and database retrieval\u2014for later versions of their system even in spite of very large scale changes (Dufournaud et al., 2000). Similar results have been reported for color images by Montesinos et al. (2000). Some extensions towards affine invariant regions have been reported as well. Lowe (1999) has extended these ideas to real scale-invariance, using circular regions that maximize the output of a difference of gaussian filters in scale space, while Hall et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 207
                            }
                        ],
                        "text": "Nevertheless, they obtained remarkable results in the context of short baseline stereo, object recognition and database retrieval\u2014for later versions of their system even in spite of very large scale changes (Dufournaud et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 314,
                                "start": 208
                            }
                        ],
                        "text": "Nevertheless, they obtained remarkable results in the context of short baseline stereo, object recognition and database retrieval\u2014for later versions of their system even in spite of very large scale changes (Dufournaud et al., 2000). Similar results have been reported for color images by Montesinos et al. (2000). Some extensions towards affine invariant regions have been reported as well."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 433,
                                "start": 348
                            }
                        ],
                        "text": "In summary, our system differs from other wide baseline stereo methods in that we do not apply a search between images but process each image and each local feature individually (Gruen, 1985; Super and Klarquist, 1997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997; Dufournaud et al., 2000) and in that we can deal with general 3D objects without assuming specific structures to be present in the image (Pritchett and Zisserman, 1998; Tell and Carlsson, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 147
                            }
                        ],
                        "text": "\u2026we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997; Dufournaud et al., 2000) and in that we can deal with general 3D objects without assuming specific structures to be present in the image (Pritchett\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 580,
                                "start": 208
                            }
                        ],
                        "text": "Nevertheless, they obtained remarkable results in the context of short baseline stereo, object recognition and database retrieval\u2014for later versions of their system even in spite of very large scale changes (Dufournaud et al., 2000). Similar results have been reported for color images by Montesinos et al. (2000). Some extensions towards affine invariant regions have been reported as well. Lowe (1999) has extended these ideas to real scale-invariance, using circular regions that maximize the output of a difference of gaussian filters in scale space, while Hall et al. (1999) not only applied automatic scale selection (based on Lindeberg (1998)), but also retrieved the orientation of the circular region in an unambiguous way."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matching image with different resolutions"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. on Computer Vision and Pattern Recognition, pp. 612\u2013618."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2891524"
                        ],
                        "name": "Yves Dufournaud",
                        "slug": "Yves-Dufournaud",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Dufournaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yves Dufournaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794229"
                        ],
                        "name": "R. Horaud",
                        "slug": "R.-Horaud",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Horaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Horaud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 207
                            }
                        ],
                        "text": "Nevertheless, they obtained remarkable results in the context of short baseline stereo, object recognition and database retrieval\u2014for later versions of their system even in spite of very large scale changes (Dufournaud et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 147
                            }
                        ],
                        "text": "\u2026we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997; Dufournaud et al., 2000) and in that we can deal with general 3D objects without assuming specific structures to be present in the image (Pritchett\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In summary, our system differs from other wide baseline stereo methods in that we do not apply a search between images but process each image and each local feature individually (Gruen, 1985; Super and Klarquist, 1997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997;  Dufournaud et al., 2000 ) and in ..."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Nevertheless, they obtained remarkable results in the context of short baseline stereo, object recognition and database retrieval\u2014for later versions of their system even in spite of very large scale changes ( Dufournaud et al., 2000 )."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 13979044,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "501e089c923e099ad235e0269df8ed37a10a98fb",
            "isKey": true,
            "numCitedBy": 190,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of matching two images with two different resolutions: a high-resolution image and a low-resolution one. On the premise that changes in resolution act as a smoothing equivalent to changes in scale, a scale-space representation of the high-resolution image is produced. Hence the one-to-one classical image matching paradigm becomes one-to-many because the low-resolution image is compared with all the scale-space representations of the high-resolution one. Key to the success of such a process is the proper representation of the features to be matched in scale-space. We show how to extract interest points at variable scales and we devise a method allowing the comparison of two images at two different resolutions. The method comprises the use of photometric- and rotation-invariant descriptors, a geometric model mapping the high-resolution image onto a low-resolution image region, and an image matching strategy based on the robust estimation of this geometric model. Extensive experiments show that our matching method can be used for scale changes up to a factor 6."
            },
            "slug": "Matching-images-with-different-resolutions-Dufournaud-Schmid",
            "title": {
                "fragments": [],
                "text": "Matching images with different resolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper shows how to extract interest points at variable scales and devise a method allowing the comparison of two images at two different resolutions, which comprises the use of photometric- and rotation-invariant descriptors, a geometric model mapping the high-resolution image onto a low- resolution image region, and an image matching strategy based on the robust estimation of this geometric model."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1919611"
                        ],
                        "name": "Florica Mindru",
                        "slug": "Florica-Mindru",
                        "structuredName": {
                            "firstName": "Florica",
                            "lastName": "Mindru",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florica Mindru"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2525101"
                        ],
                        "name": "T. Moons",
                        "slug": "T.-Moons",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Moons",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Moons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 80
                            }
                        ],
                        "text": "The moments we use are Generalized Color Moments, which have been introduced in Mindru et al. (1999) to better exploit the multi-spectral nature of the data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 73
                            }
                        ],
                        "text": "An important source of inspiration for our approach has been the work of Schmid et al. (1997). They identify special \u2018points of interest\u2019 (in casu corners) and extract 2D translation and 2D rotation invariant features from the intensity pattern in fixed circular regions around these points (in casu the local jet as defined by Koenderink and Van Doorn (1987), based on Gaussian derivatives of image intensity)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 149
                            }
                        ],
                        "text": "\u2026very well possible to construct a feature vector that is in itself invariant to all the geometric and\nphotometric transformations we consider (e.g. Mindru et al., 1999), our experiments show that better results are obtained if one first compensates for (part of) the deformations through an extra\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7100288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee146084f94c240857206208c214aa37951db244",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "New invariant features are presented that can be used for the recognition of planar color patterns such as labels, logos, pictograms, etc., irrespective of the viewpoint or the illumination conditions, and without the need for error prone contour extraction. The new features are based on moments of powers of the intensities in the individual color bands and combinations thereof. These moments implicitly characterize the shape, the intensity and the color distribution of the pattern in a uniform manner. The paper gives a classification of all functions of such moments which are invariant under both affine deformations of the pattern (thus achieving viewpoint invariance) as well as linear changes of the intensity values of the color bands (hence, coping with changes in the irradiance pattern due to different lighting conditions and/or viewpoints). The discriminant power and classification performance of the new invariants for color pattern recognition is tested on a data set of images of outdoors advertising panels. A comparison to moment invariants presented in literature is included as well."
            },
            "slug": "Recognizing-color-patterns-irrespective-of-and-Mindru-Moons",
            "title": {
                "fragments": [],
                "text": "Recognizing color patterns irrespective of viewpoint and illumination"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "New invariant features are presented that can be used for the recognition of planar color patterns such as labels, logos, pictograms, etc., irrespective of the viewpoint or the illumination conditions, and without the need for error prone contour extraction."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40316280"
                        ],
                        "name": "Dennis Tell",
                        "slug": "Dennis-Tell",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Tell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dennis Tell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 120
                            }
                        ],
                        "text": ", 2000) and in that we can deal with general 3D objects without assuming specific structures to be present in the image (Pritchett and Zisserman, 1998; Tell and Carlsson, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 265
                            }
                        ],
                        "text": "\u2026caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997; Dufournaud et al., 2000) and in that we can deal with general 3D objects without assuming specific structures to be present in the image (Pritchett and Zisserman, 1998; Tell and Carlsson, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Tell and Carlsson (2000) also proposed a wide baseline correspondence method based on affine invariance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38014951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a6ea7bd5be7631f671ea0069bc296cc51654895",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of establishing correspondences between images taken from different viewpoints is fundamental in computer vision. We propose an algorithm which is capable of handling larger changes in viewpoint than classical correlation based techniques. Optimal performance for the algorithm is achieved for textured objects which are locally planar in at least one direction. The algorithm works by computing affinely invariant fourier features from intensity profiles in each image. The intensity profiles are extracted from the image data between randomly selected pairs of image interest points. Using a voting scheme, pairs of interest points are matched across images by comparing vectors of fourier features. Outliers among the matches are rejected in two stages, a fast stage using novel view consistency constraints, and a second, slower stage using RANSAC and fundamental matrix computation. In order to demonstrate the quality of the results, the algorithm is tested on several different image pairs."
            },
            "slug": "Wide-Baseline-Point-Matching-Using-Affine-Computed-Tell-Carlsson",
            "title": {
                "fragments": [],
                "text": "Wide Baseline Point Matching Using Affine Invariants Computed from Intensity Profiles"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm which is capable of handling larger changes in viewpoint than classical correlation based techniques is proposed, which works by computing affinely invariant fourier features from intensity profiles in each image."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22188121,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "979089260419884b43cfeb3b23df23b6a7734f9f",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This contribution develops a new technique for content-based image retrieval. Where most existing image retrieval systems mainly focus on color and color distribution or texture, we classify the images based on local invariants. These features represent the image in a very compact way and allow fast comparison and feature matching with images in the database. Using local features makes the system robust to occlusions and changes in the background. Using invariants makes it robust to changes in viewpoint and illumination."
            },
            "slug": "Content-Based-Image-Retrieval-Based-on-Local-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Content-Based Image Retrieval Based on Local Affinely Invariant Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This contribution develops a new technique for content-based image retrieval that classify the images based on local invariants that represent the image in a very compact way and allow fast comparison and feature matching with images in the database."
            },
            "venue": {
                "fragments": [],
                "text": "VISUAL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704228"
                        ],
                        "name": "A. Turina",
                        "slug": "A.-Turina",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Turina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Turina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206763775,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7f44427127869be90851d55aae2e6aff80a9f0d",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a geometric framework for the efficient detection of regular repetitions of planar (but not necessarily coplanar) patterns. At the heart of our system, lie the fixed structures of the transformations that describe these regular configurations. The approach detects a number of symmetric configurations that have traditionally been dealt with separately, in that all configurations corresponding to planar homologies are detected. These include important cases such as periodicities, mirror symmetries, and reflections about a point. The approach can handle perspective distortions. It avoids to get trapped in combinatorics; through invariant-based hashing for pattern matching and through Hough transforms for the detection of fixed structures. Additional efficiency and robustness are obtained from the system's ability to \"reason\" about the consistency of multiple homologies. The performance of the system is demonstrated with several examples."
            },
            "slug": "Noncombinatorial-Detection-of-Regular-Repetitions-Tuytelaars-Turina",
            "title": {
                "fragments": [],
                "text": "Noncombinatorial Detection of Regular Repetitions under Perspective Skew"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A geometric framework for the efficient detection of regular repetitions of planar (but not necessarily coplanar) patterns through invariant-based hashing for pattern matching and through Hough transforms for the detection of fixed structures."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7977369"
                        ],
                        "name": "A. Doorn",
                        "slug": "A.-Doorn",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Doorn",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doorn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Lindeberg and G\u0227rding (1997) on the other hand have developed a method to find blob-like regions using an iterative scheme, in the context of shape from texture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 595,
                                "start": 0
                            }
                        ],
                        "text": "Lindeberg and G\u0227rding (1997) on the other hand have developed a method to find blob-like regions using an iterative scheme, in the context of shape from texture. In the case of weak isotropy, the regions found by their algorithm correspond to rotationally symmetric smoothing and rotationally symmetric window functions in the tangent plane to the surface. However, in general, their method does not necessarily converge, as there are, in most cases, at least two additional attraction points. Similar ideas have recently been used for wide baseline stereo by Schaffalitzky and Zisserman (2001). First, they roughly match textured regions in the image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 24284500,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "00aa5220d49f3fcf357c1b64ac14f24cd8afb76d",
            "isKey": false,
            "numCitedBy": 626,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that a convolution with certain reasonable receptive field (RF) profiles yields the exact partial derivatives of the retinal illuminance blurred to a specified degree. Arbitrary concatenations of such RF profiles yield again similar ones of higher order and for a greater degree of blurring.By replacing the illuminance with its third order jet extension we obtain position dependent geometries. It is shown how such a representation can function as the substrate for \u201cpoint processors\u201d computing geometrical features such as edge curvature. We obtain a clear dichotomy between local and multilocal visual routines. The terms of the truncated Taylor series representing the jets are partial derivatives whose corresponding RF profiles closely mimic the well known units in the primary visual cortex. Hence this description provides a novel means to understand and classify these units.Taking the receptive field outputs as the basic input data one may devise visual routines that compute geometric features on the basis of standard differential geometry exploiting the equivalence with the local jets (partial derivatives with respect to the space coordinates)."
            },
            "slug": "Representation-of-local-geometry-in-the-visual-Koenderink-Doorn",
            "title": {
                "fragments": [],
                "text": "Representation of local geometry in the visual system"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "It is shown that a convolution with certain reasonable receptive field (RF) profiles yields the exact partial derivatives of the retinal illuminance blurred to a specified degree and how this representation can function as the substrate for \u201cpoint processors\u201d computing geometrical features such as edge curvature."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3260234"
                        ],
                        "name": "J. G\u00e5rding",
                        "slug": "J.-G\u00e5rding",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "G\u00e5rding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. G\u00e5rding"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 104
                            }
                        ],
                        "text": "Baumberg (2000) proposed a wide baseline system that is based on a simplified version of the regions of Lindeberg and Ga\u0307rding (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Lindeberg and Ga\u0307rding (1997) on the other hand have developed a method to find blob-like regions using an iterative scheme, in the context of shape from texture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18264626,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f87bcdf4a0dc79f85e171ec26733424d0e459cd2",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Shape-adapted-smoothing-in-estimation-of-3-D-shape-Lindeberg-G\u00e5rding",
            "title": {
                "fragments": [],
                "text": "Shape-adapted smoothing in estimation of 3-D shape cues from affine deformations of local 2-D brightness structure"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859042"
                        ],
                        "name": "D. Hall",
                        "slug": "D.-Hall",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2481445"
                        ],
                        "name": "V. Verdi\u00e8re",
                        "slug": "V.-Verdi\u00e8re",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Verdi\u00e8re",
                            "middleNames": [
                                "Colin",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Verdi\u00e8re"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687022"
                        ],
                        "name": "J. Crowley",
                        "slug": "J.-Crowley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crowley",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crowley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 868624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a881611042fa91b72689d90307fefd84c28dd5fc",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an extension of a technique for the recognition and tracking of every day objects in cluttered scenes. The goal is to build a system in which ordinary desktop objects serve as physical icons in a vision based system for man-machine interaction. In such a system, the manipulation of objects replaces user commands. \n \nA view-variant recognition technique, developed by the second author, has been adapted by the first author for a problem of recognising and tracking objects on a cluttered background in the presence of occlusions. This method is based on sampling a local appearance function at discrete viewpoints by projecting it onto a vector of receptive fields which have been normalised to local scale and orientation. This paper reports on the experimental validation of the approach, and of its extension to the use of receptive fields based on colour. The experimental results indicate that the second author's technique does indeed provide a method for building a fast and robust recognition technique. Furthermore, the extension to coloured receptive fields provides a greater degree of local discrimination and an enhanced robustness to variable background conditions. \n \nThe approach is suitable for the recognition of general objects as physical icons in an augmented reality."
            },
            "slug": "Object-Recognition-Using-Coloured-Receptive-Fields-Hall-Verdi\u00e8re",
            "title": {
                "fragments": [],
                "text": "Object Recognition Using Coloured Receptive Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results indicate that the second author's technique does indeed provide a method for building a fast and robust recognition technique, and its extension to the use of receptive fields based on colour provides a greater degree of local discrimination and an enhanced robustness to variable background conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702012"
                        ],
                        "name": "C. Ballester",
                        "slug": "C.-Ballester",
                        "structuredName": {
                            "firstName": "Coloma",
                            "lastName": "Ballester",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ballester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110033162"
                        ],
                        "name": "Manuel Gonz\u00e1lez",
                        "slug": "Manuel-Gonz\u00e1lez",
                        "structuredName": {
                            "firstName": "Manuel",
                            "lastName": "Gonz\u00e1lez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manuel Gonz\u00e1lez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 66
                            }
                        ],
                        "text": "Two points p1 and p2 move away from the corner in both directions along the edge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15306257,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "7675aafa4fd4aae670e27f87d823002a9bd62e56",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of texture segmentation by using a novel affine invariant model. The introduction of affine invariance as a requirement for texture analysis goes beyond what is known of the human performance and also beyond the psychophysical theories. We propose to compute texture features using affine invariant intrinsic neighborhoods and affine invariant intrinsic orientation matrices. We discuss several possibilities for the definition of the channels and give comparative experimental results where an affine invariant Mumford-Shah type energy functional is used to compute the multichannel affine invariant segmentation. We prove that the method is able to retrieve faithfully the texture regions and to recover the shape from texture information in images where several textures are present. The numerical algorithm is multiscale."
            },
            "slug": "Affine-Invariant-Texture-Segmentation-and-Shape-by-Ballester-Gonz\u00e1lez",
            "title": {
                "fragments": [],
                "text": "Affine Invariant Texture Segmentation and Shape from Texture by Variational Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is proved that the method is able to retrieve faithfully the texture regions and to recover the shape from texture information in images where several textures are present and the numerical algorithm is multiscale."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Mathematical Imaging and Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055532508"
                        ],
                        "name": "David Sinclair",
                        "slug": "David-Sinclair",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Sinclair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Sinclair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723059"
                        ],
                        "name": "H. Christensen",
                        "slug": "H.-Christensen",
                        "structuredName": {
                            "firstName": "Henrik",
                            "lastName": "Christensen",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Christensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144760431"
                        ],
                        "name": "Charlie Rothwell",
                        "slug": "Charlie-Rothwell",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Rothwell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie Rothwell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Sinclair et al. (1995) proposed a method to test whether two rigid plane motions are compatible based on their homographies H1 and H2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117485683,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "8998e4975922dba58725d0b525b9f3488b491207",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A portable slag beneficiating plant comprises lengthwise adjacent first and second stage sizing devices with an intermediate magnetically operated separating unit arranged to deliver separated metallics to the second stage sizing device and to deliver the separated non-metallic slag to a conveyor for remote accumulation. The first and second stage sizing devices in the slag beneficiating plant and the magnetic separating unit which incorporates a feed conveyor belt and the disposal slag conveyor are individually operated by hydraulic motor subject to the control of individual valves and supplied from a common source of hydraulic fluid pressure enabling the individual sizing separating and conveying devices in the portable slag beneficiating plant to be operated at different speeds and capacities manually variable continuously to expedite rapid and efficient handling of large quantities of slag by the plant."
            },
            "slug": "Using-the-Relation-Between-a-Plane-Projectivity-and-Sinclair-Christensen",
            "title": {
                "fragments": [],
                "text": "Using the Relation Between a Plane Projectivity and the Fundamental Matrix"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The first and second stage sizing devices in the slag beneficiating plant and the magnetic separating unit which incorporates a feed conveyor belt and the disposal slag conveyor are individually operated by hydraulic motor subject to the control of individual valves and supplied from a common source of hydraulic fluid pressure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143921197"
                        ],
                        "name": "P. Montesinos",
                        "slug": "P.-Montesinos",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Montesinos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Montesinos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398826846"
                        ],
                        "name": "V. Gouet-Brunet",
                        "slug": "V.-Gouet-Brunet",
                        "structuredName": {
                            "firstName": "Val\u00e9rie",
                            "lastName": "Gouet-Brunet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Gouet-Brunet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702017"
                        ],
                        "name": "R. Deriche",
                        "slug": "R.-Deriche",
                        "structuredName": {
                            "firstName": "Rachid",
                            "lastName": "Deriche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Deriche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40220023"
                        ],
                        "name": "D. Pele",
                        "slug": "D.-Pele",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Pele",
                            "middleNames": [
                                "Traian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pele"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 55
                            }
                        ],
                        "text": "Similar results have been reported for color images by Montesinos et al. (2000)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 149
                            }
                        ],
                        "text": "\u20261997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997; Dufournaud et al., 2000) and in that we can deal with general 3D objects without assuming specific\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16924152,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ee6cfe38e3a607f21d9e018465b6868d730efd88",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Matching-color-uncalibrated-images-using-invariants-Montesinos-Gouet-Brunet",
            "title": {
                "fragments": [],
                "text": "Matching color uncalibrated images using differential invariants"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398773259"
                        ],
                        "name": "L. D'haene",
                        "slug": "L.-D'haene",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "D'haene",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D'haene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144839904"
                        ],
                        "name": "R. Koch",
                        "slug": "R.-Koch",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Koch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Initial results for such applications can be found in  Tuytelaars and Van Gool (1999) , Tuytelaars et al. (1999) and Turina et al. (2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 86
                            }
                        ],
                        "text": "Initial results for such applications can be found in Tuytelaars and Van Gool (1999), Tuytelaars et al. (1999) and Turina et al. (2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206541238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12c794d7a7315ab87e5477b2abdaf84a06c86adb",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops new image matching techniques for visual servoing based on affine invariants which allow one to deal with large viewpoint changes and that do not rely on specific markers. The only assumption is that there are some locally planar and unoccluded scene regions that have enough structure to be detected in the image. Those regions are classified by a set of illumination and viewpoint invariant features. The features represent the image in a very compact way and allow fast comparison and feature matching between quite different viewpoints. The matching procedure is embedded in a visual servoing system for a mobile robot. Experiments show its potential for navigation with large camera rotations and view point changes in a cluttered environment without the need for artificial landmarks."
            },
            "slug": "Matching-of-affinely-invariant-regions-for-visual-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Matching of affinely invariant regions for visual servoing"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "New image matching techniques for visual servoing based on affine invariants which allow one to deal with large viewpoint changes and that do not rely on specific markers are developed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 149
                            }
                        ],
                        "text": "\u2026in that we do not apply a search between images but process each image and each local feature individually (Gruen, 1985; Super and Klarquist, 1997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 178
                            }
                        ],
                        "text": "In summary, our system differs from other wide baseline stereo methods in that we do not apply a search between images but process each image and each local feature individually (Gruen, 1985; Super and Klarquist, 1997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999; Montesinos et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 66
                            }
                        ],
                        "text": "Similar ideas have recently been used for wide baseline stereo by Schaffalitzky and Zisserman (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2964260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aac66ac5e90cc4c187a5aa063b522e5193ef8834",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and demonstrate a texture region descriptor which is invariant to affine geometric and photometric transformations, and insensitive to the shape of the texture region. It is applicable to texture patches which are locally planar and have stationary statistics. The novelty of the descriptor is that it is based on statistics aggregated over the region, resulting in richer and more stable descriptors than those computed at a point. Two texture matching applications of this descriptor are demonstrated: (1) it is used to automatically identify, regions of the same type of texture, but with varying surface pose, within a single image; (2) it is used to support wide baseline stereo, i.e. to enable the automatic computation of the epipolar geometry between two images acquired from quite separated viewpoints. Results are presented on several sets of real images."
            },
            "slug": "Viewpoint-invariant-texture-matching-and-wide-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Viewpoint invariant texture matching and wide baseline stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A texture region descriptor is described and demonstrated which is invariant to affine geometric and photometric transformations, and insensitive to the shape of the texture region, resulting in richer and more stable descriptors than those computed at a point."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076817912"
                        ],
                        "name": "P. Pritchett",
                        "slug": "P.-Pritchett",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Pritchett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pritchett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 32
                            }
                        ],
                        "text": "This is akin to the approach of Pritchett and Zisserman (1998) who start their wide baseline stereo algorithm by extracting quadrangles present in the image and match these based on normalized crosscorrelation to find local homographies, which are then exploited in a search for additional\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 234
                            }
                        ],
                        "text": "\u2026caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997; Dufournaud et al., 2000) and in that we can deal with general 3D objects without assuming specific structures to be present in the image (Pritchett and Zisserman, 1998; Tell and Carlsson, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46527015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4da91ba2e80a4d8deb597b1c884cda890f086653",
            "isKey": false,
            "numCitedBy": 351,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically. This facilitates matching between quite disparate views-wide baseline stereo. Two extensions are made to the current small baseline algorithms: first, and most importantly, a viewpoint invariant measure is developed for assessing the affinity of corner neighbourhoods over image pairs; second, algorithms are given for generating putative corner matches between image pairs using local homographies. Two novel infrastructure developments are also described: the automatic generation of local homographies, and the combination of possibly conflicting sets of matches prior to RANSAC estimation. The wide baseline matching algorithm is demonstrated on a number of image pairs with varying relative motion, and for different scene types. All processing is automatic."
            },
            "slug": "Wide-baseline-stereo-matching-Pritchett-Zisserman",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo matching"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically, and to facilitate matching between quite disparate views-wide baseline stereo."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50818863"
                        ],
                        "name": "A. Gruen",
                        "slug": "A.-Gruen",
                        "structuredName": {
                            "firstName": "Armin",
                            "lastName": "Gruen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gruen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 130
                            }
                        ],
                        "text": "One approach is to deform a patch in the first image in an iterative way, until it more or less fits a patch in the\nsecond image (Gruen, 1985; Super and Klarquist, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 178
                            }
                        ],
                        "text": "In summary, our system differs from other wide baseline stereo methods in that we do not apply a search between images but process each image and each local feature individually (Gruen, 1985; Super and Klarquist, 1997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999; Montesinos et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 149
                            }
                        ],
                        "text": "\u2026from other wide baseline stereo methods in that we do not apply a search between images but process each image and each local feature individually (Gruen, 1985; Super and Klarquist, 1997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17649126,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ea8085172671e9870dfdb2b835d42c6f1f6fa5ef",
            "isKey": false,
            "numCitedBy": 779,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The Adaptive Least Squares Correlation is a very potent and flexible technique for all kinds of data matching problems. Here its application to image matching is outlined. It allows for simultaneous radiometric corrections and local geometrical image shaping, whereby the system parameters are automatically assessed, corrected, and thus optimized during the least squares iterations. The various tools of least squares estimation can be favourably utilized for the assessment of the correlation quality. Furthermore, the system allows for stabilization and improvement of the correlation procedure through the simultaneous consideration of geometrical constraints, e.g. the collinearity condition. Some exciting new perspectives are emphasized, as for example multiphoto correlation, multitemporal and multisensor correlation, multipoint correlation, and simultaneous correlation/triangulation."
            },
            "slug": "ADAPTIVE-LEAST-SQUARES-CORRELATION:-A-POWERFUL-Gruen",
            "title": {
                "fragments": [],
                "text": "ADAPTIVE LEAST SQUARES CORRELATION: A POWERFUL IMAGE MATCHING TECHNIQUE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729041"
                        ],
                        "name": "J. Canny",
                        "slug": "J.-Canny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canny",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 219
                            }
                        ],
                        "text": "The first method for affine invariant region extraction starts from Harris corner points (Harris and Stephens, 1983) and the edges that can often be found close to such a point (extracted using the Canny edge detector (Canny, 1986))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13284142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec",
            "isKey": false,
            "numCitedBy": 27659,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge."
            },
            "slug": "A-Computational-Approach-to-Edge-Detection-Canny",
            "title": {
                "fragments": [],
                "text": "A Computational Approach to Edge Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "There is a natural uncertainty principle between detection and localization performance, which are the two main goals, and with this principle a single operator shape is derived which is optimal at any scale."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692283"
                        ],
                        "name": "C. Bauckhage",
                        "slug": "C.-Bauckhage",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bauckhage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bauckhage"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Apart from the necessary properties of good anchor points mentioned above, they typically contain a large amount of information ( Schmid and Mohr, 1998 ), resulting in a high distinctive power, and they are well localized, i.e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32357,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "3a3457d49c92398df2dfe43a4a3bd4bbbabce425",
            "isKey": false,
            "numCitedBy": 353,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Many computer vision tasks rely on feature extraction. Interest points are such features. This paper shows that interest points are geometrically stable under different transformations and have high information content (distinctiveness). These two properties make interest points very successful in the contest of image matching. To measure these two properties quantitatively, we introduce two evaluation criteria: repeatability rate and information content. The quality of the interest points depends on the detector used. In this paper several detectors are compared according to the criteria specified above. We determine which detector gives the best results and show that it satisfies the criteria well."
            },
            "slug": "Comparing-and-evaluating-interest-points-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Comparing and evaluating interest points"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This paper shows that interest points are geometrically stable under different transformations and have high information content (distinctiveness) which make interest points very successful in the contest of image matching."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 87
                            }
                        ],
                        "text": "the position of the corner point is accurately defined (even up to sub-pixel accuracy) (Shi and Tomasi, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 276
                            }
                        ],
                        "text": "\u2026good anchor points mentioned above, they typically contain a large amount of information (Schmid and Mohr, 1998), resulting in a high distinctive power, and they are well localized, i.e. the position of the corner point is accurately defined (even up to sub-pixel accuracy) (Shi and Tomasi, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 778478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ab46391005cea85fa5c204b6e77a9c870fdbaed",
            "isKey": false,
            "numCitedBy": 8402,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. We propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world. These methods are based on a new tracking algorithm that extends previous Newton-Raphson style search methods to work under affine image transformations. We test performance with several simulations and experiments.<<ETX>>"
            },
            "slug": "Good-features-to-track-Shi-Tomasi",
            "title": {
                "fragments": [],
                "text": "Good features to track"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153120475"
                        ],
                        "name": "S. Carlsson",
                        "slug": "S.-Carlsson",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Carlsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carlsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 274
                            }
                        ],
                        "text": "\u2026caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997; Dufournaud et al., 2000) and in that we can deal with general 3D objects without assuming specific structures to be present in the image (Pritchett and Zisserman, 1998; Tell and Carlsson, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 9
                            }
                        ],
                        "text": "Tell and Carlsson (2000) also proposed a wide baseline correspondence method based on affine invariance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 28
                            }
                        ],
                        "text": "This is akin to the work of Carlsson (2000), who has recently proposed a view compatibility constraint for five points in two views based on a scaled orthographic camera model."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 11718504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2438a354b10d8cb78843fde331ba366d384f8d7",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for the recognition of walking people in monocular image sequences based on the extraction of coordinates of specific point locations on the body. The method works by a comparison of sequences of recorded coordinates with a library of sequences from different individuals. The comparison is based on the evaluation of view invariant and calibration independent view consistency constraints. These constraints are functions of corresponding image coordinates in two views and are satisfied whenever the two views are projected from the same three-dimensional (3D) object. By evaluating the view consistency constraints for each pair of frames in a sequence of a walking person and a stored sequence, we obtain a matrix of consistency values that ideally are zero whenever the pair of images depict the same 3D posture. The method is virtually parameter free and computes a consistency residual between a pair of sequences that can be used as a distance for clustering and classification. Using interactively extracted data we present experimental results that are superior to those of previously published algorithms both in terms of performance and generality."
            },
            "slug": "Recognizing-Walking-People-Carlsson",
            "title": {
                "fragments": [],
                "text": "Recognizing Walking People"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The method is virtually parameter free and computes a consistency residual between a pair of sequences that can be used as a distance for clustering and classification and presents experimental results that are superior to those of previously published algorithms both in terms of performance and generality."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 197
                            }
                        ],
                        "text": "\u2026scale-invariance, using circular regions that maximize the output of a difference of gaussian filters in scale space, while Hall et al. (1999) not only applied automatic scale selection (based on Lindeberg (1998)), but also retrieved the orientation of the circular region in an unambiguous way."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 723210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b02f474196fb9bd61fa3d418a7ba8ac500e8d422",
            "isKey": false,
            "numCitedBy": 2940,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of \u03b3-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure.Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation.In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments."
            },
            "slug": "Feature-Detection-with-Automatic-Scale-Selection-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Feature Detection with Automatic Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation and how it can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "\u2026Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997; Dufournaud et al., 2000) and in that we can deal with general 3D objects without assuming specific structures to be present in\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3221174"
                        ],
                        "name": "B. Super",
                        "slug": "B.-Super",
                        "structuredName": {
                            "firstName": "Boaz",
                            "lastName": "Super",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Super"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2402361"
                        ],
                        "name": "W. Klarquist",
                        "slug": "W.-Klarquist",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Klarquist",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Klarquist"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 143
                            }
                        ],
                        "text": "One approach is to deform a patch in the first image in an iterative way, until it more or less fits a patch in the\nsecond image (Gruen, 1985; Super and Klarquist, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 146
                            }
                        ],
                        "text": "\u2026baseline stereo methods in that we do not apply a search between images but process each image and each local feature individually (Gruen, 1985; Super and Klarquist, 1997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3229178,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bb9647a89651ddb1cc0ac5a56f75754bd6d25fd",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a one-stage stereo algorithm that yields 3D planar surface patches directly from matching image patch intensity information. The method allows an arbitrary rotation and translation between the cameras; it is not limited to parallel-axis, narrow-baseline, or vergent geometries. The key to the approach is to match image patches that have positions, shapes, sizes, orientations, and samplings consistent with a hypothesized surface patch and with each other. The match error then reflects only the mismatch of patch contents and not the mismatch of patch geometries or samplings. The algorithm is quantitatively evaluated against ground truth on real images with difficult viewing geometries, and demonstrates an average accuracy of about 1% in estimating surface depths and 10/spl deg/ in estimating surface normals."
            },
            "slug": "Patch-Based-Stereo-in-a-General-Binocular-Viewing-Super-Klarquist",
            "title": {
                "fragments": [],
                "text": "Patch-Based Stereo in a General Binocular Viewing Geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A one-stage stereo algorithm that yields 3D planar surface patches directly from matching image patch intensity information and quantitatively evaluated against ground truth on real images with difficult viewing geometries is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Baumberg (2000) proposed a wide baseline system that is based on a simplified version of the regions of Lindeberg and G\u0227rding (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 0
                            }
                        ],
                        "text": "Baumberg (2000) proposed a wide baseline system that is based on a simplified version of the regions of Lindeberg and G\u0227rding (1997). However, the regions Baumberg uses are only invariant under rotation, stretch and skew, while scale changes are dealt with by applying a scale space approach."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Baumberg (2000) proposed a wide baseline system that is based on a simplified version of the regions of Lindeberg and Ga\u0307rding (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15626261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67f693427d956c0dbc822e7f3452aee8ca36204b",
            "isKey": false,
            "numCitedBy": 767,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints. Unlike conventional stereo matching approaches we assume no prior knowledge about the relative camera positions and orientations. In fact in our application this is the information we wish to determine from the image feature matches. Features are detected in two or more images and characterised using affine texture invariants. The problem of window effects is explicitly addressed by our method-our feature characterisation is invariant to linear transformations of the image data including rotation, stretch and skew. The feature matching process is optimised for a structure-from-motion application where we wish to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "slug": "Reliable-feature-matching-across-widely-separated-Baumberg",
            "title": {
                "fragments": [],
                "text": "Reliable feature matching across widely separated views"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints that is optimised for a structure-from-motion application where it wishes to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3260234"
                        ],
                        "name": "J. G\u00e5rding",
                        "slug": "J.-G\u00e5rding",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "G\u00e5rding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. G\u00e5rding"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 104
                            }
                        ],
                        "text": "Baumberg (2000) proposed a wide baseline system that is based on a simplified version of the regions of Lindeberg and Ga\u0307rding (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 11
                            }
                        ],
                        "text": "From now on, we simply use l when referring to l1 = l2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 0
                            }
                        ],
                        "text": "Lindeberg and Ga\u0307rding (1997) on the other hand have developed a method to find blob-like regions using an iterative scheme, in the context of shape from texture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7210200,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aacb988081214bfd87c9ae06310453d01119e326",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Rotationally symmetric operations in the image domain may give rise to shape distortions. This article describes a way of reducing this effect for a general class of methods for deriving 3-D shape cues from 2-D image data, which are based on the estimation of locally linearized distortion of brightness patterns. By extending the linear scale-space concept into an affine scale-space representation and performing affine shape adaption of the smoothing kernels, the accuracy of surface orientation estimates derived from texture and disparity cues can be improved by typically one order of magnitude. The reason for this is that the image descriptors, on which the methods are based, will be relative invariant under affine transformations, and the error will thus be confined to the higher-order terms in the locally linearized perspective mapping."
            },
            "slug": "Shape-Adapted-Smoothing-in-Estimation-of-3-D-Depth-Lindeberg-G\u00e5rding",
            "title": {
                "fragments": [],
                "text": "Shape-Adapted Smoothing in Estimation of 3-D Depth Cues from Affine Distortions of Local 2-D Brightness Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "By extending the linear scale-space concept into an affine scale- space representation and performing affine shape adaption of the smoothing kernels, the accuracy of surface orientation estimates derived from texture and disparity cues can be improved by typically one order of magnitude."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3304188"
                        ],
                        "name": "B. Funt",
                        "slug": "B.-Funt",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Funt",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Funt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144674766"
                        ],
                        "name": "Lindsay Martin",
                        "slug": "Lindsay-Martin",
                        "structuredName": {
                            "firstName": "Lindsay",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lindsay Martin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "Since changes in the illumination are harder to quantify than changes in scale or viewpoint, we decided to use the images provided by Funt et al. (1998) to test the illumination invariance of our system, as they provide very detailed information on the different illuminants used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8455164,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1917f13246bcc7a2c396150f9de5e6ca5a74aff5",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a negative result: current machine colour constancy algorithms are not good enough for colour-based object recognition. This result has surprised us since we have previously used the better of these algorithms successfully to correct the colour balance of images for display. Colour balancing has been the typical application of colour constancy, rarely has it been actually put to use in a computer vision system, so our goal was to show how well the various methods would do on an obvious machine colour vision task, namely, object recognition. Although all the colour constancy methods we tested proved insufficient for the task, we consider this an important finding in itself. In addition we present results showing the correlation between colour constancy performance and object recognition performance, and as one might expect, the better the colour constancy the better the recognition rate."
            },
            "slug": "Is-Machine-Colour-Constancy-Good-Enough-Funt-Barnard",
            "title": {
                "fragments": [],
                "text": "Is Machine Colour Constancy Good Enough?"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The goal was to show how well the various methods would do on an obvious machine colour vision task, namely, object recognition, and results showed the correlation between colour constancy performance and object recognition performance, and as one might expect, the better the colour constancies the best the recognition rate."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40309692"
                        ],
                        "name": "C. G. Harris",
                        "slug": "C.-G.-Harris",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40365651"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stephens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 22
                            }
                        ],
                        "text": "Harris corner points (Harris and Stephens, 1983) are good candidates."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1684,
                                "start": 22
                            }
                        ],
                        "text": "Harris corner points (Harris and Stephens, 1983) are good candidates. Apart from the necessary properties of good anchor points mentioned above, they typically contain a large amount of information (Schmid and Mohr, 1998), resulting in a high distinctive power, and they are well localized, i.e. the position of the corner point is accurately defined (even up to sub-pixel accuracy) (Shi and Tomasi, 1994). Instead of using corners, local extrema of image intensity can serve as anchor points as well. To this end, we first apply some smoothing to the image to reduce the effect of noise, causing too many unstable local extrema. Then, the local extrema are extracted with a non-maximum suppression algorithm. These points cannot be localized as accurately as corner points, since the local extrema in intensity are often rather smooth. However, they can withstand any monotonic intensity transformation and they are less likely to lie close to the border of an object resulting in a non-planar region. This last property is a major drawback when working with corner points. Of course, which kind of anchor points perform best also depends on the method used for the region extraction, and how good this method deals with the shortcomings of the anchor points. For instance, for the corner points, the high chance of a non-planar region can be alleviated by constructing a region that is not centered around the corner point. Similarly, regions starting from local intensity extrema should not depend too much on the exact position of the extremum, to overcome the inaccurate localization of these points. Other types of anchor points could be used as well. For instance, Lowe (1999) uses extrema of a difference of Gaussians filter."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 90
                            }
                        ],
                        "text": "The first method for affine invariant region extraction starts from Harris corner points (Harris and Stephens, 1983) and the edges that can often be found close to such a point (extracted using the Canny edge detector (Canny, 1986))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1694378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6818668fb895d95861a2eb9673ddc3a41e27b3b3",
            "isKey": false,
            "numCitedBy": 14111,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed."
            },
            "slug": "A-Combined-Corner-and-Edge-Detector-Harris-Stephens",
            "title": {
                "fragments": [],
                "text": "A Combined Corner and Edge Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem the authors are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work."
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 120
                            }
                        ],
                        "text": ", 2000) and in that we can deal with general 3D objects without assuming specific structures to be present in the image (Pritchett and Zisserman, 1998; Tell and Carlsson, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 32
                            }
                        ],
                        "text": "This is akin to the approach of Pritchett and Zisserman (1998) who start their wide baseline stereo algorithm by extracting quadrangles present in the image and match these based on normalized crosscorrelation to find local homographies, which are then exploited in a search for additional\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 234
                            }
                        ],
                        "text": "\u2026caused by the change in viewpoint (Lowe, 1999; Montesinos et al., 2000; Schmid and Mohr, 1997; Dufournaud et al., 2000) and in that we can deal with general 3D objects without assuming specific structures to be present in the image (Pritchett and Zisserman, 1998; Tell and Carlsson, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Conf. on Computer Vision, pp. 754\u2013759."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 143
                            }
                        ],
                        "text": "One approach is to deform a patch in the first image in an iterative way, until it more or less fits a patch in the\nsecond image (Gruen, 1985; Super and Klarquist, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 178
                            }
                        ],
                        "text": "In summary, our system differs from other wide baseline stereo methods in that we do not apply a search between images but process each image and each local feature individually (Gruen, 1985; Super and Klarquist, 1997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in viewpoint (Lowe, 1999; Montesinos et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 146
                            }
                        ],
                        "text": "\u2026baseline stereo methods in that we do not apply a search between images but process each image and each local feature individually (Gruen, 1985; Super and Klarquist, 1997; Schaffalitzky and Zisserman, 2001), in that we fully take into account the affine deformations caused by the change in\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Patch matching and stereopsis in a general stereo viewing geometry"
            },
            "venue": {
                "fragments": [],
                "text": "Int. Journal on Pattern Analysis and Machine Intelligence, 19(3):247\u2013253."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "Since changes in the illumination are harder to quantify than changes in scale or viewpoint, we decided to use the images provided by Funt et al. (1998) to test the illumination invariance of our system, as they provide very detailed information on the different illuminants used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Is colour constancy good enough? In Proc"
            },
            "venue": {
                "fragments": [],
                "text": "European Conference on Computer Vision, pp. 445\u2013459."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "Since changes in the illumination are harder to quantify than changes in scale or viewpoint, we decided to use the images provided by Funt et al. (1998) to test the illumination invariance of our system, as they provide very detailed information on the different illuminants used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Is colour constancy good enough?"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. European Conference on Computer Vision"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 20,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 33,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Matching-Widely-Separated-Views-Based-on-Affine-Tuytelaars-Gool/2893662ec4001949b4afcba124492340216dfd7e?sort=total-citations"
}