{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2706258"
                        ],
                        "name": "Pranav Rajpurkar",
                        "slug": "Pranav-Rajpurkar",
                        "structuredName": {
                            "firstName": "Pranav",
                            "lastName": "Rajpurkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pranav Rajpurkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151810148"
                        ],
                        "name": "Jian Zhang",
                        "slug": "Jian-Zhang",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2787620"
                        ],
                        "name": "Konstantin Lopyrev",
                        "slug": "Konstantin-Lopyrev",
                        "structuredName": {
                            "firstName": "Konstantin",
                            "lastName": "Lopyrev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Konstantin Lopyrev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 267
                            }
                        ],
                        "text": "\u2026(Rajpurkar et al., 2016), we further assume that ai appears as a substring for some document in the set Di.2 However, we differ by setting Di as a set of documents, where previous work assumed a single document (Hermann et al., 2015) or even just a short paragraph (Rajpurkar et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 15
                            }
                        ],
                        "text": ", 2013), SQuAD (Rajpurkar et al., 2016), and NewsQA (Trischler"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 139
                            }
                        ],
                        "text": "\u2026datasets that primarily focus on one of the challenges listed above, for example by crowdsourcing the gathering of question answer pairs (Rajpurkar et al., 2016) or using cloze-style sentences instead of questions (Hermann et al., 2015; Onishi et al., 2016) (see Table 1 for more\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 229
                            }
                        ],
                        "text": "Recently, significant progress has been made by introducing large new reading comprehension datasets that primarily focus on one of the challenges listed above, for example by crowdsourcing the gathering of question answer pairs (Rajpurkar et al., 2016) or using cloze-style sentences instead of questions (Hermann et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 31
                            }
                        ],
                        "text": "Following recent formulations (Rajpurkar et al., 2016), we further assume that ai appears as a substring for some document in the set Di.2 However, we differ by setting Di as a set of documents, where previous work assumed a single document (Hermann et al., 2015) or even just a short paragraph\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 145
                            }
                        ],
                        "text": "For example, our dataset contains three times as many questions that require inference over multiple sentences than the recently released SQuAD (Rajpurkar et al., 2016) dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 6
                            }
                        ],
                        "text": "SQuAD (Rajpurkar et al., 2016) 3 3 3 7 7 MS Marco (Nguyen et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 90
                            }
                        ],
                        "text": "Datasets with natural language questions include MCTest (Richardson et al., 2013), SQuAD (Rajpurkar et al., 2016), and NewsQA (Trischler et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 39
                            }
                        ],
                        "text": ", 2015) or even just a short paragraph (Rajpurkar et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 30
                            }
                        ],
                        "text": "Following recent formulations (Rajpurkar et al., 2016), we further assume that ai appears as a substring for some document in the set Di."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11816014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05dd7254b632376973f3a1b4d39485da17814df5",
            "isKey": true,
            "numCitedBy": 4265,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. \nThe dataset is freely available at this https URL"
            },
            "slug": "SQuAD:-100,000+-Questions-for-Machine-Comprehension-Rajpurkar-Zhang",
            "title": {
                "fragments": [],
                "text": "SQuAD: 100,000+ Questions for Machine Comprehension of Text"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "A strong logistic regression model is built, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%)."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3382568"
                        ],
                        "name": "Adam Trischler",
                        "slug": "Adam-Trischler",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Trischler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Trischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116678322"
                        ],
                        "name": "Tong Wang",
                        "slug": "Tong-Wang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2854297"
                        ],
                        "name": "Xingdi Yuan",
                        "slug": "Xingdi-Yuan",
                        "structuredName": {
                            "firstName": "Xingdi",
                            "lastName": "Yuan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xingdi Yuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116842263"
                        ],
                        "name": "Justin Harris",
                        "slug": "Justin-Harris",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Harris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Justin Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041695"
                        ],
                        "name": "Alessandro Sordoni",
                        "slug": "Alessandro-Sordoni",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sordoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Sordoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143902541"
                        ],
                        "name": "Philip Bachman",
                        "slug": "Philip-Bachman",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Bachman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip Bachman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987426"
                        ],
                        "name": "Kaheer Suleman",
                        "slug": "Kaheer-Suleman",
                        "structuredName": {
                            "firstName": "Kaheer",
                            "lastName": "Suleman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaheer Suleman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 37
                            }
                        ],
                        "text": "The crucial difference between SQuAD/NewsQA and TriviaQA is that TriviaQA questions have not been crowdsourced from preselected passages."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 127
                            }
                        ],
                        "text": "Datasets with natural language questions include MCTest (Richardson et al., 2013), SQuAD (Rajpurkar et al., 2016), and NewsQA (Trischler et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 74
                            }
                        ],
                        "text": "Additionally, our evidence set consists of web documents, while SQuAD and NewsQA are limited to Wikipedia and news articles respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 24
                            }
                        ],
                        "text": ", 2016) 3 3 7 3 3 NewsQA(Trischler et al., 2016) 3 3 3 7* 7 WikiQA (Yang et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "NewsQA uses crowdsourcing to create questions solely from news article summaries in order to control potential bias."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1167588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3eda43078ae1f4741f09be08c4ecab6229046a5c",
            "isKey": true,
            "numCitedBy": 585,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present NewsQA, a challenging machine comprehension dataset of over 100,000 human-generated question-answer pairs. Crowdworkers supply questions and answers based on a set of over 10,000 news articles from CNN, with answers consisting of spans of text in the articles. We collect this dataset through a four-stage process designed to solicit exploratory questions that require reasoning. Analysis confirms that NewsQA demands abilities beyond simple word matching and recognizing textual entailment. We measure human performance on the dataset and compare it to several strong neural models. The performance gap between humans and machines (13.3% F1) indicates that significant progress can be made on NewsQA through future research. The dataset is freely available online."
            },
            "slug": "NewsQA:-A-Machine-Comprehension-Dataset-Trischler-Wang",
            "title": {
                "fragments": [],
                "text": "NewsQA: A Machine Comprehension Dataset"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "NewsQA, a challenging machine comprehension dataset of over 100,000 human-generated question-answer pairs, is presented and analysis confirms that NewsQA demands abilities beyond simple word matching and recognizing textual entailment."
            },
            "venue": {
                "fragments": [],
                "text": "Rep4NLP@ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50536468"
                        ],
                        "name": "Danqi Chen",
                        "slug": "Danqi-Chen",
                        "structuredName": {
                            "firstName": "Danqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40756403"
                        ],
                        "name": "Jason Bolton",
                        "slug": "Jason-Bolton",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Bolton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Bolton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "Finally, we present baseline experiments on the TriviaQA dataset, including a linear classifier inspired by work on CNN Dailymail and MCTest (Chen et al., 2016; Richardson et al., 2013) and a state-of-the-art neural network baseline (Seo et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "MCTest is limited in scale with only 2640 multiple choice questions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 141
                            }
                        ],
                        "text": "Finally, we present baseline experiments on the TriviaQA dataset, including a linear classifier inspired by work on CNN Dailymail and MCTest (Chen et al., 2016; Richardson et al., 2013) and a state-of-the-art neural network baseline (Seo et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 105
                            }
                        ],
                        "text": "We used a random entity baseline and a simple classifier inspired from previous work (Wang et al., 2015; Chen et al., 2016), and compare these to BiDAF (Seo et al., 2017), one of the best performing models for the SQuAD dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "This is similar to previous entity-centric classifiers for QA (Chen et al., 2016; Wang et al., 2015), and uses context and Wikipedia catalog based features."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 85
                            }
                        ],
                        "text": "We used a random entity baseline and a simple classifier inspired from previous work (Wang et al., 2015; Chen et al., 2016), and compare these to BiDAF (Seo et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 49
                            }
                        ],
                        "text": "Datasets with natural language questions include MCTest (Richardson et al., 2013), SQuAD (Rajpurkar et al., 2016), and NewsQA (Trischler et al., 2016)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 62
                            }
                        ],
                        "text": "Recurrent neural network models (RNNs) (Hermann et al., 2015; Chen et al., 2016) have been very effective for reading comprehension."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6360322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b1e20420982a4f923c08652941666b189b11b7fe",
            "isKey": true,
            "numCitedBy": 493,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Enabling a computer to understand a document so that it can answer comprehension questions is a central, yet unsolved goal of NLP. A key factor impeding its solution by machine learned systems is the limited availability of human-annotated data. Hermann et al. (2015) seek to solve this problem by creating over a million training examples by pairing CNN and Daily Mail news articles with their summarized bullet points, and show that a neural network can then be trained to give good performance on this task. In this paper, we conduct a thorough examination of this new reading comprehension task. Our primary aim is to understand what depth of language understanding is required to do well on this task. We approach this from one side by doing a careful hand-analysis of a small subset of the problems and from the other by showing that simple, carefully designed systems can obtain accuracies of 73.6% and 76.6% on these two datasets, exceeding current state-of-the-art results by 7-10% and approaching what we believe is the ceiling for performance on this task."
            },
            "slug": "A-Thorough-Examination-of-the-CNN/Daily-Mail-Task-Chen-Bolton",
            "title": {
                "fragments": [],
                "text": "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A thorough examination of this new reading comprehension task by creating over a million training examples by pairing CNN and Daily Mail news articles with their summarized bullet points, and showing that a neural network can be trained to give good performance on this task."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746841"
                        ],
                        "name": "Nicolas Usunier",
                        "slug": "Nicolas-Usunier",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Usunier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Usunier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3295092"
                        ],
                        "name": "S. Chopra",
                        "slug": "S.-Chopra",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chopra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 18
                            }
                        ],
                        "text": "Proposed datasets (Cai and Yates, 2013; Berant et al., 2013; Bordes et al., 2015) are either limited in scale or in the complexity of questions, and can only retrieve facts covered by the KB."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 168
                            }
                        ],
                        "text": "\u2026answering involves converting natural language questions to logical forms that can be executed over a KB. Proposed datasets (Cai and Yates, 2013; Berant et al., 2013; Bordes et al., 2015) are either limited in scale or in the complexity of questions, and can only retrieve facts covered by the KB."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9605730,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e565308c8081e807709cb4a917443b737e6cdb4",
            "isKey": false,
            "numCitedBy": 546,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Training large-scale question answering systems is complicated because training sources usually cover a small portion of the range of possible questions. This paper studies the impact of multitask and transfer learning for simple question answering; a setting for which the reasoning required to answer is quite easy, as long as one can retrieve the correct evidence given a question, which can be difficult in large-scale conditions. To this end, we introduce a new dataset of 100k questions that we use in conjunction with existing benchmarks. We conduct our study within the framework of Memory Networks (Weston et al., 2015) because this perspective allows us to eventually scale up to more complex reasoning, and show that Memory Networks can be successfully trained to achieve excellent performance."
            },
            "slug": "Large-scale-Simple-Question-Answering-with-Memory-Bordes-Usunier",
            "title": {
                "fragments": [],
                "text": "Large-scale Simple Question Answering with Memory Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper studies the impact of multitask and transfer learning for simple question answering; a setting for which the reasoning required to answer is quite easy, as long as one can retrieve the correct evidence given a question, which can be difficult in large-scale conditions."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144326610"
                        ],
                        "name": "Peng Li",
                        "slug": "Peng-Li",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157335836"
                        ],
                        "name": "Wei Li",
                        "slug": "Wei-Li",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116776905"
                        ],
                        "name": "Zhen He",
                        "slug": "Zhen-He",
                        "structuredName": {
                            "firstName": "Zhen",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhen He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108084524"
                        ],
                        "name": "Xuguang Wang",
                        "slug": "Xuguang-Wang",
                        "structuredName": {
                            "firstName": "Xuguang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuguang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112866139"
                        ],
                        "name": "Ying Cao",
                        "slug": "Ying-Cao",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118730271"
                        ],
                        "name": "Jie Zhou",
                        "slug": "Jie-Zhou",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47210460"
                        ],
                        "name": "W. Xu",
                        "slug": "W.-Xu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 70
                            }
                        ],
                        "text": ", 2015) for answer sentence selection, and the Chinese language WebQA (Li et al., 2016) dataset, which focuses on the task of answer phrase extraction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 214
                            }
                        ],
                        "text": "Other datasets includes SearchQA\n(Dunn et al., 2017) where Jeopardy! questions are paired with search engine snippets, the WikiQA dataset (Yang et al., 2015) for answer sentence selection, and the Chinese language WebQA (Li et al., 2016) dataset, which focuses on the task of answer phrase extraction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 216
                            }
                        ],
                        "text": "\u2026datasets includes SearchQA\n(Dunn et al., 2017) where Jeopardy! questions are paired with search engine snippets, the WikiQA dataset (Yang et al., 2015) for answer sentence selection, and the Chinese language WebQA (Li et al., 2016) dataset, which focuses on the task of answer phrase extraction."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6901603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdf28e3cadbabda3261bd904c37edea66ab84766",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "While question answering (QA) with neural network, i.e. neural QA, has achieved promising results in recent years, lacking of large scale real-word QA dataset is still a challenge for developing and evaluating neural QA system. To alleviate this problem, we propose a large scale human annotated real-world QA dataset WebQA with more than 42k questions and 556k evidences. As existing neural QA methods resolve QA either as sequence generation or classification/ranking problem, they face challenges of expensive softmax computation, unseen answers handling or separate candidate answer generation component. In this work, we cast neural QA as a sequence labeling problem and propose an end-to-end sequence labeling model, which overcomes all the above challenges. Experimental results on WebQA show that our model outperforms the baselines significantly with an F1 score of 74.69% with word-based input, and the performance drops only 3.72 F1 points with more challenging character-based input."
            },
            "slug": "Dataset-and-Neural-Recurrent-Sequence-Labeling-for-Li-Li",
            "title": {
                "fragments": [],
                "text": "Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work casts neural QA as a sequence labeling problem and proposes an end-to-end sequence labeling model, which overcomes all the above challenges and outperforms the baselines significantly on WebQA."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144422314"
                        ],
                        "name": "Matthew Richardson",
                        "slug": "Matthew-Richardson",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Richardson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859813"
                        ],
                        "name": "Erin Renshaw",
                        "slug": "Erin-Renshaw",
                        "structuredName": {
                            "firstName": "Erin",
                            "lastName": "Renshaw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erin Renshaw"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 161
                            }
                        ],
                        "text": "Finally, we present baseline experiments on the TriviaQA dataset, including a linear classifier inspired by work on CNN Dailymail and MCTest (Chen et al., 2016; Richardson et al., 2013) and a state-of-the-art neural network baseline (Seo et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "MCTest is limited in scale with only 2640 multiple choice questions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 56
                            }
                        ],
                        "text": "Datasets with natural language questions include MCTest (Richardson et al., 2013), SQuAD (Rajpurkar et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 141
                            }
                        ],
                        "text": "Finally, we present baseline experiments on the TriviaQA dataset, including a linear classifier inspired by work on CNN Dailymail and MCTest (Chen et al., 2016; Richardson et al., 2013) and a state-of-the-art neural network baseline (Seo et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 57
                            }
                        ],
                        "text": "Datasets with natural language questions include MCTest (Richardson et al., 2013), SQuAD (Rajpurkar et al., 2016), and NewsQA (Trischler et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2100831,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "564257469fa44cdb57e4272f85253efb9acfd69d",
            "isKey": true,
            "numCitedBy": 594,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present MCTest, a freely available set of stories and associated questions intended for research on the machine comprehension of text. Previous work on machine comprehension (e.g., semantic modeling) has made great strides, but primarily focuses either on limited-domain datasets, or on solving a more restricted goal (e.g., open-domain relation extraction). In contrast, MCTest requires machines to answer multiple-choice reading comprehension questions about fictional stories, directly tackling the high-level goal of open-domain machine comprehension. Reading comprehension can test advanced abilities such as causal reasoning and understanding the world, yet, by being multiple-choice, still provide a clear metric. By being fictional, the answer typically can be found only in the story itself. The stories and questions are also carefully limited to those a young child would understand, reducing the world knowledge that is required for the task. We present the scalable crowd-sourcing methods that allow us to cheaply construct a dataset of 500 stories and 2000 questions. By screening workers (with grammar tests) and stories (with grading), we have ensured that the data is the same quality as another set that we manually edited, but at one tenth the editing cost. By being open-domain, yet carefully restricted, we hope MCTest will serve to encourage research and provide a clear metric for advancement on the machine comprehension of text. 1 Reading Comprehension A major goal for NLP is for machines to be able to understand text as well as people. Several research disciplines are focused on this problem: for example, information extraction, relation extraction, semantic role labeling, and recognizing textual entailment. Yet these techniques are necessarily evaluated individually, rather than by how much they advance us towards the end goal. On the other hand, the goal of semantic parsing is the machine comprehension of text (MCT), yet its evaluation requires adherence to a specific knowledge representation, and it is currently unclear what the best representation is, for open-domain text. We believe that it is useful to directly tackle the top-level task of MCT. For this, we need a way to measure progress. One common method for evaluating someone\u2019s understanding of text is by giving them a multiple-choice reading comprehension test. This has the advantage that it is objectively gradable (vs. essays) yet may test a range of abilities such as causal or counterfactual reasoning, inference among relations, or just basic understanding of the world in which the passage is set. Therefore, we propose a multiple-choice reading comprehension task as a way to evaluate progress on MCT. We have built a reading comprehension dataset containing 500 fictional stories, with 4 multiple choice questions per story. It was built using methods which can easily scale to at least 5000 stories, since the stories were created, and the curation was done, using crowd sourcing almost entirely, at a total of $4.00 per story. We plan to periodically update the dataset to ensure that methods are not overfitting to the existing data. The dataset is open-domain, yet restricted to concepts and words that a 7 year old is expected to understand. This task is still beyond the capability of today\u2019s computers and algorithms."
            },
            "slug": "MCTest:-A-Challenge-Dataset-for-the-Open-Domain-of-Richardson-Burges",
            "title": {
                "fragments": [],
                "text": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "MCTest is presented, a freely available set of stories and associated questions intended for research on the machine comprehension of text that requires machines to answer multiple-choice reading comprehension questions about fictional stories, directly tackling the high-level goal of open-domain machine comprehension."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111841367"
                        ],
                        "name": "Matthew Dunn",
                        "slug": "Matthew-Dunn",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Dunn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Dunn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2246570"
                        ],
                        "name": "Levent Sagun",
                        "slug": "Levent-Sagun",
                        "structuredName": {
                            "firstName": "Levent",
                            "lastName": "Sagun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Levent Sagun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055681746"
                        ],
                        "name": "Mike Higgins",
                        "slug": "Mike-Higgins",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Higgins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Higgins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3243915"
                        ],
                        "name": "V. U. G\u00fcney",
                        "slug": "V.-U.-G\u00fcney",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "G\u00fcney",
                            "middleNames": [
                                "Ugur"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. U. G\u00fcney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3149518"
                        ],
                        "name": "Volkan Cirik",
                        "slug": "Volkan-Cirik",
                        "structuredName": {
                            "firstName": "Volkan",
                            "lastName": "Cirik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volkan Cirik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 24
                            }
                        ],
                        "text": "Other datasets includes SearchQA\n(Dunn et al., 2017) where Jeopardy! questions are paired with search engine snippets, the WikiQA dataset (Yang et al., 2015) for answer sentence selection, and the Chinese language WebQA (Li et al., 2016) dataset, which focuses on the task of answer phrase extraction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "(Dunn et al., 2017) where Jeopardy! questions are paired with search engine snippets, the WikiQA dataset (Yang et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 34
                            }
                        ],
                        "text": "Other datasets includes SearchQA\n(Dunn et al., 2017) where Jeopardy! questions are paired with search engine snippets, the WikiQA dataset (Yang et al., 2015) for answer sentence selection, and the Chinese language WebQA (Li et al., 2016) dataset, which focuses on the task of answer phrase\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 11606382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3adff57fd09965224506a1bacc0579d9d3c8c11e",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We publicly release a new large-scale dataset, called SearchQA, for machine comprehension, or question-answering. Unlike recently released datasets, such as DeepMind CNN/DailyMail and SQuAD, the proposed SearchQA was constructed to reflect a full pipeline of general question-answering. That is, we start not from an existing article and generate a question-answer pair, but start from an existing question-answer pair, crawled from J! Archive, and augment it with text snippets retrieved by Google. Following this approach, we built SearchQA, which consists of more than 140k question-answer pairs with each pair having 49.6 snippets on average. Each question-answer-context tuple of the SearchQA comes with additional meta-data such as the snippet's URL, which we believe will be valuable resources for future research. We conduct human evaluation as well as test two baseline methods, one simple word selection and the other deep learning based, on the SearchQA. We show that there is a meaningful gap between the human and machine performances. This suggests that the proposed dataset could well serve as a benchmark for question-answering."
            },
            "slug": "SearchQA:-A-New-Q&A-Dataset-Augmented-with-Context-Dunn-Sagun",
            "title": {
                "fragments": [],
                "text": "SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that there is a meaningful gap between the human and machine performances, which suggests that the proposed dataset could well serve as a benchmark for question-answering."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144081089"
                        ],
                        "name": "Daniel Fernando Campos",
                        "slug": "Daniel-Fernando-Campos",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Campos",
                            "middleNames": [
                                "Fernando"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Fernando Campos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116109215"
                        ],
                        "name": "Tri Nguyen",
                        "slug": "Tri-Nguyen",
                        "structuredName": {
                            "firstName": "Tri",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tri Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40319105"
                        ],
                        "name": "M. Rosenberg",
                        "slug": "M.-Rosenberg",
                        "structuredName": {
                            "firstName": "Mir",
                            "lastName": "Rosenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50706785"
                        ],
                        "name": "Xia Song",
                        "slug": "Xia-Song",
                        "structuredName": {
                            "firstName": "Xia",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xia Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800422"
                        ],
                        "name": "Jianfeng Gao",
                        "slug": "Jianfeng-Gao",
                        "structuredName": {
                            "firstName": "Jianfeng",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianfeng Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40070335"
                        ],
                        "name": "Saurabh Tiwary",
                        "slug": "Saurabh-Tiwary",
                        "structuredName": {
                            "firstName": "Saurabh",
                            "lastName": "Tiwary",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saurabh Tiwary"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32431940"
                        ],
                        "name": "Rangan Majumder",
                        "slug": "Rangan-Majumder",
                        "structuredName": {
                            "firstName": "Rangan",
                            "lastName": "Majumder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rangan Majumder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116506812"
                        ],
                        "name": "Bhaskar Mitra",
                        "slug": "Bhaskar-Mitra",
                        "structuredName": {
                            "firstName": "Bhaskar",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bhaskar Mitra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 40
                            }
                        ],
                        "text": "The recently released MS Marco dataset (Nguyen et al., 2016) also contains independently authored questions and documents drawn from the search results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 27
                            }
                        ],
                        "text": ", 2016) 3 3 3 7 7 MS Marco (Nguyen et al., 2016) 3 3 7 3 3 NewsQA(Trischler et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1289517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a69cf45d44a9d806d2487a1ffb9eca71ee73c2ee",
            "isKey": false,
            "numCitedBy": 1055,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents our recent work on the design and development of a new, large scale dataset, which we name MS MARCO, for MAchine Reading COmprehension. This new dataset is aimed to overcome a number of well-known weaknesses of previous publicly available datasets for the same task of reading comprehension and question answering. In MS MARCO, all questions are sampled from real anonymized user queries. The context passages, from which answers in the dataset are derived, are extracted from real web documents using the most advanced version of the Bing search engine. The answers to the queries are human generated. Finally, a subset of these queries has multiple answers. We aim to release one million queries and the corresponding answers in the dataset, which, to the best of our knowledge, is the most comprehensive real-world dataset of its kind in both quantity and quality. We are currently releasing 100,000 queries with their corresponding answers to inspire work in reading comprehension and question answering along with gathering feedback from the research community."
            },
            "slug": "MS-MARCO:-A-Human-Generated-MAchine-Reading-Dataset-Campos-Nguyen",
            "title": {
                "fragments": [],
                "text": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This new dataset is aimed to overcome a number of well-known weaknesses of previous publicly available datasets for the same task of reading comprehension and question answering, and is the most comprehensive real-world dataset of its kind in both quantity and quality."
            },
            "venue": {
                "fragments": [],
                "text": "CoCo@NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143684464"
                        ],
                        "name": "Yi Yang",
                        "slug": "Yi-Yang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144105277"
                        ],
                        "name": "Wen-tau Yih",
                        "slug": "Wen-tau-Yih",
                        "structuredName": {
                            "firstName": "Wen-tau",
                            "lastName": "Yih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-tau Yih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50004012"
                        ],
                        "name": "Christopher Meek",
                        "slug": "Christopher-Meek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Meek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Meek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": ", 2017) where Jeopardy! questions are paired with search engine snippets, the WikiQA dataset (Yang et al., 2015) for answer sentence selection, and the Chinese language WebQA (Li et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 139
                            }
                        ],
                        "text": "Other datasets includes SearchQA\n(Dunn et al., 2017) where Jeopardy! questions are paired with search engine snippets, the WikiQA dataset (Yang et al., 2015) for answer sentence selection, and the Chinese language WebQA (Li et al., 2016) dataset, which focuses on the task of answer phrase\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 1373518,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f53e2ae46470b89cd1ce6e3bf1d60d9c59722ce1",
            "isKey": false,
            "numCitedBy": 622,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the WIKIQA dataset, a new publicly available set of question and sentence pairs, collected and annotated for research on open-domain question answering. Most previous work on answer sentence selection focuses on a dataset created using the TREC-QA data, which includes editor-generated questions and candidate answer sentences selected by matching content words in the question. WIKIQA is constructed using a more natural process and is more than an order of magnitude larger than the previous dataset. In addition, the WIKIQA dataset also includes questions for which there are no correct sentences, enabling researchers to work on answer triggering, a critical component in any QA system. We compare several systems on the task of answer sentence selection on both datasets and also describe the performance of a system on the problem of answer triggering using the WIKIQA dataset."
            },
            "slug": "WikiQA:-A-Challenge-Dataset-for-Open-Domain-Yang-Yih",
            "title": {
                "fragments": [],
                "text": "WikiQA: A Challenge Dataset for Open-Domain Question Answering"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "The WIKIQA dataset is described, a new publicly available set of question and sentence pairs, collected and annotated for research on open-domain question answering, which is more than an order of magnitude larger than the previous dataset."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136562"
                        ],
                        "name": "Mohit Iyyer",
                        "slug": "Mohit-Iyyer",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Iyyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Iyyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389036863"
                        ],
                        "name": "Jordan L. Boyd-Graber",
                        "slug": "Jordan-L.-Boyd-Graber",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Boyd-Graber",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jordan L. Boyd-Graber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32355580"
                        ],
                        "name": "L. Claudino",
                        "slug": "L.-Claudino",
                        "structuredName": {
                            "firstName": "Leonardo",
                            "lastName": "Claudino",
                            "middleNames": [
                                "Max",
                                "Batista"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Claudino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 140
                            }
                        ],
                        "text": "10 A number of different aspects of this problem have been carefully studied, typically using classifiers over a pre-defined set of answers (Iyyer et al., 2014) and studying incremental answering to answer as"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 139
                            }
                        ],
                        "text": "\u2026A number of different aspects of this problem have been carefully studied, typically using classifiers over a pre-defined set of answers (Iyyer et al., 2014) and studying incremental answering to answer as quickly as possible (Boyd-Graber et al., 2012) or using reinforcement learning to\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 216034672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af44f5db5b4396e1670cda07eff5ad84145ba843",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Text classification methods for tasks like factoid question answering typically use manually defined string matching rules or bag of words representations. These methods are ineective when question text contains very few individual words (e.g., named entities) that are indicative of the answer. We introduce a recursive neural network (rnn) model that can reason over such input by modeling textual compositionality. We apply our model, qanta, to a dataset of questions from a trivia competition called quiz bowl. Unlike previous rnn models, qanta learns word and phrase-level representations that combine across sentences to reason about entities. The model outperforms multiple baselines and, when combined with information retrieval methods, rivals the best human players."
            },
            "slug": "A-Neural-Network-for-Factoid-Question-Answering-Iyyer-Boyd-Graber",
            "title": {
                "fragments": [],
                "text": "A Neural Network for Factoid Question Answering over Paragraphs"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces a recursive neural network model, qanta, that can reason over question text input by modeling textual compositionality and applies it to a dataset of questions from a trivia competition called quiz bowl."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4418074"
                        ],
                        "name": "Minjoon Seo",
                        "slug": "Minjoon-Seo",
                        "structuredName": {
                            "firstName": "Minjoon",
                            "lastName": "Seo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minjoon Seo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2684226"
                        ],
                        "name": "Aniruddha Kembhavi",
                        "slug": "Aniruddha-Kembhavi",
                        "structuredName": {
                            "firstName": "Aniruddha",
                            "lastName": "Kembhavi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aniruddha Kembhavi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2548384"
                        ],
                        "name": "Hannaneh Hajishirzi",
                        "slug": "Hannaneh-Hajishirzi",
                        "structuredName": {
                            "firstName": "Hannaneh",
                            "lastName": "Hajishirzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hannaneh Hajishirzi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 55
                            }
                        ],
                        "text": ", 2013) and a state-of-the-art neural network baseline (Seo et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 234
                            }
                        ],
                        "text": "Finally, we present baseline experiments on the TriviaQA dataset, including a linear classifier inspired by work on CNN Dailymail and MCTest (Chen et al., 2016; Richardson et al., 2013) and a state-of-the-art neural network baseline (Seo et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 36
                            }
                        ],
                        "text": ", 2016), and compare these to BiDAF (Seo et al., 2017), one of the best performing models for the SQuAD dataset."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 153
                            }
                        ],
                        "text": "We used a random entity baseline and a simple classifier inspired from previous work (Wang et al., 2015; Chen et al., 2016), and compare these to BiDAF (Seo et al., 2017), one of the best performing models for the SQuAD dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 43
                            }
                        ],
                        "text": "For our task, we modified the BiDAF model (Seo et al., 2017), which takes a sequence of context words as input and outputs the start and end positions of the predicted answer in the context."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8535316,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a7b63b50c64f4ec3358477790e84cbd6be2a0b4",
            "isKey": true,
            "numCitedBy": 1722,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test."
            },
            "slug": "Bidirectional-Attention-Flow-for-Machine-Seo-Kembhavi",
            "title": {
                "fragments": [],
                "text": "Bidirectional Attention Flow for Machine Comprehension"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The BIDAF network is introduced, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750652"
                        ],
                        "name": "Jonathan Berant",
                        "slug": "Jonathan-Berant",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Berant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Berant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059149862"
                        ],
                        "name": "A. Chou",
                        "slug": "A.-Chou",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Chou",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34765463"
                        ],
                        "name": "Roy Frostig",
                        "slug": "Roy-Frostig",
                        "structuredName": {
                            "firstName": "Roy",
                            "lastName": "Frostig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roy Frostig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 18
                            }
                        ],
                        "text": "Proposed datasets (Cai and Yates, 2013; Berant et al., 2013; Bordes et al., 2015) are either limited in scale or in the complexity of questions, and can only retrieve facts covered by the KB."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 147
                            }
                        ],
                        "text": "\u2026answering involves converting natural language questions to logical forms that can be executed over a KB. Proposed datasets (Cai and Yates, 2013; Berant et al., 2013; Bordes et al., 2015) are either limited in scale or in the complexity of questions, and can only retrieve facts covered by the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6401679,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b29447ba499507a259ae9d8f685d60cc1597d7d3",
            "isKey": false,
            "numCitedBy": 1337,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we train a semantic parser that scales up to Freebase. Instead of relying on annotated logical forms, which is especially expensive to obtain at large scale, we learn from question-answer pairs. The main challenge in this setting is narrowing down the huge number of possible logical predicates for a given question. We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus. Second, we use a bridging operation to generate additional predicates based on neighboring predicates. On the dataset of Cai and Yates (2013), despite not having annotated logical forms, our system outperforms their state-of-the-art parser. Additionally, we collected a more realistic and challenging dataset of question-answer pairs and improves over a natural baseline."
            },
            "slug": "Semantic-Parsing-on-Freebase-from-Question-Answer-Berant-Chou",
            "title": {
                "fragments": [],
                "text": "Semantic Parsing on Freebase from Question-Answer Pairs"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This paper trains a semantic parser that scales up to Freebase and outperforms their state-of-the-art parser on the dataset of Cai and Yates (2013), despite not having annotated logical forms."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2301874"
                        ],
                        "name": "Takeshi Onishi",
                        "slug": "Takeshi-Onishi",
                        "structuredName": {
                            "firstName": "Takeshi",
                            "lastName": "Onishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takeshi Onishi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113221447"
                        ],
                        "name": "Hai Wang",
                        "slug": "Hai-Wang",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977268"
                        ],
                        "name": "Mohit Bansal",
                        "slug": "Mohit-Bansal",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Bansal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700980"
                        ],
                        "name": "Kevin Gimpel",
                        "slug": "Kevin-Gimpel",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Gimpel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Gimpel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 60
                            }
                        ],
                        "text": ", 2016) or using cloze-style sentences instead of questions (Hermann et al., 2015; Onishi et al., 2016) (see Table 1 for more examples)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 114
                            }
                        ],
                        "text": "Researchers have constructed cloze-style datasets (Hill et al., 2015; Hermann et al., 2015; Paperno et al., 2016; Onishi et al., 2016), where the task is to predict missing words, often entities, in a document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 238
                            }
                        ],
                        "text": "\u2026datasets that primarily focus on one of the challenges listed above, for example by crowdsourcing the gathering of question answer pairs (Rajpurkar et al., 2016) or using cloze-style sentences instead of questions (Hermann et al., 2015; Onishi et al., 2016) (see Table 1 for more examples)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5761781,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a39ffa57ef8e538b3c6a6c2bbc0b641f7cdc60dc",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We have constructed a new \"Who-did-What\" dataset of over 200,000 fill-in-the-gap (cloze) multiple choice reading comprehension problems constructed from the LDC English Gigaword newswire corpus. The WDW dataset has a variety of novel features. First, in contrast with the CNN and Daily Mail datasets (Hermann et al., 2015) we avoid using article summaries for question formation. Instead, each problem is formed from two independent articles --- an article given as the passage to be read and a separate article on the same events used to form the question. Second, we avoid anonymization --- each choice is a person named entity. Third, the problems have been filtered to remove a fraction that are easily solved by simple baselines, while remaining 84% solvable by humans. We report performance benchmarks of standard systems and propose the WDW dataset as a challenge task for the community."
            },
            "slug": "Who-did-What:-A-Large-Scale-Person-Centered-Cloze-Onishi-Wang",
            "title": {
                "fragments": [],
                "text": "Who did What: A Large-Scale Person-Centered Cloze Dataset"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A new \"Who-did-What\" dataset of over 200,000 fill-in-the-gap (cloze) multiple choice reading comprehension problems constructed from the LDC English Gigaword newswire corpus is constructed and proposed as a challenge task for the community."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1857734"
                        ],
                        "name": "Guokun Lai",
                        "slug": "Guokun-Lai",
                        "structuredName": {
                            "firstName": "Guokun",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guokun Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1912046"
                        ],
                        "name": "Qizhe Xie",
                        "slug": "Qizhe-Xie",
                        "structuredName": {
                            "firstName": "Qizhe",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qizhe Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2391802"
                        ],
                        "name": "Hanxiao Liu",
                        "slug": "Hanxiao-Liu",
                        "structuredName": {
                            "firstName": "Hanxiao",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanxiao Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 42
                            }
                        ],
                        "text": "Other recently released datasets include (Lai et al., 2017)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6826032,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "636a79420d838eabe4af7fb25d6437de45ab64e8",
            "isKey": false,
            "numCitedBy": 698,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present RACE, a new dataset for benchmark evaluation of methods in the reading comprehension task. Collected from the English exams for middle and high school Chinese students in the age range between 12 to 18, RACE consists of near 28,000 passages and near 100,000 questions generated by human experts (English instructors), and covers a variety of topics which are carefully designed for evaluating the students\u2019 ability in understanding and reasoning. In particular, the proportion of questions that requires reasoning is much larger in RACE than that in other benchmark datasets for reading comprehension, and there is a significant gap between the performance of the state-of-the-art models (43%) and the ceiling human performance (95%). We hope this new dataset can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at http://www.cs.cmu.edu/~glai1/data/race/ and the code is available at https://github.com/qizhex/RACE_AR_baselines."
            },
            "slug": "RACE:-Large-scale-ReAding-Comprehension-Dataset-Lai-Xie",
            "title": {
                "fragments": [],
                "text": "RACE: Large-scale ReAding Comprehension Dataset From Examinations"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The proportion of questions that requires reasoning is much larger in RACE than that in other benchmark datasets for reading comprehension, and there is a significant gap between the performance of the state-of-the-art models and the ceiling human performance."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38087946"
                        ],
                        "name": "Anthony Fader",
                        "slug": "Anthony-Fader",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Fader",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Fader"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "Other recent approaches attempt to combine structured high precision KBs with semistructured information sources like OpenIE triples (Fader et al., 2014), HTML tables (Pasupat and Liang, 2015), and large (and noisy) corpora (Sawant and Chakrabarti, 2013; Joshi et al., 2014; Xu et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 133
                            }
                        ],
                        "text": "Other recent approaches attempt to combine structured high precision KBs with semistructured information sources like OpenIE triples (Fader et al., 2014), HTML tables (Pasupat and Liang, 2015), and large (and noisy) corpora (Sawant and Chakrabarti, 2013; Joshi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207214527,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f86ec155cce6259e5230aaad3b762343757feb1d",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of open-domain question answering (Open QA) over massive knowledge bases (KBs). Existing approaches use either manually curated KBs like Freebase or KBs automatically extracted from unstructured text. In this paper, we present OQA, the first approach to leverage both curated and extracted KBs. A key technical challenge is designing systems that are robust to the high variability in both natural language questions and massive KBs. OQA achieves robustness by decomposing the full Open QA problem into smaller sub-problems including question paraphrasing and query reformulation. OQA solves these sub-problems by mining millions of rules from an unlabeled question corpus and across multiple KBs. OQA then learns to integrate these rules by performing discriminative training on question-answer pairs using a latent-variable structured perceptron algorithm. We evaluate OQA on three benchmark question sets and demonstrate that it achieves up to twice the precision and recall of a state-of-the-art Open QA system."
            },
            "slug": "Open-question-answering-over-curated-and-extracted-Fader-Zettlemoyer",
            "title": {
                "fragments": [],
                "text": "Open question answering over curated and extracted knowledge bases"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents OQA, the first approach to leverage both curated and extracted KBs, and demonstrates that it achieves up to twice the precision and recall of a state-of-the-art Open QA system."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2129425"
                        ],
                        "name": "Denis Paperno",
                        "slug": "Denis-Paperno",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Paperno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denis Paperno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067996"
                        ],
                        "name": "Germ\u00e1n Kruszewski",
                        "slug": "Germ\u00e1n-Kruszewski",
                        "structuredName": {
                            "firstName": "Germ\u00e1n",
                            "lastName": "Kruszewski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Germ\u00e1n Kruszewski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2672644"
                        ],
                        "name": "Angeliki Lazaridou",
                        "slug": "Angeliki-Lazaridou",
                        "structuredName": {
                            "firstName": "Angeliki",
                            "lastName": "Lazaridou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Angeliki Lazaridou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422089"
                        ],
                        "name": "Q. N. Pham",
                        "slug": "Q.-N.-Pham",
                        "structuredName": {
                            "firstName": "Quan",
                            "lastName": "Pham",
                            "middleNames": [
                                "Ngoc"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. N. Pham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040726"
                        ],
                        "name": "R. Bernardi",
                        "slug": "R.-Bernardi",
                        "structuredName": {
                            "firstName": "Raffaella",
                            "lastName": "Bernardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bernardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422247"
                        ],
                        "name": "Sandro Pezzelle",
                        "slug": "Sandro-Pezzelle",
                        "structuredName": {
                            "firstName": "Sandro",
                            "lastName": "Pezzelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sandro Pezzelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145283199"
                        ],
                        "name": "Marco Baroni",
                        "slug": "Marco-Baroni",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Baroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Baroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807810"
                        ],
                        "name": "Gemma Boleda",
                        "slug": "Gemma-Boleda",
                        "structuredName": {
                            "firstName": "Gemma",
                            "lastName": "Boleda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gemma Boleda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144151273"
                        ],
                        "name": "R. Fern\u00e1ndez",
                        "slug": "R.-Fern\u00e1ndez",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Fern\u00e1ndez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fern\u00e1ndez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2381275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77fb0b7aef619dfac650423d4677170df2158e0d",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce LAMBADA, a dataset to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word. To succeed on LAMBADA, computational models cannot simply rely on local context, but must be able to keep track of information in the broader discourse. We show that LAMBADA exemplifies a wide range of linguistic phenomena, and that none of several state-of-the-art language models reaches accuracy above 1% on this novel benchmark. We thus propose LAMBADA as a challenging test set, meant to encourage the development of new models capable of genuine understanding of broad context in natural language text."
            },
            "slug": "The-LAMBADA-dataset:-Word-prediction-requiring-a-Paperno-Kruszewski",
            "title": {
                "fragments": [],
                "text": "The LAMBADA dataset: Word prediction requiring a broad discourse context"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that LAMBADA exemplifies a wide range of linguistic phenomena, and that none of several state-of-the-art language models reaches accuracy above 1% on this novel benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2910877"
                        ],
                        "name": "K. Hermann",
                        "slug": "K.-Hermann",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Hermann",
                            "middleNames": [
                                "Moritz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2367821"
                        ],
                        "name": "Tom\u00e1s Kocisk\u00fd",
                        "slug": "Tom\u00e1s-Kocisk\u00fd",
                        "structuredName": {
                            "firstName": "Tom\u00e1s",
                            "lastName": "Kocisk\u00fd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom\u00e1s Kocisk\u00fd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1864353"
                        ],
                        "name": "Edward Grefenstette",
                        "slug": "Edward-Grefenstette",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Grefenstette"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2311318"
                        ],
                        "name": "Lasse Espeholt",
                        "slug": "Lasse-Espeholt",
                        "structuredName": {
                            "firstName": "Lasse",
                            "lastName": "Espeholt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lasse Espeholt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062879616"
                        ],
                        "name": "Will Kay",
                        "slug": "Will-Kay",
                        "structuredName": {
                            "firstName": "Will",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Will Kay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2573615"
                        ],
                        "name": "Mustafa Suleyman",
                        "slug": "Mustafa-Suleyman",
                        "structuredName": {
                            "firstName": "Mustafa",
                            "lastName": "Suleyman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mustafa Suleyman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685771"
                        ],
                        "name": "P. Blunsom",
                        "slug": "P.-Blunsom",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Blunsom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Blunsom"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 70
                            }
                        ],
                        "text": "Researchers have constructed cloze-style datasets (Hill et al., 2015; Hermann et al., 2015; Paperno et al., 2016; Onishi et al., 2016), where the task is to predict missing words, often entities, in a document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 102
                            }
                        ],
                        "text": "However, we differ by setting Di as a set of documents, where previous work assumed a single document (Hermann et al., 2015) or even just a short paragraph (Rajpurkar et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 213
                            }
                        ],
                        "text": "\u2026(Rajpurkar et al., 2016), we further assume that ai appears as a substring for some document in the set Di.2 However, we differ by setting Di as a set of documents, where previous work assumed a single document (Hermann et al., 2015) or even just a short paragraph (Rajpurkar et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 40
                            }
                        ],
                        "text": "Recurrent neural network models (RNNs) (Hermann et al., 2015; Chen et al., 2016) have been very effective for reading comprehension."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 60
                            }
                        ],
                        "text": ", 2016) or using cloze-style sentences instead of questions (Hermann et al., 2015; Onishi et al., 2016) (see Table 1 for more examples)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 216
                            }
                        ],
                        "text": "\u2026datasets that primarily focus on one of the challenges listed above, for example by crowdsourcing the gathering of question answer pairs (Rajpurkar et al., 2016) or using cloze-style sentences instead of questions (Hermann et al., 2015; Onishi et al., 2016) (see Table 1 for more examples)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6203757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1505c6123c102e53eb19dff312cb25cea840b72",
            "isKey": true,
            "numCitedBy": 2432,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Teaching machines to read natural language documents remains an elusive challenge. Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. In this work we define a new methodology that resolves this bottleneck and provides large scale supervised reading comprehension data. This allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure."
            },
            "slug": "Teaching-Machines-to-Read-and-Comprehend-Hermann-Kocisk\u00fd",
            "title": {
                "fragments": [],
                "text": "Teaching Machines to Read and Comprehend"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new methodology is defined that resolves this bottleneck and provides large scale supervised reading comprehension data that allows a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure to be developed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2616463"
                        ],
                        "name": "Panupong Pasupat",
                        "slug": "Panupong-Pasupat",
                        "structuredName": {
                            "firstName": "Panupong",
                            "lastName": "Pasupat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Panupong Pasupat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145419642"
                        ],
                        "name": "Percy Liang",
                        "slug": "Percy-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Percy Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 21
                            }
                        ],
                        "text": ", 2014), HTML tables (Pasupat and Liang, 2015), and large (and noisy) corpora (Sawant and Chakrabarti, 2013; Joshi et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9027681,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b41e95c8c97846d5ca4c11ef79d7814499cc9663",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Two important aspects of semantic parsing for question answering are the breadth of the knowledge source and the depth of logical compositionality. While existing work trades off one aspect for another, this paper simultaneously makes progress on both fronts through a new task: answering complex questions on semi-structured tables using question-answer pairs as supervision. The central challenge arises from two compounding factors: the broader domain results in an open-ended set of relations, and the deeper compositionality results in a combinatorial explosion in the space of logical forms. We propose a logical-form driven parsing algorithm guided by strong typing constraints and show that it obtains significant improvements over natural baselines. For evaluation, we created a new dataset of 22,033 complex questions on Wikipedia tables, which is made publicly available."
            },
            "slug": "Compositional-Semantic-Parsing-on-Semi-Structured-Pasupat-Liang",
            "title": {
                "fragments": [],
                "text": "Compositional Semantic Parsing on Semi-Structured Tables"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes a logical-form driven parsing algorithm guided by strong typing constraints and shows that it obtains significant improvements over natural baselines and is made publicly available."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145941665"
                        ],
                        "name": "S. Riedel",
                        "slug": "S.-Riedel",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Riedel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786422"
                        ],
                        "name": "Limin Yao",
                        "slug": "Limin-Yao",
                        "structuredName": {
                            "firstName": "Limin",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Limin Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 133
                            }
                        ],
                        "text": "For example, our data would also support multiinstance learning, which makes the at least once assumption, from relation extraction (Riedel et al., 2010; Hoffmann et al., 2011) or many other possibilities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2386383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7e7b9a731678bf0494fe29cbebb42a822224cc6",
            "isKey": false,
            "numCitedBy": 1034,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Several recent works on relation extraction have been applying the distant supervision paradigm: instead of relying on annotated text to learn how to predict relations, they employ existing knowledge bases (KBs) as source of supervision. Crucially, these approaches are trained based on the assumption that each sentence which mentions the two related entities is an expression of the given relation. Here we argue that this leads to noisy patterns that hurt precision, in particular if the knowledge base is not directly related to the text we are working with. We present a novel approach to distant supervision that can alleviate this problem based on the following two ideas: First, we use a factor graph to explicitly model the decision whether two entities are related, and the decision whether this relation is mentioned in a given sentence; second, we apply constraint-driven semi-supervision to train this model without any knowledge about which sentences express the relations in our training KB. We apply our approach to extract relations from the New York Times corpus and use Freebase as knowledge base. When compared to a state-of-the-art approach for relation extraction under distant supervision, we achieve 31% error reduction."
            },
            "slug": "Modeling-Relations-and-Their-Mentions-without-Text-Riedel-Yao",
            "title": {
                "fragments": [],
                "text": "Modeling Relations and Their Mentions without Labeled Text"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel approach to distant supervision that can alleviate the problem of noisy patterns that hurt precision by using a factor graph and applying constraint-driven semi-supervision to train this model without any knowledge about which sentences express the relations in the authors' training KB."
            },
            "venue": {
                "fragments": [],
                "text": "ECML/PKDD"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145783676"
                        ],
                        "name": "Felix Hill",
                        "slug": "Felix-Hill",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Felix Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3295092"
                        ],
                        "name": "S. Chopra",
                        "slug": "S.-Chopra",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chopra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 51
                            }
                        ],
                        "text": "Researchers have constructed cloze-style datasets (Hill et al., 2015; Hermann et al., 2015; Paperno et al., 2016; Onishi et al., 2016), where the task is to predict missing words, often entities, in a document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14915449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35b91b365ceb016fb3e022577cec96fb9b445dc5",
            "isKey": false,
            "numCitedBy": 530,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new test of how well language models capture meaning in children's books. Unlike standard language modelling benchmarks, it distinguishes the task of predicting syntactic function words from that of predicting lower-frequency words, which carry greater semantic content. We compare a range of state-of-the-art models, each with a different way of encoding what has been previously read. We show that models which store explicit representations of long-term contexts outperform state-of-the-art neural language models at predicting semantic content words, although this advantage is not observed for syntactic function words. Interestingly, we find that the amount of text encoded in a single memory representation is highly influential to the performance: there is a sweet-spot, not too big and not too small, between single words and full sentences that allows the most meaningful information in a text to be effectively retained and recalled. Further, the attention over such window-based memories can be trained effectively through self-supervision. We then assess the generality of this principle by applying it to the CNN QA benchmark, which involves identifying named entities in paraphrased summaries of news articles, and achieve state-of-the-art performance."
            },
            "slug": "The-Goldilocks-Principle:-Reading-Children's-Books-Hill-Bordes",
            "title": {
                "fragments": [],
                "text": "The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "There is a sweet-spot, not too big and not too small, between single words and full sentences that allows the most meaningful information in a text to be effectively retained and recalled, and models which store explicit representations of long-term contexts outperform state-of-the-art neural language models at predicting semantic content words."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113221447"
                        ],
                        "name": "Hai Wang",
                        "slug": "Hai-Wang",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977268"
                        ],
                        "name": "Mohit Bansal",
                        "slug": "Mohit-Bansal",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Bansal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700980"
                        ],
                        "name": "Kevin Gimpel",
                        "slug": "Kevin-Gimpel",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Gimpel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Gimpel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 9
                            }
                        ],
                        "text": "ous work (Wang et al., 2015; Chen et al., 2016), and compare these to BiDAF (Seo et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "This is similar to previous entity-centric classifiers for QA (Chen et al., 2016; Wang et al., 2015), and uses context and Wikipedia catalog based features."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 86
                            }
                        ],
                        "text": "We used a random entity baseline and a simple classifier inspired from previous work (Wang et al., 2015; Chen et al., 2016), and compare these to BiDAF (Seo et al., 2017), one of the best performing models for the SQuAD dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8764466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "999f0acfac28215db2e4c69ff42711fd4f56511d",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate significant improvement on the MCTest question answering task (Richardson et al., 2013) by augmenting baseline features with features based on syntax, frame semantics, coreference, and word embeddings, and combining them in a max-margin learning framework. We achieve the best results we are aware of on this dataset, outperforming concurrentlypublished results. These results demonstrate a significant performance gradient for the use of linguistic structure in machine comprehension."
            },
            "slug": "Machine-Comprehension-with-Syntax,-Frames,-and-Wang-Bansal",
            "title": {
                "fragments": [],
                "text": "Machine Comprehension with Syntax, Frames, and Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This work demonstrates significant improvement on the MCTest question answering task (Richardson et al., 2013) by augmenting baseline features with features based on syntax, frame semantics, coreference, and word embeddings, and combining them in a max-margin learning framework."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746656"
                        ],
                        "name": "E. Voorhees",
                        "slug": "E.-Voorhees",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Voorhees",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Voorhees"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2575691"
                        ],
                        "name": "Dawn M. Tice",
                        "slug": "Dawn-M.-Tice",
                        "structuredName": {
                            "firstName": "Dawn",
                            "lastName": "Tice",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dawn M. Tice"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 76
                            }
                        ],
                        "text": "A standard task for open domain IR-style QA is the annual TREC competitions (Voorhees and Tice, 2000), which contains questions from various domains but is limited in size."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11465263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2161251488dbba08616a9cdd4223a0ac1190cef",
            "isKey": false,
            "numCitedBy": 377,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The TREC-8 Question Answering (QA) Track was the first large-scale evaluation of domain-independent question answering systems. In addition to fostering research on the QA task, the track was used to investigate whether the evaluation methodology used for document retrieval is appropriate for a different natural language processing task. As with document relevance judging, assessors had legitimate differences of opinions as to whether a response actually answers a question, but comparative evaluation of QA systems was stable despite these differences. Creating a reusable QA test collection is fundamentally more difficult than creating a document retrieval test collection since the QA task has no equivalent to document identifiers."
            },
            "slug": "Building-a-question-answering-test-collection-Voorhees-Tice",
            "title": {
                "fragments": [],
                "text": "Building a question answering test collection"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The TREC-8 Question Answering (QA) Track was the first large-scale evaluation of domain-independent question answering systems and was used to investigate whether the evaluation methodology used for document retrieval is appropriate for a different natural language processing task."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2566295"
                        ],
                        "name": "Raphael Hoffmann",
                        "slug": "Raphael-Hoffmann",
                        "structuredName": {
                            "firstName": "Raphael",
                            "lastName": "Hoffmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raphael Hoffmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799338"
                        ],
                        "name": "Congle Zhang",
                        "slug": "Congle-Zhang",
                        "structuredName": {
                            "firstName": "Congle",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Congle Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145787377"
                        ],
                        "name": "Xiao Ling",
                        "slug": "Xiao-Ling",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 154
                            }
                        ],
                        "text": "For example, our data would also support multiinstance learning, which makes the at least once assumption, from relation extraction (Riedel et al., 2010; Hoffmann et al., 2011) or many other possibilities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16483125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d48edf9e81653f4c3da716b037b0b50d54c5b034",
            "isKey": false,
            "numCitedBy": 870,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction (IE) holds the promise of generating a large-scale knowledge base from the Web's natural language text. Knowledge-based weak supervision, using structured data to heuristically label a training corpus, works towards this goal by enabling the automated learning of a potentially unbounded number of relation extractors. Recently, researchers have developed multi-instance learning algorithms to combat the noisy training data that can come from heuristic labeling, but their models assume relations are disjoint --- for example they cannot extract the pair Founded(Jobs, Apple) and CEO-of(Jobs, Apple). \n \nThis paper presents a novel approach for multi-instance learning with overlapping relations that combines a sentence-level extraction model with a simple, corpus-level component for aggregating the individual facts. We apply our model to learn extractors for NY Times text using weak supervision from Free-base. Experiments show that the approach runs quickly and yields surprising gains in accuracy, at both the aggregate and sentence level."
            },
            "slug": "Knowledge-Based-Weak-Supervision-for-Information-of-Hoffmann-Zhang",
            "title": {
                "fragments": [],
                "text": "Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel approach for multi-instance learning with overlapping relations that combines a sentence-level extraction model with a simple, corpus-level component for aggregating the individual facts is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389036863"
                        ],
                        "name": "Jordan L. Boyd-Graber",
                        "slug": "Jordan-L.-Boyd-Graber",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Boyd-Graber",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jordan L. Boyd-Graber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780572"
                        ],
                        "name": "Brianna Satinoff",
                        "slug": "Brianna-Satinoff",
                        "structuredName": {
                            "firstName": "Brianna",
                            "lastName": "Satinoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brianna Satinoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144533687"
                        ],
                        "name": "He He",
                        "slug": "He-He",
                        "structuredName": {
                            "firstName": "He",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "He He"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 93
                            }
                        ],
                        "text": "Trivia questions from quiz bowl have been previously used in other question answering tasks (Boyd-Graber et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 195
                            }
                        ],
                        "text": "\u2026this problem have been carefully studied, typically using classifiers over a pre-defined set of answers (Iyyer et al., 2014) and studying incremental answering to answer as quickly as possible (Boyd-Graber et al., 2012) or using reinforcement learning to model opponent behavior (He et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 20
                            }
                        ],
                        "text": "quickly as possible (Boyd-Graber et al., 2012) or using reinforcement learning to model opponent behavior (He et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215514151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eeeca31116b2e17cbbc08584a3fe77c1e8b16504",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Cost-sensitive classification, where the features used in machine learning tasks have a cost, has been explored as a means of balancing knowledge against the expense of incrementally obtaining new features. We introduce a setting where humans engage in classification with incrementally revealed features: the collegiate trivia circuit. By providing the community with a web-based system to practice, we collected tens of thousands of implicit word-by-word ratings of how useful features are for eliciting correct answers. Observing humans' classification process, we improve the performance of a state-of-the art classifier. We also use the dataset to evaluate a system to compete in the incremental classification task through a reduction of reinforcement learning to classification. Our system learns when to answer a question, performing better than baselines and most human players."
            },
            "slug": "Besting-the-Quiz-Master:-Crowdsourcing-Incremental-Boyd-Graber-Satinoff",
            "title": {
                "fragments": [],
                "text": "Besting the Quiz Master: Crowdsourcing Incremental Classification Games"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work introduces a setting where humans engage in classification with incrementally revealed features: the collegiate trivia circuit and improves the performance of a state-of-the art classifier by observing humans' classification process."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144863691"
                        ],
                        "name": "Mandar Joshi",
                        "slug": "Mandar-Joshi",
                        "structuredName": {
                            "firstName": "Mandar",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mandar Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3214158"
                        ],
                        "name": "Uma Sawant",
                        "slug": "Uma-Sawant",
                        "structuredName": {
                            "firstName": "Uma",
                            "lastName": "Sawant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uma Sawant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40941894"
                        ],
                        "name": "Soumen Chakrabarti",
                        "slug": "Soumen-Chakrabarti",
                        "structuredName": {
                            "firstName": "Soumen",
                            "lastName": "Chakrabarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumen Chakrabarti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 255
                            }
                        ],
                        "text": "Other recent approaches attempt to combine structured high precision KBs with semistructured information sources like OpenIE triples (Fader et al., 2014), HTML tables (Pasupat and Liang, 2015), and large (and noisy) corpora (Sawant and Chakrabarti, 2013; Joshi et al., 2014; Xu et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 78
                            }
                        ],
                        "text": ", 2014), HTML tables (Pasupat and Liang, 2015), and large (and noisy) corpora (Sawant and Chakrabarti, 2013; Joshi et al., 2014; Xu et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9526475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0e471f63193dd58e80081c03ec712d12d3d1254",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Much recent work focuses on formal interpretation of natural question utterances, with the goal of executing the resulting structured queries on knowledge graphs (KGs) such as Freebase. Here we address two limitations of this approach when applied to open-domain, entity-oriented Web queries. First, Web queries are rarely wellformed questions. They are \u201ctelegraphic\u201d, with missing verbs, prepositions, clauses, case and phrase clues. Second, the KG is always incomplete, unable to directly answer many queries. We propose a novel technique to segment a telegraphic query and assign a coarse-grained purpose to each segment: a base entity e1, a relation type r, a target entity type t2, and contextual words s. The query seeks entity e2 2 t2 where r(e1,e2) holds, further evidenced by schema-agnostic words s. Query segmentation is integrated with the KG and an unstructured corpus where mentions of entities have been linked to the KG. We do not trust the best or any specific query segmentation. Instead, evidence in favor of candidate e2s are aggregated across several segmentations. Extensive experiments on the ClueWeb corpus and parts of Freebase as our KG, using over a thousand telegraphic queries adapted from TREC, INEX, and WebQuestions, show the efficacy of our approach. For one benchmark, MAP improves from 0.2\u20100.29 (competitive baselines) to 0.42 (our system). NDCG@10 improves from 0.29\u20100.36 to 0.54."
            },
            "slug": "Knowledge-Graph-and-Corpus-Driven-Segmentation-and-Joshi-Sawant",
            "title": {
                "fragments": [],
                "text": "Knowledge Graph and Corpus Driven Segmentation and Answer Inference for Telegraphic Entity-seeking Queries"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel technique to segment a telegraphic query and assign a coarse-grained purpose to each segment: a base entity e1, a relation type r, a target entity type t2, and contextual words s is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3214158"
                        ],
                        "name": "Uma Sawant",
                        "slug": "Uma-Sawant",
                        "structuredName": {
                            "firstName": "Uma",
                            "lastName": "Sawant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uma Sawant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40941894"
                        ],
                        "name": "Soumen Chakrabarti",
                        "slug": "Soumen-Chakrabarti",
                        "structuredName": {
                            "firstName": "Soumen",
                            "lastName": "Chakrabarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumen Chakrabarti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 78
                            }
                        ],
                        "text": ", 2014), HTML tables (Pasupat and Liang, 2015), and large (and noisy) corpora (Sawant and Chakrabarti, 2013; Joshi et al., 2014; Xu et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6858396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce8e1cc5f6ece52594bb33f1620a0255d8f396bf",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Thanks to information extraction and semantic Web efforts, search on unstructured text is increasingly refined using semantic annotations and structured knowledge bases. However, most users cannot become familiar with the schema of knowledge bases and ask structured queries. Interpreting free-format queries into a more structured representation is of much current interest. The dominant paradigm is to segment or partition query tokens by purpose (references to types, entities, attribute names, attribute values, relations) and then launch the interpreted query on structured knowledge bases. Given that structured knowledge extraction is never complete, here we choose a less trodden path: a data representation that retains the unstructured text corpus, along with structured annotations (mentions of entities and relationships) on it. We propose two new, natural formulations for joint query interpretation and response ranking that exploit bidirectional flow of information between the knowledge base and the corpus. One, inspired by probabilistic language models, computes expected response scores over the uncertainties of query interpretation. The other is based on max-margin discriminative learning, with latent variables representing those uncertainties. In the context of typed entity search, both formulations bridge a considerable part of the accuracy gap between a generic query that does not constrain the type at all, and the upper bound where the \"perfect\" target entity type of each query is provided by humans. Our formulations are also superior to a two-stage approach of first choosing a target type using recent query type prediction techniques, and then launching a type-restricted entity search query."
            },
            "slug": "Learning-joint-query-interpretation-and-response-Sawant-Chakrabarti",
            "title": {
                "fragments": [],
                "text": "Learning joint query interpretation and response ranking"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes two new, natural formulations for joint query interpretation and response ranking that exploit bidirectional flow of information between the knowledge base and the corpus, inspired by probabilistic language models and max-margin discriminative learning."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295799"
                        ],
                        "name": "D. Ferrucci",
                        "slug": "D.-Ferrucci",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ferrucci",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ferrucci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793454"
                        ],
                        "name": "E. Brown",
                        "slug": "E.-Brown",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brown",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684353"
                        ],
                        "name": "Jennifer Chu-Carroll",
                        "slug": "Jennifer-Chu-Carroll",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Chu-Carroll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jennifer Chu-Carroll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48203512"
                        ],
                        "name": "James Fan",
                        "slug": "James-Fan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2771137"
                        ],
                        "name": "David Gondek",
                        "slug": "David-Gondek",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Gondek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Gondek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1973186"
                        ],
                        "name": "Aditya Kalyanpur",
                        "slug": "Aditya-Kalyanpur",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Kalyanpur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aditya Kalyanpur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144071952"
                        ],
                        "name": "Adam Lally",
                        "slug": "Adam-Lally",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Lally",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Lally"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145412011"
                        ],
                        "name": "J. William Murdock",
                        "slug": "J.-William-Murdock",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Murdock",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. William Murdock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144287919"
                        ],
                        "name": "Eric Nyberg",
                        "slug": "Eric-Nyberg",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Nyberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Nyberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30210546"
                        ],
                        "name": "J. Prager",
                        "slug": "J.-Prager",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Prager",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Prager"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807334"
                        ],
                        "name": "Nico Schlaefer",
                        "slug": "Nico-Schlaefer",
                        "structuredName": {
                            "firstName": "Nico",
                            "lastName": "Schlaefer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nico Schlaefer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143778120"
                        ],
                        "name": "Chris Welty",
                        "slug": "Chris-Welty",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Welty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Welty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 1
                            }
                        ],
                        "text": "(Ferrucci et al., 2010)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1831060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ff2862a8121cc823a8eb72f3e0a97bbf25c82ec",
            "isKey": false,
            "numCitedBy": 1400,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "IBM Research undertook a challenge to build a computer system that could compete at the human champion level in real time on the American TV Quiz show, Jeopardy! The extent of the challenge includes fielding a real-time automatic contestant on the show, not merely a laboratory exercise. The Jeopardy! Challenge helped us address requirements that led to the design of the DeepQA architecture and the implementation of Watson. After 3 years of intense research and development by a core team of about 20 researches, Watson is performing at human expert-levels in terms of precision, confidence and speed at the Jeopardy! Quiz show. Our results strongly suggest that DeepQA is an effective and extensible architecture that may be used as a foundation for combining, deploying, evaluating and advancing a wide range of algorithmic techniques to rapidly advance the field of QA."
            },
            "slug": "Building-Watson:-An-Overview-of-the-DeepQA-Project-Ferrucci-Brown",
            "title": {
                "fragments": [],
                "text": "Building Watson: An Overview of the DeepQA Project"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results strongly suggest that DeepQA is an effective and extensible architecture that may be used as a foundation for combining, deploying, evaluating and advancing a wide range of algorithmic techniques to rapidly advance the field of QA."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117101253"
                        ],
                        "name": "Ke Xu",
                        "slug": "Ke-Xu",
                        "structuredName": {
                            "firstName": "Ke",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ke Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3450996"
                        ],
                        "name": "Ryan Kiros",
                        "slug": "Ryan-Kiros",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Kiros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan Kiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 275
                            }
                        ],
                        "text": "Other recent approaches attempt to combine structured high precision KBs with semistructured information sources like OpenIE triples (Fader et al., 2014), HTML tables (Pasupat and Liang, 2015), and large (and noisy) corpora (Sawant and Chakrabarti, 2013; Joshi et al., 2014; Xu et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 78
                            }
                        ],
                        "text": ", 2014), HTML tables (Pasupat and Liang, 2015), and large (and noisy) corpora (Sawant and Chakrabarti, 2013; Joshi et al., 2014; Xu et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1055111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d8f2d14af5991d4f0d050d22216825cac3157bd",
            "isKey": false,
            "numCitedBy": 7252,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr9k, Flickr30k and MS COCO."
            },
            "slug": "Show,-Attend-and-Tell:-Neural-Image-Caption-with-Xu-Ba",
            "title": {
                "fragments": [],
                "text": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "An attention based model that automatically learns to describe the content of images is introduced that can be trained in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681278"
                        ],
                        "name": "P. Ferragina",
                        "slug": "P.-Ferragina",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Ferragina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ferragina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2104451"
                        ],
                        "name": "Ugo Scaiella",
                        "slug": "Ugo-Scaiella",
                        "structuredName": {
                            "firstName": "Ugo",
                            "lastName": "Scaiella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ugo Scaiella"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 113
                            }
                        ],
                        "text": "We therefore collected an additional set of evidence documents by applying TAGME, an off-the-shelf entity linker (Ferragina and Scaiella, 2010), to find Wikipedia entities mentioned in the question, and added the corresponding pages as evidence documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16178102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b18fbdff9b5feac766bd9cde9b266de274d8c4b2",
            "isKey": false,
            "numCitedBy": 717,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We designed and implemented TAGME, a system that is able to efficiently and judiciously augment a plain-text with pertinent hyperlinks to Wikipedia pages. The specialty of TAGME with respect to known systems [5,8] is that it may annotate texts which are short and poorly composed, such as snippets of search-engine results, tweets, news, etc.. This annotation is extremely informative, so any task that is currently addressed using the bag-of-words paradigm could benefit from using this annotation to draw upon (the millions of) Wikipedia pages and their inter-relations."
            },
            "slug": "TAGME:-on-the-fly-annotation-of-short-text-(by-Ferragina-Scaiella",
            "title": {
                "fragments": [],
                "text": "TAGME: on-the-fly annotation of short text fragments (by wikipedia entities)"
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8387085"
                        ],
                        "name": "Zichao Yang",
                        "slug": "Zichao-Yang",
                        "structuredName": {
                            "firstName": "Zichao",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zichao Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022168"
                        ],
                        "name": "Diyi Yang",
                        "slug": "Diyi-Yang",
                        "structuredName": {
                            "firstName": "Diyi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diyi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 26
                            }
                        ],
                        "text": ", 2016) 3 3 3 7* 7 WikiQA (Yang et al., 2016) 7 7 7 3 7 TREC (Voorhees and Tice, 2000) 7 3 3 3 3"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 123
                            }
                        ],
                        "text": "Other datasets includes SearchQA\n(Dunn et al., 2017) where Jeopardy! questions are paired with search engine snippets, the WikiQA dataset (Yang et al., 2015) for answer sentence selection, and the Chinese language WebQA (Li et al., 2016) dataset, which focuses on the task of answer phrase extraction."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6857205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "455afd748e8834ef521e4b67c7c056d3c33429e2",
            "isKey": false,
            "numCitedBy": 3226,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a hierarchical attention network for document classification. Our model has two distinctive characteristics: (i) it has a hierarchical structure that mirrors the hierarchical structure of documents; (ii) it has two levels of attention mechanisms applied at the wordand sentence-level, enabling it to attend differentially to more and less important content when constructing the document representation. Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin. Visualization of the attention layers illustrates that the model selects qualitatively informative words and sentences."
            },
            "slug": "Hierarchical-Attention-Networks-for-Document-Yang-Yang",
            "title": {
                "fragments": [],
                "text": "Hierarchical Attention Networks for Document Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108728368"
                        ],
                        "name": "Qiang Wu",
                        "slug": "Qiang-Wu",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742466"
                        ],
                        "name": "K. Svore",
                        "slug": "K.-Svore",
                        "structuredName": {
                            "firstName": "Krysta",
                            "lastName": "Svore",
                            "middleNames": [
                                "Marie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Svore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800422"
                        ],
                        "name": "Jianfeng Gao",
                        "slug": "Jianfeng-Gao",
                        "structuredName": {
                            "firstName": "Jianfeng",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianfeng Gao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 47
                            }
                        ],
                        "text": "The function score is learnt using LambdaMART (Wu et al., 2010),6 a boosted tree based ranking algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5552139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18e93fa7d408e9596992f3d63155cb92827839a4",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new ranking algorithm that combines the strengths of two previous methods: boosted tree classification, and LambdaRank, which has been shown to be empirically optimal for a widely used information retrieval measure. Our algorithm is based on boosted regression trees, although the ideas apply to any weak learners, and it is significantly faster in both train and test phases than the state of the art, for comparable accuracy. We also show how to find the optimal linear combination for any two rankers, and we use this method to solve the line search problem exactly during boosting. In addition, we show that starting with a previously trained model, and boosting using its residuals, furnishes an effective technique for model adaptation, and we give significantly improved results for a particularly pressing problem in web search\u2014training rankers for markets for which only small amounts of labeled data are available, given a ranker trained on much more data from a larger market."
            },
            "slug": "Adapting-boosting-for-information-retrieval-Wu-Burges",
            "title": {
                "fragments": [],
                "text": "Adapting boosting for information retrieval measures"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This work presents a new ranking algorithm that combines the strengths of two previous methods: boosted tree classification, and LambdaRank, and shows how to find the optimal linear combination for any two rankers, and uses this method to solve the line search problem exactly during boosting."
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054915766"
                        ],
                        "name": "Qingqing Cai",
                        "slug": "Qingqing-Cai",
                        "structuredName": {
                            "firstName": "Qingqing",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qingqing Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3321874"
                        ],
                        "name": "A. Yates",
                        "slug": "A.-Yates",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Yates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yates"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 18
                            }
                        ],
                        "text": "Proposed datasets (Cai and Yates, 2013; Berant et al., 2013; Bordes et al., 2015) are either limited in scale or in the complexity of questions, and can only retrieve facts covered by the KB."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2265838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80c2d8c691b09f8b4e53f512b9d2641b49fda935",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Supervised training procedures for semantic parsers produce high-quality semantic parsers, but they have difficulty scaling to large databases because of the sheer number of logical constants for which they must see labeled training data. We present a technique for developing semantic parsers for large databases based on a reduction to standard supervised training algorithms, schema matching, and pattern learning. Leveraging techniques from each of these areas, we develop a semantic parser for Freebase that is capable of parsing questions with an F1 that improves by 0.42 over a purely-supervised learning algorithm."
            },
            "slug": "Large-scale-Semantic-Parsing-via-Schema-Matching-Cai-Yates",
            "title": {
                "fragments": [],
                "text": "Large-scale Semantic Parsing via Schema Matching and Lexicon Extension"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A semantic parser for Freebase is developed based on a reduction to standard supervised training algorithms, schema matching, and pattern learning that is capable of parsing questions with an F1 that improves by 0.42 over a purely-supervised learning algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2140062900"
                        ],
                        "name": "He He",
                        "slug": "He-He",
                        "structuredName": {
                            "firstName": "He",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "He He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389036863"
                        ],
                        "name": "Jordan L. Boyd-Graber",
                        "slug": "Jordan-L.-Boyd-Graber",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Boyd-Graber",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jordan L. Boyd-Graber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 67
                            }
                        ],
                        "text": ", 2012) or using reinforcement learning to model opponent behavior (He et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 281
                            }
                        ],
                        "text": "\u2026this problem have been carefully studied, typically using classifiers over a pre-defined set of answers (Iyyer et al., 2014) and studying incremental answering to answer as quickly as possible (Boyd-Graber et al., 2012) or using reinforcement learning to model opponent behavior (He et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3393747,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa8e4263ef59d095dc0f87fb0dae19b441bfa6c5",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Opponent modeling is necessary in multi-agent settings where secondary agents with competing goals also adapt their strategies, yet it remains challenging because strategies interact with each other and change. Most previous work focuses on developing probabilistic models or parameterized strategies for specific applications. Inspired by the recent success of deep reinforcement learning, we present neural-based models that jointly learn a policy and the behavior of opponents. Instead of explicitly predicting the opponent's action, we encode observation of the opponents into a deep Q-Network (DQN); however, we retain explicit modeling (if desired) using multitasking. By using a Mixture-of-Experts architecture, our model automatically discovers different strategy patterns of opponents without extra supervision. We evaluate our models on a simulated soccer game and a popular trivia game, showing superior performance over DQN and its variants."
            },
            "slug": "Opponent-Modeling-in-Deep-Reinforcement-Learning-He-Boyd-Graber",
            "title": {
                "fragments": [],
                "text": "Opponent Modeling in Deep Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Inspired by the recent success of deep reinforcement learning, this work presents neural-based models that jointly learn a policy and the behavior of opponents, and uses a Mixture-of-Experts architecture to encode observation of the opponents into a deep Q-Network."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 99
                            }
                        ],
                        "text": "Developed for a dataset where the evidence document is a single paragraph (average 122 words), the BiDAF model does not scale to long documents."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 234
                            }
                        ],
                        "text": "Finally, we present baseline experiments on the TriviaQA dataset, including a linear classifier inspired by work on CNN Dailymail and MCTest (Chen et al., 2016; Richardson et al., 2013) and a state-of-the-art neural network baseline (Seo et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 38
                            }
                        ],
                        "text": "For both Wikipedia and web documents, BiDAF (40"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 153
                            }
                        ],
                        "text": "We used a random entity baseline and a simple classifier inspired from previous work (Wang et al., 2015; Chen et al., 2016), and compare these to BiDAF (Seo et al., 2017), one of the best performing models for the SQuAD dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 13
                            }
                        ],
                        "text": "For training BiDAF on the web domain, we first randomly sampled 80,000 documents."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 52
                            }
                        ],
                        "text": "The authors would like to thank Minjoon Seo for the BiDAF code, and Noah Smith, Srinivasan Iyer, Mark Yatskar, Nicholas FitzGerald, Antoine Bosselut, Dallas Card, and anonymous reviewers for helpful comments."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 43
                            }
                        ],
                        "text": "For our task, we modified the BiDAF model (Seo et al., 2017), which takes a sequence of context words as input and outputs the start and end positions of the predicted answer in the context."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 30
                            }
                        ],
                        "text": "We analyse the performance of BiDAF on the development set using Wikipedia as the evidence source by question length and answer type."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 34
                            }
                        ],
                        "text": "We randomly sampled 100 incorrect BiDAF predictions from the development set and used Wikipedia evidence documents for manual analysis."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learn - ing joint query interpretation and response rank"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 22 Nd International Conference on World Wide Web"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 9
                            }
                        ],
                        "text": "ous work (Wang et al., 2015; Chen et al., 2016), and compare these to BiDAF (Seo et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "Finally, we present baseline experiments on the TriviaQA dataset, including a linear classifier inspired by work on CNN Dailymail and MCTest (Chen et al., 2016; Richardson et al., 2013) and a state-of-the-art neural network baseline (Seo et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "MCTest is limited in scale with only 2640 multiple choice questions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 141
                            }
                        ],
                        "text": "Finally, we present baseline experiments on the TriviaQA dataset, including a linear classifier inspired by work on CNN Dailymail and MCTest (Chen et al., 2016; Richardson et al., 2013) and a state-of-the-art neural network baseline (Seo et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 105
                            }
                        ],
                        "text": "We used a random entity baseline and a simple classifier inspired from previous work (Wang et al., 2015; Chen et al., 2016), and compare these to BiDAF (Seo et al., 2017), one of the best performing models for the SQuAD dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "This is similar to previous entity-centric classifiers for QA (Chen et al., 2016; Wang et al., 2015), and uses context and Wikipedia catalog based features."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 49
                            }
                        ],
                        "text": "Datasets with natural language questions include MCTest (Richardson et al., 2013), SQuAD (Rajpurkar et al., 2016), and NewsQA (Trischler et al., 2016)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 62
                            }
                        ],
                        "text": "Recurrent neural network models (RNNs) (Hermann et al., 2015; Chen et al., 2016) have been very effective for reading comprehension."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A thorough examination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041701"
                        ],
                        "name": "Aciel Eshky",
                        "slug": "Aciel-Eshky",
                        "structuredName": {
                            "firstName": "Aciel",
                            "lastName": "Eshky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aciel Eshky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2100733"
                        ],
                        "name": "B. Allison",
                        "slug": "B.-Allison",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Allison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Allison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145332820"
                        ],
                        "name": "M. Steedman",
                        "slug": "M.-Steedman",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Steedman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Steedman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64512972,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8bcc314b6f53db304565cd39598e368015b9654e",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-2012-Joint-Conference-on-Methods-Eshky-Allison",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 225
                            }
                        ],
                        "text": "Other recent approaches attempt to combine structured high precision KBs with semistructured information sources like OpenIE triples (Fader et al., 2014), HTML tables (Pasupat and Liang, 2015), and large (and noisy) corpora (Sawant and Chakrabarti, 2013; Joshi et al., 2014; Xu et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learn - ing joint query interpretation and response rank"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Large-scale simple ques"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 236
                            }
                        ],
                        "text": "Other recent approaches attempt to combine structured high precision KBs with semistructured information sources like OpenIE triples (Fader et al., 2014), HTML tables (Pasupat and Liang, 2015), and large (and noisy) corpora (Sawant and Chakrabarti, 2013; Joshi et al., 2014; Xu et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learn - ing joint query interpretation and response rank"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 22 Nd International Conference on World Wide Web"
            },
            "year": 2013
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 26,
            "methodology": 12,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 39,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/TriviaQA:-A-Large-Scale-Distantly-Supervised-for-Joshi-Choi/f010affab57b5fcf1cd6be23df79d8ec98c7289c?sort=total-citations"
}