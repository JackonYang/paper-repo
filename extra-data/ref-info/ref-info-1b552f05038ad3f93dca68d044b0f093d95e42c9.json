{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2665417"
                        ],
                        "name": "Yu-Long Qiao",
                        "slug": "Yu-Long-Qiao",
                        "structuredName": {
                            "firstName": "Yu-Long",
                            "lastName": "Qiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-Long Qiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49141099"
                        ],
                        "name": "Meng Li",
                        "slug": "Meng-Li",
                        "structuredName": {
                            "firstName": "Meng",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meng Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779618"
                        ],
                        "name": "Zhe-ming Lu",
                        "slug": "Zhe-ming-Lu",
                        "structuredName": {
                            "firstName": "Zhe-ming",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhe-ming Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34842509"
                        ],
                        "name": "Shenghe Sun",
                        "slug": "Shenghe-Sun",
                        "structuredName": {
                            "firstName": "Shenghe",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shenghe Sun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 70
                            }
                        ],
                        "text": "Gabor filter was also employed for segmentation in the document image [8, 17, 19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17309783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "823de2c347f2c91e09391f63e42595b9f79abda7",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The automatic text detection in document images is useful for many applications. This paper presents an algorithm that can automatically detect and extract text in digital document images. Firstly, we process and fuse Gabor filtered images at different orientations and scales and obtain an image that reflects the layout of the document image. Then, potential text regions are directly extracted from the resulting image. Finally, two criteria based on the geometrical property and high frequency content are adopted to kick-out those non-text regions. The experiments are performed on some representative images with different styles and with texts in different languages and fonts. Experimental results show that the algorithm works well on document images from a wide variety of source."
            },
            "slug": "Gabor-Filter-Based-Text-Extraction-from-Digital-Qiao-Li",
            "title": {
                "fragments": [],
                "text": "Gabor Filter Based Text Extraction from Digital Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "An algorithm that can automatically detect and extract text in digital document images and two criteria based on the geometrical property and high frequency content are adopted to kick-out non-text regions."
            },
            "venue": {
                "fragments": [],
                "text": "2006 International Conference on Intelligent Information Hiding and Multimedia"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757655"
                        ],
                        "name": "S. Bhattacharjee",
                        "slug": "S.-Bhattacharjee",
                        "structuredName": {
                            "firstName": "Sushil",
                            "lastName": "Bhattacharjee",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bhattacharjee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 70
                            }
                        ],
                        "text": "Gabor filter was also employed for segmentation in the document image [8, 17, 19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13639250,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "808f205f834cfdfa823b97fbf1f20bf82ddaa8d7",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a considerable interest in designing automatic systems that will scan a given paper document and store it on electronic media for easier storage, manipulation, and access. Most documents contain graphics and images in addition to text. Thus, the document image has to be segmented to identify the text regions, so that OCR techniques may be applied only to those regions. In this paper, we present a simple method for document image segmentation in which text regions in a given document image are automatically identified. The proposed segmentation method for document images is based on a multichannel filtering approach to texture segmentation. The text in the document is considered as a textured region. Nontext contents in the document, such as blank spaces, graphics, and pictures, are considered as regions with different textures. Thus, the problem of segmenting document images into text and nontext regions can be posed as a texture segmentation problem. Two-dimensional Gabor filters are used to extract texture features for each of these regions. These filters have been extensively used earlier for a variety of texture segmentation tasks. Here we apply the same filters to the document image segmentation problem. Our segmentation method does not assume any a priori knowledge about the content or font styles of the document, and is shown to work even for skewed images and handwritten text. Results of the proposed segmentation method are presented for several test images which demonstrate the robustness of this technique."
            },
            "slug": "Text-segmentation-using-gabor-filters-for-automatic-Jain-Bhattacharjee",
            "title": {
                "fragments": [],
                "text": "Text segmentation using gabor filters for automatic document processing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents a simple method for document image segmentation in which text regions in a given document image are automatically identified and is shown to work even for skewed images and handwritten text."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Vision and Applications"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40263913"
                        ],
                        "name": "Chucai Yi",
                        "slug": "Chucai-Yi",
                        "structuredName": {
                            "firstName": "Chucai",
                            "lastName": "Yi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chucai Yi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35484757"
                        ],
                        "name": "Yingli Tian",
                        "slug": "Yingli-Tian",
                        "structuredName": {
                            "firstName": "Yingli",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yingli Tian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 268
                            }
                        ],
                        "text": "It is based on the magnitude gradient difference in Laplacian map [18] and the adjacent character grouping to find out all possible fragments of text strings, which are three or more edge boundaries with approximately equal heights, distances and horizontal alignment [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206724376,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cb107a5b3b6539a9b9a758d91871f8b2519c79d",
            "isKey": false,
            "numCitedBy": 380,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Text information in natural scene images serves as important clues for many image-based applications such as scene understanding, content-based image retrieval, assistive navigation, and automatic geocoding. However, locating text from a complex background with multiple colors is a challenging task. In this paper, we explore a new framework to detect text strings with arbitrary orientations in complex natural scene images. Our proposed framework of text string detection consists of two steps: 1) image partition to find text character candidates based on local gradient features and color uniformity of character components and 2) character candidate grouping to detect text strings based on joint structural features of text characters in each text string such as character size differences, distances between neighboring characters, and character alignment. By assuming that a text string has at least three characters, we propose two algorithms of text string detection: 1) adjacent character grouping method and 2) text line grouping method. The adjacent character grouping method calculates the sibling groups of each character candidate as string segments and then merges the intersecting sibling groups into text string. The text line grouping method performs Hough transform to fit text line among the centroids of text candidates. Each fitted text line describes the orientation of a potential text string. The detected text string is presented by a rectangle region covering all characters whose centroids are cascaded in its text line. To improve efficiency and accuracy, our algorithms are carried out in multi-scales. The proposed methods outperform the state-of-the-art results on the public Robust Reading Dataset, which contains text only in horizontal orientation. Furthermore, the effectiveness of our methods to detect text strings with arbitrary orientations is evaluated on the Oriented Scene Text Dataset collected by ourselves containing text strings in nonhorizontal orientations."
            },
            "slug": "Text-String-Detection-From-Natural-Scenes-by-and-Yi-Tian",
            "title": {
                "fragments": [],
                "text": "Text String Detection From Natural Scenes by Structure-Based Partition and Grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new framework to detect text strings with arbitrary orientations in complex natural scene images with outperform the state-of-the-art results on the public Robust Reading Dataset, which contains text only in horizontal orientation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46772547"
                        ],
                        "name": "Xilin Chen",
                        "slug": "Xilin-Chen",
                        "structuredName": {
                            "firstName": "Xilin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xilin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118579343"
                        ],
                        "name": "Jie Yang",
                        "slug": "Jie-Yang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155703534"
                        ],
                        "name": "Jing Zhang",
                        "slug": "Jing-Zhang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [4], Gabor filter is applied to obtain local features for text recognition after text detection and affine rectification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6109448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5295b6770ebbbc27a4651ed44b4b7e184d884f8e",
            "isKey": false,
            "numCitedBy": 330,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an approach to automatic detection and recognition of signs from natural scenes, and its application to a sign translation task. The proposed approach embeds multiresolution and multiscale edge detection, adaptive searching, color analysis, and affine rectification in a hierarchical framework for sign detection, with different emphases at each phase to handle the text in different sizes, orientations, color distributions and backgrounds. We use affine rectification to recover deformation of the text regions caused by an inappropriate camera view angle. The procedure can significantly improve text detection rate and optical character recognition (OCR) accuracy. Instead of using binary information for OCR, we extract features from an intensity image directly. We propose a local intensity normalization method to effectively handle lighting variations, followed by a Gabor transform to obtain local features, and finally a linear discriminant analysis (LDA) method for feature selection. We have applied the approach in developing a Chinese sign translation system, which can automatically detect and recognize Chinese signs as input from a camera, and translate the recognized text into English."
            },
            "slug": "Automatic-detection-and-recognition-of-signs-from-Chen-Yang",
            "title": {
                "fragments": [],
                "text": "Automatic detection and recognition of signs from natural scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes a local intensity normalization method to effectively handle lighting variations, followed by a Gabor transform to obtain local features, and finally a linear discriminant analysis (LDA) method for feature selection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054656200"
                        ],
                        "name": "R. Sandler",
                        "slug": "R.-Sandler",
                        "structuredName": {
                            "firstName": "Roman",
                            "lastName": "Sandler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sandler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727935"
                        ],
                        "name": "M. Lindenbaum",
                        "slug": "M.-Lindenbaum",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lindenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lindenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 75
                            }
                        ],
                        "text": "Gabor filter was widely used for texture analysis and image representation [10, 20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 23520095,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5b24473c555246bffecc14a4e8ead2550c19b0d",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "An effective and efficient texture analysis method, based on a new criterion for designing Gabor filter sets, is proposed. The commonly used filter sets are usually designed for optimal signal representation. We propose here an alternative criterion for designing the filter set. We consider a set of filters and its response to pairs of harmonic signals. Two signals are considered separable if the corresponding two sets of vector responses are disjoint in at least one of the components. We propose an algorithm for deriving the set of Gabor filters that maximizes the fraction of separable harmonic signal pairs in a given frequency range. The resulting filters differ significantly from the traditional ones. We test these maximal harmonic discrimination (MHD) filters in several texture analysis tasks: clustering, recognition, and edge detection. It turns out that the proposed filters perform much better than the traditional ones in these tasks. They can achieve performance similar to that of state-of-the-art, distribution based (texton) methods, while being simpler and more computationally efficient."
            },
            "slug": "Optimizing-Gabor-Filter-Design-for-Texture-Edge-Sandler-Lindenbaum",
            "title": {
                "fragments": [],
                "text": "Optimizing Gabor Filter Design for Texture Edge Detection and\u00a0Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes an algorithm for deriving the set of Gabor filters that maximizes the fraction of separable harmonic signal pairs in a given frequency range, and test these maximal harmonic discrimination filters in several texture analysis tasks: clustering, recognition, and edge detection."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109862994"
                        ],
                        "name": "Sunil Kumar",
                        "slug": "Sunil-Kumar",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sunil Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110344379"
                        ],
                        "name": "Rajat Gupta",
                        "slug": "Rajat-Gupta",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajat Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48676526"
                        ],
                        "name": "N. Khanna",
                        "slug": "N.-Khanna",
                        "structuredName": {
                            "firstName": "Nitin",
                            "lastName": "Khanna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Khanna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144725842"
                        ],
                        "name": "S. Chaudhury",
                        "slug": "S.-Chaudhury",
                        "structuredName": {
                            "firstName": "Santanu",
                            "lastName": "Chaudhury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chaudhury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705669"
                        ],
                        "name": "S. Joshi",
                        "slug": "S.-Joshi",
                        "structuredName": {
                            "firstName": "Shiv",
                            "lastName": "Joshi",
                            "middleNames": [
                                "Dutt"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Joshi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] established a set of globally matched wavelet filters as feature descriptors and used SVM and Fisher classifier to classify image windows as text or non-text."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1223283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "909f2c6dec43e702d425b6e5166043d878e42996",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we have proposed a novel scheme for the extraction of textual areas of an image using globally matched wavelet filters. A clustering-based technique has been devised for estimating globally matched wavelet filters using a collection of groundtruth images. We have extended our text extraction scheme for the segmentation of document images into text, background, and picture components (which include graphics and continuous tone images). Multiple, two-class Fisher classifiers have been used for this purpose. We also exploit contextual information by using a Markov random field formulation-based pixel labeling scheme for refinement of the segmentation results. Experimental results have established effectiveness of our approach."
            },
            "slug": "Text-Extraction-and-Document-Image-Segmentation-and-Kumar-Gupta",
            "title": {
                "fragments": [],
                "text": "Text Extraction and Document Image Segmentation Using Matched Wavelets and MRF Model"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A clustering-based technique has been devised for estimating globally matched wavelet filters using a collection of groundtruth images and a text extraction scheme for the segmentation of document images into text, background, and picture components is extended."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093164350"
                        ],
                        "name": "Nikos A. Nikolaou",
                        "slug": "Nikos-A.-Nikolaou",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Nikolaou",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nikos A. Nikolaou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144368634"
                        ],
                        "name": "N. Papamarkos",
                        "slug": "N.-Papamarkos",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Papamarkos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Papamarkos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11797188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7931dd44065b546c2e91c7ff8039406313f74961",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "A new technique for color reduction of complex document images is presented in this article. It reduces significantly the number of colors of the document image (less than 15 colors in most of the cases) so as to have solid characters and uniform local backgrounds. Therefore, this technique can be used as a preprocessing step by text information extraction applications. Specifically, using the edge map of the document image, a representative set of samples is chosen that constructs a 3D color histogram. Based on these samples in the 3D color space, a relatively large number of colors (usually no more than 100 colors) are obtained by using a simple clustering procedure. The final colors are obtained by applying a mean\u2010shift based procedure. Also, an edge preserving smoothing filter is used as a preprocessing stage that enhances significantly the quality of the initial image. Experimental results prove the method's capability of producing correctly segmented complex color documents where the character elements can be easily extracted as connected components. \u00a9 2009 Wiley Periodicals, Inc. Int J Imaging Syst Technol, 19, 14\u201326, 2009"
            },
            "slug": "Color-reduction-for-complex-document-images-Nikolaou-Papamarkos",
            "title": {
                "fragments": [],
                "text": "Color reduction for complex document images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results prove the method's capability of producing correctly segmented complex color documents where the character elements can be easily extracted as connected components."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Imaging Syst. Technol."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681758"
                        ],
                        "name": "Wumo Pan",
                        "slug": "Wumo-Pan",
                        "structuredName": {
                            "firstName": "Wumo",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wumo Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144957197"
                        ],
                        "name": "T. Bui",
                        "slug": "T.-Bui",
                        "structuredName": {
                            "firstName": "Tien",
                            "lastName": "Bui",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bui"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [17], Gabor filter is used for script identification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 70
                            }
                        ],
                        "text": "Gabor filter was also employed for segmentation in the document image [8, 17, 19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8516082,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "6c4be265aecf5e0150d1758f30617b8e16833f51",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-channel Gabor filtering has been widely used in texture classification. In this paper, Gabor filters have been applied to the problem of script identification in printed documents. Our work is divided into two stages. Firstly, a Gabor filter bank is appropriately designed so that extracted rotation-invariant features can handle scripts that are similar in shape and even share many characters. Secondly, the steerability property of Gabor filters is exploited to reduce the high computation cost resulted from the frequent image filtering, which is a common problem encountered in Gabor filter related applications. Results from preliminary experiments are quite promising, where Chinese, Japanese, Korean and English are considered. Over 98.5 % language identification rate can be achieved while image filtering operations have been reduced by 40%."
            },
            "slug": "Script-identification-using-steerable-Gabor-filters-Pan-Suen",
            "title": {
                "fragments": [],
                "text": "Script identification using steerable Gabor filters"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The steerability property of Gabor filters is exploited to reduce the high computation cost resulted from the frequent image filtering, which is a common problem encountered in Gabor filter related applications."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715066"
                        ],
                        "name": "T. Phan",
                        "slug": "T.-Phan",
                        "structuredName": {
                            "firstName": "Trung",
                            "lastName": "Phan",
                            "middleNames": [
                                "Quy"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Phan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744575"
                        ],
                        "name": "P. Shivakumara",
                        "slug": "P.-Shivakumara",
                        "structuredName": {
                            "firstName": "Palaiahnakote",
                            "lastName": "Shivakumara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Shivakumara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679749"
                        ],
                        "name": "C. Tan",
                        "slug": "C.-Tan",
                        "structuredName": {
                            "firstName": "Chew",
                            "lastName": "Tan",
                            "middleNames": [
                                "Lim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "It is based on the magnitude gradient difference in Laplacian map [18] and the adjacent character grouping to find out all possible fragments of text strings, which are three or more edge boundaries with approximately equal heights, distances and horizontal alignment [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 65
                            }
                        ],
                        "text": "Many rule-based algorithms have been proposed for text detection [6, 12, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123638,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0c4294d517de3243fd4f8a09359e265fbf2f1ea",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose an efficient text detection method based on the Laplacian operator. The maximum gradient difference value is computed for each pixel in the Laplacian-filtered image. K-means is then used to classify all the pixels into two clusters: text and non-text. For each candidate text region, the corresponding region in the Sobel edge map of the input image undergoes projection profile analysis to determine the boundary of the text blocks. Finally, we employ empirical rules to eliminate false positives based on geometrical properties. Experimental results show that the proposed method is able to detect text of different fonts, contrast and backgrounds. Moreover, it outperforms three existing methods in terms of detection and false positive rates."
            },
            "slug": "A-Laplacian-Method-for-Video-Text-Detection-Phan-Shivakumara",
            "title": {
                "fragments": [],
                "text": "A Laplacian Method for Video Text Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The proposed text detection method outperforms three existing methods in terms of detection and false positive rates and employs empirical rules to eliminate false positives based on geometrical properties."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681758"
                        ],
                        "name": "Wumo Pan",
                        "slug": "Wumo-Pan",
                        "structuredName": {
                            "firstName": "Wumo",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wumo Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144957197"
                        ],
                        "name": "T. Bui",
                        "slug": "T.-Bui",
                        "structuredName": {
                            "firstName": "Tien",
                            "lastName": "Bui",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] extracted segments of character boundaries as features and employed a K-SVD based learning model to detect text."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 230672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "443bf555d3ac1b78d90715ef09228833622e3530",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A sparse representation based method is proposed for text detection from scene images. We start with edge information extracted using Canny operator and then group these edge points into connected components. Each connected component is labeled as text or non-text by a two-level labeling process: pixel level labeling and connected component labeling. The core of the labeling process is a sparsity test using an over-complete dictionary, which is learned from edge segments of isolated character images. Layout analysis is further applied to verify these text candidates. Experimental results show that improvements in both recall rate and detection accuracy in text detection have been achieved."
            },
            "slug": "Text-detection-from-scene-images-using-sparse-Pan-Bui",
            "title": {
                "fragments": [],
                "text": "Text detection from scene images using sparse representation"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A sparse representation based method is proposed for text detection from scene images that starts with edge information extracted using Canny operator and then group these edge points into connected components that are labeled as text or non-text by a two-level labeling process."
            },
            "venue": {
                "fragments": [],
                "text": "2008 19th International Conference on Pattern Recognition"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126798"
                        ],
                        "name": "B. Epshtein",
                        "slug": "B.-Epshtein",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Epshtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Epshtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20592981"
                        ],
                        "name": "E. Ofek",
                        "slug": "E.-Ofek",
                        "structuredName": {
                            "firstName": "Eyal",
                            "lastName": "Ofek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ofek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743988"
                        ],
                        "name": "Y. Wexler",
                        "slug": "Y.-Wexler",
                        "structuredName": {
                            "firstName": "Yonatan",
                            "lastName": "Wexler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wexler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8890220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39c4ae83b5c92e0fa55de1ec7e5cf12589c408db",
            "isKey": false,
            "numCitedBy": 1470,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel image operator that seeks to find the value of stroke width for each image pixel, and demonstrate its use on the task of text detection in natural images. The suggested operator is local and data dependent, which makes it fast and robust enough to eliminate the need for multi-scale computation or scanning windows. Extensive testing shows that the suggested scheme outperforms the latest published algorithms. Its simplicity allows the algorithm to detect texts in many fonts and languages."
            },
            "slug": "Detecting-text-in-natural-scenes-with-stroke-width-Epshtein-Ofek",
            "title": {
                "fragments": [],
                "text": "Detecting text in natural scenes with stroke width transform"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A novel image operator is presented that seeks to find the value of stroke width for each image pixel, and its use on the task of text detection in natural images is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48873890"
                        ],
                        "name": "Qifeng Liu",
                        "slug": "Qifeng-Liu",
                        "structuredName": {
                            "firstName": "Qifeng",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qifeng Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "95055206"
                        ],
                        "name": "Cheolkon Jung",
                        "slug": "Cheolkon-Jung",
                        "structuredName": {
                            "firstName": "Cheolkon",
                            "lastName": "Jung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheolkon Jung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2198635"
                        ],
                        "name": "Youngsu Moon",
                        "slug": "Youngsu-Moon",
                        "structuredName": {
                            "firstName": "Youngsu",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Youngsu Moon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 65
                            }
                        ],
                        "text": "Many rule-based algorithms have been proposed for text detection [6, 12, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18522972,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23e9a4a9ebdff7fdbf8119241bd62d144a426f31",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Most existing methods of text segmentation in video images are not robust because they do not consider the intrinsic characteristics of text. In this paper, we propose a novel method of text segmentation based on stroke filter (SF). First, we give the definition of text, which is realized in the form of stroke filter based on local region analysis. Based on stroke filter response, text polarity determination and local region growing modules are performed successively. The effectiveness of our method is validated by experiments on a challenging database."
            },
            "slug": "Text-segmentation-based-on-stroke-filter-Liu-Jung",
            "title": {
                "fragments": [],
                "text": "Text segmentation based on stroke filter"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper gives the definition of text, which is realized in the form of stroke filter based on local region analysis, and proposes a novel method of text segmentation based on stroke filter (SF)."
            },
            "venue": {
                "fragments": [],
                "text": "MM '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739752"
                        ],
                        "name": "S. Bhagavathy",
                        "slug": "S.-Bhagavathy",
                        "structuredName": {
                            "firstName": "Sitaram",
                            "lastName": "Bhagavathy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bhagavathy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789352"
                        ],
                        "name": "Jelena Tesic",
                        "slug": "Jelena-Tesic",
                        "structuredName": {
                            "firstName": "Jelena",
                            "lastName": "Tesic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jelena Tesic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "Inspired by the Rayleigh nature of Gabor filter outputs in the texture analysis [2], we employ a mirror reversed Rayleigh distribution to model the statistical results of suitability measurements from positive samples."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6257973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99e921080c63fc2a9f0af0c5fc5c5deb95b95f04",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Texture has been recognized as an important visual primitive in image analysis. A widely used texture descriptor, which is part, of the MPEG-7 standard, is that computed using multiscale Gabor filters. The high dimensionality and computational complexity of this descriptor adversely affect the efficiency of content-based retrieval systems. We propose a modified texture descriptor that has comparable performance, but with nearly half the dimensionality and less computational expense. This gain is based on a claim that the distribution of (absolute values of) filter outputs have a strong tendency to be Rayleigh. Experimental results show that the dimensionality can be reduced by almost 50%, with a tradeoff of less than 3% on the error rate. Furthermore, it is easy to compute the new feature using the old, one, without having to repeat the computationally expensive filtering step. We also propose a new normalization method that improves similarity retrieval and indexing efficiency."
            },
            "slug": "On-the-Rayleigh-nature-of-Gabor-filter-outputs-Bhagavathy-Tesic",
            "title": {
                "fragments": [],
                "text": "On the Rayleigh nature of Gabor filter outputs"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A modified texture descriptor is proposed that has comparable performance, but with nearly half the dimensionality and less computational expense, based on a claim that the distribution of (absolute values of) filter outputs have a strong tendency to be Rayleigh."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110711666"
                        ],
                        "name": "T. Lee",
                        "slug": "T.-Lee",
                        "structuredName": {
                            "firstName": "Tai",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 75
                            }
                        ],
                        "text": "Gabor filter was widely used for texture analysis and image representation [10, 20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7230571,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2adac8e7ad1818d6a1fbc19ecf858581d9a5df9f",
            "isKey": false,
            "numCitedBy": 1733,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper extends to two dimensions the frame criterion developed by Daubechies for one-dimensional wavelets, and it computes the frame bounds for the particular case of 2D Gabor wavelets. Completeness criteria for 2D Gabor image representations are important because of their increasing role in many computer vision applications and also in modeling biological vision, since recent neurophysiological evidence from the visual cortex of mammalian brains suggests that the filter response profiles of the main class of linearly-responding cortical neurons (called simple cells) are best modeled as a family of self-similar 2D Gabor wavelets. We therefore derive the conditions under which a set of continuous 2D Gabor wavelets will provide a complete representation of any image, and we also find self-similar wavelet parametrization which allow stable reconstruction by summation as though the wavelets formed an orthonormal basis. Approximating a \"tight frame\" generates redundancy which allows low-resolution neural responses to represent high-resolution images."
            },
            "slug": "Image-Representation-Using-2D-Gabor-Wavelets-Lee",
            "title": {
                "fragments": [],
                "text": "Image Representation Using 2D Gabor Wavelets"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The conditions under which a set of continuous 2D Gabor wavelets will provide a complete representation of any image are derived, and self-similar wavelet parametrization is found which allow stable reconstruction by summation as though the wavelets formed an orthonormal basis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690430"
                        ],
                        "name": "Shiyan Hu",
                        "slug": "Shiyan-Hu",
                        "structuredName": {
                            "firstName": "Shiyan",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shiyan Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50133585"
                        ],
                        "name": "Minya Chen",
                        "slug": "Minya-Chen",
                        "structuredName": {
                            "firstName": "Minya",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minya Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] presented an adaptive Frechet Kernel based support vector machine (SVM) for text detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5638741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "203d2d096045383931659474eacf8656ba3293d9",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel general paradigm for text detection using a support vector machine (SVM) is proposed. Unlike prevailing techniques in the literature, our adaptive SVM incorporates information from each input image. In addition, for better classification results and higher efficiency, a novel kernel called the Fre/spl acute/chet kernel is presented for SVM classification. The adaptive SVM aims to serve as a general paradigm to improve the prevailing techniques. In the experiment, we apply the paradigm to a simple algorithm and successfully obtain a new competitive method for text detection."
            },
            "slug": "Adaptive-Fre/spl-acute/chet-kernel-based-support-Hu-Chen",
            "title": {
                "fragments": [],
                "text": "Adaptive Fre/spl acute/chet kernel based support vector machine for text detection"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel general paradigm for text detection using a support vector machine (SVM) and a novel kernel called the Fre/spl acute/chet kernel is presented for SVM classification."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87531536"
                        ],
                        "name": "A. Panaretos",
                        "slug": "A.-Panaretos",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Panaretos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Panaretos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073684197"
                        ],
                        "name": "Luis Sosa",
                        "slug": "Luis-Sosa",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Sosa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis Sosa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052189571"
                        ],
                        "name": "Anthony Tang",
                        "slug": "Anthony-Tang",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108862960"
                        ],
                        "name": "Shirley Wong",
                        "slug": "Shirley-Wong",
                        "structuredName": {
                            "firstName": "Shirley",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shirley Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114080648"
                        ],
                        "name": "Robert Young",
                        "slug": "Robert-Young",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6379469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce39eb5cc1049a1060a499d6b6e94c8b2ec11da1",
            "isKey": false,
            "numCitedBy": 591,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the robust reading competitions forICDAR 2003. With the rapid growth in research over thelast few years on recognizing text in natural scenes, thereis an urgent need to establish some common benchmarkdatasets, and gain a clear understanding of the current stateof the art. We use the term robust reading to refer to text imagesthat are beyond the capabilities of current commercialOCR packages. We chose to break down the robust readingproblem into three sub-problems, and run competitionsfor each stage, and also a competition for the best overallsystem. The sub-problems we chose were text locating,character recognition and word recognition.By breaking down the problem in this way, we hope togain a better understanding of the state of the art in eachof the sub-problems. Furthermore, our methodology involvesstoring detailed results of applying each algorithm toeach image in the data sets, allowing researchers to study indepth the strengths and weaknesses of each algorithm. Thetext locating contest was the only one to have any entries.We report the results of this contest, and show cases wherethe leading algorithms succeed and fail."
            },
            "slug": "ICDAR-2003-robust-reading-competitions-Lucas-Panaretos",
            "title": {
                "fragments": [],
                "text": "ICDAR 2003 robust reading competitions"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The robust reading problem was broken down into three sub-problems, and competitions for each stage, and also a competition for the best overall system, which was the only one to have any entries."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1842569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbf50fe5622253f401e892ed943a18033e18b7b9",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the results of the ICDAR 2005 competition for locating text in camera captured scenes. For this we used the same data as the ICDAR 2003 competition, which has been kept private until now. This allows a direct comparison with the 2003 entries. The main result is that the leading 2005 entry has improved significantly on the leading 2003 entry, with an increase in average f-score from 0.5 to 0.62, where the f-score is the same adapted information retrieval measure used for the 2003 competition. The paper also discusses the Web-based deployment and evaluation of text locating systems, and one of the leading entries has now been deployed in this way. This mode of usage could lead to more complete and more immediate knowledge of the strengths and weaknesses of each newly developed system."
            },
            "slug": "ICDAR-2005-text-locating-competition-results-Lucas",
            "title": {
                "fragments": [],
                "text": "ICDAR 2005 text locating competition results"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The main result is that the leading 2005 entry has improved significantly on the leading 2003 entry, with an increase in average f- score from 0.5 to 0.62, where the f-score is the same adapted information retrieval measure used for the 2003 competition."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781325"
                        ],
                        "name": "J. Daugman",
                        "slug": "J.-Daugman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Daugman",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Daugman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40518532,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "5faac4d01ce2c09eabb9b025d1b3b16130e6ae00",
            "isKey": false,
            "numCitedBy": 1343,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Two-dimensional-spectral-analysis-of-cortical-field-Daugman",
            "title": {
                "fragments": [],
                "text": "Two-dimensional spectral analysis of cortical receptive field profiles"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145298866"
                        ],
                        "name": "Jyotirmoy Banerjee",
                        "slug": "Jyotirmoy-Banerjee",
                        "structuredName": {
                            "firstName": "Jyotirmoy",
                            "lastName": "Banerjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jyotirmoy Banerjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3185334"
                        ],
                        "name": "A. Namboodiri",
                        "slug": "A.-Namboodiri",
                        "structuredName": {
                            "firstName": "Anoop",
                            "lastName": "Namboodiri",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Namboodiri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 43
                            }
                        ],
                        "text": "Different from the scanned document images [1, 11], extracting text from natural scene images is a challenging problem because of complex backgrounds and large variations of text patterns such as font, color, scale, and orientation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14612048,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64246feebea0884b070356761c731414256d4983",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to restore severely degraded document images using a probabilistic context model. Unlike traditional approaches that use previously learned prior models to restore an image, we are able to learn the text model from the degraded document itself, making the approach independent of script, font, style, etc. We model the contextual relationship using an MRF. The ability to work with larger patch sizes allows us to deal with severe degradations including cuts, blobs, merges and vandalized documents. Our approach can also integrate document restoration and super-resolution into a single framework, thus directly generating high quality images from degraded documents. Experimental results show significant improvement in image quality on document images collected from various sources including magazines and books, and comprehensively demonstrate the robustness and adaptability of the approach. It works well with document collections such as books, even with severe degradations, and hence is ideally suited for repositories such as digital libraries."
            },
            "slug": "Contextual-restoration-of-severely-degraded-images-Banerjee-Namboodiri",
            "title": {
                "fragments": [],
                "text": "Contextual restoration of severely degraded document images"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work proposes an approach to restore severely degraded document images using a probabilistic context model that works well with document collections such as books, even with severe degradations, and hence is ideally suited for repositories such as digital libraries."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144752865"
                        ],
                        "name": "Jian Liang",
                        "slug": "Jian-Liang",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31423777"
                        ],
                        "name": "D. DeMenthon",
                        "slug": "D.-DeMenthon",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "DeMenthon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. DeMenthon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 43
                            }
                        ],
                        "text": "Different from the scanned document images [1, 11], extracting text from natural scene images is a challenging problem because of complex backgrounds and large variations of text patterns such as font, color, scale, and orientation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1599704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c5ac89658511a0df08a108c2c85880a0f454f02",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Compared to typical scanners, handheld cameras offer convenient, flexible, portable, and noncontact image capture, which enables many new applications and breathes new life into existing ones. However, camera-captured documents may suffer from distortions caused by a nonplanar document shape and perspective projection, which lead to the failure of current optical character recognition (OCR) technologies. We present a geometric rectification framework for restoring the frontal-flat view of a document from a single camera-captured image. Our approach estimates the 3D document shape from texture flow information obtained directly from the image without requiring additional 3D/metric data or prior camera calibration. Our framework provides a unified solution for both planar and curved documents and can be applied in many, especially mobile, camera-based document analysis applications. Experiments show that our method produces results that are significantly more OCR compatible than the original images."
            },
            "slug": "Geometric-Rectification-of-Camera-Captured-Document-Liang-DeMenthon",
            "title": {
                "fragments": [],
                "text": "Geometric Rectification of Camera-Captured Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a geometric rectification framework for restoring the frontal-flat view of a document from a single camera-captured image and estimates the 3D document shape from texture flow information obtained directly from the image without requiring additional 3D/metric data or prior camera calibration."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ICDAR 2003 Robust Reading Competitions ICDAR"
            },
            "venue": {
                "fragments": [],
                "text": "ICDAR 2003 Robust Reading Competitions ICDAR"
            },
            "year": 2003
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 21,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Text-Detection-in-Natural-Scene-Images-by-Stroke-Yi-Tian/1b552f05038ad3f93dca68d044b0f093d95e42c9?sort=total-citations"
}