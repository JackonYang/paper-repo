{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144723337"
                        ],
                        "name": "Christophe Garcia",
                        "slug": "Christophe-Garcia",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christophe Garcia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1812064"
                        ],
                        "name": "M. Delakis",
                        "slug": "M.-Delakis",
                        "structuredName": {
                            "firstName": "Manolis",
                            "lastName": "Delakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Delakis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "In the preliminary approach that we presented in [37], we proposed a solution in which the number of positive answers nok in the local pyramid was considered in order to take the classification decision."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32706640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffda2eefb2458bb50f1c71d6fab6f3d6470fac9a",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a connectionist approach for detecting and precisely localizing semi-frontal human faces in complex images, making no assumption about the content or the lighting conditions of the scene, or about the size or the appearance of the faces. We propose a convolutional neural network architecture designed to recognize strongly variable face patterns directly from pixel images with no preprocessing, by automatically synthesizing its own set of feature extractors from a large training set of faces. We present in details the optimized design of our architecture, our learning strategy and the resulting process of face detection. We also provide experimental results to demonstrate the robustness of our approach and its capability to precisely detect extremely variable faces in uncontrolled environments."
            },
            "slug": "A-neural-architecture-for-fast-and-robust-face-Garcia-Delakis",
            "title": {
                "fragments": [],
                "text": "A neural architecture for fast and robust face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A convolutional neural network architecture designed to recognize strongly variable face patterns directly from pixel images with no preprocessing, by automatically synthesizing its own set of feature extractors from a large training set of faces."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2796017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca",
            "isKey": false,
            "numCitedBy": 11227,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second."
            },
            "slug": "Robust-Real-Time-Face-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new image representation called the \u201cIntegral Image\u201d is introduced which allows the features used by the detector to be computed very quickly and a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2432463"
                        ],
                        "name": "E. Hjelm\u00e5s",
                        "slug": "E.-Hjelm\u00e5s",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Hjelm\u00e5s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hjelm\u00e5s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054024193"
                        ],
                        "name": "B. K. Low",
                        "slug": "B.-K.-Low",
                        "structuredName": {
                            "firstName": "Boon",
                            "lastName": "Low",
                            "middleNames": [
                                "Kee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K. Low"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Only a few papers, including [17], address the definition of what is a correctly detected face [ 2 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Numerous approaches for face detection have been proposed in the last decade, many of them described and compared in two interesting recent surveys by Yang et al. [1] and Hjelmas et al. [ 2 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15724653,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "887567782cb859ecd339693589056903b0071353",
            "isKey": false,
            "numCitedBy": 1649,
            "numCiting": 336,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a comprehensive and critical survey of face detection algorithms. Face detection is a necessary first-step in face recognition systems, with the purpose of localizing and extracting the face region from the background. It also has several applications in areas such as content-based image retrieval, video coding, video conferencing, crowd surveillance, and intelligent human?computer interfaces. However, it was not until recently that the face detection problem received considerable attention among researchers. The human face is a dynamic object and has a high degree of variability in its apperance, which makes face detection a difficult problem in computer vision. A wide variety of techniques have been proposed, ranging from simple edge-based algorithms to composite high-level approaches utilizing advanced pattern recognition methods. The algorithms presented in this paper are classified as either feature-based or image-based and are discussed in terms of their technical approach and performance. Due to the lack of standardized tests, we do not provide a comprehensive comparative evaluation, but in cases where results are reported on common datasets, comparisons are presented. We also give a presentation of some proposed applications and possible application areas."
            },
            "slug": "Face-Detection:-A-Survey-Hjelm\u00e5s-Low",
            "title": {
                "fragments": [],
                "text": "Face Detection: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A comprehensive and critical survey of face detection algorithms, ranging from simple edge-based algorithms to composite high-level approaches utilizing advanced pattern recognition methods, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275441"
                        ],
                        "name": "K. Yow",
                        "slug": "K.-Yow",
                        "structuredName": {
                            "firstName": "Kin",
                            "lastName": "Yow",
                            "middleNames": [
                                "Choong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16932868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30e2f29d26f31846d6e0294cfa3733adfc618bbb",
            "isKey": false,
            "numCitedBy": 432,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-based-human-face-detection-Yow-Cipolla",
            "title": {
                "fragments": [],
                "text": "Feature-based human face detection"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "The face detection procedure acts like a pipeline of simple convolution and subsampling modules that treat the raw input image as a whole."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9045232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebb34b75982f628f9ce5995821fff81fd967dc2d",
            "isKey": false,
            "numCitedBy": 3968,
            "numCiting": 251,
            "paperAbstract": {
                "fragments": [],
                "text": "Images containing faces are essential to intelligent vision-based human-computer interaction, and research efforts in face processing include face recognition, face tracking, pose estimation and expression recognition. However, many reported methods assume that the faces in an image or an image sequence have been identified and localized. To build fully automated systems that analyze the information contained in face images, robust and efficient face detection algorithms are required. Given a single image, the goal of face detection is to identify all image regions which contain a face, regardless of its 3D position, orientation and lighting conditions. Such a problem is challenging because faces are non-rigid and have a high degree of variability in size, shape, color and texture. Numerous techniques have been developed to detect faces in a single image, and the purpose of this paper is to categorize and evaluate these algorithms. We also discuss relevant issues such as data collection, evaluation metrics and benchmarking. After analyzing these algorithms and identifying their limitations, we conclude with several promising directions for future research."
            },
            "slug": "Detecting-Faces-in-Images:-A-Survey-Yang-Kriegman",
            "title": {
                "fragments": [],
                "text": "Detecting Faces in Images: A Survey"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3430625"
                        ],
                        "name": "R. F\u00e9raud",
                        "slug": "R.-F\u00e9raud",
                        "structuredName": {
                            "firstName": "Rapha\u00ebl",
                            "lastName": "F\u00e9raud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. F\u00e9raud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118328"
                        ],
                        "name": "O. Bernier",
                        "slug": "O.-Bernier",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Bernier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Bernier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35094984"
                        ],
                        "name": "J. Viallet",
                        "slug": "J.-Viallet",
                        "structuredName": {
                            "firstName": "Jean-Emmanuel",
                            "lastName": "Viallet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Viallet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586567"
                        ],
                        "name": "M. Collobert",
                        "slug": "M.-Collobert",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collobert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Low level analysis first deals with the segmentation of visual features using image properties such as edges [3], intensity [4], color [5], [6], motion [7], or generalized measures [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In most image-based approaches ([6], [16], [22], [23], [24]), in order to search for faces at a given scale, the network must be replicated (or scanned) at all locations in the input image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[6] proposed another neural approach, based on constrained generative models (CGM), which are autoassociative fully connected MLPs with three large layers of weights, trained to perform a nonlinear PCA."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "No intensity normalization is performed on the cropped faces, such as overall brightness correction and histogram equalizationthatareappliedin[6], [16], [22], [23], [24]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Most of the image-based approaches in the literature ([6], [16], [22], [23], [24]) use a face window of about 20 20pixels, reported as being the smallest window one can use without loosing critical information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In [6], [16], [22], [23], neural filters are applied at every pixel of each image of the pyramid, after some operations of lighting correction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33451369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebfab3c7d0fdffc3d2f570c105e7a4e43997d04c",
            "isKey": true,
            "numCitedBy": 355,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting faces in images with complex backgrounds is a difficult task. Our approach, which obtains state of the art results, is based on a neural network model: the constrained generative model (CGM). Generative, since the goal of the learning process is to evaluate the probability that the model has generated the input data, and constrained since some counter-examples are used to increase the quality of the estimation performed by the model. To detect side view faces and to decrease the number of false alarms, a conditional mixture of networks is used. To decrease the computational time cost, a fast search algorithm is proposed. The level of performance reached, in terms of detection accuracy and processing time, allows us to apply this detector to a real world application: the indexing of images and videos."
            },
            "slug": "A-Fast-and-Accurate-Face-Detector-Based-on-Neural-F\u00e9raud-Bernier",
            "title": {
                "fragments": [],
                "text": "A Fast and Accurate Face Detector Based on Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The level of performance reached, in terms of detection accuracy and processing time, allows us to apply this detector to a real world application: the indexing of images and videos."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "in [38]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1619589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fd1c99edbb3d22cec4adc9ba9319cfc2360e903",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a neural network-based face detection system. Unlike similar systems which are limited to detecting upright, frontal faces, this system detects faces at any degree of rotation in the image plane. The system employs multiple networks; a \"router\" network first processes each input window to determine its orientation and then uses this information to prepare the window for one or more \"detector\" networks. We present the training methods for both types of networks. We also perform sensitivity analysis on the networks, and present empirical results on a large test set. Finally, we present preliminary results for detecting faces rotated out of the image plane, such as profiles and semi-profiles."
            },
            "slug": "Rotation-invariant-neural-network-based-face-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Rotation invariant neural network-based face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper presents a neural network-based face detection system, which is limited to detecting upright, frontal faces, and presents preliminary results for detecting faces rotated out of the image plane, such as profiles and semi-profiles."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084700325"
                        ],
                        "name": "G. Simandiris",
                        "slug": "G.-Simandiris",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Simandiris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Simandiris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2441655"
                        ],
                        "name": "G. Tziritas",
                        "slug": "G.-Tziritas",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Tziritas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tziritas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "We present extensive experimental results illustrating the efficiency of the proposed approach on difficult test sets and including an indepth sensitivity analysis with respect to the degrees of variability of the face patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 959392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecf6b9de1b1df965b9eff46d0c5f0d2db4b16fe8",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel scheme for detection and precise segmentation of human faces in color images where the number, the location, the orientation and the size of the faces are unknown, under nonconstrained scene conditions such as complex background and uncontrolled illumination. A deformable template is used as a generic model of the face, de ned by stable facial features grouped by anthropometric geometric and textural constraints. The di erent areas of the face template are characterized by extracting simple statistical measures from suitably selected bands of a wavelet decomposition. The candidate face is classi ed by applying a set of optimally ordered heuristic and probabilistic tests on the extracted statistical feature vectors. Experimental results are provided to demonstrate the robustness of our approach and its capability to precisely detect faces under varying scale, expression and orientation."
            },
            "slug": "A-FEATURE-BASED-FACE-DETECTOR-USING-WAVELET-FRAMES-Simandiris-Tziritas",
            "title": {
                "fragments": [],
                "text": "A FEATURE-BASED FACE DETECTOR USING WAVELET FRAMES"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A novel scheme for detection and precise segmentation of human faces in color images where the number, the location, the orientation and the size of the faces are unknown, under nonconstrained scene conditions such as complex background and uncontrolled illumination is proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145840115"
                        ],
                        "name": "S. Lawrence",
                        "slug": "S.-Lawrence",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Lawrence",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lawrence"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144288586"
                        ],
                        "name": "A. Back",
                        "slug": "A.-Back",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Back",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Back"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 218
                            }
                        ],
                        "text": "Different architectures of convolutional networks have been used successfully in many difficult applications such as handwriting recognition [29], [30], machine-printed character recognition [31], and face recognition [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2883848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86890c82b589e24007c56e1f40c5f928a0e04183",
            "isKey": false,
            "numCitedBy": 2716,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer."
            },
            "slug": "Face-recognition:-a-convolutional-neural-network-Lawrence-Giles",
            "title": {
                "fragments": [],
                "text": "Face recognition: a convolutional neural-network approach"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A hybrid neural-network for human face recognition which compares favourably with other methods and analyzes the computational complexity and discusses how new classes could be added to the trained recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "In most image-based approaches ([6], [16], [22], [23], [24]), in order to search for faces at a given scale, the network must be replicated (or scanned) at all locations in the input image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[23] present an analysis of the network output variations with respect to localized noise affecting the face patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 171
                            }
                        ],
                        "text": "This detection rate is still equivalent to or higher than the ones reported by Viola and\nTABLE 2 Comparison of Selected Methods for Various Numbers of False Alarms on the CMU Test Set\nTABLE 3 Results Reported in Terms of Percentage of Good Detection/Number of False Alarms, on the CMU and MIT Test Sets\nThe results obtained with our approach are reported for all test sets for ThrV ol \u00bc 17:0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "Finally, we examine the performance of our face detector on different test sets of images, including the CMU Test Set [23], used for comparison with other state-of-the-art techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "No intensity normalization is performed on the cropped faces, such as overall brightness correction and histogram equalizationthatareappliedin[6], [16], [22], [23], [24]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[23] proposed the first advanced neural approach which reported results on a large and difficult data set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "different test sets of images, including the CMU test set [23], that we use to compare our method with state-of-the-art"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "Most of the image-based approaches in the literature ([6], [16], [22], [23], [24]) use a face window of about 20 20pixels, reported as being the smallest window one can use without loosing critical information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "In [6], [16], [22], [23], neural filters are applied at every pixel of each image of the pyramid, after some operations of lighting correction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "We use the CMU test set [23], which is, so far, the most widely used data set in the literature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[23], Sung and Poggio [16], and ourselves."
                    },
                    "intents": []
                }
            ],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3885c13438132b516e5ffc8b640d20b4e41a7a4",
            "isKey": true,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural network-based face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 235084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cb4d685b47001652b29dc41c1b3e786277e7647",
            "isKey": false,
            "numCitedBy": 4016,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features and yields extremely efficient classifiers [4]. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performance comparable to the best previous systems [16, 11, 14, 10, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second. Author email: fPaul.Viola,Mike.J.Jonesg@compaq.com c Compaq Computer Corporation, 2001 This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of the Cambridge Research Laboratory of Compaq Computer Corporation in Cambridge, Massachusetts; an acknowledgment of the authors and individual contributors to the work; and all applicable portions of the copyright notice. Copying, reproducing, or republishing for any other purpose shall require a license with payment of fee to the Cambridge Research Laboratory. All rights reserved. CRL Technical reports are available on the CRL\u2019s web page at http://crl.research.compaq.com. Compaq Computer Corporation Cambridge Research Laboratory One Cambridge Center Cambridge, Massachusetts 02142 USA"
            },
            "slug": "Robust-Real-time-Object-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-time Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates is described, with the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144723337"
                        ],
                        "name": "Christophe Garcia",
                        "slug": "Christophe-Garcia",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christophe Garcia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2441655"
                        ],
                        "name": "G. Tziritas",
                        "slug": "G.-Tziritas",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Tziritas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tziritas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "The proposed scheme provides very high detection rate with a particularly low level of false positives, demonstrated on difficult test sets, without requiring the use of multiple networks for handling difficult cases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17988718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ddbb6e0913ac127004be73e2d4097513a8f02d37",
            "isKey": false,
            "numCitedBy": 654,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting and recognizing human faces automatically in digital images strongly enhance content-based video indexing systems. In this paper, a novel scheme for human faces detection in color images under nonconstrained scene conditions, such as the presence of a complex background and uncontrolled illumination, is presented. Color clustering and filtering using approximations of the YCbCr and HSV skin color subspaces are applied on the original image, providing quantized skin color regions. A merging stage is then iteratively performed on the set of homogeneous skin color regions in the color quantized image, in order to provide a set of potential face areas. Constraints related to shape and size of faces are applied, and face intensity texture is analyzed by performing a wavelet packet decomposition on each face area candidate in order to detect human faces. The wavelet coefficients of the band filtered images characterize the face texture and a set of simple statistical deviations is extracted in order to form compact and meaningful feature vectors. Then, an efficient and reliable probabilistic metric derived from the Bhattacharrya distance is used in order to classify the extracted feature vectors into face or nonface areas, using some prototype face area vectors, acquired in a previous training stage."
            },
            "slug": "Face-Detection-Using-Quantized-Skin-Color-Regions-Garcia-Tziritas",
            "title": {
                "fragments": [],
                "text": "Face Detection Using Quantized Skin Color Regions Merging and Wavelet Packet Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An efficient and reliable probabilistic metric derived from the Bhattacharrya distance is used in order to classify the extracted feature vectors into face or nonface areas, using some prototype face area vectors, acquired in a previous training stage."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Multim."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783224"
                        ],
                        "name": "A. Colmenarez",
                        "slug": "A.-Colmenarez",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Colmenarez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Colmenarez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9192390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e744c3eef4fbc4ac52b2458eb2d545a4432bcb86",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a visual learning technique that maximizes the discrimination between positive and negative examples in a training set. We demonstrate our technique in the context of face detection with complex background without color or motion information, which has proven to be a challenging problem. We use a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics. Then, we convert the learning process into an optimization, selecting the Markov process that optimizes the information-based discrimination between the two classes. The detection process is carried out by computing the likelihood ratio using the probability model obtained from the learning procedure. We show that because of the discrete nature of these models, the detection process is at least two orders of magnitude less computationally expensive than neural network approaches. However, no improvement in terms of correct-answer/false-alarm tradeoff is achieved."
            },
            "slug": "Face-detection-with-information-based-maximum-Colmenarez-Huang",
            "title": {
                "fragments": [],
                "text": "Face detection with information-based maximum discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A visual learning technique that maximizes the discrimination between positive and negative examples in a training set by using a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2721983"
                        ],
                        "name": "F. Fleuret",
                        "slug": "F.-Fleuret",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Fleuret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fleuret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6754141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b535f4edc4cbf8d4fb6182ec6b5c54db3c1cccb",
            "isKey": false,
            "numCitedBy": 339,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We study visual selection: Detect and roughly localize all instances of a generic object class, such as a face, in a greyscale scene, measuring performance in terms of computation and false alarms. Our approach is sequential testing which is coarse-to-fine in both in the exploration of poses and the representation of objects. All the tests are binary and indicate the presence or absence of loose spatial arrangements of oriented edge fragments. Starting from training examples, we recursively find larger and larger arrangements which are \u201cdecomposable,\u201d which implies the probability of an arrangement appearing on an object decays slowly with its size. Detection means finding a sufficient number of arrangements of each size along a decreasing sequence of pose cells. At the beginning, the tests are simple and universal, accommodating many poses simultaneously, but the false alarm rate is relatively high. Eventually, the tests are more discriminating, but also more complex and dedicated to specific poses. As a result, the spatial distribution of processing is highly skewed and detection is rapid, but at the expense of (isolated) false alarms which, presumably, could be eliminated with localized, more intensive, processing."
            },
            "slug": "Coarse-to-Fine-Face-Detection-Fleuret-Geman",
            "title": {
                "fragments": [],
                "text": "Coarse-to-Fine Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The approach is sequential testing which is coarse-to-fine in both in the exploration of poses and the representation of objects, and the spatial distribution of processing is highly skewed and detection is rapid, but at the expense of (isolated) false alarms which could be eliminated with localized, more intensive, processing."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48636477"
                        ],
                        "name": "G. Yang",
                        "slug": "G.-Yang",
                        "structuredName": {
                            "firstName": "Guangzheng",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Low level analysis first deals with the segmentation of visual features using image properties such as edges [3], intensity [ 4 ], color [5], [6], motion [7], or generalized measures [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38060615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2bb1ba70d48561ce8c3fbf59739fabc95e7b3d50",
            "isKey": false,
            "numCitedBy": 661,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Human-face-detection-in-a-complex-background-Yang-Huang",
            "title": {
                "fragments": [],
                "text": "Human face detection in a complex background"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2715202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63",
            "isKey": false,
            "numCitedBy": 17883,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection."
            },
            "slug": "Rapid-object-detection-using-a-boosted-cascade-of-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Rapid object detection using a boosted cascade of simple features"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates and the introduction of a new image representation called the \"integral image\" which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[24] proposed a face detector based on a learning architecture called SNoW (Sparse Network of Winnows), which consists of two linear threshold units, representing the classes of faces and nonfaces, that operate on an input space of Boolean features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In most image-based approaches ([6], [16], [22], [23], [24]), in order to search for faces at a given scale, the network must be replicated (or scanned) at all locations in the input image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Most of the image-based approaches in the literature ([6], [16], [22], [23], [24]) use a face window of about 20 20pixels, reported as being the smallest window one can use without loosing critical information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "No intensity normalization is performed on the cropped faces, such as overall brightness correction and histogram equalizationthatareappliedin[6], [16], [22], [23], [24]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1709452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23234a0f211a44d9706b2570d474427b8f899ec1",
            "isKey": true,
            "numCitedBy": 354,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel learning approach for human face detection using a network of linear units is presented. The SNoW learning architecture is a sparse network of linear functions over a pre-defined or incrementally learned feature space and is specifically tailored for learning in the presence of a very large number of features. A wide range of face images in different poses, with different expressions and under different lighting conditions are used as a training set to capture the variations of human faces. Experimental results on commonly used benchmark data sets of a wide range of face images show that the SNoW-based approach outperforms methods that use neural networks, Bayesian methods, support vector machines and others. Furthermore, learning and evaluation using the SNoW-based method are significantly more efficient than with other methods."
            },
            "slug": "A-SNoW-Based-Face-Detector-Yang-Roth",
            "title": {
                "fragments": [],
                "text": "A SNoW-Based Face Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results on commonly used benchmark data sets of a wide range of face images show that the SNoW-based approach outperforms methods that use neural networks, Bayesian methods, support vector machines and others."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39664966"
                        ],
                        "name": "C. Liu",
                        "slug": "C.-Liu",
                        "structuredName": {
                            "firstName": "Chengjun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8033147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0569e4ebc3c0c334de2bb5667e267d7e61d4f2a0",
            "isKey": false,
            "numCitedBy": 268,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel Bayesian discriminating features (BDF) method for multiple frontal face detection. The BDF method, which is trained on images from only one database, yet works on test images from diverse sources, displays robust generalization performance. The novelty of this paper comes from the integration of the discriminating feature analysis of the input image, the statistical modeling of face and nonface classes, and the Bayes classifier for multiple frontal face detection. First, feature analysis derives a discriminating feature vector by combining the input image, its 1D Harr wavelet representation, and its amplitude projections. While the Harr wavelets produce an effective representation for object detection, the amplitude projections capture the vertical symmetric distributions and the horizontal characteristics of human face images. Second, statistical modeling estimates the conditional probability density functions, or PDFs, of the face and nonface classes, respectively. While the face class is usually modeled as a multivariate normal distribution, the nonface class is much more difficult to model due to the fact that it includes \"the rest of the world.\" The estimation of such a broad category is, in practice, intractable. However, one can still derive a subset of the nonfaces that lie closest to the face class, and then model this particular subset as a multivariate normal distribution."
            },
            "slug": "A-Bayesian-Discriminating-Features-Method-for-Face-Liu",
            "title": {
                "fragments": [],
                "text": "A Bayesian Discriminating Features Method for Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The novelty of this paper comes from the integration of the discriminating feature analysis of the input image, the statistical modeling of face and nonface classes, and the Bayes classifier for multiple frontal face detection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47814225"
                        ],
                        "name": "Shi-Hong Jeng",
                        "slug": "Shi-Hong-Jeng",
                        "structuredName": {
                            "firstName": "Shi-Hong",
                            "lastName": "Jeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shi-Hong Jeng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704678"
                        ],
                        "name": "H. Liao",
                        "slug": "H.-Liao",
                        "structuredName": {
                            "firstName": "Hong-Yuan",
                            "lastName": "Liao",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203056"
                        ],
                        "name": "Chin-Chuan Han",
                        "slug": "Chin-Chuan-Han",
                        "structuredName": {
                            "firstName": "Chin-Chuan",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Chuan Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40037860"
                        ],
                        "name": "M. Chern",
                        "slug": "M.-Chern",
                        "structuredName": {
                            "firstName": "Ming-Yang",
                            "lastName": "Chern",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108924004"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Yao",
                            "lastName": "Liu",
                            "middleNames": [
                                "Tsorng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42126886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b60030b334f9fae4f2c8744e024898ec83dc0e59",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Facial-feature-detection-using-geometrical-face-An-Jeng-Liao",
            "title": {
                "fragments": [],
                "text": "Facial feature detection using geometrical face model: An efficient approach"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144850567"
                        ],
                        "name": "Long Zhu",
                        "slug": "Long-Zhu",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2651359"
                        ],
                        "name": "ZhenQiu Zhang",
                        "slug": "ZhenQiu-Zhang",
                        "structuredName": {
                            "firstName": "ZhenQiu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ZhenQiu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154486"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32107239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c4fdffc12589f9f312a44802b8e2fe8311aa13e",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A new boosting algorithm, called FloatBoost, is proposed to overcome the monotonicity problem of the sequential AdaBoost learning. AdaBoost [1, 2] is a sequential forward search procedure using the greedy selection strategy. The premise oyered by the sequential procedure can be broken-down when the monotonicity assumption, i.e. that when adding a new feature to the current set, the value of the performance criterion does not decrease, is violated. FloatBoost incorporates the idea of Floating Search [3] into AdaBoost to solve the non-monotonicity problem encountered in the sequential search of AdaBoost.We then present a system which learns to detect multi-view faces using FloatBoost. The system uses a coarse-to-fine, simple-to-complex architecture called detector-pyramid. FloatBoost learns the component detectors in the pyramid and yields similar or higher classification accuracy than AdaBoost with a smaller number of weak classifiers. This work leads to the first real-time multi-view face detection system in the world. It runs at 200 ms per image of size 320x240 pixels on a Pentium-III CPU of 700 MHz. A live demo will be shown at the conference."
            },
            "slug": "Statistical-Learning-of-Multi-view-Face-Detection-Li-Zhu",
            "title": {
                "fragments": [],
                "text": "Statistical Learning of Multi-view Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "FloatBoost incorporates the idea of Floating Search into AdaBoost to solve the non-monotonicity problem encountered in the sequential search of AdaBoost and leads to the first real-time multi-view face detection system in the world."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "147984118"
                        ],
                        "name": "R. Vaillant",
                        "slug": "R.-Vaillant",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Vaillant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vaillant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3208918"
                        ],
                        "name": "C. Monrocq",
                        "slug": "C.-Monrocq",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Monrocq",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Monrocq"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9326933"
                        ],
                        "name": "Y. L. Cun",
                        "slug": "Y.-L.-Cun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Cun",
                            "middleNames": [
                                "le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. L. Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[33], input images of size 20 20 are preprocessed with a Laplacian filter, normalized and passed to an architecture composed of one convolutional layer of four feature maps of size 16 16, followed by a subsampling layer of four feature maps."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[33] used convolutional networks for imagebased object detection and considered the case of face detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16690291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc7fa2cf9d7d2b3aca4fa22271412831e9a61e22",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents an algorithm for the detection of faces in images using shared-weight replicated neural networks. A neural net forms rough hypotheses about the position of faces. These hypotheses are then verified using a second neural network. The algorithm applies to images where the size of the faces is unknown a priori. The computational time which is necessary for the complete processing of an image is reasonable. With a classical workstation an image of size 512*512 is treated in 50 seconds including smoothing and normalization of the image. This algorithm can be easily installed on a more specialized machine as the major part of the operation is based on convolutions with kernels of size 5*5 or 8*8. In this paper, the authors assume that the face are well oriented in the image. It is possible to eliminate this assumption by following an approach similar to the one used for the scale problem. A net is trained to be insensitive to the precise orientation of the face. This kind of segmentation algorithm can be applied to other problems where the objects to be detected cannot be characterized easily by its outline or by classical primitives in image processing."
            },
            "slug": "An-original-approach-for-the-localization-of-in-Vaillant-Monrocq",
            "title": {
                "fragments": [],
                "text": "An original approach for the localization of objects in images"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An algorithm for the detection of faces in images using shared-weight replicated neural networks, trained to be insensitive to the precise orientation of the face by following an approach similar to the one used for the scale problem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36439812,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b22aea31f1bc4f226916460da546c0771dd1003",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two methods using multimodal density models for face detection in gray-level images. One generative method uses a mixture of factor analyzers to concurrently perform clustering and, within each cluster, perform local dimensionality reduction. The parameters of the mixture model are estimated using the EM algorithm. A face is detected if the probability of an input sample is above a predefined threshold. The other discriminative method uses Kohonen's self-organizing map for clustering, Fisher's linear discriminant to find an optimal projection for pattern classification, and a Gaussian distribution to model the class-conditional density function of the projected samples for each class. The parameters of the class-conditional density functions are maximum likelihood estimates, and the decision rule is also based on maximum likelihood. A wide range of face images including ones in different poses, with different expressions and under different lighting conditions, is used as the training set to capture variations of the human face. Our methods have been tested on three data sets with a total of 225 images containing 871 faces. Experimental results on the first two data sets show that our generative and discriminative methods perform as well as the best methods in the literature, yet have fewer false detections. Meanwhile, both methods are able to detect faces of nonfrontal views and under more extreme lighting in the third data set."
            },
            "slug": "Face-Detection-Using-Multimodal-Density-Models-Yang-Kriegman",
            "title": {
                "fragments": [],
                "text": "Face Detection Using Multimodal Density Models"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "Two methods using multimodal density models for face detection in gray-level images perform as well as the best methods in the literature, yet have fewer false detections."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747625"
                        ],
                        "name": "D. Maio",
                        "slug": "D.-Maio",
                        "structuredName": {
                            "firstName": "Dario",
                            "lastName": "Maio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687735"
                        ],
                        "name": "D. Maltoni",
                        "slug": "D.-Maltoni",
                        "structuredName": {
                            "firstName": "Davide",
                            "lastName": "Maltoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maltoni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15505950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb8427550a099124ebdbc44f783f6b62a0583a5e",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Real-time-face-location-on-gray-scale-static-images-Maio-Maltoni",
            "title": {
                "fragments": [],
                "text": "Real-time face location on gray-scale static images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": false,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144723337"
                        ],
                        "name": "Christophe Garcia",
                        "slug": "Christophe-Garcia",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christophe Garcia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69028867"
                        ],
                        "name": "G. Zikos",
                        "slug": "G.-Zikos",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Zikos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zikos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2441655"
                        ],
                        "name": "G. Tziritas",
                        "slug": "G.-Tziritas",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Tziritas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tziritas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11957230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ecb7764dac7a51a9aff86cfec9cb9872c137037",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Wavelet-packet-analysis-for-face-recognition-Garcia-Zikos",
            "title": {
                "fragments": [],
                "text": "Wavelet packet analysis for face recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "The proposed scheme provides very high detection rate with a particularly low level of false positives, demonstrated on difficult test sets, without requiring the use of multiple networks for handling difficult cases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29332361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6275f9f4208e91bece3e31312717fb5ffdbdf08c",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The human face is an object that is easily located in complex scenes by infants and adults alike. Yet the development of an automated system to perform this task is extremely challenging. An attempt to solve this problem raises two important issues in object location. First, natural objects such as human faces tend to have boundaries which are not exactly described by analytical functions. Second, the object of interest (face) could occur in a scene in various sizes, thus requiring the use of scale independent techniques which can detect instances of the object at all scales.Although, the task of identifying a well-framed face (as one of a set of labeled faces) has been well researched, the task of locating a face in a natural scene is relatively unexplored. We present a computational theory for locating human faces in scenes with certain constraints. The theory will be validated by experiments confined to instances where people's faces are the primary subject of the scene, occlusion is minimal, and the faces contrast well against the background."
            },
            "slug": "Locating-human-faces-in-photographs-Govindaraju",
            "title": {
                "fragments": [],
                "text": "Locating human faces in photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A computational theory for locating human faces in scenes with certain constraints is presented and will be validated by experiments confined to instances where people's faces are the primary subject of the scene, occlusion is minimal, and the faces contrast well against the background."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771659"
                        ],
                        "name": "R. Freund",
                        "slug": "R.-Freund",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Freund",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2845602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9008cdacbdcff8a218a6928e94fe7c6dfc237b24",
            "isKey": false,
            "numCitedBy": 2841,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points."
            },
            "slug": "Training-support-vector-machines:-an-application-to-Osuna-Freund",
            "title": {
                "fragments": [],
                "text": "Training support vector machines: an application to face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets is presented, and the feasibility of the approach on a face detection problem that involves a data set of 50,000 data points is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Face detection, neural networks, machine learning, convolutional networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35252,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145893752"
                        ],
                        "name": "J. Fellous",
                        "slug": "J.-Fellous",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Fellous",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fellous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "We present extensive experimental results illustrating the efficiency of the proposed approach on difficult test sets and including an indepth sensitivity analysis with respect to the degrees of variability of the face patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10223132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c27487c3e0894b65e976a287e6f8c9aa40f089c",
            "isKey": false,
            "numCitedBy": 2135,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for recognizing human faces from single images out of a large database containing one image per person. Faces are represented by labeled graphs, based on a Gabor wavelet transform. Image graphs of new faces are extracted by an elastic graph matching process and can be compared by a simple similarity function. The system differs from Lades et al. (1993) in three respects. Phase information is used for accurate node positioning. Object-adapted graphs are used to handle large rotations in depth. Image graph extraction is based on a novel data structure, the bunch graph, which is constructed from a small set of sample image graphs."
            },
            "slug": "Face-recognition-by-elastic-bunch-graph-matching-Wiskott-Fellous",
            "title": {
                "fragments": [],
                "text": "Face recognition by elastic bunch graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A system for recognizing human faces from single images out of a large database containing one image per person, based on a Gabor wavelet transform, which differs from Lades et al. (1993) in three respects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153903103"
                        ],
                        "name": "C. Lin",
                        "slug": "C.-Lin",
                        "structuredName": {
                            "firstName": "Cheng",
                            "lastName": "Lin",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2262254"
                        ],
                        "name": "Wei-Chung Lin",
                        "slug": "Wei-Chung-Lin",
                        "structuredName": {
                            "firstName": "Wei-Chung",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Chung Lin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "The proposed scheme provides very high detection rate with a particularly low level of false positives, demonstrated on difficult test sets, without requiring the use of multiple networks for handling difficult cases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31656339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d558124a6c0d894bc009555a8035f7f08df28472",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The extraction of facial features is a fundamental and crucial step in most face detection and recognition systems. Here a set of approaches are proposed for extracting internal and external facial features in a grey-level images containing single or multiple faces of various sizes at different locations without any restriction on the background. These approaches are distinctive in several aspects: the use of some rarely exploited photometric properties as the basis for facial features extraction, a novel metrics on radial symmetry of gradient orientations, an inhibitory mechanism for extracting internal facial features, and a simple mechanism for external ones."
            },
            "slug": "Extracting-facial-features-by-an-inhibitory-based-Lin-Lin",
            "title": {
                "fragments": [],
                "text": "Extracting facial features by an inhibitory mechanism based on gradient distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A set of approaches are proposed for extracting internal and external facial features in a grey-level images containing single or multiple faces of various sizes at different locations without any restriction on the background."
            },
            "venue": {
                "fragments": [],
                "text": "Optical Engineering Midwest"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054024143"
                        ],
                        "name": "B. K. Low",
                        "slug": "B.-K.-Low",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Low",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K. Low"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47836515"
                        ],
                        "name": "M. Ibrahim",
                        "slug": "M.-Ibrahim",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Ibrahim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ibrahim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "The proposed scheme provides very high detection rate with a particularly low level of false positives, demonstrated on difficult test sets, without requiring the use of multiple networks for handling difficult cases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16615943,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "251715a6154d2fbb362c17858df8773a722deb8b",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A facial feature segmentation algorithm for head and shoulder sequences is proposed. The method is based on simple spatial and temporal heuristics techniques for the purpose of practical implementation. Facial features are segmented using two common cues (i) regular and high image intensity variation in the temporal domain due to various motion like talking and moving, and (ii) high edge density around the feature regions. A simple motion detection method and a generic spatial operator are applied to achieve the required segmentation. The paper addresses the issue of how to combine both information to obtain final results and also assesses the segmentation performance."
            },
            "slug": "A-fast-and-accurate-algorithm-for-facial-feature-Low-Ibrahim",
            "title": {
                "fragments": [],
                "text": "A fast and accurate algorithm for facial feature segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The paper addresses the issue of how to combine both information to obtain final results and also assesses the segmentation performance."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144144572"
                        ],
                        "name": "G. Martin",
                        "slug": "G.-Martin",
                        "structuredName": {
                            "firstName": "Gale",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Martin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Different architectures of convolutional networks have been used successfully in many difficult applications such as handwriting recognition [29], [ 30 ], machine-printed character recognition [31], and face recognition [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207744862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfb28df0e6a807cabdecc8ab5ca9c9ed006be7c0",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual object recognition is often conceived of as a final step in a visual processing system, First, physical information in the raw image is used to isolate and enhance to-be-recognized clumps and then each of the resulting preprocessed representations is fed into the recognizer. This general conception fails when there are no reliable physical cues for isolating the objects, such as when objects overlap. This paper describes an approach, called centered object integrated segmentation and recognition (COISR), for integrating object segmentation and recognition within a single neural network. The application is handprinted character recognition. The approach uses a backpropagation network that scans a field of characters and is trained to recognize whether it is centered over a single character or between characters. When it is centered over a character, the net classifies the character. The approach is tested on a dataset of handprinted digits and high accuracy rates are reported."
            },
            "slug": "Centered-Object-Integrated-Segmentation-and-of-Martin",
            "title": {
                "fragments": [],
                "text": "Centered-Object Integrated Segmentation and Recognition of Overlapping Handprinted Characters"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The approach uses a backpropagation network that scans a field of characters and is trained to recognize whether it is centered over a single character or between characters, which classifies the character."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120465549"
                        ],
                        "name": "J. Wang",
                        "slug": "J.-Wang",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2130202"
                        ],
                        "name": "J. Jean",
                        "slug": "J.-Jean",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Jean",
                            "middleNames": [
                                "S.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jean"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61843965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64e7adce9a36ffcace36a2e0a334a0415fbbfe75",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A multiresolution optical character recognition (OCR) using neural networks is proposed for omnifont character recognition. It is motivated by the human reading process in which a low resolution is used to effectively process the majority of clean and unambiguous text, while a more complicated recognition scheme is invoked only when a high resolution is needed. Compared with the method that utilizes single resolution, the multiresolution system not only speeds up recognition by up to 20 times, but also improves accuracy of isolated character recognition from 99.8% to 99.9%. The multiresolution approach captures the essence of better reading, and provides the building blocks for the next-generation OCR systems.<<ETX>>"
            },
            "slug": "Multiresolution-neural-networks-for-omnifont-Wang-Jean",
            "title": {
                "fragments": [],
                "text": "Multiresolution neural networks for omnifont character recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A multiresolution optical character recognition using neural networks is proposed for omnifont character recognition, which not only speeds up recognition by up to 20 times, but also improves accuracy of isolated character recognition from 99.8% to 99.9%."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12209481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3565c5a65842f26091578b9d71d496cc1561239d",
            "isKey": false,
            "numCitedBy": 1292,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints."
            },
            "slug": "A-statistical-method-for-3D-object-detection-to-and-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "A statistical method for 3D object detection applied to faces and cars"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Using this method, this work has developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithms thatCan reliably detect passenger cars over a wide range of viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "[15], [28], [29], are powerful bioinspired hierarchical multilayered neural networks that combine three architectural ideas to ensure some degree of shift, scale, and distortion invariance: local receptive fields, shared weights, and spatial subsampling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "Different architectures of convolutional networks have been used successfully in many difficult applications such as handwriting recognition [29], [30], machine-printed character recognition [31], and face recognition [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2542741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86ab4cae682fbd49c5a5bedb630e5a40fa7529f6",
            "isKey": false,
            "numCitedBy": 2930,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service."
            },
            "slug": "Handwritten-Digit-Recognition-with-a-Network-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Handwritten Digit Recognition with a Back-Propagation Network"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task, and has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 483975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b312560b79929540734067e58de46966b96130",
            "isKey": false,
            "numCitedBy": 1684,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands."
            },
            "slug": "Probabilistic-Visual-Learning-for-Object-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic Visual Learning for Object Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An unsupervised technique for visual learning is presented, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334226"
                        ],
                        "name": "D. Hubel",
                        "slug": "D.-Hubel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hubel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hubel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2629471"
                        ],
                        "name": "T. Wiesel",
                        "slug": "T.-Wiesel",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Wiesel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wiesel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 197
                            }
                        ],
                        "text": "The idea of connecting units to local receptive fields on the input was largely inspired by Hubel and Wiesel\u2019s discovery of locally-sensitive, orientationselective neurons in the cat visual system [34] and local connections have been used many times in neural models of visual learning [28], [35], [36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17055992,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "6b4fe4aa4d66fecc7b2869569002714d91d0b3f7",
            "isKey": false,
            "numCitedBy": 12428,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "What chiefly distinguishes cerebral cortex from other parts of the central nervous system is the great diversity of its cell types and interconnexions. It would be astonishing if such a structure did not profoundly modify the response patterns of fibres coming into it. In the cat's visual cortex, the receptive field arrangements of single cells suggest that there is indeed a degree of complexity far exceeding anything yet seen at lower levels in the visual system. In a previous paper we described receptive fields of single cortical cells, observing responses to spots of light shone on one or both retinas (Hubel & Wiesel, 1959). In the present work this method is used to examine receptive fields of a more complex type (Part I) and to make additional observations on binocular interaction (Part II). This approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours. In the past, the technique of recording evoked slow waves has been used with great success in studies of functional anatomy. It was employed by Talbot & Marshall (1941) and by Thompson, Woolsey & Talbot (1950) for mapping out the visual cortex in the rabbit, cat, and monkey. Daniel & Whitteiidge (1959) have recently extended this work in the primate. Most of our present knowledge of retinotopic projections, binocular overlap, and the second visual area is based on these investigations. Yet the method of evoked potentials is valuable mainly for detecting behaviour common to large populations of neighbouring cells; it cannot differentiate functionally between areas of cortex smaller than about 1 mm2. To overcome this difficulty a method has in recent years been developed for studying cells separately or in small groups during long micro-electrode penetrations through nervous tissue. Responses are correlated with cell location by reconstructing the electrode tracks from histological material. These techniques have been applied to"
            },
            "slug": "Receptive-fields,-binocular-interaction-and-in-the-Hubel-Wiesel",
            "title": {
                "fragments": [],
                "text": "Receptive fields, binocular interaction and functional architecture in the cat's visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This method is used to examine receptive fields of a more complex type and to make additional observations on binocular interaction and this approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of physiology"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47953439"
                        ],
                        "name": "R\u00e9gis Vaillant",
                        "slug": "R\u00e9gis-Vaillant",
                        "structuredName": {
                            "firstName": "R\u00e9gis",
                            "lastName": "Vaillant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9gis Vaillant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3208918"
                        ],
                        "name": "C. Monrocq",
                        "slug": "C.-Monrocq",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Monrocq",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Monrocq"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9326933"
                        ],
                        "name": "Y. L. Cun",
                        "slug": "Y.-L.-Cun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Cun",
                            "middleNames": [
                                "le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. L. Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[33] used convolutional networks for imagebased object detection and considered the case of face detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62763570,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "09ebd9ad4fa21c0d56433ac57a4cd69e94c72281",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An original approach is presented for the localisation of objects in an image which approach is neuronal and has two steps. In the first step, a rough localisation is performed by presenting each pixel with its neighbourhood to a neural net which is able to indicate whether this pixel and its neighbourhood are the image of the search object. This first filter does not discriminate for position. From its result, areas which might contain an image of the object can be selected. In the second step, these areas are presented to another neural net which can determine the exact position of the object in each area. This algorithm is applied to the problem of localising faces in images."
            },
            "slug": "Original-approach-for-the-localisation-of-objects-Vaillant-Monrocq",
            "title": {
                "fragments": [],
                "text": "Original approach for the localisation of objects in images"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "An original approach is presented for the localisation of objects in an image which approach is neuronal and has two steps and is applied to the problem of localising faces in images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144473519"
                        ],
                        "name": "M. Mozer",
                        "slug": "M.-Mozer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mozer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mozer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The idea of connecting units to local receptive fields on the input was largely inspired by Hubel and Wiesel\u2019s discovery of locally-sensitive, orientationselective neurons in the cat visual system [34] and local connections have been used many times in neural models of visual learning [28], [35], [36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5125059,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1762498d7ef09cc706b551c54ce6894a7b2ee14d",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "\"The Perception of Multiple Objects \"describes a neurally inspired computational model of two-dimensional object recognition and spatial attention that can explain many characteristics of human visual perception. The model, called MORSEL (named for its ability to perform Multiple Object Recognition and attentional Selection), is unique in providing a broad and unified explanation for a wide range of experimental psychological data on visual perception and attention. Although it draws on existing theoretical perspectives from cognitive psychology, it is a fully mechanistic account, not just a functional-level theory.MORSEL has been trained to recognize letters and words in various positions on its \"retina.\" Following training, it can also recognize several items at once, subject to capacity limitations. The model makes predictions about what sorts of information the visual system can process in parallel and what sorts must be processed serially.Through simulation experiments, chiefly in letter and word perception, MORSEL has been shown to account for a variety of psychological phenomena, including perceptual errors that arise when several items appear simultaneously in the visual field, facilitatory effects of context and redundant information, attentional phenomena, visual search performance, and behaviors exhibited by neurological patients with acquired dyslexia."
            },
            "slug": "Perception-of-multiple-objects-a-connectionist-Mozer",
            "title": {
                "fragments": [],
                "text": "Perception of multiple objects - a connectionist approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The model, called MORSEL, is unique in providing a broad and unified explanation for a wide range of experimental psychological data on visual perception and attention, and draws on existing theoretical perspectives from cognitive psychology."
            },
            "venue": {
                "fragments": [],
                "text": "Neural network modeling and connectionism"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 292
                            }
                        ],
                        "text": "The idea of connecting units to local receptive fields on the input was largely inspired by Hubel and Wiesel\u2019s discovery of locally-sensitive, orientationselective neurons in the cat visual system [34] and local connections have been used many times in neural models of visual learning [28], [35], [36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 28586460,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "03b4a233b19cf202ba9117d501a82a48ef3ed6e9",
            "isKey": false,
            "numCitedBy": 328,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A new hypothesis for the organization of synapses between neurons is proposed: \u201cThe synapse from neuron x to neuron y is reinforced when x fires provided that no neuron in the vicinity of y is firing stronger than y\u201d. By introducing this hypothesis, a new algorithm with which a multilayered neural network is effectively organized can be deduced. A self-organizing multilayered neural network, which is named \u201ccognitron\u201d, is constructed following this algorithm, and is simulated on a digital computer. Unlike the organization of a usual brain models such as a three-layered perceptron, the self-organization of a cognitron progresses favorably without having a \u201cteacher\u201d which instructs in all particulars how the individual cells respond. After repetitive presentations of several stimulus patterns, the cognitron is self-organized in such a way that the receptive fields of the cells become relatively larger in a deeper layer. Each cell in the final layer integrates the information from whole parts of the first layer and selectively responds to a specific stimulus pattern or a feature."
            },
            "slug": "Cognitron:-A-self-organizing-multilayered-neural-Fukushima",
            "title": {
                "fragments": [],
                "text": "Cognitron: A self-organizing multilayered neural network"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A new hypothesis for the organization of synapses between neurons is proposed: \u201cThe synapse from neuron x to neuron y is reinforced when x fires provided that no neuron in the vicinity of y is firing stronger than y\u201d, and a new algorithm with which a multilayered neural network is effectively organized can be deduced."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [1], we proposed a fast method using skin color filtering and probabilistic classification of facial textures based on statistical measures extracted from a wavelet packet decomposition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "As a comparison, with our previous approach [1] we obtained 94."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 71
                            }
                        ],
                        "text": "The proposed method has been evaluated using the test data set used in [1], which contains images kindly provided by the Institut National Audiovisuel (INA), France and by ERT Television, Greece."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Detection Using Quantized Skin Color Region Merging and Wavelet Packet Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Multimedia,"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[15], [28], [29], are powerful bioinspired hierarchical multilayered neural networks that combine three architectural ideas to ensure some degree of shift, scale, and distortion invariance: local receptive fields, shared weights, and spatial subsampling."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "different locations in the image, to have identical weight vectors [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The idea of connecting units to local receptive fields on the input was largely inspired by Hubel and Wiesel\u2019s discovery of locally-sensitive, orientationselective neurons in the cat visual system [34] and local connections have been used many times in neural models of visual learning [28], [35], [36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 59861896,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01b6affe3ea4eae1978aec54e87087feb76d9215",
            "isKey": false,
            "numCitedBy": 863,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generalization-and-network-design-strategies-LeCun",
            "title": {
                "fragments": [],
                "text": "Generalization and network design strategies"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Perception of Multiple Objects: A Connectionist Approach Connectionism in Perspective"
            },
            "venue": {
                "fragments": [],
                "text": "The Perception of Multiple Objects: A Connectionist Approach Connectionism in Perspective"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 147
                            }
                        ],
                        "text": "For training the network, we used the classical backpropagation algorithm with momentum modified for use on convolutional networks as described in [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "and successfully applied to handwritten character recognition [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handwritten digit recognition with a backpropagation neural network"
            },
            "venue": {
                "fragments": [],
                "text": "In D. Touretzky editor, Advances in Neural Information Processing Systems"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "We present extensive experimental results illustrating the efficiency of the proposed approach on difficult test sets and including an indepth sensitivity analysis with respect to the degrees of variability of the face patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic Visual Learning for Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalization and Network Design Strategies Connectionism in Perspective"
            },
            "venue": {
                "fragments": [],
                "text": "Generalization and Network Design Strategies Connectionism in Perspective"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
            },
            "venue": {
                "fragments": [],
                "text": "For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 27,
            "methodology": 13,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 47,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Convolutional-face-finder:-a-neural-architecture-Garcia-Delakis/68a859142ef42196e6a56305b8c6ac4cb2c9326e?sort=total-citations"
}