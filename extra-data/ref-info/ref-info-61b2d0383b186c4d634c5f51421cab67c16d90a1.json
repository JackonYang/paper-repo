{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 127
                            }
                        ],
                        "text": "There are four edge types, corresponding roughly to vertical and horizontal orientation and two polarities; the details are in Amit, Geman, and Jedynak (1998) and are not important for the discussion here, except to note that the orientation is not very precise."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 40
                            }
                        ],
                        "text": "Some evidence for this was discussed in Amit and Geman (1997) in the context of shape quantization; decision trees induced from training data about one object class were found to be useful for classifying shapes never seen during training."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 3
                            }
                        ],
                        "text": "In Amit (1998) we show\nhow a fixed architecture with a moderate number of arrays can accommodate any detection task with a central memory module storing the representations of the various objects."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 53
                            }
                        ],
                        "text": "Several tens of trees are grown and aggregated as in Amit and Geman (1997). The use of multiple trees together with photometrically invariant edge features provides a robust classifier."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 264
                            }
                        ],
                        "text": ") Choosing Nedges = 3 and Npixels = 10 yields frequencies on the order of 50%, which leads to very low false-negative rates with only order Ntypes = 10 local features; these are the values used in the experiments reported in the following section as well as in in Amit et al. (1998). Clearly the local variability of the object class is crucial in determining these frequencies."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1390011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62ccf3020ac41088b39c3982d119752b0ba6b261",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes a parallel neural net architecture for efficient and robust visual selection in generic gray-level images. Objects are represented through flexible star-type planar arrangements of binary local features which are in turn star-type planar arrangements of oriented edges. Candidate locations are detected over a range of scales and other deformations, using a generalized Hough transform. The flexibility of the arrangements provides the required invariance. Training involves selecting a small number of stable local features from a predefined pool, which are well localized on registered examples of the object. Training therefore requires only small data sets. The parallel architecture is constructed so that the Hough transform associated with any object can be implemented without creating or modifying any connections. The different object representations are learned and stored in a central module. When one of these representations is evoked, it primes the appropriate layers in the network so that the corresponding Hough transform is computed. Analogies between the different layers in the network and those in the visual system are discussed. Furthermore, the model can be used to explain certain experiments on visual selection reported in the literature."
            },
            "slug": "A-Neural-Network-Architecture-for-Visual-Selection-Amit",
            "title": {
                "fragments": [],
                "text": "A Neural Network Architecture for Visual Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A parallel neural net architecture for efficient and robust visual selection in generic gray-level images, constructed so that the Hough transform associated with any object can be implemented without creating or modifying any connections."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 236
                            }
                        ],
                        "text": "\u2026selection, if not final classification, can be accomplished with object representations that are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on parts (Winston, 1970; Biederman, 1985) and pictorial representations (Ullman, 1996)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5535504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c7babd0f86f6e1e61cdc02a4b22aab0c1245e92",
            "isKey": false,
            "numCitedBy": 528,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Human-image-understanding:-Recent-research-and-a-Biederman",
            "title": {
                "fragments": [],
                "text": "Human image understanding: Recent research and a theory"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2879893"
                        ],
                        "name": "A. Lueschow",
                        "slug": "A.-Lueschow",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lueschow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lueschow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171934932"
                        ],
                        "name": "E. Miller",
                        "slug": "E.-Miller",
                        "structuredName": {
                            "firstName": "Earl",
                            "lastName": "Miller",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144375727"
                        ],
                        "name": "R. Desimone",
                        "slug": "R.-Desimone",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Desimone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Desimone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 123
                            }
                        ],
                        "text": "There is clear evidence for translation and scale invariance within certain ranges in the responses of some neurons in IT (Lueschow et al., 1994; Ito, Tamura, Fujita, & Tanaka, 1995)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 25454448,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "4c63fa480d1232a128ef91fa4cc262ecce15e501",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The specific size and retinal location of an object are readily perceived, yet recognition of an object's identity is hardly affected by transformations of its size or location. To explore how such stimulus transformations are treated by known mechanisms for visual short-term memory in inferior temporal (IT) cortex, IT cells were recorded in monkeys performing a delayed matching-to-sample task. The stimuli were pictures of complex objects, and the monkeys ignored differences in size and retinal location when matching the test items to the sample held in memory. The sensory information communicated by cells was assessed in their responses to the sample stimuli, and mnemonic information was assessed in their responses to the test stimuli. In the sensory domain, the ordering of relative stimulus preferences for nearly all cells was invariant over changes in size or location; however, some cells nonetheless preferred stimuli of a given size or location. In the mnemonic domain, the responses of many cells were modulated according to whether the test stimulus matched the sample held in memory, and these memory effects were invariant over the relative sizes and locations of the stimuli. Thus, IT neuronal populations may mediate not only the recognition and memory of object identity, which are invariant over size and location, but also the perception of the transformations themselves."
            },
            "slug": "Inferior-temporal-mechanisms-for-invariant-object-Lueschow-Miller",
            "title": {
                "fragments": [],
                "text": "Inferior temporal mechanisms for invariant object recognition."
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "IT neuronal populations may mediate not only the recognition and memory of object identity, which are invariant over size and location, but also the perception of the transformations themselves."
            },
            "venue": {
                "fragments": [],
                "text": "Cerebral cortex"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 53
                            }
                        ],
                        "text": "Several tens of trees are grown and aggregated as in Amit and Geman (1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 40
                            }
                        ],
                        "text": "Some evidence for this was discussed in Amit and Geman (1997) in the context of shape quantization; decision trees induced from training data about one object class were found to be useful for classifying shapes never seen during training."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12470146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de5e95325e139fd0a46df1dd28aabecd0273b772",
            "isKey": false,
            "numCitedBy": 1152,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore a new approach to shape recognition based on a virtually infinite family of binary features (queries) of the image data, designed to accommodate prior information about shape invariance and regularity. Each query corresponds to a spatial arrangement of several local topographic codes (or tags), which are in themselves too primitive and common to be informative about shape. All the discriminating power derives from relative angles and distances among the tags. The important attributes of the queries are a natural partial ordering corresponding to increasing structure and complexity; semi-invariance, meaning that most shapes of a given class will answer the same way to two queries that are successive in the ordering; and stability, since the queries are not based on distinguished points and substructures. No classifier based on the full feature set can be evaluated, and it is impossible to determine a priori which arrangements are informative. Our approach is to select informative features and build tree classifiers at the same time by inductive learning. In effect, each tree provides an approximation to the full posterior where the features chosen depend on the branch that is traversed. Due to the number and nature of the queries, standard decision tree construction based on a fixed-length feature vector is not feasible. Instead we entertain only a small random sample of queries at each node, constrain their complexity to increase with tree depth, and grow multiple trees. The terminal nodes are labeled by estimates of the corresponding posterior distribution over shape classes. An image is classified by sending it down every tree and aggregating the resulting distributions. The method is applied to classifying handwritten digits and synthetic linear and nonlinear deformations of three hundred symbols. State-of-the-art error rates are achieved on the National Institute of Standards and Technology database of digits. The principal goal of the experiments on symbols is to analyze invariance, generalization error and related issues, and a comparison with artificial neural networks methods is presented in this context. Figure 1: LATEX Symbol"
            },
            "slug": "Shape-Quantization-and-Recognition-with-Randomized-Amit-Geman",
            "title": {
                "fragments": [],
                "text": "Shape Quantization and Recognition with Randomized Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A new approach to shape recognition based on a virtually infinite family of binary features (queries) of the image data, designed to accommodate prior information about shape invariance and regularity, and a comparison with artificial neural networks methods is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5260610"
                        ],
                        "name": "D. Grosof",
                        "slug": "D.-Grosof",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grosof",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Grosof"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1994273"
                        ],
                        "name": "R. Shapley",
                        "slug": "R.-Shapley",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Shapley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shapley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2480424"
                        ],
                        "name": "M. Hawken",
                        "slug": "M.-Hawken",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Hawken",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hawken"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4318697,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "925548196e6545d3cc64bbc4ed99578775f5fa14",
            "isKey": false,
            "numCitedBy": 385,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "WE describe here a new view of primary visual cortex (VI) based on measurements of neural responses in V1 to patterns called \u2018illusory contours\u2019 (Fig. la, b). Detection of an object's boundary contours is a fundamental visual task. Boundary contours are defined by discontinuities not only in luminance and colour, but also in texture1\u00963, disparity4 and motion5\u00967. Two theoretical approaches can account for illusory contour perception. The cognitive approach emphasizes top-down processes8,9. An alternative emphasizes bottom-up processing. This latter view is supported by (1) stimulus constraints for illusory contour perception10\u009614 and (2) the discovery by von der Heydt and Peterhans15\u009617 of neurons in extrastriate visual area V2 (but not in V1) of macaque monkeys that respond to illusory contours. Using stimuli different from those used previously15,16, we found illusory contour responses in about half the neurons studied in V1 of macaque monkeys. Therefore, there are neurons as early as V1 with the computational power to detect illusory contours and to help distinguish figure from ground."
            },
            "slug": "Macaque-VI-neurons-can-signal-\u2018illusory\u2019-contours-Grosof-Shapley",
            "title": {
                "fragments": [],
                "text": "Macaque VI neurons can signal \u2018illusory\u2019 contours"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "There are neurons as early as V1 with the computational power to detect illusory contour and to help distinguish figure from ground, according to a new view of primary visual cortex based on measurements of neural responses in V1 to patterns called \u2018illusory contours\u2019."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747836"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 61
                            }
                        ],
                        "text": "In addition, there are experiments in neuropsychology (e.g., Bulthoff & Edelman, 1992) that indicate that 3D information is not crucial."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15899784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb181b3bead64a4b8b08d5f0b051743b186bd040",
            "isKey": false,
            "numCitedBy": 170,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Does the human brain represent objects for recognition by storing a series of twodimensional snapshots, or are the object models, in some sense, three-dimensional analogs of the objects they represent? One way to address this question is to explore the ability of the human visual system to generalize recognition from familiar to novel views of three-dimensional objects. Three recently proposed theories of object recognition | viewpoint normalization or alignment of 3D models [Ullman, S. (1989) Cognition, 32, 193-254], linear combination of 2D views [Ullman, S. & Basri, R. (1990)], and view approximation [Poggio, T. & Edelman, S. (1990) Nature, 343, 263-266] | predict di erent patterns of generalization to novel views. We have exploited the con icting predictions to test the three theories directly, in a psychophysical experiment involving computer-generated 3D objects. Our results suggest that the human visual system is better described as recognizing these objects by 2D view interpolation than by alignment or other methods that rely on object-centered 3D models. 2 How does the human visual system represent objects for recognition? The experiments we describe address this question by testing the ability of human subjects (and of computer models instantiating particular theories of recognition) to generalize from familiar to unfamiliar views of novel objects. Since di erent theories predict di erent patterns of generalization according to the experimental conditions, this approach yields concrete evidence in favor of some of the theories, and contradicts others. Theories that rely on 3D object-centered representations The rst class of theories we have considered [1, 4, 5] represent objects by 3D models, encoded in a viewpoint-independent fashion. One such approach, recognition by alignment [1], compares the input image with the projection of a stored model after the two are brought into register. The transformation necessary to achieve this registration is computed by matching a small number of features in the image with the corresponding features in the model. The aligning transformation is computed separately for each of the models stored in the system. Recognition is declared for the model that ts the input most closely after the two are aligned, if the residual dissimilarity between them is small enough. The decision criterion for recognition in this case can be stated in the following simpli ed form: kPTX(3D) X(2D)k < (1) where T is the aligning transformation, P is a 3D ! 2D projection operator, and the norm k kmeasures the dissimilarity between the projection of the transformed 3D model X(3D) and the input image X(2D). Recognition decision is then made based on a comparison between the measured dissimilarity and a threshold . One may make a further distinction between full alignment that uses 3D models and attempts to compensate for 3D transformations of objects (such as 3 rotation in depth), and the alignment of pictorial descriptions that uses multiple views rather than a single object-centered representation. Speci cally ([1], p.228), the multiple-view version of alignment involves representation that is \\view-dependent, since a number of di erent models of the same object from di erent viewing positions will be used,\" but at the same time \\view-insensitive, since the di erences between views are partially compensated by the alignment process.\" Consequently, view-independent performance (e.g., low error rate for novel views) can be considered the central distinguishing feature of both versions of this theory. Visual systems that rely on alignment and other 3D approaches can in principle achieve near perfect recognition performance, provided that (i) the 3D models of the input objects are available, and (ii) the information needed to access the correct model is present in the image. We note that a similar behavior is predicted by those recognition theories that represent objects by 3D structural relationships between generic volumetric primitives. Theories belonging to this class (e.g., [6, 7]) tend to focus on basic-level classi cation of objects rather than on the recognition of speci c object instances,1 and will not be given further consideration in this paper. Theories that rely on 2D viewer-centered representations Two recently proposed approaches to recognition dispense with the need for storing 3D models. The rst of these, recognition by linear combination of views [2], is built on the mathematical observation that, under orthographic projection, the 1Numerous studies in cognitive science (see [8] for a review) reveal that in the hierarchical structure of object categories there exists a certain level, called basic level, which is the most salient according to a variety of criteria (such as the ease and preference of access). Taking as an example the hierarchy \\quadruped, mammal, cat, Siamese\", the basic level is that of \\cat\". Objects whose recognition implies more detailed distinctions than those required for basic-level categorization are said to belong to a subordinate level. 4 2D coordinates of an object point can be represented by a linear combination of the coordinates of the corresponding points in a small number of xed 2D views of the same object. The required number of views depends on the allowed 3D transformations of the objects and on the representation of an individual view. A polyhedral object that can undergo a general linear transformation requires three views if separate linear bases are used to represent the x and the y coordinates of a new view; two views su ce if a mixed x; y basis is used [2, 9]. The recognition criterion under one possible version of the linear combination approach [10] can be formulated schematically as kXi iX(2D) i X(2D)k < (2) where the stored views X(2D) i comprise the linear vector basis that represents an object model (i.e., spans the space of the object's views), X(2D) is the input image, and i are the coe cients estimated for the given model/image pair. A recognition system that is perfectly linear and relies exclusively on the above approach should achieve uniformly high performance on those views that fall within the space spanned by the stored set of model views, and should perform poorly on views that belong to an orthogonal space. Another approach that represents objects by sets of 2D views is view approximation by regularization networks [3, 11], which includes as a special case approximation by radial basis functions (RBFs) [12, 13]. In this approach, generalization from familiar to novel views is regarded as a problem of approximating a smooth hypersurface in the space of all possible views, with the \\height\" of the surface known only at a sparse set of points corresponding to the familiar views. The approximation can be performed by a two-stage network (see [9] for details). In the rst stage intermediate responses are formed by a collection of nonlinear \\receptive elds\" (shaped, e.g., as multidimensional Gaussians), centered at the 5 familiar views. The output of the second stage is a linear combination of the intermediate receptive eld responses. If the regularization network is trained to output the value 1 for various views of a given object, the decision criterion for recognition can be stated as jXk ckG kX(2D) X(2D) k k 1j < (3) where X(2D) is the input image, X(2D) k are the familiar or prototypical views stored in the system, ck are the linear coe cients, and the function G( ) represents the shape of the receptive eld. A recognition system based on this method is expected to perform well when the novel view is close to the stored ones (that is, when most of the features of the input image fall close to their counterparts at least in some of the stored views; cf. [14]). The performance should become progressively worse on views that are far from the familiar ones. Methods To distinguish between the theories outlined above, we have developed an experimental paradigm based on a two-alternative forced-choice (2AFC) task. Our experiments consist of two phases: training and testing. In the training phase subjects are shown a novel object (see Figure 1) de ned as the target, usually as a motion sequence of 2D views that leads to an impression of solid shape through the kinetic depth e ect. In the testing phase the subjects are presented with single static views of either the target or a distractor (one of a relatively large set of similar objects). Target test views were situated either on the equator (on the 0 75 or on the 75 360 portion of the great circle, called inter and extra conditions), or on the meridian passing through one of the training views (ortho condition) (see Figure 2). The subject's task was to press a \\yes-button\" 6 if the displayed object is the current target and a \\no-button\" otherwise, and to do it as quickly and as accurately as possible. These instructions usually resulted in mean response times around 1 sec, and in mean miss rates2 around 30%. The fast response times indicate that the subjects did not apply conscious problemsolving techniques or reason explicitly about the stimuli. In all our experiments the subjects received no feedback as to the correctness of their response. The main features of our experimental approach are as follows: We can control precisely the subject's prior exposure to the targets, by employing novel computer-generated three-dimensional objects, similar to those shown in Figure 1. We can generate an unlimited number of novel objects with controlled complexity and surface appearance. Because the stimuli are produced by computer graphics, we can conduct identical experiments with human subjects and with computational models. Results The experimental setup satis ed both requirements of the alignment theory for perfect recognition: the subjects, all of whom reported perfect perception of 3D structure from motion during training, had the opportunity to form 3D models of the stimuli, and al"
            },
            "slug": "Psychophysical-support-for-a-2D-view-interpolation-B\u00fclthoff",
            "title": {
                "fragments": [],
                "text": "Psychophysical support for a 2D view interpolation theory of object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The results suggest that the human visual system is better described as recognizing these objects by 2D view interpolation than by alignment or other methods that rely on object-centered 3D models, as well as those recognition theories that represent objects by 3D structural relationships between generic volumetric primitives."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153905429"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "H",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 61
                            }
                        ],
                        "text": "In addition, there are experiments in neuropsychology (e.g., Bulthoff & Edelman, 1992) that indicate that 3D information is not crucial."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2657697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca97fc4dadcc564e5081743b52a4d77031d1c177",
            "isKey": false,
            "numCitedBy": 726,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Does the human brain represent objects for recognition by storing a series of two-dimensional snapshots, or are the object models, in some sense, three-dimensional analogs of the objects they represent? One way to address this question is to explore the ability of the human visual system to generalize recognition from familiar to unfamiliar views of three-dimensional objects. Three recently proposed theories of object recognition--viewpoint normalization or alignment of three-dimensional models [Ullman, S. (1989) Cognition 32, 193-254], linear combination of two-dimensional views [Ullman, S. & Basri, R. (1990) Recognition by Linear Combinations of Models (Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge), A. I. Memo No. 1152], and view approximation [Poggio, T. & Edelman, S. (1990) Nature (London) 343, 263-266]--predict different patterns of generalization to unfamiliar views. We have exploited the conflicting predictions to test the three theories directly in a psychophysical experiment involving computer-generated three-dimensional objects. Our results suggest that the human visual system is better described as recognizing these objects by two-dimensional view interpolation than by alignment or other methods that rely on object-centered three-dimensional models."
            },
            "slug": "Psychophysical-support-for-a-two-dimensional-view-B\u00fclthoff-Edelman",
            "title": {
                "fragments": [],
                "text": "Psychophysical support for a two-dimensional view interpolation theory of object recognition."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results suggest that the human visual system is better described as recognizing these objects by two-dimensional view interpolation than by alignment or other methods that rely on object-centered three-dimensional models."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40190254"
                        ],
                        "name": "I. Fujita",
                        "slug": "I.-Fujita",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Fujita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2048860"
                        ],
                        "name": "Keiji Tanaka",
                        "slug": "Keiji-Tanaka",
                        "structuredName": {
                            "firstName": "Keiji",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keiji Tanaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108813944"
                        ],
                        "name": "Minami Ito",
                        "slug": "Minami-Ito",
                        "structuredName": {
                            "firstName": "Minami",
                            "lastName": "Ito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minami Ito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40622591"
                        ],
                        "name": "K. Cheng",
                        "slug": "K.-Cheng",
                        "structuredName": {
                            "firstName": "Kang",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cheng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38714031,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "083630744dbf60994867cbd776bfe601b4d0dbe6",
            "isKey": false,
            "numCitedBy": 684,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "AT early stages of the mammalian visual cortex, neurons with similar stimulus selectivities are vertically arrayed through the thickness of the cortical sheet and clustered in patches or bands across the surface. This organization, referred to as a 'column', has been found with respect to one-dimensional stimulus parameters such as orientation of stimulus contours1, eye dominance of visual inputs1, and direction of stimulus motion2. It is unclear, however, whether information with extremely high dimensions, such as visual shape, is organized in a similar columnar fashion or in a different manner in the brain. Here we report that the anterior inferotemporal area of the monkey cortex, the final station of the visual cortical stream crucial for object recognition3\u20138, consists of columns, each containing cells responsive to similar visual features of objects."
            },
            "slug": "Columns-for-visual-features-of-objects-in-monkey-Fujita-Tanaka",
            "title": {
                "fragments": [],
                "text": "Columns for visual features of objects in monkey inferotemporal cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The anterior inferotemporal area of the monkey cortex, the final station of the visual cortical stream crucial for object recognition, consists of columns, each containing cells responsive to similar visual features of objects."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2521020"
                        ],
                        "name": "B. Jedynak",
                        "slug": "B.-Jedynak",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Jedynak",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Jedynak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The one we use is based on comparisons of intensity differences and is consequently invariant to linear transformations of the gray scale, ensuring the photometric part of LI. There are four edge types, corresponding roughly to vertical and horizontal orientation and two polarities; the details are in  Amit, Geman, and Jedynak (1998)  and are not important for the discussion here, except to note that the orientation is not very precise.,observed for randomly deformed Latex symbols.) Choosing NedgesD 3 and NpixelsD 10 yields frequencies on the order of 50%, which leads to very low false-negative rates with only order NtypesD 10 local features; these are the values used in the experiments reported in the following section as well as in in  Amit et al. (1998) ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 262
                            }
                        ],
                        "text": "Choosing Nedges = 3 and Npixels = 10 yields frequencies on the order of 50%, which leads to very low false-negative rates with only order Ntypes = 10 local features; these are the values used in the experiments reported in the following section as well as in in Amit et al. (1998)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 127
                            }
                        ],
                        "text": "There are four edge types, corresponding roughly to vertical and horizontal orientation and two polarities; the details are in Amit, Geman, and Jedynak (1998) and are not important for the discussion here, except to note that the orientation is not very precise."
                    },
                    "intents": []
                }
            ],
            "corpusId": 118052090,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b56ab69d6d2ed840f3850df3c60ccdf1d5f284d9",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for shape detection and apply it to frontal views of faces in still grey level images with arbitrary backgrounds. Detection is done in two stages: (i) \u201cfocusing,\u201d during which a relatively small number of regions-of-interest are identified, minimizing computation and false negatives at the (temporary) expense of false positives; and (ii) \u201cintensive classification,\u201d during which a selected region-of-interest is labeled face or background based on multiple decision trees and normalized data. In contrast to most detection algorithms, the processing is then very highly concentrated in the regions near faces and near false positives."
            },
            "slug": "Efficient-Focusing-and-Face-Detection-Amit-Geman",
            "title": {
                "fragments": [],
                "text": "Efficient Focusing and Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "An algorithm for shape detection is presented and applied to frontal views of faces in still grey level images with arbitrary backgrounds and a selected region-of-interest is labeled face or background based on multiple decision trees and normalized data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47482017"
                        ],
                        "name": "E. Kobatake",
                        "slug": "E.-Kobatake",
                        "structuredName": {
                            "firstName": "Eucaly",
                            "lastName": "Kobatake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kobatake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157875742"
                        ],
                        "name": "K. Tanaka",
                        "slug": "K.-Tanaka",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tanaka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 74
                            }
                        ],
                        "text": "Moreover, the general strategy for visual selection goes back at least to Lowe (1985) and others who emphasized the role of selecting groupings based on their statistical or \u201cnonaccidental\u201d properties."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 43
                            }
                        ],
                        "text": "This is demonstrated in the experiments in Kobatake and Tanaka (1994) and in Ito et al. (1995), where successive simplifications of the selective stimuli and various deformations or degradations still evoke a strong response."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5864841,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9a4880278882962ccecd03d70d478507b1f2b851",
            "isKey": false,
            "numCitedBy": 836,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "1. To infer relative roles of cortical areas at different stages of the ventral visual pathway, we quantitatively examined visual responses of cells in V2, V4, the posterior part of the inferotemporal cortex (posterior IT), and the anterior part of the inferotemporal cortex (anterior IT), using anesthetized macaque monkeys. 2. The critical feature for the activation was first determined for each recorded cell by using a reduction method. We started from images of three-dimensional complex objects and simplified the image of effective stimuli step by step by eliminating a part of the features present in the image. The simplest feature that maximally activated the cell was determined as the critical feature. The response to the critical feature was then compared with responses of the same cell to a routine set of 32 simple stimuli, which included white and black bars of four different orientations and squares or spots of four different colors. 3. Cells that responded maximally to particular complex object features were found in posterior IT and V4 as well as in anterior IT. The cells in posterior IT and V4 were, however, different from the cells in anterior IT in that many of them responded to some extent to some simple features, that the size of the receptive field was small, and that they intermingled in single penetrations with cells that responded maximally to some simple features. The complex critical features in posterior IT and V4 varied; they consisted of complex shapes, combinations of a shape and texture, and combinations of a shape and color. 4. We suggest that local neuronal networks in V4 and posterior IT play an essential role in the formation of selective responses to complex object features."
            },
            "slug": "Neuronal-selectivities-to-complex-object-features-Kobatake-Tanaka",
            "title": {
                "fragments": [],
                "text": "Neuronal selectivities to complex object features in the ventral visual pathway of the macaque cerebral cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is suggested that local neuronal networks in V4 and posterior IT play an essential role in the formation of selective responses to complex object features."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of neurophysiology"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153591291"
                        ],
                        "name": "M. Ito",
                        "slug": "M.-Ito",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Ito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "81815112"
                        ],
                        "name": "H. Tamura",
                        "slug": "H.-Tamura",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Tamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Tamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40190254"
                        ],
                        "name": "I. Fujita",
                        "slug": "I.-Fujita",
                        "structuredName": {
                            "firstName": "Ichiro",
                            "lastName": "Fujita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Fujita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157875742"
                        ],
                        "name": "K. Tanaka",
                        "slug": "K.-Tanaka",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tanaka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 77
                            }
                        ],
                        "text": "This is demonstrated in the experiments in Kobatake and Tanaka (1994) and in Ito et al. (1995), where successive simplifications of the selective stimuli and various deformations or degradations still evoke a strong response."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10374964,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "5dd13b7295d875c7bf0fc4e7f1714a1f2e98a2b2",
            "isKey": false,
            "numCitedBy": 470,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Object vision is largely invariant to changes of retinal images of objects in size and position. To reveal neuronal mechanisms of this invariance, we recorded activities from single cells in the anterior part of the inferotemporal cortex (anterior IT), determined the critical features for the activation of individual cells, and examined the effects of changes in stimulus size and position on the responses. 2. Twenty-one percent of the anterior IT cells studied here responded to ranges of size > 4 octaves, whereas 43% responded to size ranges < 2 octaves. The optimal stimulus size, measured by the distance between the outer edges along the longest axis of the stimulus, ranged from 1.7 to 30 degrees. 3. The selectivity for shape was mostly preserved over the entire range of effective size and over the receptive field, whereas some subtle but statistically significant changes were observed in one half of the cells studied here. 4. The size-specific responses observed in 43% of the cells are consistent with recent psychophysical data that suggest that images of objects are stored in a size-specific manner in the long-term memory. Both size-dependent and -independent processing of images may occur in anterior IT."
            },
            "slug": "Size-and-position-invariance-of-neuronal-responses-Ito-Tamura",
            "title": {
                "fragments": [],
                "text": "Size and position invariance of neuronal responses in monkey inferotemporal cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The size-specific responses observed in 43% of the cells are consistent with recent psychophysical data that suggest that images of objects are stored in a size- specific manner in the long-term memory, and both size-dependent and -independent processing of images may occur in anterior IT."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of neurophysiology"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334226"
                        ],
                        "name": "D. Hubel",
                        "slug": "D.-Hubel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hubel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hubel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2629471"
                        ],
                        "name": "T. Wiesel",
                        "slug": "T.-Wiesel",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Wiesel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wiesel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 172
                            }
                        ],
                        "text": "This is partly motivated by the widespread assumption that local processing carried out in V1 involves the detection, and possibly organization, of oriented edge segments (Hubel & Wiesel, 1977; Hubel, 1988)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This is partly motivated by the widespread assumption that local processing carried out in V1 involves the detection, and possibly organization, of oriented edge segments ( Hubel & Wiesel, 1977;  Hubel, 1988)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 36565707,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "362e5e735cd4dc3b291df916b34511bb2a9286a8",
            "isKey": false,
            "numCitedBy": 2196,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "Of the many possible functions of the macaque monkey primary visual cortex (striate cortex, area 17) two are now fairly well understood. First, the incoming information from the lateral geniculate bodies is rearranged so that most cells in the striate cortex respond to specifically oriented line segments, and, second, information originating from the two eyes converges upon single cells. The rearrangement and convergence do not take place immediately, however: in layer IVc, where the bulk of the afferents terminate, virtually all cells have fields with circular symmetry and are strictly monocular, driven from the left eye or from the right, but not both; at subsequent stages, in layers above and below IVc, most cells show orientation specificity, and about half are binocular. In a binocular cell the receptive fields in the two eyes are on corresponding regions in the two retinas and are identical in structure, but one eye is usually more effective than the other in influencing the cell; all shades of ocular dominance are seen. These two functions are strongly reflected in the architecture of the cortex, in that cells with common physiological properties are grouped together in vertically organized systems of columns. In an ocular dominance column all cells respond preferentially to the same eye. By four independent anatomical methods it has been shown that these columns have the form of vertically disposed alternating left-eye and right-eye slabs, which in horizontal section form alternating stripes about 400 \u03bcm thick, with occasional bifurcations and blind endings. Cells of like orientation specificity are known from physiological recordings to be similarly grouped in much narrower vertical sheeet-like aggregations, stacked in orderly sequences so that on traversing the cortex tangentially one normally encounters a succession of small shifts in orientation, clockwise or counterclockwise; a 1 mm traverse is usually accompanied by one or several full rotations through 180\u00b0, broken at times by reversals in direction of rotation and occasionally by large abrupt shifts. A full complement of columns, of either type, left-plus-right eye or a complete 180\u00b0 sequence, is termed a hypercolumn. Columns (and hence hypercolumns) have roughly the same width throughout the binocular part of the cortex. The two independent systems of hypercolumns are engrafted upon the well known topographic representation of the visual field. The receptive fields mapped in a vertical penetration through cortex show a scatter in position roughly equal to the average size of the fields themselves, and the area thus covered, the aggregate receptive field, increases with distance from the fovea. A parallel increase is seen in reciprocal magnification (the number of degrees of visual field corresponding to 1 mm of cortex). Over most or all of the striate cortex a movement of 1-2 mm, traversing several hypercolumns, is accompanied by a movement through the visual field about equal in size to the local aggregate receptive field. Thus any 1-2 mm block of cortex contains roughly the machinery needed to subserve an aggregate receptive field. In the cortex the fall-off in detail with which the visual field is analysed, as one moves out from the foveal area, is accompanied not by a reduction in thickness of layers, as is found in the retina, but by a reduction in the area of cortex (and hence the number of columnar units) devoted to a given amount of visual field: unlike the retina, the striate cortex is virtually uniform morphologically but varies in magnification. In most respects the above description fits the newborn monkey just as well as the adult, suggesting that area 17 is largely genetically programmed. The ocular dominance columns, however, are not fully developed at birth, since the geniculate terminals belonging to one eye occupy layer IVc throughout its length, segregating out into separate columns only after about the first 6 weeks, whether or not the animal has visual experience. If one eye is sutured closed during this early period the columns belonging to that eye become shrunken and their companions correspondingly expanded. This would seem to be at least in part the result of interference with normal maturation, though sprouting and retraction of axon terminals are not excluded."
            },
            "slug": "Ferrier-lecture-Functional-architecture-of-macaque-Hubel-Wiesel",
            "title": {
                "fragments": [],
                "text": "Ferrier lecture - Functional architecture of macaque monkey visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In most respects the above description fits the newborn monkey just as well as the adult, suggesting that area 17 is largely genetically programmed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Royal Society of London. Series B. Biological Sciences"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34180590"
                        ],
                        "name": "S. Thorpe",
                        "slug": "S.-Thorpe",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Thorpe",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thorpe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50780533"
                        ],
                        "name": "D. Fize",
                        "slug": "D.-Fize",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Fize",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fize"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3677347"
                        ],
                        "name": "Catherine Marlot",
                        "slug": "Catherine-Marlot",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Marlot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine Marlot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "selection (or selective attention) and sequential processing\u2014is widely accepted in the literature (see  Thorpe, Fize, & Marlot, 1996;  Desimone, Miller, Chelazzi, & Lueschow, 1995; Lueschow, Miller & Desimone, 1994; Van Essen & Deyoe, 1995; Ullman, 1996)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4303570,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "addbd39fc775c12aa453ebd0cb77ea1bd3389572",
            "isKey": false,
            "numCitedBy": 2537,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speed-of-processing-in-the-human-visual-system-Thorpe-Fize",
            "title": {
                "fragments": [],
                "text": "Speed of processing in the human visual system"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1993085645"
                        ],
                        "name": "P. Schiller",
                        "slug": "P.-Schiller",
                        "structuredName": {
                            "firstName": "P",
                            "lastName": "Schiller",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Schiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33760699"
                        ],
                        "name": "B. Finlay",
                        "slug": "B.-Finlay",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Finlay",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Finlay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6849044"
                        ],
                        "name": "S. Volman",
                        "slug": "S.-Volman",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Volman",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Volman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15065592,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0be7a5abe126b799d1820b321326f92ba42c65a3",
            "isKey": false,
            "numCitedBy": 519,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "1. The properties of single cells in striate cortex of the rhesus monkey, representing the visual field 2 degrees -5 degrees from the fovea, were examined quantitatively with stationary and moving stimuli. Three distinct classes of cells were identified: S type, CX type, and T type. 2. S-type cells were defined as those oriented cells which to the optimal direction of movement in their receptive fields exhibited one or more spatially separate subfields within each of which a response was obtained to either a light or dark edge, but not to both. Several different types of S-cells were distinguished: a) S1-type cells for which moving edges revealed a single excitatory area within which a response was elicited by either a light or a dark edge but not by both. Most of these cells were unidirectional. b) S2-type cells for which moving edges revealed two spatially separate response areas, one of which was excited by a light edge and the other by a dark edge. Both regions responded to the same direction of movement. c) S3-type cells which had two response areas, one of which was excited by a stimulus moving in one direction (at right angles to the axis of orientation) and the other, of opposite contrast, which responded in the opposite direction, d) S4-type cells which to one direction of movement showed two spatially separate regions sensitive to a light and dark edge and which in the other direction of movement had only one responsive area (either light or dark). e) Cells which had multiple spatially separate subfields (S5-7 types). 3. CX-type cells were defined as those oriented cells which in their receptive fields exhibited no spatial separation for light- and dark-edge responses; they discharged to both edges in the same direction of movement and in the same spatial area. Flashing stimuli elicited both on and off responses throughout the receptive field. CX-type cells were predominantly of two types: those which were selective for direction of stimulus movement and those which were not. 4. A third class of cells (T-type) were those which were excited by only one sign of contrast change and responded in a sustained fashion even when there was no contour within the receptive field. These cells were poorly or not at all oriented; some of them were selective to wavelength. 5. Quantitative comparisons showed the following differences between S-type and CX-type cells: a) S-type cells had smaller receptive fields than CX-type cells but the populations over-lapped considerably. Receptive-field size was smallest in layer 4c. In all other layers S-type cells had the same size fields. CX-type cells, by contrast, tended to have larger fields in layer 5-6 than 2-3. b) The spatial separation between light and dark response areas was the best criterion for distinguishing S-type and CX-type cells. The distribution of this measure disclosed two populations of cells with relatively limited overlap. c) In layers 2 and 3, both S-type and CX-type cells had low spontaneous activity..."
            },
            "slug": "Quantitative-studies-of-single-cell-properties-in-Schiller-Finlay",
            "title": {
                "fragments": [],
                "text": "Quantitative studies of single-cell properties in monkey striate cortex. I. Spatiotemporal organization of receptive fields."
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "The properties of single cells in striate cortex of the rhesus monkey, representing the visual field 2 degrees -5 degrees from the fovea, were examined quantitatively with stationary and moving stimuli and showed differences between S-type and CX-type cells."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of neurophysiology"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "Finally, there are shared properties with artificial neural networks (Rowley, Baluja, & Takeo, 1998; Sung & Poggio, 1998), for example, the emphasis on learning and the absence of formal models."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": false,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156786341"
                        ],
                        "name": "tephen E. Palmer",
                        "slug": "tephen-E.-Palmer",
                        "structuredName": {
                            "firstName": "tephen",
                            "lastName": "Palmer",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "tephen E. Palmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 67
                            }
                        ],
                        "text": "Perhaps context plays a significant role (see Biederman, 1981, and Palmer, 1975)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Perhaps context plays a significant role (see Biederman, 1981, and  Palmer, 1975 )."
                    },
                    "intents": []
                }
            ],
            "corpusId": 20646799,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "cc9057f0fc18874314a3c1049d93a6749dc36f73",
            "isKey": false,
            "numCitedBy": 631,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This experiment demonstrates the influence of the prior presentation of visual scenes on the identification of briefly presented drawings of real-world objects. Different pairings of objects and scenes were used to produce three main contextual conditions: appropriate, inappropriate, and no context. Correct responses and confusions with visually similar objects depended strongly on both the contextual condition and the particular target object presented. The probability of being correct was highest in the appropriate context condition and lowest in the inappropriate context condition. Confidence ratings of responses were a function of the perceptual similarity between the stimulus object and the named object; they were not strongly affected by contextual conditions. Morton\u2019s (1970) \u201clogogen\u201d model provided a good quantitative fit to the response probability data."
            },
            "slug": "The-effects-of-contextual-scenes-on-the-of-objects-Palmer",
            "title": {
                "fragments": [],
                "text": "The effects of contextual scenes on the identification of objects"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This experiment demonstrates the influence of the prior presentation of visual scenes on the identification of briefly presented drawings of real-world objects using Morton\u2019s (1970) \u201clogogen\u201d model."
            },
            "venue": {
                "fragments": [],
                "text": "Memory & cognition"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055501916"
                        ],
                        "name": "Thomas Maurer",
                        "slug": "Thomas-Maurer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Maurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Maurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17312452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce5f297cb037b2101da175344e2597a52c0e5908",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate a system capable of tracking in real world image sequences, landmarks such as eyes, mouth, or chin on a face. In the standard version, knowledge previously collected about faces is used for finding the landmarks in the first frame. In a second version, the system is able to track the face without any prior knowledge about faces and is thus applicable to other object classes. By using Gabor filters as visual features, and by both avoiding limiting assumptions and many parameters our tracking tool is simple and easy to use. As a first application the tracking results are used to estimate the pose of a face."
            },
            "slug": "Tracking-and-learning-graphs-and-pose-on-image-of-Maurer-Malsburg",
            "title": {
                "fragments": [],
                "text": "Tracking and learning graphs and pose on image sequences of faces"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A system capable of tracking in real world image sequences, landmarks such as eyes, mouth, or chin on a face, and is applicable to other object classes by using Gabor filters as visual features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3096453"
                        ],
                        "name": "Y. Lamdan",
                        "slug": "Y.-Lamdan",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Lamdan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lamdan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035149"
                        ],
                        "name": "J. Schwartz",
                        "slug": "J.-Schwartz",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36500949,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f314b8066e4b8248172e0b9c1e73a31588e73f6",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Novel techniques are described for model-based recognition of 3-D objects from unknown viewpoints using single-gray-scale images. The objects in the scene may be overlapping and partially occluded. Efficient matching algorithms, which assume affine approximation to the perspective viewing transformation, are proposed. The study is currently restricted to flat rigid 3-D objects. Point, line and curve matching algorithms are presented. The study especially emphasizes the curve matching problem. Experimental results are included.<<ETX>>"
            },
            "slug": "Object-recognition-by-affine-invariant-matching-Lamdan-Schwartz",
            "title": {
                "fragments": [],
                "text": "Object recognition by affine invariant matching"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "Novel techniques are described for model-based recognition of 3-D objects from unknown viewpoints using single-gray-scale images and efficient matching algorithms are proposed, which assume affine approximation to the perspective viewing transformation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 40
                            }
                        ],
                        "text": "The algorithm was tested on images from Rowley et al. (1998) (for example Figure 1), and images captured on the Sun Videocam (for example, Figure 6)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 73
                            }
                        ],
                        "text": "In hundreds of experiments using pictures obtained from the videocam and Rowley et al.\u2019s (1998) database, the false-negative rate of the visual selection stage is close to zero."
                    },
                    "intents": []
                }
            ],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3885c13438132b516e5ffc8b640d20b4e41a7a4",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural network-based face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5976171"
                        ],
                        "name": "L. Cosmides",
                        "slug": "L.-Cosmides",
                        "structuredName": {
                            "firstName": "Leda",
                            "lastName": "Cosmides",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cosmides"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 272
                            }
                        ],
                        "text": "However, edge detectors do not directly determine smooth, connected curves which delineate well-defined regions and it is now clear to many researchers in both computer and biological vision that purely edge-based segmentation is not feasible in most real scenes (von der Heydt (1995), Ullman (1996)), at least not without a tentative interpretation of the visual input."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 15
                            }
                        ],
                        "text": "And in von der Heydt (1995) there is a review of the neurophysiological evidence for V2 cells responsive to \"illusory\" or \"anomalous\" contours; even in VI according to Grosof, Shapley & Hawken (1993). These cells respond equally well to an oriented line and to an occluded or interrupted line."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 15
                            }
                        ],
                        "text": "And in von der Heydt (1995) there is a review of the neurophysiological evidence for V2 cells responsive to \u201cillusory\u201d or \u201canomalous\u201d contours and even in V1 according to Grosof, Shapley, & Hawken, (1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 15
                            }
                        ],
                        "text": "And in von der Heydt (1995) there is a review of the neurophysiological evidence for V2 cells responsive to \"illusory\" or \"anomalous\" contours; even in VI according to Grosof, Shapley & Hawken (1993)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 198
                            }
                        ],
                        "text": "\u2026that delineate well-defined regions, and it is now clear to many researchers in both computer and biological vision that purely edge-based segmentation is not feasible in most real scenes (von der Heydt, 1995; Ullman, 1996), at least not without a tentative interpretation of the visual input."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12863361,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "a6270876c3a3f22c0fdc700ab422fdd2bb36f43e",
            "isKey": true,
            "numCitedBy": 511,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "The human brain is a biological system produced by the evolutionary process, and so cognitive neuroscience is itself a branch of modem evolutionary biology. Accordingly, cognitive neuroscientists can benefit by acquiring a professional knowledge of the recent technical advances made in evolutionary biology and by applying them to their research. Useful tools include the biologically rigorous concept of function that is appropriate to neural and cognitive systems; a growing list of the specialized functions the human brain evolved to perform; and criteria for distinguishing the narrowly functional aspects of the neural and cognitive architecture that are responsible for the brain's organization from the much larger set of properties that are by-products or noise. With such tools, researchers can construct biologically meaningful experimental tasks and stimuli. These are more likely to activate the large array of functionally dedicated mechanisms that constitute the core of human brain function, but which are at present largely unstudied. Nothing in b i o l o ~ makes sense except in the light of evolution. T. Dobzhamky It is tiu theory which decides what we can observe. -Einstein Seeing with new eyes: Toward an evolutionarily informed cognitive neuroscience The task of cognitive neuroscience is to map the information-processing structure of the human mind, and to discover how this computational organization is implemented in the physical organization of the brain. The central impediment to progress is obvious: The human brain is, by many orders of magnitude, the most complex system humans have yet investigated. Purely as a physical system, the vast intricacy of chemical and electrical interactions among roughly one hundred billion neurons defeats any straightforward attempt to build a comprehensive model, as one might attempt to do with particle collisions, geological processes, protein folding, or host-parasite interactions. At present, the underlying logic of the system seems lost among the torrent of observations that have been accumulated to date, and obscured by the inherent complexity of the system. Historically, however, well-established theories from one discipline have functioned as organs of perception for others. They allow new relationships to be observed and make visible elegant systems of organization that had previously eluded detection. I t seems worth exploring whether the same could be true for the brain sciences. In fact, the brain is more than a physical system: I t is both a computational system and an evolved biological system. Although cognitive neuroscience began with the recognition that studying the brain as a computational system would offer important new insights, the field has so far failed to take equal advantage of the fact that the brain is an evolved system as well. Indeed, the brain is a computational system that was organized and specifically designed to solve a narrowly identifiable set of biological information-processing problems. For this reason, evolutionary biology can supply a key missing element in the cognitive neuroscience research program: a list of the native information-processing functions that the human brain was built to execute. Our computational architecture evolved its distinctive sets of structured information-processing relationships JOHN TOOBY Department of Anthropoiogy, and LEDA COSMIDES Department of Psychology, Center for Evoludevices Or perform this particular tartionary Psychology, University of California, Santa Barbara, geted set of adaptive functions. In turn, our neural Calif. architecture evolved its distinctive physical configuTOOBY AND COSMIDES: MAPPING THE EVOLVED FUNCTIONAL ORGANIZATION 1185 ration because it brought these targeted sets of functional information-processing relationships into existence. By providing the functional engineering specifications to which human brains were built to conform, evolutionary biology can help researchers to isolate, identify, activate, and map the important functional aspects of the cognitive architecture, aspects that would otherwise be lost among the myriad irrelevant phenomena in which they are embedded. The resulting maps of the computational structure of each device will then allow researchers to isolate, identify and map the functional aspects of the neural architecture. The biologically implausible view that the brain is a generalpurpose information-processing system provides little guidance for research in cognitive neuroscience. In contrast, an evolutionary approach allows cognitive neuroscientists to apply a sophisticated body of new knowledge to their problems. In short, because theories and principled systems of knowledge can function as organs of perception, the incorporation of a modern evolutionary framework into cognitive neuroscience may allow the community to detect ordered relationships in phenomena that otherwise seem too complex to be understood. Over the last 30 years, evolutionary biology has made a number of important advances that have not yet diffused into allied hisciplines such as the cognitive and neural sciences. These advances constitute a potent set of new principles relevant to dissecting and understanding the phenomena studied by cognitive neuroscientists (Tooby and Cosmides, 1992). Central to these advances is the modem technical theory of evolution. This consists of the logically derivable set of causal principles that necessarily govern the dynamics of reproducing systems. These principles account for the properties that reproducing systems cumulatively acquire over successive generations. The explicit identification of this core logic has allowed the biological community to develop an increasingly comprehensive set of principles about what kinds of features can and do become incorporated into the designs of reproducing systems down their chains of descent, and what kinds of features do not (Hamilton, 1964, 1972; Maynard Smith, 1964, 1982; Williams, 1966; Dawkins, 1976, 1982, 1986; Cosmides and Tooby 1981; Tooby, 1982). This set of principles has been tested, validated, and enriched through its integration with functional and comparative anatomy, biogeography, genetics, immunology, embryology, behavioral ecology, and a number of other disciplines. Just as the fields of electrical and mechanical engineering summarize our knowledge of principles that govern the design of human-built machines, the field of evolutionary biology summarizes our knowledge of the engineering principles that govern the design of organisms, which can be thought of as machines built by the evolutionary process (for overviews, see Dawkins, 1976, 1982, 1986; Daly and Wilson, 1984; Krebs and Davies, 1987). Modern evolutionary biology constitutes, in effect, a foundational organism design theory, whose principles can be used to fit together research findings into'koherent models of specific cognitive and neural mechanisms. First principles: Reproduction, feedback, and the antientropic construction of organic design Within an evolutionary framework, an organism is describable as a self-reproducing machine, and the defining property of life is the presence in a system of devices or organization that cause the system to construct new and similarly reproducing systems. From this defining property of self-reproduction, the entire deductive structure of modem Darwinism logically follows (Dawkins, 1976; Williams, 1985; Tooby and Cosmides, 1990b). Because the replication of the design of the parental machine is not always error-free, randomly modified designs (i.e., mutants). are introduced into populations of reproducers. Because such machines are highly organized so that they cause the otherwise improbable outcome of constructing offspring machines, the great majority of random modifications will interfere with the complex sequence of actions necessary for self-reproduction. Consequently, such modified designs will tend to remove themselves from the population-a case of negative feedback. However, a small residual subset of design modifications will, by chance, happen to constitute improvements in the design's machinery for causing its own reproduction. Such improved designs (by definition) cause their own frequency to increase in the population-a case of positive feedback. This increase continues until (usually) such modified designs outreproduce and thereby replace all alternative designs in the population, leading to a new species-standard design. After such an event, the population of reproducing machines is different from the ancestral population: The populationor species-standard design has taken a step \"uphill\" toward a greater degree of functional organization for reproduction. This spontaneous feedback process-natural selection-is the only known process by which functional organization emerges naturally in the world, without intelligent design and intervention. Hence, all naturally occurring functional organization in organisms must be ascribed to its operation and must be consistent with its principles. Over the long run, down chains of descent, this feedback cycle pushes the design of a species stepwise \"uphill\" toward arrangements of elements that are increasingly improbably well organized to cause their own reproduction in the environment the species evolved in. Because the reproductive fates of the inherited traits that coexist in the same organism are linked together, traits will be selected to enhance each other's functionality (but see Cosmides and Tooby, 1981; Tooby and Cosmides, 1990b, for the relevant genetic analysis and qualifications). Consequently, accumulating design features will tend to fit themselves together sequentially into increasingly functionally elaborated machines for reproduction, composed of constituent mechanisms-called adaptations-that solve problems whose solutions either are necessary for reproduction or increase its likelihood (Darwin, 1859; Williams, 1966, 1985;"
            },
            "slug": "From-:-The-Cognitive-Neurosciences-Cosmides",
            "title": {
                "fragments": [],
                "text": "From : The Cognitive Neurosciences"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Cognitive neuroscience is a computational system that was organized and specifically designed to solve a narrowly identifiable set of biological information-processing problems, and an evolutionary approach allows cognitive neuroscientists to apply a sophisticated body of new knowledge to their problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11079833"
                        ],
                        "name": "S. Sutherland",
                        "slug": "S.-Sutherland",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Sutherland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sutherland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 280
                            }
                        ],
                        "text": "\u2026model has three clearly distinct levels of computation:\n\u2022 Level I, edge fragments \u2022 Level II, local groupings of fragments \u2022 Level III, global arrangements of local groupings\nLevel I roughly corresponds to the basic type of processing believed to be performed in certain layers of V1 (Hubel, 1988)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 194
                            }
                        ],
                        "text": "This is partly motivated by the widespread assumption that local processing carried out in V1 involves the detection, and possibly organization, of oriented edge segments (Hubel & Wiesel, 1977; Hubel, 1988)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 35236366,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "ef46c51a9f9db65311accbfa5405b1d0dc280f93",
            "isKey": false,
            "numCitedBy": 444,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Vision and Visual Dysfunction.General editor: John Cronly-Dillon. Macmillan: 1991. 17 volumes. Approximately 5,000 pages. \u00a31,250, $2,295."
            },
            "slug": "Eye,-brain-and-vision-Sutherland",
            "title": {
                "fragments": [],
                "text": "Eye, brain and vision"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060896"
                        ],
                        "name": "P. Winston",
                        "slug": "P.-Winston",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Winston",
                            "middleNames": [
                                "Henry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Winston"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 253
                            }
                        ],
                        "text": "In addition, we argue that visual selection, if not final classification, can be accomplished with object representations that are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on parts (Winston, 1970; Biederman, 1985) and pictorial representations (Ullman, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 221
                            }
                        ],
                        "text": "\u2026selection, if not final classification, can be accomplished with object representations that are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on parts (Winston, 1970; Biederman, 1985) and pictorial representations (Ullman, 1996)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 106617047,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "a7eb50210a468d0878666e8f82fb55f2b179f802",
            "isKey": false,
            "numCitedBy": 1207,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Massachusetts Institute of Technology. Dept. of Electrical Engineering. Thesis. 1970. Ph.D."
            },
            "slug": "Learning-Structural-Descriptions-From-Examples-Winston",
            "title": {
                "fragments": [],
                "text": "Learning Structural Descriptions From Examples"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 46
                            }
                        ],
                        "text": "Perhaps context plays a significant role; see Biederman (1981) and Palmer (1975)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 394,
                                "start": 273
                            }
                        ],
                        "text": "In addition, we argue that visual selection, if not final classification, can be accomplished with object representations which are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on \"parts\" (Winston (1970), Biederman (1985)) and \"pictorial representations\" (Ullman (1996)). The \"face graphs\" in Maurer & von der Malsburg (1996) are closer in spirit, although the \"jets\" (outputs from multiple Gabor filters) at the graph vertices are more discriminating than our local groupings; also, the representation there is much denser, perhaps because the application, namely face recognition, is more challenging."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 273
                            }
                        ],
                        "text": "In addition, we argue that visual selection, if not final classification, can be accomplished with object representations which are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on \"parts\" (Winston (1970), Biederman (1985)) and \"pictorial representations\" (Ullman (1996))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 827,
                                "start": 273
                            }
                        ],
                        "text": "In addition, we argue that visual selection, if not final classification, can be accomplished with object representations which are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on \"parts\" (Winston (1970), Biederman (1985)) and \"pictorial representations\" (Ullman (1996)). The \"face graphs\" in Maurer & von der Malsburg (1996) are closer in spirit, although the \"jets\" (outputs from multiple Gabor filters) at the graph vertices are more discriminating than our local groupings; also, the representation there is much denser, perhaps because the application, namely face recognition, is more challenging. Our representation of pose space (a three point \"basis\" or local coordinate system) is the same as in geometric hashing (Lamdan, Schwartz & Wolfson (1988)), wherein the local features are affine invariants (e."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1665,
                                "start": 273
                            }
                        ],
                        "text": "In addition, we argue that visual selection, if not final classification, can be accomplished with object representations which are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on \"parts\" (Winston (1970), Biederman (1985)) and \"pictorial representations\" (Ullman (1996)). The \"face graphs\" in Maurer & von der Malsburg (1996) are closer in spirit, although the \"jets\" (outputs from multiple Gabor filters) at the graph vertices are more discriminating than our local groupings; also, the representation there is much denser, perhaps because the application, namely face recognition, is more challenging. Our representation of pose space (a three point \"basis\" or local coordinate system) is the same as in geometric hashing (Lamdan, Schwartz & Wolfson (1988)), wherein the local features are affine invariants (e.g., sharp inflections and concavities) and objects are represented by hash tables indexed by feature locations. But again our framework is inherently nondeterministic: Features may or may not be visible on the objects, regardless of occlusion or other degrading factors, and are characterized by probability distributions. In addition, the global arrangements are more than a list; it is the geometrical constraints which render them \"rare\" in the background population. The statistical framework in Rojer & Schwartz (1992) is similar, although there is no systematic exploration of features. Also pose indexing based on global information is more efficient than the Hough transform. Finally, there are shared properties with artificial neural networks (Rowley, Baluja h Takeo (1998), Sung & Poggio (1998)), for example the emphasis on learning and the absence of formal models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 46
                            }
                        ],
                        "text": "Perhaps context plays a significant role (see Biederman, 1981, and Palmer, 1975)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1405,
                                "start": 273
                            }
                        ],
                        "text": "In addition, we argue that visual selection, if not final classification, can be accomplished with object representations which are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on \"parts\" (Winston (1970), Biederman (1985)) and \"pictorial representations\" (Ullman (1996)). The \"face graphs\" in Maurer & von der Malsburg (1996) are closer in spirit, although the \"jets\" (outputs from multiple Gabor filters) at the graph vertices are more discriminating than our local groupings; also, the representation there is much denser, perhaps because the application, namely face recognition, is more challenging. Our representation of pose space (a three point \"basis\" or local coordinate system) is the same as in geometric hashing (Lamdan, Schwartz & Wolfson (1988)), wherein the local features are affine invariants (e.g., sharp inflections and concavities) and objects are represented by hash tables indexed by feature locations. But again our framework is inherently nondeterministic: Features may or may not be visible on the objects, regardless of occlusion or other degrading factors, and are characterized by probability distributions. In addition, the global arrangements are more than a list; it is the geometrical constraints which render them \"rare\" in the background population. The statistical framework in Rojer & Schwartz (1992) is similar, although there is no systematic exploration of features."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the semantic of a glance at a scene, in M"
            },
            "venue": {
                "fragments": [],
                "text": "Kubovy k J. R"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 282
                            }
                        ],
                        "text": "\u2026c\u00a9 1999 Massachusetts Institute of Technology\nselection (or selective attention) and sequential processing\u2014is widely accepted in the literature (see Thorpe, Fize, & Marlot, 1996; Desimone, Miller, Chelazzi, & Lueschow, 1995; Lueschow, Miller & Desimone, 1994; Van Essen & Deyoe, 1995; Ullman, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 330,
                                "start": 316
                            }
                        ],
                        "text": "In addition, we argue that visual selection, if not final classification, can be accomplished with object representations that are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on parts (Winston, 1970; Biederman, 1985) and pictorial representations (Ullman, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 284
                            }
                        ],
                        "text": "\u2026selection, if not final classification, can be accomplished with object representations that are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on parts (Winston, 1970; Biederman, 1985) and pictorial representations (Ullman, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 261
                            }
                        ],
                        "text": "For example, although faces can be detected at low resolution, it might be very difficult to identify say, a left eye based on only the intensity data in its immediate vicinity, that is, outside the context of the entire face (see the example and discussion in Ullman, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 263
                            }
                        ],
                        "text": "However, edge detectors do not directly determine smooth, connected curves that delineate well-defined regions, and it is now clear to many researchers in both computer and biological vision that purely edge-based segmentation is not feasible in most real scenes (von der Heydt, 1995; Ullman, 1996), at least not without a tentative interpretation of the visual input."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 211
                            }
                        ],
                        "text": "\u2026that delineate well-defined regions, and it is now clear to many researchers in both computer and biological vision that purely edge-based segmentation is not feasible in most real scenes (von der Heydt, 1995; Ullman, 1996), at least not without a tentative interpretation of the visual input."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 98
                            }
                        ],
                        "text": "selection (or selective attention) and sequential processing\u2014is widely accepted in the literature (see Thorpe, Fize, & Marlot, 1996; Desimone, Miller, Chelazzi, & Lueschow, 1995; Lueschow, Miller & Desimone, 1994; Van Essen & Deyoe, 1995; Ullman, 1996)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "High-Level Vision"
            },
            "venue": {
                "fragments": [],
                "text": "High-Level Vision"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144375727"
                        ],
                        "name": "R. Desimone",
                        "slug": "R.-Desimone",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Desimone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Desimone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171934932"
                        ],
                        "name": "E. Miller",
                        "slug": "E.-Miller",
                        "structuredName": {
                            "firstName": "Earl",
                            "lastName": "Miller",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1976956375"
                        ],
                        "name": "L. Chelazzi",
                        "slug": "L.-Chelazzi",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Chelazzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chelazzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2879893"
                        ],
                        "name": "A. Lueschow",
                        "slug": "A.-Lueschow",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lueschow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lueschow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 140496592,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "e4a54ccd7554dcacf1672614963d621acd9dc7b5",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multiple-memory-systems-in-the-visual-cortex.-Desimone-Miller",
            "title": {
                "fragments": [],
                "text": "Multiple memory systems in the visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880368"
                        ],
                        "name": "D. V. Essen",
                        "slug": "D.-V.-Essen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Essen",
                            "middleNames": [
                                "C.",
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. V. Essen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3177102"
                        ],
                        "name": "E. DeYoe",
                        "slug": "E.-DeYoe",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "DeYoe",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. DeYoe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 261
                            }
                        ],
                        "text": "\u2026c\u00a9 1999 Massachusetts Institute of Technology\nselection (or selective attention) and sequential processing\u2014is widely accepted in the literature (see Thorpe, Fize, & Marlot, 1996; Desimone, Miller, Chelazzi, & Lueschow, 1995; Lueschow, Miller & Desimone, 1994; Van Essen & Deyoe, 1995; Ullman, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 257
                            }
                        ],
                        "text": "In addition, we argue that visual selection, if not final classification, can be accomplished with object representations which are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on \"parts\" (Winston (1970), Biederman (1985)) and \"pictorial representations\" (Ullman (1996))."
                    },
                    "intents": []
                }
            ],
            "corpusId": 142428203,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "eb90a342cb18809f5e617b2670ee71e03dac5356",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Concurrent-processing-in-the-primate-visual-cortex.-Essen-DeYoe",
            "title": {
                "fragments": [],
                "text": "Concurrent processing in the primate visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiple memory systems in visual cortexThe Cognitive Neurosciences"
            },
            "venue": {
                "fragments": [],
                "text": "Multiple memory systems in visual cortexThe Cognitive Neurosciences"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient focusing and face detection , in H"
            },
            "venue": {
                "fragments": [],
                "text": "' Face Recognition : From Theory to Applications , NATO ASI Series F \\"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Form analysis in visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 190
                            }
                        ],
                        "text": "\u2026that delineate well-defined regions, and it is now clear to many researchers in both computer and biological vision that purely edge-based segmentation is not feasible in most real scenes (von der Heydt, 1995; Ullman, 1996), at least not without a tentative interpretation of the visual input."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 7
                            }
                        ],
                        "text": "And in von der Heydt (1995) there is a review of the neurophysiological evidence for V2 cells responsive to \u201cillusory\u201d or \u201canomalous\u201d contours and even in V1 according to Grosof, Shapley, & Hawken, (1993)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Form analysis in visual cortexThe Cognitive Neurosciences"
            },
            "venue": {
                "fragments": [],
                "text": "Form analysis in visual cortexThe Cognitive Neurosciences"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Quantitative studies of single-cell in monkey striate cortex. I. Spatiotemporal organization of receptive fields"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Neurophysiology,"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object recognition by aane invariant matching"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. on Computer Vision and Pattern Recognition"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 67
                            }
                        ],
                        "text": "Perhaps context plays a significant role (see Biederman, 1981, and Palmer, 1975)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The eeects of contextual scenes on the identiication of objects"
            },
            "venue": {
                "fragments": [],
                "text": "Memory and Cognition"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "Finally, there are shared properties with artificial neural networks (Rowley, Baluja, & Takeo, 1998; Sung & Poggio, 1998), for example, the emphasis on learning and the absence of formal models."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Example-based learning for view-based face detection"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. PAMI"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 29
                            }
                        ],
                        "text": "The statistical framework in Rojer and Schwartz (1992) is similar, although they do not suggest a systematic exploration of local features."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A quotient space hough transform for scpaevariant visual attention"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Vision and Image Processing"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Macaque v1 neurons can signal \\illusory"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 262
                            }
                        ],
                        "text": "Choosing Nedges = 3 and Npixels = 10 yields frequencies on the order of 50%, which leads to very low false-negative rates with only order Ntypes = 10 local features; these are the values used in the experiments reported in the following section as well as in in Amit et al. (1998)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 127
                            }
                        ],
                        "text": "There are four edge types, corresponding roughly to vertical and horizontal orientation and two polarities; the details are in Amit, Geman, and Jedynak (1998) and are not important for the discussion here, except to note that the orientation is not very precise."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "EEcient focusing and face detectionFace Recognition: From Theory to Applications, NATO ASI Series F"
            },
            "venue": {
                "fragments": [],
                "text": "EEcient focusing and face detectionFace Recognition: From Theory to Applications, NATO ASI Series F"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Columns for visual features"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 280
                            }
                        ],
                        "text": "\u2026model has three clearly distinct levels of computation:\n\u2022 Level I, edge fragments \u2022 Level II, local groupings of fragments \u2022 Level III, global arrangements of local groupings\nLevel I roughly corresponds to the basic type of processing believed to be performed in certain layers of V1 (Hubel, 1988)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 194
                            }
                        ],
                        "text": "This is partly motivated by the widespread assumption that local processing carried out in V1 involves the detection, and possibly organization, of oriented edge segments (Hubel & Wiesel, 1977; Hubel, 1988)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 109
                            }
                        ],
                        "text": "Level I roughly corresponds to the basic type of processing believed to be performed in certain layers of V1 (Hubel, 1988)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eye, brain, and vision. New York: Scientific American Library"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 29
                            }
                        ],
                        "text": "The statistical framework in Rojer and Schwartz (1992) is similar, although they do not suggest a systematic exploration of local features."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A quotient space Hough transform for space-variant visual attention"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 172
                            }
                        ],
                        "text": "This is partly motivated by the widespread assumption that local processing carried out in V1 involves the detection, and possibly organization, of oriented edge segments (Hubel & Wiesel, 1977; Hubel, 1988)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Terrier lecture: Functional architecture"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 46
                            }
                        ],
                        "text": "Perhaps context plays a significant role (see Biederman, 1981, and Palmer, 1975)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 386,
                                "start": 269
                            }
                        ],
                        "text": "In addition, we argue that visual selection, if not final classification, can be accomplished with object representations that are very coarse and sparse compared with most others, for example 3D geometric models, structural descriptions based on parts (Winston, 1970; Biederman, 1985) and pictorial representations (Ullman, 1996). The face graphs in Maurer and von der Malsburg (1996) are closer in spirit, although the jets (outputs from multiple Gabor filters) at the graph vertices are more discriminating than our local groupings; also, the representation there is much denser, perhaps because the application, face recognition, is more challenging."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the semantic of a glance at a scene"
            },
            "venue": {
                "fragments": [],
                "text": "On the semantic of a glance at a scene"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 15
                            }
                        ],
                        "text": "And in von der Heydt (1995) there is a review of the neurophysiological evidence for V2 cells responsive to \u201cillusory\u201d or \u201canomalous\u201d contours and even in V1 according to Grosof, Shapley, & Hawken, (1993). These cells respond equally well to an oriented line and an occluded or interrupted line."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 198
                            }
                        ],
                        "text": "\u2026that delineate well-defined regions, and it is now clear to many researchers in both computer and biological vision that purely edge-based segmentation is not feasible in most real scenes (von der Heydt, 1995; Ullman, 1996), at least not without a tentative interpretation of the visual input."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 15
                            }
                        ],
                        "text": "And in von der Heydt (1995) there is a review of the neurophysiological evidence for V2 cells responsive to \u201cillusory\u201d or \u201canomalous\u201d contours and even in V1 according to Grosof, Shapley, & Hawken, (1993)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Form analysis in visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Quantitative studies of singlecell in monkey striate cortex. i. spatiotemporal organization of receptive elds"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Neurophysiology"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 3
                            }
                        ],
                        "text": "In Amit (1998) we show\nhow a fixed architecture with a moderate number of arrays can accommodate any detection task with a central memory module storing the representations of the various objects."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A neural network architecture for visual selection ( Tech . Rep . No . 474 )"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Quantitative studies of singlecell in monkey striate cortex, i. spatiotemporal organization of receptive fields"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Neurophysiology"
            },
            "year": 1976
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 46,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Computational-Model-for-Visual-Selection-Amit-Geman/61b2d0383b186c4d634c5f51421cab67c16d90a1?sort=total-citations"
}