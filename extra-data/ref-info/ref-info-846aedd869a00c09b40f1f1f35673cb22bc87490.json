{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4337102"
                        ],
                        "name": "Julian Schrittwieser",
                        "slug": "Julian-Schrittwieser",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Schrittwieser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian Schrittwieser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460849"
                        ],
                        "name": "Ioannis Antonoglou",
                        "slug": "Ioannis-Antonoglou",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Antonoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Antonoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885349"
                        ],
                        "name": "Aja Huang",
                        "slug": "Aja-Huang",
                        "structuredName": {
                            "firstName": "Aja",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aja Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35099444"
                        ],
                        "name": "A. Guez",
                        "slug": "A.-Guez",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Guez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Guez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067208983"
                        ],
                        "name": "T. Hubert",
                        "slug": "T.-Hubert",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hubert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hubert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067596385"
                        ],
                        "name": "Lucas baker",
                        "slug": "Lucas-baker",
                        "structuredName": {
                            "firstName": "Lucas",
                            "lastName": "baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucas baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40227832"
                        ],
                        "name": "Matthew Lai",
                        "slug": "Matthew-Lai",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34848283"
                        ],
                        "name": "A. Bolton",
                        "slug": "A.-Bolton",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Bolton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bolton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275897"
                        ],
                        "name": "Yutian Chen",
                        "slug": "Yutian-Chen",
                        "structuredName": {
                            "firstName": "Yutian",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yutian Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059412590"
                        ],
                        "name": "Fan Hui",
                        "slug": "Fan-Hui",
                        "structuredName": {
                            "firstName": "Fan",
                            "lastName": "Hui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fan Hui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2175946"
                        ],
                        "name": "L. Sifre",
                        "slug": "L.-Sifre",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Sifre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sifre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47568983"
                        ],
                        "name": "George van den Driessche",
                        "slug": "George-van-den-Driessche",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Driessche",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George van den Driessche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686971"
                        ],
                        "name": "T. Graepel",
                        "slug": "T.-Graepel",
                        "structuredName": {
                            "firstName": "Thore",
                            "lastName": "Graepel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Graepel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48987704"
                        ],
                        "name": "D. Hassabis",
                        "slug": "D.-Hassabis",
                        "structuredName": {
                            "firstName": "Demis",
                            "lastName": "Hassabis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hassabis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "Moreover, the DeepMind team achieved even superhuman performance with AlphaGo\u2019s sucessors AlphaGo Zero [7] and AlphaZero [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205261034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c27db32efa8137cbf654902f8f728f338e55cd1c",
            "isKey": false,
            "numCitedBy": 5954,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo\u2019s own move selections and also the winner of AlphaGo\u2019s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100\u20130 against the previously published, champion-defeating AlphaGo."
            },
            "slug": "Mastering-the-game-of-Go-without-human-knowledge-Silver-Schrittwieser",
            "title": {
                "fragments": [],
                "text": "Mastering the game of Go without human knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An algorithm based solely on reinforcement learning is introduced, without human data, guidance or domain knowledge beyond game rules, that achieves superhuman performance, winning 100\u20130 against the previously published, champion-defeating AlphaGo."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2772217"
                        ],
                        "name": "Chris J. Maddison",
                        "slug": "Chris-J.-Maddison",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Maddison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris J. Maddison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885349"
                        ],
                        "name": "Aja Huang",
                        "slug": "Aja-Huang",
                        "structuredName": {
                            "firstName": "Aja",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aja Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7355762,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "127f464c2dc8d85b7612a6924495f79e5458710f",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract: The game of Go is more challenging than other board games, due to the difficulty of constructing a position or move evaluation function. In this paper we investigate whether deep convolutional networks can be used to directly represent and learn this knowledge. We train a large 12-layer convolutional neural network by supervised learning from a database of human professional games. The network correctly predicts the expert move in 55% of positions, equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional search program GnuGo in 97% of games, and matched the performance of a state-of-the-art Monte-Carlo tree search that simulates a million positions per move."
            },
            "slug": "Move-Evaluation-in-Go-Using-Deep-Convolutional-Maddison-Huang",
            "title": {
                "fragments": [],
                "text": "Move Evaluation in Go Using Deep Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A large 12-layer convolutional neural network is trained by supervised learning from a database of human professional games that beats the traditional search program GnuGo in 97% of games, and matched the performance of a state-of-the-art Monte-Carlo tree search that simulates a million positions per move."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143997772"
                        ],
                        "name": "Christopher Clark",
                        "slug": "Christopher-Clark",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728216"
                        ],
                        "name": "A. Storkey",
                        "slug": "A.-Storkey",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Storkey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Storkey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6254050,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb184a6de06a888d136089bc8d76cc70c7401a6e",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Mastering the game of Go has remained a longstanding challenge to the field of AI. Modern computer Go programs rely on processing millions of possible future positions to play well, but intuitively a stronger and more 'humanlike' way to play the game would be to rely on pattern recognition rather than brute force computation. Following this sentiment, we train deep convolutional neural networks to play Go by training them to predict the moves made by expert Go players. To solve this problem we introduce a number of novel techniques, including a method of tying weights in the network to 'hard code' symmetries that are expected to exist in the target function, and demonstrate in an ablation study they considerably improve performance. Our final networks are able to achieve move prediction accuracies of 41.1% and 44.4% on two different Go datasets, surpassing previous state of the art on this task by significant margins. Additionally, while previous move prediction systems have not yielded strong Go playing programs, we show that the networks trained in this work acquired high levels of skill. Our convolutional neural networks can consistently defeat the well known Go program GNU Go and win some games against state of the art Go playing program Fuego while using a fraction of the play time."
            },
            "slug": "Training-Deep-Convolutional-Neural-Networks-to-Play-Clark-Storkey",
            "title": {
                "fragments": [],
                "text": "Training Deep Convolutional Neural Networks to Play Go"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The convolutional neural networks trained in this work can consistently defeat the well known Go program GNU Go and win some games against state of the art Go playing program Fuego while using a fraction of the play time."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067208983"
                        ],
                        "name": "T. Hubert",
                        "slug": "T.-Hubert",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hubert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hubert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4337102"
                        ],
                        "name": "Julian Schrittwieser",
                        "slug": "Julian-Schrittwieser",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Schrittwieser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian Schrittwieser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460849"
                        ],
                        "name": "Ioannis Antonoglou",
                        "slug": "Ioannis-Antonoglou",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Antonoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Antonoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40227832"
                        ],
                        "name": "Matthew Lai",
                        "slug": "Matthew-Lai",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35099444"
                        ],
                        "name": "A. Guez",
                        "slug": "A.-Guez",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Guez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Guez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1975889"
                        ],
                        "name": "Marc Lanctot",
                        "slug": "Marc-Lanctot",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Lanctot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Lanctot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2175946"
                        ],
                        "name": "L. Sifre",
                        "slug": "L.-Sifre",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Sifre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sifre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106164"
                        ],
                        "name": "D. Kumaran",
                        "slug": "D.-Kumaran",
                        "structuredName": {
                            "firstName": "Dharshan",
                            "lastName": "Kumaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kumaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686971"
                        ],
                        "name": "T. Graepel",
                        "slug": "T.-Graepel",
                        "structuredName": {
                            "firstName": "Thore",
                            "lastName": "Graepel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Graepel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48987704"
                        ],
                        "name": "D. Hassabis",
                        "slug": "D.-Hassabis",
                        "structuredName": {
                            "firstName": "Demis",
                            "lastName": "Hassabis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hassabis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "Moreover, the DeepMind team achieved even superhuman performance with AlphaGo\u2019s sucessors AlphaGo Zero [7] and AlphaZero [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54457125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9717d29840f4d8f1cc19d1b1e80c5d12ec40608",
            "isKey": false,
            "numCitedBy": 1708,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "One program to rule them all Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system. Science, this issue p. 1140; see also pp. 1087 and 1118 AlphaZero teaches itself to play three different board games and beats state-of-the-art programs in each. The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go."
            },
            "slug": "A-general-reinforcement-learning-algorithm-that-and-Silver-Hubert",
            "title": {
                "fragments": [],
                "text": "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper generalizes the AlphaZero approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games, and convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739396"
                        ],
                        "name": "N. Schraudolph",
                        "slug": "N.-Schraudolph",
                        "structuredName": {
                            "firstName": "Nicol",
                            "lastName": "Schraudolph",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Schraudolph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6314186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73382b3efd243d330a902e6a1eb0f6b32dbc5f29",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The game of Go has a high branching factor that defeats the tree search approach used in computer chess, and long-range spatiotemporal interactions that make position evaluation extremely difficult. Development of conventional Go programs is hampered by their knowledge-intensive nature. We demonstrate a viable alternative by training networks to evaluate Go positions via temporal difference (TD) learning. \n \nOur approach is based on network architectures that reflect the spatial organization of both input and reinforcement signals on the Go board, and training protocols that provide exposure to competent (though unlabelled) play. These techniques yield far better performance than undifferentiated networks trained by selfplay alone. A network with less than 500 weights learned within 3,000 games of 9\u00d79 Go a position evaluation function that enables a primitive one-ply search to defeat a commercial Go program at a low playing level."
            },
            "slug": "Temporal-Difference-Learning-of-Position-Evaluation-Schraudolph-Dayan",
            "title": {
                "fragments": [],
                "text": "Temporal Difference Learning of Position Evaluation in the Game of Go"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work demonstrates a viable alternative by training networks to evaluate Go positions via temporal difference (TD) learning, based on network architectures that reflect the spatial organization of both input and reinforcement signals on the Go board, and training protocols that provide exposure to competent (though unlabelled) play."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144054003"
                        ],
                        "name": "Martin M\u00fcller",
                        "slug": "Martin-M\u00fcller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207211661,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a27a651d28909a8413a69bfc0c6996a338c39f1",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Temporal-difference learning is one of the most successful and broadly applied solutions to the reinforcement learning problem; it has been used to achieve master-level play in chess, checkers and backgammon. The key idea is to update a value function from episodes of real experience, by bootstrapping from future value estimates, and using value function approximation to generalise between related states. Monte-Carlo tree search is a recent algorithm for high-performance search, which has been used to achieve master-level play in Go. The key idea is to use the mean outcome of simulated episodes of experience to evaluate each state in a search tree. We introduce a new approach to high-performance search in Markov decision processes and two-player games. Our method, temporal-difference search, combines temporal-difference learning with simulation-based search. Like Monte-Carlo tree search, the value function is updated from simulated experience; but like temporal-difference learning, it uses value function approximation and bootstrapping to efficiently generalise between related states. We apply temporal-difference search to the game of 9\u00d79 Go, using a million binary features matching simple patterns of stones. Without any explicit search tree, our approach outperformed an unenhanced Monte-Carlo tree search with the same number of simulations. When combined with a simple alpha-beta search, our program also outperformed all traditional (pre-Monte-Carlo) search and machine learning programs on the 9\u00d79 Computer Go Server."
            },
            "slug": "Temporal-difference-search-in-computer-Go-Silver-Sutton",
            "title": {
                "fragments": [],
                "text": "Temporal-difference search in computer Go"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work applies temporal-difference search to the game of 9\u00d79 Go, using a million binary features matching simple patterns of stones, and outperformed an unenhanced Monte-Carlo tree search with the same number of simulations."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47547090"
                        ],
                        "name": "David H. Stern",
                        "slug": "David-H.-Stern",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stern",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David H. Stern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3234984"
                        ],
                        "name": "R. Herbrich",
                        "slug": "R.-Herbrich",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Herbrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Herbrich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686971"
                        ],
                        "name": "T. Graepel",
                        "slug": "T.-Graepel",
                        "structuredName": {
                            "firstName": "Thore",
                            "lastName": "Graepel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Graepel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 651147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a2f15cac4b27a5cc3a29c89b4e9e88ffab920a9",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the problem of learning to predict moves in the board game of Go from game records of expert players. In particular, we obtain a probability distribution over legal moves for professional play in a given position. This distribution has numerous applications in computer Go, including serving as an efficient stand-alone Go player. It would also be effective as a move selector and move sorter for game tree search and as a training tool for Go players. Our method has two major components: a) a pattern extraction scheme for efficiently harvesting patterns of given size and shape from expert game records and b) a Bayesian learning algorithm (in two variants) that learns a distribution over the values of a move given a board position based on the local pattern context. The system is trained on 181,000 expert games and shows excellent prediction performance as indicated by its ability to perfectly predict the moves made by professional Go players in 34% of test positions."
            },
            "slug": "Bayesian-pattern-ranking-for-move-prediction-in-the-Stern-Herbrich",
            "title": {
                "fragments": [],
                "text": "Bayesian pattern ranking for move prediction in the game of Go"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A probability distribution over legal moves for professional play in a given position in Go is obtained and shows excellent prediction performance as indicated by its ability to perfectly predict the moves made by professional Go players in 34% of test positions."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144056327"
                        ],
                        "name": "J. Veness",
                        "slug": "J.-Veness",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Veness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742809"
                        ],
                        "name": "William T. B. Uther",
                        "slug": "William-T.-B.-Uther",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Uther",
                            "middleNames": [
                                "T.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William T. B. Uther"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806864"
                        ],
                        "name": "A. Blair",
                        "slug": "A.-Blair",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Blair",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blair"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7493916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c099cf2b1080699434f9b22b9c5a02ebb4e7509",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce a new algorithm for updating the parameters of a heuristic evaluation function, by updating the heuristic towards the values computed by an alpha-beta search. Our algorithm differs from previous approaches to learning from search, such as Samuel's checkers player and the TD-Leaf algorithm, in two key ways. First, we update all nodes in the search tree, rather than a single node. Second, we use the outcome of a deep search, instead of the outcome of a subsequent search, as the training signal for the evaluation function. We implemented our algorithm in a chess program Meep, using a linear heuristic function. After initialising its weight vector to small random values, Meep was able to learn high quality weights from self-play alone. When tested online against human opponents, Meep played at a master level, the best performance of any chess program with a heuristic learned entirely from self-play."
            },
            "slug": "Bootstrapping-from-Game-Tree-Search-Veness-Silver",
            "title": {
                "fragments": [],
                "text": "Bootstrapping from Game Tree Search"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper introduces a new algorithm for updating the parameters of a heuristic evaluation function, by updating the heuristic towards the values computed by an alpha-beta search, and implemented this algorithm in a chess program Meep, using a linear heuristic function."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802148"
                        ],
                        "name": "S. Gelly",
                        "slug": "S.-Gelly",
                        "structuredName": {
                            "firstName": "Sylvain",
                            "lastName": "Gelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34908205"
                        ],
                        "name": "Levente Kocsis",
                        "slug": "Levente-Kocsis",
                        "structuredName": {
                            "firstName": "Levente",
                            "lastName": "Kocsis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Levente Kocsis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69881991"
                        ],
                        "name": "Marc Schoenauer",
                        "slug": "Marc-Schoenauer",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Schoenauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Schoenauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69343681"
                        ],
                        "name": "M. Sebag",
                        "slug": "M.-Sebag",
                        "structuredName": {
                            "firstName": "Mich\u00e8le",
                            "lastName": "Sebag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sebag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40868287"
                        ],
                        "name": "Csaba Szepesvari",
                        "slug": "Csaba-Szepesvari",
                        "structuredName": {
                            "firstName": "Csaba",
                            "lastName": "Szepesvari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Csaba Szepesvari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776193"
                        ],
                        "name": "O. Teytaud",
                        "slug": "O.-Teytaud",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Teytaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Teytaud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2485362,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ed7228949343d827fe2342368778c0cf79253fc",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "The ancient oriental game of Go has long been considered a grand challenge for artificial intelligence. For decades, computer Go has defied the classical methods in game tree search that worked so successfully for chess and checkers. However, recent play in computer Go has been transformed by a new paradigm for tree search based on Monte-Carlo methods. Programs based on Monte-Carlo tree search now play at human-master levels and are beginning to challenge top professional players. In this paper, we describe the leading algorithms for Monte-Carlo tree search and explain how they have advanced the state of the art in computer Go."
            },
            "slug": "The-grand-challenge-of-computer-Go-Gelly-Kocsis",
            "title": {
                "fragments": [],
                "text": "The grand challenge of computer Go"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper describes the leading algorithms for Monte-Carlo tree search and explains how they have advanced the state of the art in computer Go."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35219266"
                        ],
                        "name": "P. Baudis",
                        "slug": "P.-Baudis",
                        "structuredName": {
                            "firstName": "Petr",
                            "lastName": "Baudis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baudis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46612710,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bc9edacdc35de8c7a1a75f9ee9338288d06c94f",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Monte-Carlo Tree Search tends to produce unstable and unreasonable results in the game of Go when used in positions with an extreme advantage or disadvantage. This is due to a poor move selection because of the low signal-to-noise ratio. Notably, it frequently occurs, when playing in a high handicap game. The handicap advantage is in some sense a disadvantage for the computer when playing against a strong human opponent. We explore and compare multiple approaches to mitigate this problem by artificially evening out the game by modifying the final game score by a variable amount of points (\u201cdynamic komi\u201d) before noting the result in the game tree. Moreover, we compare the performance of MCTS and the traditional tree search in the context of extreme positions and measure the effect of the dynamic komi on the actual playing strength of a state-of-art MCTS Go program. Based on our results, we formulate a conjecture on the resilience of the game search tree to changes in the evaluation function throughout the search."
            },
            "slug": "Balancing-MCTS-by-Dynamically-Adjusting-the-Komi-Baudis",
            "title": {
                "fragments": [],
                "text": "Balancing MCTS by Dynamically Adjusting the Komi Value"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A conjecture on the resilience of the game search tree to changes in the evaluation function throughout the search is formulated and a comparison of MCTS and the traditional tree search in the context of extreme positions is compared."
            },
            "venue": {
                "fragments": [],
                "text": "J. Int. Comput. Games Assoc."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694170"
                        ],
                        "name": "J. Schaeffer",
                        "slug": "J.-Schaeffer",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Schaeffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schaeffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6364294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4f1ee4494d3131d53a284dee3a672821837e4f7",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-games-computers-(and-people)-play-Schaeffer",
            "title": {
                "fragments": [],
                "text": "The games computers (and people) play"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502026"
                        ],
                        "name": "Hendrik Baier",
                        "slug": "Hendrik-Baier",
                        "structuredName": {
                            "firstName": "Hendrik",
                            "lastName": "Baier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hendrik Baier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34897087"
                        ],
                        "name": "P. Drake",
                        "slug": "P.-Drake",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Drake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Drake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13578069,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "6476fbde81546d15f3e513ccf5172f021b7ddabf",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The dominant paradigm for programs playing the game of Go is Monte Carlo tree search. This algorithm builds a search tree by playing many simulated games (playouts). Each playout consists of a sequence of moves within the tree followed by many moves beyond the tree. Moves beyond the tree are generated by a biased random sampling policy. The recently published last-good-reply policy makes moves that, in previous playouts, have been successful replies to immediately preceding moves. This paper presents a modification of this policy that not only remembers moves that recently succeeded but also immediately forgets moves that recently failed. This modification provides a large improvement in playing strength. We also show that responding to the previous two moves is superior to responding to the previous one move. Surprisingly, remembering the win rate of every reply performs much worse than simply remembering the last good reply (and indeed worse than not storing good replies at all)."
            },
            "slug": "The-Power-of-Forgetting:-Improving-the-Policy-in-Go-Baier-Drake",
            "title": {
                "fragments": [],
                "text": "The Power of Forgetting: Improving the Last-Good-Reply Policy in Monte Carlo Go"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A modification of the recently published last-good-reply policy that not only remembers moves that recently succeeded but also immediately forgets Moves that recently failed is presented, providing a large improvement in playing strength."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computational Intelligence and AI in Games"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47392513"
                        ],
                        "name": "Jonathan Baxter",
                        "slug": "Jonathan-Baxter",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Baxter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Baxter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2327611"
                        ],
                        "name": "A. Tridgell",
                        "slug": "A.-Tridgell",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Tridgell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tridgell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37228807"
                        ],
                        "name": "Lex Weaver",
                        "slug": "Lex-Weaver",
                        "structuredName": {
                            "firstName": "Lex",
                            "lastName": "Weaver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lex Weaver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10389798,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb45465f0924795d4eb98d1bf1524d244a05ed3e",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present TDLEAF(\u03bb), a variation on the TD(\u03bb) algorithm that enables it to be used in conjunction with game-tree search. We present some experiments in which our chess program \u201cKnightCap\u201d used TDLEAF(\u03bb) to learn its evaluation function while playing on Internet chess servers. The main success we report is that KnightCap improved from a 1650 rating to a 2150 rating in just 308 games and 3 days of play. As a reference, a rating of 1650 corresponds to about level B human play (on a scale from E (1000) to A (1800)), while 2150 is human master level. We discuss some of the reasons for this success, principle among them being the use of on-line, rather than self-play. We also investigate whether TDLEAF(\u03bb) can yield better results in the domain of backgammon, where TD(\u03bb) has previously yielded striking success."
            },
            "slug": "Learning-to-Play-Chess-Using-Temporal-Differences-Baxter-Tridgell",
            "title": {
                "fragments": [],
                "text": "Learning to Play Chess Using Temporal Differences"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "TDLEAF(\u03bb), a variation on the TD(\u03bb) algorithm that enables it to be used in conjunction with game-tree search, is presented and it is investigated whether it can yield better results in the domain of backgammon, where TD( \u03b5) has previously yielded striking success."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502026"
                        ],
                        "name": "Hendrik Baier",
                        "slug": "Hendrik-Baier",
                        "structuredName": {
                            "firstName": "Hendrik",
                            "lastName": "Baier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hendrik Baier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1997644"
                        ],
                        "name": "M. Winands",
                        "slug": "M.-Winands",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Winands",
                            "middleNames": [
                                "H.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Winands"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11727595,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b730b69446f0d2d263d6d13ef85ce8a16bec7c1",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The dominant approach for programs playing the Asian board game of Go is nowadays Monte-Carlo Tree Search (MCTS). However, MCTS does not perform well in the opening phase of the game, as the branching factor is high and consequences of moves can be far delayed. Human knowledge about Go openings is typically captured in joseki, local sequences of moves that are considered optimal for both players. The choice of the correct joseki in a given whole-board position, however, is difficult to formalize. This paper presents an approach to successfully apply global as well as local opening moves, extracted from databases of high-level game records, in the MCTS framework. Instead of blindly playing moves that match local joseki patterns (passive opening book application), knowledge about these moves is integrated into the search algorithm by the techniques of move pruning and move biasing (active opening book application). Thus, the opening book serves to nudge the search into the direction of tried and tested local moves, while the search is able to filter out locally optimal, but globally problematic move choices. In our experiments, active book application outperforms passive book application and plain MCTS in 19\u00d719 Go."
            },
            "slug": "Active-Opening-Book-Application-for-Monte-Carlo-in-Baier-Winands",
            "title": {
                "fragments": [],
                "text": "Active Opening Book Application for Monte-Carlo Tree Search in 19\u00d719 Go"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents an approach to successfully apply global as well as local opening moves, extracted from databases of high-level game records, in the MCTS framework, and in experiments, active book application outperforms passive book application and plain M CTS in 19\u00d719 Go."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2520096"
                        ],
                        "name": "R\u00e9mi Coulom",
                        "slug": "R\u00e9mi-Coulom",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Coulom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9mi Coulom"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5733047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e60d5bb2d3c47d0c15d9541301b5e0333ed326f",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Move patterns are an essential method to incorporate do- main knowledge into Go-playing programs. This paper presents a new Bayesian technique for supervised learning of such patterns from game records, based on a generalization of Elo ratings. Each sample move in the training data is considered as a victory of a team of pattern features. Elo ratings of individual pattern features are computed from these victo- ries, and can be used in previously unseen positions to compute a prob- ability distribution over legal moves. In this approach, several pattern features may be combined, without an exponential cost in the number of features. Despite a very small number of training games (652), this algorithm outperforms most previous pattern-learning algorithms, both in terms of mean log-evidence ( 2.69), and prediction rate (34.9%). A 19\u25ca 19 Monte-Carlo program improved with these patterns reached the level of the strongest classical programs. and little domain expertise. This paper presents a new supervised pattern-learning algorithm, based on the Bradley-Terry model. The Bradley-Terry model is the theoretical basis of the Elo rating system. The principle of Elo ratings, as applied to chess, is that each player gets a numerical strength estimation, computed from the observation of past game results. From the ratings of players, it is possible to estimate a probability distribution over the outcome of future games. The same principle"
            },
            "slug": "Computing-\"Elo-Ratings\"-of-Move-Patterns-in-the-of-Coulom",
            "title": {
                "fragments": [],
                "text": "Computing \"Elo Ratings\" of Move Patterns in the Game of Go"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A new Bayesian technique for supervised learning of move patterns from game records, based on a generalization of Elo ratings, which outperforms most previous pattern-learning algorithms, both in terms of mean log-evidence, and prediction rate."
            },
            "venue": {
                "fragments": [],
                "text": "J. Int. Comput. Games Assoc."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699108"
                        ],
                        "name": "G. Tesauro",
                        "slug": "G.-Tesauro",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Tesauro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tesauro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14742574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b11305f69641ecb8bd4a5e59cfebe41ad9ed989",
            "isKey": false,
            "numCitedBy": 843,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "TD-Gammon is a neural network that is able to teach itself to play backgammon solely by playing against itself and learning from the results, based on the TD() reinforcement learning algorithm (Sutton 1988). Despite starting from random initial weights (and hence random initial strategy), TD-Gammon achieves a surprisingly strong level of play. With zero knowledge built in at the start of learning (i.e., given only a raw description of the board state), the network learns to play at a strong intermediate level. Furthermore, when a set of hand-crafted features is added to the network's input representation, the result is a truly staggering level of performance: the latest version of TD-Gammon is now estimated to play at a strong master level that is extremely close to the world's best human players."
            },
            "slug": "TD-Gammon,-a-Self-Teaching-Backgammon-Program,-Play-Tesauro",
            "title": {
                "fragments": [],
                "text": "TD-Gammon, a Self-Teaching Backgammon Program, Achieves Master-Level Play"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The latest version of TD-Gammon is now estimated to play at a strong master level that is extremely close to the world's best human players."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699108"
                        ],
                        "name": "G. Tesauro",
                        "slug": "G.-Tesauro",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Tesauro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tesauro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2796200"
                        ],
                        "name": "Gregory R. Galperin",
                        "slug": "Gregory-R.-Galperin",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Galperin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory R. Galperin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10886094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3552fba431aa866bf9de293bebf7eff168e9e19c",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a Monte-Carlo simulation algorithm for real-time policy improvement of an adaptive controller. In the Monte-Carlo simulation, the long-term expected reward of each possible action is statistically measured, using the initial policy to make decisions in each step of the simulation. The action maximizing the measured expected reward is then taken, resulting in an improved policy. Our algorithm is easily parallelizable and has been implemented on the IBM SP1 and SP2 parallel-RISC supercomputers. \n \nWe have obtained promising initial results in applying this algorithm to the domain of backgammon. Results are reported for a wide variety of initial policies, ranging from a random policy to TD-Gammon, an extremely strong multi-layer neural network. In each case, the Monte-Carlo algorithm gives a substantial reduction, by as much as a factor of 5 or more, in the error rate of the base players. The algorithm is also potentially useful in many other adaptive control applications in which it is possible to simulate the environment."
            },
            "slug": "On-line-Policy-Improvement-using-Monte-Carlo-Search-Tesauro-Galperin",
            "title": {
                "fragments": [],
                "text": "On-line Policy Improvement using Monte-Carlo Search"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A Monte-Carlo simulation algorithm for real-time policy improvement of an adaptive controller and results are reported for a wide variety of initial policies, ranging from a random policy to TD-Gammon, an extremely strong multi-layer neural network."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730590"
                        ],
                        "name": "A. Barto",
                        "slug": "A.-Barto",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barto",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9166388,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97efafdb4a3942ab3efba53ded7413199f79c054",
            "isKey": false,
            "numCitedBy": 32849,
            "numCiting": 636,
            "paperAbstract": {
                "fragments": [],
                "text": "Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning."
            },
            "slug": "Reinforcement-Learning:-An-Introduction-Sutton-Barto",
            "title": {
                "fragments": [],
                "text": "Reinforcement Learning: An Introduction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book provides a clear and simple account of the key ideas and algorithms of reinforcement learning, which ranges from the history of the field's intellectual foundations to the most recent developments and applications."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228824"
                        ],
                        "name": "Andrei A. Rusu",
                        "slug": "Andrei-A.-Rusu",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Rusu",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrei A. Rusu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144056327"
                        ],
                        "name": "J. Veness",
                        "slug": "J.-Veness",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Veness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792298"
                        ],
                        "name": "Marc G. Bellemare",
                        "slug": "Marc-G.-Bellemare",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Bellemare",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc G. Bellemare"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145600108"
                        ],
                        "name": "A. Fidjeland",
                        "slug": "A.-Fidjeland",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Fidjeland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fidjeland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2273072"
                        ],
                        "name": "Georg Ostrovski",
                        "slug": "Georg-Ostrovski",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Ostrovski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georg Ostrovski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48348688"
                        ],
                        "name": "Stig Petersen",
                        "slug": "Stig-Petersen",
                        "structuredName": {
                            "firstName": "Stig",
                            "lastName": "Petersen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stig Petersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50388928"
                        ],
                        "name": "Charlie Beattie",
                        "slug": "Charlie-Beattie",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Beattie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie Beattie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49813280"
                        ],
                        "name": "A. Sadik",
                        "slug": "A.-Sadik",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Sadik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sadik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460849"
                        ],
                        "name": "Ioannis Antonoglou",
                        "slug": "Ioannis-Antonoglou",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Antonoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Antonoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143776287"
                        ],
                        "name": "Helen King",
                        "slug": "Helen-King",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "King",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helen King"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106164"
                        ],
                        "name": "D. Kumaran",
                        "slug": "D.-Kumaran",
                        "structuredName": {
                            "firstName": "Dharshan",
                            "lastName": "Kumaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kumaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34313265"
                        ],
                        "name": "S. Legg",
                        "slug": "S.-Legg",
                        "structuredName": {
                            "firstName": "Shane",
                            "lastName": "Legg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Legg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48987704"
                        ],
                        "name": "D. Hassabis",
                        "slug": "D.-Hassabis",
                        "structuredName": {
                            "firstName": "Demis",
                            "lastName": "Hassabis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hassabis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205242740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d",
            "isKey": false,
            "numCitedBy": 16194,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks."
            },
            "slug": "Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "Human-level control through deep reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1975889"
                        ],
                        "name": "Marc Lanctot",
                        "slug": "Marc-Lanctot",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Lanctot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Lanctot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1997644"
                        ],
                        "name": "M. Winands",
                        "slug": "M.-Winands",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Winands",
                            "middleNames": [
                                "H.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Winands"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2615667"
                        ],
                        "name": "Tom Pepels",
                        "slug": "Tom-Pepels",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Pepels",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Pepels"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15914175"
                        ],
                        "name": "Nathan R Sturtevant",
                        "slug": "Nathan-R-Sturtevant",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Sturtevant",
                            "middleNames": [
                                "R"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan R Sturtevant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5392817,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "6c372fbbf228bb9146a50cfbda0bb9fbd760b8d6",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Monte Carlo Tree Search (MCTS) has improved the performance of game engines in domains such as Go, Hex, and general game playing. MCTS has been shown to outperform classic \u03b1\u03b2 search in games where good heuristic evaluations are difficult to obtain. In recent years, combining ideas from traditional minimax search in MCTS has been shown to be advantageous in some domains, such as Lines of Action, Amazons, and Breakthrough. In this paper, we propose a new way to use heuristic evaluations to guide the MCTS search by storing the two sources of information, estimated win rates and heuristic evaluations, separately. Rather than using the heuristic evaluations to replace the playouts, our technique backs them up implicitly during the MCTS simulations. These minimax values are then used to guide future simulations. We show that using implicit minimax backups leads to stronger play performance in Kalah, Breakthrough, and Lines of Action."
            },
            "slug": "Monte-Carlo-Tree-Search-with-heuristic-evaluations-Lanctot-Winands",
            "title": {
                "fragments": [],
                "text": "Monte Carlo Tree Search with heuristic evaluations using implicit minimax backups"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a new way to use heuristic evaluations to guide the MCTS search by storing the two sources of information, estimated win rates and heuristic evaluated, separately, separately and shows that using implicit minimax backups leads to stronger play performance in Kalah, Breakthrough, and Lines of Action."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE Conference on Computational Intelligence and Games"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685622"
                        ],
                        "name": "H. J. V. Herik",
                        "slug": "H.-J.-V.-Herik",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Herik",
                            "middleNames": [
                                "Jaap",
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. J. V. Herik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145495343"
                        ],
                        "name": "J. Uiterwijk",
                        "slug": "J.-Uiterwijk",
                        "structuredName": {
                            "firstName": "Jos",
                            "lastName": "Uiterwijk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Uiterwijk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742015"
                        ],
                        "name": "J. V. Rijswijck",
                        "slug": "J.-V.-Rijswijck",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Rijswijck",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Rijswijck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17747291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8296bc0ab855841088b31190c9f2923951853d7b",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 151,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Games-solved:-Now-and-in-the-future-Herik-Uiterwijk",
            "title": {
                "fragments": [],
                "text": "Games solved: Now and in the future"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3201686"
                        ],
                        "name": "F. Dahl",
                        "slug": "F.-Dahl",
                        "structuredName": {
                            "firstName": "Fredrik",
                            "lastName": "Dahl",
                            "middleNames": [
                                "Andreas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Dahl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14371985,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e43fc96c3ca361be3129a8e6334ca998efec960c",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The Go-playing program HONTE is described. It uses neural nets together with more conventional AI-methods like alpha-beta search. A neural net is trained by supervised learning to imitate local shapes seen in a database of expert games. A second net is trained to estimate the safety of groups by self play using a modified version of TD(\u03bb)-learning. A third net is trained to estimate territorial potential of unoccupied points, also based on self play and TD(\u03bb)- learning. Although the program has not yet reached the level of the most popular commercial Go-programs, results are encouraging."
            },
            "slug": "Honte,-a-go-playing-program-using-neural-nets-Dahl",
            "title": {
                "fragments": [],
                "text": "Honte, a go-playing program using neural nets"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "The Go-playing program HONTE is described, which uses neural nets together with more conventional AI-methods like alpha-beta search and a modified version of TD(\u03bb)-learning to estimate territorial potential of unoccupied points."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421405"
                        ],
                        "name": "Shih-Chieh Huang",
                        "slug": "Shih-Chieh-Huang",
                        "structuredName": {
                            "firstName": "Shih-Chieh",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Chieh Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2520096"
                        ],
                        "name": "R\u00e9mi Coulom",
                        "slug": "R\u00e9mi-Coulom",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Coulom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9mi Coulom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9295999"
                        ],
                        "name": "Shun-Shii Lin",
                        "slug": "Shun-Shii-Lin",
                        "structuredName": {
                            "firstName": "Shun-Shii",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shun-Shii Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14104078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c932ff5bb943c702ccd72e0bbc6f547afa208a6b",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Monte-Carlo tree search (MCTS) is a new technique that has produced a huge leap forward in the strength of Go-playing programs. An interesting aspect of MCTS that has been rarely studied in the past is the problem of time management. This paper presents the effect on playing strength of a variety of time-management heuristics for 19x19 Go. Results indicate that clever time management can have a very significant effect on playing strength. Experiments demonstrate that the most basic algorithm for sudden-death time controls(dividing the remaining time by a constant) produces a winning rate of 43.2\u00b12.2% against GNU Go 3.8 Level 2, whereas our most efficient time-allocation strategy can reach a winning rate of 60\u00b12.2% without pondering and 67.4\u00b12.1% with pondering."
            },
            "slug": "Time-Management-for-Monte-Carlo-Tree-Search-Applied-Huang-Coulom",
            "title": {
                "fragments": [],
                "text": "Time Management for Monte-Carlo Tree Search Applied to the Game of Go"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Results indicate that clever time management can have a very significant effect on playing strength in the case of Monte-Carlo tree search."
            },
            "venue": {
                "fragments": [],
                "text": "2010 International Conference on Technologies and Applications of Artificial Intelligence"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706789"
                        ],
                        "name": "M. Enzenberger",
                        "slug": "M.-Enzenberger",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Enzenberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Enzenberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144054003"
                        ],
                        "name": "Martin M\u00fcller",
                        "slug": "Martin-M\u00fcller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3316111"
                        ],
                        "name": "B. Arneson",
                        "slug": "B.-Arneson",
                        "structuredName": {
                            "firstName": "Broderick",
                            "lastName": "Arneson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Arneson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057966810"
                        ],
                        "name": "R. Segal",
                        "slug": "R.-Segal",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Segal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Segal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8323579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6941f3507c1eaa4e7517f69ef81b37a7dcad1081",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "FUEGO is both an open-source software framework and a state-of-the-art program that plays the game of Go. The framework supports developing game engines for full-information two-player board games, and is used successfully in a substantial number of projects. The FUEGO Go program became the first program to win a game against a top professional player in 9 \u00d7 9 Go. It has won a number of strong tournaments against other programs, and is competitive for 19 \u00d7 19 as well. This paper gives an overview of the development and current state of the FUEGO project. It describes the reusable components of the software framework and specific algorithms used in the Go engine."
            },
            "slug": "Fuego\u2014An-Open-Source-Framework-for-Board-Games-and-Enzenberger-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "Fuego\u2014An Open-Source Framework for Board Games and Go Engine Based on Monte Carlo Tree Search"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An overview of the development and current state of the FUEGO project is given, which describes the reusable components of the software framework and specific algorithms used in the Go engine."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computational Intelligence and AI in Games"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699108"
                        ],
                        "name": "G. Tesauro",
                        "slug": "G.-Tesauro",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Tesauro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tesauro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13881100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1886b7cb26105a8fcb3f2eb3cf03ee85ed09de58",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce the first algorithms for efficiently learning a simulation policy for Monte-Carlo search. Our main idea is to optimise the balance of a simulation policy, so that an accurate spread of simulation outcomes is maintained, rather than optimising the direct strength of the simulation policy. We develop two algorithms for balancing a simulation policy by gradient descent. The first algorithm optimises the balance of complete simulations, using a policy gradient algorithm; whereas the second algorithm optimises the balance over every two steps of simulation. We compare our algorithms to reinforcement learning and supervised learning algorithms for maximising the strength of the simulation policy. We test each algorithm in the domain of 5 x 5 and 6 x 6 Computer Go, using a softmax policy that is parameterised by weights for a hundred simple patterns. When used in a simple Monte-Carlo search, the policies learnt by simulation balancing achieved significantly better performance, with half the mean squared error of a uniform random policy, and similar overall performance to a sophisticated Go engine."
            },
            "slug": "Monte-Carlo-simulation-balancing-Silver-Tesauro",
            "title": {
                "fragments": [],
                "text": "Monte-Carlo simulation balancing"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The main idea is to optimise the balance of a simulation policy, so that an accurate spread of simulation outcomes is maintained, rather than optimising the direct strength of the simulation policy."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145317122"
                        ],
                        "name": "C. Browne",
                        "slug": "C.-Browne",
                        "structuredName": {
                            "firstName": "Cameron",
                            "lastName": "Browne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Browne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144473215"
                        ],
                        "name": "E. Powley",
                        "slug": "E.-Powley",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Powley",
                            "middleNames": [
                                "Jack"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Powley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33424773"
                        ],
                        "name": "D. Whitehouse",
                        "slug": "D.-Whitehouse",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Whitehouse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Whitehouse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714467"
                        ],
                        "name": "P. Cowling",
                        "slug": "P.-Cowling",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Cowling",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cowling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3095131"
                        ],
                        "name": "Philipp Rohlfshagen",
                        "slug": "Philipp-Rohlfshagen",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Rohlfshagen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Rohlfshagen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31893339"
                        ],
                        "name": "Stephen Tavener",
                        "slug": "Stephen-Tavener",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Tavener",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Tavener"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717017"
                        ],
                        "name": "Diego Perez Liebana",
                        "slug": "Diego-Perez-Liebana",
                        "structuredName": {
                            "firstName": "Diego",
                            "lastName": "Liebana",
                            "middleNames": [
                                "Perez"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diego Perez Liebana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2032434"
                        ],
                        "name": "Spyridon Samothrakis",
                        "slug": "Spyridon-Samothrakis",
                        "structuredName": {
                            "firstName": "Spyridon",
                            "lastName": "Samothrakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Spyridon Samothrakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687610"
                        ],
                        "name": "S. Colton",
                        "slug": "S.-Colton",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Colton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Colton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9316331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c37f1baac3c8ba30250084f067167ac3837cf6fd",
            "isKey": false,
            "numCitedBy": 2122,
            "numCiting": 277,
            "paperAbstract": {
                "fragments": [],
                "text": "Monte Carlo tree search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difficult problem of computer Go, but has also proved beneficial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the first five years of MCTS research. We outline the core algorithm's derivation, impart some structure on the many variations and enhancements that have been proposed, and summarize the results from the key game and nongame domains to which MCTS methods have been applied. A number of open research questions indicate that the field is ripe for future work."
            },
            "slug": "A-Survey-of-Monte-Carlo-Tree-Search-Methods-Browne-Powley",
            "title": {
                "fragments": [],
                "text": "A Survey of Monte Carlo Tree Search Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A survey of the literature to date of Monte Carlo tree search, intended to provide a snapshot of the state of the art after the first five years of MCTS research, outlines the core algorithm's derivation, impart some structure on the many variations and enhancements that have been proposed, and summarizes the results from the key game and nongame domains."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computational Intelligence and AI in Games"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421405"
                        ],
                        "name": "Shih-Chieh Huang",
                        "slug": "Shih-Chieh-Huang",
                        "structuredName": {
                            "firstName": "Shih-Chieh",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Chieh Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2520096"
                        ],
                        "name": "R\u00e9mi Coulom",
                        "slug": "R\u00e9mi-Coulom",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Coulom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9mi Coulom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9295999"
                        ],
                        "name": "Shun-Shii Lin",
                        "slug": "Shun-Shii-Lin",
                        "structuredName": {
                            "firstName": "Shun-Shii",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shun-Shii Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9493918,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "a1d923353932e097e47494fdda1c5c215ed9b2ca",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Simulation balancing is a new technique to tune parameters of a playout policy for a Monte-Carlo game-playing program. So far, this algorithm had only been tested in a very artificial setting: it was limited to 5\u00d75 and 6\u00d76 Go, and required a stronger external program that served as a supervisor. In this paper, the effectiveness of simulation balancing is demonstrated in a more realistic setting. A state-of-the-art program, Erica, learned an improved playout policy on the 9\u00d79 board, without requiring any external expert to provide position evaluations. The evaluations were collected by letting the program analyze positions by itself. The previous version of Erica learned pattern weights with the minorization-maximization algorithm. Thanks to simulation balancing, its playing strength was improved from a winning rate of 69% to 78% against Fuego 0.4."
            },
            "slug": "Monte-Carlo-Simulation-Balancing-in-Practice-Huang-Coulom",
            "title": {
                "fragments": [],
                "text": "Monte-Carlo Simulation Balancing in Practice"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The effectiveness of simulation balancing is demonstrated in a more realistic setting and a state-of-the-art program, Erica, learned an improved playout policy on the 9\u00d79 board, without requiring any external expert to provide position evaluations."
            },
            "venue": {
                "fragments": [],
                "text": "Computers and Games"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802148"
                        ],
                        "name": "S. Gelly",
                        "slug": "S.-Gelly",
                        "structuredName": {
                            "firstName": "Sylvain",
                            "lastName": "Gelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18941952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c542aaafcf80a87b37ffa350344e65fe19b9c0ce",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Monte-Carlo-tree-search-and-rapid-action-value-in-Gelly-Silver",
            "title": {
                "fragments": [],
                "text": "Monte-Carlo tree search and rapid action value estimation in computer Go"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694170"
                        ],
                        "name": "J. Schaeffer",
                        "slug": "J.-Schaeffer",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Schaeffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schaeffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2442813"
                        ],
                        "name": "Markian Hlynka",
                        "slug": "Markian-Hlynka",
                        "structuredName": {
                            "firstName": "Markian",
                            "lastName": "Hlynka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markian Hlynka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2684045"
                        ],
                        "name": "V. Jussila",
                        "slug": "V.-Jussila",
                        "structuredName": {
                            "firstName": "Vili",
                            "lastName": "Jussila",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Jussila"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37030282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85941af287e2158bd201a633cbcc763693652c7f",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The temporal difference (TD) learning algorithm offers the hope that the arduous task of manually tuning the evaluation function weights of game-playing programs can be automated. With one exception (TD-Gammon), TD learning has not been demonstrated to be effictive in a high-performance, world Class game-palying program. Further, there has been doubt expressed by game-program developers that learned weights could compete with the best hand-tuned weights. Chinook is the World Man-Machine tuned over 5 years. This paper shows that TD learinng is capable of competing with the best human effort."
            },
            "slug": "Temporal-Difference-Learning-Applied-to-a-Program-Schaeffer-Hlynka",
            "title": {
                "fragments": [],
                "text": "Temporal Difference Learning Applied to a High-Performance Game-Playing Program"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper shows that TD learinng is capable of competing with the best human effort."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35219266"
                        ],
                        "name": "P. Baudis",
                        "slug": "P.-Baudis",
                        "structuredName": {
                            "firstName": "Petr",
                            "lastName": "Baudis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baudis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144663576"
                        ],
                        "name": "J. Gailly",
                        "slug": "J.-Gailly",
                        "structuredName": {
                            "firstName": "Jean-Loup",
                            "lastName": "Gailly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gailly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17734019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e58dff9198c1f4327c2ee2e0753b642b552180b",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a state of the art implementation of the Monte Carlo Tree Search algorithm for the game of Go. Our Pachi software is currently one of the strongest open source Go programs, competing at the top level with other programs and playing evenly against advanced human players. We describe our implementation and choice of published algorithms as well as three notable original improvements: (1) an adaptive time control algorithm, (2) dynamic komi, and (3) the usage of the criticality statistic. We also present new methods to achieve efficient scaling both in terms of multiple threads and multiple machines in a cluster."
            },
            "slug": "PACHI:-State-of-the-Art-Open-Source-Go-Program-Baudis-Gailly",
            "title": {
                "fragments": [],
                "text": "PACHI: State of the Art Open Source Go Program"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A state of the art implementation of the Monte Carlo Tree Search algorithm for the game of Go and three notable original improvements: an adaptive time control algorithm, dynamic komi, and the usage of the criticality statistic are described."
            },
            "venue": {
                "fragments": [],
                "text": "ACG"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706789"
                        ],
                        "name": "M. Enzenberger",
                        "slug": "M.-Enzenberger",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Enzenberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Enzenberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5236783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25b139983c1aa777f24aaa375b5e13f4964803d6",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article a neural network architecture is presented that is able to build a soft segmentation of a two-dimensional input. This network architecture is applied to position evaluation in the game of Go. It is trained using self-play and temporal difference learning combined with a rich two-dimensional reinforcement signal. Two experiments are performed, one using the raw board position as input, the other one doing some simple preprocessing of the board. The second network is able to achieve playing strength comparable to a 13-kyu Go program."
            },
            "slug": "Evaluation-in-Go-by-a-Neural-Network-using-Soft-Enzenberger",
            "title": {
                "fragments": [],
                "text": "Evaluation in Go by a Neural Network using Soft Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A neural network architecture is presented that is able to build a soft segmentation of a two-dimensional input that is applied to position evaluation in the game of Go."
            },
            "venue": {
                "fragments": [],
                "text": "ACG"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144885169"
                        ],
                        "name": "M. Littman",
                        "slug": "M.-Littman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Littman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Littman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8108362,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7fbf55baccbc5fdc7ded1ba18330605909aef5e5",
            "isKey": false,
            "numCitedBy": 2272,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Markov-Games-as-a-Framework-for-Multi-Agent-Littman",
            "title": {
                "fragments": [],
                "text": "Markov Games as a Framework for Multi-Agent Reinforcement Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802148"
                        ],
                        "name": "S. Gelly",
                        "slug": "S.-Gelly",
                        "structuredName": {
                            "firstName": "Sylvain",
                            "lastName": "Gelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2917313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e7aa6d3c4272eb867419a4e88a4c064887e20b4",
            "isKey": false,
            "numCitedBy": 555,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The UCT algorithm learns a value function online using sample-based search. The TD(\u03bb) algorithm can learn a value function offline for the on-policy distribution. We consider three approaches for combining offline and online value functions in the UCT algorithm. First, the offline value function is used as a default policy during Monte-Carlo simulation. Second, the UCT value function is combined with a rapid online estimate of action values. Third, the offline value function is used as prior knowledge in the UCT search tree. We evaluate these algorithms in 9 x 9 Go against GnuGo 3.7.10. The first algorithm performs better than UCT with a random simulation policy, but surprisingly, worse than UCT with a weaker, handcrafted simulation policy. The second algorithm outperforms UCT altogether. The third algorithm outperforms UCT with handcrafted prior knowledge. We combine these algorithms in MoGo, the world's strongest 9 x 9 Go program. Each technique significantly improves MoGo's playing strength."
            },
            "slug": "Combining-online-and-offline-knowledge-in-UCT-Gelly-Silver",
            "title": {
                "fragments": [],
                "text": "Combining online and offline knowledge in UCT"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work considers three approaches for combining offline and online value functions in the UCT algorithm, and combines these algorithms in MoGo, the world's strongest 9 x 9 Go program, where each technique significantly improves MoGo's playing strength."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143903370"
                        ],
                        "name": "Murray Campbell",
                        "slug": "Murray-Campbell",
                        "structuredName": {
                            "firstName": "Murray",
                            "lastName": "Campbell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Murray Campbell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32498609"
                        ],
                        "name": "A. J. Hoane",
                        "slug": "A.-J.-Hoane",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Hoane",
                            "middleNames": [
                                "Joseph"
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Hoane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144844988"
                        ],
                        "name": "Feng-hsiung Hsu",
                        "slug": "Feng-hsiung-Hsu",
                        "structuredName": {
                            "firstName": "Feng-hsiung",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng-hsiung Hsu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 662187,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e4bc1aa55c752918ae99b1a125f6adef61afad2",
            "isKey": false,
            "numCitedBy": 947,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Deep-Blue-Campbell-Hoane",
            "title": {
                "fragments": [],
                "text": "Deep Blue"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759257"
                        ],
                        "name": "B. Bouzy",
                        "slug": "B.-Bouzy",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Bouzy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bouzy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2445336"
                        ],
                        "name": "Bernard Helmstetter",
                        "slug": "Bernard-Helmstetter",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Helmstetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernard Helmstetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9480541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7cb9b8372f245a545f5333b62e52d1a61d3115b4",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe two Go programs, Olga and Oleg, developed by a Monte-Carlo approach that is simpler than Bruegmann\u2019s (1993) approach. Our method is based on Abramson (1990). We performed experiments, to assess ideas on (1) progressive pruning, (2) all moves as first heuristic, (3) temperature, (4) simulated annealing, and (5) depth-two tree search within the Monte-Carlo framework. Progressive pruning and the all moves as first heuristic are good speed-up enhancements that do not deteriorate the level of the program too much. Then, using a constant temperature is an adequate and simple heuristic that is about as good as simulated annealing. The depth-two heuristic gives deceptive results at the moment. The results of our Monte-Carlo programs against knowledge-based programs on 9x9 boards are promising. Finally, the ever-increasing power of computers lead us to think that Monte-Carlo approaches are worth considering for computer Go in the future."
            },
            "slug": "Monte-Carlo-Go-Developments-Bouzy-Helmstetter",
            "title": {
                "fragments": [],
                "text": "Monte-Carlo Go Developments"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Two Go programs are described, Olga and Oleg, developed by a Monte-Carlo approach that is simpler than Bruegmann\u2019s (1993) approach, and the ever-increasing power of computers lead us to think that Monte- carlo approaches are worth considering for computer Go in the future."
            },
            "venue": {
                "fragments": [],
                "text": "ACG"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3089272"
                        ],
                        "name": "R. Monga",
                        "slug": "R.-Monga",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Monga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Monga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145139947"
                        ],
                        "name": "Matthieu Devin",
                        "slug": "Matthieu-Devin",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Devin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Devin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715548"
                        ],
                        "name": "Mark Z. Mao",
                        "slug": "Mark-Z.-Mao",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Mao",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Z. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33666044"
                        ],
                        "name": "A. Senior",
                        "slug": "A.-Senior",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Senior",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Senior"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080690"
                        ],
                        "name": "P. Tucker",
                        "slug": "P.-Tucker",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Tucker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143781496"
                        ],
                        "name": "Ke Yang",
                        "slug": "Ke-Yang",
                        "structuredName": {
                            "firstName": "Ke",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ke Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 372467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3127190433230b3dc1abd0680bb58dced4bcd90e",
            "isKey": false,
            "numCitedBy": 3028,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in unsupervised feature learning and deep learning has shown that being able to train large models can dramatically improve performance. In this paper, we consider the problem of training a deep network with billions of parameters using tens of thousands of CPU cores. We have developed a software framework called DistBelief that can utilize computing clusters with thousands of machines to train large models. Within this framework, we have developed two algorithms for large-scale distributed training: (i) Downpour SGD, an asynchronous stochastic gradient descent procedure supporting a large number of model replicas, and (ii) Sandblaster, a framework that supports a variety of distributed batch optimization procedures, including a distributed implementation of L-BFGS. Downpour SGD and Sandblaster L-BFGS both increase the scale and speed of deep network training. We have successfully used our system to train a deep network 30x larger than previously reported in the literature, and achieves state-of-the-art performance on ImageNet, a visual object recognition task with 16 million images and 21k categories. We show that these same techniques dramatically accelerate the training of a more modestly- sized deep network for a commercial speech recognition service. Although we focus on and report performance of these methods as applied to training large neural networks, the underlying algorithms are applicable to any gradient-based machine learning algorithm."
            },
            "slug": "Large-Scale-Distributed-Deep-Networks-Dean-Corrado",
            "title": {
                "fragments": [],
                "text": "Large Scale Distributed Deep Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper considers the problem of training a deep network with billions of parameters using tens of thousands of CPU cores and develops two algorithms for large-scale distributed training, Downpour SGD and Sandblaster L-BFGS, which increase the scale and speed of deep network training."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699868"
                        ],
                        "name": "Satinder Singh",
                        "slug": "Satinder-Singh",
                        "structuredName": {
                            "firstName": "Satinder",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Satinder Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144830983"
                        ],
                        "name": "Y. Mansour",
                        "slug": "Y.-Mansour",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Mansour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Mansour"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1211821,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a20f0ce0616def7cc9a87446c228906cd5da093b",
            "isKey": false,
            "numCitedBy": 4405,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams's REINFORCE method and actor-critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy."
            },
            "slug": "Policy-Gradient-Methods-for-Reinforcement-Learning-Sutton-McAllester",
            "title": {
                "fragments": [],
                "text": "Policy Gradient Methods for Reinforcement Learning with Function Approximation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proves for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2332513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "isKey": false,
            "numCitedBy": 5181,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms."
            },
            "slug": "Simple-statistical-gradient-following-algorithms-Williams",
            "title": {
                "fragments": [],
                "text": "Simple statistical gradient-following algorithms for connectionist reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units that are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reInforcement tasks, and they do this without explicitly computing gradient estimates."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802148"
                        ],
                        "name": "S. Gelly",
                        "slug": "S.-Gelly",
                        "structuredName": {
                            "firstName": "Sylvain",
                            "lastName": "Gelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2267939"
                        ],
                        "name": "Yizao Wang",
                        "slug": "Yizao-Wang",
                        "structuredName": {
                            "firstName": "Yizao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yizao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708654"
                        ],
                        "name": "R. Munos",
                        "slug": "R.-Munos",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Munos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Munos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776193"
                        ],
                        "name": "O. Teytaud",
                        "slug": "O.-Teytaud",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Teytaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Teytaud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15414292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83ae6a9d4d886d9746a21860dc04a7cdfec39f52",
            "isKey": false,
            "numCitedBy": 377,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithm UCB1 for multi-armed bandit problem has already been extended to Algorithm UCT (Upper bound Confidence for Tree) which works for minimax tree search. We have developed a Monte-Carlo Go program, MoGo, which is the first computer Go program using UCT. We explain our modification of UCT for Go application and also the intelligent random simulation with patterns which has improved significantly the performance of MoGo. UCT combined with pruning techniques for large Go board is discussed, as well as parallelization of UCT. MoGo is now a top level Go program on $9\\times9$ and $13\\times13$ Go boards."
            },
            "slug": "Modi\ufb01cation-of-UCT-with-Patterns-in-Monte-Carlo-Go-Gelly-Wang",
            "title": {
                "fragments": [],
                "text": "Modi\ufb01cation of UCT with Patterns in Monte-Carlo Go"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A Monte-Carlo Go program, MoGo, which is the first computer Go program using UCT, is developed, and the modification of UCT for Go application is explained and also the intelligent random simulation with patterns which has improved significantly the performance of MoGo."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2520096"
                        ],
                        "name": "R\u00e9mi Coulom",
                        "slug": "R\u00e9mi-Coulom",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Coulom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9mi Coulom"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16724115,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5d64db0dcd088a9db3480aecf52a3f96dc1499b",
            "isKey": false,
            "numCitedBy": 1109,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A Monte-Carlo evaluation consists in estimating a position by averaging the outcome of several random continuations. The method can serve as an evaluation function at the leaves of a min-max tree. This paper presents a new framework to combine tree search with Monte-Carlo evaluation, that does not separate between a min-max phase and a Monte-Carlo phase. Instead of backing-up the min-max value close to the root, and the average value at some depth, a more general backup operator is defined that progressively changes from averaging to minmax as the number of simulations grows. This approach provides a finegrained control of the tree growth, at the level of individual simulations, and allows efficient selectivity. The resulting algorithm was implemented in a 9 \u00d7 9 Go-playing program, Crazy Stone, that won the 10th KGS computer-Go tournament."
            },
            "slug": "Efficient-Selectivity-and-Backup-Operators-in-Tree-Coulom",
            "title": {
                "fragments": [],
                "text": "Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new framework to combine tree search with Monte-Carlo evaluation, that does not separate between a min-max phase and a Monte- carlo phase is presented, that provides finegrained control of the tree growth, at the level of individual simulations, and allows efficient selectivity."
            },
            "venue": {
                "fragments": [],
                "text": "Computers and Games"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932627"
                        ],
                        "name": "Steffen H\u00f6lldobler",
                        "slug": "Steffen-H\u00f6lldobler",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "H\u00f6lldobler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen H\u00f6lldobler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958333"
                        ],
                        "name": "Sibylle M\u00f6hle",
                        "slug": "Sibylle-M\u00f6hle",
                        "structuredName": {
                            "firstName": "Sibylle",
                            "lastName": "M\u00f6hle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sibylle M\u00f6hle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2583806"
                        ],
                        "name": "Anna Tigunova",
                        "slug": "Anna-Tigunova",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Tigunova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anna Tigunova"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 235
                            }
                        ],
                        "text": "Interestingly, other researchers say that AlphaGo is not a breakthrough technology but rather a consequence of the recent research in computer Go because all the methods that AlphaGo uses have been known and developed for a long while [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41522296,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f29203441d0a0c4d447454e5da445adfc3ad5548",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The game of Go is known to be one of the most complicated board games. Competing in Go against a professional human player has been a long-standing challenge for AI. In this paper we shed light on the AlphaGo program that could beat a Go world champion, which was previously considered non-achievable for the state of the art AI."
            },
            "slug": "Lessons-Learned-from-AlphaGo-H\u00f6lldobler-M\u00f6hle",
            "title": {
                "fragments": [],
                "text": "Lessons Learned from AlphaGo"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Light is shed on the AlphaGo program that could beat a Go world champion, which was previously considered non-achievable for the state of the art AI."
            },
            "venue": {
                "fragments": [],
                "text": "YSIP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421405"
                        ],
                        "name": "Shih-Chieh Huang",
                        "slug": "Shih-Chieh-Huang",
                        "structuredName": {
                            "firstName": "Shih-Chieh",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Chieh Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144054003"
                        ],
                        "name": "Martin M\u00fcller",
                        "slug": "Martin-M\u00fcller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2728802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "445e411183c60ec94aa1795d5279f5851238f450",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Monte-Carlo Tree Search methods have led to huge progress in computer Go. Still, program performance is uneven - most current Go programs are much stronger in some aspects of the game, such as local fighting and positional evaluation, than in other aspects. Well known weaknesses of many programs include (1) the handling of several simultaneous fights, including the two safe groups problem, and (2) dealing with coexistence in seki."
            },
            "slug": "Investigating-the-Limits-of-Monte-Carlo-Tree-Search-Huang-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "Investigating the Limits of Monte-Carlo Tree Search Methods in Computer Go"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This chapter discusses Monte-Carlo Tree Search methods for Go, and some of the challenges faced in dealing with several simultaneous fights, including the two safe groups problem, and dealing with coexistence in seki."
            },
            "venue": {
                "fragments": [],
                "text": "Computers and Games"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 80978,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7991309"
                        ],
                        "name": "A. Samuel",
                        "slug": "A.-Samuel",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Samuel",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Samuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2126705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9e6bb5f2a04ae30d8ecc9287f8b702eedd7b772",
            "isKey": false,
            "numCitedBy": 3043,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A new signature-table technique is described together with an improved book-learning procedure which is thought to be much superior to the linear polynomial method. Full use is made of the so-called \u201calpha-beta\u201d pruning and several forms of forward pruning to restrict the spread of the move tree and to permit the program to look ahead to a much greater depth than it otherwise could do. While still unable to outplay checker masters, the program's playing ability has been greatly improved.tplay checker masters, the"
            },
            "slug": "Some-Studies-in-Machine-Learning-Using-the-Game-of-Samuel",
            "title": {
                "fragments": [],
                "text": "Some Studies in Machine Learning Using the Game of Checkers"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A new signature-table technique is described together with an improved book-learning procedure which is thought to be much superior to the linear polynomial method and to permit the program to look ahead to a much greater depth than it otherwise could do."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2520096"
                        ],
                        "name": "R\u00e9mi Coulom",
                        "slug": "R\u00e9mi-Coulom",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Coulom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9mi Coulom"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16392190,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ee7fa5ba18c71b5eb18a702391afea15edad0ba",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Whole-History Rating (WHR) is a new method to estimate the time-varying strengths of players involved in paired comparisons. Like many variations of the Elo rating system, the whole-history approach is based on the dynamic Bradley-Terry model. But, instead of using incremental approximations, WHR directly computes the exact maximum a posteriori over the whole rating history of all players. This additional accuracy comes at a higher computational cost than traditional methods, but computation is still fast enough to be easily applied in real time to large-scale game servers (a new game is added in less than 0.001 second). Experiments demonstrate that, in comparison to Elo, Glicko, TrueSkill, and decayed-history algorithms, WHR produces better predictions."
            },
            "slug": "Whole-History-Rating:-A-Bayesian-Rating-System-for-Coulom",
            "title": {
                "fragments": [],
                "text": "Whole-History Rating: A Bayesian Rating System for Players of Time-Varying Strength"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experiments demonstrate that, in comparison to Elo, Glicko, TrueSkill, and decayed-history algorithms, WHR produces better predictions."
            },
            "venue": {
                "fragments": [],
                "text": "Computers and Games"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3349598,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a91635f8d0e7fb804efd1c38d9c24ee952ba7076",
            "isKey": false,
            "numCitedBy": 3557,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "This article introduces a class of incremental learning procedures specialized for prediction \u2013 that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, the new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference methods have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, temporal-difference methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporal-difference methods can be applied to advantage."
            },
            "slug": "Learning-to-Predict-by-the-Methods-of-Temporal-Sutton",
            "title": {
                "fragments": [],
                "text": "Learning to Predict by the Methods of Temporal Differences"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This article introduces a class of incremental learning procedures specialized for prediction \u2013 that is, for using past experience with an incompletely known system to predict its future behavior \u2013 and proves their convergence and optimality for special cases and relation to supervised-learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16759604"
                        ],
                        "name": "H. Berliner",
                        "slug": "H.-Berliner",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Berliner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Berliner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36154525,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "3a5913530437e463e6160012eb3f97812d5eaedc",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Chronology-of-Computer-Chess-and-its-Literature-Berliner",
            "title": {
                "fragments": [],
                "text": "A Chronology of Computer Chess and its Literature"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46291010"
                        ],
                        "name": "C. Rosin",
                        "slug": "C.-Rosin",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Rosin",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rosin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207081359,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c0c0445e89347798800aad3497fcf2f2d27d4e6",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A multi-armed bandit episode consists of n trials, each allowing selection of one of K arms, resulting in payoff from a distribution over [0,1] associated with that arm. We assume contextual side information is available at the start of the episode. This context enables an arm predictor to identify possible favorable arms, but predictions may be imperfect so that they need to be combined with further exploration during the episode. Our setting is an alternative to classical multi-armed bandits which provide no contextual side information, and is also an alternative to contextual bandits which provide new context each individual trial. Multi-armed bandits with episode context can arise naturally, for example in computer Go where context is used to bias move decisions made by a multi-armed bandit algorithm. The UCB1 algorithm for multi-armed bandits achieves worst-case regret bounded by $O\\left(\\sqrt{Kn\\log(n)}\\right)$. We seek to improve this using episode context, particularly in the case where K is large. Using a predictor that places weight Mi\u2009>\u20090 on arm i with weights summing to 1, we present the PUCB algorithm which achieves regret $O\\left(\\frac{1}{M_{\\ast}}\\sqrt{n\\log(n)}\\right)$ where M\u2009\u2217\u2009 is the weight on the optimal arm. We illustrate the behavior of PUCB with small simulation experiments, present extensions that provide additional capabilities for PUCB, and describe methods for obtaining suitable predictors for use with PUCB."
            },
            "slug": "Multi-armed-bandits-with-episode-context-Rosin",
            "title": {
                "fragments": [],
                "text": "Multi-armed bandits with episode context"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The PUCB algorithm is presented, using a predictor that places weight Mi\u2009>\u20090 on arm i with weights summing to 1, which achieves regret $O\\left(\\frac{1}{M_{\\ast}}\\sqrt{n\\log(n)}\\right)$ where M\u2009\u2217\u2009 is the weight on the optimal arm."
            },
            "venue": {
                "fragments": [],
                "text": "Annals of Mathematics and Artificial Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3074096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4cec122a08216fe8a3bc19b22e78fbaea096256",
            "isKey": false,
            "numCitedBy": 28199,
            "numCiting": 938,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine-learning technology powers many aspects of modern society: from web searches to content filtering on social networks to recommendations on e-commerce websites, and it is increasingly present in consumer products such as cameras and smartphones. Machine-learning systems are used to identify objects in images, transcribe speech into text, match news items, posts or products with users\u2019 interests, and select relevant results of search. Increasingly, these applications make use of a class of techniques called deep learning. Conventional machine-learning techniques were limited in their ability to process natural data in their raw form. For decades, constructing a pattern-recognition or machine-learning system required careful engineering and considerable domain expertise to design a feature extractor that transformed the raw data (such as the pixel values of an image) into a suitable internal representation or feature vector from which the learning subsystem, often a classifier, could detect or classify patterns in the input. Representation learning is a set of methods that allows a machine to be fed with raw data and to automatically discover the representations needed for detection or classification. Deep-learning methods are representation-learning methods with multiple levels of representation, obtained by composing simple but non-linear modules that each transform the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level. With the composition of enough such transformations, very complex functions can be learned. For classification tasks, higher layers of representation amplify aspects of the input that are important for discrimination and suppress irrelevant variations. An image, for example, comes in the form of an array of pixel values, and the learned features in the first layer of representation typically represent the presence or absence of edges at particular orientations and locations in the image. The second layer typically detects motifs by spotting particular arrangements of edges, regardless of small variations in the edge positions. The third layer may assemble motifs into larger combinations that correspond to parts of familiar objects, and subsequent layers would detect objects as combinations of these parts. The key aspect of deep learning is that these layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure. Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years. It has turned out to be very good at discovering intricate structures in high-dimensional data and is therefore applicable to many domains of science, business and government. In addition to beating records in image recognition and speech recognition, it has beaten other machine-learning techniques at predicting the activity of potential drug molecules, analysing particle accelerator data, reconstructing brain circuits, and predicting the effects of mutations in non-coding DNA on gene expression and disease. Perhaps more surprisingly, deep learning has produced extremely promising results for various tasks in natural language understanding, particularly topic classification, sentiment analysis, question answering and language translation. We think that deep learning will have many more successes in the near future because it requires very little engineering by hand, so it can easily take advantage of increases in the amount of available computation and data. New learning algorithms and architectures that are currently being developed for deep neural networks will only accelerate this progress."
            },
            "slug": "Deep-Learning-Goodfellow-Bengio",
            "title": {
                "fragments": [],
                "text": "Deep Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years, and will have many more successes in the near future because it requires very little engineering by hand and can easily take advantage of increases in the amount of available computation and data."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148954297"
                        ],
                        "name": "Fei-yue Wang",
                        "slug": "Fei-yue-Wang",
                        "structuredName": {
                            "firstName": "Fei-yue",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei-yue Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155659664"
                        ],
                        "name": "J. Zhang",
                        "slug": "J.-Zhang",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Zhang",
                            "middleNames": [
                                "Jason"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2481151"
                        ],
                        "name": "Xinhu Zheng",
                        "slug": "Xinhu-Zheng",
                        "structuredName": {
                            "firstName": "Xinhu",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinhu Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153315870"
                        ],
                        "name": "Xiao Wang",
                        "slug": "Xiao-Wang",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144057336"
                        ],
                        "name": "Yong Yuan",
                        "slug": "Yong-Yuan",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yuan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2142311"
                        ],
                        "name": "Xiaoxiao Dai",
                        "slug": "Xiaoxiao-Dai",
                        "structuredName": {
                            "firstName": "Xiaoxiao",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoxiao Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2159191766"
                        ],
                        "name": "Jie Zhang",
                        "slug": "Jie-Zhang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119062499"
                        ],
                        "name": "Liuqing Yang",
                        "slug": "Liuqing-Yang",
                        "structuredName": {
                            "firstName": "Liuqing",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liuqing Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 128
                            }
                        ],
                        "text": "So perhaps, the pipeline introduced in AlphaGo bears the potential to be also applied to other domains with minor modifications [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35991085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bef4ae975a0068484cfa62d3b006991d68716c04",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "An investigation on the impact and significance of the AlphaGo vs. Lee Sedol Go match is conducted, and concludes with a conjecture of the AlphaGo Thesis and its extension in accordance with the Church-Turing Thesis in the history of computing. It is postulated that the architecture and method utilized by the AlphaGo program provide an engineering solution for tackling issues in complexity and intelligence. Specifically, the AlphaGo Thesis implies that any effective procedure for hard decision problems such as NP-hard can be implemented with AlphaGo-like approach. Deep rule-based networks are proposed in attempt to establish an understandable structure for deep neural networks in deep learning. The success of AlphaGo and corresponding thesis ensure the technical soundness of the parallel intelligence approach for intelligent control and management of complex systems and knowledge automation."
            },
            "slug": "Where-does-AlphaGo-go:-from-church-turing-thesis-to-Wang-Zhang",
            "title": {
                "fragments": [],
                "text": "Where does AlphaGo go: from church-turing thesis to AlphaGo thesis and beyond"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is postulated that the architecture and method utilized by the AlphaGo program provide an engineering solution for tackling issues in complexity and intelligence and implies that any effective procedure for hard decision problems such as NP-hard can be implemented with AlphaGo-like approach."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE/CAA Journal of Automatica Sinica"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145840115"
                        ],
                        "name": "S. Lawrence",
                        "slug": "S.-Lawrence",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Lawrence",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lawrence"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144288586"
                        ],
                        "name": "A. Back",
                        "slug": "A.-Back",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Back",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Back"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2883848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86890c82b589e24007c56e1f40c5f928a0e04183",
            "isKey": false,
            "numCitedBy": 2720,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer."
            },
            "slug": "Face-recognition:-a-convolutional-neural-network-Lawrence-Giles",
            "title": {
                "fragments": [],
                "text": "Face recognition: a convolutional neural-network approach"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A hybrid neural-network for human face recognition which compares favourably with other methods and analyzes the computational complexity and discusses how new classes could be added to the trained recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694170"
                        ],
                        "name": "J. Schaeffer",
                        "slug": "J.-Schaeffer",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Schaeffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schaeffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038110"
                        ],
                        "name": "J. Culberson",
                        "slug": "J.-Culberson",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Culberson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Culberson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2501516"
                        ],
                        "name": "N. Treloar",
                        "slug": "N.-Treloar",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Treloar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Treloar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144170840"
                        ],
                        "name": "B. Knight",
                        "slug": "B.-Knight",
                        "structuredName": {
                            "firstName": "Brent",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093016"
                        ],
                        "name": "P. Lu",
                        "slug": "P.-Lu",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144617374"
                        ],
                        "name": "D. Szafron",
                        "slug": "D.-Szafron",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Szafron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Szafron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9020643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d088cdda1948d291d7c7cf4bbfe46c9391242cdc",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-World-Championship-Caliber-Checkers-Program-Schaeffer-Culberson",
            "title": {
                "fragments": [],
                "text": "A World Championship Caliber Checkers Program"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681735"
                        ],
                        "name": "J. Ma\u0144dziuk",
                        "slug": "J.-Ma\u0144dziuk",
                        "structuredName": {
                            "firstName": "Jacek",
                            "lastName": "Ma\u0144dziuk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ma\u0144dziuk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11585603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "078c68b6f9653b0b64dc07e12e3d3a6208f615c8",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "The chapter considers recent achievements and perspectives of Computational Intelligence (CI) applied to mind games. Several notable examples of unguided, autonomous CI learning systems are presented and discussed. Based on advantages and limitations of existing approaches a list of challenging issues and open problems in the area of intelligent game playing is proposed and motivated."
            },
            "slug": "Computational-Intelligence-in-Mind-Games-Ma\u0144dziuk",
            "title": {
                "fragments": [],
                "text": "Computational Intelligence in Mind Games"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "The chapter considers recent achievements and perspectives of Computational Intelligence (CI) applied to mind games and proposes and discusses a list of challenging issues and open problems in the area of intelligent game playing."
            },
            "venue": {
                "fragments": [],
                "text": "Challenges for Computational Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799228"
                        ],
                        "name": "M. Buro",
                        "slug": "M.-Buro",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Buro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Buro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14614209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d57519d44de48454ab248802b3e1b96547f1aab",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses a practical framework for the semi-automatic construction of evaluation-functions for games. Based on a structured evaluation function representation, a procedure for exploring the feature space is presented that is able to discover new features in a computationally feasible way. Besides the theoretical aspects, related practical issues such as the generation of training positions, feature selection, and weight fitting in large linear systems are discussed. Finally, we present experimental results for Othello, which demonstrate the potential of the described approach."
            },
            "slug": "From-Simple-Features-to-Sophisticated-Evaluation-Buro",
            "title": {
                "fragments": [],
                "text": "From Simple Features to Sophisticated Evaluation Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A practical framework for the semi-automatic construction of evaluation-functions for games based on a structured evaluation function representation is presented that is able to discover new features in a computationally feasible way."
            },
            "venue": {
                "fragments": [],
                "text": "Computers and Games"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2229222"
                        ],
                        "name": "Richard B. Segal",
                        "slug": "Richard-B.-Segal",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Segal",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard B. Segal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5872023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d57310247a9822fec7c484edb8ec131547341561",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The parallelization of MCTS across multiple-machines has proven surprisingly difficult. The limitations of existing algorithms were evident in the 2009 Computer Olympiad where ZEN using a single fourcore machine defeated both Fuego with ten eight-core machines, and Mogo with twenty thirty-two core machines. This paper investigates the limits of parallel MCTS in order to understand why distributed parallelism has proven so difficult and to pave the way towards future distributed algorithms with better scaling. We first analyze the single-threaded scaling of Fuego and find that there is an upper bound on the play-quality improvements which can come from additional search. We then analyze the scaling of an idealized N-core shared memory machine to determine the maximum amount of parallelism supported by MCTS. We show that parallel speedup depends critically on how much time is given to each player. We use this relationship to predict parallel scaling for time scales beyond what can be empirically evaluated due to the immense computation required. Our results show that MCTS can scale nearly perfectly to at least 64 threads when combined with virtual loss, but without virtual loss scaling is limited to just eight threads. We also find that for competition time controls scaling to thousands of threads is impossible not necessarily due to MCTS not scaling, but because high levels of parallelism can start to bump up against the upper performance bound of FUEGO itself."
            },
            "slug": "On-the-Scalability-of-Parallel-UCT-Segal",
            "title": {
                "fragments": [],
                "text": "On the Scalability of Parallel UCT"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper first analyzes the single-threaded scaling of Fuego and finds that there is an upper bound on the play-quality improvements which can come from additional search, and determines the maximum amount of parallelism supported by MCTS."
            },
            "venue": {
                "fragments": [],
                "text": "Computers and Games"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706789"
                        ],
                        "name": "M. Enzenberger",
                        "slug": "M.-Enzenberger",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Enzenberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Enzenberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144054003"
                        ],
                        "name": "Martin M\u00fcller",
                        "slug": "Martin-M\u00fcller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6731489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9926bca07805af3f9ba23f1354b6c2b205a6f14",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "With the recent success of Monte-Carlo tree search algorithms in Go and other games, and the increasing number of cores in standard CPUs, the efficient parallelization of the search has become an important issue. We present a new lock-free parallel algorithm for Monte-Carlo tree search which takes advantage of the memory model of the IA-32 and Intel-64 CPU architectures and intentionally ignores rare faulty updates of node values. We show that this algorithm significantly improves the scalability of the Fuego Go program."
            },
            "slug": "A-Lock-Free-Multithreaded-Monte-Carlo-Tree-Search-Enzenberger-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "A Lock-Free Multithreaded Monte-Carlo Tree Search Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new lock-free parallel algorithm for Monte-Carlo tree search which takes advantage of the memory model of the IA-32 and Intel-64 CPU architectures and intentionally ignores rare faulty updates of node values is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACG"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34908205"
                        ],
                        "name": "Levente Kocsis",
                        "slug": "Levente-Kocsis",
                        "structuredName": {
                            "firstName": "Levente",
                            "lastName": "Kocsis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Levente Kocsis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40868287"
                        ],
                        "name": "Csaba Szepesvari",
                        "slug": "Csaba-Szepesvari",
                        "structuredName": {
                            "firstName": "Csaba",
                            "lastName": "Szepesvari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Csaba Szepesvari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15184765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e635d81a617d1239232a9c9a11a196c53dab8240",
            "isKey": false,
            "numCitedBy": 2632,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "For large state-space Markovian Decision Problems Monte-Carlo planning is one of the few viable approaches to find near-optimal solutions. In this paper we introduce a new algorithm, UCT, that applies bandit ideas to guide Monte-Carlo planning. In finite-horizon or discounted MDPs the algorithm is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling. Experimental results show that in several domains, UCT is significantly more efficient than its alternatives."
            },
            "slug": "Bandit-Based-Monte-Carlo-Planning-Kocsis-Szepesvari",
            "title": {
                "fragments": [],
                "text": "Bandit Based Monte-Carlo Planning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new algorithm is introduced, UCT, that applies bandit ideas to guide Monte-Carlo planning and is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075623070"
                        ],
                        "name": "B. Sheppard",
                        "slug": "B.-Sheppard",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Sheppard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sheppard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2850073,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "5acbb3f169bc13a0e6b3848adabf856c20edf9c2",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "World-championship-caliber-Scrabble-Sheppard",
            "title": {
                "fragments": [],
                "text": "World-championship-caliber Scrabble"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717349"
                        ],
                        "name": "D. Knuth",
                        "slug": "D.-Knuth",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Knuth",
                            "middleNames": [
                                "Ervin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Knuth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109856376"
                        ],
                        "name": "Ronald W. Moore",
                        "slug": "Ronald-W.-Moore",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Moore",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald W. Moore"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28918417,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c876c5fed5b6a3a91b5f55e1f776d629cc8ed9bc",
            "isKey": false,
            "numCitedBy": 1003,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Analysis-of-Alpha-Beta-Pruning-Knuth-Moore",
            "title": {
                "fragments": [],
                "text": "An Analysis of Alpha-Beta Pruning"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144054003"
                        ],
                        "name": "Martin M\u00fcller",
                        "slug": "Martin-M\u00fcller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15132510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49ca0eda8e224507d341d16a8c3fdb4d566cefe3",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Go-M\u00fcller",
            "title": {
                "fragments": [],
                "text": "Computer Go"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144497046"
                        ],
                        "name": "N. Nilsson",
                        "slug": "N.-Nilsson",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nilsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1028275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b886f2c097b635ee9550ca29fff7dcbbb7727ff7",
            "isKey": false,
            "numCitedBy": 5912,
            "numCiting": 271,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a survey of Artifici'al Intelligence (AI). It divides the field into four cor~ topics (embodying the base fo\u00b7r a science of intelligence) and eight applications topics (in which research has been contributing to core ideas).. The paper discusses the history, the major landmarks, and some of the controversies in each of these twelve topics. Each topic is represented by a chart citing the major references. These references are contained in an extensive bibliography. The paper concludes with a discussion of some of the criticisms of 'AI and with some predictions about the course of future research."
            },
            "slug": "Artificial-Intelligence-Nilsson",
            "title": {
                "fragments": [],
                "text": "Artificial Intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The history, the major landmarks, and some of the controversies in each of these twelve topics are discussed, as well as some predictions about the course of future research."
            },
            "venue": {
                "fragments": [],
                "text": "IFIP Congress"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3266933"
                        ],
                        "name": "L. Chittka",
                        "slug": "L.-Chittka",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Chittka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chittka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2850317"
                        ],
                        "name": "Vera Vasas",
                        "slug": "Vera-Vasas",
                        "structuredName": {
                            "firstName": "Vera",
                            "lastName": "Vasas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vera Vasas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "Because of that, it was also considered as one of the \"grand challenges\" of artificial intelligence [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 254
                            }
                        ],
                        "text": "In October 2015, DeepMind\u2019s AlphaGo defeated the European champion, Fan Hui, a 2 dan professional, in formal five-game match, which was the first time a computer Go program has defeated a human professional player (without handicap) in a full game of Go [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 224235194,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e918770057d78bcffcd12e32b682af3b2e238c78",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Faculty-Opinions-recommendation-of-Mastering-the-of-Chittka-Vasas",
            "title": {
                "fragments": [],
                "text": "Faculty Opinions recommendation of Mastering the game of Go with deep neural networks and tree search."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "148897496"
                        ],
                        "name": "\u4e00\u6a39 \u7f8e\u6dfb",
                        "slug": "\u4e00\u6a39-\u7f8e\u6dfb",
                        "structuredName": {
                            "firstName": "\u4e00\u6a39",
                            "lastName": "\u7f8e\u6dfb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u4e00\u6a39 \u7f8e\u6dfb"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 186248485,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48185dd3107a54a67cc047d6644a80738d17ada7",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "5\u5206\u3067\u5206\u304b\u308b!-\u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aSilver,-D.-et-al.-:-Mastering-the-\u4e00\u6a39",
            "title": {
                "fragments": [],
                "text": "5\u5206\u3067\u5206\u304b\u308b! ? \u6709\u540d\u8ad6\u6587\u30ca\u30ca\u30e1\u8aad\u307f\uff1aSilver, D. et al. : Mastering the Game of Go without Human Knowledge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84457029"
                        ],
                        "name": "D. A. Mechner",
                        "slug": "D.-A.-Mechner",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mechner",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. A. Mechner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 70670932,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "c37093c6ada711439d3935471d7e15608408ac82",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "All-Systems-Go-Mechner",
            "title": {
                "fragments": [],
                "text": "All Systems Go"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802148"
                        ],
                        "name": "S. Gelly",
                        "slug": "S.-Gelly",
                        "structuredName": {
                            "firstName": "Sylvain",
                            "lastName": "Gelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60146442,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d85a5e797355e9843a3dc6176938699a0ac88847",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Combining-Online-and-Offline-Learning-in-UCT-Gelly-Silver",
            "title": {
                "fragments": [],
                "text": "Combining Online and Offline Learning in UCT"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3204972"
                        ],
                        "name": "L. Allis",
                        "slug": "L.-Allis",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Allis",
                            "middleNames": [
                                "Victor"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Allis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60886521,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ef577bf5f23390111b886543c4e6c96062e233f",
            "isKey": false,
            "numCitedBy": 417,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Searching-for-solutions-in-games-and-artificial-Allis",
            "title": {
                "fragments": [],
                "text": "Searching for solutions in games and artificial intelligence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073603971"
                        ],
                        "name": "Vinod Nair",
                        "slug": "Vinod-Nair",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Nair"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8507564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a19147696e7bd47af0fdca9de1e0c362386da00",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Building a strong computer Go player is a longstanding open problem. In this paper we consider the related problem of predicting the moves made by Go experts in professional games. The ability to predict experts' moves is useful, because it can, in principle, be used to narrow the search done by a computer Go player. We applied an ensemble of convolutional neural networks to this problem. Our main result is that the ensemble learns to predict 36.9% of the moves made in test expert Go games, improving upon the state of the art, and that the best single convolutional neural network of the ensemble achieves 34% accuracy. This network has less than 104parameters."
            },
            "slug": "Mimicking-Go-Experts-with-Convolutional-Neural-Sutskever-Nair",
            "title": {
                "fragments": [],
                "text": "Mimicking Go Experts with Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The main result is that the ensemble learns to predict 36.9% of the moves made in test expert Go games, improving upon the state of the art, and that the best single convolutional neural network of the ensemble achieves 34% accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cross-table of percentage win rates between programs in the singlemachine scalability study. 95% Agresti-Coull confidence intervals in grey. Each program played with 2 seconds per move"
            },
            "venue": {
                "fragments": [],
                "text": "Cross-table of percentage win rates between programs in the singlemachine scalability study. 95% Agresti-Coull confidence intervals in grey. Each program played with 2 seconds per move"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer Go. Artificial Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Go. Artificial Intelligence"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "British Go Association. An Introduction to Go"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Extended Data Table 8: Results of a tournament between AlphaGo and distributed AlphaGo, testing scalability with hardware. Each program played with a maximum of 2 seconds computation time per move"
            },
            "venue": {
                "fragments": [],
                "text": "Extended Data Table 8: Results of a tournament between AlphaGo and distributed AlphaGo, testing scalability with hardware. Each program played with a maximum of 2 seconds computation time per move"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "October 5 \u2013 9, 2015 @BULLET <Official match> Time limit:1 hour @BULLET"
            },
            "venue": {
                "fragments": [],
                "text": "October 5 \u2013 9, 2015 @BULLET <Official match> Time limit:1 hour @BULLET"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "95% Agresti\u2013Coull confidence intervals in grey. Each program played with 2 s per move; komi was 7.5 in all games"
            },
            "venue": {
                "fragments": [],
                "text": "95% Agresti\u2013Coull confidence intervals in grey. Each program played with 2 s per move; komi was 7.5 in all games"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Each program played with a maximum of 5 s thinking time per move. CN4, ZN4 and PC4 were given 4 handicap stones; komi was 7.5 in all games. Distributed AlphaGo scored 77% [70"
            },
            "venue": {
                "fragments": [],
                "text": "95% Agresti\u2013Coull confidence intervals in grey"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cross-table of percentage win rates between programs in the distributed scalability study. 95% Agresti-Coull confidence intervals in grey. Each program played with 2 seconds per move"
            },
            "venue": {
                "fragments": [],
                "text": "Cross-table of percentage win rates between programs in the distributed scalability study. 95% Agresti-Coull confidence intervals in grey. Each program played with 2 seconds per move"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u201c Lessons Learned from AlphaGo \u201d \u201c Mastering the game of Go with deep neural networks and tree search \u201d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "action values to select an unexplored edge, AlphaGo\u2019s MCTS uses the probabilities supplied by the SL policy network [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reinforcement Learning: An Introduction. Second"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 209
                            }
                        ],
                        "text": "In March 2016, AlphaGo even defeated the world champion, Lee Sedol, a 9 dan professional, the highest rank a player can achieve, at the Google DeepMind challenge, which was an event held in Seoul, South Korea [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Artificial intelligence: Google\u2019s AlphaGo beats Go master Lee Se-dol"
            },
            "venue": {
                "fragments": [],
                "text": "Mar."
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to predict by the method of temporal differences"
            },
            "venue": {
                "fragments": [],
                "text": "Mach. Learn"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distributed AlphaGo scored 77% [70; 82] against \u03b1 rvp and 100% against all other programs (no handicap games were played)"
            },
            "venue": {
                "fragments": [],
                "text": "Distributed AlphaGo scored 77% [70; 82] against \u03b1 rvp and 100% against all other programs (no handicap games were played)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A brief introduction of AlphaGo and Deep Learning: How it works"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 81,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/Mastering-the-game-of-Go-with-deep-neural-networks-Silver-Huang/846aedd869a00c09b40f1f1f35673cb22bc87490?sort=total-citations"
}