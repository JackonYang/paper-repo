{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145512909"
                        ],
                        "name": "G. Rigoll",
                        "slug": "G.-Rigoll",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Rigoll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Rigoll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143720989"
                        ],
                        "name": "D. Willett",
                        "slug": "D.-Willett",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Willett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Willett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14449112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb83d579a045f7ebd6a20b7283aa4583c6043599",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper deals with a hybrid NN/HMM architecture for continuous speech recognition. We present a novel approach to set up a neural linear or nonlinear feature transformation that is used as a preprocessor on top of the HMM system's RBF-network to produce discriminative feature vectors that are well suited for being modeled by mixtures of Gaussian distributions. In order to omit the computational cost of discriminative training of a context-dependent system, we propose to train a discriminant neural feature transformation on a system of low complexity and reuse this transformation in the context-dependent system to output improved feature vectors. The resulting hybrid system is an extension of a state-of-the-art continuous HMM system, and in fact, it is the first hybrid system that really is capable of outperforming these standard systems with respect to the recognition accuracy, without the need for discriminative training of the entire system. In experiments carried out on the Resource Management 1000-word continuous speech recognition task we achieved a relative error reduction of about 10% with a recognition system that, even before, was among the best ever observed on this task."
            },
            "slug": "A-NN/HMM-hybrid-for-continuous-speech-recognition-a-Rigoll-Willett",
            "title": {
                "fragments": [],
                "text": "A NN/HMM hybrid for continuous speech recognition with a discriminant nonlinear feature extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A novel approach to set up a neural linear or nonlinear feature transformation that is used as a preprocessor on top of the HMM system's RBF-network to produce discriminative feature vectors that are well suited for being modeled by mixtures of Gaussian distributions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The hybrid connectionist-HMM framework [1] replaces the GMM acoustic model with a neural network (NN), discriminatively trained to estimate the posterior probabilities of each subword class given the data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61058350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d82e058a5c40954b8f5db170a298a889a254c37",
            "isKey": false,
            "numCitedBy": 1409,
            "numCiting": 190,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nConnectionist Speech Recognition: A Hybrid Approach describes the theory and implementation of a method to incorporate neural network approaches into state-of-the-art continuous speech recognition systems based on Hidden Markov Models (HMMs) to improve their performance. In this framework, neural networks (and in particular, multilayer perceptrons or MLPs) have been restricted to well-defined subtasks of the whole system, i.e., HMM emission probability estimation and feature extraction. The book describes a successful five year international collaboration between the authors. The lessons learned form a case study that demonstrates how hybrid systems can be developed to combine neural networks with more traditional statistical approaches. The book illustrates both the advantages and limitations of neural networks in the framework of a statistical system. Using standard databases and comparing with some conventional approaches, it is shown that MLP probability estimation can improve recognition performance. Other approaches are discussed, though there is no such unequivocal experimental result for these methods. Connectionist Speech Recognition: A Hybrid Approach is of use to anyone intending to use neural networks for speech recognition or within the framework provided by an existing successful statistical approach. This includes research and development groups working in the field of speech recognition, both with standard and neural network approaches, as well as other pattern recognition and/or neural network researchers. This book is also suitable as a text for advanced courses on neural networks or speech processing."
            },
            "slug": "Connectionist-Speech-Recognition:-A-Hybrid-Approach-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "Connectionist Speech Recognition: A Hybrid Approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109947002"
                        ],
                        "name": "Sangita Sharma",
                        "slug": "Sangita-Sharma",
                        "structuredName": {
                            "firstName": "Sangita",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangita Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745455"
                        ],
                        "name": "D. Ellis",
                        "slug": "D.-Ellis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ellis",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687763"
                        ],
                        "name": "S. Kajarekar",
                        "slug": "S.-Kajarekar",
                        "structuredName": {
                            "firstName": "Sachin",
                            "lastName": "Kajarekar",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kajarekar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066975404"
                        ],
                        "name": "P. Jain",
                        "slug": "P.-Jain",
                        "structuredName": {
                            "firstName": "Pratibha",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [8], we show positive results with this approach but using much smaller nets of about 28,000 weights in total."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "These are two components of our full Aurora system, which is described in more detail in [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15468643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ade11fb54b848a683fc5daac49e767e2cb29e44b",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We evaluate the performance of several feature sets on the Aurora task as defined by ETSI. We show that after a non-linear transformation, a number of features can be effectively used in a HMM-based recognition system. The non-linear transformation is computed using a neural network which is discriminatively trained on the phonetically labeled (forcibly aligned) training data. A combination of the non-linearly transformed PLP (perceptive linear predictive coefficients), MSG (modulation filtered spectrogram) and TRAP (temporal pattern) features yields a 63% improvement in error rate as compared to baseline me frequency cepstral coefficients features. The use of the non-linearly transformed RASTA-like features, with system parameters scaled down to take into account the ETSI imposed memory and latency constraints, still yields a 40% improvement in error rate."
            },
            "slug": "Feature-extraction-using-non-linear-transformation-Sharma-Ellis",
            "title": {
                "fragments": [],
                "text": "Feature extraction using non-linear transformation for robust speech recognition on the Aurora database"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that after a non-linear transformation, a number of features can be effectively used in a HMM-based recognition system."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714393"
                        ],
                        "name": "R. Mori",
                        "slug": "R.-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Mori",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2376916"
                        ],
                        "name": "G. Flammia",
                        "slug": "G.-Flammia",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Flammia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Flammia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688499"
                        ],
                        "name": "R. Kompe",
                        "slug": "R.-Kompe",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Kompe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kompe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Bengio [10] suggested using them to increase state likelihoods in HMM systems, and Rigoll and Willet [11] showed significant imWER% / SNR Baseline System Clean 20dB 15dB ratio %"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 894840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffbe67c217967b6bfb0a5ecc0dc4cdd5cda65776",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "An original method for integrating artificial neural networks (ANN) with hidden Markov models (HMM) is proposed. ANNs are suitable for performing phonetic classification, whereas HMMs have been proven successful at modeling the temporal structure of the speech signal. In the approach described, the ANN outputs constitute the sequence of observation vectors for the HMM. An algorithm is proposed for global optimization of all the parameters. Results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported.<<ETX>>"
            },
            "slug": "Global-optimization-of-a-neural-network-hidden-Bengio-Mori",
            "title": {
                "fragments": [],
                "text": "Global optimization of a neural network-hidden Markov model hybrid"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "An original method for integrating artificial neural networks (ANN) with hidden Markov models (HMM) with results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109947002"
                        ],
                        "name": "Sangita Sharma",
                        "slug": "Sangita-Sharma",
                        "structuredName": {
                            "firstName": "Sangita",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangita Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066975404"
                        ],
                        "name": "P. Jain",
                        "slug": "P.-Jain",
                        "structuredName": {
                            "firstName": "Pratibha",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "It may be of an interest that in our earlier work [9] we also compared corpus-dependent and corpus-independent nets and observed only about 25-30% increase in the error rate from the use of the corpus-independent feature net."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 217
                            }
                        ],
                        "text": "To investigate this possibility, we trained a network of the same size as our previous examples on the large-vocabulary OGI Stories corpus (which we have used previously as a source of general-purpose acoustic models [9])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18782969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d2da776b4a1c40bb7aeb59b5fa29897b5c66ccc",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Rather long temporal trajectory of critical band logarithmic power spectrum energy at a given frequency is used as an input feature vector in a MLP-based phoneme classi er, trained on a task-independent hand-labeled development data. Class-speci c log likelihood vectors from the individual sub-classi ers form input to a merging MLP classi er trained on the training data. Output of this merging classi er forms a feature vector for subsequent HMM ASR."
            },
            "slug": "Data-Derived-Non-Linear-Mapping-for-Feature-in-HMM-Hermansky-Sharma",
            "title": {
                "fragments": [],
                "text": "Data-Derived Non-Linear Mapping for Feature Extraction in HMM"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Rather long temporal trajectory of critical band logarithmic power spectrum energy at a given frequency is used as an input feature vector in a MLP-based phoneme classi er, trained on a task-independent hand-labeled development data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861944"
                        ],
                        "name": "G. Williams",
                        "slug": "G.-Williams",
                        "structuredName": {
                            "firstName": "Gethin",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745455"
                        ],
                        "name": "D. Ellis",
                        "slug": "D.-Ellis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ellis",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ellis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 233
                            }
                        ],
                        "text": "Our view of these neural network classifiers is that they focus their modeling power on the small patches of feature space that lie on the boundaries between phones, since these represent the most difficult cases in the training set [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15228447,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1662dba5ab1fc87e871605d1fc14b89b0b1a029c",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "[MorgB95] N. Morgan and H. Bourlard, \u201cContinuous Speech Recognition: An Introduction to the Hybrid HMM/Connectionist Approach,\u201d Signal Processing Magazine, pp 25-42, May 1995. [Cook99] G. Cook, J. Christie, D. Ellis, E. Fosler-Lussier, Y. Gotoh, B. Kingsbury, N. Morgan, S. Renals, A. Robinson and G. Williams, \u201cThe SPRACH System for the Transcription of Broadcast News,\u201d Proc. DARPA Broadcast News Transcription and Understanding Workshop, Herndon VA, Feb 1999. [ScheirS97] E. Scheirer and M. Slaney, \u201cConstruction and evaluation of a robust multifeature speech/music discriminator,\u201d Proc. ICASSP, Munich, 1997. [Williams99] G. Williams, Acoustic confidence measures in connectionist speech recognition, Ph.D. thesis, Dept. of Computer Science, Univ. of Sheffield, 1999."
            },
            "slug": "Speech/music-discrimination-based-on-posterior-Williams-Ellis",
            "title": {
                "fragments": [],
                "text": "Speech/music discrimination based on posterior probability features"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Acoustic confidence measures in connectionist speech recognition, Ph.D. thesis, Dept. of Computer Science, Univ. of Sheffield, 1999."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15052804,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "b578f4faeb00b808e8786d897447f2493b12b4e9",
            "isKey": false,
            "numCitedBy": 2939,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "A new technique for the analysis of speech, the perceptual linear predictive (PLP) technique, is presented and examined. This technique uses three concepts from the psychophysics of hearing to derive an estimate of the auditory spectrum: (1) the critical-band spectral resolution, (2) the equal-loudness curve, and (3) the intensity-loudness power law. The auditory spectrum is then approximated by an autoregressive all-pole model. A 5th-order all-pole model is effective in suppressing speaker-dependent details of the auditory spectrum. In comparison with conventional linear predictive (LP) analysis, PLP analysis is more consistent with human hearing. The effective second formant F2' and the 3.5-Bark spectral-peak integration theories of vowel perception are well accounted for. PLP analysis is computationally efficient and yields a low-dimensional representation of speech. These properties are found to be useful in speaker-independent automatic-speech recognition."
            },
            "slug": "Perceptual-linear-predictive-(PLP)-analysis-of-Hermansky",
            "title": {
                "fragments": [],
                "text": "Perceptual linear predictive (PLP) analysis of speech."
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A new technique for the analysis of speech, the perceptual linear predictive (PLP) technique, which uses three concepts from the psychophysics of hearing to derive an estimate of the auditory spectrum, and yields a low-dimensional representation of speech."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48788686"
                        ],
                        "name": "Adam L. Janin",
                        "slug": "Adam-L.-Janin",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Janin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam L. Janin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745455"
                        ],
                        "name": "D. Ellis",
                        "slug": "D.-Ellis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ellis",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 220
                            }
                        ],
                        "text": "One approach that has shown itself to be beneficial time and again in hybrid systems is feature stream combination via simple averaging of the log posterior probabilities from several independent acoustic model networks [4, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2577562,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3a5b998dc44ff1ed7cdb8c78666eda2b18468c4",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Multi-stream and multi-band methods can improve the accuracy of speech recognition systems without overly increasing the complexity. However, they cannot be applied blindly. In this paper, we review our experience applying multi-stream and multiband methods to the Broadcast News corpus. We found that multi-stream systems using different acoustic front-ends provide a significant improvement over single stream systems. However, despite the fact that they have been successful on smaller tasks, we have not yet been able to show any improvement using multiband methods. We report various insights gained from the experience in applying these methods in a large-vocabulary task."
            },
            "slug": "Multi-stream-speech-recognition:-ready-for-prime-Janin-Ellis",
            "title": {
                "fragments": [],
                "text": "Multi-stream speech recognition: ready for prime time?"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper found that multi-stream systems using different acoustic front-ends provide a significant improvement over single stream systems, however, despite the fact that they have been successful on smaller tasks, they have not yet been able to show any improvement using multiband methods."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144707379"
                        ],
                        "name": "Brian Kingsbury",
                        "slug": "Brian-Kingsbury",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kingsbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Kingsbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 220
                            }
                        ],
                        "text": "One approach that has shown itself to be beneficial time and again in hybrid systems is feature stream combination via simple averaging of the log posterior probabilities from several independent acoustic model networks [4, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16161896,
            "fieldsOfStudy": [
                "Engineering",
                "Physics"
            ],
            "id": "8c2fb8f77b830357ef64e4f1064c939f7d1a2bb9",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of the PLP (perceptual linear predictive), log-RASTA-PLP, and J-RASTA-PLP front ends for recognition of highly reverberant speech is measured and compared with the performance of humans and the performance of an experimental RASTA-like front end on reverberant speech, and with the performance of a PLP-based recognizer trained on reverberant speech. While humans are able to reliably recognize the reverberant test set, achieving a 6.1% word error rate, the best RASTA-PLP-based recognizer has a word error rate of 68.7% on the same test set, and the PLP-based recognizer trained on reverberant speech has a 50.3% word error rate. Our experimental variant on RASTA processing provides a statistically significant improvement in performance on the reverberant speech, with a best word error rate of 64.1%."
            },
            "slug": "Recognizing-reverberant-speech-with-RASTA-PLP-Kingsbury-Morgan",
            "title": {
                "fragments": [],
                "text": "Recognizing reverberant speech with RASTA-PLP"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The authors' experimental variant on RASTA processing provides a statistically significant improvement in performance on the reverberant speech, with a best word error rate of 64.1%."
            },
            "venue": {
                "fragments": [],
                "text": "1997 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31881134"
                        ],
                        "name": "Brian E. D. Kingsbury",
                        "slug": "Brian-E.-D.-Kingsbury",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kingsbury",
                            "middleNames": [
                                "E.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian E. D. Kingsbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "PLP [6] and modulation-filtered spectrogram (MSG, [7])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 27765869,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "8df9b9887d79fcc92d183a70369e925ea1136cfd",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 132,
            "paperAbstract": {
                "fragments": [],
                "text": "Perceptually Inspired Signal-processing Strategies for Robust Speech Recognition in Reverberant Environments"
            },
            "slug": "Perceptually-inspired-signal-processing-strategies-Kingsbury-Morgan",
            "title": {
                "fragments": [],
                "text": "Perceptually inspired signal processing strategies for robust speech recognition in reverberant environments"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work presentsceptually Inspired Signal-processing Strategies for Robust Speech Recognition in Reverberant Environments, a novel approach to signal-processing that automates the very labor-intensive and therefore time-heavy and expensive process of recognizing speech."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49265436"
                        ],
                        "name": "V. Fontaine",
                        "slug": "V.-Fontaine",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Fontaine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Fontaine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980449"
                        ],
                        "name": "C. Ris",
                        "slug": "C.-Ris",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Ris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3342906"
                        ],
                        "name": "Jean-Marc Boite",
                        "slug": "Jean-Marc-Boite",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Boite",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Marc Boite"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[12] use the first 3 layers of a four-layer net as a form of \u201cnon-linear discriminant analysis\u201d (NLDA), to emphasize the relationship to the betterknown linear discriminant analysis (LDA)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14666644,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "4f69c15fc559c5eb893c47f7de727ee4ffad6f5e",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nonlinear-discriminant-analysis-for-improved-speech-Fontaine-Ris",
            "title": {
                "fragments": [],
                "text": "Nonlinear discriminant analysis for improved speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "The relative dominance of likelihood-based systems has resulted in the availability of very sophisticated tools such as HTK [2] offering advanced, mature, and integrated system parameter estimation procedures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hidden Markov Model Toolkit V2.1 reference manual"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report, Speech group, Cambridge University Engineering Department, March 1997."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 242
                            }
                        ],
                        "text": "\u2026probabilistic basis (likelihoods versus posteriors) and different representations for the acoustic models (means and variances of mixture components versus network\nJoint first authors appear in random order.\nweights), techniques developed for one domain are often difficult to transfer to the other."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experimental framework for the performance evaluation of distributed speech recognition front-ends, ETSI working paper"
            },
            "venue": {
                "fragments": [],
                "text": "Experimental framework for the performance evaluation of distributed speech recognition front-ends, ETSI working paper"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature extraction using non - linear transformation for robust speech recognition on the Aurora database , \u201d in preparation . [ 9 ]"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Aurora Project: Experimental framework for the performance evaluation of distributed speech recognition front-ends, ETSl working"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Global optimization of a neuralhidden markov model hybrid"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . on Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 277
                            }
                        ],
                        "text": "\u2026probabilistic basis (likelihoods versus posteriors) and different representations for the acoustic models (means and variances of mixture components versus network\nJoint first authors appear in random order.\nweights), techniques developed for one domain are often difficult to transfer to the other."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experimental framework for the performance evaluation of distributed speech recognition front-ends, ETSl working paper"
            },
            "venue": {
                "fragments": [],
                "text": "Experimental framework for the performance evaluation of distributed speech recognition front-ends, ETSl working paper"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "This research was supported by DoD under MDA904-98-1-0521, NSF under IRI-9712579, and by industrial grant from Intel Inc"
            },
            "venue": {
                "fragments": [],
                "text": "This research was supported by DoD under MDA904-98-1-0521, NSF under IRI-9712579, and by industrial grant from Intel Inc"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perceptual linear predictive (plp) analysis for speech The Journal of The Acoustical Sociew of America"
            },
            "venue": {
                "fragments": [],
                "text": "Perceptual linear predictive (plp) analysis for speech The Journal of The Acoustical Sociew of America"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 219
                            }
                        ],
                        "text": "The resulting system, which effectively has two acoustic models in tandem - first a neural-net then a GMM - performs significantly better than either the hybrid or conventional baselines on the Aurora noisy digits task [3], achieving an average 35% relative error rate reduction over the multiple test conditions when based on the same mel-cepstral features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Project: Experimental framework for the performance evaluation of distributed speech recognition front-ends, ETSI working"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing reverberant speech with RASTA-PLY' Proc. ICASSP-97"
            },
            "venue": {
                "fragments": [],
                "text": "Recognizing reverberant speech with RASTA-PLY' Proc. ICASSP-97"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 6,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 21,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Tandem-connectionist-feature-extraction-for-HMM-Hermansky-Ellis/5e9082caea65c76bfd23b8763872804473ee7872?sort=total-citations"
}