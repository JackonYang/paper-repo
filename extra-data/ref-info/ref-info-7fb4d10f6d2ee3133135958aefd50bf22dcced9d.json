{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590683"
                        ],
                        "name": "W. Stornetta",
                        "slug": "W.-Stornetta",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Stornetta",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Stornetta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144157926"
                        ],
                        "name": "T. Hogg",
                        "slug": "T.-Hogg",
                        "structuredName": {
                            "firstName": "Tad",
                            "lastName": "Hogg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hogg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794321"
                        ],
                        "name": "B. Huberman",
                        "slug": "B.-Huberman",
                        "structuredName": {
                            "firstName": "Bernardo",
                            "lastName": "Huberman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Huberman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "Simil ar arguments have been raised elsewhere [16] [17] [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 209
                            }
                        ],
                        "text": "\u2026tw o set s of units, the weight s connec ti ng the input uni t s to the conte xt uni t s and t he context unit s t o themselves speci fy a mapping function f. Jordan [19] and Sto rnetta, Hogg , and Hub erman [17] have explore d this approach using fixed weights that do not change with expe rience."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16771106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "268e772554222e1dc738f87077b64f1b67258225",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognizing patterns with temporal context is important for such tasks as speech recognition, motion detection and signature verification. We propose an architecture in which time serves as its own representation, and temporal context is encoded in the state of the nodes. We contrast this with the approach of replicating portions of the architecture to represent time. \n \nAs one example of these ideas, we demonstrate an architecture with capacitive inputs serving as temporal feature detectors in an otherwise standard back propagation model. Experiments involving motion detection and word discrimination serve to illustrate novel features of the system. Finally, we discuss possible extensions of the architecture."
            },
            "slug": "A-Dynamical-Approach-to-Temporal-Pattern-Processing-Stornetta-Hogg",
            "title": {
                "fragments": [],
                "text": "A Dynamical Approach to Temporal Pattern Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes an architecture in which time serves as its own representation, and temporal context is encoded in the state of the nodes, and contrasts this with the approach of replicating portions of the architecture to represent time."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2546518"
                        ],
                        "name": "D. Plaut",
                        "slug": "D.-Plaut",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Plaut",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Plaut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802785"
                        ],
                        "name": "S. Nowlan",
                        "slug": "S.-Nowlan",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Nowlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 237
                            }
                        ],
                        "text": "Previous connectionist approaches to temporal patter n r ecognit ion One popular approach to tempora l pattern recogn it ion has been t o const ruct a buffer to hold t he n most recent elements of the input sequence [6] [7] [8] [9] [10] [11] [12] [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15150815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a42b2104ca8ff891ae77c40a915d4c94c8f8428",
            "isKey": false,
            "numCitedBy": 390,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Rumelhart, Hinton and Williams (Rumelhart 86) describe a learning procedure for layered networks of deterministic, neuron-like units. This paper describes further research on the learning procedure. We start by describing the units, the way they are connected, the learning procedure, and the extension to iterative nets. We then give an example in which a network learns a set of filters that enable it to discriminate formant-like patterns in the presence of noise. The speed of learning is strongly dependent on the shape of the surface formed by the error measure in weight space . We give examples of the shape of the error surface for a typical task and illustrate how an acceleration method speeds up descent in weight space. The main drawback of the learning procedure is the way it scales as the size of the task and the network increases. We give some preliminary results on scaling and show how the magnitude of the optimal weight changes depends on the fan-in of the units. Additional results illustrate the effects on learning speed of the amount of interaction between the weights. A variation of the learning procedure that back-propagates desired state information rather than error gradients is developed and compared with the standard procedure. Finally, we discuss the relationship between our iterative networks and the analog networks described by Hopefield and Tank (Hopfield 85). The learning procedure can discover appropriate weights in their kind of network, as well as determine an optimal schedule for varying the nonlinearity of the units during a search."
            },
            "slug": "Experiments-on-Learning-by-Back-Propagation.-Plaut-Nowlan",
            "title": {
                "fragments": [],
                "text": "Experiments on Learning by Back Propagation."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The learning procedure can discover appropriate weights in their kind of network, as well as determine an optimal schedule for varying the nonlinearity of the units during a search."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20678424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c86590e947c28e8791d1e8bab8fc8ab53302341f",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In the work described here, the backpropagation neural network learning procedure is applied to the analysis and recognition of speech. This procedure takes a set of input/output pattern pairs and attempts to learn their functional relationship; it develops the necessary representational features during the course of learning. A series of computer simulation studies was carried out to assess the ability of these networks to accurately label sounds, to learn to recognize sounds without labels, and to learn feature representations of continuous speech. These studies demonstrated that the networks can learn to label presegmented test tokens with accuracies of up to 95%. Networks trained on segmented sounds using a strategy that requires no external labels were able to recognize and delineate sounds in continuous speech. These networks developed rich internal representations that included units which corresponded to such traditional distinctions as vowels and consonants, as well as units that were sensitive to novel and nonstandard features. Networks trained on a large corpus of unsegmented, continuous speech without labels also developed interesting feature representations, which may be useful in both segmentation and label learning. The results of these studies, while preliminary, demonstrate that backpropagation learning can be used with complex, natural data to identify a feature structure that can serve as the basis for both analysis and nontrivial pattern recognition."
            },
            "slug": "Learning-the-hidden-structure-of-speech.-Elman-Zipser",
            "title": {
                "fragments": [],
                "text": "Learning the hidden structure of speech."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results of these studies demonstrate that backpropagation learning can be used with complex, natural data to identify a feature structure that can serve as the basis for both analysis and nontrivial pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 45
                            }
                        ],
                        "text": "Similar arguments have been raised elsewhere (Elman, 1990; Stornetta, Hogg, & Huberman, 1987; Watrous & Shastri, 1987)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2763403,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "668087f0ae7ce1de6e0bd0965dbb480c08103260",
            "isKey": false,
            "numCitedBy": 9859,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction."
            },
            "slug": "Finding-Structure-in-Time-Elman",
            "title": {
                "fragments": [],
                "text": "Finding Structure in Time"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory and suggests a method for representing lexical categories and the type/token distinction is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146667228"
                        ],
                        "name": "English Text",
                        "slug": "English-Text",
                        "structuredName": {
                            "firstName": "English",
                            "lastName": "Text",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "English Text"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62040877,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c43c56a346a31ab93bd1c4faa0486a317db4abb",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes NETtalk, a class of massively-parallel network systems that learn to convert English text to speech. The memory representations for pronunciations are learned by practice and are shared among many processing units. The performance of NETtalk has some similarities with observed human performance. (i) The learning follows a power law. (;i) The more words the network learns, the better it is at generalizing and correctly pronouncing new words, (iii) The performance of the network degrades very slowly as connections in the network are damaged: no single link or processing unit is essential. (iv) Relearning after damage is much faster than learning during the original training. (v) Distributed or spaced prac- tice is more effective for long-term retention than massed practice. Network models can be constructed that have the same perfor- mance and learning characteristics on a particular task, but differ completely at the levels of synaptic strengths and single-unit responses. However, hierarchical clustering techniques applied to NETtalk re- veal that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units. This suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations."
            },
            "slug": "Parallel-Networks-that-Learn-to-Pronounce-Text",
            "title": {
                "fragments": [],
                "text": "Parallel Networks that Learn to Pronounce"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "H hierarchical clustering techniques applied to NETtalk suggest that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units, which suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60666828,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "424710825d726e10b016204ed2bc979e2a342d10",
            "isKey": false,
            "numCitedBy": 336,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The real-time recurrent learning algorithm is a gradient-following learning algorithm for completely recurrent networks running in continually sampled time. Here we use a series of simulation experiments to investigate the power and properties of this algorithm. In the recurrent networks studied here, any unit can be connected to any other, and any unit can receive external input. These networks run continually in the sense that they sample their inputs on every update cycle, and any unit can have a training target on any cycle. The storage required and computation time on each step are independent of time and are completely determined by the size of the network, so no prior knowledge of the temporal structure of the task being learned is required. The algorithm is nonlocal in the sense that each unit must have knowledge of the complete recurrent weight matrix and error vector. The algorithm is computationally intensive in sequential computers, requiring a storage capacity of the order of the thi..."
            },
            "slug": "Experimental-Analysis-of-the-Real-time-Recurrent-Williams-Zipser",
            "title": {
                "fragments": [],
                "text": "Experimental Analysis of the Real-time Recurrent Learning Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A series of simulation experiments are used to investigate the power and properties of the real-time recurrent learning algorithm, a gradient-following learning algorithm for completely recurrent networks running in continually sampled time."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8899009"
                        ],
                        "name": "R. de Mori",
                        "slug": "R.-de-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "de Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. de Mori"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13927858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ab73467f48f9c453be07c389c5dd1d1bfa70f25",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel backpropagation learning algorithm for a particular class of dynamic neural networks in which some units have a local feedback is proposed. Hence these networks can be trained to respond to sequences of input patterns. This algorithm has the same order of space and time requirements as backpropagation applied to feedforward networks. The authors present experimental results and comparisons with a speech recognition problem.<<ETX>>"
            },
            "slug": "BPS:-a-learning-algorithm-for-capturing-the-dynamic-Gori-Bengio",
            "title": {
                "fragments": [],
                "text": "BPS: a learning algorithm for capturing the dynamic nature of speech"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A novel backpropagation learning algorithm for a particular class of dynamic neural networks in which some units have a local feedback is proposed, which can be trained to respond to sequences of input patterns."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140752"
                        ],
                        "name": "Charles R. Rosenberg",
                        "slug": "Charles-R.-Rosenberg",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Rosenberg",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles R. Rosenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "Connectionist models have pro ven su ccessful in a variety of pattern recognition tasks (e.g. , [2] [3])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12926318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de996c32045df6f7b404dda2a753b6a9becf3c08",
            "isKey": false,
            "numCitedBy": 1885,
            "numCiting": 229,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes NETtalk, a class of massively-parallel network systems that learn to convert English text to speech. The memory representations for pronunciations are learned by practice and are shared among many processing units. The performance of NETtalk has some similarities with observed human performance. (i) The learning follows a power law. (ii) The more words the network learns, the better it is at generalizing and correctly pronouncing new words, (iii) The performance of the network degrades very slowly as connections in the network are damaged: no single link or processing unit is essential. (iv) Relearning after damage is much faster than learning during the original training. (v) Distributed or spaced practice is more effective for long-term retention than massed practice. Network models can be constructed that have the same performance and learning characteristics on a particular task, but differ completely at the levels of synaptic strengths and single-unit responses. However, hierarchical clustering techniques applied to NETtalk reveal that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units. This suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations."
            },
            "slug": "Parallel-Networks-that-Learn-to-Pronounce-English-Sejnowski-Rosenberg",
            "title": {
                "fragments": [],
                "text": "Parallel Networks that Learn to Pronounce English Text"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "H hierarchical clustering techniques applied to NETtalk reveal that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units, which suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations."
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14711886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce9a21b93ba29d4145a8ef6bf401e77f261848de",
            "isKey": false,
            "numCitedBy": 3832,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks. These algorithms have (1) the advantage that they do not require a precisely defined training interval, operating while the network runs; and (2) the disadvantage that they require nonlocal communication in the network being trained and are computationally expensive. These algorithms allow networks having recurrent connections to learn complex tasks that require the retention of information over time periods having either fixed or indefinite length."
            },
            "slug": "A-Learning-Algorithm-for-Continually-Running-Fully-Williams-Zipser",
            "title": {
                "fragments": [],
                "text": "A Learning Algorithm for Continually Running Fully Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 134
                            }
                        ],
                        "text": "This strategy of building a priori structural knowledge into the network directly can often speed learning and improve generalization (Hinton, 1989)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 110
                            }
                        ],
                        "text": "This means that a large number of training examples must be used or else the network will not generalize well (Hinton, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7840452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a57c6d627ffc667ae3547073876c35d6420accff",
            "isKey": false,
            "numCitedBy": 1574,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Connectionist-Learning-Procedures-Hinton",
            "title": {
                "fragments": [],
                "text": "Connectionist Learning Procedures"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144473519"
                        ],
                        "name": "M. Mozer",
                        "slug": "M.-Mozer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mozer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mozer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 161
                            }
                        ],
                        "text": "Wickelgren (1969) has suggested a representational scheme that seems to satisfy these criteria and has been applied successfully in several connectionist models (Mozer, 1991; Rumelhart & McClelland, 1986; Seidenberg, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5125059,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1762498d7ef09cc706b551c54ce6894a7b2ee14d",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "\"The Perception of Multiple Objects \"describes a neurally inspired computational model of two-dimensional object recognition and spatial attention that can explain many characteristics of human visual perception. The model, called MORSEL (named for its ability to perform Multiple Object Recognition and attentional Selection), is unique in providing a broad and unified explanation for a wide range of experimental psychological data on visual perception and attention. Although it draws on existing theoretical perspectives from cognitive psychology, it is a fully mechanistic account, not just a functional-level theory.MORSEL has been trained to recognize letters and words in various positions on its \"retina.\" Following training, it can also recognize several items at once, subject to capacity limitations. The model makes predictions about what sorts of information the visual system can process in parallel and what sorts must be processed serially.Through simulation experiments, chiefly in letter and word perception, MORSEL has been shown to account for a variety of psychological phenomena, including perceptual errors that arise when several items appear simultaneously in the visual field, facilitatory effects of context and redundant information, attentional phenomena, visual search performance, and behaviors exhibited by neurological patients with acquired dyslexia."
            },
            "slug": "Perception-of-multiple-objects-a-connectionist-Mozer",
            "title": {
                "fragments": [],
                "text": "Perception of multiple objects - a connectionist approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The model, called MORSEL, is unique in providing a broad and unified explanation for a wide range of experimental psychological data on visual perception and attention, and draws on existing theoretical perspectives from cognitive psychology."
            },
            "venue": {
                "fragments": [],
                "text": "Neural network modeling and connectionism"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48429353"
                        ],
                        "name": "Pineda",
                        "slug": "Pineda",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Pineda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pineda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40994937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6602985bd326d9996c68627b56ed389e2c90fd08",
            "isKey": false,
            "numCitedBy": 905,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "An adaptive neural network with asymmetric connections is introduced. This network is related to the Hopfield network with graded neurons and uses a recurrent generalization of the \\ensuremath{\\delta} rule of Rumelhart, Hinton, and Williams to modify adaptively the synaptic weights. The new network bears a resemblance to the master/slave network of Lapedes and Farber but it is architecturally simpler."
            },
            "slug": "Generalization-of-back-propagation-to-recurrent-Pineda",
            "title": {
                "fragments": [],
                "text": "Generalization of back-propagation to recurrent neural networks."
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "An adaptive neural network with asymmetric connections is introduced that bears a resemblance to the master/slave network of Lapedes and Farber but it is architecturally simpler."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review letters"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2845294"
                        ],
                        "name": "Y. Miyata",
                        "slug": "Y.-Miyata",
                        "structuredName": {
                            "firstName": "Yoshiro",
                            "lastName": "Miyata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Miyata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 56
                            }
                        ],
                        "text": "Such decay connections have proven useful in other work (Jordan, 1987; Miyata, 1988; Stornetta et al., 1987; Watrous & Shastri, 1987)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 63237298,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b20d5768fc83686047379fc691b8e8c045d6276",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Models of action control have focused on the process of executing pre-specified action sequences, and largely neglected the process of learning and planning in the selection of appropriate actions. This thesis develops a theory of action control in which both planning and execution of actions are the developmental product of learning. The first section presents a framework for learning by interacting with the environment and illustrates planning of actions may proceed from a partially specified environmental state given as the goal. By interacting with the environment the mappings between its actions and their effect on the environment are first established. When planning actions, these mappings are used iteratively to find an action plan. An analysis is presented showing the assumptions under which the system can find an appropriate action plan. This framework is implemented as a parallel distributed processing network and demonstrated in an application to a ship navigation task used by Anzai (1984). The second section focuses on execution of actions and presents a model of skill learning in which performance becomes faster as representations develop for increasingly complex sequences in a hierarchical sequential network. The model exhibits a number of characteristics similar to those observed empirically, including the power law, digraph frequency effect, and frequency effects in action errors."
            },
            "slug": "The-learning-and-planning-of-actions-Miyata",
            "title": {
                "fragments": [],
                "text": "The learning and planning of actions"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A theory of action control is developed in which both planning and execution of actions are the developmental product of learning, and a model of skill learning in which performance becomes faster as representations develop for increasingly complex sequences in a hierarchical sequential network is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748557"
                        ],
                        "name": "P. Smolensky",
                        "slug": "P.-Smolensky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Smolensky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Smolensky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14915217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a08f1b9d48c4a3ba5b3672dccafd0e9434e3d1b",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of stimuli presenting views of some environment, how can one characterize the natural modules or \"objects\" that compose the environment? Should a given set of items be encoded as a collection of instances or as a set of rules? Restricted formulations of these questions are addressed by analysis within a new mathematical framework that describes stochastic parallel computation. An algorithm is given for simulating this computation once schemas encoding the modules of the environment have been selected. The concept of computational temperature is introduced. As this temperature is lowered, the system appears to display a dramatic tendency to interpret input, even if the evidence for any particular interpretation is very weak."
            },
            "slug": "Schema-Selection-and-Stochastic-Inference-in-Smolensky",
            "title": {
                "fragments": [],
                "text": "Schema Selection and Stochastic Inference in Modular Environments"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The concept of computational temperature is introduced and the system appears to display a dramatic tendency to interpret input, even if the evidence for any particular interpretation is very weak."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144473519"
                        ],
                        "name": "M. Mozer",
                        "slug": "M.-Mozer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mozer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mozer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60254585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d68d546029bdc4bc6644a874e788556f60dc7c6",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : A challenging problem for connectionist models is the representation of varying-length sequences (e.g., the sequence of phonemes that compose a word). One representation that has been proposed involves encoding each sequence element with respect to its local context; this is known as a \"Wickelfeature\" representation. Handcrafted Wickelfeature representations suffer from a number of limitations, as pointed out by Pinker and Prince (1988). However, these limitations can be avoided if the representation is constructed with a priori knowledge of the set of possible sequences. This paper proposes a specialized connectionist network architecture and learning algorithm for the discovery of faithful Wickelfeature representations -- ones that do not lose critical information about the sequence to be encoded. The architecture is applied to a simplified version of Rumelhart and MeClelland's (1986) verb past-tense model."
            },
            "slug": "Discovering-Faithful-`Wickelfeature'-in-a-Network-Mozer",
            "title": {
                "fragments": [],
                "text": "Discovering Faithful `Wickelfeature' Representations in a Connectionist Network"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper proposes a specialized connectionist network architecture and learning algorithm for the discovery of faithful Wickelfeature representations -- ones that do not lose critical information about the sequence to be encoded."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60541109,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9f7d5a98f22bd880f42775f6300ae984ebcfc8c2",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Some Important Facts about Speech, The Trace Model, Factors Influencing Phoneme Identification, The Time Course of Spoken Word Recognition, General Discussion, Conclusion, Acknowledgments"
            },
            "slug": "Interactive-processes-in-speech-perception:-the-McClelland-Elman",
            "title": {
                "fragments": [],
                "text": "Interactive processes in speech perception: the TRACE model"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter contains sections titled: Some Important Facts about Speech, The Trace Model, Factors Influencing Phoneme Identification, The Time Course of Spoken Word Recognition, General Discussion, Conclusion, Acknowledgments."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29951691"
                        ],
                        "name": "Joan L. Bybee",
                        "slug": "Joan-L.-Bybee",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bybee",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan L. Bybee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4354494"
                        ],
                        "name": "D. Slobin",
                        "slug": "D.-Slobin",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Slobin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Slobin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 66
                            }
                        ],
                        "text": "The categories are based loosely on a set suggested by Byb ee and Slobin [28] ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "The categories are based loosely on a set suggested by Byb ee and Slobin [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 63048002,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ec1bed2d0c548ba48c7a8466c8a9925286899f4d",
            "isKey": false,
            "numCitedBy": 539,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Consistent error patterns in English past-tense forms are reported for three age groups: preschoolers, 8-10-year-olds, and adults. It is argued that, although irregular forms are rote-learned, speakers make generalizations about such forms. Such a generalization is defined as a SCHEMA which describes general phonological properties of a morphological class, and is used in organizing and accessing the lexicon. Schemas for the English past tense develop and change with age, yielding implications for both acquisitional and diachronic theory.*"
            },
            "slug": "Rules-and-schemas-in-the-development-and-use-of-the-Bybee-Slobin",
            "title": {
                "fragments": [],
                "text": "Rules and schemas in the development and use of the English past tense"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "2 Almeida [20] and Pineda [21] have proposed a variation of the backpropagation algorithm for recurrent networks that does not need an activity-level history."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "However, the most promisi ng and po pular algorithm , backpropagation [20], is design ed for feedforward net work s."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19355,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Each phoneme was encoded by a set of four trinary acoustic features (see [1], table 5) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "T he corpus of verbs was borr owed from a psychological model of Rumelhart and McC lelland [1] designed to account for children 's acquisition of verb pas t t enses ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "I will call these units Wickelphones , aft er the terminology of Rumelhart and McClelland [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 0
                            }
                        ],
                        "text": "Rumelhart and McClelland reduced the number of Wickelphones by devising a more compact and dis tributed encoding that depended on features of phonemes rather than the phonemes t hemselves."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "The architecture has been used to implement a temporal version of Rumelhart and McClelland's verb past-tense model [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 197
                            }
                        ],
                        "text": "My interest in studying this problem was t o see whether t he focused recu rr ent network cou ld, given t ime-varying inpu ts , learn something like the W ickelement representation pres upposed by Rumelhart and McClelland's model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 24
                            }
                        ],
                        "text": "Dave Rumelhart and J ay McClelland were kind enough to provide me with the phonological encoding and classification of verbs from their simu lation work."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 162
                            }
                        ],
                        "text": "Wickelgr en [23J has suggest ed a represent ational scheme that seems to satisfy these criteria and has been applied successfully in several connectionist models [1,24-26] ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On learni ng the past tenses of English verbs"
            },
            "venue": {
                "fragments": [],
                "text": "Parallel distri buted processing: Explorations in the microstructure of cognition. Vol. II: Psychological and biological models, J .L. McClelland and D.E. Rumelhart, eds., (MIT Press/Bradford Books, Cambridge, 1986) 216-271."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116530952"
                        ],
                        "name": "Wayne A. Wickelgran",
                        "slug": "Wayne-A.-Wickelgran",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Wickelgran",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wayne A. Wickelgran"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143755179,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2da1dd84c0679f0687a1f3e239f266c4396f4526",
            "isKey": false,
            "numCitedBy": 373,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Context-sensitive-coding,-associative-memory,-and-Wickelgran",
            "title": {
                "fragments": [],
                "text": "Context-sensitive coding, associative memory, and serial order in (speech) behavior."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2020074"
                        ],
                        "name": "A. Lapedes",
                        "slug": "A.-Lapedes",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Lapedes",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lapedes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63072477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56757a7ea9fd7e2e5ad99bf200f40adf33d756a1",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nonlinear-Signal-Processing-Using-Neural-Networks-Lapedes",
            "title": {
                "fragments": [],
                "text": "Nonlinear Signal Processing Using Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144473519"
                        ],
                        "name": "M. Mozer",
                        "slug": "M.-Mozer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mozer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mozer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728478"
                        ],
                        "name": "D. Norman",
                        "slug": "D.-Norman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Norman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Norman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 162
                            }
                        ],
                        "text": "Wickelgr en [23J has suggest ed a represent ational scheme that seems to satisfy these criteria and has been applied successfully in several connectionist models [1,24-26] ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61269762,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fdb0f2020d4d909b56c0b694e295c8cb9cb83efe",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-perception-of-multiple-objects:-a-parallel,-Mozer-Norman",
            "title": {
                "fragments": [],
                "text": "The perception of multiple objects: a parallel, distributed processing approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2099637863"
                        ],
                        "name": "Mozer",
                        "slug": "Mozer",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Mozer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mozer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 162
                            }
                        ],
                        "text": "Wickelgr en [23J has suggest ed a represent ational scheme that seems to satisfy these criteria and has been applied successfully in several connectionist models [1,24-26] ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60188984,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e58c5bc394f96a6882a3c8730e46be955cdd8414",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Early-parallel-processing-in-reading:-a-approach.-Mozer",
            "title": {
                "fragments": [],
                "text": "Early parallel processing in reading: a connectionist approach. Technical report, April-November 1986"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Jordan [19] and Sto rnetta, Hogg , and Hub erman [17] have explored this approach using fixed weights that do not change with experience."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 56
                            }
                        ],
                        "text": "Such decay connections have proven useful in other work [17-19 ,27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 56723681,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d76aafbeb54575859441a442376766c597f6bb52",
            "isKey": false,
            "numCitedBy": 1102,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Attractor-dynamics-and-parallelism-in-a-sequential-Jordan",
            "title": {
                "fragments": [],
                "text": "Attractor dynamics and parallelism in a connectionist sequential machine"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068289963"
                        ],
                        "name": "L. B. Almeida",
                        "slug": "L.-B.-Almeida",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Almeida",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. B. Almeida"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "2 Almeida [20] and Pineda [21] have proposed a variation of the backpropagation algorithm for recurrent networks that does not need an activity-level history."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58820035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8be3f21ab796bd9811382b560507c1c679fae37f",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-learning-rule-for-asynchronous-perceptrons-with-a-Almeida",
            "title": {
                "fragments": [],
                "text": "A learning rule for asynchronous perceptrons with feedback in a combinatorial environment"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53796860,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ade4934db522fe6d634ff6f48887da46eedb4d1",
            "isKey": false,
            "numCitedBy": 903,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-distributed-representations-of-concepts.-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning distributed representations of concepts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2683931"
                        ],
                        "name": "J. Freyd",
                        "slug": "J.-Freyd",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Freyd",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Freyd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26599790,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "427256332d5234c9a43d71b04fbfe4533c97aeb6",
            "isKey": false,
            "numCitedBy": 510,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Dynamic-mental-representations.-Freyd",
            "title": {
                "fragments": [],
                "text": "Dynamic mental representations."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lear ning t o represent state Unpublished master's thes is"
            },
            "venue": {
                "fragments": [],
                "text": "Lear ning t o represent state Unpublished master's thes is"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rules and schem as in the developm ent and use of the English past t ense"
            },
            "venue": {
                "fragments": [],
                "text": "Language"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Alternatively, the weights mu st be cons traine d in some manner so as to reduce the number of free paramet ers [13] [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 247
                            }
                        ],
                        "text": "Previous connectionist approaches to temporal patter n r ecognit ion One popular approach to tempora l pattern recogn it ion has been t o const ruct a buffer to hold t he n most recent elements of the input sequence [6] [7] [8] [9] [10] [11] [12] [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "P honem e recognition using time-delay neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "P honem e recognition using time-delay neural networks"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 110
                            }
                        ],
                        "text": "Alternatively, the weights must be cons trained in some manner so as to reduce the number of free paramet ers [13,15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "P honeme recognition using time-delay neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report 1-0006, ATR Interpreting Telephony Resear ch Labs, Japan (1987)."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Teaching a minimally structured back propagation network to recognize speech"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Ninth Annual Conference of the Cognitive Science Society"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Word recognition and naming : A computational model and its implications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 242
                            }
                        ],
                        "text": "Previous connectionist approaches to temporal patter n r ecognit ion One popular approach to tempora l pattern recogn it ion has been t o const ruct a buffer to hold t he n most recent elements of the input sequence [6] [7] [8] [9] [10] [11] [12] [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the National A cademy of Sciences"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National A cademy of Sciences"
            },
            "year": 1896
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 216
                            }
                        ],
                        "text": "Previous connectionist approaches to temporal patter n r ecognit ion One popular approach to tempora l pattern recogn it ion has been t o const ruct a buffer to hold t he n most recent elements of the input sequence [6] [7] [8] [9] [10] [11] [12] [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exploiting lawful variability in the speech wave,\" in In variance and varia bility in speech proc esses"
            },
            "venue": {
                "fragments": [],
                "text": "Exploiting lawful variability in the speech wave,\" in In variance and varia bility in speech proc esses"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalization of back prop agation to recurre nt neural net works"
            },
            "venue": {
                "fragments": [],
                "text": "Memo SIA-63-87, Johns Hopkins Univer sity, Applied Physics Laboratory, Laurel, MD (1987)."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalization of back prop agation t o recurre nt neural net works"
            },
            "venue": {
                "fragments": [],
                "text": "Generalization of back prop agation t o recurre nt neural net works"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Schema selection and stochas tic inference in mod ula r environments , \" P roceedings of the Sixth An nual Conference on Artificial Int el - ligence AAAI - 83 ("
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to represent time"
            },
            "venue": {
                "fragments": [],
                "text": "Unpublished master's thesis,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 161
                            }
                        ],
                        "text": "Wickelgren (1969) has suggested a representational scheme that seems to satisfy these criteria and has been applied successfully in several connectionist models (Mozer, 1991; Rumelhart & McClelland, 1986; Seidenberg, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Word recognition and naming: A computational model and its implica"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 224
                            }
                        ],
                        "text": "Previous connectionist approaches to temporal patter n r ecognit ion One popular approach to tempora l pattern recogn it ion has been t o const ruct a buffer to hold t he n most recent elements of the input sequence [6] [7] [8] [9] [10] [11] [12] [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Teaching a minim ally str uctu red back propagation net work to recognize speec h"
            },
            "venue": {
                "fragments": [],
                "text": "Pro ceedings of th e Ninth Annual Conference of the Cognitive Science Society"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exploiting lawful variability in the speech wave"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 220
                            }
                        ],
                        "text": "Previous connectionist approaches to temporal patter n r ecognit ion One popular approach to tempora l pattern recogn it ion has been t o const ruct a buffer to hold t he n most recent elements of the input sequence [6] [7] [8] [9] [10] [11] [12] [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning t he hidden struc ture of speech"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of tile Acoustical Society of America"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "Freyd [5] has argued that even for som e st atic objects, perception may be dynamic in the sense that a temporal dimens ion is incorporated into the pe rceptual analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dy namic mental representations"
            },
            "venue": {
                "fragments": [],
                "text": "Psychological Review, 94 (1987) 427-438."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Early parallel processing in reading: A connectionist approach Attention and performance XII: Th e psy chology of reading"
            },
            "venue": {
                "fragments": [],
                "text": "Early parallel processing in reading: A connectionist approach Attention and performance XII: Th e psy chology of reading"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Yoshiro Miyata, personal communicat ion"
            },
            "venue": {
                "fragments": [],
                "text": "Yoshiro Miyata, personal communicat ion"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 29
                            }
                        ],
                        "text": "As was mentioned previously, Bachrach [27], Yoshiro Miyata, and I have examined a third architecture one with 1 -1 connections and nonlinear integration."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "As was mentioned previously, Bachrach [27], Yoshiro Miyata, and I have examined a third architecture one with 1 - 1 connections and nonlinear integration."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 56
                            }
                        ],
                        "text": "Such decay connections have proven useful in other work [17-19 ,27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to represent state"
            },
            "venue": {
                "fragments": [],
                "text": "Unpublished master's thes is , University of Massachusetts, Amh erst (1988)."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Teaching a minimally str uc - tu red back propagation network to recognize speech"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 122
                            }
                        ],
                        "text": "Another solution to this problem is to constrain the weights in some manner so as to reduce the number of free parameters (Lang, 1987; Le Cun, this volume; Waibel et al. 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning acoustic features from speech data using connec"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Teaching a minimally structured back"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Each phoneme was encoded by a set of four trinary acoustic features (see [1] , table 5) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "O n learni ng the past tenses of English verbs, \" in Parallel distri bu ted proc essing: Explorations in the microstructure of cognition. Vol. II: Psyc hological and biological models"
            },
            "venue": {
                "fragments": [],
                "text": "O n learni ng the past tenses of English verbs, \" in Parallel distri bu ted proc essing: Explorations in the microstructure of cognition. Vol. II: Psyc hological and biological models"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Singah al,\"Teaching a minimally str uctu red back propagation network to recognize speech,"
            },
            "venue": {
                "fragments": [],
                "text": "Pro ceedings of the Ninth Annual Conference of the Cognitive Science Society,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "Alternatively, the weights mu st be cons traine d in some manner so as to reduce the number of free paramet ers [13] [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist speech recognit ion Unp ublished P h.D. th esis pro posal"
            },
            "venue": {
                "fragments": [],
                "text": "Connectionist speech recognit ion Unp ublished P h.D. th esis pro posal"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 56
                            }
                        ],
                        "text": "Such decay connections have proven useful in other work [17-19 ,27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 45
                            }
                        ],
                        "text": "Similar arguments have been raised elsewhere [16-18]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning acoustic fea tures from speech data using connectionist networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Ninth Annual Conference of the Cognitive Science Society, Hillsdale , NJ (1987) 518-530."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "Connectionist models have pro ven su ccessful in a variety of pattern recognition tasks (e.g. , [2] [3])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lear ning distributed representations of concept s"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Eighth A nn ual Conference of the Cognitive Science Society"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "Simil ar arguments have been raised elsewhere [16] [17] [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning acoustic fea t ure s from speech da ta using connectionist networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of th e Ninth Annual Conference of the Cognitive Science Society"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "This argument is born out by empirical comparisons of learning speed using temporal versus spatial patterns made by myself and by Steven Nowlan [29]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stev en Nowlan , personal communic ation"
            },
            "venue": {
                "fragments": [],
                "text": "Stev en Nowlan , personal communic ation"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Context -sensi tive coding , associat ive memory, and serial or der in (spe ech) behavior"
            },
            "venue": {
                "fragments": [],
                "text": "Psychological R eview"
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 110
                            }
                        ],
                        "text": "Alternatively, the weights must be cons trained in some manner so as to reduce the number of free paramet ers [13,15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist speech recognit ion"
            },
            "venue": {
                "fragments": [],
                "text": "Unpublished Ph.D. th esis proposal, Carnegie-Mellon Univer sity, Pit tsburgh, PA (1987) ."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 232
                            }
                        ],
                        "text": "Previous connectionist approaches to temporal patter n r ecognit ion One popular approach to tempora l pattern recogn it ion has been t o const ruct a buffer to hold t he n most recent elements of the input sequence [6] [7] [8] [9] [10] [11] [12] [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Interactive proces ses in speech perception : The TRACE model Parallel distr ibuted processing: Explorations in the microstructure of cogni tion . Vol. II : Psychological and biological m odels"
            },
            "venue": {
                "fragments": [],
                "text": "Interactive proces ses in speech perception : The TRACE model Parallel distr ibuted processing: Explorations in the microstructure of cogni tion . Vol. II : Psychological and biological m odels"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "Freyd [5] has argue d t hat even for som e st atic objects , perception may be dyn amic in the sense t hat a t emporal dimens ion is incor por at ed into the pe rceptual analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dy namic mental represent ations"
            },
            "venue": {
                "fragments": [],
                "text": "Psy chologi cal Review"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning acoustic features from speech data using connectionist networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Ninth Annua ! Conference of the Cognitive Science Society"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 26,
            "methodology": 7,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 63,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Focused-Backpropagation-Algorithm-for-Temporal-Mozer/7fb4d10f6d2ee3133135958aefd50bf22dcced9d?sort=total-citations"
}