{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787006"
                        ],
                        "name": "Ruifang Ge",
                        "slug": "Ruifang-Ge",
                        "structuredName": {
                            "firstName": "Ruifang",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruifang Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 26
                            }
                        ],
                        "text": "A more recent approach by Ge & Mooney (2005) adds detailed semantics to a stateof-the-art statistical parser."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2046600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ae207cfaf01dc2b6799da67f454190b34994870",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a learning semantic parser, Scissor, that maps natural-language sentences to a detailed, formal, meaning-representation language. It first uses an integrated statistical parser to produce a semantically augmented parse tree, in which each non-terminal node has both a syntactic and a semantic label. A compositional-semantics procedure is then used to map the augmented parse tree into a final meaning representation. We evaluate the system in two domains, a natural-language database interface and an interpreter for coaching instructions in robotic soccer. We present experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches."
            },
            "slug": "A-Statistical-Semantic-Parser-that-Integrates-and-Ge-Mooney",
            "title": {
                "fragments": [],
                "text": "A Statistical Semantic Parser that Integrates Syntax and Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A learning semantic parser that maps natural-language sentences to a detailed, formal, meaning-representation language and presents experimental results demonstrating that Scissor produces more accurate semantic representations than several previous approaches."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710450"
                        ],
                        "name": "J. Zelle",
                        "slug": "J.-Zelle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Zelle",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 87
                            }
                        ],
                        "text": "The GEOQUERYlanguage consists of Prolog queries augmented with several metapredicates (Zelle & Mooney 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 65
                            }
                        ],
                        "text": "All rights reserved.\nping sentences to a logical query language (Zelle & Mooney 1996; Tang & Mooney 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 77
                            }
                        ],
                        "text": "We ran two versions of CHILL , one based on the CHILLIN induction algorithm (Zelle & Mooney 1996), the other based on COCKTAIL (Tang & Mooney 2001), which uses multiple clause constructors based on the CHILLIN and mFOIL algorithms (Lavrac & Dzeroski 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 113
                            }
                        ],
                        "text": "The first one is a database query language as used in a previously-developed corpus of U.S. geography questions (Zelle & Mooney 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 57
                            }
                        ],
                        "text": "Queries were then manually translated into logical form (Zelle & Mooney 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 263135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7c0e47f8b768258b7d536c21b218e6c46ab8791",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural-language interface for database queries. CHILL treats parser acquisition as the learning of search-control rules within a logic program representing a shift-reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge. Starting with a general framework for constructing a suitable logical form, CHILL is able to train on a corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries. Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart. These results demonstrate the ability of a corpus-based system to produce more than purely syntactic representations. They also provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "slug": "Learning-to-Parse-Database-Queries-Using-Inductive-Zelle-Mooney",
            "title": {
                "fragments": [],
                "text": "Learning to Parse Database Queries Using Inductive Logic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a preexisting, hand-crafted counterpart, and provide direct evidence of the utility of an empirical approach at the level of a complete natural language application."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 2"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36445704"
                        ],
                        "name": "Ana-Maria Popescu",
                        "slug": "Ana-Maria-Popescu",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Popescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Popescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2177004"
                        ],
                        "name": "Alex Armanasu",
                        "slug": "Alex-Armanasu",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Armanasu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Armanasu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061196271"
                        ],
                        "name": "David Ko",
                        "slug": "David-Ko",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Ko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3321874"
                        ],
                        "name": "A. Yates",
                        "slug": "A.-Yates",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Yates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yates"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1942340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49a8ae5eb474e7f6ce3669f9c55efaee1d43cdec",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural Language Interfaces to Databases (NLIs) can benefit from the advances in statistical parsing over the last fifteen years or so. However, statistical parsers require training on a massive, labeled corpus, and manually creating such a corpus for each database is prohibitively expensive. To address this quandary, this paper reports on the PRECISE NLI, which uses a statistical parser as a \"plug in\". The paper shows how a strong semantic model coupled with \"light re-training\" enables PRECISE to overcome parser errors, and correctly map from parsed questions to the corresponding SQL queries. We discuss the issues in using statistical parsers to build database-independent NLIs, and report on experimental results with the benchmark ATIS data set where PRECISE achieves 94% accuracy."
            },
            "slug": "Modern-Natural-Language-Interfaces-to-Databases:-Popescu-Armanasu",
            "title": {
                "fragments": [],
                "text": "Modern Natural Language Interfaces to Databases: Composing Statistical Parsing with Semantic Tractability"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The paper shows how a strong semantic model coupled with \"light re-training\" enables PRECISE to overcome parser errors, and correctly map from parsed questions to the corresponding SQL queries."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190169"
                        ],
                        "name": "L. Tang",
                        "slug": "L.-Tang",
                        "structuredName": {
                            "firstName": "Lappoon",
                            "lastName": "Tang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 71
                            }
                        ],
                        "text": "On the CLANG corpus, both versions of SILT do a lot better than either COCKTAIL or CHILLIN ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 86
                            }
                        ],
                        "text": "All rights reserved.\nping sentences to a logical query language (Zelle & Mooney 1996; Tang & Mooney 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 7
                            }
                        ],
                        "text": "First, COCKTAIL and CHILLIN do not exploit the formal grammar of the target language."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 128
                            }
                        ],
                        "text": "We ran two versions of CHILL , one based on the CHILLIN induction algorithm (Zelle & Mooney 1996), the other based on COCKTAIL (Tang & Mooney 2001), which uses multiple clause constructors based on the CHILLIN and mFOIL algorithms (Lavrac & Dzeroski 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 8
                            }
                        ],
                        "text": "Second, COCKTAIL and CHILLIN use a shift-reduce parsing framework to parse a sentence from left to right."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 24
                            }
                        ],
                        "text": "On the GEOQUERY corpus, COCKTAIL has the best recall but the worst precision."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 138
                            }
                        ],
                        "text": "By learning to transform natural language (NL) to a complete formal language, NL interfaces to complex computing and AI systems can be more easily developed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16100071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f60d8dd8ca3a7dfa7d0a14988af73084ad93619d",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we explored a learning approach which combines different learning methods in inductive logic programming (ILP) to allow a learner to produce more expressive hypotheses than that of each individual learner. Such a learning approach may be useful when the performance of the task depends on solving a large amount of classification problems and each has its own characteristics which may or may not fit a particular learning method. The task of semantic parser acquisition in two different domains was attempted and preliminary results demonstrated that such an approach is promising."
            },
            "slug": "Using-Multiple-Clause-Constructors-in-Inductive-for-Tang-Mooney",
            "title": {
                "fragments": [],
                "text": "Using Multiple Clause Constructors in Inductive Logic Programming for Semantic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "Preliminary results demonstrated that an approach which combines different learning methods in inductive logic programming (ILP) to allow a learner to produce more expressive hypotheses than that of each individual learner is promising."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36445704"
                        ],
                        "name": "Ana-Maria Popescu",
                        "slug": "Ana-Maria-Popescu",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Popescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Popescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690271"
                        ],
                        "name": "Henry A. Kautz",
                        "slug": "Henry-A.-Kautz",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Kautz",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henry A. Kautz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9101619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b50f78c9534182a09c060580811274928702b38d",
            "isKey": false,
            "numCitedBy": 465,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The need for Natural Language Interfaces to databases (NLIs) has become increasingly acute as more and more people access information through their web browsers, PDAs, and cell phones. Yet NLIs are only usable if they map natural language questions to SQL queries correctly. As Schneiderman and Norman have argued, people are unwilling to trade reliable and predictable user interfaces for intelligent but unreliable ones. In this paper, we introduce a theoretical framework for reliable NLIs, which is the foundation for the fully implemented Precise NLI. We prove that, for a broad class of semantically tractable natural language questions, Precise is guaranteed to map each question to the corresponding SQL query. We report on experiments testing Precise on several hundred questions drawn from user studies over three benchmark databases. We find that over 80% of the questions are semantically tractable questions, which Precise answers correctly. Precise automatically recognizes the 20% of questions that it cannot handle, and requests a paraphrase. Finally, we show that Precise compares favorably with Mooney's learning NLI and with Microsoft's English Query product"
            },
            "slug": "Towards-a-theory-of-natural-language-interfaces-to-Popescu-Etzioni",
            "title": {
                "fragments": [],
                "text": "Towards a theory of natural language interfaces to databases"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proves that, for a broad class of semantically tractable natural language questions, Precise is guaranteed to map each question to the corresponding SQL query, and shows that Precise compares favorably with Mooney's learning NLI and with Microsoft's English Query product."
            },
            "venue": {
                "fragments": [],
                "text": "IUI '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793218"
                        ],
                        "name": "D. Gildea",
                        "slug": "D.-Gildea",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gildea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gildea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 104
                            }
                        ],
                        "text": "Most recent work in corpus-based semantic parsing has focused on shallow thematic (case-role) analysis (Gildea & Jurafsky 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207747200,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "fcb7e6cf3b4c349b729fa0444bbb5ac1f99c3f3a",
            "isKey": false,
            "numCitedBy": 882,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame. Given an input sentence and a target word and frame, the system labels constituents with either abstract semantic roles, such as Agent or Patient, or more domain-specific semantic roles, such as Speaker, Message, and Topic. The system is based on statistical classifiers trained on roughly 50,000 sentences that were hand-annotated with semantic roles by the FrameNet semantic labeling project. We then parsed each training sentence into a syntactic tree and extracted various lexical and syntactic features, including the phrase type of each constituent, its grammatical function, and its position in the sentence. These features were combined with knowledge of the predicate verb, noun, or adjective, as well as information such as the prior probabilities of various combinations of semantic roles. We used various lexical clustering algorithms to generalize across possible fillers of roles. Test sentences were parsed, were annotated with these features, and were then passed through the classifiers. Our system achieves 82 accuracy in identifying the semantic role of presegmented constituents. At the more difficult task of simultaneously segmenting constituents and identifying their semantic role, the system achieved 65 precision and 61 recall. Our study also allowed us to compare the usefulness of different features and feature combination methods in the semantic role labeling task. We also explore the integration of role labeling with statistical syntactic parsing and attempt to generalize to predicates unseen in the training data."
            },
            "slug": "Automatic-Labeling-of-Semantic-Roles-Gildea-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Automatic Labeling of Semantic Roles"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame, based on statistical classifiers trained on roughly 50,000 sentences that were hand-annotated with semantic roles by the FrameNet semantic labeling project."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2023469"
                        ],
                        "name": "D. Bikel",
                        "slug": "D.-Bikel",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bikel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bikel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 89
                            }
                        ],
                        "text": "Syntactic parses required by SILT \u2019s tree-based version were generated by Collins\u2019 parser (Bikel 2004) trained with the WSJ treebank and gold-standard parse trees of the training sentences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 862713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0606291dae96446e812ea8f09d9fbdc6acc3ec37",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This article documents a large set of heretofore unpublished details Collins used in his parser, such that, along with Collins' (1999) thesis, this article contains all information necessary to duplicate Collins' benchmark results. Indeed, these as-yet-unpublished details account for an 11 relative increase in error from an implementation including all details to a clean-room implementation of Collins' model. We also show a cleaner and equally well-performing method for the handling of punctuation and conjunction and reveal certain other probabilistic oddities about Collins' parser. We not only analyze the effect of the unpublished details, but also reanalyze the effect of certain well-known details, revealing that bilexical dependencies are barely used by the model and that head choice is not nearly as important to overall parsing performance as once thought. Finally, we perform experiments that show that the true discriminative power of lexicalization appears to lie in the fact that unlexicalized syntactic structures are generated conditioning on the headword and its part of speech."
            },
            "slug": "Intricacies-of-Collins'-Parsing-Model-Bikel",
            "title": {
                "fragments": [],
                "text": "Intricacies of Collins' Parsing Model"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A large set of heretofore unpublished details Collins used in his parser are documents, such that, along with Collins' (1999) thesis, this article contains all information necessary to duplicate Collins' benchmark results."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145147566"
                        ],
                        "name": "S. Muggleton",
                        "slug": "S.-Muggleton",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Muggleton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muggleton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117343701"
                        ],
                        "name": "C. Feng",
                        "slug": "C.-Feng",
                        "structuredName": {
                            "firstName": "Cao",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Feng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 60
                            }
                        ],
                        "text": "This process is similar to the learning algorithm of GOLEM (Muggleton & Feng 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14992676,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a669636e0ada62a0fb444e95435e24fdbdf4dbd",
            "isKey": false,
            "numCitedBy": 848,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently there has been increasing interest in systems which induce rst order logic programs from examples. However, many diiculties need to be overcome. Well-known algorithms fail to discover correct logical descriptions for large classes of interesting predicates , due either to the intractability of search or overly strong limitations applied to the hypothesis space. In contrast, search is avoided within Plotkin's framework of relative least general generalisation (rlgg). It is replaced by the process of constructing a unique clause which covers a set of examples relative to given background knowledge. However, such a clause can in the worst case contain innnitely many literals, or at best grow exponentially with the number of examples involved. In this paper we introduce the concept of h-easy rlgg clauses and show that they have nite length. We also prove that the length of a certain class of \\determinate\" rlgg is bounded by a polynomial function of certain features of the background knowledge. This function is independent of the number of examples used to construct them. An existing implementation called GOLEM is shown to be capable of inducing many interesting logic programs which have not been demonstrated to be learnable using other algorithms."
            },
            "slug": "Efficient-Induction-of-Logic-Programs-Muggleton-Feng",
            "title": {
                "fragments": [],
                "text": "Efficient Induction of Logic Programs"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The concept of h-easy rlgg clauses is introduced and it is proved that the length of a certain class of \\determinate\" r lgg is bounded by a polynomial function of certain features of the background knowledge."
            },
            "venue": {
                "fragments": [],
                "text": "ALT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114607071"
                        ],
                        "name": "Gregory Kuhlmann and Peter Stone and Raymond J. Mooney and Shavlik",
                        "slug": "Gregory-Kuhlmann-and-Peter-Stone-and-Raymond-J.-and",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Shavlik",
                            "middleNames": [
                                "Kuhlmann",
                                "and",
                                "Peter",
                                "Stone",
                                "and",
                                "Raymond",
                                "J.",
                                "Mooney",
                                "and"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Kuhlmann and Peter Stone and Raymond J. Mooney and Shavlik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 127
                            }
                        ],
                        "text": "The pattern of a rule is matched against phrases in the sentence, and when successfully matched, the corresponding template is instantiated to create part of the formal representation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9265394,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd2d5ddc0399e0b87c339ebea4042ef2ad6f0317",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe our current efforts towards creating a reinforcement learner that learns both from reinforcements provided by its environment and from human-generated advice. Our research involves two complementary components: (a) mapping advice expressed in English to a formal advice language and (b) using advice expressed in a formal notation in a reinforcement learner. We use a subtask of the challenging RoboCup simulated soccer task (Noda et al. 1998) as our testbed."
            },
            "slug": "Guiding-a-Reinforcement-Learner-with-Natural-in-Shavlik",
            "title": {
                "fragments": [],
                "text": "Guiding a Reinforcement Learner with Natural Language Advice: Initial Results in RoboCup Soccer"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This work describes the current efforts towards creating a reinforcement learner that learns both from reinforcements provided by its environment and from human-generated advice, using advice expressed in a formal notation in a reinforcement learners."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 28
                            }
                        ],
                        "text": "This example uses string-based transformation rules, but it can be easily extended to tree-based rules."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 96
                            }
                        ],
                        "text": "Although transformation rules have been used in other NLP tasks such as part-of-speech tagging (Brill 1995), our approach differs substantially from Brill\u2019s method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 134248,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "2b2eb4a9bb146e3ffaa0b025fba0ed14240c683f",
            "isKey": false,
            "numCitedBy": 1821,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of injection molding wherein a pair of separable mold plates are initially urged together and fluid plastic is injected into a mold cavity formed between the mold plates to form an article. The injection pressure of the fluid plastic is utilized to generate forces sufficient to overcome the internal forces urging the mold plates apart and thus hold the mold plates together until the material being molded solidifies either by cooling, chemical reaction or phase change."
            },
            "slug": "Transformation-Based-Error-Driven-Learning-and-A-in-Brill",
            "title": {
                "fragments": [],
                "text": "Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "Injection molding wherein a pair of separable mold plates are initially urged together and fluid plastic is injected into a mold cavity formed between the mold plates to form an article."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730104"
                        ],
                        "name": "N. Lavrac",
                        "slug": "N.-Lavrac",
                        "structuredName": {
                            "firstName": "Nada",
                            "lastName": "Lavrac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lavrac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693549"
                        ],
                        "name": "S. D\u017eeroski",
                        "slug": "S.-D\u017eeroski",
                        "structuredName": {
                            "firstName": "Sa\u0161o",
                            "lastName": "D\u017eeroski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D\u017eeroski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 232
                            }
                        ],
                        "text": "We ran two versions of CHILL , one based on the CHILLIN induction algorithm (Zelle & Mooney 1996), the other based on COCKTAIL (Tang & Mooney 2001), which uses multiple clause constructors based on the CHILLIN and mFOIL algorithms (Lavrac & Dzeroski 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 36237350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58095bae1d836943bdaa52b76fa8d17cf77d06b3",
            "isKey": false,
            "numCitedBy": 931,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 Empirical inductive logic programming: introduction empirical ILP systems - an overview LINUS - using attribute-value learners in an ILP framework experiments in learning relations with LINUS ILP as search for program clauses. Part 2 Learning relations from imperfect data: handling imperfect data in ILP using heuristics to handle noise in ILP mFOIL - extending noise-handling in FOIL experiments in learning relations from noisy examples. Part 3 Applications of inductive logic programming: learning rules for early diagnosis of rheumatic diseases finite element mesh design an overview of selected ILP applications."
            },
            "slug": "Inductive-logic-programming-techniques-and-Lavrac-D\u017eeroski",
            "title": {
                "fragments": [],
                "text": "Inductive logic programming - techniques and applications"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Applications of inductive logic programming: learning rules for early diagnosis of rheumatic diseases finite element mesh design an overview of selected ILP applications."
            },
            "venue": {
                "fragments": [],
                "text": "Ellis Horwood series in artificial intelligence"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793218"
                        ],
                        "name": "D. Gildea",
                        "slug": "D.-Gildea",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Gildea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gildea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 46
                            }
                        ],
                        "text": "Experimental results are presented for two corpora, one which maps English instructions into an existing formal coaching language for simulated RoboCup soccer agents, and another which maps English U.S.-geography questions into a database query language."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 104
                            }
                        ],
                        "text": "Most recent work in corpus-based semantic parsing has focused on shallow thematic (case-role) analysis (Gildea & Jurafsky 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62182406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c274b8aac56e49e65a3827c570b2496b14429166",
            "isKey": false,
            "numCitedBy": 1099,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame. Various lexical and syntactic features are derived from parse trees and used to derive statistical classifiers from hand-annotated training data."
            },
            "slug": "Automatic-Labeling-of-Semantic-Roles-Gildea-Jurafsky",
            "title": {
                "fragments": [],
                "text": "Automatic Labeling of Semantic Roles"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This work presents a system for identifying the semantic relationships, or semantic roles, filled by constituents of a sentence within a semantic frame, derived from parse trees and hand-annotated training data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710543"
                        ],
                        "name": "V. Zue",
                        "slug": "V.-Zue",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Zue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zue"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 131
                            }
                        ],
                        "text": "The queries in this corpus are more complex than those in the ATIS database-query corpus used in the speech recognition community (Zue & Glass 2000) which makes the GEOQUERY problem harder, as also shown by the results in (Popescuet al. 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7344503,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "157f5fc669dfc440492fa01cb7fe46593ed55304",
            "isKey": false,
            "numCitedBy": 310,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": "The past decade has witnessed the emergence of a new breed of human-computer interfaces that combines several human language technologies to enable humans to converse with computers using spoken dialogue for information access, creation and processing. In this paper, we introduce the nature of these conversational interfaces and describe the underlying human language technologies on which they are based. After summarizing some of the recent progress in this area around the world, we discuss development issues faced by researchers creating these kinds of systems and present some of the ongoing and unmet research challenges in this field."
            },
            "slug": "Conversational-interfaces:-advances-and-challenges-Zue",
            "title": {
                "fragments": [],
                "text": "Conversational interfaces: advances and challenges"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The nature of these conversational interfaces is introduced and the underlying human language technologies on which they are based are described, and development issues faced by researchers creating these kinds of systems are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727076"
                        ],
                        "name": "H. Lodhi",
                        "slug": "H.-Lodhi",
                        "structuredName": {
                            "firstName": "Huma",
                            "lastName": "Lodhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lodhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144884649"
                        ],
                        "name": "C. Saunders",
                        "slug": "C.-Saunders",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Saunders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Saunders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4562073"
                        ],
                        "name": "C. Watkins",
                        "slug": "C.-Watkins",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Watkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Watkins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 104
                            }
                        ],
                        "text": "We are currently developing an improved version of SILT by exploiting the use of string and treek rnels(Lodhi et al. 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 669209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f330f1f472f860212b980bb9be81eff884f7f0e1",
            "isKey": false,
            "numCitedBy": 1643,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel kernel for comparing two text documents. The kernel is an inner product in the feature space consisting of all subsequences of length k. A subsequence is any ordered sequence of k characters occurring in the text though not necessarily contiguously. The subsequences are weighted by an exponentially decaying factor of their full length in the text, hence emphasising those occurrences which are close to contiguous. A direct computation of this feature vector would involve a prohibitive amount of computation even for modest values of k, since the dimension of the feature space grows exponentially with k. The paper describes how despite this fact the inner product can be efficiently evaluated by a dynamic programming technique. A preliminary experimental comparison of the performance of the kernel compared with a standard word feature space kernel [6] is made showing encouraging results."
            },
            "slug": "Text-Classification-using-String-Kernels-Lodhi-Saunders",
            "title": {
                "fragments": [],
                "text": "Text Classification using String Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A novel kernel is introduced for comparing two text documents consisting of an inner product in the feature space consisting of all subsequences of length k, which can be efficiently evaluated by a dynamic programming technique."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 44
                            }
                        ],
                        "text": "We also compared SILT with GEOBASE (Borland International 1988), a hand-built NL interface for the GEOQUERYdomain."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 6
                            }
                        ],
                        "text": "The second version (tree-based) uses trees (words and syntactic markers) as patterns and matches them against syntactic parse-trees of the NL sentences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 188
                            }
                        ],
                        "text": "This domain was originally chosen to test corpus-based semantic parsing due to the availability of a hand-built naturallanguage interface, GEOBASE, supplied with Turbo Prolog 2.0 (Borland International 1988)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Turbo Prolog 2.0 Reference Guide"
            },
            "venue": {
                "fragments": [],
                "text": "Turbo Prolog 2.0 Reference Guide"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69449911"
                        ],
                        "name": "Mathematical Linguistics",
                        "slug": "Mathematical-Linguistics",
                        "structuredName": {
                            "firstName": "Mathematical",
                            "lastName": "Linguistics",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathematical Linguistics"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1858908"
                        ],
                        "name": "A. Zampolli",
                        "slug": "A.-Zampolli",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Zampolli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zampolli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60379798,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "03410f1bb521fcf4355446430b40a4d25a44101a",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Linguistic-structures-processing-Linguistics-Zampolli",
            "title": {
                "fragments": [],
                "text": "Linguistic structures processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740042"
                        ],
                        "name": "L. D. Raedt",
                        "slug": "L.-D.-Raedt",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Raedt",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Raedt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730104"
                        ],
                        "name": "N. Lavrac",
                        "slug": "N.-Lavrac",
                        "structuredName": {
                            "firstName": "Nada",
                            "lastName": "Lavrac",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lavrac"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693549"
                        ],
                        "name": "S. D\u017eeroski",
                        "slug": "S.-D\u017eeroski",
                        "structuredName": {
                            "firstName": "Sa\u0161o",
                            "lastName": "D\u017eeroski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D\u017eeroski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20957467,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "b7184513e22212c4093aeee0918c3d3366a18314",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multiple-Predicate-Learning-Raedt-Lavrac",
            "title": {
                "fragments": [],
                "text": "Multiple Predicate Learning"
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 134
                            }
                        ],
                        "text": "However, relatively little research in empirical natural-language processing (NLP) has addressed the problem of learning such semantic parsers from corpora of sentences paired with their formal-language equivalents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 41
                            }
                        ],
                        "text": "The GEOQUERYlanguage consists of Prolog queries augmented with several metapredicates (Zelle & Mooney 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Users manual: RoboCup soccer server manual for soccer server version 7"
            },
            "venue": {
                "fragments": [],
                "text": "Users manual: RoboCup soccer server manual for soccer server version 7"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "AAAI-05"
            },
            "venue": {
                "fragments": [],
                "text": "AAAI-05"
            },
            "year": 1068
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text classification using string kernels.JMLR2:419\u2013444"
            },
            "venue": {
                "fragments": [],
                "text": "InProc. of 1st Conf. on Algorithmic"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 104
                            }
                        ],
                        "text": "We are currently developing an improved version of SILT by exploiting the use of string and tree k rnels(Lodhi et al. 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 104
                            }
                        ],
                        "text": "We are currently developing an improved version of SILT by exploiting the use of string and treek rnels(Lodhi et al. 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text classification using string kernels.JMLR2:419\u2013444"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. of IUI-03"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of IUI-03"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 33
                            }
                        ],
                        "text": "The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non-terminal symbols in this grammar."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 186
                            }
                        ],
                        "text": "Introduction The ability to map natural language to a formal query or command language is critical to developing more user-friendly interfaces to many computing systems (e.g. databases (Woods 1977))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lunar rocks in natural English: Explorations in natural language question answering"
            },
            "venue": {
                "fragments": [],
                "text": "Linguistic Structures Processing"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Users manual: RoboCup soccer server manual for soccer server version"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Users manual : RoboCup soccer server manual for soccer server version 7 . 07 and later"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 11,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-to-Transform-Natural-to-Formal-Languages-Kate-Wong/8dd9fd6a45afd266d48255c398429e01ea4fd6db?sort=total-citations"
}