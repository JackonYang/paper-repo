{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14163969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b296fcc89dc26ff2769d6290c71859b708e51a25",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for modeling object classes (such as faces) using 2D example images and an algorithm for matching a model to a novel image. The object class models are ``learned'''' from example images that we call prototypes. In addition to the images, the pixelwise correspondences between a reference prototype and each of the other prototypes must also be provided. Thus a model consists of a linear combination of prototypical shapes and textures. A stochastic gradient descent algorithm is used to match a model to a novel image by minimizing the error between the model and the novel image. Example models are shown as well as example matches to novel images. The robustness of the matching algorithm is also evaluated. The technique can be used for a number of applications including the computation of correspondence between novel images of a certain known class, object recognition, image synthesis and image compression."
            },
            "slug": "Model-Based-Matching-by-Linear-Combinations-of-Jones-Poggio",
            "title": {
                "fragments": [],
                "text": "Model-Based Matching by Linear Combinations of Prototypes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The technique can be used for a number of applications including the computation of correspondence between novel images of a certain known class, object recognition, image synthesis and image compression."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8989489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d781d5e651e12bf666cf993ae307db785113b9ae",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >"
            },
            "slug": "Recognition-by-Linear-Combinations-of-Models-Ullman-Basri",
            "title": {
                "fragments": [],
                "text": "Recognition by Linear Combinations of Models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed and it is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4754199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a393ad864f6fe95002e8d4412f3ebe5c42f699d6",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a technique for finding pixelwise correspondences between two images by using models of objects of the same class to guide the search. The object models are \"learned\" from example images (also called prototypes) of an object class. The models consist of a linear combination of prototypes. The flow fields giving pixelwise correspondences between a base prototype and each of the other prototypes must be given. A novel image of an object of the same class is matched to a model by minimizing an error between the novel image and the current guess for the closest model image. Currently, the algorithm applies to line drawings of objects. An extension to real grey level images is discussed.<<ETX>>"
            },
            "slug": "Model-based-matching-of-line-drawings-by-linear-of-Jones-Poggio",
            "title": {
                "fragments": [],
                "text": "Model-based matching of line drawings by linear combinations of prototypes"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A technique for finding pixelwise correspondences between two images by using models of objects of the same class to guide the search, which applies to line drawings of objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 57
                            }
                        ],
                        "text": "The \\linear class\" idea of [Poggio and Vetter, 1992] and [Vetter and Poggio, 1995] together with the image representation used by [Beymer et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10047234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "617b34332fcd1cb196f93656ee1d49561b81ebf8",
            "isKey": false,
            "numCitedBy": 471,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The need to generate new views of a 3D object from a single real image arises in several fields, including graphics and object recognition. While the traditional approach relies on the use of 3D models, simpler techniques are applicable under restricted conditions. The approach exploits image transformations that are specific to the relevant object class, and learnable from example views of other \"prototypical\" objects of the same class. In this paper, we introduce such a technique by extending the notion of linear class proposed by the authors (1992). For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views. We demonstrate the approach on artificial objects and then show preliminary evidence that the technique can effectively \"rotate\" high-resolution face images from a single 2D view."
            },
            "slug": "Linear-Object-Classes-and-Image-Synthesis-From-a-Vetter-Poggio",
            "title": {
                "fragments": [],
                "text": "Linear Object Classes and Image Synthesis From a Single Example Image"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "For linear object classes, it is shown that linear transformations can be learned exactly from a basis set of 2D prototypical views and preliminary evidence that the technique can effectively \"rotate\" high-resolution face images from a single 2D view is shown."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62531491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89121ed4d0d3db9bc192fd79f541fc299eba7d6b",
            "isKey": false,
            "numCitedBy": 304,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models. Many of these techniques depend on a representation of images that induces a linear vector space structure and in principle requires dense feature correspondence. This image representation allows the use of learning techniques for the analysis of images (for computer vision) as well as for the synthesis of images (for computer graphics)."
            },
            "slug": "Image-Representations-for-Visual-Learning-Beymer-Poggio",
            "title": {
                "fragments": [],
                "text": "Image Representations for Visual Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Computer vision researchers are developing new approaches to object recognition and detection that are based almost directly on images and avoid the use of intermediate three-dimensional models."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 499271,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "13e6061933989252abd5b694e1d4d20550bbef8f",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a multiresolution approach to image search using flexible shape models. This is an extension of work on active shape models (ASMs)-statistical models which iteratively deform to match image data. An ASM consists of a shape model controlling a set of landmark points, together with a statistical model of the grey-levels expected around each landmark. Both the shape model and the grey-level models are trained on sets of labelled example images. In order to apply a coarse-to-fine search strategy it is necessary to train a set of grey-level models for each landmark, one for every level of a multiresolution image pyramid. We demonstrate the approach and give results of quantitative experiments which show a significant increase in both speed, robustness and quality of fit compared to previous methods."
            },
            "slug": "Multi-resolution-search-with-active-shape-models-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Multi-resolution search with active shape models"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work describes a multiresolution approach to image search using flexible shape models and gives results of quantitative experiments which show a significant increase in both speed, robustness and quality of fit compared to previous methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 12th International Conference on Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32250556"
                        ],
                        "name": "D. H. Cooper",
                        "slug": "D.-H.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47581828"
                        ],
                        "name": "J. Graham",
                        "slug": "J.-Graham",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Graham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9737106,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d7f4e5d48bb21c2b0c5672688ea8a8072f6a35f0",
            "isKey": false,
            "numCitedBy": 630,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for building flexible shape models is presented in which a shape is represented by a set of labelled points. The technique determines the statistics of the points over a collection of example shapes. The mean positions of the points give an average shape and a number of modes of variation are determined describing the main ways in which the example shapes tend to deform from the average. In this way allowed variation in shape can be included in the model. The method produces a compact flexible \u2018Point Distribution Model\u2019 with a small number of linearly independent parameters, which can be used during image search. We demonstrate the application of the Point Distribution Model in describing two classes of shapes."
            },
            "slug": "Training-Models-of-Shape-from-Sets-of-Examples-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Training Models of Shape from Sets of Examples"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A method for building flexible shape models is presented in which a shape is represented by a set of labelled points and a number of modes of variation are determined describing the main ways in which the example shapes tend to deform from the average."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3893740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82962da5c273a9e6627a040d56c8a7973fe22440",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this note we discuss how recognition can be achieved from a single 2D model view exploiting prior knowledge of an object''s structure (e.g. symmetry). We prove that for any bilaterally symmetric 3D object one non- accidental 2D model view is sufficient for recognition. Symmetries of higher order allow the recovery of structure from one 2D view. Linear transformations can be learned exactly from a small set of examples in the case of \"linear object classes\" and used to produce new views of an object from a single view."
            },
            "slug": "Recognition-and-Structure-from-one-2D-Model-View:-Poggio-Vetter",
            "title": {
                "fragments": [],
                "text": "Recognition and Structure from one 2D Model View: Observations on Prototypes, Object Classes and Symmetries"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is proved that for any bilaterally symmetric 3D object one non- accidental 2D model view is sufficient for recognition and linear transformations can be learned exactly from a small set of examples in the case of \"linear object classes\"."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18648884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf474fd5b89b6b38bec83cd1e8d3b11166ba2a1a",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Face images are difficult to interpret because they are highly variable. Sources of variability include individual appearance, 3D pose, facial expression and lighting. We describe a compact parametrised model of facial appearance which takes into account all these sources of variability. The model represents both shape and grey-level appearance and is created by performing a statistical analysis over a training set of face images. A robust multi-resolution search algorithm is used to fit the model to faces in new images. This allows the main facial features to be located and a set of shape and grey-level appearance parameters to be recovered. A good approximation to a given face can be reconstructed using less than 100 of these parameters. This representation can be used for tasks such as image coding, person identification, pose recovery, gender recognition and expression recognition. The system performs well on all the tasks listed above.<<ETX>>"
            },
            "slug": "A-unified-approach-to-coding-and-interpreting-face-Lanitis-Taylor",
            "title": {
                "fragments": [],
                "text": "A unified approach to coding and interpreting face images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A compact parametrised model of facial appearance which takes into account all sources of variability and can be used for tasks such as image coding, person identification, pose recovery, gender recognition and expression recognition is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32250556"
                        ],
                        "name": "D. H. Cooper",
                        "slug": "D.-H.-Cooper",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cooper",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. H. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47581828"
                        ],
                        "name": "J. Graham",
                        "slug": "J.-Graham",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Graham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Graham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 36445761,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a041199f33d69a949d9bd889068187ffe4140cc7",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe a technique for building compact models of the shape and appearance of flexible objects seen in 2-D images. The models are derived from the statistics of sets of labeled images of example objects. Each model consists of a flexible shape template, describing how important points of the object can vary, and a statistical model of the expected grey levels in regions around each model point. Such models have proved useful in a wide variety of applications. A description is given on how the models can be used in local image search, and examples of their application are included.<<ETX>>"
            },
            "slug": "Building-and-using-flexible-models-incorporating-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Building and using flexible models incorporating grey-level information"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A technique for building compact models of the shape and appearance of flexible objects seen in 2-D images derived from the statistics of sets of labeled images of example objects, which have proved useful in a wide variety of applications."
            },
            "venue": {
                "fragments": [],
                "text": "1993 (4th) International Conference on Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48195968"
                        ],
                        "name": "A. Hill",
                        "slug": "A.-Hill",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1153559,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a576bc9d7d40c1c9fdd7f1c94e69aabd9279400",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a generic approach to image interpretation, based on combining a general method of building flexible template models with Genetic Algorithm (GA) search. The method can be applied to a given image interpretation problem simply by training a Point Distribution Model (PDM), using a set of examples of the image structure to be located. A local optimisation technique, developed for use with PDMs, has been incorporated into the GA search with the aim of improving the speed of convergence and optimality of solution. We present results, from three practical applications, demonstrating that the new method offers significant improvements when compared to previously reported approaches to flexible template matching. The benefits include the ability to deal with different domains of application using a standard method, the ability to deal with complex multi-part models and improved search performance."
            },
            "slug": "A-Generic-System-for-Image-Interpretation-Using-Hill-Cootes",
            "title": {
                "fragments": [],
                "text": "A Generic System for Image Interpretation Using Flexible Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A generic approach to image interpretation is described, based on combining a general method of building flexible template models with Genetic Algorithm (GA) search, and demonstrating that the new method offers significant improvements when compared to previously reported approaches to flexible template matching."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48195968"
                        ],
                        "name": "A. Hill",
                        "slug": "A.-Hill",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62761551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1db23b42d900c9b2a8fcbf9e23be1ae5467634c9",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a generic approach to image interpretation, based on combining a general method of building flexible template models with Genetic Algorithm (GA) search. The method can be applied to a given image interpretation problem simply by training a Point Distribution Model (PDM), using a set of examples of the image structure to be located. A local optimisation technique, developed for use with PDMs, has been incorporated into the GA search with the aim of improving the speed of convergence and optimality of solution. We present results, from three practical applications, demonstrating that the new method offers significant improvements when compared to previously reported approaches to flexible template matching. The benefits include the ability to deal with different domains of application using a standard method, the ability to deal with complex multi-part models and improved search performance."
            },
            "slug": "A-generic-system-for-image-interpretation-using-Hill-Cootes",
            "title": {
                "fragments": [],
                "text": "A generic system for image interpretation using flexible templates."
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A generic approach to image interpretation is described, based on combining a general method of building flexible template models with Genetic Algorithm (GA) search, and demonstrating that the new method offers significant improvements when compared to previously reported approaches to flexible template matching."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61001553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d34bac36fcaa3fa5bdc9d843a7fd0972649116b0",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that we can optimally represent the set of 2D images produced by the point features of a rigid 3D model as two lines in two high-dimensional spaces. We then decribe a working recognition system in which we represent these spaces discretely in a hash table. We can access this table at run time to find all the groups of model features that could match a group of image features, accounting for the effects of sensing error. We also use this representation of a model''s images to demonstrate significant new limitations of two other approaches to recognition: invariants, and non- accidental properties."
            },
            "slug": "A-Novel-Approach-to-Graphics-Poggio-Brunelli",
            "title": {
                "fragments": [],
                "text": "A Novel Approach to Graphics"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This work shows that it can optimally represent the set of 2D images produced by the point features of a rigid 3D model as two lines in two high-dimensional spaces, and decribes a working recognition system in which these spaces are represented discretely in a hash table."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 170
                            }
                        ],
                        "text": "Poggio and Vetter introduced the idea of linear combinations of views to de ne and model classes of objects, trying to extend the results of [Ullman and Basri, 1991] and [Shashua, 1992] who showed that linear combinations of three views of a single object may be used to obtain any other views of the object (barring self-occlusion and assuming orthographic projection)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2937213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db0e6692d49bdf8a59f4a722119a5e7406a5bc2e",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Address the problem of reconstructing 3-D space in a projective framework from two or more views, and the problem of artificially generating novel views of the scene from two given views (reprojection). The author describes an invariance relation that provides a new description of structure, which the author calls projective depth, that is captured by a single equation relating image point correspondences across two or more views and the homographics of two arbitrary virtual planes. The framework is based on knowledge of correspondence of features across views, is linear and extremely simple, and the computations of structure readily extend to overdetermination using multiple views. Experimental results demonstrate a high degree of accuracy in both tasks: reconstruction and reprojection. >"
            },
            "slug": "Projective-Structure-from-Uncalibrated-Images:-From-Shashua",
            "title": {
                "fragments": [],
                "text": "Projective Structure from Uncalibrated Images: Structure From Motion and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The author describes an invariance relation that provides a new description of structure that is captured by a single equation relating image point correspondences across two or more views and the homographics of two arbitrary virtual planes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26288947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "688da1cdc435eadaed83a564ae2c30de4f216e59",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The need to generate new views of a 3D object from a single real image arises in several fields, including graphics and object recognition. While the traditional approach relies on the use of 3D models, we exploit 2D image transformations that are specific to the relevant object class and learnable from example views of other \u201cprototypical\u201d objects of the same class."
            },
            "slug": "Image-Synthesis-from-a-Single-Example-Image-Vetter-Poggio",
            "title": {
                "fragments": [],
                "text": "Image Synthesis from a Single Example Image"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work exploits 2D image transformations that are specific to the relevant object class and learnable from example views of other \u201cprototypical\u201d objects of the same class."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123525290,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cdb0a19d9ee3a36a2954bf991f817f43aa645127",
            "isKey": false,
            "numCitedBy": 521,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe \u2018Active Shape Models\u2019 which iteratively adapt to refine estimates of the pose, scale and shape of models of image objects. The method uses flexible models derived from sets of training examples. These models, known as Point Distribution Models, represent objects as sets of labelled points. An initial estimate of the location of the model points in an image is improved by attempting to move each point to a better position nearby. Adjustments to the pose variables and shape parameters are calculated. Limits are placed on the shape parameters ensuring that the example can only deform into shapes conforming to global constraints imposed by the training set. An iterative procedure deforms the model example to find the best fit to the image object. Results of applying the method are described. The technique is shown to be a powerful method for refining estimates of object shape and location."
            },
            "slug": "Active-shape-models-'Smart-Snakes'.-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Active shape models - 'Smart Snakes'."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932365"
                        ],
                        "name": "N. Troje",
                        "slug": "N.-Troje",
                        "structuredName": {
                            "firstName": "Nikolaus",
                            "lastName": "Troje",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Troje"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747836"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13115909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53d415bf5018255f57d36108cfd9c8b8216d9d2f",
            "isKey": false,
            "numCitedBy": 435,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Face-recognition-under-varying-poses:-The-role-of-Troje-B\u00fclthoff",
            "title": {
                "fragments": [],
                "text": "Face recognition under varying poses: The role of texture and shape"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46942796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "65a7c92a3bde6ec2f8e013875e499398c741adeb",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe methods for using flexible models to locate structures in images. We have previously described statistical models of shape and shape variability which can be used for this purpose (active shape models). In this paper we show how statistical models of grey-level appearance can be incorporated, leading to improved reliability and accuracy. We describe experiments designed to: 1) test how well an active shape model can locate an object in a new image; 2) to assess the effects on performance of varying the model parameters; and 3) to compare the results using grey-level models with those using a search for strongest edges. The results demonstrate that the addition of grey-level models leads to considerable improvement over earlier schemes."
            },
            "slug": "Using-grey-level-models-to-improve-active-shape-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Using grey-level models to improve active shape model search"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The results demonstrate that the addition of grey-level models leads to considerable improvement over earlier schemes, leading to improved reliability and accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 12th International Conference on Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 570648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66d75a5fe9e1b6511c5135d68e9ce8c0da5a7374",
            "isKey": false,
            "numCitedBy": 2853,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion. This results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix, without increasing the complexity of the calculation. The resulting approximation of faces projected from outside of the data set onto this optimal basis is improved on average. >"
            },
            "slug": "Application-of-the-Karhunen-Loeve-Procedure-for-the-Kirby-Sirovich",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen-Loeve Procedure for the Characterization of Human Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion, which results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740300"
                        ],
                        "name": "D. Beymer",
                        "slug": "D.-Beymer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Beymer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Beymer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13151746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8abe2824f9851d3c465b1aa11849661430d60ca0",
            "isKey": false,
            "numCitedBy": 217,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Image analysis and graphics synthesis can be achieved with learning techniques using directly image examples without physically-based, 3D models. In our technique: -- the mapping from novel images to a vector of ``pose'''' and ``expression'''' parameters can be learned from a small set of example images using a function approximation technique that we call an {\\it analysis network}; -- the inverse mapping from input ``pose'''' and ``expression'''' parameters to output images can be synthesized from a small set of example images and used to produce new images using a similar {\\it synthesis network}. The techniques described here have several applications in computer graphics, special effects, interactive multimedia and very low bandwidth teleconferencing."
            },
            "slug": "Example-Based-Image-Analysis-and-Synthesis-Beymer-Shashua",
            "title": {
                "fragments": [],
                "text": "Example Based Image Analysis and Synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The mapping from novel images to a vector of ``pose'''' and ``expression'''' parameters can be learned from a small set of example images using a function approximation technique that it analysis network."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10214317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "706c7bd758f933bffd60b5153a4498e83a880a38",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in video-tracking allow the outlines of moving, natural objects in a video-camera input stream to be tracked live, at full video-rate. Previous systems have been available to do this for specially illuminated objects or for naturally illuminated but polyhedral objects. Other systems have been able to track nonpolyhedral objects in motion, in some cases from live video, but following only centroids or key-points rather than tracking whole curves. The system described here can track accurately the curved silhouettes of moving non-polyhedral objects at frame-rate, for example hands, lips, legs, vehicles, fruit, and without any special hardware beyond a desktop workstation and a video-camera and framestore. The new algorithms are a synthesis of methods in deformable models, B-splines curve representation and control theory. This paper shows how such a facility can be used to turn parts of the body\u2014for instance, hands and lips\u2014into input devices. Rigid motion of a hand can be used as a 3D mouse with non-rigid gestures signalling a button press or the \u201clifting\u201d of the mouse. Both rigid and non-rigid motions of lips can be tracked independently and used as inputs, for example to animate a computer-generated face."
            },
            "slug": "3D-position,-attitude-and-shape-input-using-video-Blake-Isard",
            "title": {
                "fragments": [],
                "text": "3D position, attitude and shape input using video tracking of hands and lips"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The system described here can track accurately the curved silhouettes of moving non-polyhedral objects at frame-rate, for example hands, lips, legs, vehicles, fruit, and without any special hardware beyond a desktop workstation and a video-camera and framestore."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2320082"
                        ],
                        "name": "C. Choi",
                        "slug": "C.-Choi",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Choi",
                            "middleNames": [
                                "Seok"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50540918"
                        ],
                        "name": "T. Okazaki",
                        "slug": "T.-Okazaki",
                        "structuredName": {
                            "firstName": "Toru",
                            "lastName": "Okazaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Okazaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698996"
                        ],
                        "name": "H. Harashima",
                        "slug": "H.-Harashima",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Harashima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Harashima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72636269"
                        ],
                        "name": "T. Takebe",
                        "slug": "T.-Takebe",
                        "structuredName": {
                            "firstName": "Tsuyosi",
                            "lastName": "Takebe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Takebe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61405009,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3458ce2e92102a721277e1208032f24c1a19f46",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A system is presented which analyzes and synthesizes the facial images. This system is focused on analysis and synthesis of facial features. Any particular image is assumed to be a weighted sum of facial image bases. The weights represent the facial features of the particular image. A method which analyzes and synthesizes the facial images on the basis of a three-dimensional facial shape model is presented. The method is extended so that the features of parts as well as the whole of the face can be analyzed and synthesized. Moreover, a procedure is developed for orthogonalizing the image bases for optimal description.<<ETX>>"
            },
            "slug": "A-system-of-analyzing-and-synthesizing-facial-Choi-Okazaki",
            "title": {
                "fragments": [],
                "text": "A system of analyzing and synthesizing facial images"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A method which analyzes and synthesizes the facial images on the basis of a three-dimensional facial shape model is presented, extended so that the features of parts as well as the whole of the face can be analyzed and synthesized."
            },
            "venue": {
                "fragments": [],
                "text": "1991., IEEE International Sympoisum on Circuits and Systems"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076891538"
                        ],
                        "name": "Stephen Lines",
                        "slug": "Stephen-Lines",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Lines",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Lines"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 142782088,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "2cb6eb4ba955c49eb149ac961cfb14530e3dd07a",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Thesis (M.S.)--Massachusetts Institute of Technology, Dept. of Brain and Cognitive Sciences, 1996."
            },
            "slug": "The-photo-realistic-synthesis-of-novel-views-from-Lines",
            "title": {
                "fragments": [],
                "text": "The photo-realistic synthesis of novel views from example images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144886844"
                        ],
                        "name": "R. Lathe",
                        "slug": "R.-Lathe",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lathe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lathe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 150
                            }
                        ],
                        "text": "Sometimes, however, we were forced to use interactive techniques requiring the user to specify at least some of the correspondences (see for instance [Lines, 1996])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5063877,
            "fieldsOfStudy": [
                "Geography",
                "Environmental Science",
                "Geology"
            ],
            "id": "6ec27fba80de3b9c52ef6ac4eaa9f59821aefb4b",
            "isKey": false,
            "numCitedBy": 11671,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Deposits of clastic carbonate-dominated (calciclastic) sedimentary slope systems in the rock record have been identified mostly as linearly-consistent carbonate apron deposits, even though most ancient clastic carbonate slope deposits fit the submarine fan systems better. Calciclastic submarine fans are consequently rarely described and are poorly understood. Subsequently, very little is known especially in mud-dominated calciclastic submarine fan systems. Presented in this study are a sedimentological core and petrographic characterisation of samples from eleven boreholes from the Lower Carboniferous of Bowland Basin (Northwest England) that reveals a >250 m thick calciturbidite complex deposited in a calciclastic submarine fan setting. Seven facies are recognised from core and thin section characterisation and are grouped into three carbonate turbidite sequences. They include: 1) Calciturbidites, comprising mostly of highto low-density, wavy-laminated bioclast-rich facies; 2) low-density densite mudstones which are characterised by planar laminated and unlaminated muddominated facies; and 3) Calcidebrites which are muddy or hyper-concentrated debrisflow deposits occurring as poorly-sorted, chaotic, mud-supported floatstones. These"
            },
            "slug": "Phd-by-thesis-Lathe",
            "title": {
                "fragments": [],
                "text": "Phd by thesis"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 200
                            }
                        ],
                        "text": "1 A key problem: creating the model from prototypes The distinguishing aspect of our linear exible models is that they are linear combinations of prototype shape and texture vectors and not of images [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "2 Past work The \\linear class\" idea of [14] and [16] together with the image representation used by [2] (see [3] for a review) is the main motivation behind the work of this and previous papers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "For a set of images to behave as vectors, they must be in pixelwise correspondence (see [3])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image repre-  sentations for visual learning"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1905
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 88
                            }
                        ],
                        "text": "For a set of images to behave as vectors, they must be in pixelwise correspondence (see [Poggio and Beymer, 1996])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 243002130,
            "fieldsOfStudy": [],
            "id": "1c41ace01865870d8d225679573f75e3698a72a9",
            "isKey": false,
            "numCitedBy": 420,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "IEEE-Spectrum",
            "title": {
                "fragments": [],
                "text": "IEEE Spectrum"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144437305"
                        ],
                        "name": "A. Posner",
                        "slug": "A.-Posner",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Posner",
                            "middleNames": [
                                "Charles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Posner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7391957,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "b9cde732f40e5a48ca07d0f2b858079db0f6894d",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-to-see.-Posner",
            "title": {
                "fragments": [],
                "text": "Learning to see."
            },
            "venue": {
                "fragments": [],
                "text": "Eye, ear, nose & throat monthly"
            },
            "year": 1955
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Building and using exible models incorporating greylevel information"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Alignment b y maximization of mutual information. MIT A.I"
            },
            "venue": {
                "fragments": [],
                "text": "Alignment b y maximization of mutual information. MIT A.I"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 9
                            }
                        ],
                        "text": ", 1992]; [Lanitis et al., 1995]) on active shape models is probably the closest to ours."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 368{ 373"
            },
            "venue": {
                "fragments": [],
                "text": "Cambridge, MA, June"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 242{246"
            },
            "venue": {
                "fragments": [],
                "text": "Berlin, May"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 470,
                                "start": 108
                            }
                        ],
                        "text": "The problem of using the flexible model to an~(Zyze novel images was the main concern of Jones and Poggio ([9, lo]). They introduced a novel approach to match flexible linear models to novel images that can be used for several visual analysis tasks, including recognition, image correspondence and image compression. Recently we have become aware of several papers dealing with various forms of the idea of linear combination of prototypical images. Choi et. al. (1991) were perhaps the first to suggest a model which represented face images with separate shape and texture components, using a 3D model tot provide correspondences between example face images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiresolution search with active shape models"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Pattern Recognitfon"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Michael Jonesand Tomaso Poggio . Model - based matching bylinear combinations of prototypes"
            },
            "venue": {
                "fragments": [],
                "text": "A . I . Memo"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Steve Lines. The photorealistic synthesis of novel views from example images. Master's thesis, MIT"
            },
            "venue": {
                "fragments": [],
                "text": "Steve Lines. The photorealistic synthesis of novel views from example images. Master's thesis, MIT"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 190
                            }
                        ],
                        "text": "Our model uses pixelwise correspondence between example images and should not be confused with techniques which use linear combinations of images such as the so-called eigenfaces technique ([Kirby and Sirovich, 1990]; [Turk and Pentland, 1991])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "12(1):103{ 108"
            },
            "venue": {
                "fragments": [],
                "text": "January"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 64
                            }
                        ],
                        "text": "We have chosen to use the stochastic gradient descent algorithm [Viola, 1995] because it is fast and can escape from local minima."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Technical Report 1548"
            },
            "venue": {
                "fragments": [],
                "text": "MIT,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical motion-based frame rate conversion. Technical report, David Sarnoo Research C e n ter Image representations for visual learning"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Amnon Shashua Projective structure from two uncalibrated images: Structure from motion and recognition. A.I. Memo 1363"
            },
            "venue": {
                "fragments": [],
                "text": "Amnon Shashua Projective structure from two uncalibrated images: Structure from motion and recognition. A.I. Memo 1363"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 58
                            }
                        ],
                        "text": "have been proposed, such as the model of Blake and Issard [Blake and Isard, 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 68
                            }
                        ],
                        "text": "Many other flexible models have been proposed, such as the model of Blake and Issard [4]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3d position"
            },
            "venue": {
                "fragments": [],
                "text": "attitude and shape input using video tracking of hands and lips. Computer Graphics Proceedings, pages 185{192,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Build - ing and using exible models incorporatinggreylevel information"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "Poggio and Vetter introduced the idea of linear combinations of views to de ne and model classes of objects, trying to extend the results of [15] who showed that linear combinations of three views of a single object may be used to obtain any other views of the object."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition by lin-  ear combinations of models"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions  on Pattern Analysis and Machine Intelligence,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 92
                            }
                        ],
                        "text": "We have mostly used the multiresolution, laplacian-based, optical ow algorithm described in [Bergen and Hingorani, 1990]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "David Sarno Research Center"
            },
            "venue": {
                "fragments": [],
                "text": "April"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Michael Jones and Tomaso Poggio. Model-based matching by linear combinations of prototypes. A.I. Memo 1583"
            },
            "venue": {
                "fragments": [],
                "text": "Michael Jones and Tomaso Poggio. Model-based matching by linear combinations of prototypes. A.I. Memo 1583"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bratish hlachzne If-zszon Conference"
            },
            "venue": {
                "fragments": [],
                "text": "pages 276-285."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Alignment b y m a x i mization of mutual information. MIT A.I"
            },
            "venue": {
                "fragments": [],
                "text": "Alignment b y m a x i mization of mutual information. MIT A.I"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lanitis Multi - resolution search with active shape models"
            },
            "venue": {
                "fragments": [],
                "text": "Bratish hlachzne If - zszon Conference , pages 276 - 285 ."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "AndrewBlake and Michael Isard . 3 d position , attitudeand shape input using video tracking of handsand lips"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Graphics Proceedings"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "David Beymer andTomaso Poggio . Image representations for visual learning"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "We have chosen to use the stochastic gradient descent algorithm [17] because it is fast and can escape from local minima."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Alignment by maximization of mu-  tual information"
            },
            "venue": {
                "fragments": [],
                "text": "MIT A.I. Technical Report  1548,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hierarchical motion-based frame rate conversion"
            },
            "venue": {
                "fragments": [],
                "text": "Hierarchical motion-based frame rate conversion"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Thomas Vetter and Tomaso Poggio. Linear object classes and image synthesis from a single example image. A.I. Memo 1531"
            },
            "venue": {
                "fragments": [],
                "text": "Thomas Vetter and Tomaso Poggio. Linear object classes and image synthesis from a single example image. A.I. Memo 1531"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The ph [ 14 ] Tomaso Poggio and [ 15 ] S . Ullman"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Steve Lines. The Photorealistic Synthesis of Novel Views from Example Images"
            },
            "venue": {
                "fragments": [],
                "text": "Steve Lines. The Photorealistic Synthesis of Novel Views from Example Images"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 57
                            }
                        ],
                        "text": "The \\linear class\" idea of [Poggio and Vetter, 1992] and [Vetter and Poggio, 1995] together with the image representation used by [Beymer et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Memo 1531"
            },
            "venue": {
                "fragments": [],
                "text": "MIT,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A system of analyzing andsynthesizing facial images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 38
                            }
                        ],
                        "text": "(1991) were perhaps the rst (see also [Poggio and Brunelli, 1992]) to suggest a model which represented face images with separate shape and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Memo 1354"
            },
            "venue": {
                "fragments": [],
                "text": "MIT,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "To write the linear object clas!: model mathematically, we must first introduce some notation, which we summarize from [lo]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Memo 1583"
            },
            "venue": {
                "fragments": [],
                "text": "MIT,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 149
                            }
                        ],
                        "text": "The distinguishing aspect of our linear exible models is that they are linear combinations of prototype shape and texture vectors and not of images ([Beymer and Poggio, 1996])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 13
                            }
                        ],
                        "text": ", 1993] (see [Beymer and Poggio, 1996] for a review) is the main motivation behind the work of this and previous papers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "272:1905{1909"
            },
            "venue": {
                "fragments": [],
                "text": "June"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "David Beymer andTomaso Poggio . Image representations for visual learning"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 1
                            }
                        ],
                        "text": "([6, 7, 8, 12]) on active shape models is probably the closest to ours."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A uni-  ed approach to coding and interpreting face im-  ages"
            },
            "venue": {
                "fragments": [],
                "text": "In ICCV,"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 11,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 60,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/A-bootstrapping-algorithm-for-learning-linear-of-Vetter-Jones/cef9b899297bee5b50cb7a15442b18ac01f58784?sort=total-citations"
}