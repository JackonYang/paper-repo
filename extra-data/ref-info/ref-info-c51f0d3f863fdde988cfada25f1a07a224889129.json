{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "DH parameters for the rst author's right hand, used in the experiments, can be found in [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "The tip Jacobian derivation proceeds identically, and can be found in [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "A 3D mouse interface based on visual hand tracking is presented in [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "See [11] for a more extensive bibliography."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14133354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aaf6f7a14ba984b296b524474823e425ab3dd61e",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Passive sensing of human hand and limb motion is important for a wide range of applications from human-computer interaction to athletic performance measurement. High degree of freedom articulated mechanisms like the human hand are difficult to track because of their large state space and complex image appearance. This article describes a model-based hand tracking system, called DigitEyes, that can recover the state of a 27 DOF hand model from gray scale images at speeds of up to 10 Hz. We employ kinematic and geometric hand models, along with a high temporal sampling rate, to decompose global image patterns into incremental, local motions of simple shapes. Hand pose and joint angles are estimated from line and point features extracted from images of unmarked, unadorned hands, taken from one or more viewpoints. We present some preliminary results on a 3D mouse interface based on the DigitEyes sensor."
            },
            "slug": "DigitEyes:-Vision-Based-Human-Hand-Tracking-Rehg-Kanade",
            "title": {
                "fragments": [],
                "text": "DigitEyes: Vision-Based Human Hand Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A model-based hand tracking system that can recover the state of a 27 DOF hand model from gray scale images at speeds of up to 10 Hz is described, and some preliminary results on a 3D mouse interface based on the DigitEyes sensor are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3013562"
                        ],
                        "name": "H. Rijpkema",
                        "slug": "H.-Rijpkema",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Rijpkema",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rijpkema"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145749933"
                        ],
                        "name": "M. Girard",
                        "slug": "M.-Girard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Girard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Girard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "We currently employ the thumb model used in Rijpkema and Girard's grasp modeling system [12] (see Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8578444,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af9e08efed2f5bc58d71761a6c0c493e2b988e22",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "The synthesis of human hand motion and grasping of arbitrary shaped objects is a very complex problem. Therefore high-level control is needed to perform these actions. In order to satisfy the kinematic and physical constraints associated with the human hand and to reduce the enormous search space associated with the problem of grasping objects, a knowledge based approach is used. A three-phased scheme is presented which incorporates the role of the hand, the object, the environment and the animator. The implementation of a hand simulation system HANDS is discussed."
            },
            "slug": "Computer-animation-of-knowledge-based-human-Rijpkema-Girard",
            "title": {
                "fragments": [],
                "text": "Computer animation of knowledge-based human grasping"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A three-phased scheme is presented which incorporates the role of the hand, the object, the environment and the animator and the implementation of a hand simulation system HANDS is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47579815"
                        ],
                        "name": "Masanobu Yamamoto",
                        "slug": "Masanobu-Yamamoto",
                        "structuredName": {
                            "firstName": "Masanobu",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masanobu Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2638101"
                        ],
                        "name": "K. Koshikawa",
                        "slug": "K.-Koshikawa",
                        "structuredName": {
                            "firstName": "Kazutada",
                            "lastName": "Koshikawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Koshikawa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [14], Yamamoto and Koshikawa describe a system for human body tracking using kinematic and geometric models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 121
                            }
                        ],
                        "text": "Visual tracking is a sequential estimation problem: given an image sequence, recover the time-varying state of the world [5, 7, 14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 63
                            }
                        ],
                        "text": "Previous work on tracking general articulated objects includes [14, 10, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35103895,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "4ff071ca1e5207975ca8cd146f5c33eddfdb2d98",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A model-based method for analyzing a human body motion is presented. The method is based on a robot arm model which represents a human body motion. Combining the model and the gradient scheme, the movement of the configuration of the model (Human) can be directly estimated from an image sequence.<<ETX>>"
            },
            "slug": "Human-motion-analysis-based-on-a-robot-arm-model-Yamamoto-Koshikawa",
            "title": {
                "fragments": [],
                "text": "Human motion analysis based on a robot arm model"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A model-based method based on a robot arm model which represents a human body motion and the movement of the configuration of the model can be directly estimated from an image sequence."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67242598"
                        ],
                        "name": "Mann Rw",
                        "slug": "Mann-Rw",
                        "structuredName": {
                            "firstName": "Mann",
                            "lastName": "Rw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mann Rw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143875007"
                        ],
                        "name": "A. Ek",
                        "slug": "A.-Ek",
                        "structuredName": {
                            "firstName": "Antonsson",
                            "lastName": "Ek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 111
                            }
                        ],
                        "text": "Current commercially available solutions are invasive, and require the user to don gloves [15] or wear targets [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63923001,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d10dd93a018045007f6a2d36ee14884244b09d94",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ": A fully automatic optoelectronic photogrammetric technique is presented for measuring the spatial kinematics of human motion (both position and orientation) and estimating the inertial (net) dynamics. Calibration and verification showed that in a two-meter cube viewing volume, the system achieves one millimeter of accuracy and resolution in translation and 20 milliradians in rotation. Since double differentiation of generalized position data to determine accelerations amplifies noise, the frequency domain characteristics of the system were investigated. It was found that the noise and all other errors in the kinematic data contribute less than five percent error to the resulting dynamics."
            },
            "slug": "Gait-analysis--precise,-rapid,-automatic,-3-D-and-Rw-Ek",
            "title": {
                "fragments": [],
                "text": "Gait analysis--precise, rapid, automatic, 3-D position and orientation kinematics and dynamics."
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A fully automatic optoelectronic photogrammetric technique is presented for measuring the spatial kinematics of human motion and estimating the inertial dynamics, finding that the noise and all other errors in the kinematic data contribute less than five percent error to the resulting dynamics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47409127"
                        ],
                        "name": "R. Mann",
                        "slug": "R.-Mann",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mann",
                            "middleNames": [
                                "W."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702201"
                        ],
                        "name": "E. Antonsson",
                        "slug": "E.-Antonsson",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Antonsson",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Antonsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40270298,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "01423c052648359ebf8678193875e08a747ea0a0",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A fully automatic optoelectronic photogrammetric technique is presented for measuring the spatial kinematics of human motion (both position and orientation) and estimating the inertial (net) dynamics. Calibration and verification showed that in a two-meter cube viewing volume, the system achieves one millimeter of accuracy and resolution in translation and 20 milliradians in rotation. Since double differentiation of generalized position data to determine accelerations amplifies noise, the frequency domain characteristics of the system were investigated. It was found that the noise and all other errors in the kinematic data contribute less than five percent error to the resulting dynamics."
            },
            "slug": "Gait-analysis--precise,-rapid,-automatic,-3-D-and-Mann-Antonsson",
            "title": {
                "fragments": [],
                "text": "Gait analysis--precise, rapid, automatic, 3-D position and orientation kinematics and dynamics."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Since double differentiation of generalized position data to determine accelerations amplifies noise, the frequency domain characteristics of the system were investigated and it was found that the noise and all other errors in the kinematic data contribute less than five percent error to the resulting dynamics."
            },
            "venue": {
                "fragments": [],
                "text": "Bulletin of the Hospital for Joint Diseases Orthopaedic Institute"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "Second, analysis is typically restricted to a subset of the total hand motion, such as a set of gestures [2] or rigid motion of the palm [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 93
                            }
                        ],
                        "text": "Darrell and Pentland describe a system for learning and recognizing dynamic hand gestures in [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5344867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1807058512ae2934b2be0b43f395d8583ef67303",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented. Objects are represented using sets of view models, rather than single templates. Stereotypical space-time patterns, i.e., gestures, are then matched to stored gesture patterns using dynamic time warping. Real-time performance is achieved by using special purpose correlation hardware and view prediction to prune as much of the search space as possible. Both view models and view predictions are learned from examples. Results showing tracking and recognition of human hand gestures at over 10 Hz are presented.<<ETX>>"
            },
            "slug": "Space-time-gestures-Darrell-Pentland",
            "title": {
                "fragments": [],
                "text": "Space-time gestures"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented and results showing tracking and recognition of human hand gestures at over 10 Hz are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052391642"
                        ],
                        "name": "J. O'Rourke",
                        "slug": "J.-O'Rourke",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "O'Rourke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Rourke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699200"
                        ],
                        "name": "N. Badler",
                        "slug": "N.-Badler",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Badler",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Badler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "A much earlier system by O'Rourke and Badler [9] analyzed human body motion using constraint propagation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 63
                            }
                        ],
                        "text": "Previous work on tracking general articulated objects includes [14, 10, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15680007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9df0428c30b8aab4f7e6f367e70126efdfb8fc45",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "A system capable of analyzing image sequences of human motion is described. The system is structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level. The domain of human motion lends itself to a model-driven analysis, and the system includes a detailed model of the human body. All information extracted from the image is interpreted through a constraint network based on the structure of the human model. A constraint propagation operator is defined and its theoretical properties outlined. An implementation of this operator is described, and results of the analysis system for short image sequences are presented."
            },
            "slug": "Model-based-image-analysis-of-human-motion-using-O'Rourke-Badler",
            "title": {
                "fragments": [],
                "text": "Model-based image analysis of human motion using constraint propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A system capable of analyzing image sequences of human motion is described, structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144152544"
                        ],
                        "name": "B. Horowitz",
                        "slug": "B.-Horowitz",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horowitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Pentland and Horowitz [10] give an example of tracking the motion of a human gure using optical ow and an articulated deformable model."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 63
                            }
                        ],
                        "text": "Previous work on tracking general articulated objects includes [14, 10, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28815139,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "f706f1babe84c0728be3a06a4d3023cdc44f61c2",
            "isKey": false,
            "numCitedBy": 417,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors introduce a physically correct model of elastic nonrigid motion. This model is based on the finite element method, but decouples the degrees of freedom by breaking down object motion into rigid and nonrigid vibration or deformation modes. The result is an accurate representation for both rigid and nonrigid motion that has greatly reduced dimensionality, capturing the intuition that nonrigid motion is normally coherent and not chaotic. Because of the small number of parameters involved, this representation is used to obtain accurate overstrained estimates of both rigid and nonrigid global motion. It is also shown that these estimates can be integrated over time by use of an extended Kalman filter, resulting in stable and accurate estimates of both three-dimensional shape and three-dimensional velocity. The formulation is then extended to include constrained nonrigid motion. Examples of tracking single nonrigid objects and multiple constrained objects are presented. >"
            },
            "slug": "Recovery-of-Nonrigid-Motion-and-Structure-Pentland-Horowitz",
            "title": {
                "fragments": [],
                "text": "Recovery of Nonrigid Motion and Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This model is based on the finite element method, but decouples the degrees of freedom by breaking down object motion into rigid and nonrigid vibration or deformation modes, resulting in an accurate representation for both rigid andnonrigid motion that has greatly reduced dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145963824"
                        ],
                        "name": "M. Spong",
                        "slug": "M.-Spong",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Spong",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Spong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "We model kinematic chains, like the nger, with the Denavit-Hartenburg (DH) representation, which is widely used in robotics [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "As a result, these Jacobian entries can be obtained directly from the model kinematics by means of some standard formulas (see [13], Chapter 5)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14613723,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7976560c96c3fd326c1f7efb4f96595b9c39e893",
            "isKey": false,
            "numCitedBy": 3752,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis self-contained introduction to practical robot kinematics and dynamics includes a comprehensive treatment of robot control. Provides background material on terminology and linear transformations, followed by coverage of kinematics and inverse kinematics, dynamics, manipulator control, robust control, force control, use of feedback in nonlinear systems, and adaptive control. Each topic is supported by examples of specific applications. Derivations and proofs are included in many cases. Includes many worked examples, examples illustrating all aspects of the theory, and problems."
            },
            "slug": "Robot-dynamics-and-control-Spong",
            "title": {
                "fragments": [],
                "text": "Robot dynamics and control"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This self-contained introduction to practical robot kinematics and dynamics includes a comprehensive treatment of robot control, providing background material on terminology and linear transformations and examples illustrating all aspects of the theory and problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738740"
                        ],
                        "name": "S. B. Kang",
                        "slug": "S.-B.-Kang",
                        "structuredName": {
                            "firstName": "Sing",
                            "lastName": "Kang",
                            "middleNames": [
                                "Bing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. B. Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739452"
                        ],
                        "name": "K. Ikeuchi",
                        "slug": "K.-Ikeuchi",
                        "structuredName": {
                            "firstName": "Katsushi",
                            "lastName": "Ikeuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ikeuchi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "In other hand-speci c work, Kang and Ikeuchi describe a range sensor-based approach to hand pose estimation [6], used in their Assembly Plan from Observation system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42313274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee6eb56104d6b01bc2451aa12c6b9badc39b37f8",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to teach robots to ger- form grasping tasks. This approach is based on the Assembly Plan from Observation (APO) paradigm, where the key idea is to enable a system to observe a human performing a grasping task, understand it, and perform the task with minimal human intervention. A grasping task is composed of three phases: pre-grasp phase, static grasp phase, and manipulation phase. The first step in recognizing a grasping task is to identify the grasp itself (within the static grasp phase). We propose to identify the grasp by means of a grasp representation called the contact web which is composed of a pattern of effective contact points between the hand and the object. We also propose a grasp taxonomy based on the contact web to systematically identify a grasp. Results from grasping experiments show that it is possi- ble to distinguish between various types of grasps using the proposed contact web and grasp taxonomy."
            },
            "slug": "Grasp-Recognition-Using-The-Contact-Web-Kang-Ikeuchi",
            "title": {
                "fragments": [],
                "text": "Grasp Recognition Using The Contact Web"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Results from grasping experiments show that it is possi- ble to distinguish between various types of grasps using the proposed contact web and grasp taxonomy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800149"
                        ],
                        "name": "J. Dennis",
                        "slug": "J.-Dennis",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Dennis",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dennis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795397"
                        ],
                        "name": "Bobby Schnabel",
                        "slug": "Bobby-Schnabel",
                        "structuredName": {
                            "firstName": "Bobby",
                            "lastName": "Schnabel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bobby Schnabel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "We employ the Levenburg-Marquardt (LM) algorithm for nonlinear least squares problems [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27578127,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e1053197256c6c3c0631377ec23a3f7dc1cb4781",
            "isKey": false,
            "numCitedBy": 7616,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1. Introduction. Problems to be considered Characteristics of 'real-world' problems Finite-precision arithmetic and measurement of error Exercises 2. Nonlinear Problems in One Variable. What is not possible Newton's method for solving one equation in one unknown Convergence of sequences of real numbers Convergence of Newton's method Globally convergent methods for solving one equation in one uknown Methods when derivatives are unavailable Minimization of a function of one variable Exercises 3. Numerical Linear Algebra Background. Vector and matrix norms and orthogonality Solving systems of linear equations-matrix factorizations Errors in solving linear systems Updating matrix factorizations Eigenvalues and positive definiteness Linear least squares Exercises 4. Multivariable Calculus Background Derivatives and multivariable models Multivariable finite-difference derivatives Necessary and sufficient conditions for unconstrained minimization Exercises 5. Newton's Method for Nonlinear Equations and Unconstrained Minimization. Newton's method for systems of nonlinear equations Local convergence of Newton's method The Kantorovich and contractive mapping theorems Finite-difference derivative methods for systems of nonlinear equations Newton's method for unconstrained minimization Finite difference derivative methods for unconstrained minimization Exercises 6. Globally Convergent Modifications of Newton's Method. The quasi-Newton framework Descent directions Line searches The model-trust region approach Global methods for systems of nonlinear equations Exercises 7. Stopping, Scaling, and Testing. Scaling Stopping criteria Testing Exercises 8. Secant Methods for Systems of Nonlinear Equations. Broyden's method Local convergence analysis of Broyden's method Implementation of quasi-Newton algorithms using Broyden's update Other secant updates for nonlinear equations Exercises 9. Secant Methods for Unconstrained Minimization. The symmetric secant update of Powell Symmetric positive definite secant updates Local convergence of positive definite secant methods Implementation of quasi-Newton algorithms using the positive definite secant update Another convergence result for the positive definite secant method Other secant updates for unconstrained minimization Exercises 10. Nonlinear Least Squares. The nonlinear least-squares problem Gauss-Newton-type methods Full Newton-type methods Other considerations in solving nonlinear least-squares problems Exercises 11. Methods for Problems with Special Structure. The sparse finite-difference Newton method Sparse secant methods Deriving least-change secant updates Analyzing least-change secant methods Exercises Appendix A. A Modular System of Algorithms for Unconstrained Minimization and Nonlinear Equations (by Robert Schnabel) Appendix B. Test Problems (by Robert Schnabel) References Author Index Subject Index."
            },
            "slug": "Numerical-methods-for-unconstrained-optimization-Dennis-Schnabel",
            "title": {
                "fragments": [],
                "text": "Numerical methods for unconstrained optimization and nonlinear equations"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Newton's Method for Nonlinear Equations and Unconstrained Minimization and methods for solving nonlinear least-squares problems with Special Structure."
            },
            "venue": {
                "fragments": [],
                "text": "Prentice Hall series in computational mathematics"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hand shape identiication and tracking for sign language interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "Looking at People Workshop, IJCAI"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gait analysiss precise, rapid, automatic, 3-d position and orientation kinematics and dynamics"
            },
            "venue": {
                "fragments": [],
                "text": "BULLETIN of the Hospital for Joint Diseases Orthopaedic Institute"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "First, markers or gloves are often used to simplify motion analysis [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [4], Dorner describes a system for interpreting American Sign Language from image sequences of a single hand."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hand shape identi cation and tracking for sign language interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "In Looking at People Workshop,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "Current commercially available solutions are invasive, and require the user to don gloves [15] or wear targets [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A hand ges ture interface device"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. Human Factors in Comp. Sys. and Graphics Interface (CHI+GI'87),"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Visual-Tracking-of-High-DOF-Articulated-Structures:-Rehg-Kanade/c51f0d3f863fdde988cfada25f1a07a224889129?sort=total-citations"
}