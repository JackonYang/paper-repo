{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076817912"
                        ],
                        "name": "P. Pritchett",
                        "slug": "P.-Pritchett",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Pritchett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pritchett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 43
                            }
                        ],
                        "text": "Current approaches to wide baseline stereo\nPritchett and Zisserman [15] describe their approach which is to generate sets of local planar homographies and to use these for two purposes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Pritchett and Zisserman [15] describe their approach which is to generate sets of local planar homographies and to use these for two purposes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46527015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4da91ba2e80a4d8deb597b1c884cda890f086653",
            "isKey": false,
            "numCitedBy": 351,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically. This facilitates matching between quite disparate views-wide baseline stereo. Two extensions are made to the current small baseline algorithms: first, and most importantly, a viewpoint invariant measure is developed for assessing the affinity of corner neighbourhoods over image pairs; second, algorithms are given for generating putative corner matches between image pairs using local homographies. Two novel infrastructure developments are also described: the automatic generation of local homographies, and the combination of possibly conflicting sets of matches prior to RANSAC estimation. The wide baseline matching algorithm is demonstrated on a number of image pairs with varying relative motion, and for different scene types. All processing is automatic."
            },
            "slug": "Wide-baseline-stereo-matching-Pritchett-Zisserman",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo matching"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The objective of this work is to enlarge the class of camera motions for which epipolar geometry and image correspondences can be computed automatically, and to facilitate matching between quite disparate views-wide baseline stereo."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "More recently, Lowe [13] describes a Scale Invariant Feature Transform (SIFT) approach where scale-space features are detected and characterised in a manner invariant to location, scale and orientation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": false,
            "numCitedBy": 16255,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398826846"
                        ],
                        "name": "V. Gouet-Brunet",
                        "slug": "V.-Gouet-Brunet",
                        "structuredName": {
                            "firstName": "Val\u00e9rie",
                            "lastName": "Gouet-Brunet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Gouet-Brunet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143921197"
                        ],
                        "name": "P. Montesinos",
                        "slug": "P.-Montesinos",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Montesinos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Montesinos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40220023"
                        ],
                        "name": "D. Pele",
                        "slug": "D.-Pele",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Pele",
                            "middleNames": [
                                "Traian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 168
                            }
                        ],
                        "text": "Once the image patch has been normalised for stretch and skew we use a conventional intensity (or colour) normalisation algorithm such as that described by Gouet et al [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "Gouetet al describe an approach based on image invariants [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 189
                            }
                        ],
                        "text": "Normalising for lighting changes\nOnce the image patch has been normalised for stretch and skew we use a conventional intensity (or colour) normalisation algorithm such as that described by Gouet et al [7]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12786197,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d8101853a6ace159b72d79eece54ac94fe2ed1f",
            "isKey": true,
            "numCitedBy": 28,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new method for point matching in stereoscopic color images. Our approach consists rst in characterizing points of interest using di erential invariants. Then we de ne additional rst order invariants using color information, which make su\u00c6cient the characterization till rst order. In addition, we make our description robust to important image transformations like rotation, range of viewpoint and linear illumination variations. Second, we propose a new incremental technique for point matching using our characterization, which works robustly and rapidly whatever the number of points to be matched. Our stereo matching scheme is evaluated using stereo color images, with viewpoint and illumination variations. The very good results obtained clearly show the pertinence of our approach. Our color characterization produces a high rate of good matches, even though only rst order derivatives are used. Results on images holding many points show that our matching process is robust and rapidly implemented even if the points to be matched are numerous. It is a great asset, when matching a high set of points is necessary for example to realize dense depth maps between images. 1 Key word : Color Images, Di erential Invariants, Stereo Matching, Transfer Methods. This work was supported by a CCETT grant 96-ME-24. BMVC 1998 doi:10.5244/C.12.37 368 British Machine Vision Conference"
            },
            "slug": "A-Fast-Matching-Method-for-Color-Uncalibrated-using-Gouet-Brunet-Montesinos",
            "title": {
                "fragments": [],
                "text": "A Fast Matching Method for Color Uncalibrated Images using Differential Invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes a new incremental technique for point matching using the authors' characterization, which works robustly and rapidly whatever the number of points to be matched, and produces a high rate of good matches, even though only rst order derivatives are used."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145796910"
                        ],
                        "name": "J. Sato",
                        "slug": "J.-Sato",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Sato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "Sato and Cipolla consider the statistics of image texture features over the whole image to recover affine transformations [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2888923,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2eba58aad601640b66e3a8c2f31fdd8651745840",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a novel, efficient and geometrically intuitive method to compute the four components of an affine transformation from the change in simple statistics of images of texture. In particular we show how the changes in first, second and third moments of edge orientation and changes in density are directly related to the rotation (curl), scale (divergence) and deformation components of an affine transformation. A simple implementation is described which does not require point, edge or contour correspondences to be established. It is tested on a wide range of repetitive and non-repetitive visual textures which are neither isotropic nor homogeneous. As a demonstration of the power of this technique the estimated affine transforms are used as the first stage in shape from texture and structure from motion applications."
            },
            "slug": "Extracting-the-Affine-Transformation-from-Texture-Sato-Cipolla",
            "title": {
                "fragments": [],
                "text": "Extracting the Affine Transformation from Texture Moments"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A novel, efficient and geometrically intuitive method to compute the four components of an affine transformation from the change in simple statistics of images of texture is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702017"
                        ],
                        "name": "R. Deriche",
                        "slug": "R.-Deriche",
                        "structuredName": {
                            "firstName": "Rachid",
                            "lastName": "Deriche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Deriche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51064498"
                        ],
                        "name": "Zhengyou Zhang",
                        "slug": "Zhengyou-Zhang",
                        "structuredName": {
                            "firstName": "Zhengyou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyou Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 58
                            }
                        ],
                        "text": "There has been much work with short baseline images (e.g. Deriche [2], Xu [20]) as well as tracking features through video sequences (e.g. Tomasi and Shi [19])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "Deriche [2], Xu [20]) as well as tracking features through video sequences (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "We use an ambiguity measure similar to that used by Deriche [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "A general approach to matching uncalibrated images is described by Deriche [2]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13587889,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f0261505e0086c33c03035e24963c9481896e1e1",
            "isKey": true,
            "numCitedBy": 198,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of accurately and automatically recovering the epipolar geometry from an uncalibrated stereo rig and its application to the image matching problem. A robust correlation based approach that eliminates outliers is developed to produce a reliable set of corresponding high curvature points. These points are used to estimate the so-called Fundamental Matrix which is closely related to the epipolar geometry of the uncalibrated stereo rig. We show that an accurate determination of this matrix is a central problem. Using a linear criterion in the estimation of this matrix is shown to yield erroneous results. Different parameterization and non-linear criteria are then developed to take into account the specific constraints of the Fundamental Matrix providing more accurate results. Various experimental results on real images illustrates the approach."
            },
            "slug": "Robust-Recovery-of-the-Epipolar-Geometry-for-an-Rig-Deriche-Zhang",
            "title": {
                "fragments": [],
                "text": "Robust Recovery of the Epipolar Geometry for an Uncalibrated Stereo Rig"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A robust correlation based approach that eliminates outliers is developed to produce a reliable set of corresponding high curvature points that are used to estimate the so-called Fundamental Matrix which is closely related to the epipolar geometry of the uncalibrated stereo rig."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777539"
                        ],
                        "name": "P. Beardsley",
                        "slug": "P.-Beardsley",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Beardsley",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Beardsley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "In fact in our application this is the information we wish to determine from the image feature matches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45380280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92e9d8d6ed560f58cd32a72ede6c6252fb1b8311",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for matching image primitives through a sequence is described, for the purpose of acquiring 3D geometric models. The method includes a novel robust estimator of the trifocal tensor, based on a minimum number of token correspondences across an image triplet; and a novel tracking algorithm in which corners and line segments are matched over image triplets in an integrated framework. The matching techniques are both robust (detecting and discarding mismatches) and fully automatic."
            },
            "slug": "3D-Model-Acquisition-from-Extended-Image-Sequences-Beardsley-Torr",
            "title": {
                "fragments": [],
                "text": "3D Model Acquisition from Extended Image Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A method for matching image primitives through a sequence is described, for the purpose of acquiring 3D geometric models, which includes a novel robust estimator of the trifocal tensor, based on a minimum number of token correspondences across an image triplet."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Tomasi and Shi [19])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 778478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ab46391005cea85fa5c204b6e77a9c870fdbaed",
            "isKey": false,
            "numCitedBy": 8402,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. We propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world. These methods are based on a new tracking algorithm that extends previous Newton-Raphson style search methods to work under affine image transformations. We test performance with several simulations and experiments.<<ETX>>"
            },
            "slug": "Good-features-to-track-Shi-Tomasi",
            "title": {
                "fragments": [],
                "text": "Good features to track"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2169983565"
                        ],
                        "name": "G. Xu",
                        "slug": "G.-Xu",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Xu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Deriche [2], Xu [20]) as well as tracking features through video sequences (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64330066,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff666fdf5cd56008cf376fee5749e45a7377a4db",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Videre: Journal of Computer Vision Research (ISSN 1089-2788) is a quarterly journal published electronically on the Internet by The MIT Press, Cambridge, Massachusetts, 02142. Subscriptions and address changes should be addressed to MIT Press Journals, Five Cambridge Center, Cambridge, MA 02142; phone: (617) 253-2889; fax: (617) 577-1545; e-mail: journals-orders@mit.edu. Subscription rates are: Individuals $30.00, Institutions $125.00. Canadians add additional 7% GST. Prices subject to change without notice."
            },
            "slug": "A-unified-approach-to-image-matching-and-in-stereo,-Xu",
            "title": {
                "fragments": [],
                "text": "A unified approach to image matching and segmentation in stereo, motion and object recognition via recovery of epipolar geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "Videre: Journal of Computer Vision Research is a quarterly journal published electronically on the Internet by The MIT Press, Cambridge, Massachusetts, 02142 and prices subject to change without notice."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40309692"
                        ],
                        "name": "C. G. Harris",
                        "slug": "C.-G.-Harris",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40365651"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stephens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "Hence we have found that a better approach is to detect spatial Harris features [9] at a set of scales and order these features based on a scalenormalised feature strength as follows."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1694378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6818668fb895d95861a2eb9673ddc3a41e27b3b3",
            "isKey": false,
            "numCitedBy": 14111,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed."
            },
            "slug": "A-Combined-Corner-and-Edge-Detector-Harris-Stephens",
            "title": {
                "fragments": [],
                "text": "A Combined Corner and Edge Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem the authors are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work."
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "Schmid and Mohr describe an approach to indexing greyscale intensity images using differential rotation invariants calculated at multiple scales [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3260234"
                        ],
                        "name": "J. G\u00e5rding",
                        "slug": "J.-G\u00e5rding",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "G\u00e5rding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. G\u00e5rding"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "The algorithm extends the idea of shape-adapted texture descriptors as described by Lindeberg [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 83
                            }
                        ],
                        "text": "An obvious future step would be to implement the full scale adaptation approach of Lindeberg."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "Lindeberg shows that if moment image descriptors are calculated under these conditions then the image descriptors will be relative invariant under arbitrary affine transformations (see [12] for details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "Lindeberg points out that there are two scales that can be varied in the calculation ofM \u2013 the integration scale, and the \u201clocal scale\u201d at which derivatives are calculated,t."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 90
                            }
                        ],
                        "text": "We use the determinant and trace of the scale normalised 2nd moment matrix (as defined by Lindeberg [11]) to calculate a scale normalised corner strength measure."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 47
                            }
                        ],
                        "text": "L(qL; t;L; s;L) = ML\nt;L = tM 1 L s;L = sM 1 L\nLindeberg shows that if moment image descriptors are calculated under these conditions then the image descriptors will be relative invariant under arbitrary affine transformations (see [12] for details)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 113
                            }
                        ],
                        "text": "We have found that in practice true scale-space features such as scale-space maxima of a \u201ccornerness\u201d measure (see Lindeberg [11]) are not reliably detectable."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 75
                            }
                        ],
                        "text": "In practice for this part of the algorithm, we use a simplified version of Lindeberg\u2019s shape adaptation scheme."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 6
                            }
                        ],
                        "text": "Using Lindeberg\u2019s notation we define the following second moment descriptor, L by\nL(:; t; s) = g(:; s) ((rL)(:; t)(rL)(; ; t)T )\nwhereL(:; ) is the affine Gaussian scale-space representation for an intensity imageI(:), t is a covariance matrix corresponding to the local scale and s is a covariance matrix corresponding to the integration scale."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 47
                            }
                        ],
                        "text": "We observe that the shape adaptation scheme of Lindeberg can be used to determine a stretch-skew normalised image patch as follows."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "Lindeberg describes an iterative procedure for adapting the shape matrices such that the following \u201cfixed point\u201d property holds for some matrixML."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "Lindeberg derives the following transformation property for affine scale-space second moment matrices."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "Lindeberg extends the notion of scale space to \u201caffine Gaussian scale-space\u201d."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18264626,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f87bcdf4a0dc79f85e171ec26733424d0e459cd2",
            "isKey": true,
            "numCitedBy": 290,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Shape-adapted-smoothing-in-estimation-of-3-D-shape-Lindeberg-G\u00e5rding",
            "title": {
                "fragments": [],
                "text": "Shape-adapted smoothing in estimation of 3-D shape cues from affine deformations of local 2-D brightness structure"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144929642"
                        ],
                        "name": "A. Kadyrov",
                        "slug": "A.-Kadyrov",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Kadyrov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kadyrov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 94
                            }
                        ],
                        "text": "Affine invariants have been used for recognition purposes (e.g. moment invariants are used by Kadyrov [10], Flusser and Suk [6] and photometric affine invariants by Van Gool [14])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "moment invariants are used by Kadyrov [10], Flusser and Suk [6] and photometric affine invariants by Van Gool [14])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28568544,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "60caa074043be6ba1fb24ea66830eb87d43d7552",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The theory of trace transformations and triple features is extended to a new area. In previous papers it was introduced for conformai distortion of images. Many triple features of images are proposed making use of this new theory. Some of the features are independent of shifting, rotating and shrinking images. Others are dependent on these transformations with a simple manner. So we are able to recognise a pattern and clarify its parameters of displacement, rotation and sizing. In this paper we consider triple features which are independent of its linear distortion also. The meaning of these triple features is unknown beforehand because of great number of them, however PC experiments prove their usefulness."
            },
            "slug": "Triple-Features-for-Linear-Distorted-Images-Kadyrov",
            "title": {
                "fragments": [],
                "text": "Triple Features for Linear Distorted Images"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper considers triple features which are independent of its linear distortion also and is able to recognise a pattern and clarify its parameters of displacement, rotation and sizing."
            },
            "venue": {
                "fragments": [],
                "text": "CAIP"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50818863"
                        ],
                        "name": "A. Gruen",
                        "slug": "A.-Gruen",
                        "structuredName": {
                            "firstName": "Armin",
                            "lastName": "Gruen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gruen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This means that corner strengths can be compared across different scales and the top \u2018n\u2019 corners over all detected scales can be determined."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17649126,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ea8085172671e9870dfdb2b835d42c6f1f6fa5ef",
            "isKey": false,
            "numCitedBy": 779,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The Adaptive Least Squares Correlation is a very potent and flexible technique for all kinds of data matching problems. Here its application to image matching is outlined. It allows for simultaneous radiometric corrections and local geometrical image shaping, whereby the system parameters are automatically assessed, corrected, and thus optimized during the least squares iterations. The various tools of least squares estimation can be favourably utilized for the assessment of the correlation quality. Furthermore, the system allows for stabilization and improvement of the correlation procedure through the simultaneous consideration of geometrical constraints, e.g. the collinearity condition. Some exciting new perspectives are emphasized, as for example multiphoto correlation, multitemporal and multisensor correlation, multipoint correlation, and simultaneous correlation/triangulation."
            },
            "slug": "ADAPTIVE-LEAST-SQUARES-CORRELATION:-A-POWERFUL-Gruen",
            "title": {
                "fragments": [],
                "text": "ADAPTIVE LEAST SQUARES CORRELATION: A POWERFUL IMAGE MATCHING TECHNIQUE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 972888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278c9a78d4505cfaf6b709df364dbd1206a017c1",
            "isKey": false,
            "numCitedBy": 15951,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing"
            },
            "slug": "Random-sample-consensus:-a-paradigm-for-model-with-Fischler-Bolles",
            "title": {
                "fragments": [],
                "text": "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "New results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form that provide the basis for an automatic system that can solve the Location Determination Problem under difficult viewing."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2190567"
                        ],
                        "name": "L. Falkenhagen",
                        "slug": "L.-Falkenhagen",
                        "structuredName": {
                            "firstName": "Lutz",
                            "lastName": "Falkenhagen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Falkenhagen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6149819,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "0be610c208cb2412c8841005aa963a9d9f797263",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for estimating reliable and accurate depth maps from stereoscopic image pairs is presented, which is based on block-atching techniques for disparity estimation. By taking neighboring disparity values into account, reliability and accuracy of the estimated disparity values are increased and the corona effect at disparity discontinuities is avoided. An interpolation of disparity values within segmented regions of homogeneous disparity enables the computation of dense depth maps by means of triangulation."
            },
            "slug": "Depth-Estimation-from-Stereoscopic-Image-Pairs-Falkenhagen",
            "title": {
                "fragments": [],
                "text": "Depth Estimation from Stereoscopic Image Pairs Assuming Piecewise Continuos Surfaces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700379"
                        ],
                        "name": "Y. Shirai",
                        "slug": "Y.-Shirai",
                        "structuredName": {
                            "firstName": "Yoshiaki",
                            "lastName": "Shirai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shirai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "The conventional convergent stereo configuration makes the correspondence problem much easier because for any given point in the left image, the corresponding point in the right image lies on a known epipolar line."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37768423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "241ef2d7ac03ecd3996e6117839fa8cee3d33c6f",
            "isKey": false,
            "numCitedBy": 962,
            "numCiting": 104,
            "paperAbstract": {
                "fragments": [],
                "text": "There are some difficulties in applying 3-dimensional computer vision to industry. One of them is that a vast amount of computation is required for low level processing. Some special hardware systems are described and one device is shown in more detail. Applications of the hardware are discussed in three examples. Two methods for range data acquisition employing special processors are described. Then our studies for range data processing are introduced. Finally, a complete production system is proposed which makes use of unified geometric models to be shared by CAD, CAM, and visual processing. This approach can solve a second difficulty in applying 3-dimensional computer vision to industry, namely the problem of the extensive programming effort that is required."
            },
            "slug": "Three-Dimensional-Computer-Vision-Shirai",
            "title": {
                "fragments": [],
                "text": "Three-Dimensional Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A complete production system is proposed which makes use of unified geometric models to be shared by CAD, CAM, and visual processing, and can solve a second difficulty in applying 3-dimensional computer vision to industry, namely the problem of the extensive programming effort."
            },
            "venue": {
                "fragments": [],
                "text": "Symbolic Computation"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749525"
                        ],
                        "name": "J. Flusser",
                        "slug": "J.-Flusser",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Flusser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Flusser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2890846"
                        ],
                        "name": "T. Suk",
                        "slug": "T.-Suk",
                        "structuredName": {
                            "firstName": "Tom\u00e1\u0161",
                            "lastName": "Suk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Suk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 108
                            }
                        ],
                        "text": "Affine invariants have been used for recognition purposes (e.g. moment invariants are used by Kadyrov [10], Flusser and Suk [6] and photometric affine invariants by Van Gool [14])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "moment invariants are used by Kadyrov [10], Flusser and Suk [6] and photometric affine invariants by Van Gool [14])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32435779,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ab69bb4099518e12a87717d494ac9b7d33359321",
            "isKey": false,
            "numCitedBy": 814,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-recognition-by-affine-moment-invariants-Flusser-Suk",
            "title": {
                "fragments": [],
                "text": "Pattern recognition by affine moment invariants"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "We have found that in practice true scale-space features such as scale-space maxima of a \u201ccornerness\u201d measure (see Lindeberg [11]) are not reliably detectable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "We use the determinant and trace of the scale normalised 2nd moment matrix (as defined by Lindeberg [11]) to calculate a scale normalised corner strength measure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10336140,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c55dfe48a3c49a6dc366d50a60521f73aa31151a",
            "isKey": false,
            "numCitedBy": 2435,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A basic problem when deriving information from measured data, such as images, originates from the fact that objects in the world, and hence image structures, exist as meaningful entities only over ..."
            },
            "slug": "Scale-Space-Theory-in-Computer-Vision-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Scale-Space Theory in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A basic problem when deriving information from measured data, such as images, originates from the fact that objects in the world, and hence image structures, exist as meaningful entities only over measured data."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66957615"
                        ],
                        "name": "R. J. Schalko",
                        "slug": "R.-J.-Schalko",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Schalko",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J. Schalko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "In practice we use a variant of the Fourier-Mellin transformation [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58770897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a995e33e958dd7dc801b12e029154ced1b8fc9ca",
            "isKey": false,
            "numCitedBy": 238,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Digital-Image-Processing-and-Computer-Vision-Schalko",
            "title": {
                "fragments": [],
                "text": "Digital Image Processing and Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IEEE"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo match"
            },
            "venue": {
                "fragments": [],
                "text": "In ICCV"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 21,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Reliable-feature-matching-across-widely-separated-Baumberg/67f693427d956c0dbc822e7f3452aee8ca36204b?sort=total-citations"
}