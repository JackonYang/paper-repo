{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60458454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69859be3ea6cb8eb38434c80fef5d4997eaec2dc",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation introduces a new theoretical model for text classification systems, including systems for document retrieval, automated indexing, electronic mail filtering, and similar tasks. The Concept Learning model emphasizes the role of manual and automated feature selection and classifier formation in text classification. It enables drawing on results from statistics and machine learning in explaining the effectiveness of alternate representations of text, and specifies desirable characteristics of text representations. \nThe use of syntactic parsing to produce indexing phrases has been widely investigated as a possible route to better text representations. Experiments with syntactic phrase indexing, however, have never yielded significant improvements in text retrieval performance. The Concept Learning model suggests that the poor statistical characteristics of a syntactic indexing phrase representation negate its desirable semantic characteristics. The application of term clustering to this representation to improve its statistical properties while retaining its desirable meaning properties is proposed. \nStandard term clustering strategies from information retrieval (IR), based on cooccurrence of indexing terms in documents or groups of documents, were tested on a syntactic indexing phrase representation. In experiments using a standard text retrieval test collection, small effectiveness improvements were obtained. \nAs a means of evaluating representation quality, a text retrieval test collection introduces a number of confounding factors. In contrast, the text categorization task allows much cleaner determination of text representation properties. In preparation for the use of text categorization to study text representation, a more effective and theoretically well-founded probabilistic text categorization algorithm was developed, building on work by Maron, Fuhr, and others. \nText categorization experiments supported a number of predictions of the Concept Learning model about properties of phrasal representations, including dimensionality properties not previously measured for text representations. However, in carefully controlled experiments using syntactic phrases produced by Church's stochastic bracketer, in conjunction with reciprocal nearest neighbor clustering, term clustering was found to produce essentially no improvement in the properties of the phrasal representation. New cluster analysis approaches are proposed to remedy the problems found in traditional term clustering methods."
            },
            "slug": "Representation-and-Learning-in-Information-Lewis",
            "title": {
                "fragments": [],
                "text": "Representation and Learning in Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new theoretical model for text classification systems, including systems for document retrieval, automated indexing, electronic mail filtering, and similar tasks, is introduced, suggesting that the poor statistical characteristics of a syntactic indexing phrase representation negate its desirable semantic characteristics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 526032,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6160d37a7871cef2d6450832507b53201aa66682",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "While certain standard procedures are widely used for evaluating text retrieval systems and algorithms, the same is not true for text categorization. Omission of important data from reports is common and methods of measuring effectiveness vary widely. This has made judging the relative merits of techniques for text categorization difficult and has disguised important research issues.In this paper I discuss a variety of ways of evaluating the effectiveness of text categorization systems, drawing both on reported categorization experiments and on methods used in evaluating query-driven retrieval. I also consider the extent to which the same evaluation methods may be used with systems for text extraction, a more complex task. In evaluating either kind of system, the purpose for which the output is to be used is crucial in choosing appropriate evaluation methods."
            },
            "slug": "Evaluating-Text-Categorization-I-Lewis",
            "title": {
                "fragments": [],
                "text": "Evaluating Text Categorization I"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A variety of ways of evaluating the effectiveness of text categorization systems are discussed, drawing both on reported categorization experiments and on methods used in evaluating query-driven retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16644750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07f0f4553cfb42c0ed2bd6b07c9b22777b313d8",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic phrase indexing and term clustering have been widely explored as text representation techniques for text retrieval. In this paper we study the properties of phrasal and clustered indexing languages on a text categorization task, enabling us to study their properties in isolation from query interpretation issues. We show that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing. We also present results suggesting that traditional term clustering method are unlikely to provide significantly improved text representations. An improved probabilistic text categorization method is also presented."
            },
            "slug": "An-evaluation-of-phrasal-and-clustered-on-a-text-Lewis",
            "title": {
                "fragments": [],
                "text": "An evaluation of phrasal and clustered representations on a text categorization task"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403733672"
                        ],
                        "name": "Natasha Vleduts-Stokolov",
                        "slug": "Natasha-Vleduts-Stokolov",
                        "structuredName": {
                            "firstName": "Natasha",
                            "lastName": "Vleduts-Stokolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Natasha Vleduts-Stokolov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62724258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8774b04fe79a65c78bd438a9f67d023c0deef4f3",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes a natural\u2010language text\u2010processing system designed as an automatic aid to subject indexing at BIOSIS. The intellectual procedure the system should model is a deep indexing with a controlled vocabulary of biological concepts \u2014 Concept Headings (CHs). On the average, ten CHs are assigned to each article by BIOSIS indexers. The automatic procedure consists of two stages: (1) translation of natural\u2010language biological titles into title\u2010semantic representations which are in the constructed formalized language of Concept Primitives, and (2) translation of the latter representations into the language of CHs. The first stage is performed by matching the titles against the system's Semantic Vocabulary (SV). The SV currently contains approximately 15,000 biological natural\u2010language terms and their translations in the language of Concept Primitives. For the ambiguous terms, the SV contains the algorithmical rules of term disambiguation, rules based on semantic analysis of the contexts. The second stage of the automatic procedure is performed by matching the title representations against the CH definitions, formulated as Boolean search strategies in the language of Concept Primitives. Three experiments performed with the system and their results are described. The most typical problems the system encounters, the problems of lexical and situational ambiguities, are discussed. The disambiguation techniques employed are described and demonstrated in many examples. \u00a9 1987 John Wiley & Sons, Inc."
            },
            "slug": "Concept-recognition-in-an-automatic-text\u2010processing-Vleduts-Stokolov",
            "title": {
                "fragments": [],
                "text": "Concept recognition in an automatic text\u2010processing system for the life sciences"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A natural\u2010language text\u2010processing system designed as an automatic aid to subject indexing at BIOSIS with the most typical problems the system encounters, the problems of lexical and situational ambiguities, are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144864352"
                        ],
                        "name": "M. Maron",
                        "slug": "M.-Maron",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Maron",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6692916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c390dbf06af49d3691bc7b906f5fd9b909c2f89b",
            "isKey": false,
            "numCitedBy": 519,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "This inquiry examines a technique for automatically classifying (indexing) documents according to their subject content. The task, in essence, is to have a computing machine read a document and on the basis of the occurrence of selected clue words decide to which of many subject categories the document in question belongs. This paper describes the design, execution and evaluation of a modest experimental study aimed at testing empirically one statistical technique for automatic indexing."
            },
            "slug": "Automatic-Indexing:-An-Experimental-Inquiry-Maron",
            "title": {
                "fragments": [],
                "text": "Automatic Indexing: An Experimental Inquiry"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The design, execution and evaluation of a modest experimental study aimed at testing empirically one statistical technique for automatic indexed documents according to their subject content are described."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642798"
                        ],
                        "name": "Stuart L. Crawford",
                        "slug": "Stuart-L.-Crawford",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Crawford",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart L. Crawford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25238251"
                        ],
                        "name": "R. Fung",
                        "slug": "R.-Fung",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fung",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1812139"
                        ],
                        "name": "L. Appelbaum",
                        "slug": "L.-Appelbaum",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Appelbaum",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Appelbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724728"
                        ],
                        "name": "R. Tong",
                        "slug": "R.-Tong",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Tong",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30957556,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "d940db7869f1df33c1d266c13a537258bd5ac2f6",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Classification-Trees-for-Information-Retrieval-Crawford-Fung",
            "title": {
                "fragments": [],
                "text": "Classification Trees for Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "ML"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 196019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cc2269aaf62399eed33e1c7cb210de2405d1159",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The data extraction systems studied in the MUC-3 evaluation perform a variety of subtasks in filling out templates. Some of these tasks are quite complex, and seem to require a system to represent the structure of a text in some detail to perform the task successfully. Capturing reference relations between slot fillers, distinguishing between historic and recent events, and many other subtasks appear to have this character."
            },
            "slug": "Data-extraction-as-text-categorization:-an-with-the-Lewis",
            "title": {
                "fragments": [],
                "text": "Data extraction as text categorization: an experiment with the MUC-3 corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "The data extraction systems studied in the MUC-3 evaluation perform a variety of subtasks in filling out templates that seem to require a system to represent the structure of a text in some detail to perform the task successfully."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428001"
                        ],
                        "name": "P. Hayes",
                        "slug": "P.-Hayes",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Hayes",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hayes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053034118"
                        ],
                        "name": "S. P. Weinstein",
                        "slug": "S.-P.-Weinstein",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Weinstein",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. P. Weinstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18312939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01d6d53fce6fac2a33d92ddf096290d6b99c2d13",
            "isKey": false,
            "numCitedBy": 230,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The Construe news story categorization system assigns indexing terms to news stories according to their content using knowledge-based techniques. An initial deployment of Construe in Reuters Ltd. topic identification system (TIS) has replaced human indexing for Reuters Country Reports, an online information service based on news stories indexed by country and type of news. TIS indexing is comparable to human indexing in overall accuracy but costs much less, is more consistent, and is available much more rapidly. TIS can be justified in terms of cost savings alone, but Reuters also expects the speed and consistency of TIS to provide significant competitive advantage and, hence, an increased market share for Country Reports and other products from Reuters Historical Information Products Division."
            },
            "slug": "CONSTRUE/TIS:-A-System-for-Content-Based-Indexing-a-Hayes-Weinstein",
            "title": {
                "fragments": [],
                "text": "CONSTRUE/TIS: A System for Content-Based Indexing of a Database of News Stories"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The Construe news story categorization system assigns indexing terms to news stories according to their content using knowledge-based techniques and Reuters expects the speed and consistency of TIS to provide significant competitive advantage and, hence, an increased market share for Country Reports and other products from Reuters Historical Information Products Division."
            },
            "venue": {
                "fragments": [],
                "text": "IAAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770316"
                        ],
                        "name": "P. Jacobs",
                        "slug": "P.-Jacobs",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jacobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2685671"
                        ],
                        "name": "L. F. Rau",
                        "slug": "L.-F.-Rau",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Rau",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. F. Rau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11515711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e5c33ab632310d827155002311e0adceebb6ec0",
            "isKey": false,
            "numCitedBy": 309,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The future of natural language text processing is examined in the SCISOR prototype. Drawing on artificial intelligence techniques, and applying them to financial news items, this powerful tool illustrates some of the future benefits of natural language analysis through a combination of bottom-up and top-down processing."
            },
            "slug": "SCISOR:-extracting-information-from-on-line-news-Jacobs-Rau",
            "title": {
                "fragments": [],
                "text": "SCISOR: extracting information from on-line news"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "The future of natural language text processing is examined in the SCISOR prototype, drawing on artificial intelligence techniques, and applying them to financial news items through a combination of bottom-up and top-down processing."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70219052"
                        ],
                        "name": "Wray L. Buntine",
                        "slug": "Wray-L.-Buntine",
                        "structuredName": {
                            "firstName": "Wray",
                            "lastName": "Buntine",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wray L. Buntine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145727186"
                        ],
                        "name": "R. Caruana",
                        "slug": "R.-Caruana",
                        "structuredName": {
                            "firstName": "Rich",
                            "lastName": "Caruana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Caruana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 123174972,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b1888a2b01fde65d30c2455db24da290f36eb1be",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "This manual describes the IND package for learning tree classifiers from data. The package is an integrated C and C shell re-implementation of tree learning routines such as CART, C4, and various MDL and Bayesian variations. The package includes routines for experiment control, interactive operation, and analysis of tree building. The manual introduces the system and its many options, gives a basic review of tree learning, contains a guide to the literature and a glossary, and lists the manual pages for the routines and instructions on installation."
            },
            "slug": "Introduction-in-IND-and-recursive-partitioning-Buntine-Caruana",
            "title": {
                "fragments": [],
                "text": "Introduction in IND and recursive partitioning"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This manual describes the IND package for learning tree classifiers from data, an integrated C and C shell re-implementation of tree learning routines such as CART, C4, and various MDL and Bayesian variations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701772"
                        ],
                        "name": "L. B. Balcom",
                        "slug": "L.-B.-Balcom",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Balcom",
                            "middleNames": [
                                "Blumer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. B. Balcom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724728"
                        ],
                        "name": "R. Tong",
                        "slug": "R.-Tong",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Tong",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11826614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c339bc0e17854b8ea7e85965fba8a92fadadf319",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "ADS has been developing an approach to text processing, called CODEX, COntext directed Data EXtraction), that couples a concept-based, probabilistic keyword pattern matcher, called RUBRIC, with a probabilistic, generalized graph composition chart parser, called CAUCUS. We configure these two key technologies together for a variety of natural language sorting and gisting applications to provide greater depth of analysis (higher precision) than keyword-based techniques alone, as well as higher throughput and greater breadth of coverage than parsing techniques alone."
            },
            "slug": "Advanced-Decision-Systems:-description-of-the-CODEX-Balcom-Tong",
            "title": {
                "fragments": [],
                "text": "Advanced Decision Systems: description of the CODEX system as used for MUC-3"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work configure these two key technologies together for a variety of natural language sorting and gisting applications to provide greater depth of analysis (higher precision) than keyword-based techniques alone, as well as higher throughput and greater breadth of coverage than parsing techniques alone."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2195972"
                        ],
                        "name": "P. Utgoff",
                        "slug": "P.-Utgoff",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Utgoff",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Utgoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61047266,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "f5157391985e1b8b451461f3350e9f91e697b76f",
            "isKey": false,
            "numCitedBy": 375,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We identify and examine the fundamental role that bias plays in inductive concept learning. Bias is the set of all influences, procedural or declarative, that causes a concept learner to prefer one hypothesis to another. Much of the success of concept learning programs to date results from the program's author having provided the learning program with appropriate bias. To date there has been no good mechanical method for shifting from one bias to another that is better. Instead, the author of a learning program has himself had to search for a better bias. The program author manually generates a bias, from scratch or by revising a previous bias, and then tests it in his program. If the author is not satisfied with the induced concepts, then he repeats the manual-generate and program-test cycle. If the author is satisfied, then he deems his program successful. Too often, he does not recognize his own role in the learning process. \nOur thesis is that search for appropriate bias is itself a major part of the learning task, and that we can create mechanical procedures for conducting a well-directed search for an appropriate bias. We would like to understand better how a program author goes about doing his search for appropriate bias. What insights does he have? What does he learn when he observes that a particular bias produces poor performance? What domain knowledge does he apply? \nWe explore the problem of mechanizing the search for appropriate bias. To that end, we develop a framework for a procedure that shifts bias. We then build two instantiations of the procedure in a program called STABB, which we then incorporate in the LEX learning program. One, called \"least disjunction\", uses simple syntactic manipulation, and the other, called \"constraint back propagation\" uses analytic deduction. We report experiments with the implementations that both demonstrate the usefulness of the framework, and uncover important issues for this kind of learning."
            },
            "slug": "Shift-of-bias-for-inductive-concept-learning-Utgoff",
            "title": {
                "fragments": [],
                "text": "Shift of bias for inductive concept learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that search for appropriate bias is itself a major part of the learning task, and that mechanical procedures for conducting a well-directed search for an appropriate bias can be created."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10164826,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d30aa623fd96da99a16c0c3bde73f50c92a5c42",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "It is difficult to estimate the probability of a word's context because of sparse data problems. If appropriate care is taken, we find that it is possible to make useful estimates of contextual probabilities that improve performance in a spelling correction application. In contrast, less careful estimates are found to be useless. Specifically, we will show that the Good-Turing method makes the use of contextual information practical for a spelling corrector, while attempts to use the maximum likelihood estimator (MLE) or expected likelihood estimator (ELE) fail. Spelling correction was selected as an application domain because it is analogous to many important recognition applications based on a noisy channel model (such as speech recognition), though somewhat simpler and therefore possibly more amenable to detailed statistical analysis."
            },
            "slug": "Poor-Estimates-of-Context-are-Worse-than-None-Gale-Church",
            "title": {
                "fragments": [],
                "text": "Poor Estimates of Context are Worse than None"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "It is found that it is possible to make useful estimates of contextual probabilities that improve performance in a spelling correction application, and it is shown that the Good-Turing method makes the use of contextual information practical for a spelling corrector."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145897843"
                        ],
                        "name": "Kathleen Dahlgren",
                        "slug": "Kathleen-Dahlgren",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "Dahlgren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kathleen Dahlgren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39160595"
                        ],
                        "name": "Carol Lord",
                        "slug": "Carol-Lord",
                        "structuredName": {
                            "firstName": "Carol",
                            "lastName": "Lord",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carol Lord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056972919"
                        ],
                        "name": "H. Wada",
                        "slug": "H.-Wada",
                        "structuredName": {
                            "firstName": "Hajime",
                            "lastName": "Wada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2569030"
                        ],
                        "name": "Joyce P. McDowell",
                        "slug": "Joyce-P.-McDowell",
                        "structuredName": {
                            "firstName": "Joyce",
                            "lastName": "McDowell",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joyce P. McDowell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1998886"
                        ],
                        "name": "E. Stabler",
                        "slug": "E.-Stabler",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Stabler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Stabler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18660316,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68d4ac76a3d1b3fd854a5c3dd5136ec8d7e4e868",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Intelligent Text Processing is a small start-up company participating in the MUC-3 exercise for the first time this year. Our system, Interpretext, is based on a prototype text understanding system. With three full-time and three part-time people, dividing time between MUC-3 and other contract projects, ITP made maximum use of modest resources."
            },
            "slug": "ITP-Interpretext-System:-MUC-3-Test-Results-and-Dahlgren-Lord",
            "title": {
                "fragments": [],
                "text": "ITP Interpretext System: MUC-3 Test Results and Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "Intelligent Text Processing is a small start-up company participating in the MUC-3 exercise for the first time this year, and its system, Interpretext, is based on a prototype text understanding system."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16927,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40199624"
                        ],
                        "name": "R. Creecy",
                        "slug": "R.-Creecy",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Creecy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Creecy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127759"
                        ],
                        "name": "B. Masand",
                        "slug": "B.-Masand",
                        "structuredName": {
                            "firstName": "Brij",
                            "lastName": "Masand",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Masand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111051178"
                        ],
                        "name": "Stephen J. Smith",
                        "slug": "Stephen-J.-Smith",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smith",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen J. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788375"
                        ],
                        "name": "D. Waltz",
                        "slug": "D.-Waltz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Waltz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Waltz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18744432,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "7403fa3e56cee44e0f48185bb4a79d935eb9b01c",
            "isKey": false,
            "numCitedBy": 237,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "mission to profile and economy of ~e Census Bureau ~dustry and occupation data for individuals in the labor force. For the 1990 Decennial Census, each of an estimated 22 million natural language responses to questions on the census long form had to be classified into one of 232 industry categories and 504 occupation categories. If done fully by hand the cost of this task would be on the order of $15 million."
            },
            "slug": "Trading-MIPS-and-memory-for-knowledge-engineering-Creecy-Masand",
            "title": {
                "fragments": [],
                "text": "Trading MIPS and memory for knowledge engineering"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "mission to profile and economy of ~e Census Bureau ~dustry and occupation data for individuals in the labor force, for the 1990 Decennial Census, which had to be classified into one of 232 industry categories and 504 occupation categories."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144360624"
                        ],
                        "name": "J. Sterling",
                        "slug": "J.-Sterling",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Sterling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sterling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34617501"
                        ],
                        "name": "C. Macleod",
                        "slug": "C.-Macleod",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Macleod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Macleod"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53771137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96652ef7abd829eb95bfd0d527ec7a07cf43ca5c",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The Proteus system which we have used for MUC-5 is largely unchanged from that used for MUC-3 and MUC-4. It has three main components: a syntactic analyzer, a semantic analyzer, and a template generator."
            },
            "slug": "New-York-University:-description-of-the-PROTEUS-as-Grishman-Sterling",
            "title": {
                "fragments": [],
                "text": "New York University: description of the PROTEUS system as used for MUC-3"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The Proteus system which the MUC-5 team has used is largely unchanged from that used for MUCs 3 and 4, and has three main components: a syntactic analyzer, a semantic analyzers, and a template generator."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764931"
                        ],
                        "name": "C. Dolan",
                        "slug": "C.-Dolan",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Dolan",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dolan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3225972"
                        ],
                        "name": "T. V. Cuda",
                        "slug": "T.-V.-Cuda",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cuda",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. V. Cuda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067529898"
                        ],
                        "name": "S. Goldman",
                        "slug": "S.-Goldman",
                        "structuredName": {
                            "firstName": "Seth",
                            "lastName": "Goldman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3218323"
                        ],
                        "name": "A. M. Nakamura",
                        "slug": "A.-M.-Nakamura",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Nakamura",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. M. Nakamura"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1762275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7277ee11961309fc740e4ee3e0ffd273c21ef0d",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of the Hughes Trainable Text Skimmer (TTS) Project is to create text skimming software that: (1) can be easily re-configured for new applications, (2) improves its performance with use, and (3) is fast enough to process megabytes of text per day. The TTS-MUC3 system is our first full scale prototype."
            },
            "slug": "Hughes-Trainable-Text-Skimmer:-description-of-the-Dolan-Cuda",
            "title": {
                "fragments": [],
                "text": "Hughes Trainable Text Skimmer: description of the TTS system as used for MUC-3"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "The objective of the Hughes Trainable Text Skimmer Project is to create text skimming software that can be easily re-configured for new applications, improves its performance with use, and is fast enough to process megabytes of text per day."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2222817"
                        ],
                        "name": "C. Cleverdon",
                        "slug": "C.-Cleverdon",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Cleverdon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cleverdon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1066940,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3ccdda9e2b4e270dd4b3b5db4aaefa5724c9fb1e",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "s Co F().w"
            },
            "slug": "The-significance-of-the-Cranfield-tests-on-index-Cleverdon",
            "title": {
                "fragments": [],
                "text": "The significance of the Cranfield tests on index languages"
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '91"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On recognizing planned deception"
            },
            "venue": {
                "fragments": [],
                "text": "AAAI-88 Workshop on Plan Recognition"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Intelligent Banking System: natural language processing for nancial communications"
            },
            "venue": {
                "fragments": [],
                "text": "Innovative Applications of Artiicial Intelligence"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The automatic indexing system AIR/PHYS|from research to application Automatic document classiication"
            },
            "venue": {
                "fragments": [],
                "text": "Eleventh International Conference on Research & Development in Information Retrieval"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A theory of learning classiication rules"
            },
            "venue": {
                "fragments": [],
                "text": "A theory of learning classiication rules"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A fuzzy measure of agreement between machine and manual assignment of documents to subject categories"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 46th ASIS Annual Meeting"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Heuristic classiication"
            },
            "venue": {
                "fragments": [],
                "text": "Artiicial Intelligence"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. Information Retrieval. Butterworths"
            },
            "venue": {
                "fragments": [],
                "text": "J. Information Retrieval. Butterworths"
            },
            "year": 1979
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-comparison-of-two-learning-algorithms-for-text-Lewis-Ringuette/e9fd1a7ae0322d417ab2d32017e373dd50efc063?sort=total-citations"
}