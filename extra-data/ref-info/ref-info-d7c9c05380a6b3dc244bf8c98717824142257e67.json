{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 181
                            }
                        ],
                        "text": "For years, many researchers have computed stereo correspondence by searching over all possible disparities along a scanline, which can be done efficiently using dynamic programming [2, 3, 8, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14472918,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "53e606d468feedc9d581434b4853904e79083333",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The author presents a method for reconstructing the three-dimensional scene geometry, i.e., depth, surface orientation, occluding contours, and surface creases, from a pair of stereo images. This reconstruction is not done as a postprocessing step, but rather all of the quantities are estimated simultaneously as part of the matching algorithm. An energy functional is considered in which each of the quantities in the scene geometry is explicitly represented. For this energy functional, a smoothness prior that, in addition to its ability to detect surface discontinuities and the accompanying half-occluded regions, is able to reconstruct steeply sloping surfaces with sharp creases is used. Experimental results demonstrating the effectiveness of the algorithm are presented.<<ETX>>"
            },
            "slug": "A-binocular-stereo-algorithm-for-reconstructing-and-Belhumeur",
            "title": {
                "fragments": [],
                "text": "A binocular stereo algorithm for reconstructing sloping, creased, and broken surfaces in the presence of half-occlusion"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A smoothness prior that, in addition to its ability to detect surface discontinuities and the accompanying half-occluded regions, is able to reconstruct steeply sloping surfaces with sharp creases is used."
            },
            "venue": {
                "fragments": [],
                "text": "1993 (4th) International Conference on Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144520793"
                        ],
                        "name": "S\u00e9bastien Roy",
                        "slug": "S\u00e9bastien-Roy",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Roy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716933"
                        ],
                        "name": "I. Cox",
                        "slug": "I.-Cox",
                        "structuredName": {
                            "firstName": "Ingemar",
                            "lastName": "Cox",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cox"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Roy and Cox [12] and Ishikawa and Geiger [9] presented formulations that, with the right edge weights, can find the global minimum of such a functional."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16612668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "006328c8add2ce30c186048c89097560d2661c27",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new algorithm for solving the N-camera stereo correspondence problem by transforming it into a maximum-flow problem. Once solved, the minimum-cut associated to the maximum-flow yields a disparity surface for the whole image at once. This global approach to stereo analysis provides a more accurate and coherent depth map than the traditional line-by-line stereo. Moreover, the optimality of the depth surface is guaranteed and can be shown to be a generalization of the dynamic programming approach that is widely used in standard stereo. Results show improved depth estimation as well as better handling of depth discontinuities. While the worst case running time is O(n/sup 2/d/sup 2/log(nd)), the observed average running time is O(n/sup 1.2/ d/sup 1.3/) for an image size of n pixels and depth resolution d."
            },
            "slug": "A-maximum-flow-formulation-of-the-N-camera-stereo-Roy-Cox",
            "title": {
                "fragments": [],
                "text": "A maximum-flow formulation of the N-camera stereo correspondence problem"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A new algorithm for solving the N-camera stereo correspondence problem by transforming it into a maximum-flow problem that provides a more accurate and coherent depth map than the traditional line-by-line stereo."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145337347"
                        ],
                        "name": "H. Baker",
                        "slug": "H.-Baker",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Baker",
                            "middleNames": [
                                "Harlyn"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738591"
                        ],
                        "name": "T. Binford",
                        "slug": "T.-Binford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Binford",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Binford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 181
                            }
                        ],
                        "text": "For years, many researchers have computed stereo correspondence by searching over all possible disparities along a scanline, which can be done efficiently using dynamic programming [2, 3, 8, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11002139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278618251450aaeb334227ec82bacabfc1c266de",
            "isKey": false,
            "numCitedBy": 545,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The past few years have seen a growing interest in the application\" of three-dimensional image processing. With the increasing demand for 3-D spatial information for tasks of passive navigation [7,12], automatic surveillance [9], aerial cartography [10,13], and inspection in industrial automation, the importance of effective stereo analysis has been made quite clear. A particular challenge is to provide reliable and accurate depth data for input to object or terrain modelling systems (such as [5]. This paper describes an algorithm for such stereo sensing It uses an edge-based line-by-line stereo correlation scheme, and appears to be fast, robust, and parallel implementable. The processing consists of extracting edge descriptions for a stereo pair of images, linking these edges to their nearest neighbors to obtain the edge connectivity structure, correlating the edge descriptions on the basis of local edge properties, then cooperatively removmg those edge correspondences determined to be in error - those which violate the connectivity structure of the two images. A further correlation process, using a technique similar to that used for the edges, is applied to the image intensity values over intervals defined by the previous correlation The result of the processing is a full image array disparity map of the scene viewed."
            },
            "slug": "Depth-from-Edge-and-Intensity-Based-Stereo-Baker-Binford",
            "title": {
                "fragments": [],
                "text": "Depth from Edge and Intensity Based Stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper describes an algorithm for stereo sensing that uses an edge-based line-by-line stereo correlation scheme, and appears to be fast, robust, and parallel implementable."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717736"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Fua",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 188
                            }
                        ],
                        "text": "We set (x; x) to be proportional to the inverse of the magnitude of the gradient of intensity at that location, thresholded, in order to align the discontinuities with the intensity edges [4, 6, 7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10161610,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ff4a905eeb744129d17a3039f229802749c3edc",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we show how simple and parallel techniques can be efficiently combined to compute dense depth maps and preserve depth discontinuities in complex real world scenes. Our algorithm relies on correlation followed by interpolation. During the correlation phase the two images play a symmetric role and we use a validity criterion for the matches that eliminates gross errors: at places where the images cannot be correlated reliably, due to lack of texture or occlusions for example, the algori thm does not produce wrong matches but a very sparse disparity map as opposed to a dense one when the correlation is successful. To generate dense depth map, the information is then propagated across the featureless areas but not across discontinuities by an interpolation scheme that takes image grey levels into account to preserve image features. We show that our algorithm performs very well on difficult images such as faces and cluttered ground level scenes. Because all the techniques described here are parallel and very regular they could be implemented in hardware and lead to extremely fast stereo systems."
            },
            "slug": "Combining-Stereo-and-Monocular-Information-to-Dense-Fua",
            "title": {
                "fragments": [],
                "text": "Combining Stereo and Monocular Information to Compute Dense Depth Maps that Preserve Depth Discontinuities"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper shows how simple and parallel techniques can be efficiently combined to compute dense depth maps and preserve depth discontinuities in complex real world scenes and shows that their algorithm performs very well on difficult images such as faces and cluttered ground level scenes."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722219"
                        ],
                        "name": "Y. Ohta",
                        "slug": "Y.-Ohta",
                        "structuredName": {
                            "firstName": "Yuichi",
                            "lastName": "Ohta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ohta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 181
                            }
                        ],
                        "text": "For years, many researchers have computed stereo correspondence by searching over all possible disparities along a scanline, which can be done efficiently using dynamic programming [2, 3, 8, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9691638,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffacc9e5144f0efed41fd49b2a388939afff5db9",
            "isKey": false,
            "numCitedBy": 1113,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a stereo matching algorithm using the dynamic programming technique. The stereo matching problem, that is, obtaining a correspondence between right and left images, can be cast as a search problem. When a pair of stereo images is rectified, pairs of corresponding points can be searched for within the same scanlines. We call this search intra-scanline search. This intra-scanline search can be treated as the problem of finding a matching path on a two-dimensional (2D) search plane whose axes are the right and left scanlines. Vertically connected edges in the images provide consistency constraints across the 2D search planes. Inter-scanline search in a three-dimensional (3D) search space, which is a stack of the 2D search planes, is needed to utilize this constraint. Our stereo matching algorithm uses edge-delimited intervals as elements to be matched, and employs the above mentioned two searches: one is inter-scanline search for possible correspondences of connected edges in right and left images and the other is intra-scanline search for correspondences of edge-delimited intervals on each scanline pair. Dynamic programming is used for both searches which proceed simultaneously: the former supplies the consistency constraint to the latter while the latter supplies the matching score to the former. An interval-based similarity metric is used to compute the score. The algorithm has been tested with different types of images including urban aerial images, synthesized images, and block scenes, and its computational requirement has been discussed."
            },
            "slug": "Stereo-by-Intra-and-Inter-Scanline-Search-Using-Ohta-Kanade",
            "title": {
                "fragments": [],
                "text": "Stereo by Intra- and Inter-Scanline Search Using Dynamic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This paper presents a stereo matching algorithm using the dynamic programming technique that uses edge-delimited intervals as elements to be matched, and employs the above mentioned two searches: one is inter-scanline search for possible correspondences of connected edges in right and left images and the other is intra-scanlines search for correspondence of edge-Delimited interval on each scanline pair."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "Another graph-based technique for performing image segmentation is the normalized cut algorithm [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9804657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76f3b19858a14778322efb97dca16b80ddc65879",
            "isKey": false,
            "numCitedBy": 427,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a motion segmentation algorithm that aims to break a scene into its most prominent moving groups. A weighted graph is constructed on the image sequence by connecting pixels that are in the spatiotemporal neighborhood of each other. At each pixel, we define motion profile vectors which capture the probability distribution of the image velocity. The distance between motion profiles is used to assign a weight on the graph edges. Using normalised cuts we find the most salient partitions of the spatiotemporal graph formed by the image sequence. For segmenting long image sequences, we have developed a recursive update procedure that incorporates knowledge of segmentation in previous frames for efficiently finding the group correspondence in the new frame."
            },
            "slug": "Motion-segmentation-and-tracking-using-normalized-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Motion segmentation and tracking using normalized cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A motion segmentation algorithm that aims to break a scene into its most prominent moving groups using a weighted graph constructed on the image sequence by connecting pixels that are in the spatiotemporal neighborhood of each other."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66193516"
                        ],
                        "name": "H. Ishikawa",
                        "slug": "H.-Ishikawa",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Ishikawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ishikawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14489533"
                        ],
                        "name": "D. Geiger",
                        "slug": "D.-Geiger",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Geiger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geiger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "Roy and Cox [12] and Ishikawa and Geiger [9] presented formulations that, with the right edge weights, can find the global minimum of such a functional."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6096544,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6c9817b90cfc7cd78143f3749e602febd84d2a81",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method for segmenting gray-value images. By segmentation, we mean a map from the set of pixels to a small set of levels such that each connected component of the set of pixels with the same level forms a relatively large and \"meaningful\" region. The method finds a set of levels with associated gray values by first finding junctions in the image and then seeking a minimum set of threshold values that preserves the junctions. Then it finds a segmentation map that maps each pixel to the level with the closest gray value to the pixel data, within a smoothness constraint. For a convex smoothing penalty, we show the global optimal solution for an energy function that fits the data can be obtained in a polynomial time, by a novel use of the maximum-flow algorithm. Our approach is in contrast to a view in computer vision where segmentation is driven by intensity, gradient, usually not yielding closed boundaries."
            },
            "slug": "Segmentation-by-grouping-junctions-Ishikawa-Geiger",
            "title": {
                "fragments": [],
                "text": "Segmentation by grouping junctions"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "For a convex smoothing penalty, the global optimal solution for an energy function that fits the data can be obtained in a polynomial time, by a novel use of the maximum-flow algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 68
                            }
                        ],
                        "text": "Our approach is similar to expectation-maximization (EM) algorithms [1, 15, 16] which iteratively segment an image into regions of affine motion."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5950838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a73f23484f890fafff6dd1e79ae25b33de1e666b",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Describing a video sequence in terms of a small number of coherently moving segments is useful for tasks ranging from video compression to event perception. A promising approach is to view the motion segmentation problem in a mixture estimation framework. However, existing formulations generally use only the motion, data and thus fail to make use of static cues when segmenting the sequence. Furthermore, the number of models is either specified in advance or estimated outside the mixture model framework. In this work we address both of these issues. We show how to add spatial constraints to the mixture formulations and present a variant of the EM algorithm that males use of both the form and the motion constraints. Moreover this algorithm estimates the number of segments given knowledge about the level of model failure expected in the sequence. The algorithm's performance is illustrated on synthetic and real image sequences."
            },
            "slug": "A-unified-mixture-framework-for-motion-spatial-and-Weiss-Adelson",
            "title": {
                "fragments": [],
                "text": "A unified mixture framework for motion segmentation: incorporating spatial coherence and estimating the number of models"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work shows how to add spatial constraints to the mixture formulations and presents a variant of the EM algorithm that makes use of both the form and the motion constraints and estimates the number of segments given knowledge about the level of model failure expected in the sequence."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 333
                            }
                        ],
                        "text": "This is accomplished by alternating between two steps: (1) segmenting the image, that is, assigning a label to each pixel indicating to which region it belongs, using the multiway-cut algorithm of Boykov, Veksler, and Zabih\n[6], and (2) finding the affine parameters of the displacement function for each region, using the method of Shi and Tomasi [14]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "These equations are identical to those in [14] but with simplified notation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "[6], and (2) finding the affine parameters of the displacement function for each region, using the method of Shi and Tomasi [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 778478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ab46391005cea85fa5c204b6e77a9c870fdbaed",
            "isKey": false,
            "numCitedBy": 8405,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. We propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world. These methods are based on a new tracking algorithm that extends previous Newton-Raphson style search methods to work under affine image transformations. We test performance with several simulations and experiments.<<ETX>>"
            },
            "slug": "Good-features-to-track-Shi-Tomasi",
            "title": {
                "fragments": [],
                "text": "Good features to track"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110239969"
                        ],
                        "name": "John Y. A. Wang",
                        "slug": "John-Y.-A.-Wang",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wang",
                            "middleNames": [
                                "Y.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Y. A. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 68
                            }
                        ],
                        "text": "Our approach is similar to expectation-maximization (EM) algorithms [1, 15, 16] which iteratively segment an image into regions of affine motion."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5498425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088898bc4caf25d179533afe0335aeb52dd6f723",
            "isKey": false,
            "numCitedBy": 1327,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system for representing moving images with sets of overlapping layers. Each layer contains an intensity map that defines the additive values of each pixel, along with an alpha map that serves as a mask indicating the transparency. The layers are ordered in depth and they occlude each other in accord with the rules of compositing. Velocity maps define how the layers are to be warped over time. The layered representation is more flexible than standard image transforms and can capture many important properties of natural image sequences. We describe some methods for decomposing image sequences into layers using motion analysis, and we discuss how the representation may be used for image coding and other applications."
            },
            "slug": "Representing-moving-images-with-layers-Wang-Adelson",
            "title": {
                "fragments": [],
                "text": "Representing moving images with layers"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A system for representing moving images with sets of overlapping layers that is more flexible than standard image transforms and can capture many important properties of natural image sequences."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1825734"
                        ],
                        "name": "S. Ayer",
                        "slug": "S.-Ayer",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Ayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ayer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733393"
                        ],
                        "name": "H. Sawhney",
                        "slug": "H.-Sawhney",
                        "structuredName": {
                            "firstName": "Harpreet",
                            "lastName": "Sawhney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawhney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 68
                            }
                        ],
                        "text": "Our approach is similar to expectation-maximization (EM) algorithms [1, 15, 16] which iteratively segment an image into regions of affine motion."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3135763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e26a23b57bff5e1246e49dae394eb636a3c099d1",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Representing and modeling the motion and spatial support of multiple objects and surfaces from motion video sequences is an important intermediate step towards dynamic image understanding. One such representation, called layered representation, has recently been proposed. Although a number of algorithms have been developed for computing these representations, there has not been a consolidated effort into developing a precise mathematical formulation of the problem. This paper presents one such formulation based on maximum likelihood estimation (MLE) of mixture models and the minimum description length (MDL) encoding principle. The three major issues in layered motion representation are: (i) how many motion models adequately describe image motion, (ii) what are the motion model parameters, and (iii) what is the spatial support layer for each motion model.<<ETX>>"
            },
            "slug": "Layered-representation-of-motion-video-using-robust-Ayer-Sawhney",
            "title": {
                "fragments": [],
                "text": "Layered representation of motion video using robust maximum-likelihood estimation of mixture models and MDL encoding"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents one such formulation based on maximum likelihood estimation (MLE) of mixture models and the minimum description length (MDL) encoding principle of layered motion representation, and examines how many motion models adequately describe image motion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922280"
                        ],
                        "name": "O. Veksler",
                        "slug": "O.-Veksler",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Veksler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veksler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 188
                            }
                        ],
                        "text": "We set (x; x) to be proportional to the inverse of the magnitude of the gradient of intensity at that location, thresholded, in order to align the discontinuities with the intensity edges [4, 6, 7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 283
                            }
                        ],
                        "text": "Although we may wish to have the parking meters segmented from the bushes, there is actually very little evidence in terms of disparity for such a conclusion; it takes an extremely small discontinuity penalty (which of course introduce many false discontinuities\u2014 see the results in [6]) to segment even the closer one."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "Unfortunately their approach cannot preserve sharp discontinuities, which led Boykov, Veksler, and Zabih [6] to develop another maximum-flow-based algorithm that finds a good local minimum of a more general class of cost functionals which preserve sharp discontinuities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 138
                            }
                        ],
                        "text": "Additionally, their algorithm is able to minimize vector-valued functions, making it applicable to situations such as motion, although in [6] it was applied only to stereo."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 197
                            }
                        ],
                        "text": "This is accomplished by alternating between two steps: (1) segmenting the image, that is, assigning a label to each pixel indicating to which region it belongs, using the multiway-cut algorithm of Boykov, Veksler, and Zabih\n[6], and (2) finding the affine parameters of the displacement function for each region, using the method of Shi and Tomasi [14]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 143
                            }
                        ],
                        "text": "Once the displacement functions are known, the segmentation, or labeling, problem is equivalent to the multiway cut problem on a certain graph [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "In this paper we extend the work of [6] to handle vector-valued functions with large search spaces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "To find an approximate solution to this problem, we use the algorithm of Boykov, Veksler, and Zabih [6], shown at the top of the page."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "RIGHT: The disparitymap, with region boundaries overlayed, computed by the algorithm of [6], which searches over quantized disparities."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6], and (2) finding the affine parameters of the displacement function for each region, using the method of Shi and Tomasi [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "Unfortunately, the minimum cost multiway cut problem is NP-complete [6], and, in fact, minimizing Eq."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6436838,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b543d70d3e4fe6673a2e39832f005fa7ebc79cec",
            "isKey": true,
            "numCitedBy": 528,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Markov Random Fields (MRFs) can be used for a wide variety of vision problems. In this paper we focus on MRFs with two-valued clique potentials, which form a generalized Potts model. We show that the maximum a posteriori estimate of such an MRF can be obtained by solving a multiway minimum cut problem on a graph. We develop efficient algorithms for computing good approximations to the minimum multiway, cut. The visual correspondence problem can be formulated as an MRF in our framework; this yields quite promising results on real data with ground truth. We also apply our techniques to MRFs with linear clique potentials."
            },
            "slug": "Markov-random-fields-with-efficient-approximations-Boykov-Veksler",
            "title": {
                "fragments": [],
                "text": "Markov random fields with efficient approximations"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper shows that the maximum a posteriori estimate of such an MRF can be obtained by solving a multiway minimum cut problem on a graph, and develops efficient algorithms for computing good approximations to the minimum multiway, cut."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909274"
                        ],
                        "name": "V. S. Nalwa",
                        "slug": "V.-S.-Nalwa",
                        "structuredName": {
                            "firstName": "Vishvjit",
                            "lastName": "Nalwa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. S. Nalwa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "In stereo the displacement is disparity (a scalar thanks to the epipolar constraint [10]), while in motion it is a two-element vector."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5142297,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "a39d1e09f2a8714ed12d3a8e28fa42d596627c93",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An introduction to computer vision, covering the structure and properties of the visual world. This concise guide stresses fundamental concepts, and also provides details and pointers with respect to recent developments. The author pursues the narrow view of vision covering the structure and properties of the visual world, thereby providing a lucid introduction for the novice and a fresh perspective to the expert."
            },
            "slug": "A-guided-tour-of-computer-vision-Nalwa",
            "title": {
                "fragments": [],
                "text": "A guided tour of computer vision"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The author pursues the narrow view of vision covering the structure and properties of the visual world, thereby providing a lucid introduction for the novice and a fresh perspective to the expert."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 188
                            }
                        ],
                        "text": "We set (x; x) to be proportional to the inverse of the magnitude of the gradient of intensity at that location, thresholded, in order to align the discontinuities with the intensity edges [4, 6, 7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61085884,
            "fieldsOfStudy": [],
            "id": "8926d2038af1363d7dfaad0ef40321edacaf3d1e",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Depth discontinuities by pixel-to-pixel stereo"
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Energy minimization with discontinuities. Submitted for publication to"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Multiway-cut-for-stereo-and-motion-with-slanted-Birchfield-Tomasi/d7c9c05380a6b3dc244bf8c98717824142257e67?sort=total-citations"
}