{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3717791"
                        ],
                        "name": "M. P. Kumar",
                        "slug": "M.-P.-Kumar",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Kumar",
                            "middleNames": [
                                "Pawan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 104545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b1fca32958cb821794105a0fb2e9c856f9c67e5",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a probabilistic method for segmenting instances of a particular object category within an image. Our approach overcomes the deficiencies of previous segmentation techniques based on traditional grid conditional random fields (CRF), namely that 1) they require the user to provide seed pixels for the foreground and the background and 2) they provide a poor prior for specific shapes due to the small neighborhood size of grid CRF. Specifically, we automatically obtain the pose of the object in a given image instead of relying on manual interaction. Furthermore, we employ a probabilistic model which includes shape potentials for the object to incorporate top-down information that is global across the image, in addition to the grid clique potentials which provide the bottom-up information used in previous approaches. The shape potentials are provided by the pose of the object obtained using an object category model. We represent articulated object categories using a novel layered pictorial structures model. Nonarticulated object categories are modeled using a set of exemplars. These object category models have the advantage that they can handle large intraclass shape, appearance, and spatial variation. We develop an efficient method, OBJCUT, to obtain segmentations using our probabilistic framework. Novel aspects of this method include: 1) efficient algorithms for sampling the object category models of our choice and 2) the observation that a sampling-based approximation of the expected log-likelihood of the model can be increased by a single graph cut. Results are presented on several articulated (e.g., animals) and nonarticulated (e.g., fruits) object categories. We provide a favorable comparison of our method with the state of the art in object category specific image segmentation, specifically the methods of Leibe and Schiele and Schoenemann and Cremers."
            },
            "slug": "OBJCUT:-Efficient-Segmentation-Using-Top-Down-and-Kumar-Torr",
            "title": {
                "fragments": [],
                "text": "OBJCUT: Efficient Segmentation Using Top-Down and Bottom-Up Cues"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A probabilistic method for segmenting instances of a particular object category within an image and provides a favorable comparison of the method with the state of the art in object category specific image segmentation, specifically the methods of Leibe and Schiele and Schoenemann and Cremers."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141988"
                        ],
                        "name": "Fuxin Li",
                        "slug": "Fuxin-Li",
                        "structuredName": {
                            "firstName": "Fuxin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fuxin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35681810"
                        ],
                        "name": "Jo\u00e3o Carreira",
                        "slug": "Jo\u00e3o-Carreira",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Carreira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Carreira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7625628,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ec1f8cbe8c9da709d519f99fc670604c268742f",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to visual object-class recognition and segmentation based on a pipeline that combines multiple, holistic figure-ground hypotheses generated in a bottom-up, object independent process. Decisions are performed based on continuous estimates of the spatial overlap between image segment hypotheses and each putative class. We differ from existing approaches not only in our seemingly unreasonable assumption that good object-level segments can be obtained in a feed-forward fashion, but also in framing recognition as a regression problem. Instead of focusing on a one-vs-all winning margin that can scramble ordering inside the non-maximum (non-winning) set, learning produces a globally consistent ranking with close ties to segment quality, hence to the extent entire object or part hypotheses spatially overlap with the ground truth. We demonstrate results beyond the current state of the art for image classification, object detection and semantic segmentation, in a number of challenging datasets including Caltech-101, ETHZ-Shape and PASCAL VOC 2009."
            },
            "slug": "Object-recognition-as-ranking-holistic-hypotheses-Li-Carreira",
            "title": {
                "fragments": [],
                "text": "Object recognition as ranking holistic figure-ground hypotheses"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Results are demonstrated beyond the current state of the art for image classification, object detection and semantic segmentation, in a number of challenging datasets including Caltech-101, ETHZ-Shape and PASCAL VOC 2009."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732672"
                        ],
                        "name": "A. Leonardis",
                        "slug": "A.-Leonardis",
                        "structuredName": {
                            "firstName": "Ale\u0161",
                            "lastName": "Leonardis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leonardis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14144539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c41c1f86b92a8c011e0324d90624d539a849b8b",
            "isKey": false,
            "numCitedBy": 1060,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nThis paper presents a novel method for detecting and localizing objects of a visual category in cluttered real-world scenes. Our approach considers object categorization and figure-ground segmentation as two interleaved processes that closely collaborate towards a common goal. As shown in our work, the tight coupling between those two processes allows them to benefit from each other and improve the combined performance.\n\nThe core part of our approach is a highly flexible learned representation for object shape that can combine the information observed on different training examples in a probabilistic extension of the Generalized Hough Transform. The resulting approach can detect categorical objects in novel images and automatically infer a probabilistic segmentation from the recognition result. This segmentation is then in turn used to again improve recognition by allowing the system to focus its efforts on object pixels and to discard misleading influences from the background. Moreover, the information from where in the image a hypothesis draws its support is employed in an MDL based hypothesis verification stage to resolve ambiguities between overlapping hypotheses and factor out the effects of partial occlusion.\n\nAn extensive evaluation on several large data sets shows that the proposed system is applicable to a range of different object categories, including both rigid and articulated objects. In addition, its flexible representation allows it to achieve competitive object detection performance already from training sets that are between one and two orders of magnitude smaller than those used in comparable systems.\n"
            },
            "slug": "Robust-Object-Detection-with-Interleaved-and-Leibe-Leonardis",
            "title": {
                "fragments": [],
                "text": "Robust Object Detection with Interleaved Categorization and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A novel method for detecting and localizing objects of a visual category in cluttered real-world scenes that is applicable to a range of different object categories, including both rigid and articulated objects and able to achieve competitive object detection performance from training sets that are between one and two orders of magnitude smaller than those used in comparable systems."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35681810"
                        ],
                        "name": "Jo\u00e3o Carreira",
                        "slug": "Jo\u00e3o-Carreira",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Carreira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Carreira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144135837"
                        ],
                        "name": "Adrian Ion",
                        "slug": "Adrian-Ion",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Ion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian Ion"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 208
                            }
                        ],
                        "text": "We argue that complex early multi-part consistency constraints disallow the speculative behavior necessary for segmentation algorithms, given the inherently ambiguous nature of the low-level cues they typically operate on."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10191152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b0b675416d0603008d5650bbb259f8ab230e8cb",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a mid-level image segmentation framework that combines multiple figure-ground hypothesis (FG) constrained at different locations and scales, into interpretations that tile the entire image. The problem is cast as optimization over sets of maximal cliques sampled from the graph connecting non-overlapping, putative figure-ground segment hypotheses. Potential functions over cliques combine unary Gestalt-based figure quality scores and pairwise compatibilities among spatially neighboring segments, constrained by T-junctions and the boundary interface statistics resulting from projections of real 3d scenes. Learning the model parameters is formulated as rank optimization, alternating between sampling image tilings and optimizing their potential function parameters. State of the art results are reported on both the Berkeley and the VOC2009 segmentation dataset, where a 28% improvement was achieved."
            },
            "slug": "Image-Segmentation-by-Discounted-Cumulative-Ranking-Carreira-Ion",
            "title": {
                "fragments": [],
                "text": "Image Segmentation by Discounted Cumulative Ranking on Maximal Cliques"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A mid-level image segmentation framework that combines multiple figure-ground hypothesis (FG) constrained at different locations and scales, into interpretations that tile the entire image."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26854727"
                        ],
                        "name": "Sharon Alpert",
                        "slug": "Sharon-Alpert",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Alpert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sharon Alpert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2991672"
                        ],
                        "name": "M. Galun",
                        "slug": "M.-Galun",
                        "structuredName": {
                            "firstName": "Meirav",
                            "lastName": "Galun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Galun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144880062"
                        ],
                        "name": "A. Brandt",
                        "slug": "A.-Brandt",
                        "structuredName": {
                            "firstName": "Achi",
                            "lastName": "Brandt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Brandt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "We use three publicly available datasets: Weizmann\u2019s Segmentation Evaluation Database [28], MSRC [32] and the VOC2009 train and validation sets for the object-class segmentation problem [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 7
                            }
                        ],
                        "text": "On the Weizmann Segmentation Database we select randomly 50 images, re-\nsulting in 2500 training examples, and test on the remaining 50."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "Results are reported on several publicly available benchmarks: MSRC [32], the Weizmann Segmentation Database [28] and VOC2009 [11] where the proposed method is shown to significantly outperform the state of the art using significantly fewer segments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 171
                            }
                        ],
                        "text": "The results were reported using the best F-measure criterion, F = 2RP P+R , where P and R are the precision and recall of pixels in a segment relative to the ground truth [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[28], which is also an automatic algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 146
                            }
                        ],
                        "text": "We evaluate the quality of our ranking method on both the validation set of the VOC2009 segmentation challenge, and on hold-out partitions of the Weizmann Segmentation Database."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206590857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54569a7e3726f7ccfedec667c352b8cdd5052138",
            "isKey": true,
            "numCitedBy": 344,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a parameter free approach that utilizes multiple cues for image segmentation. Beginning with an image, we execute a sequence of bottom-up aggregation steps in which pixels are gradually merged to produce larger and larger regions. In each step we consider pairs of adjacent regions and provide a probability measure to assess whether or not they should be included in the same segment. Our probabilistic formulation takes into account intensity and texture distributions in a local area around each region. It further incorporates priors based on the geometry of the regions. Finally, posteriors based on intensity and texture cues are combined using a mixture of experts formulation. This probabilistic approach is integrated into a graph coarsening scheme providing a complete hierarchical segmentation of the image. The algorithm complexity is linear in the number of the image pixels and it requires almost no user-tuned parameters. We test our method on a variety of gray scale images and compare our results to several existing segmentation algorithms."
            },
            "slug": "Image-Segmentation-by-Probabilistic-Bottom-Up-and-Alpert-Galun",
            "title": {
                "fragments": [],
                "text": "Image Segmentation by Probabilistic Bottom-Up Aggregation and Cue Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A parameter free approach that utilizes multiple cues for image segmentation that takes into account intensity and texture distributions in a local area around each region and incorporates priors based on the geometry of the regions."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781137"
                        ],
                        "name": "J. Kaufhold",
                        "slug": "J.-Kaufhold",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kaufhold",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kaufhold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642913"
                        ],
                        "name": "A. Hoogs",
                        "slug": "A.-Hoogs",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Hoogs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hoogs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 96
                            }
                        ],
                        "text": "Learning methods have been applied for segmentation, to distinguish real from apparent contours [13, 10, 16], similar from dissimilar superpixels [15], and good from bad regions [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 366508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d35a3e41430b53cf7ed2ef4bd02f138736081a0a",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The recent establishment of a large-scale ground-truth database of image segmentations [D. Martin et al., 2001] has enabled the development of learning approaches to the general segmentation problem. Using this database, we present an algorithm that learns how to segment images using region-based, perceptual features. The image is first densely segmented into regions and the edges between them using a variant of the Mumford-Shah functional. Each edge is classified as a boundary or non-boundary using a classifier trained on the ground-truth, resulting in an edge image estimating human-designated boundaries. This novel approach has a few distinct advantages over filter-based methods such as local gradient operators. First, the same perceptual features can represent texture as well as regular structure. Second, the features can measure relationships between image elements at arbitrary distances in the image, enabling the detection of Gestalt properties at any scale. Third, texture boundaries can be precisely localized, which is difficult when using filter banks. Finally, the learning system outputs a relatively small set of intuitive perceptual rules for detecting boundaries. The classifier is trained on 200 images in the ground-truth database, and tested on another 100 images according to the benchmark evaluation methods. Edge classification improves the benchmark F-score from 0.54, for the initial Mumford-Shah-variant segmentation, to 0.61 on grayscale images. This increase of 13% demonstrates the versatility and representational power of our perceptual features, as the score exceeds published results for any algorithm restricted to one type of image feature such as texture or brightness gradient."
            },
            "slug": "Learning-to-segment-images-using-region-based-Kaufhold-Hoogs",
            "title": {
                "fragments": [],
                "text": "Learning to segment images using region-based perceptual features"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm that learns how to segment images using region-based, perceptual features that improves the benchmark F-score from 0.54, for the initial Mumford-Shah-variant segmentation, to 0.61 on grayscale images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3045340"
                        ],
                        "name": "Tomasz Malisiewicz",
                        "slug": "Tomasz-Malisiewicz",
                        "structuredName": {
                            "firstName": "Tomasz",
                            "lastName": "Malisiewicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomasz Malisiewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "By generating tens to hundreds of thousand of segments per image, Malisiewicz and Efros [21] produce very good quality segments on the MSRC dataset by merging pairs and triplets of segments obtained using the Mean Shift [9], Normalized Cuts [31] and Felzenszwalb-Huttenlocher\u2019s (FH) [12] algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15599169,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "562b04ee16f27c47625b4989ab011510518d0b0a",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Sliding window scanning is the dominant paradigm in object recognition research today. But while much success has been reported in detecting several rectangular-shaped object classes (i.e. faces, cars, pedestrians), results have been much less impressive for more general types of objects. Several researchers have advocated the use of image segmentation as a way to get a better spatial support for objects. In this paper, our aim is to address this issue by studying the following two questions: 1) how important is good spatial support for recognition? 2) can segmentation provide better spatial support for objects? To answer the first, we compare recognition performance using ground-truth segmentation vs. bounding boxes. To answer the second, we use the multiple segmentation approach to evaluate how close can real segments approach the ground-truth for real objects, and at what cost. Our results demonstrate the importance of finding the right spatial support for objects, and the feasibility of doing so without excessive computational burden."
            },
            "slug": "Improving-Spatial-Support-for-Objects-via-Multiple-Malisiewicz-Efros",
            "title": {
                "fragments": [],
                "text": "Improving Spatial Support for Objects via Multiple Segmentations"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The multiple segmentation approach is used to evaluate how close can real segments approach the ground-truth for real objects, and at what cost."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944189"
                        ],
                        "name": "S. Bagon",
                        "slug": "S.-Bagon",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Bagon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bagon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1910299"
                        ],
                        "name": "Oren Boiman",
                        "slug": "Oren-Boiman",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Boiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Boiman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144611617"
                        ],
                        "name": "M. Irani",
                        "slug": "M.-Irani",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Irani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Irani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 146
                            }
                        ],
                        "text": "The automatic results obtained using CPMC on the Weizmann dataset are displayed in table 2 together with the previous best result, by Bagon et al [3], which requires the user to click a point inside the object."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] also use EM but to estimate a sophisticated self-similarity energy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Bagon et al. [3] also use EM but to estimate a sophisticated self-similarity energy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 134
                            }
                        ],
                        "text": "The automatic results obtained using CPMC on the Weizmann dataset are displayed in table 2 together with the\nprevious best result, by Bagon et al [3], which requires the user to click a point inside the object."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6219585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "614f96feb0acc25e5166aacb8fc3bc0f28ecb5c4",
            "isKey": true,
            "numCitedBy": 119,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a huge diversity of definitions of \"visually meaningful\" image segments, ranging from simple uniformly colored segments, textured segments, through symmetric patterns, and up to complex semantically meaningful objects. This diversity has led to a wide range of different approaches for image segmentation. In this paper we present a single unified framework for addressing this problem --- \"Segmentation by Composition\". We define a good image segment as one which can be easily composed using its own pieces, but is difficult to compose using pieces from other parts of the image. This non-parametric approach captures a large diversity of segment types, yet requires no pre-definition or modelling of segment types, nor prior training. Based on this definition, we develop a segment extraction algorithm --- i.e., given a single point-of-interest, provide the \"best\" image segment containing that point. This induces a figure-ground image segmentation, which applies to a range of different segmentation tasks: single image segmentation, simultaneous co-segmentation of several images, and class-based segmentations."
            },
            "slug": "What-Is-a-Good-Image-Segment-A-Unified-Approach-to-Bagon-Boiman",
            "title": {
                "fragments": [],
                "text": "What Is a Good Image Segment? A Unified Approach to Segment Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper defines a good image segment as one which can be easily composed using its own pieces, but is difficult to compose using pieces from other parts of the image, and develops a segment extraction algorithm which induces a figure-ground image segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728641"
                        ],
                        "name": "Lubor Ladicky",
                        "slug": "Lubor-Ladicky",
                        "structuredName": {
                            "firstName": "Lubor",
                            "lastName": "Ladicky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubor Ladicky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3274976"
                        ],
                        "name": "Paul Sturgess",
                        "slug": "Paul-Sturgess",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Sturgess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Sturgess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72492981"
                        ],
                        "name": "Alahari Karteek",
                        "slug": "Alahari-Karteek",
                        "structuredName": {
                            "firstName": "Alahari",
                            "lastName": "Karteek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alahari Karteek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145485799"
                        ],
                        "name": "Chris Russell",
                        "slug": "Chris-Russell",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Russell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635540"
                        ],
                        "name": "Philip H. S. Torr",
                        "slug": "Philip-H.-S.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip H. S. Torr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "We argue that segmentation is already a sufficiently challenging problem without such constraints, and that global spatial consistency should be, perhaps, enforced at a later stage of processing, by higher-level routines that have better scope for this calculation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1897971,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3581820bcd3ef21e98c49023e279cfab6fdec678",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision algorithms for individual tasks such as obj ect recognition, detection and segmentation have shown impressive r esults in the recent past. The next challenge is to integrate all these algorithm s and address the problem of scene understanding. This paper is a step towards this goal. We present a probabilistic framework for reasoning about regions, obje cts, and their attributes such as object class, location, and spatial extent. Our mode l is a Conditional Random Field defined on pixels, segments and objects. We define a g lob l energy function for the model, which combines results from sliding window detectors, and low-level pixel-based unary and pairwise relations. On e of our primary contributions is to show that this energy function can be solved efficiently. Experimental results show that our model achieves significant imp rovement over the baseline methods on CamVid and PASCAL VOCdatasets."
            },
            "slug": "What,-Where-&-How-Many-Combining-Object-Detectors-Ladicky-Sturgess",
            "title": {
                "fragments": [],
                "text": "What , Where & How Many ? Combining Object Detectors and CRFs"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A probabilistic framework for reasoning about regions, obje cts, and their attributes such as object class, location, and spatial extent is presented, which combines results from sliding window detectors, and low-level pixel-based unary and pairwise relations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739551"
                        ],
                        "name": "J. M. Gonfaus",
                        "slug": "J.-M.-Gonfaus",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Gonfaus",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Gonfaus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2343486"
                        ],
                        "name": "X. Boix",
                        "slug": "X.-Boix",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Boix",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Boix"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820687"
                        ],
                        "name": "Joost van de Weijer",
                        "slug": "Joost-van-de-Weijer",
                        "structuredName": {
                            "firstName": "Joost",
                            "lastName": "Weijer",
                            "middleNames": [
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joost van de Weijer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749498"
                        ],
                        "name": "Andrew D. Bagdanov",
                        "slug": "Andrew-D.-Bagdanov",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Bagdanov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Bagdanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3061716"
                        ],
                        "name": "J. Gual",
                        "slug": "J.-Gual",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Gual",
                            "middleNames": [
                                "Serrat"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gual"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763726"
                        ],
                        "name": "Jordi Gonz\u00e0lez",
                        "slug": "Jordi-Gonz\u00e0lez",
                        "structuredName": {
                            "firstName": "Jordi",
                            "lastName": "Gonz\u00e0lez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jordi Gonz\u00e0lez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "Semantic segmentation algorithms [10], [11], [12], [13] incorporate the outputs of these object detector s, and may need to mediate the transition between the rectangular regions produced by the detector and the desired free-form"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17114901,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24c20c28871fa923c3f45b745b9b9f2d3d280e81",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Hierarchical conditional random fields have been successfully applied to object segmentation. One reason is their ability to incorporate contextual information at different scales. However, these models do not allow multiple labels to be assigned to a single node. At higher scales in the image, this yields an oversimplified model, since multiple classes can be reasonable expected to appear within one region. This simplified model especially limits the impact that observations at larger scales may have on the CRF model. Neglecting the information at larger scales is undesirable since class-label estimates based on these scales are more reliable than at smaller, noisier scales. To address this problem, we propose a new potential, called harmony potential, which can encode any possible combination of class labels. We propose an effective sampling strategy that renders tractable the underlying optimization problem. Results show that our approach obtains state-of-the-art results on two challenging datasets: Pascal VOC 2009 and MSRC-21."
            },
            "slug": "Harmony-potentials-for-joint-classification-and-Gonfaus-Boix",
            "title": {
                "fragments": [],
                "text": "Harmony potentials for joint classification and segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a new potential, called harmony potential, which can encode any possible combination of class labels, and proposes an effective sampling strategy that renders tractable the underlying optimization problem."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38551815"
                        ],
                        "name": "Anat Levin",
                        "slug": "Anat-Levin",
                        "structuredName": {
                            "firstName": "Anat",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anat Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 558628,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26c8c478a63b880cc52634b72e4b24e885269511",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Bottom-up segmentation based only on low-level cues is a notoriously difficult problem. This difficulty has lead to recent top-down segmentation algorithms that are based on class-specific image information. Despite the success of top-down algorithms, they often give coarse segmentations that can be significantly refined using low-level cues. This raises the question of how to combine both top-down and bottom-up cues in a principled manner.In this paper we approach this problem using supervised learning. Given a training set of ground truth segmentations we train a fragment-based segmentation algorithm which takes into account both bottom-up and top-down cues simultaneously, in contrast to most existing algorithms which train top-down and bottom-up modules separately. We formulate the problem in the framework of Conditional Random Fields (CRF) and derive a feature induction algorithm for CRF, which allows us to efficiently search over thousands of candidate fragments. Whereas pure top-down algorithms often require hundreds of fragments, our simultaneous learning procedure yields algorithms with a handful of fragments that are combined with low-level cues to efficiently compute high quality segmentations."
            },
            "slug": "Learning-to-Combine-Bottom-Up-and-Top-Down-Levin-Weiss",
            "title": {
                "fragments": [],
                "text": "Learning to Combine Bottom-Up and Top-Down Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Whereas pure top-down algorithms often require hundreds of fragments, this simultaneous learning procedure yields algorithms with a handful of fragments that are combined with low-level cues to efficiently compute high quality segmentations."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758056"
                        ],
                        "name": "A. Stein",
                        "slug": "A.-Stein",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Stein",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3061173"
                        ],
                        "name": "T. Stepleton",
                        "slug": "T.-Stepleton",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Stepleton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Stepleton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1] solved Normalized Cuts with different number of segments, on a special affinity matrix derived from soft binary mattes, whereas Rabinovich et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8450158,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a8466bf688d419d8f6a66372ef85eca0d24fe75",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel step toward the unsupervised segmentation of whole objects by combining ldquohintsrdquo of partial scene segmentation offered by multiple soft, binary mattes. These mattes are implied by a set of hypothesized object boundary fragments in the scene. Rather than trying to find or define a single ldquobestrdquo segmentation, we generate multiple segmentations of an image. This reflects contemporary methods for unsupervised object discovery from groups of images, and it allows us to define intuitive evaluation metrics for our sets of segmentations based on the accurate and parsimonious delineation of scene objects. Our proposed approach builds on recent advances in spectral clustering, image matting, and boundary detection. It is demonstrated qualitatively and quantitatively on a dataset of scenes and is suitable for current work in unsupervised object discovery without top-down knowledge."
            },
            "slug": "Towards-unsupervised-whole-object-segmentation:-Stein-Stepleton",
            "title": {
                "fragments": [],
                "text": "Towards unsupervised whole-object segmentation: Combining automated matting with boundary detection"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work proposes a novel step toward the unsupervised segmentation of whole objects by combining ldquohintsrdquo of partial scene segmentation offered by multiple soft, binary mattes implied by a set of hypothesized object boundary fragments in the scene."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25633106"
                        ],
                        "name": "Eran Borenstein",
                        "slug": "Eran-Borenstein",
                        "structuredName": {
                            "firstName": "Eran",
                            "lastName": "Borenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eran Borenstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1952010"
                        ],
                        "name": "E. Sharon",
                        "slug": "E.-Sharon",
                        "structuredName": {
                            "firstName": "Eitan",
                            "lastName": "Sharon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sharon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1101504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22c5a6f756b9adecb2c0297121e382128a33b5ef",
            "isKey": false,
            "numCitedBy": 339,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we show how to combine bottom-up and top-down approaches into a single figure-ground segmentation process. This process provides accurate delineation of object boundaries that cannot be achieved by either the top-down or bottom-up approach alone. The top-down approach uses object representation learned from examples to detect an object in a given input image and provide an approximation to its figure-ground segmentation. The bottom-up approach uses image-based criteria to define coherent groups of pixels that are likely to belong together to either the figure or the background part. The combination provides a final segmentation that draws on the relative merits of both approaches: The result is as close as possible to the top-down approximation, but is also constrained by the bottom-up process to be consistent with significant image discontinuities. We construct a global cost function that represents these top-down and bottom-up requirements. We then show how the global minimum of this function can be efficiently found by applying the sum-product algorithm. This algorithm also provides a confidence map that can be used to identify image regions where additional top-down or bottom-up information may further improve the segmentation. Our experiments show that the results derived from the algorithm are superior to results given by a pure top-down or pure bottom-up approach. The scheme has broad applicability, enabling the combined use of a range of existing bottom-up and top-down segmentations."
            },
            "slug": "Combining-Top-Down-and-Bottom-Up-Segmentation-Borenstein-Sharon",
            "title": {
                "fragments": [],
                "text": "Combining Top-Down and Bottom-Up Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This work shows how to combine bottom-up and top-up approaches into a single figure-ground segmentation process that provides accurate delineation of object boundaries that cannot be achieved by either the top-down or bottom- up approach alone."
            },
            "venue": {
                "fragments": [],
                "text": "2004 Conference on Computer Vision and Pattern Recognition Workshop"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405518469"
                        ],
                        "name": "G. Funka-Lea",
                        "slug": "G.-Funka-Lea",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Funka-Lea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Funka-Lea"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "They are usually computed using max-flow algorithms that find exact solutions to certain energy minimization problems [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3027134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af0a2f6300b1888058b45fc96fe5bc4f4ca4302a",
            "isKey": false,
            "numCitedBy": 2065,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Combinatorial graph cut algorithms have been successfully applied to a wide range of problems in vision and graphics. This paper focusses on possibly the simplest application of graph-cuts: segmentation of objects in image data. Despite its simplicity, this application epitomizes the best features of combinatorial graph cuts methods in vision: global optima, practical efficiency, numerical robustness, ability to fuse a wide range of visual cues and constraints, unrestricted topological properties of segments, and applicability to N-D problems. Graph cuts based approaches to object extraction have also been shown to have interesting connections with earlier segmentation methods such as snakes, geodesic active contours, and level-sets. The segmentation energies optimized by graph cuts combine boundary regularization with region-based properties in the same fashion as Mumford-Shah style functionals. We present motivation and detailed technical description of the basic combinatorial optimization framework for image segmentation via s/t graph cuts. After the general concept of using binary graph cut algorithms for object segmentation was first proposed and tested in Boykov and Jolly (2001), this idea was widely studied in computer vision and graphics communities. We provide links to a large number of known extensions based on iterative parameter re-estimation and learning, multi-scale or hierarchical approaches, narrow bands, and other techniques for demanding photo, video, and medical applications."
            },
            "slug": "Graph-Cuts-and-Efficient-N-D-Image-Segmentation-Boykov-Funka-Lea",
            "title": {
                "fragments": [],
                "text": "Graph Cuts and Efficient N-D Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This application epitomizes the best features of combinatorial graph cuts methods in vision: global optima, practical efficiency, numerical robustness, ability to fuse a wide range of visual cues and constraints, unrestricted topological properties of segments, and applicability to N-D problems."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 96
                            }
                        ],
                        "text": "Learning methods have been applied for segmentation, to distinguish real from apparent contours [13, 10, 16], similar from dissimilar superpixels [15], and good from bad regions [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8443636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e2dac76a5876104f273b0a30617dac4c1c3033f",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper studies the problem of combining region and boundary cues for natural image segmentation. We employ a large database of manually segmented images in order to learn an optimal affinity function between pairs of pixels. These pairwise affinities can then be used to cluster the pixels into visually coherent groups. Region cues are computed as the similarity in brightness, color, and texture between image patches. Boundary cues are incorporated by looking for the presence of an \"intervening contour\", a large gradient along a straight line connecting two pixels. We first use the dataset of human segmentations to individually optimize parameters of the patch and gradient features for brightness, color, and texture cues. We then quantitatively measure the power of different feature combinations by computing the precision and recall of classifiers trained using those features. The mutual information between the output of the classifiers and the same-segment indicator function provides an alternative evaluation technique that yields identical conclusions. As expected, the best classifier makes use of brightness, color, and texture features, in both patch and gradient forms. We find that for brightness, the gradient cue outperforms the patch similarity. In contrast, using color patch similarity yields better results than using color gradients. Texture is the most powerful of the three channels, with both patches and gradients carrying significant independent information. Interestingly, the proximity of the two pixels does not add any information beyond that provided by the similarity cues. We also find that the convexity assumptions made by the intervening contour approach are supported by the ecological statistics of the dataset."
            },
            "slug": "Learning-affinity-functions-for-image-segmentation:-Fowlkes-Martin",
            "title": {
                "fragments": [],
                "text": "Learning affinity functions for image segmentation: combining patch-based and gradient-based approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A large database of manually segmented images is employed in order to learn an optimal affinity function between pairs of pixels, and it is found that for brightness, the gradient cue outperforms the patch similarity; in contrast, using color patch similarity yields better results than using color gradients."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "computed normalized cuts with different number of segments and image sizes [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2066830,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56766bab76cdcd541bf791730944a5e453006239",
            "isKey": false,
            "numCitedBy": 740,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a large dataset of images, we seek to automatically determine the visually similar object and scene classes together with their image segmentation. To achieve this we combine two ideas: (i) that a set of segmented objects can be partitioned into visual object classes using topic discovery models from statistical text analysis; and (ii) that visual object classes can be used to assess the accuracy of a segmentation. To tie these ideas together we compute multiple segmentations of each image and then: (i) learn the object classes; and (ii) choose the correct segmentations. We demonstrate that such an algorithm succeeds in automatically discovering many familiar objects in a variety of image datasets, including those from Caltech, MSRC and LabelMe."
            },
            "slug": "Using-Multiple-Segmentations-to-Discover-Objects-in-Russell-Freeman",
            "title": {
                "fragments": [],
                "text": "Using Multiple Segmentations to Discover Objects and their Extent in Image Collections"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work compute multiple segmentations of each image and then learns the object classes and chooses the correct segmentations, demonstrating that such an algorithm succeeds in automatically discovering many familiar objects in a variety of image datasets, including those from Caltech, MSRC and LabelMe."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143774737"
                        ],
                        "name": "J. Shotton",
                        "slug": "J.-Shotton",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Shotton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shotton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "By generating tens to hundreds of thousand of segments per image, Malisiewicz and Efros [21] produce very good quality segments on the MSRC dataset by merging pairs and triplets of segments obtained using the Mean Shift [9], Normalized Cuts [31] and Felzenszwalb-Huttenlocher\u2019s (FH) [12] algorithms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "We use three publicly available datasets: Weizmann\u2019s Segmentation Evaluation Database [28], MSRC [32] and the VOC2009 train and validation sets for the object-class segmentation problem [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Results on MSRC and VOC2009 are compared in table 3 to Arbela\u0301ez et al. [2], which is arguably the state of the art method for low-level segmentation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "Results are reported on several publicly available benchmarks: MSRC [32], the Weizmann Segmentation Database [28] and VOC2009 [11] where the proposed method is shown to significantly outperform the state of the art using significantly fewer segments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "The MSRC dataset is quite different, featuring 23 different classes, including some things, such as water and grass."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6075144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb444dc25bab36a8e273ed654d49e3841905e5af",
            "isKey": true,
            "numCitedBy": 1349,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new approach to learning a discriminative model of object classes, incorporating appearance, shape and context information efficiently. The learned model is used for automatic visual recognition and semantic segmentation of photographs. Our discriminative model exploits novel features, based on textons, which jointly model shape and texture. Unary classification and feature selection is achieved using shared boosting to give an efficient classifier which can be applied to a large number of classes. Accurate image segmentation is achieved by incorporating these classifiers in a conditional random field. Efficient training of the model on very large datasets is achieved by exploiting both random feature selection and piecewise training methods. \n \nHigh classification and segmentation accuracy are demonstrated on three different databases: i) our own 21-object class database of photographs of real objects viewed under general lighting conditions, poses and viewpoints, ii) the 7-class Corel subset and iii) the 7-class Sowerby database used in [1]. The proposed algorithm gives competitive results both for highly textured (e.g. grass, trees), highly structured (e.g. cars, faces, bikes, aeroplanes) and articulated objects (e.g. body, cow)."
            },
            "slug": "TextonBoost:-Joint-Appearance,-Shape-and-Context-Shotton-Winn",
            "title": {
                "fragments": [],
                "text": "TextonBoost: Joint Appearance, Shape and Context Modeling for Multi-class Object Recognition and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A new approach to learning a discriminative model of object classes, incorporating appearance, shape and context information efficiently, is proposed, which is used for automatic visual recognition and semantic segmentation of photographs."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2365442"
                        ],
                        "name": "B. Alexe",
                        "slug": "B.-Alexe",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Alexe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Alexe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879646"
                        ],
                        "name": "Thomas Deselaers",
                        "slug": "Thomas-Deselaers",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Deselaers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Deselaers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11515509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dd55b3bcaf50c1228569d0efe5620a910c1cd07",
            "isKey": false,
            "numCitedBy": 933,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a generic objectness measure, quantifying how likely it is for an image window to contain an object of any class. We explicitly train it to distinguish objects with a well-defined boundary in space, such as cows and telephones, from amorphous background elements, such as grass and road. The measure combines in a Bayesian framework several image cues measuring characteristics of objects, such as appearing different from their surroundings and having a closed boundary. This includes an innovative cue measuring the closed boundary characteristic. In experiments on the challenging PASCAL VOC 07 dataset, we show this new cue to outperform a state-of-the-art saliency measure [17], and the combined measure to perform better than any cue alone. Finally, we show how to sample windows from an image according to their objectness distribution and give an algorithm to employ them as location priors for modern class-specific object detectors. In experiments on PASCAL VOC 07 we show this greatly reduces the number of windows evaluated by class-specific object detectors."
            },
            "slug": "What-is-an-object-Alexe-Deselaers",
            "title": {
                "fragments": [],
                "text": "What is an object?"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A generic objectness measure, quantifying how likely it is for an image window to contain an object of any class, is presented, combining in a Bayesian framework several image cues measuring characteristics of objects, such as appearing different from their surroundings and having a closed boundary."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831988"
                        ],
                        "name": "Ian Endres",
                        "slug": "Ian-Endres",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Endres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Endres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 697224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0640da2565bad7037d969e9f07276c10102083d",
            "isKey": false,
            "numCitedBy": 495,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a category-independent method to produce a bag of regions and rank them, such that top-ranked regions are likely to be good segmentations of different objects. Our key objectives are completeness and diversity: every object should have at least one good proposed region, and a diverse set should be top-ranked. Our approach is to generate a set of segmentations by performing graph cuts based on a seed region and a learned affinity function. Then, the regions are ranked using structured learning based on various cues. Our experiments on BSDS and PASCAL VOC 2008 demonstrate our ability to find most objects within a small bag of proposed regions."
            },
            "slug": "Category-Independent-Object-Proposals-Endres-Hoiem",
            "title": {
                "fragments": [],
                "text": "Category Independent Object Proposals"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A category-independent method to produce a bag of regions and rank them, such that top-ranked regions are likely to be good segmentations of different objects, and the ability to find most objects within a small bag of proposed regions is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145560079"
                        ],
                        "name": "Bo Peng",
                        "slug": "Bo-Peng",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Peng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922280"
                        ],
                        "name": "O. Veksler",
                        "slug": "O.-Veksler",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Veksler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Veksler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Pen and Veksler [23] proposed, in the context of interactive segmentation, to learn to select the best segment among a small set generated for different values of one parameter."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7434510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a9b61d2d548de2b926253d916bd509d5a98ef4f",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The graph cut based approach has become very popular for interactive segmentation of the object of interest from the background. One of the most important and yet largely unsolved issues in the graph cut segmentation framework is parameter selection. Parameters are usually fixed beforehand by the developer of the algorithm. There is no single setting of parameters, however, that will result in the best possible segmentation for any general image. Usually each image has its own optimal set of parameters. If segmentation of an image is not as desired under the current setting of parameters, the user can always perform more interaction until the desired results are achieved. However, significant interaction may be required if parameter settings are far from optimal. In this paper, we develop an algorithm for automatic parameter selection. We design a measure of segmentation quality based on different features of segmentation that are combined using AdaBoost. Then we run the graph cut segmentation algorithm for different parameter values and choose the segmentation of highest quality according to our learnt measure. We develop a new way to normalize feature weights for the AdaBoost based classifier which is particularly suitable for our framework. Experimental results show a success rate of 95.6% for parameter selection."
            },
            "slug": "Parameter-Selection-for-Graph-Cut-Based-Image-Peng-Veksler",
            "title": {
                "fragments": [],
                "text": "Parameter Selection for Graph Cut Based Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm for automatic parameter selection for graph cut segmentation, designed and developed using AdaBoost, and a new way to normalize feature weights for the AdaBoost based classifier which is particularly suitable for the framework."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 24
                            }
                        ],
                        "text": "Stein et al. [1] solved Normalized Cuts with different number of segments, on a special affinity matrix derived from soft binary mattes, whereas Rabinovich et al. [24] select segmentations that tend to reoccur, hence are more stable."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 303,
                                "start": 299
                            }
                        ],
                        "text": "Graph partition properties (8 features) include the cut (sum of affinity along the segment boundary) [35], the ratio cut (sum of affinity along the boundary divided by their number) [33], the normalized cut (ratio of cut and affinity inside foreground, plus ratio of cut and affinity in background) [31], the unbalanced normalized cut (cut divided by affinity inside foreground) [30], and if the fraction of the cut larger than a threshold, normalized by segment perimeter, for 4 different thresholds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 241
                            }
                        ],
                        "text": "By generating tens to hundreds of thousand of segments per image, Malisiewicz and Efros [21] produce very good quality segments on the MSRC dataset by merging pairs and triplets of segments obtained using the Mean Shift [9], Normalized Cuts [31] and Felzenszwalb-Huttenlocher\u2019s (FH) [12] algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": false,
            "numCitedBy": 12808,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Normalized Cuts or FH [12]) to place the foreground seeds results in only minor improvements in the average best segmentation covering score on the MSRC dataset, when compared to placing the seeds on a regular grid."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 283
                            }
                        ],
                        "text": "The foreground seeds consist of small squares and we experimented with three different strategies to place them automatically: a regular grid geometry, the centroids of large regions obtained with normalized cuts and the centroids of the superpixels, obtained using the algorithm in [12], closest to each grid position."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 283
                            }
                        ],
                        "text": "By generating tens to hundreds of thousand of segments per image, Malisiewicz and Efros [21] produce very good quality segments on the MSRC dataset by merging pairs and triplets of segments obtained using the Mean Shift [9], Normalized Cuts [31] and Felzenszwalb-Huttenlocher\u2019s (FH) [12] algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207663697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aeeffe327e6c93e9010c7b1e401caa9113723851",
            "isKey": false,
            "numCitedBy": 3750,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of segmenting an image into regions. We define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. We then develop an efficient segmentation algorithm based on this predicate, and show that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions."
            },
            "slug": "Efficient-Graph-Based-Image-Segmentation-Felzenszwalb-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "Efficient Graph-Based Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An efficient segmentation algorithm is developed based on a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image and it is shown that although this algorithm makes greedy decisions it produces segmentations that satisfy global properties."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256849"
                        ],
                        "name": "R. Unnikrishnan",
                        "slug": "R.-Unnikrishnan",
                        "structuredName": {
                            "firstName": "Ranjith",
                            "lastName": "Unnikrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Unnikrishnan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2997956"
                        ],
                        "name": "C. Pantofaru",
                        "slug": "C.-Pantofaru",
                        "structuredName": {
                            "firstName": "Caroline",
                            "lastName": "Pantofaru",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Pantofaru"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17173984,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16365ad9bf7fd7dd8b1867ef0d6b791488770b52",
            "isKey": false,
            "numCitedBy": 820,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised image segmentation is an important component in many image understanding algorithms and practical vision systems. However, evaluation of segmentation algorithms thus far has been largely subjective, leaving a system designer to judge the effectiveness of a technique based only on intuition and results in the form of a few example segmented images. This is largely due to image segmentation being an ill-defined problem-there is no unique ground-truth segmentation of an image against which the output of an algorithm may be compared. This paper demonstrates how a recently proposed measure of similarity, the normalized probabilistic rand (NPR) index, can be used to perform a quantitative comparison between image segmentation algorithms using a hand-labeled set of ground-truth segmentations. We show that the measure allows principled comparisons between segmentations created by different algorithms, as well as segmentations on different images. We outline a procedure for algorithm evaluation through an example evaluation of some familiar algorithms - the mean-shift-based algorithm, an efficient graph-based segmentation algorithm, a hybrid algorithm that combines the strengths of both methods, and expectation maximization. Results are presented on the 300 images in the publicly available Berkeley segmentation data set"
            },
            "slug": "Toward-Objective-Evaluation-of-Image-Segmentation-Unnikrishnan-Pantofaru",
            "title": {
                "fragments": [],
                "text": "Toward Objective Evaluation of Image Segmentation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is demonstrated how a recently proposed measure of similarity, the normalized probabilistic rand (NPR) index, can be used to perform a quantitative comparison between image segmentation algorithms using a hand-labeled set of ground-truth segmentations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1952010"
                        ],
                        "name": "E. Sharon",
                        "slug": "E.-Sharon",
                        "structuredName": {
                            "firstName": "Eitan",
                            "lastName": "Sharon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sharon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2991672"
                        ],
                        "name": "M. Galun",
                        "slug": "M.-Galun",
                        "structuredName": {
                            "firstName": "Meirav",
                            "lastName": "Galun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Galun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4570622"
                        ],
                        "name": "D. Sharon",
                        "slug": "D.-Sharon",
                        "structuredName": {
                            "firstName": "Dahlia",
                            "lastName": "Sharon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sharon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144880062"
                        ],
                        "name": "A. Brandt",
                        "slug": "A.-Brandt",
                        "structuredName": {
                            "firstName": "Achi",
                            "lastName": "Brandt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Brandt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[30] proposed algebraic multigrid techniques for hierarchical segmentation, while Arbel\u00e1ez et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 383,
                                "start": 379
                            }
                        ],
                        "text": "Graph partition properties (8 features) include the cut (sum of affinity along the segment boundary) [35], the ratio cut (sum of affinity along the boundary divided by their number) [33], the normalized cut (ratio of cut and affinity inside foreground, plus ratio of cut and affinity in background) [31], the unbalanced normalized cut (cut divided by affinity inside foreground) [30], and if the fraction of the cut larger than a threshold, normalized by segment perimeter, for 4 different thresholds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4354430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c426cdfcb67d818960e64a0c4e002322d5aa14a",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Finding salient, coherent regions in images is the basis for many visual tasks, and is especially important for object recognition. Human observers perform this task with ease, relying on a system in which hierarchical processing seems to have a critical role. Despite many attempts, computerized algorithms have so far not demonstrated robust segmentation capabilities under general viewing conditions. Here we describe a new, highly efficient approach that determines all salient regions of an image and builds them into a hierarchical structure. Our algorithm, segmentation by weighted aggregation, is derived from algebraic multigrid solvers for physical systems, and consists of fine-to-coarse pixel aggregation. Aggregates of various sizes, which may or may not overlap, are revealed as salient, without predetermining their number or scale. Results using this algorithm are markedly more accurate and significantly faster (linear in data size) than previous approaches."
            },
            "slug": "Hierarchy-and-adaptivity-in-segmenting-visual-Sharon-Galun",
            "title": {
                "fragments": [],
                "text": "Hierarchy and adaptivity in segmenting visual scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new, highly efficient approach that determines all salient regions of an image and builds them into a hierarchical structure, derived from algebraic multigrid solvers for physical systems, and consists of fine-to-coarse pixel aggregation."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329582"
                        ],
                        "name": "Alex Levinshtein",
                        "slug": "Alex-Levinshtein",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Levinshtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Levinshtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779136"
                        ],
                        "name": "S. Dickinson",
                        "slug": "S.-Dickinson",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Dickinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dickinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3165684,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "b461bbc3a5a5cc4a2e0550949eac77de3a346ac9",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting contour closure, i.e., finding a cycle of disconnected contour fragments that separates an object from its background, is an important problem in perceptual grouping. Searching the entire space of possible groupings is intractable, and previous approaches have adopted powerful perceptual grouping heuristics, such as proximity and co-curvilinearity, to manage the search. We introduce a new formulation of the problem, by transforming the problem of finding cycles of contour fragments to finding subsets of superpixels whose collective boundary has strong edge support in the image. Our cost function, a ratio of a novel learned boundary gap measure to area, promotes spatially coherent sets of superpixels. Moreover, its properties support a global optimization procedure using parametric maxflow. We evaluate our framework by comparing it to two leading contour closure approaches, and find that it yields improved performance."
            },
            "slug": "Optimal-Contour-Closure-by-Superpixel-Grouping-Levinshtein-Sminchisescu",
            "title": {
                "fragments": [],
                "text": "Optimal Contour Closure by Superpixel Grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The problem of finding cycles of contour fragments is transformed to finding subsets of superpixels whose collective boundary has strong edge support in the image, and the cost function, a ratio of a novel learned boundary gap measure to area, promotes spatially coherent sets ofsuperpixels."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "It can be solved exactly for each seed in the same complexity as a single max-flow problem, with a parametric solver [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7582545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce7dc3a992201ee7b6706c6a8f12b41496691ea2",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "The maximum flow algorithm for minimizing energy functions of binary variables has become a standard tool in computer vision. In many cases, unary costs of the energy depend linearly on parameter lambda. In this paper we study vision applications for which it is important to solve the maxflow problem for different lambda's. An example is a weighting between data and regularization terms in image segmentation or stereo: it is desirable to vary it both during training (to learn lambda from ground truth data) and testing (to select best lambda using high-knowledge constraints, e.g. user input). We review algorithmic aspects of this parametric maximum flow problem previously unknown in vision, such as the ability to compute all breakpoints of lambda and corresponding optimal configurations infinite time. These results allow, in particular, to minimize the ratio of some geometric functional, such as flux of a vector field over length (or area). Previously, such functional were tackled with shortest path techniques applicable only in 2D. We give theoretical improvements for \"PDE cuts\" [5]. We present experimental results for image segmentation, 3D reconstruction, and the cosegmentation problem."
            },
            "slug": "Applications-of-parametric-maxflow-in-computer-Kolmogorov-Boykov",
            "title": {
                "fragments": [],
                "text": "Applications of parametric maxflow in computer vision"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Algorithmic aspects of this parametric maximum flow problem previously unknown in vision, such as the ability to compute all breakpoints of lambda and corresponding optimal configurations infinite time are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "In GrabCut [26], a seed is manually initialized and an observation model is iteratively fitted through expectation maximization (EM)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6202829,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f26d35d2e32934150cd27b030d4d769942126184",
            "isKey": false,
            "numCitedBy": 5200,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of efficient, interactive foreground/background segmentation in still images is of great practical importance in image editing. Classical image segmentation tools use either texture (colour) information, e.g. Magic Wand, or edge (contrast) information, e.g. Intelligent Scissors. Recently, an approach based on optimization by graph-cut has been developed which successfully combines both types of information. In this paper we extend the graph-cut approach in three respects. First, we have developed a more powerful, iterative version of the optimisation. Secondly, the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result. Thirdly, a robust algorithm for \"border matting\" has been developed to estimate simultaneously the alpha-matte around an object boundary and the colours of foreground pixels. We show that for moderately difficult examples the proposed method outperforms competitive tools."
            },
            "slug": "\"GrabCut\":-interactive-foreground-extraction-using-Rother-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "\"GrabCut\": interactive foreground extraction using iterated graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A more powerful, iterative version of the optimisation of the graph-cut approach is developed and the power of the iterative algorithm is used to simplify substantially the user interaction needed for a given quality of result."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "Are segment hypotheses allowed to overlap with each other?"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3198903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e79272fe3d65197100eae8be9fec6469107969ae",
            "isKey": false,
            "numCitedBy": 9371,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI--SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function."
            },
            "slug": "Object-Detection-with-Discriminatively-Trained-Part-Felzenszwalb-Girshick",
            "title": {
                "fragments": [],
                "text": "Object Detection with Discriminatively Trained Part Based Models"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An object detection system based on mixtures of multiscale deformable part models that is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9739979"
                        ],
                        "name": "P. Arbel\u00e1ez",
                        "slug": "P.-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1505240324"
                        ],
                        "name": "C. Fowlkes",
                        "slug": "C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charlotte",
                            "lastName": "Fowlkes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787589"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206764694,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e5a262bf59b68ba8a7a1103d16fa33a9f5ffc28",
            "isKey": false,
            "numCitedBy": 4196,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates two fundamental problems in computer vision: contour detection and image segmentation. We present state-of-the-art algorithms for both of these tasks. Our contour detector combines multiple local cues into a globalization framework based on spectral clustering. Our segmentation algorithm consists of generic machinery for transforming the output of any contour detector into a hierarchical region tree. In this manner, we reduce the problem of image segmentation to that of contour detection. Extensive experimental evaluation demonstrates that both our contour detection and segmentation methods significantly outperform competing algorithms. The automatically generated hierarchical segmentations can be interactively refined by user-specified annotations. Computation at multiple image resolutions provides a means of coupling our system to recognition applications."
            },
            "slug": "Contour-Detection-and-Hierarchical-Image-Arbel\u00e1ez-Maire",
            "title": {
                "fragments": [],
                "text": "Contour Detection and Hierarchical Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper investigates two fundamental problems in computer vision: contour detection and image segmentation and presents state-of-the-art algorithms for both of these tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39863668"
                        ],
                        "name": "Andrew Rabinovich",
                        "slug": "Andrew-Rabinovich",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Rabinovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Rabinovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39713260"
                        ],
                        "name": "Tilman Lange",
                        "slug": "Tilman-Lange",
                        "structuredName": {
                            "firstName": "Tilman",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tilman Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] select segmentations that tend to reoccur, hence are more stable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8535982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1885728ecc3cd0e643289c4520329a15a94aa759",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Model order selection and cue combination are both difficult open problems in the area of clustering. In this work we build upon stability-based approaches to develop a new method for automatic model order selection and cue combination with applications to visual grouping. Novel features of our approach include the ability to detect multiple stable clusterings (instead of only one), a simpler means of calculating stability that does not require training a classifier, and a new characterization of the space of stabilities for a continuum of segmentations that provides for an efficient sampling scheme. Our contribution is a framework for visual grouping that frees the user from the hassles of parameter tuning and model order selection: the input is an image, the output is a shortlist of segmentations."
            },
            "slug": "Model-Order-Selection-and-Cue-Combination-for-Image-Rabinovich-Belongie",
            "title": {
                "fragments": [],
                "text": "Model Order Selection and Cue Combination for Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A framework for visual grouping that frees the user from the hassles of parameter tuning and model order selection and a new characterization of the space of stabilities for a continuum of segmentations that provides for an efficient sampling scheme."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98828088"
                        ],
                        "name": "Song Wang",
                        "slug": "Song-Wang",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737754"
                        ],
                        "name": "J. Siskind",
                        "slug": "J.-Siskind",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Siskind",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Siskind"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 182
                            }
                        ],
                        "text": "Graph partition properties (8 features) include the cut (sum of affinity along the segment boundary) [35], the ratio cut (sum of affinity along the boundary divided by their number) [33], the normalized cut (ratio of cut and affinity inside foreground, plus ratio of cut and affinity in background) [31], the unbalanced normalized cut (cut divided by affinity inside foreground) [30], and if the fraction of the cut larger than a threshold, normalized by segment perimeter, for 4 different thresholds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 149
                            }
                        ],
                        "text": "We first filter out very small segments (up to 150 pixels in our implementation), then sort the segments using a simple energy (we use the ratio cut [33] as the energy because it is scale invariant and very effective) and keep the top up to 2000 segments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3077189,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e388fbe0f992cdf725b2950fa6cb36bfe9065305",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new cost function, cut ratio, for segmenting images using graph-based methods. The cut ratio is defined as the ratio of the corresponding sums of two different weights of edges along the cut boundary and models the mean affinity between the segments separated by the boundary per unit boundary length. This new cost function allows the image perimeter to be segmented, guarantees that the segments produced by bipartitioning are connected, and does not introduce a size, shape, smoothness, or boundary-length bias. The latter allows it to produce segmentations where boundaries are aligned with image edges. Furthermore, the cut-ratio cost function allows efficient iterated region-based segmentation as well as pixel-based segmentation. These properties may be useful for some image-segmentation applications. While the problem of finding a minimum ratio cut in an arbitrary graph is NP-hard, one can find a minimum ratio cut in the connected planar graphs that arise during image segmentation in polynomial time. While the cut ratio, alone, is not sufficient as a baseline method for image segmentation, it forms a good basis for an extended method of image segmentation when combined with a small number of standard techniques. We present an implemented algorithm for finding a minimum ratio cut, prove its correctness, discuss its application to image segmentation, and present the results of segmenting a number of medical and natural images using our techniques."
            },
            "slug": "Image-Segmentation-with-Ratio-Cut-Wang-Siskind",
            "title": {
                "fragments": [],
                "text": "Image Segmentation with Ratio Cut"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A new cost function, cut ratio, for segmenting images using graph-based methods that allows the image perimeter to be segmented, guarantees that the segments produced by bipartitioning are connected, and does not introduce a size, shape, smoothness, or boundary-length bias."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143685864"
                        ],
                        "name": "Yi Yang",
                        "slug": "Yi-Yang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2555602"
                        ],
                        "name": "S. Hallman",
                        "slug": "S.-Hallman",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Hallman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hallman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3505099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3044cb9dc9a364c6ec8d85fdc6dc4f9d14efcc20",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We formulate a layered model for object detection and multi-class segmentation. Our system uses the output of a bank of object detectors in order to define shape priors for support masks and then estimates appearance, depth ordering and labeling of pixels in the image. We train our system on the PASCAL segmentation challenge dataset and show good test results with state of the art performance in several categories including segmenting humans."
            },
            "slug": "Layered-object-detection-for-multi-class-Yang-Hallman",
            "title": {
                "fragments": [],
                "text": "Layered object detection for multi-class segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A layered model for object detection and multi-class segmentation that uses the output of a bank of object detectors in order to define shape priors for support masks and then estimates appearance, depth ordering and labeling of pixels in the image."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145273587"
                        ],
                        "name": "Stephen Gould",
                        "slug": "Stephen-Gould",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Gould",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2381913"
                        ],
                        "name": "Tianshi Gao",
                        "slug": "Tianshi-Gao",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "We argue that segmentation is already a sufficiently challenging problem without such constraints, and that global spatial consistency should be, perhaps, enforced at a later stage of processing, by higher-level routines that have better scope for this calculation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6467749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ca434a6eaf5cf4d6e86aca524e753fadb607979",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Object identification and multi-object picture separation are two firmly related processes and it can be enhanced when understood jointly by supporting data from one assignment to the next. Be that as it may, current best in object models are different portrayal for each space creation joint objects and leaving the categorization of numerous part of the scene uncertain. Picture element appearance highlights enable us to do well on classifying formless foundation classes, while the express portrayal of districts encourage the calculation of increasingly complex highlights essential for object detection. Vitally, our model gives a solitary bound together portrayal of the scene we clarify each picture elements of image and authorize it contains in the web between every random variable in our model."
            },
            "slug": "Region-based-Segmentation-and-Object-Detection-Gould-Gao",
            "title": {
                "fragments": [],
                "text": "Region-based Segmentation and Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a hierarchical region-based approach to joint object detection and image segmentation that simultaneously reasons about pixels, regions and objects in a coherent probabilistic model and gives a single unified description of the scene."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "Learning methods have been applied for segmentation, to distinguish real from apparent contours [13, 10, 16], similar from dissimilar superpixels [15], and good from bad regions [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "We differ from [25] in several essential aspects: we use a superset of previously proposed features, including graph and region properties or convexity, we aim at obtaining independent object-level segments, and learn directly from object class recognition datasets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "Our procedure bears some similarity to the one of Ren and Malik [25], who use a random search algorithm to iteratively hypothesize segmentations by combining different superpixels, and train a classifier to distinguish good from bad segmentations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13571735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a9049a50dfe94fa4473880a9b60c99333ade685",
            "isKey": false,
            "numCitedBy": 1644,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a two-class classification model for grouping. Human segmented natural images are used as positive examples. Negative examples of grouping are constructed by randomly matching human segmentations and images. In a preprocessing stage an image is over-segmented into super-pixels. We define a variety of features derived from the classical Gestalt cues, including contour, texture, brightness and good continuation. Information-theoretic analysis is applied to evaluate the power of these grouping cues. We train a linear classifier to combine these features. To demonstrate the power of the classification model, a simple algorithm is used to randomly search for good segmentations. Results are shown on a wide range of images."
            },
            "slug": "Learning-a-classification-model-for-segmentation-Ren-Malik",
            "title": {
                "fragments": [],
                "text": "Learning a classification model for segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A two-class classification model for grouping is proposed that defines a variety of features derived from the classical Gestalt cues, including contour, texture, brightness and good continuation, and trains a linear classifier to combine these features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110711666"
                        ],
                        "name": "T. Lee",
                        "slug": "T.-Lee",
                        "structuredName": {
                            "firstName": "Tai",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206769052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "023c01c4c462e8fbfaa9f6aed8a032cbd7288bf7",
            "isKey": false,
            "numCitedBy": 243,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel statistical and variational approach to image segmentation based on a new algorithm named region competition. This algorithm is derived by minimizing a generalized Bayes/MDL (Minimum Description Length) criterion using the variational principle. We show that existing techniques in early vision such as, snake/balloon models, region growing, and Bayes/MDL are addressing different aspects of the same problem and they can be unified within a common statistical framework which combines their advantages. We analyze how to optimize the precision of the resulting boundary location by studying the statistical properties of the region competition algorithm and discuss what are good initial conditions for the algorithm. Our method is generalized to color and texture segmentation and is demonstrated on grey level images, color images and texture images.<<ETX>>"
            },
            "slug": "Region-competition:-unifying-snakes,-region-for-Zhu-Lee",
            "title": {
                "fragments": [],
                "text": "Region competition: unifying snakes, region growing, energy/Bayes/MDL for multi-band image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that existing techniques in early vision such as, snake/balloon models, region growing, and Bayes/MDL are addressing different aspects of the same problem and they can be unified within a common statistical framework which combines their advantages."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 96
                            }
                        ],
                        "text": "Learning methods have been applied for segmentation, to distinguish real from apparent contours [13, 10, 16], similar from dissimilar superpixels [15], and good from bad regions [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6382669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be305b0684f1a6ec8407c107187d28502b48f993",
            "isKey": false,
            "numCitedBy": 464,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Edge detection is one of the most studied problems in computer vision, yet it remains a very challenging task. It is difficult since often the decision for an edge cannot be made purely based on low level cues such as gradient, instead we need to engage all levels of information, low, middle, and high, in order to decide where to put edges. In this paper we propose a novel supervised learning algorithm for edge and object boundary detection which we refer to as Boosted Edge Learning or BEL for short. A decision of an edge point is made independently at each location in the image; a very large aperture is used providing significant context for each decision. In the learning stage, the algorithm selects and combines a large number of features across different scales in order to learn a discriminative model using an extended version of the Probabilistic Boosting Tree classification algorithm. The learning based framework is highly adaptive and there are no parameters to tune. We show applications for edge detection in a number of specific image domains as well as on natural images. We test on various datasets including the Berkeley dataset and the results obtained are very good."
            },
            "slug": "Supervised-Learning-of-Edges-and-Object-Boundaries-Doll\u00e1r-Tu",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Edges and Object Boundaries"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes a novel supervised learning algorithm for edge and object boundary detection which it refers to as Boosted Edge Learning or BEL for short and shows applications for edge detection in a number of specific image domains as well as on natural images."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110264574"
                        ],
                        "name": "Tie Liu",
                        "slug": "Tie-Liu",
                        "structuredName": {
                            "firstName": "Tie",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tie Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33762094"
                        ],
                        "name": "Zejian Yuan",
                        "slug": "Zejian-Yuan",
                        "structuredName": {
                            "firstName": "Zejian",
                            "lastName": "Yuan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zejian Yuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688516"
                        ],
                        "name": "Jingdong Wang",
                        "slug": "Jingdong-Wang",
                        "structuredName": {
                            "firstName": "Jingdong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingdong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122737130"
                        ],
                        "name": "N. Zheng",
                        "slug": "N.-Zheng",
                        "structuredName": {
                            "firstName": "Nanning",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50295995"
                        ],
                        "name": "Xiaoou Tang",
                        "slug": "Xiaoou-Tang",
                        "structuredName": {
                            "firstName": "Xiaoou",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoou Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154486"
                        ],
                        "name": "H. Shum",
                        "slug": "H.-Shum",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Shum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14833979,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4f03f0c435f8a2891b048d19d7a0b8e3e5263b4",
            "isKey": false,
            "numCitedBy": 2326,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study the salient object detection problem for images. We formulate this problem as a binary labeling task where we separate the salient object from the background. We propose a set of novel features, including multiscale contrast, center-surround histogram, and color spatial distribution, to describe a salient object locally, regionally, and globally. A conditional random field is learned to effectively combine these features for salient object detection. Further, we extend the proposed approach to detect a salient object from sequential images by introducing the dynamic salient features. We collected a large image database containing tens of thousands of carefully labeled images by multiple users and a video segment database, and conducted a set of experiments over them to demonstrate the effectiveness of the proposed approach."
            },
            "slug": "Learning-to-Detect-a-Salient-Object-Liu-Yuan",
            "title": {
                "fragments": [],
                "text": "Learning to Detect a Salient Object"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A set of novel features, including multiscale contrast, center-surround histogram, and color spatial distribution, are proposed to describe a salient object locally, regionally, and globally."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2921651"
                        ],
                        "name": "T. Schoenemann",
                        "slug": "T.-Schoenemann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Schoenemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Schoenemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1776036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73c1e5d248309680db4be5aeaeda7a57aebab76e",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "So far global optimization techniques have been developed independently for the tasks of shape matching and image segmentation. In this paper we show that both tasks can in fact be solved simultaneously using global optimization. By computing cycles of minimal ratio in a large graph spanned by the product of the input image and a shape template, we are able to compute globally optimal segmentations of the image which are similar to a familiar shape and located in places of strong gradient. The presented approach is translation-invariant and robust to local and global scaling and rotation of the given shape. We show how it can be extended to incorporate invariance to similarity transformations. The particular structure of the graph allows for run-time and memory efficient implementations. Highly parallel implementations on graphics cards allow to produce globally optimal solutions in a few seconds only."
            },
            "slug": "Globally-Optimal-Image-Segmentation-with-an-Elastic-Schoenemann-Cremers",
            "title": {
                "fragments": [],
                "text": "Globally Optimal Image Segmentation with an Elastic Shape Prior"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper shows that both tasks of shape matching and image segmentation can in fact be solved simultaneously using global optimization, by computing cycles of minimal ratio in a large graph spanned by the product of the input image and a shape template."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826285"
                        ],
                        "name": "Frank R. Schmidt",
                        "slug": "Frank-R.-Schmidt",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Schmidt",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank R. Schmidt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36844817"
                        ],
                        "name": "F. Barthel",
                        "slug": "F.-Barthel",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Barthel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Barthel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10949323,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ab91b60c62075a02a6b331df4d12aa25c70d2ddd",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we introduce a novel implicit representation of shape which is based on assigning to each pixel a probability that this pixel is inside the shape. This probabilistic representation of shape resolves two important drawbacks of alternative implicit shape representations such as the level set method: Firstly, the space of shapes is convex in the sense that arbitrary convex combinations of a set of shapes again correspond to a valid shape. Secondly, we prove that the introduction of shape priors into variational image segmentation leads to functionals which are convex with respect to shape deformations. For a large class of commonly considered (spatially continuous) functionals, we prove that - under mild regularity assumptions - segmentation and tracking with statistical shape priors can be performed in a globally optimal manner. In experiments on tracking a walking person through a cluttered scene we demonstrate the advantage of global versus local optimality."
            },
            "slug": "Shape-priors-in-variational-image-segmentation:-and-Cremers-Schmidt",
            "title": {
                "fragments": [],
                "text": "Shape priors in variational image segmentation: Convexity, Lipschitz continuity and globally optimal solutions"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work introduces a novel implicit representation of shape which is based on assigning to each pixel a probability that this pixel is inside the shape, and proves that - under mild regularity assumptions - segmentation and tracking with statistical shape priors can be performed in a globally optimal manner."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2715202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63",
            "isKey": false,
            "numCitedBy": 17882,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection."
            },
            "slug": "Rapid-object-detection-using-a-boosted-cascade-of-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Rapid object detection using a boosted cascade of simple features"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates and the introduction of a new image representation called the \"integral image\" which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "Learning methods have been applied for segmentation, to distinguish real from apparent contours [13, 10, 16], similar from dissimilar superpixels [15], and good from bad regions [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206769405,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ae89592317675c9c7642a3976c3a064cef736f92",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Many computer vision algorithms limit their performance by ignoring the underlying 3D geometric structure in the image. We show that we can estimate the coarse geometric properties of a scene by learning appearance-based models of geometric classes, even in cluttered natural scenes. Geometric classes describe the 3D orientation of an image region with respect to the camera. We provide a multiple-hypothesis framework for robustly estimating scene structure from a single image and obtaining confidences for each geometric label. These confidences can then be used to improve the performance of many other applications. We provide a thorough quantitative evaluation of our algorithm on a set of outdoor images and demonstrate its usefulness in two applications: object detection and automatic single-view reconstruction."
            },
            "slug": "Geometric-context-from-a-single-image-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Geometric context from a single image"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work shows that it can estimate the coarse geometric properties of a scene by learning appearance-based models of geometric classes, even in cluttered natural scenes, and provides a multiple-hypothesis framework for robustly estimating scene structure from a single image and obtaining confidences for each geometric label."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "The quality of their algorithm is linked with the excellent globalPb [20] contour detector."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "put of the multi-cue contour detector globalPb [20] at a pixel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7002261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bb0f3a570936826401b4d1d322725bec3267dce",
            "isKey": false,
            "numCitedBy": 467,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Contours and junctions are important cues for perceptual organization and shape recognition. Detecting junctions locally has proved problematic because the image intensity surface is confusing in the neighborhood of a junction. Edge detectors also do not perform well near junctions. Current leading approaches to junction detection, such as the Harris operator, are based on 2D variation in the intensity signal. However, a drawback of this strategy is that it confuses textured regions with junctions. We believe that the right approach to junction detection should take advantage of the contours that are incident at a junction; contours themselves can be detected by processes that use more global approaches. In this paper, we develop a new high-performance contour detector using a combination of local and global cues. This contour detector provides the best performance to date (F=0.70) on the Berkeley Segmentation Dataset (BSDS) benchmark. From the resulting contours, we detect and localize candidate junctions, taking into account both contour salience and geometric configuration. We show that improvements in our contour model lead to better junctions. Our contour and junction detectors both provide state of the art performance."
            },
            "slug": "Using-contours-to-detect-and-localize-junctions-in-Maire-Arbel\u00e1ez",
            "title": {
                "fragments": [],
                "text": "Using contours to detect and localize junctions in natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new high-performance contour detector using a combination of local and global cues that provides the best performance to date on the Berkeley Segmentation Dataset (BSDS) benchmark and shows that improvements in the contour model lead to better junctions."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 220
                            }
                        ],
                        "text": "By generating tens to hundreds of thousand of segments per image, Malisiewicz and Efros [21] produce very good quality segments on the MSRC dataset by merging pairs and triplets of segments obtained using the Mean Shift [9], Normalized Cuts [31] and Felzenszwalb-Huttenlocher\u2019s (FH) [12] algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 691081,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74f4ecc3e4e5b91fbb54330b285ed5214afe2001",
            "isKey": false,
            "numCitedBy": 11480,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "A general non-parametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure: the mean shift. For discrete data, we prove the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators; of location is also established. Algorithms for two low-level vision tasks discontinuity-preserving smoothing and image segmentation - are described as applications. In these algorithms, the only user-set parameter is the resolution of the analysis, and either gray-level or color images are accepted as input. Extensive experimental results illustrate their excellent performance."
            },
            "slug": "Mean-Shift:-A-Robust-Approach-Toward-Feature-Space-Comaniciu-Meer",
            "title": {
                "fragments": [],
                "text": "Mean Shift: A Robust Approach Toward Feature Space Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "On VOC2009 we have also run experiments where we have complemented the initial feature set with additional appearance and shape features \u2014 a bag of dense SIFT [68] features computed on the foreground mask, a bag of Local Shape Contexts [69] computed on its boundary, and a HOG pyramid [70] with3 levels computed on the bounding box fitted on the boundary of the segment, for a total of 1,054 features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "On VOC2009 we have also run experiments where we have complemented the feature set with additional appearance and shape features\u2014 a bag of dense SIFT [19] features on the foreground mask, a bag of Local Shape Contexts [4] on its boundary, and a Pyramid HOG [5] with 3 levels \u2014 for a total of 1054 features."
                    },
                    "intents": []
                }
            ],
            "corpusId": 221242327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c04f169203f9e55056a6f7f956695babe622a38",
            "isKey": false,
            "numCitedBy": 12997,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene and can robustly identify objects among clutter and occlusion while achieving near real-time performance."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144423856"
                        ],
                        "name": "Anna Bosch",
                        "slug": "Anna-Bosch",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Bosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anna Bosch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062941326"
                        ],
                        "name": "X. Mu\u00f1oz",
                        "slug": "X.-Mu\u00f1oz",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Mu\u00f1oz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Mu\u00f1oz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 257
                            }
                        ],
                        "text": "On VOC2009 we have also run experiments where we have complemented the feature set with additional appearance and shape features\u2014 a bag of dense SIFT [19] features on the foreground mask, a bag of Local Shape Contexts [4] on its boundary, and a Pyramid HOG [5] with 3 levels \u2014 for a total of 1054 features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7211257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b98c68f01d84ac07dc7fc51af782018070da748f",
            "isKey": false,
            "numCitedBy": 1496,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of this paper is classifying images by the object categories they contain, for example motorbikes or dolphins. There are three areas of novelty. First, we introduce a descriptor that represents local image shape and its spatial layout, together with a spatial pyramid kernel. These are designed so that the shape correspondence between two images can be measured by the distance between their descriptors using the kernel. Second, we generalize the spatial pyramid kernel, and learn its level weighting parameters (on a validation set). This significantly improves classification performance. Third, we show that shape and appearance kernels may be combined (again by learning parameters on a validation set).\n Results are reported for classification on Caltech-101 and retrieval on the TRECVID 2006 data sets. For Caltech-101 it is shown that the class specific optimization that we introduce exceeds the state of the art performance by more than 10%."
            },
            "slug": "Representing-shape-with-a-spatial-pyramid-kernel-Bosch-Zisserman",
            "title": {
                "fragments": [],
                "text": "Representing shape with a spatial pyramid kernel"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work introduces a descriptor that represents local image shape and its spatial layout, together with a spatial pyramid kernel that is designed so that the shape correspondence between two images can be measured by the distance between their descriptors using the kernel."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082299938"
                        ],
                        "name": "D. Tal",
                        "slug": "D.-Tal",
                        "structuredName": {
                            "firstName": "Doron",
                            "lastName": "Tal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a1ed876196ec9733acb1daa6d65e35ff0414291",
            "isKey": false,
            "numCitedBy": 6035,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes. We define an error measure which quantifies the consistency between segmentations of differing granularities and find that different human segmentations of the same image are highly consistent. Use of this dataset is demonstrated in two applications: (1) evaluating the performance of segmentation algorithms and (2) measuring probability distributions associated with Gestalt grouping factors as well as statistics of image region properties."
            },
            "slug": "A-database-of-human-segmented-natural-images-and-to-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A database containing 'ground truth' segmentations produced by humans for images of a wide variety of natural scenes is presented and an error measure is defined which quantifies the consistency between segmentations of differing granularities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 218
                            }
                        ],
                        "text": "On VOC2009 we have also run experiments where we have complemented the feature set with additional appearance and shape features\u2014 a bag of dense SIFT [19] features on the foreground mask, a bag of Local Shape Contexts [4] on its boundary, and a Pyramid HOG [5] with 3 levels \u2014 for a total of 1054 features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14966986,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ed3f249e818d9314e90a67cc45df7a24a37d933",
            "isKey": false,
            "numCitedBy": 616,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop an approach to object recognition based on matching shapes and using a resulting measure of similarity in a nearest neighbor classifier. The key algorithmic problem here is that of finding pointwise correspondences between an image shape and a stored prototype shape. We introduce a new shape descriptor, the shape context, which makes this possible, using a simple and robust algorithm. The shape context at a point captures the distribution over relative positions of other shape points and thus summarizes global shape in a rich, local descriptor. We demonstrate that shape contexts greatly simplify recovery of correspondences between points of two given shapes. Once shapes are aligned, shape contexts are used to define a robust score for measuring shape similarity. We have used this score in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function. On the benchmark MNIST dataset of handwritten digits, this yields an error rate of 0.63%, outperforming other published techniques."
            },
            "slug": "Shape-Context:-A-New-Descriptor-for-Shape-Matching-Belongie-Malik",
            "title": {
                "fragments": [],
                "text": "Shape Context: A New Descriptor for Shape Matching and Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is demonstrated that shape contexts greatly simplify recovery of correspondences between points of two given shapes, and is used in a nearest-neighbor classifier for recognition of hand written digits as well as 3D objects, using exactly the same distance function."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150358370"
                        ],
                        "name": "Zhenyu Wu",
                        "slug": "Zhenyu-Wu",
                        "structuredName": {
                            "firstName": "Zhenyu",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhenyu Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9274265"
                        ],
                        "name": "R. Leahy",
                        "slug": "R.-Leahy",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Leahy",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Leahy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "Graph partition properties (8 features) include the cut (sum of affinity along the segment boundary) [35], the ratio cut (sum of affinity along the boundary divided by their number) [33], the normalized cut (ratio of cut and affinity inside foreground, plus ratio of cut and affinity in background) [31], the unbalanced normalized cut (cut divided by affinity inside foreground) [30], and if the fraction of the cut larger than a threshold, normalized by segment perimeter, for 4 different thresholds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2595046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "250748b4494cec56abd55ae049bdd38f4d42e5c8",
            "isKey": false,
            "numCitedBy": 1265,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel graph theoretic approach for data clustering is presented and its application to the image segmentation problem is demonstrated. The data to be clustered are represented by an undirected adjacency graph G with arc capacities assigned to reflect the similarity between the linked vertices. Clustering is achieved by removing arcs of G to form mutually exclusive subgraphs such that the largest inter-subgraph maximum flow is minimized. For graphs of moderate size ( approximately 2000 vertices), the optimal solution is obtained through partitioning a flow and cut equivalent tree of G, which can be efficiently constructed using the Gomory-Hu algorithm (1961). However for larger graphs this approach is impractical. New theorems for subgraph condensation are derived and are then used to develop a fast algorithm which hierarchically constructs and partitions a partially equivalent tree of much reduced size. This algorithm results in an optimal solution equivalent to that obtained by partitioning the complete equivalent tree and is able to handle very large graphs with several hundred thousand vertices. The new clustering algorithm is applied to the image segmentation problem. The segmentation is achieved by effectively searching for closed contours of edge elements (equivalent to minimum cuts in G), which consist mostly of strong edges, while rejecting contours containing isolated strong edges. This method is able to accurately locate region boundaries and at the same time guarantees the formation of closed edge contours. >"
            },
            "slug": "An-Optimal-Graph-Theoretic-Approach-to-Data-Theory-Wu-Leahy",
            "title": {
                "fragments": [],
                "text": "An Optimal Graph Theoretic Approach to Data Clustering: Theory and Its Application to Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A novel graph theoretic approach for data clustering is presented and its application to the image segmentation problem is demonstrated, resulting in an optimal solution equivalent to that obtained by partitioning the complete equivalent tree and is able to handle very large graphs with several hundred thousand vertices."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43289321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "716d218b0831157b6ff431f5418094bf776ee3f2",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This book is the outcome of two workshops that brought together about 40 prominent vision and machine learning researchers interested in the fundamental and applicative aspects of object recognition, as well as representatives of industry. The main goals of these two workshops were (1) to promote the creation of an international object recognition community, with common datasets and evaluation procedures, (2) to map the state of the art and identify the main open problems and opportunities for synergistic research, and (3) to articulate the industrial and societal needs and opportunities for object recognition research worldwide. These goals are reflected in a relatively small number of papers that illustrate the breadth of today's object recognition research and the arsenal of techniques at its disposal, and discuss current achievements and outstanding challenges. Most of the chapters are descriptions of technical approaches, intended to capture the current state of the art. Some of the chapters are of a tutorial nature. They cover fundamental building blocks for object recognition techniques."
            },
            "slug": "Toward-Category-Level-Object-Recognition-Ponce-Hebert",
            "title": {
                "fragments": [],
                "text": "Toward Category-Level Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This book is the outcome of two workshops that brought together about 40 prominent vision and machine learning researchers interested in the fundamental and applicative aspects of object recognition, as well as representatives of industry to promote the creation of an international object recognition community."
            },
            "venue": {
                "fragments": [],
                "text": "Toward Category-Level Object Recognition"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3453447"
                        ],
                        "name": "J. Mundy",
                        "slug": "J.-Mundy",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Mundy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mundy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1338754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e75497eb3293e3c172dde4e2b6dd8215f56dc83",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in object recognition have emphasized the integration of intensity-derived features such as affine patches with associated geometric constraints leading to impressive performance in complex scenes. Over the four previous decades, the central paradigm of recognition was based on formal geometric object descriptions with a focus on the properties of such descriptions under perspective image formation. This paper will review the key advances of the geometric era and investigate the underlying causes of the movement away from formal geometry and prior models towards the use of statistical learning methods based on appearance features."
            },
            "slug": "Object-Recognition-in-the-Geometric-Era:-A-Mundy",
            "title": {
                "fragments": [],
                "text": "Object Recognition in the Geometric Era: A Retrospective"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper will review the key advances of the geometric era and investigate the underlying causes of the movement away from formal geometry and prior models towards the use of statistical learning methods based on appearance features."
            },
            "venue": {
                "fragments": [],
                "text": "Toward Category-Level Object Recognition"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3236386"
                        ],
                        "name": "Varun Gulshan",
                        "slug": "Varun-Gulshan",
                        "structuredName": {
                            "firstName": "Varun",
                            "lastName": "Gulshan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varun Gulshan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "Are segment hypotheses allowed to overlap with each other?"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206769604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9c7ab03bdb5fee15174d910d7fea14a16b086b7",
            "isKey": false,
            "numCitedBy": 883,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Our objective is to obtain a state-of-the art object category detector by employing a state-of-the-art image classifier to search for the object in all possible image sub-windows. We use multiple kernel learning of Varma and Ray (ICCV 2007) to learn an optimal combination of exponential \u03c72 kernels, each of which captures a different feature channel. Our features include the distribution of edges, dense and sparse visual words, and feature descriptors at different levels of spatial organization."
            },
            "slug": "Multiple-kernels-for-object-detection-Vedaldi-Gulshan",
            "title": {
                "fragments": [],
                "text": "Multiple kernels for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "This work uses multiple kernel learning of Varma and Ray (ICCV 2007) to learn an optimal combination of exponential \u03c72 kernels, each of which captures a different feature channel."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141988"
                        ],
                        "name": "Fuxin Li",
                        "slug": "Fuxin-Li",
                        "structuredName": {
                            "firstName": "Fuxin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fuxin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2273228"
                        ],
                        "name": "Catalin Ionescu",
                        "slug": "Catalin-Ionescu",
                        "structuredName": {
                            "firstName": "Catalin",
                            "lastName": "Ionescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catalin Ionescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11081749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "458d437f2b8d882d59bade4f9bbbdd3015f232a2",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Approximations based on random Fourier features have recently emerged as an efficient and elegant methodology for designing large-scale kernel machines [4]. By expressing the kernel as a Fourier expansion, features are generated based on a finite set of random basis projections with inner products that are Monte Carlo approximations to the original kernel. However, the original Fourier features are only applicable to translation-invariant kernels and are not suitable for histograms that are always non-negative. This paper extends the concept of translation-invariance and the random Fourier feature methodology to arbitrary, locally compact Abelian groups. Based on empirical observations drawn from the exponentiated \u03c72 kernel, the state-of-the-art for histogram descriptors, we propose a new group called the skewed-multiplicative group and design translation-invariant kernels on it. Experiments show that the proposed kernels outperform other kernels that can be similarly approximated. In a semantic segmentation experiment on the PASCAL VOC 2009 dataset, the approximation allows us to train large-scale learning machines more than two orders of magnitude faster than previous nonlinear SVMs."
            },
            "slug": "Random-Fourier-Approximations-for-Skewed-Histogram-Li-Ionescu",
            "title": {
                "fragments": [],
                "text": "Random Fourier Approximations for Skewed Multiplicative Histogram Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The concept of translation-invariance and the random Fourier feature methodology is extended to arbitrary, locally compact Abelian groups and a new group called the skewed-multiplicative group is proposed and designed to design translation- Invariant kernels on it."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "The training set of VOC2009 is composed of 750 images, resulting in 114000 training examples, one for each segment passing the fast rejection step."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12762065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2e4d819a5934ef018d0894ad530d959f565d357",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel theory for learning generic prior models from a set of observed natural images based on a minimax entropy theory that the authors studied in modeling textures. We start by studying the statistics of natural images including the scale invariant properties, then generic prior models were learnt to duplicate the observed statistics. The learned Gibbs distributions confirm and improve the forms of existing prior models. More interestingly inverted potentials are found to be necessary, and such potentials form patterns and enhance preferred image features. The learned model is compared with existing prior models in experiments of image restoration."
            },
            "slug": "Learning-generic-prior-models-for-visual-Zhu-Mumford",
            "title": {
                "fragments": [],
                "text": "Learning generic prior models for visual computation"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A novel theory for learning generic prior models from a set of observed natural images based on a minimax entropy theory is presented, and inverted potentials are found to be necessary, and such potentials form patterns and enhance preferred image features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69424391"
                        ],
                        "name": "Ieee Xplore",
                        "slug": "Ieee-Xplore",
                        "structuredName": {
                            "firstName": "Ieee",
                            "lastName": "Xplore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ieee Xplore"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60546322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8ed6678758f9200bd23fcf11dd733c8f4d9d71c",
            "isKey": false,
            "numCitedBy": 1832,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In the real world, a realistic setting for computer vision or multimedia recognition problems is that we have some classes containing lots of training data and many classes contain a small amount of training data. Therefore, how to use frequent classes to help learning rare classes for which it is harder to collect the training data is an open question. Learning with Shared Information is an emerging topic in machine learning, computer vision and multimedia analysis. There are different level of components that can be shared during concept modeling and machine learning stages, such as sharing generic object parts, sharing attributes, sharing transformations, sharing regularization parameters and sharing training examples, etc. Regarding the specific methods, multi-task learning, transfer learning and deep learning can be seen as using different strategies to share information. These learning with shared information methods are very effective in solving real-world large-scale problems. This special issue aims at gathering the recent advances in learning with shared information methods and their applications in computer vision and multimedia analysis. Both state-of-the-art works, as well as literature reviews, are welcome for submission. Papers addressing interesting real-world computer vision and multimedia applications are especially encouraged. Topics of interest include, but are not limited to:  \u2022 Multi-task learning or transfer learning for large-scale computer vision and multimedia analysis \u2022 Deep learning for large-scale computer vision and multimedia analysis \u2022 Multi-modal approach for large-scale computer vision and multimedia analysis \u2022 Different sharing strategies, e.g., sharing generic object parts, sharing attributes, sharing transformations, sharing regularization parameters and sharing training examples, \u2022 Real-world computer vision and multimedia applications based on learning with shared information, e.g., event detection, object recognition, object detection, action recognition, human head pose estimation, object tracking, location-based services, semantic indexing. \u2022 New datasets and metrics to evaluate the benefit of the proposed sharing ability for the specific computer vision or multimedia problem. \u2022 Survey papers regarding the topic of learning with shared information.  Authors who are unsure whether their planned submission is in scope may contact the guest editors prior to the submission deadline with an abstract, in order to receive feedback."
            },
            "slug": "IEEE-transactions-on-pattern-analysis-and-machine-Xplore",
            "title": {
                "fragments": [],
                "text": "IEEE transactions on pattern analysis and machine intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This special issue aims at gathering the recent advances in learning with shared information methods and their applications in computer vision and multimedia analysis and addressing interesting real-world computer Vision and multimedia applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074806439"
                        ],
                        "name": "Kannan",
                        "slug": "Kannan",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Kannan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kannan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103921311"
                        ],
                        "name": "G. Nalini",
                        "slug": "G.-Nalini",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Nalini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nalini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15015096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9b9866314054a7c8386bd44362e9034a0690007",
            "isKey": false,
            "numCitedBy": 1356,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital image processing supports strong research program in areas of image enhancement and image based pattern recognition.Among the various image processing techniques image segmentation plays a vital role in step to analyze the given image. Image segmentation is the fundamental step to analyze images and extract data from them. This work deals on the basic principles on the methods used to segment an image. Segmentation has become a prominent objective in image analysis and computer vision. To segment the images, from segmentation techniques edge detection, thresholding, region growing and clustering are taken for this study. Segmentation algorithms are based on two properties similarity and discontinuity. This paper focuses on the various methods that are widely used to segment the image. I. INTRODUCTION Digital image processing is having many recent applications in the fields of remote sensing, medicine, photography, film and video production, security monitoring. New innovative technologies are emerging in the fields of image processing, especially in image segmentation domain."
            },
            "slug": "ON-IMAGE-SEGMENTATION-TECHNIQUES-Kannan-Nalini",
            "title": {
                "fragments": [],
                "text": "ON IMAGE SEGMENTATION TECHNIQUES"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "To segment the images, from segmentation techniques edge detection, thresholding, region growing and clustering are taken for this study."
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2921651"
                        ],
                        "name": "T. Schoenemann",
                        "slug": "T.-Schoenemann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Schoenemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Schoenemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713563"
                        ],
                        "name": "F. Kahl",
                        "slug": "F.-Kahl",
                        "structuredName": {
                            "firstName": "Fredrik",
                            "lastName": "Kahl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695302"
                        ],
                        "name": "D. Cremers",
                        "slug": "D.-Cremers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Cremers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cremers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "Interesting relaxation approaches also exist for energies where minimization is NPhard [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2875746,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5fb684aadc28e337a47ad0e99fe543af8b0d302b",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a class of region-based energies for image segmentation and inpainting which combine region integrals with curvature regularity of the region boundary. To minimize such energies, we formulate an integer linear program which jointly estimates regions and their boundaries. Curvature regularity is imposed by respective costs on pairs of adjacent boundary segments."
            },
            "slug": "Curvature-regularity-for-region-based-image-and-A-Schoenemann-Kahl",
            "title": {
                "fragments": [],
                "text": "Curvature regularity for region-based image segmentation and inpainting: A linear programming relaxation"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "An integer linear program is formulated which jointly estimates regions and their boundaries to minimize energies which combine region integrals with curvature regularity of the region boundary."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207605508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfd4259d305a00f13d5f08841230389f61322422",
            "isKey": false,
            "numCitedBy": 4304,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an approach to automatically optimizing the retrieval quality of search engines using clickthrough data. Intuitively, a good information retrieval system should present relevant documents high in the ranking, with less relevant documents following below. While previous approaches to learning retrieval functions from examples exist, they typically require training data generated from relevance judgments by experts. This makes them difficult and expensive to apply. The goal of this paper is to develop a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking. Such clickthrough data is available in abundance and can be recorded at very low cost. Taking a Support Vector Machine (SVM) approach, this paper presents a method for learning retrieval functions. From a theoretical perspective, this method is shown to be well-founded in a risk minimization framework. Furthermore, it is shown to be feasible even for large sets of queries and features. The theoretical results are verified in a controlled experiment. It shows that the method can effectively adapt the retrieval function of a meta-search engine to a particular group of users, outperforming Google in terms of retrieval quality after only a couple of hundred training examples."
            },
            "slug": "Optimizing-search-engines-using-clickthrough-data-Joachims",
            "title": {
                "fragments": [],
                "text": "Optimizing search engines using clickthrough data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The goal of this paper is to develop a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23544307,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d09deeb2eb6b1175d13817284d967189a83dbdde",
            "isKey": false,
            "numCitedBy": 1463,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional classification approaches generalize poorly on image classification tasks, because of the high dimensionality of the feature space. This paper shows that support vector machines (SVM's) can generalize well on difficult image classification problems where the only features are high dimensional histograms. Heavy-tailed RBF kernels of the form K(x, y) = e(-rho)Sigma(i)/xia-yia/b with a < or = 1 and b < or = 2 are evaluated on the classification of images extracted from the Corel stock photo collection and shown to far outperform traditional polynomial or Gaussian radial basis function (RBF) kernels. Moreover, we observed that a simple remapping of the input x(i)-->x(i)(a) improves the performance of linear SVM's to such an extend that it makes them, for this problem, a valid alternative to RBF kernels."
            },
            "slug": "Support-vector-machines-for-histogram-based-image-Chapelle-Haffner",
            "title": {
                "fragments": [],
                "text": "Support vector machines for histogram-based image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is observed that a simple remapping of the input x(i)-->x(i)(a) improves the performance of linear SVM's to such an extend that it makes them, for this problem, a valid alternative to RBF kernels."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1834658"
                        ],
                        "name": "M. A. Babenko",
                        "slug": "M.-A.-Babenko",
                        "structuredName": {
                            "firstName": "Maxim",
                            "lastName": "Babenko",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Babenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2316298"
                        ],
                        "name": "Jonathan Derryberry",
                        "slug": "Jonathan-Derryberry",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Derryberry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Derryberry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2394251"
                        ],
                        "name": "A. Goldberg",
                        "slug": "A.-Goldberg",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Goldberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721050"
                        ],
                        "name": "R. Tarjan",
                        "slug": "R.-Tarjan",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tarjan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tarjan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118116274"
                        ],
                        "name": "Yunhong Zhou",
                        "slug": "Yunhong-Zhou",
                        "structuredName": {
                            "firstName": "Yunhong",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunhong Zhou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The final pool has up to ten thousand segments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17069301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c98d21281bd37634d06fd9713476cc17329fb62",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The parametric maximum flow problem is an extension of the classical maximum flow problem in which the capacities of certain arcs are not fixed but are functions of a single parameter. Gallo et al. [6] showed that certain versions of the push-relabel algorithm for ordinary maximum flow can be extended to the parametric problem while only increasing the worst-case time bound by a constant factor. Recently Zhang et al. [14,13] proposed a novel, simple balancing algorithm for the parametric problem on bipartite networks. They claimed good performance for their algorithm on networks arising from a real-world application. We describe the results of an experimental study comparing the performance of the balancing algorithm, the GGT algorithm, and a simplified version of the GGT algorithm, on networks related to those of the application of Zhang et al. as well as networks designed to be hard for the balancing algorithm. Our implementation of the balancing algorithm beats both versions of the GGT algorithm on networks related to the application, thus supporting the observations of Zhang et al. On the other hand, the GGT algorithm is more robust; it beats the balancing algorithm on some natural networks, and by asymptotically increasing amount on networks designed to be hard for the balancing algorithm."
            },
            "slug": "Experimental-Evaluation-of-Parametric-Max-Flow-Babenko-Derryberry",
            "title": {
                "fragments": [],
                "text": "Experimental Evaluation of Parametric Max-Flow Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The implementation of the balancing algorithm beats both versions of the GGT algorithm on networks related to the application, thus supporting the observations of Zhang et al."
            },
            "venue": {
                "fragments": [],
                "text": "WEA"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717379"
                        ],
                        "name": "D. Hochbaum",
                        "slug": "D.-Hochbaum",
                        "structuredName": {
                            "firstName": "Dorit",
                            "lastName": "Hochbaum",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hochbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "In this work we used the pseudoflow solver [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5760413,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59c8d055b08284371259309bcc697eb9acc2d2ad",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an algorithm that solves the maximum flow problem without generating flows explicitly. The algorithm solves directly a problem we call the maximum s-excess problem. That problem is equivalent to the minimum cut problem, and is a direct extension of the maximum closure problem. The concepts used also lead to a new parametric analysis algorithm generating all breakpoints in the amount of time of a single run. \n \nThe insights derived from the analysis of the new algorithm lead to a new simplex algorithm for the maximum flow problem - a pseudoflow-based simplex. We show that this simplex algorithm can perform a parametric analysis in the same amount of time as a single run. This is the first known simplex algorithm for maximum flow that generates all possible breakpoints of parameter values in the same complexity as required to solve a single maximum flow instance and the fastest one. \n \nThe complexities of our pseudoflow algorithm, the new simplex algorithm, and the parametric analysis for both algorithms are O(mnlog n) on a graph with n nodes and m arcs."
            },
            "slug": "The-Pseudoflow-Algorithm-and-the-Pseudoflow-Based-Hochbaum",
            "title": {
                "fragments": [],
                "text": "The Pseudoflow Algorithm and the Pseudoflow-Based Simplex for the Maximum Flow Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This is the first known simplex algorithm for maximum flow that generates all possible breakpoints of parameter values in the same complexity as required to solve a single maximum flow instance and the fastest one."
            },
            "venue": {
                "fragments": [],
                "text": "IPCO"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "We used Random Forests [7], a popular non-linear model that predicts by averaging multiple regression trees."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 89141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986",
            "isKey": false,
            "numCitedBy": 65189,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148\u2013156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression."
            },
            "slug": "Random-Forests-Breiman",
            "title": {
                "fragments": [],
                "text": "Random Forests"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the forest, and are also applicable to regression."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059876008"
                        ],
                        "name": "Matthijs C. Dorst",
                        "slug": "Matthijs-C.-Dorst",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Dorst",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthijs C. Dorst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "On VOC2009 we have also run experiments where we have complemented the feature set with additional appearance and shape features\u2014 a bag of dense SIFT [19] features on the foreground mask, a bag of Local Shape Contexts [4] on its boundary, and a Pyramid HOG [5] with 3 levels \u2014 for a total of 1054 features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 130535382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcae70dce393c1796d4f15c7b8bbf0ed6f468be1",
            "isKey": false,
            "numCitedBy": 15907,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images. These features can then be used to reliably match objects in diering images. The algorithm was rst proposed by Lowe [12] and further developed to increase performance resulting in the classic paper [13] that served as foundation for SIFT which has played an important role in robotic and machine vision in the past decade."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-Dorst",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images that can then be used to reliably match objects in diering images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2487006"
                        ],
                        "name": "B. Fulkerson",
                        "slug": "B.-Fulkerson",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Fulkerson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Fulkerson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1458265,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d720a95e1501922ea17ee31f299f43b2db5e15ef",
            "isKey": false,
            "numCitedBy": 3386,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "VLFeat is an open and portable library of computer vision algorithms. It aims at facilitating fast prototyping and reproducible research for computer vision scientists and students. It includes rigorous implementations of common building blocks such as feature detectors, feature extractors, (hierarchical) k-means clustering, randomized kd-tree matching, and super-pixelization. The source code and interfaces are fully documented. The library integrates directly with MATLAB, a popular language for computer vision research."
            },
            "slug": "Vlfeat:-an-open-and-portable-library-of-computer-Vedaldi-Fulkerson",
            "title": {
                "fragments": [],
                "text": "Vlfeat: an open and portable library of computer vision algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "VLFeat is an open and portable library of computer vision algorithms that includes rigorous implementations of common building blocks such as feature detectors, feature extractors, (hierarchical) k-means clustering, randomized kd-tree matching, and super-pixelization."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717379"
                        ],
                        "name": "D. Hochbaum",
                        "slug": "D.-Hochbaum",
                        "structuredName": {
                            "firstName": "Dorit",
                            "lastName": "Hochbaum",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hochbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The final pool has up to ten thousand segments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8830581,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67e15c4b288590f206b55156affd97f17355915d",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the pseudoflow algorithm for the maximum-flow problem that employs only pseudoflows and does not generate flows explicitly. The algorithm solves directly a problem equivalent to the minimum-cut problem---the maximum blocking-cut problem. Once the maximum blocking-cut solution is available, the additional complexity required to find the respective maximum-flow is O(m log n). A variant of the algorithm is a new parametric maximum-flow algorithm generating all breakpoints in the same complexity required to solve the constant capacities maximum-flow problem. The pseudoflow algorithm has also a simplex variant, pseudoflow-simplex, that can be implemented to solve the maximum-flow problem. One feature of the pseudoflow algorithm is that it can initialize with any pseudoflow. This feature allows it to reach an optimal solution quickly when the initial pseudoflow is \u201cclose\u201d to an optimal solution. The complexities of the pseudoflow algorithm, the pseudoflow-simplex, and the parametric variants of pseudoflow and pseudoflow-simplex algorithms are all O(mn log n) on a graph with n nodes and m arcs. Therefore, the pseudoflow-simplex algorithm is the fastest simplex algorithm known for the parametric maximum-flow problem. The pseudoflow algorithm is also shown to solve the maximum-flow problem on s, t-tree networks in linear time, where s, t-tree networks are formed by joining a forest of capacitated arcs, with nodes s and t adjacent to any subset of the nodes."
            },
            "slug": "The-Pseudoflow-Algorithm:-A-New-Algorithm-for-the-Hochbaum",
            "title": {
                "fragments": [],
                "text": "The Pseudoflow Algorithm: A New Algorithm for the Maximum-Flow Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The pseudoflow algorithm is introduced, which is a simplex algorithm that employs only pseudoflows and does not generate flows explicitly, and is shown to solve the maximum-flow problem on s, t-tree networks in linear time."
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143712374"
                        ],
                        "name": "J. Carbonell",
                        "slug": "J.-Carbonell",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Carbonell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carbonell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403730511"
                        ],
                        "name": "Jade Goldstein-Stewart",
                        "slug": "Jade-Goldstein-Stewart",
                        "structuredName": {
                            "firstName": "Jade",
                            "lastName": "Goldstein-Stewart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jade Goldstein-Stewart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 145
                            }
                        ],
                        "text": "An effective way to increase the quality of the first N segments is to diversify the ranking, by using Maximal Marginal Relevance (MMR) measures [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6334682,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83965fb947855d27d9936ed60941c3386cc5728a",
            "isKey": false,
            "numCitedBy": 2296,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for combining\nquery-relevance with information-novelty in the context\nof text retrieval and summarization. The Maximal\nMarginal Relevance (MMR) criterion strives to reduce\nredundancy while maintaining query relevance in\nre-ranking retrieved documents and in selecting appropriate passages for text summarization. Preliminary results\nindicate some benefits for MMR diversity ranking\nin document retrieval and in single document summarization.\nThe latter are borne out by the recent results of the\nSUMMAC conference in the evaluation of summarization\nsystems. However, the clearest advantage is demonstrated\nin constructing non-redundant multi-document\nsummaries, where MMR results are clearly superior to\nnon-MMR passage selection."
            },
            "slug": "The-use-of-MMR,-diversity-based-reranking-for-and-Carbonell-Goldstein-Stewart",
            "title": {
                "fragments": [],
                "text": "The use of MMR, diversity-based reranking for reordering documents and producing summaries"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper presents a method for combining query-relevance with information-novelty in the context of text retrieval and summarization, and preliminary results indicate some benefits for MMR diversity ranking in document retrieval and in single document summarization."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056091"
                        ],
                        "name": "M. Everingham",
                        "slug": "M.-Everingham",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Everingham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Everingham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61615905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a2ed19ac684022aa3186887cd4893484ab8f80c",
            "isKey": false,
            "numCitedBy": 2169,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006). Details of the challenge, data, and evaluation are presented. Participants in the challenge submitted descriptions of their methods, and these have been included verbatim. This document should be considered preliminary, and subject to change."
            },
            "slug": "The-PASCAL-visual-object-classes-challenge-2006-Everingham-Zisserman",
            "title": {
                "fragments": [],
                "text": "The PASCAL visual object classes challenge 2006 (VOC2006) results"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report presents the results of the 2006 PASCAL Visual Object Classes Challenge (VOC2006)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40061830"
                        ],
                        "name": "G. Gallo",
                        "slug": "G.-Gallo",
                        "structuredName": {
                            "firstName": "Giorgio",
                            "lastName": "Gallo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gallo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2579896"
                        ],
                        "name": "M. Grigoriadis",
                        "slug": "M.-Grigoriadis",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Grigoriadis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Grigoriadis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721050"
                        ],
                        "name": "R. Tarjan",
                        "slug": "R.-Tarjan",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tarjan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tarjan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 207052187,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "52bacd5cd5d351ed772458aa20d71361e6063e55",
            "isKey": false,
            "numCitedBy": 625,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The classical maximum flow problem sometimes occurs in settings in which the arc capacities are not fixed but are functions of a single parameter, and the goal is to find the value of the parameter such that the corresponding maximum flow or minimum cut satisfies some side condition. Finding the desired parameter value requires solving a sequence of related maximum flow problems. In this paper it is shown that the recent maximum flow algorithm of Goldberg and Tarjan can be extended to solve an important class of such parametric maximum flow problems, at the cost of only a constant factor in its worst-case time bound. Faster algorithms for a variety of combinatorial optimization problems follow from the result."
            },
            "slug": "A-Fast-Parametric-Maximum-Flow-Algorithm-and-Gallo-Grigoriadis",
            "title": {
                "fragments": [],
                "text": "A Fast Parametric Maximum Flow Algorithm and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the recent maximum flow algorithm of Goldberg and Tarjan can be extended to solve an important class of such parametric maximum flow problems, at the cost of only a constant factor in its worst-case time bound."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31558848"
                        ],
                        "name": "A. Rahimi",
                        "slug": "A.-Rahimi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Rahimi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rahimi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9229182"
                        ],
                        "name": "B. Recht",
                        "slug": "B.-Recht",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Recht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Recht"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "We map the joint vector of the two bags of words for texture features into a 2, 000-dimensional randomized feature map drawn from the Fourier transform of the Laplacian-RBF kernel [72] , and process similarly the two PHOGs corresponding to shape features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 174
                            }
                        ],
                        "text": "Some of these similarity functions can nevertheless be handled with linear regressi on, by first applying a randomized feature map that approximates the Laplacian-RBF kernel [72], [73]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 877929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7",
            "isKey": false,
            "numCitedBy": 2831,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "To accelerate the training of kernel machines, we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods. The features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user specified shift-invariant kernel. We explore two sets of random features, provide convergence bounds on their ability to approximate various radial basis kernels, and show that in large-scale classification and regression tasks linear machine learning algorithms applied to these features outperform state-of-the-art large-scale kernel machines."
            },
            "slug": "Random-Features-for-Large-Scale-Kernel-Machines-Rahimi-Recht",
            "title": {
                "fragments": [],
                "text": "Random Features for Large-Scale Kernel Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two sets of random features are explored, provided convergence bounds on their ability to approximate various radial basis kernels, and it is shown that in large-scale classification and regression tasks linear machine learning algorithms applied to these features outperform state-of-the-art large- scale kernel machines."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116457537"
                        ],
                        "name": "Jie Yu",
                        "slug": "Jie-Yu",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5113463"
                        ],
                        "name": "D. Joshi",
                        "slug": "D.-Joshi",
                        "structuredName": {
                            "firstName": "Dhiraj",
                            "lastName": "Joshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Joshi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35558834,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "dde2cfb524372ea709cc1dd645a339c32da6600b",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "This PDF file contains the editorial \u201cObject Categorization, Computer and Human Vision Perspectives\u201d for JEI Vol. 19 Issue 3"
            },
            "slug": "Object-Categorization,-Computer-and-Human-Vision-Yu-Joshi",
            "title": {
                "fragments": [],
                "text": "Object Categorization, Computer and Human Vision Perspectives"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This PDF file contains the editorial \u201cObject Categorization, Computer and Human Vision Perspectives\u201d for JEI Vol."
            },
            "venue": {
                "fragments": [],
                "text": "J. Electronic Imaging"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144806578"
                        ],
                        "name": "M. Wertheimer",
                        "slug": "M.-Wertheimer",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Wertheimer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wertheimer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "We evaluate the quality of our ranking method on both the validation set of the VOC2009 segmentation challenge, and on hold-out partitions of the Weizmann Segmentation Database."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 143283358,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "43a0503e38b4c47a5b794c04439299bd78310189",
            "isKey": false,
            "numCitedBy": 1467,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Theoretically I might say there were 327 brightnesses and nuances of colour. Do I have \"327\"? No. I have sky, house, and trees. It is impossible to achieve \"327 \" as such. And yet even though such droll calculation were possible and implied, say, for the house 120, the trees 90, the sky 117 -I should at least have this arrangement and division of the total, and not, say, 127 and 100 and 100; or 150 and 177."
            },
            "slug": "Laws-of-organization-in-perceptual-forms.-Wertheimer",
            "title": {
                "fragments": [],
                "text": "Laws of organization in perceptual forms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1938
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059675861"
                        ],
                        "name": "Alfred M. Bruckstein",
                        "slug": "Alfred-M.-Bruckstein",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Bruckstein",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alfred M. Bruckstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068499591"
                        ],
                        "name": "Robert J. Holt",
                        "slug": "Robert-J.-Holt",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Holt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert J. Holt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079207784"
                        ],
                        "name": "Arun N. Netravali",
                        "slug": "Arun-N.-Netravali",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Netravali",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arun N. Netravali"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206642145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f50557496ef7993e0c3c7ef8a7a8d9f779bacfdc",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops a discrete approach to the design of planar curves that minimize cost functions dependent upon their shape. The curves designed by using this approach are piecewise linear with equal length segments and obey various types of endpoint constraints."
            },
            "slug": "Discrete-elastica-Bruckstein-Holt",
            "title": {
                "fragments": [],
                "text": "Discrete elastica"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper develops a discrete approach to the design of planar curves that minimize cost functions dependent upon their shape and obey various types of endpoint constraints."
            },
            "venue": {
                "fragments": [],
                "text": "DGCI"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141732326"
                        ],
                        "name": "Jianguo Zhang",
                        "slug": "Jianguo-Zhang",
                        "structuredName": {
                            "firstName": "Jianguo",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianguo Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 97
                            }
                        ],
                        "text": "On Weizmann we compared a random forests regressor trained onWeizmann images with one trained on VOC2009."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 186
                            }
                        ],
                        "text": "We use three publicly available datasets: Weizmann\u2019s Segmentation Evaluation Database [28], MSRC [32] and the VOC2009 train and validation sets for the object-class segmentation problem [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 20
                            }
                        ],
                        "text": "The training set of VOC2009 is composed of 750 images, resulting in 114000 training examples, one for each segment passing the fast rejection step."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 20
                            }
                        ],
                        "text": "Results on MSRC and VOC2009 are compared in table 3 to Arbela\u0301ez et al. [2], which is arguably the state of the art method for low-level segmentation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "Results are reported on several publicly available benchmarks: MSRC [32], the Weizmann Segmentation Database [28] and VOC2009 [11] where the proposed method is shown to significantly outperform the state of the art using significantly fewer segments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "definition of overlap is O(S, G) = |S\u2229G| |S\u222aG| [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 3
                            }
                        ],
                        "text": "On VOC2009 we have also run experiments where we have complemented the feature set with additional appearance and shape features\u2014 a bag of dense SIFT [19] features on the foreground mask, a bag of Local Shape Contexts [4] on its boundary, and a Pyramid HOG [5] with 3 levels \u2014 for a total of 1054 features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 80
                            }
                        ],
                        "text": "We evaluate the quality of our ranking method on both the validation set of the VOC2009 segmentation challenge, and on hold-out partitions of the Weizmann Segmentation Database."
                    },
                    "intents": []
                }
            ],
            "corpusId": 63925014,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "0ec48ac86456cea3d6d6172ca81ef68e98b21a61",
            "isKey": true,
            "numCitedBy": 3322,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-PASCAL-Visual-Object-Classes-Challenge-Zhang",
            "title": {
                "fragments": [],
                "text": "The PASCAL Visual Object Classes Challenge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 300,
                                "start": 296
                            }
                        ],
                        "text": "We have experimented with three different strategies to place them automatically: rectangular grid geometry, centroids of superpixels obtained with normalized cuts, and centroids o f variable size regions, closest to each rectangular grid pos ition, obtained using segments from the algorithm in [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 162
                            }
                        ],
                        "text": "The segments were obtained by merging pairs and triplets of segments obtained using the Mean Shift [26], Normalized Cuts [27] and FelzenszwalbHuttenlocher\u2019s (FH) [28] algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Normalized Cuts or FH [28]) to spatially distribute the foreground seeds does n ot significantly improve the average best segmentation coveri ng score on the MSRC dataset, over regular seed geometries."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient gr aph-based image segmentation,\u201dInternational"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Computer Vision  ,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "By generating tens to hundreds of thousand of segments per image, Malisiewicz and Efros [21] produce very good quality segments on the MSRC dataset by merging pairs and triplets of segments obtained using the Mean Shift [9], Normalized Cuts [31] and Felzenszwalb-Huttenlocher\u2019s (FH) [12] algorithms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "We use three publicly available datasets: Weizmann\u2019s Segmentation Evaluation Database [28], MSRC [32] and the VOC2009 train and validation sets for the object-class segmentation problem [11]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "We use three publicly available datasets: Weizmann\u2019s Segmentation Evaluation Database [ 28], MSRC [32] and the VOC2009 train and validation sets for the object-class segmentation problem [ 11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Results on MSRC and VOC2009 are compared in table 3 to Arbela\u0301ez et al. [2], which is arguably the state of the art method for low-level segmentation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Results are reported on several publicly available benchmarks: MSRC [32], the Weizmann Segmentation Database [28] and VOC2009 [11] where the proposed method is shown to significantly outperform the state of the art using significantly fewer segments."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "The MSRC dataset is quite different, featuring 23 different classes, including some things, such as water and grass."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Texton boost: Joint appearance"
            },
            "venue": {
                "fragments": [],
                "text": "shape and context modeling for multi-class object recognition and segmentation. In  ECCV, pages 1\u201315"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67162290"
                        ],
                        "name": "W. Marsden",
                        "slug": "W.-Marsden",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Marsden",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Marsden"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] select segmentations that tend to reoccur, hence are more stable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124633341,
            "fieldsOfStudy": [],
            "id": "3d2218b17e7898a222e5fc2079a3f1531990708f",
            "isKey": false,
            "numCitedBy": 151364,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "I-and-J-Marsden",
            "title": {
                "fragments": [],
                "text": "I and J"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144246983"
                        ],
                        "name": "H. Barlow",
                        "slug": "H.-Barlow",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Barlow",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barlow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 18
                            }
                        ],
                        "text": "Gestalt theorists [34, 22] argued that properties such as proximity, similarity and good continuation are key to visual grouping."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54390906,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ab14d510d74b0098f845fc0d88b298444398cfb4",
            "isKey": false,
            "numCitedBy": 607,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision-Science:-Photons-to-Phenomenology-by-Stephen-Barlow",
            "title": {
                "fragments": [],
                "text": "Vision Science: Photons to Phenomenology by Stephen E. Palmer"
            },
            "venue": {
                "fragments": [],
                "text": "Trends in Cognitive Sciences"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "Since our original publication [49], related id eas have been pursued also by Endres and Hoiem [50] who follow processing pipeline related to ours, but employ a learned affinity measure between superpixels, rather than pixels, a nd a structured learning approach on a similar maximum marginal relevance measure to diversify ranking."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Constrained Parametri c Min-Cuts for Automatic Object Segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Computer Vision and Pattern Recognition  , June 2010."
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 143
                            }
                        ],
                        "text": "An effective way to increase the quality of the firstN segments is todiversify the ranking, by using Maximal Marginal Relevance (MMR) measures [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The use of mmr"
            },
            "venue": {
                "fragments": [],
                "text": "diversitybased reranking for reordering documents and producing summaries.In RDIR, pages 335\u2013336"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to combine bottom-up and t op-down segmentation,\u201dInternational"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Computer Vision  ,"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "Methods that learn low-level statistics h ave been applied to distinguish real from apparent contours [37 ], [38], [39] and similar from dissimilar superpixels [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Geometric context fr om a single image"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Computer Vision  , vol. 1, pp. 654\u2013661, October 2005."
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[29] solved Normalized Cut problems for different number of segments, on a special affinity matrix derived from soft binary mattes, whereas Rabinovichet al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards unsupervised whol  e- bject segmentation: Combining automated matting with boundary detec tion"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Computer Vision and Patte  rn Recognition, June 2008."
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Texton - boost : Joint appearance , shape and context modeling for multi - class object recognition and segmentation Image segmentation with ratio cut"
            },
            "venue": {
                "fragments": [],
                "text": "PAMI"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "An implementation of the proposed algorithm is made publicly available via our website [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Constrained parametri  c min-cuts for automatic object segmentation, release 1"
            },
            "venue": {
                "fragments": [],
                "text": "http://sminchise  scu.ins.unibonn.de/code/cpmc/."
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Later, more accurate techniques emerge d\u2014 good surveys can be found in [17], [18], [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Region competition: unify  ing snakes, region growing, energy/bayes/mdl for multi-band image segment  atio"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision, 1995. Proceedings., Fifth International  Conference on, Jun. 1995, pp. 416 \u2013423."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 285
                            }
                        ],
                        "text": "On VOC2009 we have also run experiments where we have complemented the initial feature set with additional appearance and shape features \u2014 a bag of dense SIFT [68] features computed on the foreground mask, a bag of Local Shape Contexts [69] computed on its boundary, and a HOG pyramid [70] with3 levels computed on the bounding box fitted on the boundary of the segment, for a total of 1,054 features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Representing shap e with a spatial pyramid kernel,\u201dACM International Conference on Image and Video Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our final, working set of segments is significantly reduced with the most accurate segments preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image segmentation by branchand-mincut"
            },
            "venue": {
                "fragments": [],
                "text": "European Conference on Computer Vision"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[56] for the parametric analysis of a push-relabel max-flow"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A fast par  ametric maximum flow algorithm and applications"
            },
            "venue": {
                "fragments": [],
                "text": " SIAM J. Comput. , vol. 18, no. 1, pp. 30\u201355, 1989."
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "Later, more accurate techniques emerge d\u2014 good surveys can be found in [17], [18], [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image segmentation tech niques"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision, Graphics, and Image Processing , vol. 29, no. 1, pp. 100\u2013132, 1985."
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "These are designed as energy functions efficiently solvable with parametric min-cut/max-flow techniques."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Constrained parametric min-cuts for automatic object segmentation, release 1"
            },
            "venue": {
                "fragments": [],
                "text": "Constrained parametric min-cuts for automatic object segmentation, release 1"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "Interesting relaxation approaches exist for some energies whose minimization is NP-hard, such as curvature regularity of the boundary [36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Curvature regul arity for region-based image segmentation and inpainting: A linear pro gramming relaxation"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Computer Vision  , 2009."
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Palmer.Vision Science: Photons to Phenomenology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient gra phbased image segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "IJCV, 59(2):167\u2013181,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Gestalt theorists [59], [60] argued that properties such as proximity, similarity, symmetry and good continuation are key to visual grouping."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Science: Photons to Phenomenology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 192
                            }
                        ],
                        "text": "Given a pair of foreground and background seeds and f(xu), the cost can be minimized exactly for all values of \u03bb in the same complexity as a single max-flow problem, using a parametric solver [54]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Applications o  f parametric maxflow in computer vision,\u201dIEEE"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Computer Vision,"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "We use an angle approximation to the curvature [64] on triplets of points sampled regularly ever y 15"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discr ete elastica"
            },
            "venue": {
                "fragments": [],
                "text": "DCGA \u201996: Proceedings of the 6th International Workshop on D iscrete Geometry for Computer Imagery  . London, UK: Springer-Verlag, 1996, pp. 59\u201372."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[30] proposed algebraic multigrid techniques for hierarchical segmentation, while Arbel\u00e1ez et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "H  ierarchy and adaptivity in segmenting visual"
            },
            "venue": {
                "fragments": [],
                "text": "scenes. Nature,"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning affinity f  unctions for image segmentation: combining patch-based and gradient-b ased approaches"
            },
            "venue": {
                "fragments": [],
                "text": "inIEEE International Conference on Computer Vision and Pattern Recognition , vol. 2, June 2003, pp. II\u201354\u201361 vol.2."
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "In order to generate a high-quality pool of segments, we solve multiple constrained parametric min-cuts (CPMC) with different seeds and unary terms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experimental evaluation of techniques for automatic segmentation of objects in a complex scene"
            },
            "venue": {
                "fragments": [],
                "text": "Pictorial Pattern Recognition"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "Semantic segmentation algorithms [10], [11], [12], [13] incorporate the outputs of these object detector s, and may need to mediate the transition between the rectangular regions produced by the detector and the desired free-form"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Region-based segmentat  ion and object detection"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems , Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A.  Culotta, Eds., December 2009, pp. 655\u2013663."
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminatively trained deformable part models, release 4"
            },
            "venue": {
                "fragments": [],
                "text": "Discriminatively trained deformable part models, release 4"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "The first image segmentation approach, published more than 40 years ago by Muerle and Allen [16], was aimed to compute \u2018object\u2019 regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experimental evaluation of te  chniques for automatic segmentation of objects in a complex scene."
            },
            "venue": {
                "fragments": [],
                "text": "Pictorial Pattern Recognition"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distinctive image features from scale-inva  riant keypoints.IJCV"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "erarchy and adaptivity in segmenting visual scenes Normalized cuts and image segmentation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 44,
            "methodology": 43
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 103,
        "totalPages": 11
    },
    "page_url": "https://www.semanticscholar.org/paper/Constrained-parametric-min-cuts-for-automatic-Carreira-Sminchisescu/4131a2862d9f926c6727da6dc75c8fda25f4a9e5?sort=total-citations"
}