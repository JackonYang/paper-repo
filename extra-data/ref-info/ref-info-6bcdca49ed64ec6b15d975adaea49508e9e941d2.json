{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "As in our previous work[9] we have used a view-based recognition paradigm for the multiple head orientations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 128
                            }
                        ],
                        "text": "We have recently extended the eigenface technique to a view-based and modular framework for automatic detection and recognition [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 136280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf5d558220d39698ce96d59ee5772e8e1a0663",
            "isKey": false,
            "numCitedBy": 2234,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated.<<ETX>>"
            },
            "slug": "View-based-and-modular-eigenspaces-for-face-Pentland-Moghaddam",
            "title": {
                "fragments": [],
                "text": "View-based and modular eigenspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer, which yields higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14955,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62633096,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "ad79d80aa5d5d98e0e8ebe3721fce50e90380fbf",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The human ability to process faces is remarkable. We can identify perhaps thousands of faces learned throughout our lifetime and read facial expression to understand such subtle qualities as emotion. These skills are quite robust, despite sometimes large changes in the visual stimulus due to expression, aging, and distractions such as glasses or changes in hairstyle or facial hair. Computers which model and recognize faces will be useful in a variety of applications, including criminal identification, human-computer interface, and animation. We discuss models for representing faces and their applicability to the task of recognition, and present techniques for identifying faces and detecting eye blinks."
            },
            "slug": "Face-Processing:-Models-For-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Face Processing: Models For Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work discusses models for representing faces and their applicability to the task of recognition, and presents techniques for identifying faces and detecting eye blinks."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2037776"
                        ],
                        "name": "D. Reisfeld",
                        "slug": "D.-Reisfeld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Reisfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Reisfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47620675"
                        ],
                        "name": "Y. Yeshurun",
                        "slug": "Y.-Yeshurun",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Yeshurun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yeshurun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "been proposed, ranging from the early work of Kanade with edge-map projections [4], to more recent techniques using generalized symmetry operators [10] and multilayer"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33599799,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aecb450ee0b3ab1883bbb85ce92df7b274f851cb",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "An operator based on the intuitive motion of symmetry, which effectively locates interest points in real time and can be incorporated also in active visual systems, is introduced. The results of its operation agree with some psychophysical evidence concerning symmetry as well as evidence concerning fixation points. The operator can be applied successfully without prior knowledge of the world. Combining the operator with some preconceptions about the image is a powerful tool for feature detection in intricate natural scenes. The localization of faces and facial features in real time is demonstrated on detailed and noisy pictures.<<ETX>>"
            },
            "slug": "Detection-of-interest-points-using-symmetry-Reisfeld-Wolfson",
            "title": {
                "fragments": [],
                "text": "Detection of interest points using symmetry"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An operator based on the intuitive motion of symmetry, which effectively locates interest points in real time and can be incorporated also in active visual systems, is introduced and the results of its operation agree with some psychophysical evidence concerning symmetry as well as evidence concerning fixation points."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 170
                            }
                        ],
                        "text": "The general applicability of eigenvector decomposition methods for appearance-based 3D object recognition has recently been convincingly demonstrated by Murase and Nayar [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61999742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5648d1f511a5180cc0bf7af80a42d3dea3a4680",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation. In contrast to the traditional approach, they formulate the recognition problem as one of matching visual appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties of an object and are constant, pose and illumination vary from scene to scene. They present a new compact representation of object appearance that is parameterized by pose and illumination. They have conducted experiments using several objects with complex appearance characteristics.<<ETX>>"
            },
            "slug": "Learning-and-recognition-of-3D-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Learning and recognition of 3D objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation as one of matching visual appearance rather than shape and present a new compact representation of object appearance that is parameterized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "[1993] Proceedings IEEE Workshop on Qualitative Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50577973"
                        ],
                        "name": "J. Vincent",
                        "slug": "J.-Vincent",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145208455"
                        ],
                        "name": "J. Waite",
                        "slug": "J.-Waite",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Waite",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Waite"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46503163"
                        ],
                        "name": "D. Myers",
                        "slug": "D.-Myers",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Myers",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Myers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61726920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b009a4c5eaeb55f3f7b1c74c3a1a0143ab2beed0",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A two-stage neural vision system for locating facial features is described. The first stage generates search regions in an image at low spatial resolution, and the second pinpoints the features at high resolution. Both stages employ multilayered perceptrons trained to detect specific visual details, followed by sophisticated global postprocessing of their outputs. This work demonstrates the power of combining neural feature detection with knowledge-based context-sensitive methods."
            },
            "slug": "Automatic-location-of-visual-features-by-a-system-Vincent-Waite",
            "title": {
                "fragments": [],
                "text": "Automatic location of visual features by a system of multilayered perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work demonstrates the power of combining neural feature detection with knowledge-based context-sensitive methods in a two-stage neural vision system for locating facial features."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 570648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66d75a5fe9e1b6511c5135d68e9ce8c0da5a7374",
            "isKey": false,
            "numCitedBy": 2853,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion. This results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix, without increasing the complexity of the calculation. The resulting approximation of faces projected from outside of the data set onto this optimal basis is improved on average. >"
            },
            "slug": "Application-of-the-Karhunen-Loeve-Procedure-for-the-Kirby-Sirovich",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen-Loeve Procedure for the Characterization of Human Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion, which results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 69
                            }
                        ],
                        "text": "In this paper we rst explore how the eigenface technique of Turk and Pentland [12] scales when applied to much larger recognition problems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 168
                            }
                        ],
                        "text": "One can think of this architecture as a set of parallel \\observers\" each trying to explain the image data with their set of eigenvectors (see also Darrell and Pentland [3])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5344867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1807058512ae2934b2be0b43f395d8583ef67303",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented. Objects are represented using sets of view models, rather than single templates. Stereotypical space-time patterns, i.e., gestures, are then matched to stored gesture patterns using dynamic time warping. Real-time performance is achieved by using special purpose correlation hardware and view prediction to prune as much of the search space as possible. Both view models and view predictions are learned from examples. Results showing tracking and recognition of human hand gestures at over 10 Hz are presented.<<ETX>>"
            },
            "slug": "Space-time-gestures-Darrell-Pentland",
            "title": {
                "fragments": [],
                "text": "Space-time gestures"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented and results showing tracking and recognition of human hand gestures at over 10 Hz are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120127765"
                        ],
                        "name": "B. V. Kumar",
                        "slug": "B.-V.-Kumar",
                        "structuredName": {
                            "firstName": "Bhagavatula",
                            "lastName": "Kumar",
                            "middleNames": [
                                "V.",
                                "K.",
                                "Vijaya"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. V. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34925745"
                        ],
                        "name": "D. Casasent",
                        "slug": "D.-Casasent",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Casasent",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Casasent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153811123"
                        ],
                        "name": "H. Murakami",
                        "slug": "H.-Murakami",
                        "structuredName": {
                            "firstName": "Hitotoshi",
                            "lastName": "Murakami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murakami"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 160
                            }
                        ],
                        "text": "In a statistical signal detection framework, the use of eigentemplates has been shown to yield superior performance in comparison with standard matched ltering [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62246877,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "b36e4e3f910e5422171359bc492efc8ad43a74ac",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Concepts, measures, and models of image quality are shown to be quite important in pattern recognition applications. Pattern recognition of imagery subjected to geometrical differences (such as scale and rotational changes) and intensity differences (such as arise in multispectral imagery) are considered. After modeling these image differences as a stochastic process, the optimal filter is derived. This filter is shown to be the principal component of the data. This pattern recognition algorithm is verified using multi-sensor imagery, and the results are found to compare favorably to those obtained using other candidate techniques."
            },
            "slug": "Principal-Component-Imagery-For-Statistical-Pattern-Kumar-Casasent",
            "title": {
                "fragments": [],
                "text": "Principal-Component Imagery For Statistical Pattern Recognition Correlators"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This pattern recognition algorithm is verified using multi-sensor imagery, and the results are found to compare favorably to those obtained using other candidate techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50748720"
                        ],
                        "name": "W. Welsh",
                        "slug": "W.-Welsh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Welsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Welsh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054171342"
                        ],
                        "name": "D. Shah",
                        "slug": "D.-Shah",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Shah"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 174
                            }
                        ],
                        "text": "For example, a layered representation consisting of the face and eigenmouths has recently been implemented for low bitrate transmission of visual telephony by Welsh and Shah [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122331422,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "5e73c9d81a49ba7507208a36198804b4a3a44d37",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Facial features in image sequences of a single subject are coded using principal components. Since the class of images used is restricted, a very efficient coding can be obtained and mouth images have been coded with reasonable quality at intraframe compression ratios of about 400"
            },
            "slug": "Facial-feature-image-coding-using-principal-Welsh-Shah",
            "title": {
                "fragments": [],
                "text": "Facial-feature image coding using principal components"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "Facial features in image sequences of a single subject are coded using principal components and a very efficient coding can be obtained and mouth images have been coded with reasonable quality at intraframe compression ratios of about 400."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "Photobook is an X-windows browsing tool that allows the user to interactively search through image databases [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5493306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32a8660582f5b07727906a43d737fda902a312eb",
            "isKey": false,
            "numCitedBy": 786,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the Photobook system, which is a set of interactive tools for browsing and searching images and image sequences. These tools differ from those used in standard image databases in that they make direct use of the image content rather than relying on annotations. Direct search on image content is made possible by use of semantics-preserving image compression, which reduces images to a small set of perceptually-significant coefficients. We describe three Photobook tools in particular: one that allows search based on grey-level appearance, one that uses 2D shape, and a third that allows search based on textural properties."
            },
            "slug": "Photobook:-tools-for-content-based-manipulation-of-Pentland-Picard",
            "title": {
                "fragments": [],
                "text": "Photobook: tools for content-based manipulation of image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The Photobook system is described, which is a set of interactive tools for browsing and searching images and image sequences that differ from those used in standard image databases in that they make direct use of the image content rather than relying on annotations."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34925745"
                        ],
                        "name": "D. Casasent",
                        "slug": "D.-Casasent",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Casasent",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Casasent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47921690"
                        ],
                        "name": "E. Hall",
                        "slug": "E.-Hall",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Hall",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60532838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e0ce50ddad70b558ff1c93d242c6b4cfd9b6864",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "These proceedings from a conference on intelligent robots and computer vision, contain papers on the following topics: pattern recognition, image processing, tactile sensors, parallel computation of image displacement fields, and object recognition."
            },
            "slug": "Intelligent-Robots-and-Computer-Vision-VI-Casasent-Hall",
            "title": {
                "fragments": [],
                "text": "Intelligent Robots and Computer Vision VI"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "These proceedings from a conference on intelligent robots and computer vision, contain papers on the following topics: pattern recognition, image processing, tactile sensors, parallel computation of image displacement fields, and object recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picture processing by computer complex and recognition ofhuman faces"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Report, Kyoto University, Dept. of Information Science, 1973."
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "been proposed, ranging from the early work of Kanade with edge-map projections [4], to more recent techniques using generalized symmetry operators [10] and multilayer"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picture processing by computer complex and recognition of human faces,"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Report, Kyoto University, Dept. of Information Science,"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face processing: mod-  els for recognition,\" Intelligent Robots and Computer  Vision VIII"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Space4ime Gestures"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. on Computer Vision and Pattern Recognition, NY NY, June 1993."
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 160
                            }
                        ],
                        "text": "In a statistical signal detection framework, the use of eigentemplates has been shown to yield superior performance in comparison with standard matched ltering [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Princi-  pal Component Imagery for Statistical Pattern Recog-  nition Correlators,"
            },
            "venue": {
                "fragments": [],
                "text": "Optical Engineering,"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 69
                            }
                        ],
                        "text": "In this paper we rst explore how the eigenface technique of Turk and Pentland [12] scales when applied to much larger recognition problems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 168
                            }
                        ],
                        "text": "One can think of this architecture as a set of parallel \\observers\" each trying to explain the image data with their set of eigenvectors (see also Darrell and Pentland [3])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Space-Time Ges-  tures,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. on Computer Vision and  Pattern Recognition, NY NY,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 170
                            }
                        ],
                        "text": "The general applicability of eigenvector decomposition methods for appearance-based 3D object recognition has recently been convincingly demonstrated by Murase and Nayar [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning and Recog-  nition of 3D Objects from Appearance\" in IEEE 2nd  Qualitative Vision Workshop"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 2
                            }
                        ],
                        "text": ", [2]), combined featureand-template matching (e."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "A similar e ect has recently been reported by Brunelli and Poggio [2] where the cumulative normalized correlation scores of templates for the face, eyes, nose and mouth showed improved performance over the face-only templates."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition: Features vs. Templates,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Pattern Analysis and Machine Intelligence,,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J, \\Automatic Location of Visual Features by a S y s t e m o f Multilayered Perceptrons"
            },
            "venue": {
                "fragments": [],
                "text": "IEE Proceedings"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face processing: models for recognition,\" Intelligent Robots and Computer Vision VIII"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 2
                            }
                        ],
                        "text": ", [2]), combined featureand-template matching (e."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition: Fea-  tures vs. Templates,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Pattern Anal-  ysis and Machine Intelligence,,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "Photobook is an X-windows browsing tool that allows the user to interactively search through image databases [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Photo-  book: Tools for Content-Based Manipulation of Im-  age Databases,\" SPIE Storage and Retrieval Image  and Video Databases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 2
                            }
                        ],
                        "text": ", [1]) or matching using \\eigenfaces,\" i."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Topological Matching  for Human Face Recognition,\" M.I.T. Media Labo-  ratory Vision and Modeling Group"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report  No"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Topological Matching for Human Face Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "M.I.T. Media Laboratory Vision and Modeling Group"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 2
                            }
                        ],
                        "text": ", [1]) or matching using \\eigenfaces,\" i."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Topological Matching for Human Face Recognition,\" M.I.T"
            },
            "venue": {
                "fragments": [],
                "text": "Media Laboratory Vision and Modeling Group Technical Report No"
            },
            "year": 1992
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 5,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Face-recognition-using-view-based-and-modular-Moghaddam-Pentland/6bcdca49ed64ec6b15d975adaea49508e9e941d2?sort=total-citations"
}