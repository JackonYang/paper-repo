{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2376935,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da838db79e7593018894ada44db35eee670941d6",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a natural language parsing algorithm for unrestricted text which uses a probability-based scoring function to select the \"best\" parse of a sentence. The parser, Pearl, is a time-asynchronous bottom-up chart parser with Earley-type top-down prediction which pursues the highest-scoring theory in the chart, where the score of a theory represents the extent to which the context of the sentence predicts that interpretation. This parser differs from previous attempts at stochastic parsers in that it uses a richer form of conditional probabilities based on context to predict likelihood. Pearl also provides a framework for incorporating the results of previous work in part-of-speech assignment, unknown word models, and other probabilistic models of linguistic features into one parsing tool, interleaving these techniques instead of using the traditional pipeline architecture. In preliminary tests, Pearl has been successful at resolving part-of-speech and word (in speech processing) ambiguity, determining categories for unknown words, and selecting correct parses first using a very loosely fitting covering grammar."
            },
            "slug": "Pearl:-A-Probabilistic-Chart-Parser-Magerman-Marcus",
            "title": {
                "fragments": [],
                "text": "Pearl: A Probabilistic Chart Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A natural language parsing algorithm for unrestricted text which uses a probability-based scoring function to select the \"best\" parse of a sentence and provides a framework for incorporating the results of previous work in part-of-speech assignment, unknown word models, and other probabilistic models of linguistic features into one parsing tool, interleaving these techniques instead of using the traditional pipeline architecture."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818123"
                        ],
                        "name": "E. Black",
                        "slug": "E.-Black",
                        "structuredName": {
                            "firstName": "Ezra",
                            "lastName": "Black",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8], and Magerman and Weir[41], probabilistic parsers are much more accurate when their models incorporate lexical information from the context, and when the applications of the models are not assumed to be independent."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5598810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0ccae6c9f33e41de9c00053aac0bc6c615c7b4a",
            "isKey": false,
            "numCitedBy": 282,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a generative probabilistic model of natural language, which we call HBG, that takes advantage of detailed linguistic information to resolve ambiguity. HBG incorporates lexical, syntactic, semantic, and structural information from the parse tree into the disambiguation process in a novel way. We use a corpus of bracketed sentences, called a Treebank, in combination with decision tree building to tease out the relevant aspects of a parse tree that will determine the correct parse of a sentence. This stands in contrast to the usual approach of further grammar tailoring via the usual linguistic introspection in the hope of generating the correct parse. In head-to-head tests against one of the best existing robust probabilistic parsing models, which we call P-CFG, the HBG model significantly outperforms P-CFG, increasing the parsing accuracy rate from 60% to 75%, a 37% reduction in error."
            },
            "slug": "Towards-History-based-Grammars:-Using-Richer-Models-Black-Jelinek",
            "title": {
                "fragments": [],
                "text": "Towards History-based Grammars: Using Richer Models for Probabilistic Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "HBG incorporates lexical, syntactic, semantic, and structural information from the parse tree into the disambiguation process in a novel way and significantly outperforms P-CFG, increasing the parsing accuracy rate from 60% to 75%, a 37% reduction in error."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 192
                            }
                        ],
                        "text": "Although my technical knowledge developed at IBM, my interest in natural language parsing began during my undergraduate days at the University of Pennsylvania, under the tutelage of Dr. Mitch Marcus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "For instance, in 1990, I published my undergraduate thesis with Marcus [41] on parsing without a grammar using mutual information statistics from a tagged corpus."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 177
                            }
                        ],
                        "text": "More evidence that the availability of corpora has in uenced the direction of research is in the study of parsing tagged sentences using statistical methods (Magerman and Marcus[41], Brill [16], and Bod[12])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 158
                            }
                        ],
                        "text": "In the end, I chose natural language processing, and, true to his word, he introduced me to the head of the Language and Information Computing lab, Dr. Mitch Marcus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 29
                            }
                        ],
                        "text": "I am greatly indebted to Dr. Marcus for introducing me to the NLP field, and for teaching me the fundamentals of parsing."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14390678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8cf9b7c08655dadad0cad00771f3c9670181004e",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The purpose of this paper is to characterize a constituent boundary parsing algorithm, using an information-theoretic measure called generalized mutual information, which serves as an alternative to traditional grammar-based parsing methods. This method is based on the hypothesis that constituent boundaries can be extracted from a given sentence (or word sequence) by analyzing the mutual information values of the part of speech n-grams within the sentence. This hypothesis is supported by the performance of an implementation of this parsing algorithm which determines a recursive unlabeled bracketing of unrestricted English text with a relatively low error rate. This paper derives the generalized mutual information statistic, describes the parsing algorithm, and presents results and sample output from the parser."
            },
            "slug": "Parsing-a-Natural-Language-Using-Mutual-Information-Magerman-Marcus",
            "title": {
                "fragments": [],
                "text": "Parsing a Natural Language Using Mutual Information Statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The generalized mutual information statistic is derived, the parsing algorithm is described, and results and sample output from the parser are presented."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818123"
                        ],
                        "name": "E. Black",
                        "slug": "E.-Black",
                        "structuredName": {
                            "firstName": "Ezra",
                            "lastName": "Black",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Lafferty [9] uses decision tree techniques similar to those described in Chapter 3 in his paper on decision tree part-of-speech tagging."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1586259,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3a19430f47bf8370a894c93857c0be0f913ac3b",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to grammar development where the task is decomposed into two separate subtasks. The first tasks linguistic, with the goal of producing a set of rules that have a large coverage (in the sense that the correct parse is among the proposed parses) on a blind test set of sentences. The second task is statistical, with the goal of developing a model of the grammar which assigns maximum probability for the correct parse. We give parsing results on text from computer manuals."
            },
            "slug": "Development-and-Evaluation-of-a-Broad-Coverage-of-Black-Lafferty",
            "title": {
                "fragments": [],
                "text": "Development and Evaluation of a Broad-Coverage Probabilistic Grammar of English-Language Computer Manuals"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "An approach to grammar development where the task is decomposed into two separate subtasks, with the goal of producing a set of rules that have a large coverage on a blind test set of sentences."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818123"
                        ],
                        "name": "E. Black",
                        "slug": "E.-Black",
                        "structuredName": {
                            "firstName": "Ezra",
                            "lastName": "Black",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153733790"
                        ],
                        "name": "R. Garside",
                        "slug": "R.-Garside",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Garside",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garside"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143998726"
                        ],
                        "name": "G. Leech",
                        "slug": "G.-Leech",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Leech",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Leech"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "112868461"
                        ],
                        "name": "E. Eyes",
                        "slug": "E.-Eyes",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Eyes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Eyes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Black, Garside, and Leech [7] provides detailed reports on experiments performed using his P-CFG, some of which is described in this section."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 183
                            }
                        ],
                        "text": "The state-of-the-art in statistical parsing technology includes P-CFGs trained using the Inside-Outside algorithm (Schabes and Pereira [48], Kupiec [39], and Black, Garside, and Leech[7], parsers which generate unlabeled bracketing using correct tag sequences as input (Brill [16], Schabes and Pereira [48], and grammar induction strategies which attempt to acquire grammars by extracting context-free productions from treebanks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "These sentences are the same test sentences used in the experiments reported for the P-CFG parser in Black, Garside, and Leech[7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "(1)The notion of a token is not clearly de ned in [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "The de nitions of these tags and labels are given in [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "For a complete description of this grammar, see Black, Garside, and Leech[7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "Since [7] only reports results using the sentence-based crossing-brackets measure, I am reporting the same measure for the sake of comparison."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 198
                            }
                        ],
                        "text": "The idea behind the basic experiment is to construct the best parser possible and to perform experiments using the same training and test data as the experiment reported in Black, Garside, and Leech[7], which I refer to as the P-CFG experiment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 46
                            }
                        ],
                        "text": "[1]), or a combination of these methods (e.g. Black, Garside, and Leech [7])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "[10] [7], Kupiec [39], and Schabes and Pereira [48]), have applied the inside-outside algorithm, a special case of the expectation-maximization algorithm for CFGs, to probabilistic context-free grammar (P-CFG) estimation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "For example, the Lancaster Treebank uses only 17 constituent labels, whereas the grammar described in Black, Garside, and Leech[7] covering the same domain assigns over 13,000 unique"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17387777,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32889f93ab4f08e6b8d9e8bf4719fef18ec986d3",
            "isKey": true,
            "numCitedBy": 121,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book is about building computer programs that parse (analyze, or diagram) sentences of a real-world English. The English we are concerned with might be a corpus of everyday, naturally-occurring prose, such as the entire text of this morning's newspaper. Most programs that now exist for this purpose are not very successful at finding the correct analysis for everyday sentences. In contrast, the programs described here make use of a more successful statistically-driven approach. Our book is, first, a record of a five-year research collaboration between IBM and Lancaster University. Large numbers of real-world sentences were fed into the memory of a program for grammatical analysis (including a detailed grammar of English) and processed by statistical methods. The idea is to single out the correct parse, among all those offered by the grammar, on the basis of probabilities. Second, this is a how-to book, showing how to build and implement a statistically-driven broad-coverage grammar of English. We even supply our own grammar, with the necessary statistical algorithms, and with the knowledge needed to prepare a very large set (or corpus) of sentences so that it can be used to guide the statistical processing of the grammar's rules."
            },
            "slug": "Statistically-driven-computer-grammars-of-English-:-Black-Garside",
            "title": {
                "fragments": [],
                "text": "Statistically-driven computer grammars of English : the IBM/LANCASTER approach"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "This book is about building computer programs that parse (analyze, or diagram) sentences of a real-world English, which might be a corpus of everyday, naturally-occurring prose, such as the entire text of this morning's newspaper."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3187096"
                        ],
                        "name": "Jerry R. Hobbs",
                        "slug": "Jerry-R.-Hobbs",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Hobbs",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jerry R. Hobbs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697386"
                        ],
                        "name": "D. Appelt",
                        "slug": "D.-Appelt",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Appelt",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Appelt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626545"
                        ],
                        "name": "J. Bear",
                        "slug": "J.-Bear",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bear",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bear"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26701145"
                        ],
                        "name": "David J. Israel",
                        "slug": "David-J.-Israel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Israel",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Israel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30161917"
                        ],
                        "name": "W. M. Tyson",
                        "slug": "W.-M.-Tyson",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Tyson",
                            "middleNames": [
                                "Mabry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. M. Tyson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "These systems gave way to more re ned information extraction systems, such as SRI's FASTUS system [35], which abandons the grammar-based parsing strategy in favor of a nite-state machine approach, specifying exible templates for identifying the critical information necessary for accomplishing the information extraction task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18680548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebc2defb23b4667d460304eabe68fbc8395a829a",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : FASTUS is a system for extracting information from free text in English, and potentially other languages as well, for entry into a database, and potentially for other applications. It works essentially as a cascaded, nondeterministic finite state automaton. There are four steps in the operation of FASTUS. In Step (1) sentences are scanned for certain trigger words to determine whether further processing should be done. In Step (2) noun groups, verb groups, and prepositions and some other particles are recognized. The input to Step (3) is the sequence of phrases recognized in Step (2); patterns of interest are identified in Step (3) and corresponding incident structures are built up. In Step (4) incident structures that derive from the same incident are identified and merged, and these are used in generating database entries. FASTUS is an order of magnitude faster than any comparable system; it can process a news report in an average of less than eleven seconds. This translates directly into fast development time. In the three and a half weeks between its first use and the MUC-4 evaluation in May 1992, we were able to build up its domain knowledge to a point where it was among the leaders in the evaluation."
            },
            "slug": "FASTUS:-A-System-for-Extracting-Information-from-Hobbs-Appelt",
            "title": {
                "fragments": [],
                "text": "FASTUS: A System for Extracting Information from Natural-Language Text"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "In the three and a half weeks between its first use and the MUC-4 evaluation in May 1992, FASTUS was able to build up its domain knowledge to a point where it was among the leaders in the evaluation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764192"
                        ],
                        "name": "R. Bod",
                        "slug": "R.-Bod",
                        "structuredName": {
                            "firstName": "Rens",
                            "lastName": "Bod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bod"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 202
                            }
                        ],
                        "text": "More evidence that the availability of corpora has in uenced the direction of research is in the study of parsing tagged sentences using statistical methods (Magerman and Marcus[41], Brill [16], and Bod[12])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "In his recent paper [12], Bod reports achieving a 96% exact match accuracy rate parsing UPenn treebank data from the ATIS domain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Experiments F and G mimic the experiments performed by Brill [16] and by Bod [12], respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "Recently, there have been a number of papers, such as Schabes and Pereira[48], Brill [16], and Bod[12], citing work based on parsing using sentences tagged for part of speech."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "One solution might be to model multiple levels of constituent structure, as Bod does in [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60629654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa990351f8235b31efc015a2be7f0be5b5b2f979",
            "isKey": true,
            "numCitedBy": 30,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In stochastic language processing, we are often interested in the most probable parse of an input string. Since there can be exponentially many parses, comparing all of them is not efficient. The Viterbi algorithm (Viterbi, 1967; Fujisaki et al., 1989) provides a tool to calculate in cubic time the most probable derivation of a string generated by a stochastic context free grammar. However, in stochastic language models that allow a parse tree to be generated by different derivations like Data Oriented Parsing (DOP) or Stochastic Lexicalized Tree-Adjoining Grammar (SLTAG) the most probable derivation does not necessarily produce the most probable parse. In such cases, a Viterbi-style optimisation does not seem feasible to calculate the most probable parse. In the present article we show that by incorporating Monte Carlo techniques into a polynomial time parsing algorithm, the maximum probability parse can be estimated as accurately as desired in polynomial time. Monte Carlo parsing is not only relevant to DOP or SLTAG, but also provides for stochastic CFGs an interesting alternative to Viterbi. Unlike the current versions of Viterbi\u00ad style optimisation (Fujisaki et al., 1989; Jelinek et al., 1990; Wright et al., 1991), Monte Carlo parsing is not restricted to CFGs in Chomsky Normal Form. For stochastic grammars that are parsable in cubic time, the time complexity of estimating the most probable parse with Monte Carlo turns out to be O(n3c:-2), where n is the length of the input string and c: the estimation error. In this paper we will treat Monte Carlo parsing first of all in the context of the DOP model, since it is especially here that the number of derivations generating a single tree becomes dramatically large. Finally, a Monte Carlo Chart parser is used to test the DOP model on a set of hand-parsed strings from the Air Travel Information System {ATIS) spoken language corpus. Preliminary experiments indicate 96% test set parsing accuracy."
            },
            "slug": "Monte-Carlo-Parsing-Bod",
            "title": {
                "fragments": [],
                "text": "Monte Carlo Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that by incorporating Monte Carlo techniques into a polynomial time parsing algorithm, the maximum probability parse can be estimated as accurately as desired in polynometric time."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32597159"
                        ],
                        "name": "R. Sharman",
                        "slug": "R.-Sharman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sharman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sharman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32405574"
                        ],
                        "name": "R. Hercer",
                        "slug": "R.-Hercer",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Hercer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 23
                            }
                        ],
                        "text": "Drs. Fred Jelinek, Bob Mercer, and Salim Roukos, the managers in the language modeling group during the time I performed my thesis research, contributed a great number of ideas to my research."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Sharman, Jelinek and Mercer [61], Black, Garside, and Leech [10]), which assigns a probability to each rule in a context-free grammar and computes the probability of the parse tree by assuming that each grammar rule application is independent of all other rule applications in the sentence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 41
                            }
                        ],
                        "text": "During the summer of 1992, Drs. Jelinek, Mercer, and Roukos, along with Dr. John Lafferty, Adwait Ratnaparkhi, and Barbara Gates met with me twice weekly to discuss progress in the development of SPATTER and to brainstorm solutions to problems."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17402234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "860dfdaa8187bd22809f00396b30c66a2fc1ef24",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Parsing sentences of a Natural Language(NL) is an essential requirement for a variety of NL applications, and has been extensively studied. In particular, the sort of tasks which it would be desirable to do, include the ability to tag each word with its part-of-speech; to delineate with brackets, and label with a category name, each syntactic phrase; and to be able to adapt to different types of source material. Despite some 30 years of active research performing these tasks with a high degree of accuracy on unrestricted text is still an unsolved problem."
            },
            "slug": "Generating-a-grammar-for-statistical-training-Sharman-Jelinek",
            "title": {
                "fragments": [],
                "text": "Generating a grammar for statistical training"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Parsing sentences of a Natural Language is an essential requirement for a variety of NL applications, and has been extensively studied."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 189
                            }
                        ],
                        "text": "More evidence that the availability of corpora has in uenced the direction of research is in the study of parsing tagged sentences using statistical methods (Magerman and Marcus[41], Brill [16], and Bod[12])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 276
                            }
                        ],
                        "text": "The state-of-the-art in statistical parsing technology includes P-CFGs trained using the Inside-Outside algorithm (Schabes and Pereira [48], Kupiec [39], and Black, Garside, and Leech[7], parsers which generate unlabeled bracketing using correct tag sequences as input (Brill [16], Schabes and Pereira [48], and grammar induction strategies which attempt to acquire grammars by extracting context-free productions from treebanks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "Recently, there have been a number of papers, such as Schabes and Pereira[48], Brill [16], and Bod[12], citing work based on parsing using sentences tagged for part of speech."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "Experiments F and G mimic the experiments performed by Brill [16] and by Bod [12], respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16695022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17beaab6b27faef07f988325503b7c30a6377753",
            "isKey": true,
            "numCitedBy": 65,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new technique for parsing free text: a transformational grammar is automatically learned that is capable of accurately parsing text into binary-branching syntactic trees. The algorithm works by beginning in a very naive state of knowledge about phrase structure. By repeatedly comparing the results of bracketing in the current state to proper bracketing provided in the training corpus, the system learns a set of simple structural transformations that can be applied to reduce the number of errors. After describing the algorithm, we present results and compare these results to other recent results in automatic grammar induction."
            },
            "slug": "Transformation-Based-Error-Driven-Parsing-Brill",
            "title": {
                "fragments": [],
                "text": "Transformation-Based Error-Driven Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A transformational grammar is automatically learned that is capable of accurately parsing text into binary-branching syntactic trees, and a set of simple structural transformations are applied to reduce the number of errors."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699245"
                        ],
                        "name": "T. Winograd",
                        "slug": "T.-Winograd",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Winograd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Winograd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "SHRDLU demonstrated the effectiveness of functional representations on a small problem, but it also implicitly revealed one of its weaknesses."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 56
                            }
                        ],
                        "text": "While one could claim that predicates could be added to SHRDLU to fill these gaps, this is the same as claiming that a grammar would work if one only added the correct rules."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 61
                            }
                        ],
                        "text": "His theory was illustrated in Winograd\u2019s blocks-world system, SHRDLU[65]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "SHRDLU implemented a set of predicates which were defined to be the blocks-world."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "His theory was illustrated in Winograd's blocks-world system, SHRDLU[67]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 56798209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb20f121c979b535bbeade5ac06676d627d4ad7d",
            "isKey": true,
            "numCitedBy": 2455,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This paper describes a computer system for understanding English. The system answers questions, executes commands, and accepts information in an interactive English dialog. It is based on the belief that in modeling language understanding, we must deal in an integrated way with all of the aspects of language\u2014syntax, semantics, and inference. The system contains a parser, a recognition grammar of English, programs for semantic analysis, and a general problem solving system. We assume that a computer cannot deal reasonably with language unless it can understand the subject it is discussing. Therefore, the program is given a detailed model of a particular domain. In addition, the system has a simple model of its own mentality. It can remember and discuss its plans and actions as well as carrying them out. It enters into a dialog with a person, responding to English sentences with actions and English replies, asking for clarification when its heuristic programs cannot understand a sentence through the use of syntactic, semantic, contextual, and physical knowledge. Knowledge in the system is represented in the form of procedures, rather than tables of rules or lists of patterns. By developing special procedural representations for syntax, semantics, and inference, we gain flexibility and power. Since each piece of knowledge can be a procedure, it can call directly on any other piece of knowledge in the system."
            },
            "slug": "Understanding-natural-language-Winograd",
            "title": {
                "fragments": [],
                "text": "Understanding natural language"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A computer system for understanding English that contains a parser, a recognition grammar of English, programs for semantic analysis, and a general problem solving system based on the belief that in modeling language understanding, it must deal in an integrated way with all of the aspects of language\u2014syntax, semantics, and inference."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9079926"
                        ],
                        "name": "W. Woods",
                        "slug": "W.-Woods",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Woods",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Woods"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "The development of Augmented Transition Networks (ATNs) by Woods in the early 1970s [68] improved upon the power of regular expressions and context-free grammars by augmenting a nite-state automaton with register variables and functional constraints, allowing an ATN to consider more contextual information when generating an analysis while maintaining the computational simplicity of a nite-state machine."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18366823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09550accec47459a61fe1710a0a32c2ec22449bd",
            "isKey": false,
            "numCitedBy": 1450,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of augmented transition network grammars for the analysis of natural language sentences is described. Structure-building actions associated with the arcs of the grammar network allow for the reordering, restructuring, and copying of constituents necessary to produce deep-structure representations of the type normally obtained from a transformational analysis, and conditions on the arcs allow for a powerful selectivity which can rule out meaningless analyses and take advantage of semantic information to guide the parsing. The advantages of this model for natural language analysis are discussed in detail and illustrated by examples. An implementation of an experimental parsing system for transition network grammars is briefly described."
            },
            "slug": "Transition-network-grammars-for-natural-language-Woods",
            "title": {
                "fragments": [],
                "text": "Transition network grammars for natural language analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The use of augmented transition network grammars for the analysis of natural language sentences is described, and structure-building actions associated with the arcs of the grammar network allow for a powerful selectivity which can rule out meaningless analyses and take advantage of semantic information to guide the parsing."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28791020"
                        ],
                        "name": "B. Raphael",
                        "slug": "B.-Raphael",
                        "structuredName": {
                            "firstName": "Bertram",
                            "lastName": "Raphael",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Raphael"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "Systems such as Green\u2019s BASEBALL[26], Raphael\u2019s SIR[50], and Bobrow\u2019s STUDENT[11] search for simple patterns or regular expressions which indicate useful information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "Systems such as Green's BASEBALL[26], Raphael's SIR[52], and Bobrow's STUDENT[11] search for simple patterns or regular expressions which indicate useful information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62082148,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "327efd65ba18aef17379fcc0c7dc7162e06339a6",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "SIR is a computer system, programmed in the LISP language, which accepts information and answers questions expressed in a restricted form of English. This system demonstrates what can reasonably be called an ability to \"understand\" semantic information. SIR''s semantic and deductive ability is based on the construction of an internal model, which uses word associations and property lists, for the relational information normally conveyed in conversational statements. A format-matching procedure extracts semantic content from English sentences. If an input sentence is declarative, the system adds appropriate information to the model. If an input sentence is a question, the system searches the model until it either finds the answer or determines why it cannot find the answer. In all cases SIR reports its conclusions. The system has some capacity to recognize exceptions to general rules, resolve certain semantic ambiguities, and modify its model structure in order to save computer memory space. Judging from its conversational ability, SIR is more \"intelligent\" than any existing question-answering system. The author describes how this ability was developed and how the basic features of SIR compare with those of other systems. The working system, SIR , is a first step toward intelligent machine communication. The author proposes a next step by describing how to construct a more general system which is less complex and yet more powerful than SIR . This proposed system contains a generalized version of the SIR model, a formal logical system called SIR1 , and a computer program for testing the truth of SIR1 statements with respect to the generalized model by using partial proof procedures in the predicate calculus. The thesis also describes the formal properties of SIR1 and how they relate to the logical structure of SIR ."
            },
            "slug": "SIR:-A-COMPUTER-PROGRAM-FOR-SEMANTIC-INFORMATION-Raphael",
            "title": {
                "fragments": [],
                "text": "SIR: A COMPUTER PROGRAM FOR SEMANTIC INFORMATION RETRIEVAL"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author describes how this ability to \"understand\" semantic information was developed and how the basic features of SIR compare with those of other systems, and proposes a next step to construct a more general system which is less complex and yet more powerful than SIR."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818123"
                        ],
                        "name": "E. Black",
                        "slug": "E.-Black",
                        "structuredName": {
                            "firstName": "Ezra",
                            "lastName": "Black",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35551590"
                        ],
                        "name": "Steven P. Abney",
                        "slug": "Steven-P.-Abney",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Abney",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven P. Abney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277328"
                        ],
                        "name": "D. Flickenger",
                        "slug": "D.-Flickenger",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Flickenger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Flickenger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1929125"
                        ],
                        "name": "C. Gdaniec",
                        "slug": "C.-Gdaniec",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Gdaniec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gdaniec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143878270"
                        ],
                        "name": "P. Harrison",
                        "slug": "P.-Harrison",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Harrison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Harrison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21169546"
                        ],
                        "name": "Donald Hindle",
                        "slug": "Donald-Hindle",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hindle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Hindle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319612"
                        ],
                        "name": "R. Ingria",
                        "slug": "R.-Ingria",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Ingria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingria"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761739"
                        ],
                        "name": "Judith L. Klavans",
                        "slug": "Judith-L.-Klavans",
                        "structuredName": {
                            "firstName": "Judith",
                            "lastName": "Klavans",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Judith L. Klavans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144173823"
                        ],
                        "name": "M. Liberman",
                        "slug": "M.-Liberman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Liberman",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liberman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791072"
                        ],
                        "name": "T. Strzalkowski",
                        "slug": "T.-Strzalkowski",
                        "structuredName": {
                            "firstName": "Tomek",
                            "lastName": "Strzalkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Strzalkowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17643319,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "7689778171dc100bb636fc0e4e2ce4063967d3c9",
            "isKey": false,
            "numCitedBy": 554,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of quantitatively comparing the performance of different broad-coverage grammars of English has to date resisted solution. Prima facie, known English grammars appear to disagree strongly with each other as to the elements of even the simplest sentences. For instance, the grammars of Steve Abney (Bellcore), Ezra Black (IBM), Dan Flickinger (Hewlett Packard), Claudia Gdaniec (Logos), Ralph Grishman and Tomek Strzalkowski (NYU), Phil Harrison (Boeing), Don Hindle (AT&T), Bob Ingria (BBN), and Mitch Marcus (U. of Pennsylvania) recognize in common only the following constituents, when each grammarian provides the single parse which he/she would ideally want his/her grammar to specify for three sample Brown Corpus sentences:The famed Yankee Clipper, now retired, has been assisting (as (a batting coach)).One of those capital-gains ventures, in fact, has saddled him (with Gore Court).He said this constituted a (very serious) misuse (of the (Criminal court) processes)."
            },
            "slug": "A-Procedure-for-Quantitatively-Comparing-the-of-Black-Abney",
            "title": {
                "fragments": [],
                "text": "A Procedure for Quantitatively Comparing the Syntactic Coverage of English Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem of quantitatively comparing the performance of different broad-coverage grammars of English has to date resisted solution."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701400"
                        ],
                        "name": "G. Gazdar",
                        "slug": "G.-Gazdar",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Gazdar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gazdar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145606490"
                        ],
                        "name": "Ewan Klein",
                        "slug": "Ewan-Klein",
                        "structuredName": {
                            "firstName": "Ewan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ewan Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2770201"
                        ],
                        "name": "G. Pullum",
                        "slug": "G.-Pullum",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Pullum",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Pullum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2393013"
                        ],
                        "name": "I. Sag",
                        "slug": "I.-Sag",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Sag",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sag"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 392,
                                "start": 388
                            }
                        ],
                        "text": "Perhaps in response to the ad-hoc nature of ATNs, in the early 1980s a number of grammatical formalisms appeared which attempted to account for the power of the functional augmentations of ATNs in a more formal theoretical framework: DefiniteClause Grammar (DCG) [47], Functional Unification Grammar (FUG) [36], LexicalFunctional Grammar (LFG) [35], Generalized Phrase Structure Grammar (GPSG) [25], and others."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 396,
                                "start": 392
                            }
                        ],
                        "text": "Perhaps in response to the ad-hoc nature of ATNs, in the early 1980s a number of grammatical formalisms appeared which attempted to account for the power of the functional augmentations of ATNs in a more formal theoretical framework: De niteClause Grammar (DCG) [49], Functional Uni cation Grammar (FUG) [38], LexicalFunctional Grammar (LFG) [37], Generalized Phrase Structure Grammar (GPSG) [25], and others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61087257,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "cdfefdebd4686a878e6572cb8ba2da9d8efbe552",
            "isKey": false,
            "numCitedBy": 2056,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "\"Generalized Phrase Structure Grammar\" provides the definitive exposition of the theory of grammar originally proposed by Gerald Gazdar and developed during half a dozen years' work with his colleagues Ewan Klein, Geoffrey Pullum, and Ivan Sag. This long-awaited book contains both detailed specifications of the theory and extensive illustrations of its power to describe large parts of English grammar. Experts who wish to evaluate the theory and students learning GPSP for the first time will find this book an invaluable guide.The initial chapters lay out the theoretical machinery of GPSP in a readily intelligible way. Combining informal discussion with precise formalization, the authors describe all major aspects of their grammatical system, including a complete theory of syntactic features, phrase structure rules, meta rules, and feature instantiation principles. The book then shows just what a GPSP analysis of English syntax can accomplish. Topics include the internal structure of phrases, unbounded dependency constructions of many varieties, and coordinate conjunction a construction long considered the sticking point for phrase structure approaches to syntax.The book concludes with a well developed proposal for a model theoretic semantic system to go along with GPSP syntax. Throughout, the authors maintain the highest standards of explicitness and rigor in developing and assessing their grammatical system. Their aim is to provide the best possible test of the hypothesis that syntactic description can be accomplished in a single-level system. And more generally, it is their intention to formulate a grammatical framework in which linguistic universals follow directly from the form of the system and therefore require no explicit statement. Their book sets new methodological standards for work in generative grammar while presenting a grammatical system of extraordinary scope.\""
            },
            "slug": "Generalized-Phrase-Structure-Grammar-Gazdar-Klein",
            "title": {
                "fragments": [],
                "text": "Generalized Phrase Structure Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "\"Generalized Phrase Structure Grammar\" provides the definitive exposition of the theory of grammar originally proposed by Gerald Gazdar and developed during half a dozen years' work with his colleagues Ewan Klein, Geoffrey Pullum, and Ivan Sag."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145148360"
                        ],
                        "name": "L. Hirschman",
                        "slug": "L.-Hirschman",
                        "structuredName": {
                            "firstName": "Lynette",
                            "lastName": "Hirschman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hirschman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145755155"
                        ],
                        "name": "Martha Palmer",
                        "slug": "Martha-Palmer",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "Palmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha Palmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145732121"
                        ],
                        "name": "J. Dowding",
                        "slug": "J.-Dowding",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Dowding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dowding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34586863"
                        ],
                        "name": "D. Dahl",
                        "slug": "D.-Dahl",
                        "structuredName": {
                            "firstName": "Deborah",
                            "lastName": "Dahl",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2816681"
                        ],
                        "name": "M. Linebarger",
                        "slug": "M.-Linebarger",
                        "structuredName": {
                            "firstName": "Marcia",
                            "lastName": "Linebarger",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Linebarger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703046"
                        ],
                        "name": "R. Passonneau",
                        "slug": "R.-Passonneau",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Passonneau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Passonneau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076168741"
                        ],
                        "name": "F.-M. Land",
                        "slug": "F.-M.-Land",
                        "structuredName": {
                            "firstName": "F.-M.",
                            "lastName": "Land",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F.-M. Land"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35614104"
                        ],
                        "name": "Catherine N. Ball",
                        "slug": "Catherine-N.-Ball",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Ball",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine N. Ball"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143757098"
                        ],
                        "name": "C. Weir",
                        "slug": "C.-Weir",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Weir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Weir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "The grammar to which this experiment was applied is the PUNDIT string grammar developed at Unisys [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[32]), free-form logical expressions (e."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61371892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ddc68614bb19603ecdb68d6d4ca9b042a2f1c0db",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe the PUNDIT (Prolog Understanding of Integrated Text) text-understanding system, which is designed to analyze and construct representations of paragraph-length text. PUNDIT is implemented in Quintus Prolog, and consists of distinct lexical, syntactic, semantic, and pragmatic components. Each component draws on one or more sets of data, including a lexicon, a broad-coverage grammar of English, semantic verb decompositions, rules mapping between syntactic and semantic constituents, and a domain model. Modularity, careful separation of declarative and procedural information, and separation of domain-specific and domain-independent information all contribute to a system which is flexible, extensible and portable. Versions of PUNDIT are now running in five domains, including four military and one medical.<<ETX>>"
            },
            "slug": "The-PUNDIT-natural-language-processing-system-Hirschman-Palmer",
            "title": {
                "fragments": [],
                "text": "The PUNDIT natural-language processing system"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The authors describe the PUNDIT (Prolog Understanding of Integrated Text) text-understanding system, which is designed to analyze and construct representations of paragraph-length text that is flexible, extensible and portable."
            },
            "venue": {
                "fragments": [],
                "text": "[1989] Proceedings. The Annual AI Systems in Government Conference"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40552549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af386a4e0f2615ed929fdc64a86df8e383bd6121",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of predicting the next word a speaker will say, given the words already spoken; is discussed. Specifically, the problem is to estimate the probability that a given word will be the next word uttered. Algorithms are presented for automatically constructing a binary decision tree designed to estimate these probabilities. At each node of the tree there is a yes/no question relating to the words already spoken, and at each leaf there is a probability distribution over the allowable vocabulary. Ideally, these nodal questions can take the form of arbitrarily complex Boolean expressions, but computationally cheaper alternatives are also discussed. Some results obtained on a 5000-word vocabulary with a tree designed to predict the next word spoken from the preceding 20 words are included. The tree is compared to an equivalent trigram model and shown to be superior. >"
            },
            "slug": "A-tree-based-statistical-language-model-for-natural-Bahl-Brown",
            "title": {
                "fragments": [],
                "text": "A tree-based statistical language model for natural language speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Algorithms are presented for automatically constructing a binary decision tree designed to estimate the probability that a given word will be the next word uttered, which is compared to an equivalent trigram model and shown to be superior."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Resnik[53]) and verb subcategorization information (e."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17631109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "297e478f92cef1cd090706fc59fde5ea0836ce80",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "It has become common in statistical studies of natural language data to use measures of lexical association, such as the information-theoretic measure of mutual information, to extract useful relationships between words (e.g. [Church et al., 1989; Church and Hanks, 1989; Hindle, 1990]). For example, [Hindle, 1990] uses an estimate of mutual information to calculate what nouns a verb can take as its subjects and objects, based on distributions found within a large corpus of naturally occurring text."
            },
            "slug": "WordNet-and-Distributional-Analysis:-A-Class-based-Resnik",
            "title": {
                "fragments": [],
                "text": "WordNet and Distributional Analysis: A Class-based Approach to Lexical Discovery"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An estimate of mutual information is used to calculate what nouns a verb can take as its subjects and objects, based on distributions found within a large corpus of naturally occurring text."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 1992"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "Statistical part-of-speech tagging has been a hot topic since the 1988 ACL paper by Church on HMM tagging [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3166885,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7e084fe51a40eeaaf79bf0b78e837d5bc4a8e10",
            "isKey": false,
            "numCitedBy": 1058,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A program that tags each word in an input sentence with the most likely part of speech has been written. The program uses a linear-time dynamic programming algorithm to find an assignment of parts of speech to words that optimizes the product of (a) lexical probabilities (probability of observing part of speech i given word i) and (b) contextual probabilities (probability of observing part of speech i given n following parts of speech). Program performance is encouraging; a 400-word sample is presented and is judged to be 99.5% correct.<<ETX>>"
            },
            "slug": "A-Stochastic-Parts-Program-and-Noun-Phrase-Parser-Church",
            "title": {
                "fragments": [],
                "text": "A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A program that tags each word in an input sentence with the most likely part of speech has been written and performance is encouraging; a 400-word sample is presented and is judged to be 99.5% correct."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725500"
                        ],
                        "name": "Yves Schabes",
                        "slug": "Yves-Schabes",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Schabes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yves Schabes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "The state-of-the-art in statistical parsing technology includes P-CFGs trained using the Inside-Outside algorithm (Schabes and Pereira [48], Kupiec [39], and Black, Garside, and Leech[7], parsers which generate unlabeled bracketing using correct tag sequences as input (Brill [16], Schabes and Pereira [48], and grammar induction strategies which attempt to acquire grammars by extracting context-free productions from treebanks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "Recently, there have been a number of papers, such as Schabes and Pereira[48], Brill [16], and Bod[12], citing work based on parsing using sentences tagged for part of speech."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "[10] [7], Kupiec [39], and Schabes and Pereira [48]), have applied the inside-outside algorithm, a special case of the expectation-maximization algorithm for CFGs, to probabilistic context-free grammar (P-CFG) estimation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 222
                            }
                        ],
                        "text": "I also thank him for breaking the barriers imposed by my undergraduate status and allowing me the opportunity to meet and discuss my work with the leading researchers in statistical NLP, like Drs. Kenneth Church, Fernando Pereira, and Don Hindle at Bell Laboratories, Dr. Stuart Shieber at Harvard University and Dr. Fred Jelinek at\n4This work was supported by a grant awarded jointly to the IBM Language Modeling Group and the University of Pennsylvania Computer Science Department (ONR contract No."
                    },
                    "intents": []
                }
            ],
            "corpusId": 696805,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c0eab87d4855c42ae6395bf2e27eefe55003b4a",
            "isKey": true,
            "numCitedBy": 345,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information in a partially parsed corpus. Experiments on formal and natural language parsed corpora show that the new algorithm can achieve faster convergence and better modelling of hierarchical structure than the original one. In particular, over 90% of the constituents in the most likely analyses of a test set are compatible with test set constituents for a grammar trained on a corpus of 700 hand-parsed part-of-speech strings for ATIS sentences."
            },
            "slug": "Inside-Outside-Reestimation-From-Partially-Corpora-Pereira-Schabes",
            "title": {
                "fragments": [],
                "text": "Inside-Outside Reestimation From Partially Bracketed Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information in a partially parsed corpus to achieve faster convergence and better modelling of hierarchical structure than the original one."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2687013"
                        ],
                        "name": "A. Derouault",
                        "slug": "A.-Derouault",
                        "structuredName": {
                            "firstName": "Anne-Marie",
                            "lastName": "Derouault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Derouault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686820"
                        ],
                        "name": "B. M\u00e9rialdo",
                        "slug": "B.-M\u00e9rialdo",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "M\u00e9rialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. M\u00e9rialdo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 181
                            }
                        ],
                        "text": "Actually, HMM tagging was suggested a few years earlier during a lecture by Mercer at MIT, which Church attended, and Merialdo published a more obscure paper on the subject in 1986 [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61950027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "943362e27fdfff2628765f001777bf05fb0b8f95",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study the combination of an information theoretic tool (Markov modeling of natural language [3]) with probabilistic grammatical analysis. Continuous Speech Recognition for natural language raises a lot of difficulties, both for the acoustic processing and the linguistic decoding. Our work specifically concerns the linguistic decoding techniques for a very large (140,000 entries) French dictionary, and a oral open discourse. So the task is to transcribe a continuous string of pseudo-phonemes into written text. This string would be ideally the output of a perfect acoustic processor. We present a grammar designed for automatic transcription and compute probabilities for the rules. We compare its results with those obtained earlier with Markov modeling. We show that it is possible to combine the two approaches and get better results than each model separately."
            },
            "slug": "Probabilistic-grammar-for-phonetic-to-French-Derouault-M\u00e9rialdo",
            "title": {
                "fragments": [],
                "text": "Probabilistic grammar for phonetic to French transcription"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that it is possible to combine the two approaches and get better results than each model separately, and a grammar designed for automatic transcription is presented and probabilities for the rules are computed."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '85. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143757098"
                        ],
                        "name": "C. Weir",
                        "slug": "C.-Weir",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Weir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Weir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7358857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe3788f2de079b08a6b2b130bba17ec0429c7f04",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes Picky, a probabilistic agenda-based chart parsing algorithm which uses a technique called probabilistic prediction to predict which grammar rules are likely to lead to an acceptable parse of the input. Using a suboptimal search method, Picky significantly reduces the number of edges produced by CKY-like chart parsing algorithms, while maintaining the robustness of pure bottom-up parsers and the accuracy of existing probabilistic parsers. Experiments using Picky demonstrate how probabilistic modelling can impact upon the efficiency, robustness and accuracy of a parser."
            },
            "slug": "Efficiency,-Robustness-and-Accuracy-in-Picky-Chart-Magerman-Weir",
            "title": {
                "fragments": [],
                "text": "Efficiency, Robustness and Accuracy in Picky Chart Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Plymouth's Picky significantly reduces the number of edges produced by CKY-like chart parsing algorithms, while maintaining the robustness of pure bottom-up parsers and the accuracy of existing probabilistic parsers."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691192"
                        ],
                        "name": "V. Pratt",
                        "slug": "V.-Pratt",
                        "structuredName": {
                            "firstName": "Vaughan",
                            "lastName": "Pratt",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Pratt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Pratt[51]); but using very large corpora and the inside-outside algorithm, they can now be trained automatically, instead of assigning the parameters by hand."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 469505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e6d51067728ac6e6ed1de014dd1ef236eaea69",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A programming language fo r natural language processing programs is descr ibed. Examples of the output of programs w r i t t e n using it are g iven. The reasons fo r various design decisions are discussed. An actual session wi th the system is presented, in which a small fragment of an Engl ish-to-French t r ans la to r is devel oped. Some of the l i m i t a t i o n s of the system are d i s cussed, along wi th plans fo r fu r the r development."
            },
            "slug": "A-Linguistics-Oriented-Programming-Language-Pratt",
            "title": {
                "fragments": [],
                "text": "A Linguistics Oriented Programming Language"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A programming language fo r natural language processing programs is presented, in which a small fragment of an Engl ish-to-French t r ans la to r is devel oped."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35116937"
                        ],
                        "name": "R. Moll",
                        "slug": "R.-Moll",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Moll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Moll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795076"
                        ],
                        "name": "M. Arbib",
                        "slug": "M.-Arbib",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Arbib",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Arbib"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2712330"
                        ],
                        "name": "A. Kfoury",
                        "slug": "A.-Kfoury",
                        "structuredName": {
                            "firstName": "Assaf",
                            "lastName": "Kfoury",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kfoury"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29304912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d278c42ab24e014da4f991944dc55c11484e0d3a",
            "isKey": false,
            "numCitedBy": 527,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This voume combines An Introduction to Formal Language Theory with issues in computational linguistics. The book begins with standard formal language material, including a discussion of regular, context-free, context sensitive, and arbitrary phrase stucture languages. This is followed by a discussion of the corresponding families of automata: finite-state, push-down, linear bounded and Turing machines. Important topics introduced along the way include closure properties, normal forms, nondeterminism, basic parsing algorithms, and the theory of computability and undecidability. Special emphasis is given to the role of algebraic techniques in formal language theory through a chapter devoted to the fixed point approach to the analysis of context-free languages. Advanced topics in parsing are also emphasized in an unusually clear and precise presentation. A unique feature of the book is the two chapter introduction to the formal theory of natural languages. Alternative schemes for representing natural language are discussed, in particular ATNs and GPSG. This book is part of the AKM Series in Theoretical Computer Science. \"A Basis for Theoretical Computer Science\", also in the series, should provide the necessary background for this volume intended to serve as a text for upper undergraduate and graduate level students."
            },
            "slug": "An-Introduction-to-Formal-Language-Theory-Moll-Arbib",
            "title": {
                "fragments": [],
                "text": "An Introduction to Formal Language Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This volume intended to serve as a text for upper undergraduate and graduate level students and special emphasis is given to the role of algebraic techniques in formal language theory through a chapter devoted to the fixed point approach to the analysis of context-free languages."
            },
            "venue": {
                "fragments": [],
                "text": "Texts and Monographs in Computer Science"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879397"
                        ],
                        "name": "D. Warren",
                        "slug": "D.-Warren",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Warren",
                            "middleNames": [
                                "H.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Warren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 261,
                                "start": 258
                            }
                        ],
                        "text": "Perhaps in response to the ad-hoc nature of ATNs, in the early 1980s a number of grammatical formalisms appeared which attempted to account for the power of the functional augmentations of ATNs in a more formal theoretical framework: DefiniteClause Grammar (DCG) [47], Functional Unification Grammar (FUG) [36], LexicalFunctional Grammar (LFG) [35], Generalized Phrase Structure Grammar (GPSG) [25], and others."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 262
                            }
                        ],
                        "text": "Perhaps in response to the ad-hoc nature of ATNs, in the early 1980s a number of grammatical formalisms appeared which attempted to account for the power of the functional augmentations of ATNs in a more formal theoretical framework: De niteClause Grammar (DCG) [49], Functional Uni cation Grammar (FUG) [38], LexicalFunctional Grammar (LFG) [37], Generalized Phrase Structure Grammar (GPSG) [25], and others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2133116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbc04a1951003ba164303b2898fb7f3c6b4e9083",
            "isKey": false,
            "numCitedBy": 1034,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Definite-Clause-Grammars-for-Language-Analysis-A-of-Pereira-Warren",
            "title": {
                "fragments": [],
                "text": "Definite Clause Grammars for Language Analysis - A Survey of the Formalism and a Comparison with Augmented Transition Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2215426"
                        ],
                        "name": "J. Weizenbaum",
                        "slug": "J.-Weizenbaum",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Weizenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weizenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Weizenbaum's ELIZA[65] is a famous example of this \\technology,\" reviled in some corners of the community for falsely encouraging the already widely-held belief that natural language processing would be solved within a decade."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 12
                            }
                        ],
                        "text": "Weizenbaum\u2019s ELIZA[63] is a famous example of this \u201ctechnology,\u201d reviled in some corners of the community for falsely encouraging the already widely-held belief that natural language processing would be solved within a decade."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1896290,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "a798bca71c8833e49ad9bac22da4b5c3503f1e6a",
            "isKey": false,
            "numCitedBy": 1749,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "ELIZA is a program operating within the MAC time-sharing system at MIT which makes certain kinds of natural language conversation between man and computer possible. Input sentences are analyzed on the basis of decomposition rules which are triggered by key words appearing in the input text. Responses are generated by reassembly rules associated with selected decomposition rules. The fundamental technical problems with which ELIZA is concerned are: (1) the identification of key words, (2) the discovery of minimal context, (3) the choice of appropriate transformations, (4) generation of responses in the absence of key words, and (5) the provision of an editing capability for ELIZA \"scripts\". A discussion of some psychological issues relevant to the ELIZA approach as well as of future developments concludes the paper."
            },
            "slug": "ELIZA\u2014a-computer-program-for-the-study-of-natural-Weizenbaum",
            "title": {
                "fragments": [],
                "text": "ELIZA\u2014a computer program for the study of natural language communication between man and machine"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "A discussion of some psychological issues relevant to the ELIZA approach as well as of future developments concludes the paper."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21169546"
                        ],
                        "name": "Donald Hindle",
                        "slug": "Donald-Hindle",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hindle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Hindle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416786"
                        ],
                        "name": "Mats Rooth",
                        "slug": "Mats-Rooth",
                        "structuredName": {
                            "firstName": "Mats",
                            "lastName": "Rooth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mats Rooth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5410054,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "bdaf232c561f1f50e88b1d24097e214890b37e8b",
            "isKey": false,
            "numCitedBy": 638,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose that many ambiguous prepositional phrase attachments can be resolved on the basis of the relative strength of association of the preposition with verbal and nominal heads, estimated on the basis of distribution in an automatically parsed corpus. This suggests that a distributional approach can provide an approximate solution to parsing problems that, in the worst case, call for complex reasoning."
            },
            "slug": "Structural-Ambiguity-and-Lexical-Relations-Hindle-Rooth",
            "title": {
                "fragments": [],
                "text": "Structural Ambiguity and Lexical Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is proposed that many ambiguous prepositional phrase attachments can be resolved on the based of the relative strength of association of the preposition with verbal and nominal heads, estimated on the basis of distribution in an automatically parsed corpus."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3187096"
                        ],
                        "name": "Jerry R. Hobbs",
                        "slug": "Jerry-R.-Hobbs",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Hobbs",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jerry R. Hobbs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "SRI's TACITUS system [34] is another descendant of the Linguistic String Project."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7585174,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76099fb492f2a489628e67d4108842616aebd226",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "TACITUS is a system for interpreting natural language texts that has been under development since 1985. It has a preprocessor and postprocessor currently tailored to the MUC-3 application. It performs a syntactic analysis of the sentences in the text, using a fairly complete grammar of English, producing a logical form in first-order predicate calculus. Pragmatics problems are solved by abductive inference in a pragmatics, or interpretation, component."
            },
            "slug": "SRI-International:-description-of-the-TACITUS-as-Hobbs",
            "title": {
                "fragments": [],
                "text": "SRI International: description of the TACITUS system as used for MUC-3"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "TACITUS performs a syntactic analysis of the sentences in the text, using a fairly complete grammar of English, producing a logical form in first-order predicate calculus."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725500"
                        ],
                        "name": "Yves Schabes",
                        "slug": "Yves-Schabes",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Schabes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yves Schabes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718670"
                        ],
                        "name": "R. Waters",
                        "slug": "R.-Waters",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Waters",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Waters"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "None of these parsing techniques considers lexical information in its models, with the exception of probabilistic lexicalized tree-adjoining grammar (Schabes and Waters[55]), which has yet to be implemented and tested on a large scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60662416,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "2e9eb04e88413c6371ee5b4066ee23d1f6575337",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic lexicalized context-free grammar (SLCFG) is an attractive compromise between the parsing efficiency of stochastic context-free grammar (SCFG) and the lexical sensitivity of stochastic lexicalized tree-adjoining grammar (SLTAG) . SLCFG is a restricted form of SLTAG that can only generate context-free languages and can be parsed in cubic time. However, SLCFG retains the lexical sensitivity of SLTAG and is therefore a much better basis for capturing distributional information about words than SCFG."
            },
            "slug": "Stochastic-Lexicalized-Context-Free-Grammar-Schabes-Waters",
            "title": {
                "fragments": [],
                "text": "Stochastic Lexicalized Context-Free Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "SLCFG is a restricted form of SLTAG that can only generate context-free languages and can be parsed in cubic time, but retains the lexical sensitivity of SL TAG and is therefore a much better basis for capturing distributional information about words than SCFG."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32326549"
                        ],
                        "name": "J. Kupiec",
                        "slug": "J.-Kupiec",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Kupiec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kupiec"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "The state-of-the-art in statistical parsing technology includes P-CFGs trained using the Inside-Outside algorithm (Schabes and Pereira [48], Kupiec [39], and Black, Garside, and Leech[7], parsers which generate unlabeled bracketing using correct tag sequences as input (Brill [16], Schabes and Pereira [48], and grammar induction strategies which attempt to acquire grammars by extracting context-free productions from treebanks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "[10] [7], Kupiec [39], and Schabes and Pereira [48]), have applied the inside-outside algorithm, a special case of the expectation-maximization algorithm for CFGs, to probabilistic context-free grammar (P-CFG) estimation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Baker[4] and Kupiec [39]), or it can be trained in a constrained mode, maximizing the probability of the parse trees in a parsed corpus (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2197535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d11ac5f5b46f8936cd12854295b5bb95d2bfc7e4",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents a new algorithm for estimating the parameters of a hidden stochastic context-free grammar. In contrast to the Inside/Outside (I/O) algorithm it does not require the grammar to be expressed in Chomsky normal form, and thus can operate directly on more natural representations of a grammar. The algorithm uses a trellis-based structure as opposed to the binary branching tree structure used by the I/O algorithm. The form of the trellis is an extension of that used by the Forward/Backward algorithm, and as a result the algorithm reduces to the latter for components that can be modeled as finite-state networks. In the same way that a hidden Markov model (HMM) is a stochastic analogue of a finite-state network, the representation used by the new algorithm is a stochastic analogue of a recursive transition network, in which a state may be simple or itself contain an underlying structure."
            },
            "slug": "A-Trellis-Based-Algorithm-For-Estimating-The-Of-Kupiec",
            "title": {
                "fragments": [],
                "text": "A Trellis-Based Algorithm For Estimating The Parameters Of Hidden Stochastic Context-Free Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new algorithm for estimating the parameters of a hidden stochastic context-free grammar that does not require the grammar to be expressed in Chomsky normal form, and thus can operate directly on more natural representations of a grammar."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692491"
                        ],
                        "name": "S. Shieber",
                        "slug": "S.-Shieber",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Shieber",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shieber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 279
                            }
                        ],
                        "text": "I also thank him for breaking the barriers imposed by my undergraduate status and allowing me the opportunity to meet and discuss my work with the leading researchers in statistical NLP, like Drs. Kenneth Church, Fernando Pereira, and Don Hindle at Bell Laboratories, Dr. Stuart Shieber at Harvard University and Dr. Fred Jelinek at\n4This work was supported by a grant awarded jointly to the IBM Language Modeling Group and the University of Pennsylvania Computer Science Department (ONR contract No."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "Excellent descriptions of these theories can be found in Sells [58] and Shieber[62]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 222273301,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "d65f4afadac11cd2ec6f0b14f244060c387926ce",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "This book surveys the important concept of unification as it relates to linguistic theory and, in particular, to Functional Unification Grammar, Definite-Clause Grammars, Lexical-Function Grammar, Generalized Phrase Struture Grammar, and Head-Driven Phrase Structure Grammar. The notes include careful and correct definitions, as well as well-chosen examples of actual grammars, and a discussion of the relationships of computational systems and linguistic theories which use ideas from unification."
            },
            "slug": "An-introduction-to-unification-based-approaches-to-Shieber",
            "title": {
                "fragments": [],
                "text": "An introduction to unification-based approaches to grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This book surveys the important concept of unification as it relates to linguistic theory and, in particular, to Functional Unification Grammar, Definite-Clause Grammars, Lexical- functions, and Generalized Phrase Struture Grammar."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3853032"
                        ],
                        "name": "J. Lai",
                        "slug": "J.-Lai",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Lai",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10986188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3de5d40b60742e3dfa86b19e7f660962298492af",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics."
            },
            "slug": "Class-Based-n-gram-Models-of-Natural-Language-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "Class-Based n-gram Models of Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work addresses the problem of predicting a word from previous words in a sample of text and discusses n-gram models based on classes of words, finding that these models are able to extract classes that have the flavor of either syntactically based groupings or semanticallybased groupings, depending on the nature of the underlying statistics."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48603437"
                        ],
                        "name": "A. Newell",
                        "slug": "A.-Newell",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Newell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Newell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "The most extreme example of this is the HARPY system [45], developed at"
                    },
                    "intents": []
                }
            ],
            "corpusId": 46547850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d453e0a1022719f7a52155d0f71761ac756d0047",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Harpy is a speech understanding system that attained (in 1976) a set of highly demanding specifications laid down in 1971 for the recognition of continuous speech (902 accuracy, 1000 words, several speakers, but restricted syntax and semantics). Harpy is an achievement in artificial intelligence, without regard to psychology. Its success, however, makes it worthwhile to ask for its implications for the psychology of speech perception. This paper explores that issue by performing a sufficiency analysis, ie, by constructing a psychological model of speech perception that is faithful to Harpy and then inquiring whether it is acceptable given what we know about human processing capabilities. The strategy for accomplishing this is to select a specific model of basic human cognitive architecture, a production system architecture called HPSA77 that is under investigation independently as a model of cognition; and then to map Harpy into this structure in a way that maintains performance plausibility. The paper (1) presents the production system architecture; (2) presents Harpy; (3) performs the mapping; (4) detours into a consideration of intensity encoding in production systems to solve a problem in the mapping; (5) does the sufficiency analysis; (6) examines what the model says about some human speech phenomena; (7) attempts to state what has been achieved. It seems to the author that a viable and interesting theory of human speech perception has been generated by this exercise, though it has several major difficulties (as noted)."
            },
            "slug": "Harpy,-production-systems-and-human-cognition-Newell",
            "title": {
                "fragments": [],
                "text": "Harpy, production systems and human cognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A viable and interesting theory of human speech perception has been generated by constructing a psychological model of speech perception that is faithful to Harpy and asking whether it is acceptable given what the authors know about human processing capabilities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Schuetze [57] has developed a vector-based representation for language which aids in word sense disambiguation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62394326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "411943acef949712afe31007d4dd73f1888104c4",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The syntactic category of words is represented in a distributed manner by deriving part-of-speech representations from a text corpus by means of a large scale singular value decomposition. The representations are input to an artificial neural network, which is trained on two days of the New York Times News Service, attaining an accuracy of 92%-98% in tagging ambiguous lexical items. >"
            },
            "slug": "Distributed-syntactic-representations-with-an-to-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Distributed syntactic representations with an application to part-of-speech tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The syntactic category of words is represented in a distributed manner by deriving part-of-speech representations from a text corpus by means of a large scale singular value decomposition."
            },
            "venue": {
                "fragments": [],
                "text": "ICNN"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2214048"
                        ],
                        "name": "Damaris M. Ayuso",
                        "slug": "Damaris-M.-Ayuso",
                        "structuredName": {
                            "firstName": "Damaris",
                            "lastName": "Ayuso",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Damaris M. Ayuso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2248665"
                        ],
                        "name": "S. Boisen",
                        "slug": "S.-Boisen",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Boisen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Boisen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20866393"
                        ],
                        "name": "Heidi Fox",
                        "slug": "Heidi-Fox",
                        "structuredName": {
                            "firstName": "Heidi",
                            "lastName": "Fox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heidi Fox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319612"
                        ],
                        "name": "R. Ingria",
                        "slug": "R.-Ingria",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Ingria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingria"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "e-art translation system. Following this model, researchers at BBN are working on generating semantic analyses for sentences using statistical models. Their Probabilistic Language Understanding Model [62] de\ufb01nes a semantic language and attempts to translate the natural 18 CHAPTER2. RELATEDWORK language sentence into the semantic language. A system developed at CRIN, a Canadian natural language company"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18854833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf268f4635e172bd619ed841de97a6ae1fd49d38",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper first briefly describes the architecture of PLUM, BBN's text Processing system, and then reports on some experiments evaluating the effectiveness of the design at the component level. Three features are unusual in PLUM's architecture: a domain-independent deterministic parser, processing of (the resulting) fragments at the semantic and discourse level, and probabilistic models."
            },
            "slug": "A-New-Approach-to-Text-Understanding-Weischedel-Ayuso",
            "title": {
                "fragments": [],
                "text": "A New Approach to Text Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The architecture of PLUM, BBN's text Processing system, is described, and some experiments evaluating the effectiveness of the design at the component level are reported on."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114531657"
                        ],
                        "name": "Noam Chomsky",
                        "slug": "Noam-Chomsky",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Chomsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam Chomsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "Chomsky's work in the late 1950s and early 1960s in transformational grammars and formal language theory [19] [20] provided much of the machinery for the next generation of natural language processing research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12867884,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "16c762445f11fa2020994918dc4f93e76264df17",
            "isKey": false,
            "numCitedBy": 14181,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Contents: Methodological preliminaries: Generative grammars as theories of linguistic competence; theory of performance; organization of a generative grammar; justification of grammars; formal and substantive grammars; descriptive and explanatory theories; evaluation procedures; linguistic theory and language learning; generative capacity and its linguistic relevance Categories and relations in syntactic theory: Scope of the base; aspects of deep structure; illustrative fragment of the base component; types of base rules Deep structures and grammatical transformations Residual problems: Boundaries of syntax and semantics; structure of the lexicon"
            },
            "slug": "\u0935\u093e\u0915\u094d\u092f\u0935\u093f\u0928\u094d\u092f\u093e\u0938-\u0915\u093e-\u0938\u0948\u0926\u094d\u0927\u093e\u0928\u094d\u0924\u093f\u0915-\u092a\u0915\u094d\u0937-=-Aspects-of-the-Chomsky",
            "title": {
                "fragments": [],
                "text": "Aspects of the Theory of Syntax"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Methodological preliminaries of generative grammars as theories of linguistic competence; theory of performance; organization of a generative grammar; justification of grammar; descriptive and explanatory theories; evaluation procedures; linguistic theory and language learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62608994,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2603113681739f0ec88452451363f9674507ae5b",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The stack decoder is an attractive algorithm for controlling the acoustic and language model matching in a continuous speech recognizer. It implements a best-first tree search of the language to find the best match to both the language model and the observed speech. This paper describes a method for performing the optimal A search which guarantees to find the most likely path (recognized sentence) while extending the minimum number of stack entries. A tree search, however, is exponential in the number of words. A second algorithm is presented which linearizes the search at the cost of approximating some of the path likelihoods."
            },
            "slug": "Algorithms-for-an-optimal-A-search-and-linearizing-Paul",
            "title": {
                "fragments": [],
                "text": "Algorithms for an optimal A search and linearizing the search in the stack decoder"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method for performing the optimal A search which guarantees to find the most likely path (recognized sentence) while extending the minimum number of stack entries is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35226330"
                        ],
                        "name": "B. Green",
                        "slug": "B.-Green",
                        "structuredName": {
                            "firstName": "Bert",
                            "lastName": "Green",
                            "middleNames": [
                                "F."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32223729"
                        ],
                        "name": "A. K. Wolf",
                        "slug": "A.-K.-Wolf",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Wolf",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. K. Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6370361"
                        ],
                        "name": "C. Chomsky",
                        "slug": "C.-Chomsky",
                        "structuredName": {
                            "firstName": "Carol",
                            "lastName": "Chomsky",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chomsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94536391"
                        ],
                        "name": "Kenneth Laughery",
                        "slug": "Kenneth-Laughery",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Laughery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Laughery"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5867164,
            "fieldsOfStudy": [
                "Computer Science",
                "Education"
            ],
            "id": "89d025804988944d6fa4e95f49bff011b33d1418",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "<u>Baseball</u> is a computer program that answers questions phrased in ordinary English about stored data. The program reads the question from punched cards. After the words and idioms are looked up in a dictionary, the phrase structure and other syntactic facts are determined for a content analysis, which lists attribute-value pairs specifying the information given and the information requested. The requested information is then extracted from the data matching the specifications, and any necessary processing is done. Finally, the answer is printed. The program's present context is baseball games; it answers such questions as \"Where did each team play on July 7?\""
            },
            "slug": "Baseball:-an-automatic-question-answerer-Green-Wolf",
            "title": {
                "fragments": [],
                "text": "Baseball: an automatic question-answerer"
            },
            "venue": {
                "fragments": [],
                "text": "IRE-AIEE-ACM '61 (Western)"
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710543"
                        ],
                        "name": "V. Zue",
                        "slug": "V.-Zue",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Zue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145898106"
                        ],
                        "name": "James R. Glass",
                        "slug": "James-R.-Glass",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Glass",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Glass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352703"
                        ],
                        "name": "David Goodine",
                        "slug": "David-Goodine",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Goodine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Goodine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796273"
                        ],
                        "name": "H. Leung",
                        "slug": "H.-Leung",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Leung",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49551529"
                        ],
                        "name": "M. S. Phillips",
                        "slug": "M.-S.-Phillips",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Phillips",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. S. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686491"
                        ],
                        "name": "J. Polifroni",
                        "slug": "J.-Polifroni",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Polifroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Polifroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745131"
                        ],
                        "name": "S. Seneff",
                        "slug": "S.-Seneff",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "Seneff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seneff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 207
                            }
                        ],
                        "text": "Similarly, the grammar-based systems with complete syntactic, semantic and pragmatic analysis designed for spoken language applications, such as SRI\u2019s Core Language Engine (CLE) [1] and MIT\u2019s VOYAGER system [67], have been dominated by newer finite-state template-based systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "In the original experiment, the Pearl parser was trained on 1,100 sentences from the Voyager direction-finding domain [67] and tested on 40 test sentences from the same domain."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3543547,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "d6d875f2e0fb17f4abd95447f293233ee455e480",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "As part of the DARPA Spoken Language System program, we recently initiated an effort in spoken language understanding. A spoken language system addresses applications in which speech is used for interactive problem solving between a person and a computer. In these applications, not only must the system convert the speech signal into text, it must also understand the linguistic structure of a sentence in order to generate the correct response. This paper describes our early experience with the development of the MIT VOYAGER spoken language system."
            },
            "slug": "The-VOYAGER-Speech-Understanding-System:-A-Progress-Zue-Glass",
            "title": {
                "fragments": [],
                "text": "The VOYAGER Speech Understanding System: A Progress Report"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "Early experience with the development of the MIT VOYAGER spoken language system is described, which addresses applications in which speech is used for interactive problem solving between a person and a computer."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144461837"
                        ],
                        "name": "C. Shannon",
                        "slug": "C.-Shannon",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Shannon",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Shannon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "Information theory, developed by Shannon[60] and Wiener[66], is concerned with the compression of information when transmitted through a channel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9101213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1e3f2d537e50e0d5263e4731ab6c7983acd6687",
            "isKey": false,
            "numCitedBy": 2530,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of estimating the entropy and redundancy of a language is described. This method exploits the knowledge of the language statistics possessed by those who speak the language, and depends on experimental results in prediction of the next letter when the preceding text is known. Results of experiments in prediction are given, and some properties of an ideal predictor are developed."
            },
            "slug": "Prediction-and-entropy-of-printed-English-Shannon",
            "title": {
                "fragments": [],
                "text": "Prediction and entropy of printed English"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A new method of estimating the entropy and redundancy of a language is described, which exploits the knowledge of the language statistics possessed by those who speak the language, and depends on experimental results in prediction of the next letter when the preceding text is known."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145148360"
                        ],
                        "name": "L. Hirschman",
                        "slug": "L.-Hirschman",
                        "structuredName": {
                            "firstName": "Lynette",
                            "lastName": "Hirschman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hirschman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "An example of biased data collection comes from the ARPA ATIS project [31]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13949323,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "a981d42948ff306f89e19fb4a646933f0ecefcfd",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a recently collected spoken language corpus for the ATIS (Air Travel Information System) domain. This data collection effort has been co-ordinated by MADCOW (Multi-site ATIS Data COllection Working group). We summarize the motivation for this effort, the goals, the implementation of a multi-site data collection paradigm, and the accomplishments of MADCOW in monitoring the collection and distribution of 12,000 utterances of spontaneous speech from five sites for use in a multi-site common evaluation of speech, natural language and spoken language."
            },
            "slug": "Multi-Site-Data-Collection-for-a-Spoken-Language-Hirschman",
            "title": {
                "fragments": [],
                "text": "Multi-Site Data Collection for a Spoken Language Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A recently collected spoken language corpus for the ATIS (Air Travel Information System) domain is described and the motivation for this effort, the goals, the implementation of a multi-site data collection paradigm, and the accomplishments of MADCOW are summarized."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227843"
                        ],
                        "name": "M. Meteer",
                        "slug": "M.-Meteer",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Meteer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meteer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "At BBN,Weischedel [44] explored the behavior of HMM tagging algorithms when trained on limited data, and reports experimental results using various models designed to account for weaknesses of the simple HMM trigram word-tag model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12951757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f89268038d043ab1bc3aff0034202ba46e7acd84",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We report here on our experiments with POST (Part of Speech Tagger) to address problems of ambiguity and of understanding unknown words. Part of speech tagging, per se, is a well understood problem. Our paper reports experiments in three important areas: handling unknown words, limiting the size of the training set, and returning a set of the most likely tags for each word rather than a single tag. We describe the algorithms that we used and the specific results of our experiments on Wall Street Journal articles and on MUC terrorist messages."
            },
            "slug": "Studies-in-Part-of-Speech-Labelling-Meteer-Schwartz",
            "title": {
                "fragments": [],
                "text": "Studies in Part of Speech Labelling"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper reports experiments in three important areas: handling unknown words, limiting the size of the training set, and returning a set of the most likely tags for each word rather than a single tag."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102981024"
                        ],
                        "name": "A. Poritz",
                        "slug": "A.-Poritz",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Poritz",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Poritz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "For proofs concerning this and other properties of the forwardbackward algorithm, see Poritz[50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62479678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6627d8efde3ed55e34ccee059eb6cdac99bb2fe",
            "isKey": false,
            "numCitedBy": 304,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov modeling is a probabilistic technique for the study of time series. Hidden Markov theory permits modeling with any of the classical probability distributions. The costs of implementation are linear in the length of data. Models can be nested to reflect hierarchical sources of knowledge. These and other desirable features have made hidden Markov methods increasingly attractive for problems in language, speech and signal processing. The basic ideas are introduced by elementary examples in the spirit of the Polya urn models. The main tool in hidden Markov modeling is the Baum-Welch (or forward-backward) algorithm for maximum likelihood estimation of the model parameters. This iterative algorithm is discussed both from an intuitive point of view as an exercise in the art of counting and from a formal point of view via the information-theoretic Q-function. Selected examples drawn from the literature illustrate how the Baum-Welch technique places a rich variety of computational models at the disposal of the researcher.<<ETX>>"
            },
            "slug": "Hidden-Markov-models:-a-guided-tour-Poritz",
            "title": {
                "fragments": [],
                "text": "Hidden Markov models: a guided tour"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The main tool in hidden Markov modeling is the Baum-Welch algorithm for maximum likelihood estimation of the model parameters, which is discussed both from an intuitive point of view as an exercise in the art of counting and from a formalpoint of view via the information-theoretic Q-function."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14789841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4775e2f0d27e8be4aae7b5b5c2560b96ce2eb58",
            "isKey": false,
            "numCitedBy": 1403,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition is formulated as a problem of maximum likelihood decoding. This formulation requires statistical models of the speech production process. In this paper, we describe a number of statistical models for use in speech recognition. We give special attention to determining the parameters for such models from sparse data. We also describe two decoding methods, one appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks. To illustrate the usefulness of the methods described, we review a number of decoding results that have been obtained with them."
            },
            "slug": "A-Maximum-Likelihood-Approach-to-Continuous-Speech-Bahl-Jelinek",
            "title": {
                "fragments": [],
                "text": "A Maximum Likelihood Approach to Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper describes a number of statistical models for use in speech recognition, with special attention to determining the parameters for such models from sparse data, and describes two decoding methods appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3530486"
                        ],
                        "name": "R. Darnell",
                        "slug": "R.-Darnell",
                        "structuredName": {
                            "firstName": "R\u00e9gna",
                            "lastName": "Darnell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Darnell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Automatic natural language processing research can be traced back to the early 1950s, to Weaver\u2019s early work on machine translation (MT) [61]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215102261,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "5839ad026ee43f3b72493c416dddb4203791714d",
            "isKey": false,
            "numCitedBy": 861,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "?well worth reproducing in English.?Edts., I. M. Gazette.] On the loss of the epithelium of the intestinal canal, consequent on the excessive secretion of fluid from its surface. We are all well acquainted with the fact, that in certain diseases the outer layers of the epithelial cells protecting the skin are thrown off in flakes ; and I believe that it is the same in Asiatic cholera as regards epithelial cells lining the surface of the jntestinal mucous membrane?a matter of greater pathological significance than that concerning the skin, because the intestinal epithelium is intended to guard more delicate and important structures than the cells that cover the cutis. The symptoms of cholera, however, are very much dependent on this desquamation of the epithelia?a fact which may be demonstrated by the aid of the microscope; but we are not to suppose that all parts of the intestinal canal are equally affected in cholera. The epithelium of the stomach suffers less than that of the intestines, and the upper part of the small intestines is not so deeply involved in the disease as the lower part of the ileum. In the duodenum, where the peristaltic action of the canal is not very strong, you often find the epithelial cells lining the mucous membrane ; the cells are loosened, but riot detached, because this part of the canal has less mechanical work to do than the lower portion of the gut. The valvulae conniventes (kerkring), which are large and closely approximated in the second part of the duodenum, protect by covering in the epithelial celh that lie between them, but on the surface of these folds wo shall observe the commencement of the desquamative process which is so marked in the ileum. We shall see with the naked eye that the epithelium, which should cover the valvulae conniventes, has disappeared in places, leaving small isolated patches of the denuded mucous membrane. In their early stages, these spots are distinguishable by their whiter colour, and by a soft velvet-like texture, which may be well demonstrated if a spot of this kind is isolates1, and fixed on a plate under the object glass of the microscope, little water being allowed to trickle over it. You may also in this way examine the villi, which are clearly denuded of epithelial cells in the patches of the valvulae conniventes above referred to. In some parts wo notice that a space evidently extends through the length of the villi, and externally the villi are covered"
            },
            "slug": "Translation-Darnell",
            "title": {
                "fragments": [],
                "text": "Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This chapter discusses the loss of the epithelium of the intestinal canal, consequent on the excessive secretion of fluid from its surface, and examines the villi, which are clearly denuded of epithelial cells in the patches of the valvulae conniventes above referred to."
            },
            "venue": {
                "fragments": [],
                "text": "The Indian medical gazette"
            },
            "year": 1873
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "Baker[4] and Kupiec [39]), or it can be trained in a constrained mode, maximizing the probability of the parse trees in a parsed corpus (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62138892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8cf661487d8708a3e9a74e9cc83ce290aa5355b8",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stochastic-modeling-for-automatic-speech-Baker",
            "title": {
                "fragments": [],
                "text": "Stochastic modeling for automatic speech understanding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15000287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d46cd5ab029f7b01956c1158859da0042842234",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Two algorithms are presented for accelerating the operation of a stack decoder. The first is a method for computing the true least upper bound so that an optimal admissible A* search can be performed. The second is a set of methods for linearizing the computation required by a stack decoder. The A* search has been implemented in a continuous speech recognizer simulator and has demonstrated a significant speedup. The linearizing algorithm has been partially implemented in the simulator and has also shown significant computational savings.<<ETX>>"
            },
            "slug": "Algorithms-for-an-Optimal-A*-Search-and-Linearizing-Paul",
            "title": {
                "fragments": [],
                "text": "Algorithms for an Optimal A* Search and Linearizing the Search in the Stack Decoder*"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "Two algorithms are presented for accelerating the operation of a stack decoder using a method for computing the true least upper bound so that an optimal admissible A* search can be performed."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103556459"
                        ],
                        "name": "C. J. Stone",
                        "slug": "C.-J.-Stone",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29458883,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8017699564136f93af21575810d557dba1ee6fc6",
            "isKey": false,
            "numCitedBy": 16307,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Background. Introduction to Tree Classification. Right Sized Trees and Honest Estimates. Splitting Rules. Strengthening and Interpreting. Medical Diagnosis and Prognosis. Mass Spectra Classification. Regression Trees. Bayes Rules and Partitions. Optimal Pruning. Construction of Trees from a Learning Sample. Consistency. Bibliography. Notation Index. Subject Index."
            },
            "slug": "Classification-and-Regression-Trees-Breiman-Friedman",
            "title": {
                "fragments": [],
                "text": "Classification and Regression Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This chapter discusses tree classification in the context of medicine, where right Sized Trees and Honest Estimates are considered and Bayes Rules and Partitions are used as guides to optimal pruning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144716964"
                        ],
                        "name": "J. Cocke",
                        "slug": "J.-Cocke",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cocke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cocke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3069902"
                        ],
                        "name": "P. Roossin",
                        "slug": "P.-Roossin",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Roossin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Roossin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "A signi cant application of statistical modeling technology is the Candide system [17], developed by the IBM Machine Translation group."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14386564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1066659ec1afee9dce586f6f49b7d44527827e1",
            "isKey": false,
            "numCitedBy": 1940,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a statistical approach to machine translation. We describe the application of our approach to translation from French to English and give preliminary results."
            },
            "slug": "A-Statistical-Approach-to-Machine-Translation-Brown-Cocke",
            "title": {
                "fragments": [],
                "text": "A Statistical Approach to Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The application of the statistical approach to translation from French to English and preliminary results are described and the results are given."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861837498"
                        ],
                        "name": "G. G. Stokes",
                        "slug": "G.-G.-Stokes",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Stokes",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. G. Stokes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 46
                            }
                        ],
                        "text": "[1]), or a combination of these methods (e.g. Black, Garside, and Leech [7])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Sharman, Jelinek and Mercer [61], Black, Garside, and Leech [10]), which assigns a probability to each rule in a context-free grammar and computes the probability of the parse tree by assuming that each grammar rule application is independent of all other rule applications in the sentence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[10] [7], Kupiec [39], and Schabes and Pereira [48]), have applied the inside-outside algorithm, a special case of the expectation-maximization algorithm for CFGs, to probabilistic context-free grammar (P-CFG) estimation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 221060727,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "90006064cafcb0a9ad8a30cffeb56efe7e14129b",
            "isKey": false,
            "numCitedBy": 672670,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "however (for it was the literal soul of the life of the Redeemer, John xv. io), is the peculiar token of fellowship with the Redeemer. That love to God (what is meant here is not God\u2019s love to men) is described in such a case as a perfect love (love that has been perfected), involves no difficulty, for the simple reason that the proposition is purely hypothetical. We must, of course, also take the &dquo;keeping&dquo; in all its stringency. John knows right well that the case supposed here ncver becomes full reality. &dquo; Hereb)\u2019,&dquo; i.e. from the actual realization of love to God. &dquo; TIli7i 7e)e are ill Hinz &dquo;"
            },
            "slug": "\"J.\"-Stokes",
            "title": {
                "fragments": [],
                "text": "\"J.\""
            },
            "venue": {
                "fragments": [],
                "text": "The New Yale Book of Quotations"
            },
            "year": 2021
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115282352"
                        ],
                        "name": "Joy A. Thomas",
                        "slug": "Joy-A.-Thomas",
                        "structuredName": {
                            "firstName": "Joy",
                            "lastName": "Thomas",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joy A. Thomas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "A more complete introduction to information theory can be found in Cover and Thomas[22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 190432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dbdb4209626fd92d2436a058663206216036e68",
            "isKey": false,
            "numCitedBy": 42795,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface to the Second Edition. Preface to the First Edition. Acknowledgments for the Second Edition. Acknowledgments for the First Edition. 1. Introduction and Preview. 1.1 Preview of the Book. 2. Entropy, Relative Entropy, and Mutual Information. 2.1 Entropy. 2.2 Joint Entropy and Conditional Entropy. 2.3 Relative Entropy and Mutual Information. 2.4 Relationship Between Entropy and Mutual Information. 2.5 Chain Rules for Entropy, Relative Entropy, and Mutual Information. 2.6 Jensen's Inequality and Its Consequences. 2.7 Log Sum Inequality and Its Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Inequality. Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Asymptotic Equipartition Property Theorem. 3.2 Consequences of the AEP: Data Compression. 3.3 High-Probability Sets and the Typical Set. Summary. Problems. Historical Notes. 4. Entropy Rates of a Stochastic Process. 4.1 Markov Chains. 4.2 Entropy Rate. 4.3 Example: Entropy Rate of a Random Walk on a Weighted Graph. 4.4 Second Law of Thermodynamics. 4.5 Functions of Markov Chains. Summary. Problems. Historical Notes. 5. Data Compression. 5.1 Examples of Codes. 5.2 Kraft Inequality. 5.3 Optimal Codes. 5.4 Bounds on the Optimal Code Length. 5.5 Kraft Inequality for Uniquely Decodable Codes. 5.6 Huffman Codes. 5.7 Some Comments on Huffman Codes. 5.8 Optimality of Huffman Codes. 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Optimality of the Shannon Code. 5.11 Generation of Discrete Distributions from Fair Coins. Summary. Problems. Historical Notes. 6. Gambling and Data Compression. 6.1 The Horse Race. 6.2 Gambling and Side Information. 6.3 Dependent Horse Races and Entropy Rate. 6.4 The Entropy of English. 6.5 Data Compression and Gambling. 6.6 Gambling Estimate of the Entropy of English. Summary. Problems. Historical Notes. 7. Channel Capacity. 7.1 Examples of Channel Capacity. 7.2 Symmetric Channels. 7.3 Properties of Channel Capacity. 7.4 Preview of the Channel Coding Theorem. 7.5 Definitions. 7.6 Jointly Typical Sequences. 7.7 Channel Coding Theorem. 7.8 Zero-Error Codes. 7.9 Fano's Inequality and the Converse to the Coding Theorem. 7.10 Equality in the Converse to the Channel Coding Theorem. 7.11 Hamming Codes. 7.12 Feedback Capacity. 7.13 Source-Channel Separation Theorem. Summary. Problems. Historical Notes. 8. Differential Entropy. 8.1 Definitions. 8.2 AEP for Continuous Random Variables. 8.3 Relation of Differential Entropy to Discrete Entropy. 8.4 Joint and Conditional Differential Entropy. 8.5 Relative Entropy and Mutual Information. 8.6 Properties of Differential Entropy, Relative Entropy, and Mutual Information. Summary. Problems. Historical Notes. 9. Gaussian Channel. 9.1 Gaussian Channel: Definitions. 9.2 Converse to the Coding Theorem for Gaussian Channels. 9.3 Bandlimited Channels. 9.4 Parallel Gaussian Channels. 9.5 Channels with Colored Gaussian Noise. 9.6 Gaussian Channels with Feedback. Summary. Problems. Historical Notes. 10. Rate Distortion Theory. 10.1 Quantization. 10.2 Definitions. 10.3 Calculation of the Rate Distortion Function. 10.4 Converse to the Rate Distortion Theorem. 10.5 Achievability of the Rate Distortion Function. 10.6 Strongly Typical Sequences and Rate Distortion. 10.7 Characterization of the Rate Distortion Function. 10.8 Computation of Channel Capacity and the Rate Distortion Function. Summary. Problems. Historical Notes. 11. Information Theory and Statistics. 11.1 Method of Types. 11.2 Law of Large Numbers. 11.3 Universal Source Coding. 11.4 Large Deviation Theory. 11.5 Examples of Sanov's Theorem. 11.6 Conditional Limit Theorem. 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff Information. 11.10 Fisher Information and the Cram-er-Rao Inequality. Summary. Problems. Historical Notes. 12. Maximum Entropy. 12.1 Maximum Entropy Distributions. 12.2 Examples. 12.3 Anomalous Maximum Entropy Problem. 12.4 Spectrum Estimation. 12.5 Entropy Rates of a Gaussian Process. 12.6 Burg's Maximum Entropy Theorem. Summary. Problems. Historical Notes. 13. Universal Source Coding. 13.1 Universal Codes and Channel Capacity. 13.2 Universal Coding for Binary Sequences. 13.3 Arithmetic Coding. 13.4 Lempel-Ziv Coding. 13.5 Optimality of Lempel-Ziv Algorithms. Compression. Summary. Problems. Historical Notes. 14. Kolmogorov Complexity. 14.1 Models of Computation. 14.2 Kolmogorov Complexity: Definitions and Examples. 14.3 Kolmogorov Complexity and Entropy. 14.4 Kolmogorov Complexity of Integers. 14.5 Algorithmically Random and Incompressible Sequences. 14.6 Universal Probability. 14.7 Kolmogorov complexity. 14.9 Universal Gambling. 14.10 Occam's Razor. 14.11 Kolmogorov Complexity and Universal Probability. 14.12 Kolmogorov Sufficient Statistic. 14.13 Minimum Description Length Principle. Summary. Problems. Historical Notes. 15. Network Information Theory. 15.1 Gaussian Multiple-User Channels. 15.2 Jointly Typical Sequences. 15.3 Multiple-Access Channel. 15.4 Encoding of Correlated Sources. 15.5 Duality Between Slepian-Wolf Encoding and Multiple-Access Channels. 15.6 Broadcast Channel. 15.7 Relay Channel. 15.8 Source Coding with Side Information. 15.9 Rate Distortion with Side Information. 15.10 General Multiterminal Networks. Summary. Problems. Historical Notes. 16. Information Theory and Portfolio Theory. 16.1 The Stock Market: Some Definitions. 16.2 Kuhn-Tucker Characterization of the Log-Optimal Portfolio. 16.3 Asymptotic Optimality of the Log-Optimal Portfolio. 16.4 Side Information and the Growth Rate. 16.5 Investment in Stationary Markets. 16.6 Competitive Optimality of the Log-Optimal Portfolio. 16.7 Universal Portfolios. 16.8 Shannon-McMillan-Breiman Theorem (General AEP). Summary. Problems. Historical Notes. 17. Inequalities in Information Theory. 17.1 Basic Inequalities of Information Theory. 17.2 Differential Entropy. 17.3 Bounds on Entropy and Relative Entropy. 17.4 Inequalities for Types. 17.5 Combinatorial Bounds on Entropy. 17.6 Entropy Rates of Subsets. 17.7 Entropy and Fisher Information. 17.8 Entropy Power Inequality and Brunn-Minkowski Inequality. 17.9 Inequalities for Determinants. 17.10 Inequalities for Ratios of Determinants. Summary. Problems. Historical Notes. Bibliography. List of Symbols. Index."
            },
            "slug": "Elements-of-Information-Theory-Cover-Thomas",
            "title": {
                "fragments": [],
                "text": "Elements of Information Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author examines the role of entropy, inequality, and randomness in the design of codes and the construction of codes in the rapidly changing environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62562997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae9443b39a5abfbf3cc9776173c1ae4f94732408",
            "isKey": false,
            "numCitedBy": 593,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a new sequential decoding algorithm is introduced that uses stack storage at the receiver. It is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp the rate below which the average number of decoding steps is bounded by a constant. Practical problems connected with implementing the stack algorithm are discussed and a scheme is described that facilitates satisfactory performance even with limited stack storage capacity. Preliminary simulation results estimating the decoding effort and the needed stack siazree presented."
            },
            "slug": "Fast-sequential-decoding-algorithm-using-a-stack-Jelinek",
            "title": {
                "fragments": [],
                "text": "Fast sequential decoding algorithm using a stack"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new sequential decoding algorithm is introduced that uses stack storage at the receiver that is much simpler to describe and analyze than the Fano algorithm, and is about six times faster than the latter at transmission rates equal to Rcomp."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34093039"
                        ],
                        "name": "A. Newell",
                        "slug": "A.-Newell",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Newell",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Newell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "In 1971, the Advanced Research Projects Agency (ARPA) of the Defense Department asked ve speech research groups to build demonstration systems to solve a simple speech recognition task [46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59594798,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "338b4a29b872fcd7b5d12f3de0652da84dd38478",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "This report provides an evaluation of the state of the art and a program for research towards the development of speech understanding systems. To assess the possibility of such systems four specific tasks were considered and evaluated. Problem areas are identified and discussed leading to the conclusions on the technical aspects of the study. A possible program for research and development is presented."
            },
            "slug": "Speech-understanding-systems-:-Final-report-of-a-Newell",
            "title": {
                "fragments": [],
                "text": "Speech understanding systems : Final report of a study group"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An evaluation of the state of the art and a program for research towards the development of speech understanding systems to assess the possibility of such systems four specific tasks were considered and evaluated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 197
                            }
                        ],
                        "text": "The FEATURE array is set to the value fTag, Tag, Tag, Tag, Tag, Tag, Tag, Tagg and the ACTIVE array is set to the value f0; 1; 2; 3; 4; 5; 6; 7g: Using DWC = 2; the tag feature for NODE[0] and NODE[1] are assigned."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 183
                            }
                        ],
                        "text": "This means that for all possible tags t, a new state is generated with the tag feature value of NODE[0] set to t, and another new state is generated with the tag feature value of NODE[1] set to t: Since there are 196 part-of-speech tags, a total of 392 new states are generated in this step."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "5, the NEWNODE[1] for these four states is completed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1]), or a combination of these methods (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "The state for which the NEWNODE[1] extend feature was assigned the value unary contains a constituent consisting of the word character."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "Consider the four states added in this step which had their NODE[1] extend feature value assigned."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "For the sake of the example, assume that the next state extended is the state which has the tag feature value for NODE[1] set to the correct tag, NN1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "tag feature value of NODE[0] and the extend feature value of NODE[1] are assigned."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 178
                            }
                        ],
                        "text": "Similarly, the grammar-based systems with complete syntactic, semantic and pragmatic analysis designed for spoken language applications, such as SRI's Core Language Engine (CLE) [1] and MIT's VOYAGER system [69], have been dominated by newer nite-state template-based systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 165
                            }
                        ],
                        "text": "The node feature value of the ith node of INITNODE is set to the ith word in the sentence, with the word each assigned to INITNODE[0], character assigned to INITNODE[1], etc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Interim report on the sri core language engine"
            },
            "venue": {
                "fragments": [],
                "text": "Interim report on the sri core language engine"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "[8], and Magerman and Weir[43], probabilistic parsers are much more accurate when their models incorporate lexical information from the context, and when the applications of the models are not assumed to be independent."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Recently, a number of parsing papers, including two of my own [42] [43], have reported results using test sets were randomly sampled from a corpus, using the remainder of the corpus as training material."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "This work was published in Magerman and Weir[43]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E ciency"
            },
            "venue": {
                "fragments": [],
                "text": "robustness, and accuracy in picky chart parsing. Proceedings of the Association for Computational Linguistics, 1992"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "Context-free grammar parsers, such as Lindsay's SAD-SAM[56], took advantage of Chomsky's formalization to improve upon the simpler single-state and nite-state models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 47
                            }
                        ],
                        "text": "Context-free grammar parsers, such as Lindsay\u2019s SAD-SAM[54], took advantage of Chomsky\u2019s formalization to improve upon the simpler single-state and finite-state models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 60
                            }
                        ],
                        "text": "In contrast to the decomposition of syntax and semantics in SAD-SAM, Halliday\u2019s"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sam a story understander"
            },
            "venue": {
                "fragments": [],
                "text": "Research Report"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145707626"
                        ],
                        "name": "N. Wiener",
                        "slug": "N.-Wiener",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Wiener",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Wiener"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60881246,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80e9826f5a4238251340b5bf8e81bed7337e7c12",
            "isKey": false,
            "numCitedBy": 3191,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Extrapolation,-Interpolation,-and-Smoothing-of-Time-Wiener",
            "title": {
                "fragments": [],
                "text": "Extrapolation, Interpolation, and Smoothing of Stationary Time Series"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2519145"
                        ],
                        "name": "P. Sells",
                        "slug": "P.-Sells",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sells",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sells"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Excellent descriptions of these theories can be found in Sells [58] and Shieber[62]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62640893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d765882ed720b90ae7e7d86cb5500d8b267a3961",
            "isKey": false,
            "numCitedBy": 275,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lectures-on-contemporary-syntactic-theories-Sells",
            "title": {
                "fragments": [],
                "text": "Lectures on contemporary syntactic theories"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60804212,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "539036ab9e8f038c8a948596e77cc0dfcfa91fb3",
            "isKey": false,
            "numCitedBy": 1785,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-inequality-and-associated-maximization-technique-Baum",
            "title": {
                "fragments": [],
                "text": "An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3356532"
                        ],
                        "name": "N. Sager",
                        "slug": "N.-Sager",
                        "structuredName": {
                            "firstName": "Naomi",
                            "lastName": "Sager",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sager"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Both of these systems are descendants of the Linguistic String Project (LSP) [54], an early e ort to develop grammar-based parsers for sublanguages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59892813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c4abc117b0617c131b9e383697dc81232ed6d85",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Natural-language-information-processing-Sager",
            "title": {
                "fragments": [],
                "text": "Natural language information processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145493610"
                        ],
                        "name": "M. Kay",
                        "slug": "M.-Kay",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Kay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kay"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 310,
                                "start": 306
                            }
                        ],
                        "text": "Perhaps in response to the ad-hoc nature of ATNs, in the early 1980s a number of grammatical formalisms appeared which attempted to account for the power of the functional augmentations of ATNs in a more formal theoretical framework: DefiniteClause Grammar (DCG) [47], Functional Unification Grammar (FUG) [36], LexicalFunctional Grammar (LFG) [35], Generalized Phrase Structure Grammar (GPSG) [25], and others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57536700,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "658acf2e40c6c3296174300754067f745927d8e3",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Parsing-in-functional-unification-grammar-Kay",
            "title": {
                "fragments": [],
                "text": "Parsing in functional unification grammar"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753394"
                        ],
                        "name": "D. Bobrow",
                        "slug": "D.-Bobrow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Bobrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bobrow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 67
                            }
                        ],
                        "text": "Systems such as Green\u2019s BASEBALL[26], Raphael\u2019s SIR[50], and Bobrow\u2019s STUDENT[11] search for simple patterns or regular expressions which indicate useful information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Systems such as Green's BASEBALL[26], Raphael's SIR[52], and Bobrow's STUDENT[11] search for simple patterns or regular expressions which indicate useful information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 56584838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fc77941297522cc420ce9292193dd04ed2ed1af",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Natural-Language-Input-for-a-Computer-Problem-Bobrow",
            "title": {
                "fragments": [],
                "text": "Natural Language Input for a Computer Problem Solving System"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69899740"
                        ],
                        "name": "K. Gehrkens",
                        "slug": "K.-Gehrkens",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Gehrkens",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Gehrkens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "[8], and Magerman and Weir[41], probabilistic parsers are much more accurate when their models incorporate lexical information from the context, and when the applications of the models are not assumed to be independent."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "This work was published in Magerman and Weir[41]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Recently, a number of parsing papers, including two of my own [40] [41], have reported results using test sets were randomly sampled from a corpus, using the remainder of the corpus as training material."
                    },
                    "intents": []
                }
            ],
            "corpusId": 221076642,
            "fieldsOfStudy": [],
            "id": "b8b8df9a9772f9ddaff92be60a89855776f97116",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Efficiency-Gehrkens",
            "title": {
                "fragments": [],
                "text": "Efficiency"
            },
            "venue": {
                "fragments": [],
                "text": "Industry, Innovation and Infrastructure"
            },
            "year": 2021
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[33]) weighting systems to accumulate disambiguation decisions throughout the processing of a sentence into a single score for each interpretation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The dialogic parser"
            },
            "venue": {
                "fragments": [],
                "text": "The dialogic parser"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Doctoral dissertation. University o f P ennsylvania"
            },
            "venue": {
                "fragments": [],
                "text": "Doctoral dissertation. University o f P ennsylvania"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "Systems such as Green\u2019s BASEBALL[26], Raphael\u2019s SIR[50], and Bobrow\u2019s STUDENT[11] search for simple patterns or regular expressions which indicate useful information."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and Laughery"
            },
            "venue": {
                "fragments": [],
                "text": "K. Baseball: An automatic question answerer. Computers and Thought, pages 207\u2013216"
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A.5 Perplexities for extension model from basic experiment"
            },
            "venue": {
                "fragments": [],
                "text": "A.5 Perplexities for extension model from basic experiment"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PROTEUS Project Memorandum No"
            },
            "venue": {
                "fragments": [],
                "text": "4-C. New York University, New York, New York"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "4: Perplexities for tag model after each iteration of smoothing basic connguration models 1.0, 1.9, 2.0, and 2"
            },
            "venue": {
                "fragments": [],
                "text": "4: Perplexities for tag model after each iteration of smoothing basic connguration models 1.0, 1.9, 2.0, and 2"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic acquisition of subcategorization frames from untagged free-text corpora"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "6: Perplexities for conjunction model after each iteration of smoothing basic connguration models 1.0, 1.9, 2.0, and 2"
            },
            "venue": {
                "fragments": [],
                "text": "6: Perplexities for conjunction model after each iteration of smoothing basic connguration models 1.0, 1.9, 2.0, and 2"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "P arsing in functional uniication grammar. Natural Language Parsing: Psychological, Computational and Theoretical Perspectives"
            },
            "venue": {
                "fragments": [],
                "text": "P arsing in functional uniication grammar. Natural Language Parsing: Psychological, Computational and Theoretical Perspectives"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A probabilistic parser for speech understanding systems"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the August 1989 International Workshop on Parsing Technologies,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "Chomsky\u2019s work in the late 1950s and early 1960s in transformational grammars and formal language theory [19] [20] provided much of the machinery for the next generation of natural language processing research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Syntactic Structures"
            },
            "venue": {
                "fragments": [],
                "text": "Mouton, The Hague"
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A10 Perplexities for conjunction model from experiments A -G. : : : : : : 129 APPENDIX A"
            },
            "venue": {
                "fragments": [],
                "text": "A10 Perplexities for conjunction model from experiments A -G. : : : : : : 129 APPENDIX A"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "B.1 Part-of-Speech T ag Vocabulary Here is the part-of-speech tag vocabulary, sorted by frequency of occurrence in the Lancaster Computer Manuals Treebank"
            },
            "venue": {
                "fragments": [],
                "text": "B.1 Part-of-Speech T ag Vocabulary Here is the part-of-speech tag vocabulary, sorted by frequency of occurrence in the Lancaster Computer Manuals Treebank"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A.6 Perplexities for conjunction model from basic experiment"
            },
            "venue": {
                "fragments": [],
                "text": "A.6 Perplexities for conjunction model from basic experiment"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A.7 Perplexities for label model from experiments A -G"
            },
            "venue": {
                "fragments": [],
                "text": "A.7 Perplexities for label model from experiments A -G"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classi cation and Regression Trees"
            },
            "venue": {
                "fragments": [],
                "text": "Wadsworth and Brooks, Paci c Grove, California"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A statistical approach t o m a c hine translation"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A.8 Perplexities for tag model from experiments A -G"
            },
            "venue": {
                "fragments": [],
                "text": "A.8 Perplexities for tag model from experiments A -G"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "7: Perplexities for label model after each iteration of smoothing models from experiments A -G"
            },
            "venue": {
                "fragments": [],
                "text": "7: Perplexities for label model after each iteration of smoothing models from experiments A -G"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "10: Perplexities for conjunction model after each iteration of smoothing models from experiment s A -G"
            },
            "venue": {
                "fragments": [],
                "text": "10: Perplexities for conjunction model after each iteration of smoothing models from experiment s A -G"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "Information theory, developed by Shannon[58] and Wiener[64], is concerned with the compression of information when transmitted through a channel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Extracpolation"
            },
            "venue": {
                "fragments": [],
                "text": "Interpolation, and Smoothing of Stationary Time Series. John WIley and Sons, New York, New York"
            },
            "year": 1949
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 304,
                                "start": 301
                            }
                        ],
                        "text": "Perhaps in response to the ad-hoc nature of ATNs, in the early 1980s a number of grammatical formalisms appeared which attempted to account for the power of the functional augmentations of ATNs in a more formal theoretical framework: DefiniteClause Grammar (DCG) [47], Functional Unification Grammar (FUG) [36], LexicalFunctional Grammar (LFG) [35], Generalized Phrase Structure Grammar (GPSG) [25], and others."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 308,
                                "start": 304
                            }
                        ],
                        "text": "Perhaps in response to the ad-hoc nature of ATNs, in the early 1980s a number of grammatical formalisms appeared which attempted to account for the power of the functional augmentations of ATNs in a more formal theoretical framework: De niteClause Grammar (DCG) [49], Functional Uni cation Grammar (FUG) [38], LexicalFunctional Grammar (LFG) [37], Generalized Phrase Structure Grammar (GPSG) [25], and others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parsing in functional uni cation grammar"
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Parsing: Psychological, Computational and Theoretical Perspectives"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classiication and Regression Trees"
            },
            "venue": {
                "fragments": [],
                "text": "Classiication and Regression Trees"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Extracpolation, Interpolation, and Smoothing of Stationary Time Series"
            },
            "venue": {
                "fragments": [],
                "text": "The Extracpolation, Interpolation, and Smoothing of Stationary Time Series"
            },
            "year": 1949
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PROTEUS Project Memorandum No. 4-C"
            },
            "venue": {
                "fragments": [],
                "text": "PROTEUS Project Memorandum No. 4-C"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Doctoral dissertation. ??? University, ???, ???"
            },
            "venue": {
                "fragments": [],
                "text": "Doctoral dissertation. ??? University, ???, ???"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "This revolution in speech technology can be traced back to a seminar given by researchers at IDA in October, 1980, on Hidden Markov Models (HMMs) [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hidden Markov Models for Speech"
            },
            "venue": {
                "fragments": [],
                "text": "IDA-CRD, Princeton, New Jersey,"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Appendix B SPATTER Vocabularies and Binary Encodings"
            },
            "venue": {
                "fragments": [],
                "text": "Appendix B SPATTER Vocabularies and Binary Encodings"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3: Perplexities for label model after each iteration of smoothing basic conguration models 1.0, 1.9, 2.0, and 2"
            },
            "venue": {
                "fragments": [],
                "text": "3: Perplexities for label model after each iteration of smoothing basic conguration models 1.0, 1.9, 2.0, and 2"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "9: Perplexities for extension model after each iteration of smoothing models from experiment s A -G"
            },
            "venue": {
                "fragments": [],
                "text": "9: Perplexities for extension model after each iteration of smoothing models from experiment s A -G"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "8: Perplexities for tag model after each iteration of smoothing models from experiments A -G"
            },
            "venue": {
                "fragments": [],
                "text": "8: Perplexities for tag model after each iteration of smoothing models from experiments A -G"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tina: A probabilistic parser for speech understanding systems"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the August 1989 International Workshop on Parsing Technologies,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "systemic grammar [28] proposed a formalism that encoded the functional relationships in a sentence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Language structure and language function"
            },
            "venue": {
                "fragments": [],
                "text": "New Horizons in Linguistics"
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hidden Markov Models for Speech. I D A-CRD"
            },
            "venue": {
                "fragments": [],
                "text": "Hidden Markov Models for Speech. I D A-CRD"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tina: A probabilistic parser for speech understanding systems"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the August 1989 International Workshop on Parsing Technologies"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A.9 Perplexities for extension model from experiment s A -G"
            },
            "venue": {
                "fragments": [],
                "text": "A.9 Perplexities for extension model from experiment s A -G"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fc right-to-left Fc Fa Fn right-to-left Fn S Ti N Fr right-to-left Fr S G left-to-right G N J right-to"
            },
            "venue": {
                "fragments": [],
                "text": "P II II21 II32 IO IW IF Si right-to-left Si S Nn"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2: Training entropies after each iteration of smoothing algorithm for models A -G. Smoothing entropies are based on 2,800 sentences. Last row contains test entropies, based on 100 sentences"
            },
            "venue": {
                "fragments": [],
                "text": "2: Training entropies after each iteration of smoothing algorithm for models A -G. Smoothing entropies are based on 2,800 sentences. Last row contains test entropies, based on 100 sentences"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 41,
            "methodology": 20,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 100,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/Natural-Language-Parsing-as-Statistical-Pattern-Magerman/9e78155b28b1f4db52a7c9076c89e81ac4b7d8ce?sort=total-citations"
}