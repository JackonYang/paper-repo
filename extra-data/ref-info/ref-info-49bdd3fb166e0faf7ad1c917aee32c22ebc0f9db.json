{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847264"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "\u2026applied this framework to other applications, e.g. speaker tracking in seminar videos (Wu et al., 2006) and conferee tracking in meeting videos (Wu and Nevatia, 2006c), and have achieved good scores in the VACE (http://www.ic-arda.org/InfoExploit/vace/) and CHIL\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 23
                            }
                        ],
                        "text": "In our previous paper (Wu and Nevatia, 2006a), we show results on a\nsubset, 23 sequences, only, as ground-truth for three sequences was not available at that time."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16134208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dee79dd2876a74e3f98e7537841aa0fb57dfead8",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Tracking of humans in videos is important for many applications. A major source of difficulty in performing this task is due to inter-human or scene occlusion. We present an approach based on representing humans as an assembly of four body parts and detection of the body parts in single frames which makes the method insensitive to camera motions. The responses of the body part detectors and a combined human detector provide the \"observations\" used for tracking. Trajectory initialization and termination are both fully automatic and rely on the confidences computed from the detection responses. An object is tracked by data association if its corresponding detection response can be found; otherwise it is tracked by a meanshift style tracker. Our method can track humans with both inter-object and scene occlusions. The system is evaluated on three sets of videos and compared with previous method."
            },
            "slug": "Tracking-of-Multiple,-Partially-Occluded-Humans-on-Wu-Nevatia",
            "title": {
                "fragments": [],
                "text": "Tracking of Multiple, Partially Occluded Humans based on Static Body Part Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents an approach based on representing humans as an assembly of four body parts and detection of the body parts in single frames which makes the method insensitive to camera motions."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847264"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "\u2026applied this framework to other applications, e.g. speaker tracking in seminar videos (Wu et al., 2006) and conferee tracking in meeting videos (Wu and Nevatia, 2006c), and have achieved good scores in the VACE (http://www.ic-arda.org/InfoExploit/vace/) and CHIL\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 23
                            }
                        ],
                        "text": "In our previous paper (Wu and Nevatia, 2006a), we show results on a\nsubset, 23 sequences, only, as ground-truth for three sequences was not available at that time."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 22
                            }
                        ],
                        "text": "In our previous paper (Wu and Nevatia, 2006a), we show results on a"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 206769463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de1ac0baea1f907388ff5fe9fa22f25f406e2ca6",
            "isKey": false,
            "numCitedBy": 881,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a method for human detection in crowded scene from static images. An individual human is modeled as an assembly of natural body parts. We introduce edgelet features, which are a new type of silhouette oriented features. Part detectors, based on these features, are learned by a boosting method. Responses of part detectors are combined to form a joint likelihood model that includes cases of multiple, possibly inter-occluded humans. The human detection problem is formulated as maximum a posteriori (MAP) estimation. We show results on a commonly used previous dataset as well as new data sets that could not be processed by earlier methods."
            },
            "slug": "Detection-of-multiple,-partially-occluded-humans-in-Wu-Nevatia",
            "title": {
                "fragments": [],
                "text": "Detection of multiple, partially occluded humans in a single image by Bayesian combination of edgelet part detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The human detection problem is formulated as maximum a posteriori (MAP) estimation, and edgelet features are introduced, which are a new type of silhouette oriented features that are learned by a boosting method."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 155
                            }
                        ],
                        "text": "Second, in Section 7.1.3, we evaluate our method with two public data sets, on which many previous papers report quantitative results (Mohan et al., 2001; Mikolajczyk et al., 2004; Dalal and Triggs, 2005); the samples in these\ntwo experiments are un-occluded ones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 54
                            }
                        ],
                        "text": "When training with only 300 positive samples, like in Mikolajczyk et al. (2004), our method suffered from over-fitting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 3
                            }
                        ],
                        "text": "In Mikolajczyk et al. (2004), Dalal and Triggs (2005) and Mohan et al. (2001), the MIT pedestrian set is used to evaluate the methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 30
                            }
                        ],
                        "text": "However, the legs detector of Mikolajczyk et al. (2004) is slightly inferior to their head-shoulder detector."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 31
                            }
                        ],
                        "text": "Note that (Mohan et al., 2001; Mikolajczyk et al., 2004; Dalal and Triggs, 2005) did experiments on 64 pixel wide samples, while our method requires samples to be 24 pixel wide only and still have comparable performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Mikolajczyk et al. (2004) trained their head-shoulder/legs detector with 250/300 positive and 4,000 negative samples for each boosting stage, and evaluation was done with 400 positive samples and 200 negative images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 56
                            }
                        ],
                        "text": "The previous such approaches, e.g. (Mohan et al., 2001; Mikolajczyk et al., 2004; Shashua et al., 2004), consider humans independently from each other and do not model inter-object occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 141
                            }
                        ],
                        "text": "If inter-object occlusion is present, the assumption of conditional independence between individual human appearances given the state, as in Mikolajczyk et al. (2004), is not valid and a more complex formulation is necessary."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 108
                            }
                        ],
                        "text": "The last observation is consistent with that reported in Mohan et al. (2001), but inconsistent with that in Mikolajczyk et al. (2004)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Mikolajczyk et al. (2004) divide human body into seven parts, face/head for frontal view, face/head for profile view, head-shoulder for frontal and rear view, head-shoulder for profile view, and legs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 41
                            }
                        ],
                        "text": "The methods of Shashua et al. (2004) and Mikolajczyk et al. (2004) both achieved better results than that of Mohan et al. (2001), but there is no direct comparison between (Shashua et al., 2004) and (Mikolajczyk et al., 2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 206
                            }
                        ],
                        "text": "\u2026spatially global features as in Gavrila (2000), Felzenszwalb (2001) and Leibe et al. (2005); others use spatially local features as in Papageorgiou et al. (1998), Mohan et al. (2001), Viola et al. (2003), Mikolajczyk et al. (2004), Wu et al. (2005), Leibe et al. (2005), and Dalal and Triggs (2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3870070,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9cc6155cd69023a736a7b8f8680bcd6232c840e",
            "isKey": true,
            "numCitedBy": 764,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel method for human detection in single images which can detect full bodies as well as close-up views in the presence of clutter and occlusion. Humans are modeled as flexible assemblies of parts, and robust part detection is the key to the approach. The parts are represented by co-occurrences of local features which captures the spatial layout of the partrsquos appearance. Feature selection and the part detectors are learnt from training images using AdaBoost. The detection algorithm is very efficient as (i) all part detectors use the same initial features, (ii) a coarse-to-fine cascade approach is used for part detection, (iii) a part assembly strategy reduces the number of spurious detections and the search space. The results outperform existing human detectors."
            },
            "slug": "Human-Detection-Based-on-a-Probabilistic-Assembly-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Human Detection Based on a Probabilistic Assembly of Robust Part Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A novel method for human detection in single images which can detect full bodies as well as close-up views in the presence of clutter and occlusion is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144626092"
                        ],
                        "name": "D. Snow",
                        "slug": "D.-Snow",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Snow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Snow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Viola et al. (2003) report that applied to human detection, this approach does not work very well using the static Haar features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 185
                            }
                        ],
                        "text": "\u2026spatially global features as in Gavrila (2000), Felzenszwalb (2001) and Leibe et al. (2005); others use spatially local features as in Papageorgiou et al. (1998), Mohan et al. (2001), Viola et al. (2003), Mikolajczyk et al. (2004), Wu et al. (2005), Leibe et al. (2005), and Dalal and Triggs (2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 47726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3702c79b8d118f8f363d685905bd285ab8e33979",
            "isKey": false,
            "numCitedBy": 1526,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a pedestrian detection system that integrates image intensity information with motion information. We use a detection style algorithm that scans a detector over two consecutive frames of a video sequence. The detector is trained (using AdaBoost) to take advantage of both motion and appearance information to detect a walking person. Past approaches have built detectors based on motion information or detectors based on appearance information, but ours is the first to combine both sources of information in a single detector. The implementation described runs at about 4 frames/second, detects pedestrians at very small scales (as small as 20 \u00d7 15 pixels), and has a very low false positive rate.Our approach builds on the detection work of Viola and Jones. Novel contributions of this paper include: (i) development of a representation of image motion which is extremely efficient, and (ii) implementation of a state of the art pedestrian detection system which operates on low resolution images under difficult conditions (such as rain and snow)."
            },
            "slug": "Detecting-Pedestrians-Using-Patterns-of-Motion-and-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Detecting Pedestrians Using Patterns of Motion and Appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This pedestrian detection system is the first to combine both sources of information in a single detector, and operates on low resolution images under difficult conditions (such as rain and snow)."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698422"
                        ],
                        "name": "J. MacCormick",
                        "slug": "J.-MacCormick",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "MacCormick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacCormick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 129
                            }
                        ],
                        "text": "Because the joint hypotheses space is usually of high dimension, an efficient optimization algorithm, such as a particle filter (Isard and MacCormick, 2001), MCMC (Zhao and Nevatia, 2004a; Smith et al., 2005) or EM (Peter et al., 2005) is used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 132
                            }
                        ],
                        "text": "Also, as the cues for tracking are strong, we do not utilize statistical sampling techniques as in some of the previous work, e.g. (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "( Isard and MacCormick, 2001;  Zhao and Nevatia, 2004a; Smith et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Some of the recent methods ( Isard and MacCormick, 2001;  Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005) try to fit multiple object hypotheses to explain the foreground or motion blobs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 166
                            }
                        ],
                        "text": "A trajectory is initialized when evidence from new observations can not be explained by the current hypotheses, as also in many previous methods (Davis et al., 2000; Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "( Isard and MacCormick, 2001;  Zhao and Nevatia, 2004a; Smith et al., 2005), to segment multiple humans from motion blobs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 28
                            }
                        ],
                        "text": "Some of the recent methods (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005) try to fit multiple object hypotheses to explain the foreground or motion blobs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 63
                            }
                        ],
                        "text": "A number of systems have been developed in recent years, e.g. (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005), to segment multiple humans from motion blobs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Because the joint hypotheses space is usually of high dimension, an efficient optimization algorithm, such as a particle filter ( Isard and MacCormick, 2001 ), MCMC (Zhao and Nevatia, 2004a; Smith et al., 2005) or EM (Peter et al., 2005) is used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5369395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b46da16dca784e66f600cfa05aa3d9d8bc1dee6d",
            "isKey": true,
            "numCitedBy": 729,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Blob trackers have become increasingly powerful in recent years largely due to the adoption of statistical appearance models which allow effective background subtraction and robust tracking of deforming foreground objects. It has been standard, however, to treat background and foreground modelling as separate processes-background subtraction is followed by blob detection and tracking-which prevents a principled computation of image likelihoods. This paper presents two theoretical advances which address this limitation and lead to a robust multiple-person tracking system suitable for single-camera real-time surveillance applications. The first innovation is a multi-blob likelihood function which assigns directly comparable likelihoods to hypotheses containing different numbers of objects. This likelihood function has a rigorous mathematical basis: it is adapted from the theory of Bayesian correlation, but uses the assumption of a static camera to create a more specific background model while retaining a unified approach to background and foreground modelling. Second we introduce a Bayesian filter for tracking multiple objects when the number of objects present is unknown and varies over time. We show how a particle filter can be used to perform joint inference on both the number of objects present and their configurations. Finally we demonstrate that our system runs comfortably in real time on a modest workstation when the number of blobs in the scene is small."
            },
            "slug": "BraMBLe:-a-Bayesian-multiple-blob-tracker-Isard-MacCormick",
            "title": {
                "fragments": [],
                "text": "BraMBLe: a Bayesian multiple-blob tracker"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A multi-blob likelihood function which assigns directly comparable likelihoods to hypotheses containing different numbers of objects and a Bayesian filter for tracking multiple objects when the number of objects present is unknown and varies over time are introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3309893"
                        ],
                        "name": "G. Brostow",
                        "slug": "G.-Brostow",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Brostow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Brostow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 22
                            }
                        ],
                        "text": "For example, recently Brostow and Cipolla (2006) proposed a method to detect independent motions in crowds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11636674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db2e05ccd1d6d106ee8816bf65c655f250f7206c",
            "isKey": false,
            "numCitedBy": 449,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "While crowds of various subjects may offer applicationspecific cues to detect individuals, we demonstrate that for the general case, motion itself contains more information than previously exploited. This paper describes an unsupervised data driven Bayesian clustering algorithm which has detection of individual entities as its primary goal. We track simple image features and probabilistically group them into clusters representing independently moving entities. The numbers of clusters and the grouping of constituent features are determined without supervised learning or any subject-specific model. The new approach is instead, that space-time proximity and trajectory coherence through image space are used as the only probabilistic criteria for clustering. An important contribution of this work is how these criteria are used to perform a one-shot data association without iterating through combinatorial hypotheses of cluster assignments. Our proposed general detection algorithm can be augmented with subject-specific filtering, but is shown to already be effective at detecting individual entities in crowds of people, insects, and animals. This paper and the associated video examine the implementation and experiments of our motion clustering framework."
            },
            "slug": "Unsupervised-Bayesian-Detection-of-Independent-in-Brostow-Cipolla",
            "title": {
                "fragments": [],
                "text": "Unsupervised Bayesian Detection of Independent Motion in Crowds"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An unsupervised data driven Bayesian clustering algorithm which has detection of individual entities as its primary goal and can be augmented with subject-specific filtering, but is shown to already be effective at detecting individual entities in crowds of people, insects, and animals."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46887580"
                        ],
                        "name": "Tao Zhao",
                        "slug": "Tao-Zhao",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 3
                            }
                        ],
                        "text": "In Zhao and Nevatia (2004a), a part-based representation is used for segmenting motion blobs by considering various articulations and their appearances but parts are not tracked explicitly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 164
                            }
                        ],
                        "text": "Because the joint hypotheses space is usually of high dimension, an efficient optimization algorithm, such as a particle filter (Isard and MacCormick, 2001), MCMC (Zhao and Nevatia, 2004a; Smith et al., 2005) or EM (Peter et al., 2005) is used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 59
                            }
                        ],
                        "text": "4 It can be seen that our method outperforms the method of Zhao and Nevatia (2004a) when the resolution is good."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 56
                            }
                        ],
                        "text": "In this experiment, we compared our method with that in Zhao and Nevatia (2004a)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 657,
                                "start": 59
                            }
                        ],
                        "text": "4 It can be seen that our method outperforms the method of Zhao and Nevatia (2004a) when the resolution is good. This comes from the low false alarm rate of the combined detector. Some sample frames and results are shown in Fig. 26. However, on the small humans, our shape based method does not work (the combined tracker only gets only 1 out of the 40 small humans tracked) while the motion based tracker gets 21 small humans mostly tracked. This great superiority of the motion based tracker at low resolution is because the motion based method does not rely on a discriminative model of humans. The comparison with the method in Zhao and Nevatia (2004a) is done on cases where both methods work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 0
                            }
                        ],
                        "text": "(Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005), to segment multiple humans from motion blobs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 81
                            }
                        ],
                        "text": "The only previous tracker for which we have an implementation in hand is that of Zhao and Nevatia (2004a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 160
                            }
                        ],
                        "text": "Also, as the cues for tracking are strong, we do not utilize statistical sampling techniques as in some of the previous work, e.g. (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 115
                            }
                        ],
                        "text": "Table 3 gives the comparative results at tracking level.4 It can be seen that our method outperforms the method of Zhao and Nevatia (2004a) when the resolution is good."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 163
                            }
                        ],
                        "text": "Because the joint hypotheses space is usually of high dimension, an efficient optimization algorithm, such as a particle filter (Isard and MacCormick, 2001), MCMC (Zhao and Nevatia, 2004a; Smith et al., 2005) or EM (Peter et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 140
                            }
                        ],
                        "text": "On the\nother hand, our method, which is based on frame by frame detection, can work with moving and/or zooming cameras, while the method of Zhao and Nevatia (2004a) can not."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 80
                            }
                        ],
                        "text": "We compare our results on the CAVIAR set with a previous system from our group (Zhao and Nevatia, 2004a)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 14
                            }
                        ],
                        "text": "The method of Zhao and Nevatia (2004a), which is based on 3D model and motion segmentation, is less view dependent and can work on lower resolution videos, while our method, which is based on 2D shape, requires higher resolution and does not work with large camera tilt angles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 81
                            }
                        ],
                        "text": "The only previous tracker for which we have an implementation in hand is that of Zhao and Nevatia (2004a). In this experiment, we compared our method with that in Zhao and Nevatia (2004a). This method is based on background subtraction, and requires a calibrated stationary camera."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 81
                            }
                        ],
                        "text": "The only previous tracker for which we have an implementation in hand is that of Zhao and Nevatia (2004a). In this experiment, we compared our method with that in Zhao and Nevatia (2004a)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 194
                            }
                        ],
                        "text": "A trajectory is initialized when evidence from new observations can not be explained by the current hypotheses, as also in many previous methods (Davis et al., 2000; Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 779,
                                "start": 59
                            }
                        ],
                        "text": "4 It can be seen that our method outperforms the method of Zhao and Nevatia (2004a) when the resolution is good. This comes from the low false alarm rate of the combined detector. Some sample frames and results are shown in Fig. 26. However, on the small humans, our shape based method does not work (the combined tracker only gets only 1 out of the 40 small humans tracked) while the motion based tracker gets 21 small humans mostly tracked. This great superiority of the motion based tracker at low resolution is because the motion based method does not rely on a discriminative model of humans. The comparison with the method in Zhao and Nevatia (2004a) is done on cases where both methods work. However, each has different limitations. The method of Zhao and Nevatia (2004a), which is based on 3D model and motion segmentation, is less view dependent and can work on lower resolution videos, while our method, which is based on 2D shape, requires higher resolution and does not work with large camera tilt angles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 34
                            }
                        ],
                        "text": "The comparison with the method in Zhao and Nevatia (2004a) is done on cases where both methods work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 49
                            }
                        ],
                        "text": "For tracking of human, some early methods, e.g. (Zhao and Nevatia, 2004b) track motion blobs and assume that each individual blob corresponds to one human."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 56
                            }
                        ],
                        "text": "Some of the recent methods (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005) try to fit multiple object hypotheses to explain the foreground or motion blobs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 91
                            }
                        ],
                        "text": "A number of systems have been developed in recent years, e.g. (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005), to segment multiple humans from motion blobs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3465596,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d8c8e1c7a1b0de2827ce00a2fb10a57eca629d98",
            "isKey": true,
            "numCitedBy": 365,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Tracking of humans in dynamic scenes has been an important topic of research. Most techniques, however, are limited to situations where humans appear isolated and occlusion is small. Typical methods rely on appearance models that must be acquired when the humans enter the scene and are not occluded. We present a method that can track humans in crowded environments, with significant and persistent occlusion by making use of human shape models in addition to camera models, the assumption that humans walk on a plane and acquired appearance models. Experimental results and a quantitative evaluation are included."
            },
            "slug": "Tracking-multiple-humans-in-crowded-environment-Zhao-Nevatia",
            "title": {
                "fragments": [],
                "text": "Tracking multiple humans in crowded environment"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A method that can track humans in crowded environments, with significant and persistent occlusion by making use of human shape models in addition to camera models, the assumption that humans walk on a plane and acquired appearance models is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50118130"
                        ],
                        "name": "Ying Wu",
                        "slug": "Ying-Wu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117900326"
                        ],
                        "name": "Ting Yu",
                        "slug": "Ting-Yu",
                        "structuredName": {
                            "firstName": "Ting",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ting Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144988571"
                        ],
                        "name": "G. Hua",
                        "slug": "G.-Hua",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Hua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 187
                            }
                        ],
                        "text": "\u2026et al. (1998) is known as the MIT pedestrian sample set which is available online1), Felzenszwalb\u2019s shape models (Felzenszwalb, 2001), Wu et al.\u2019s Markov Random Field based representation (Wu et al., 2005), and Gavrila et al.\u2019s edge templates (Gavrila and Philomin, 1999; Gavrila, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 44
                            }
                        ],
                        "text": "\u2019s Markov Random Field based representation (Wu et al., 2005), and Gavrila et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 233
                            }
                        ],
                        "text": "\u2026spatially global features as in Gavrila (2000), Felzenszwalb (2001) and Leibe et al. (2005); others use spatially local features as in Papageorgiou et al. (1998), Mohan et al. (2001), Viola et al. (2003), Mikolajczyk et al. (2004), Wu et al. (2005), Leibe et al. (2005), and Dalal and Triggs (2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 595021,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b76c07612157af7ecc6dc5b7780c9007667ff23",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new statistical model for detecting and tracking deformable objects such as pedestrians, where large shape variations induced by local shape deformation can not be well captured by global methods such as PCA. The proposed model employs a Boltzmann distribution to capture the prior of local deformation, and embeds it into a Markov network which can be learned from data. A mean field variational analysis of this model provides computationally efficient algorithms for computing the likelihood of image observations and facilitate fast model training. Based on that, effective detection and tracking algorithms for deformable objects are proposed and applied to pedestrian detection and tracking. The proposed method has several advantages. Firstly, it captures local deformation well and thus is robust to occlusions and clutter. In addition, it is computationally tractable. Moreover, it divides deformation into local deformation and global deformation, then conquers them by combining bottom-up and top-down methodologies. Extensive experiments demonstrate the effectiveness of the proposed model for deformable objects."
            },
            "slug": "A-statistical-field-model-for-pedestrian-detection-Wu-Yu",
            "title": {
                "fragments": [],
                "text": "A statistical field model for pedestrian detection"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A new statistical model for detecting and tracking deformable objects such as pedestrians, where large shape variations induced by local shape deformation can not be well captured by global methods such as PCA, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2124866301"
                        ],
                        "name": "A. Mohan",
                        "slug": "A.-Mohan",
                        "structuredName": {
                            "firstName": "Anuj",
                            "lastName": "Mohan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mohan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 135
                            }
                        ],
                        "text": "Second, in Section 7.1.3, we evaluate our method with two public data sets, on which many previous papers report quantitative results (Mohan et al., 2001; Mikolajczyk et al., 2004; Dalal and Triggs, 2005); the samples in these\ntwo experiments are un-occluded ones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Mohan et al. (2001) divide human body into four parts: head-shoulder, legs, left arm, and right arm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 58
                            }
                        ],
                        "text": "In Mikolajczyk et al. (2004), Dalal and Triggs (2005) and Mohan et al. (2001), the MIT pedestrian set is used to evaluate the methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Mohan et al. (2001) gave an explanation for the superiority of legs detector: the background of legs is usually road or grassland, which is relatively clutter-free compared to the background for head-shoulder."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 48
                            }
                        ],
                        "text": "Our experimental setup is comparable to that of Mohan et al. (2001), and Dalal and Triggs (2005)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 11
                            }
                        ],
                        "text": "Note that (Mohan et al., 2001; Mikolajczyk et al., 2004; Dalal and Triggs, 2005) did experiments on 64 pixel wide samples, while our method requires samples to be 24 pixel wide only and still have comparable performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 36
                            }
                        ],
                        "text": "The previous such approaches, e.g. (Mohan et al., 2001; Mikolajczyk et al., 2004; Shashua et al., 2004), consider humans independently from each other and do not model inter-object occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 57
                            }
                        ],
                        "text": "The last observation is consistent with that reported in Mohan et al. (2001), but inconsistent with that in Mikolajczyk et al. (2004)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 24
                            }
                        ],
                        "text": "The results reported in Mohan et al. (2001) show that the part based human model is much better than the holistic model in Papageorgiou et al. (1998) for detection task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 109
                            }
                        ],
                        "text": "The methods of Shashua et al. (2004) and Mikolajczyk et al. (2004) both achieved better results than that of Mohan et al. (2001), but there is no direct comparison between (Shashua et al., 2004) and (Mikolajczyk et al., 2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 164
                            }
                        ],
                        "text": "\u2026spatially global features as in Gavrila (2000), Felzenszwalb (2001) and Leibe et al. (2005); others use spatially local features as in Papageorgiou et al. (1998), Mohan et al. (2001), Viola et al. (2003), Mikolajczyk et al. (2004), Wu et al. (2005), Leibe et al. (2005), and Dalal and Triggs (2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Mohan et al. (2001) used 856/866 positive and 9,315/9,260 negative samples to train their head-\nshoulder/legs detectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2559322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "448bd4e124175ad358078a7b930ecad994c97812",
            "isKey": true,
            "numCitedBy": 1137,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general example-based framework for detecting objects in static images by components. The technique is demonstrated by developing a system that locates people in cluttered scenes. The system is structured with four distinct example-based detectors that are trained to separately find the four components of the human body: the head, legs, left arm, and right arm. After ensuring that these components are present in the proper geometric configuration, a second example-based classifier combines the results of the component detectors to classify a pattern as either a \"person\" or a \"nonperson.\" We call this type of hierarchical architecture, in which learning occurs at multiple stages, an adaptive combination of classifiers (ACC). We present results that show that this system performs significantly better than a similar full-body person detector. This suggests that the improvement in performance is due to the component-based approach and the ACC data classification architecture. The algorithm is also more robust than the full-body person detection method in that it is capable of locating partially occluded views of people and people whose body parts have little contrast with the background."
            },
            "slug": "Example-Based-Object-Detection-in-Images-by-Mohan-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Example-Based Object Detection in Images by Components"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results suggest that the improvement in performance is due to the component-based approach and the ACC data classification architecture, which is capable of locating partially occluded views of people and people whose body parts have little contrast with the background."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847264"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 48
                            }
                        ],
                        "text": ", 2006) and conferee tracking in meeting videos (Wu and Nevatia, 2006c), and have achieved good scores in the VACE (http://www."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "\u2026applied this framework to other applications, e.g. speaker tracking in seminar videos (Wu et al., 2006) and conferee tracking in meeting videos (Wu and Nevatia, 2006c), and have achieved good scores in the VACE (http://www.ic-arda.org/InfoExploit/vace/) and CHIL\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 23
                            }
                        ],
                        "text": "In our previous paper (Wu and Nevatia, 2006a), we show results on a\nsubset, 23 sequences, only, as ground-truth for three sequences was not available at that time."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 15945623,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "108080e42b74c5fbec3114a5215d62f65c9727e9",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Tracking conferees in meeting rooms is important for many applications. In this paper, we present an approach based on single-frame head-shoulder detection to track multiple humans in meetings. The responses of a multiple view head-shoulder detection system are taken as the observation of the human hypotheses. Trajectory initialization and termination are fully automatic and rely on the evidence collected from the detection responses. An object is tracked by data association if its corresponding detection response can be found; otherwise it is tracked by a meanshift style tracker. Finally the tracked hypotheses are verified by evidence collected from body part movements. The system is evaluated on two meeting video corpora."
            },
            "slug": "Tracking-of-Multiple-Humans-in-Meetings-Wu-Nevatia",
            "title": {
                "fragments": [],
                "text": "Tracking of Multiple Humans in Meetings"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper presents an approach based on single-frame head-shoulder detection to track multiple humans in meetings and proves the tracked hypotheses are verified by evidence collected from body part movements."
            },
            "venue": {
                "fragments": [],
                "text": "2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 53
                            }
                        ],
                        "text": "A nested structure differs from a cascade structure (Viola and Jones, 2001); in a nested structure, each layer is used as the first weak classifier of its succeeding layer so that the information of classification is inherited efficiently."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 170
                            }
                        ],
                        "text": "We learn tree structured multiview part detectors by a boosting approach proposed by Huang et al. (2004, 2005) which is an enhanced version of Viola and Jones\u2019 framework (Viola and Jones, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 83
                            }
                        ],
                        "text": "We use an enhanced version (Huang et al., 2004) of the original boosting method of Viola and Jones (2001) to learn the part detectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 43
                            }
                        ],
                        "text": "The object detection framework proposed by Viola and Jones (2001) has\nproved very efficient for the face detection problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 72
                            }
                        ],
                        "text": "(2004, 2005) which is an enhanced version of Viola and Jones\u2019 framework (Viola and Jones, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2715202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63",
            "isKey": true,
            "numCitedBy": 17887,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection."
            },
            "slug": "Rapid-object-detection-using-a-boosted-cascade-of-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Rapid object detection using a boosted cascade of simple features"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates and the introduction of a new image representation called the \"integral image\" which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116733876"
                        ],
                        "name": "Liang Zhao",
                        "slug": "Liang-Zhao",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Zhao and Davis (2005) proposed an iterative method for upper body segmentation to verify the detected human hypotheses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16930539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca4aa5c6bf7dd6c92fa748b0e3efb12cb413e31d",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a closely coupled object detection and segmentation algorithm for enhancing both processes in a cooperative and iterative manner. Figure-ground segmentation reduces the effect of background clutter on template matching; the matched template provides shape constraints on segmentation. More precisely, we estimate the probability of each pixel belonging to the foreground by a weighted sum of the estimates based on shape and color alone. The weight on the shape-based estimate is related to the probability that a familiar object is present and is updated dynamically so that we enforce shape constraints only where the object is present. Experiments on detecting people in images of cluttered scenes demonstrate that the proposed algorithm improves both segmentation and detection. More accurate object boundaries are extracted; higher object detection rates and lower false alarm rates are achieved than performing the two processes separately or sequentially."
            },
            "slug": "Closely-coupled-object-detection-and-segmentation-Zhao-Davis",
            "title": {
                "fragments": [],
                "text": "Closely coupled object detection and segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A closely coupled object detection and segmentation algorithm for enhancing both processes in a cooperative and iterative manner is proposed, which improves both segmentation and detection."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762260"
                        ],
                        "name": "V. Philomin",
                        "slug": "V.-Philomin",
                        "structuredName": {
                            "firstName": "Vasanth",
                            "lastName": "Philomin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Philomin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719541"
                        ],
                        "name": "R. Duraiswami",
                        "slug": "R.-Duraiswami",
                        "structuredName": {
                            "firstName": "Ramani",
                            "lastName": "Duraiswami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duraiswami"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 146
                            }
                        ],
                        "text": "A trajectory is initialized when evidence from new observations can not be explained by the current hypotheses, as also in many previous methods (Davis et al., 2000; Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A trajectory is initialized when evidence from new observations can not be explained by the current hypotheses, as also in many previous methods ( Davis et al., 2000;  Isard and Mac-Cormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 35
                            }
                        ],
                        "text": "Some discriminative methods, e.g. (Davis et al., 2000) build deformable silhouette models for pedestrians and track the models from edge features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "( Davis et al., 2000 ) build deformable silhouette models for pedestrians and track the models from edge features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2062711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "001f46241cd8347ac30936e54b55450c88004404",
            "isKey": true,
            "numCitedBy": 60,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Research at the Computer Vision Laboratory at the University of Maryland has focussed on developing algorithms and systems that can look at humans and recognize their activities in near real-time. Our earlier implementation while quite successful, was restricted to applications with a fixed camera. In this paper we present some recent work that removes this restriction. Such systems are required for machine vision from moving platforms such as robots, intelligent vehicles, and unattended large field of regard cameras with a small field of view. Our approach is based on the use of a deformable shape model for humans coupled with a novel variant of the condensation algorithm that uses quasi-random sampling for efficiency. This allows the use of simple motion models which results in algorithm robustness, enabling us to handle unknown camera/human motion with unrestricted camera viewing angles. We present the details of our human tracking algorithms and some examples from pedestrian tracking and automated surveillance."
            },
            "slug": "Tracking-humans-from-a-moving-platform-Davis-Philomin",
            "title": {
                "fragments": [],
                "text": "Tracking humans from a moving platform"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work uses a deformable shape model for humans coupled with a novel variant of the condensation algorithm that uses quasi-random sampling for efficiency to handle unknown camera/human motion with unrestricted camera viewing angles."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 15th International Conference on Pattern Recognition. ICPR-2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695351"
                        ],
                        "name": "J. Rittscher",
                        "slug": "J.-Rittscher",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Rittscher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rittscher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2163184"
                        ],
                        "name": "P. Tu",
                        "slug": "P.-Tu",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Tu",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694977"
                        ],
                        "name": "N. Krahnstoever",
                        "slug": "N.-Krahnstoever",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Krahnstoever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Krahnstoever"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 239
                            }
                        ],
                        "text": "A trajectory is initialized when evidence from new observations can not be explained by the current hypotheses, as also in many previous methods (Davis et al., 2000; Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 216
                            }
                        ],
                        "text": "Because the joint hypotheses space is usually of high dimension, an efficient optimization algorithm, such as a particle filter (Isard and MacCormick, 2001), MCMC (Zhao and Nevatia, 2004a; Smith et al., 2005) or EM (Peter et al., 2005) is used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 101
                            }
                        ],
                        "text": "Some of the recent methods (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005) try to fit multiple object hypotheses to explain the foreground or motion blobs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12087352,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2be18df5e6aafef751240c474a7ed9f624112a13",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The main focus of this work is the integration of feature grouping and model based segmentation into one consistent framework. The algorithm is based on partitioning a given set of image features using a likelihood function that is parameterized on the shape and location of potential individuals in the scene. Using a variant of the EM formulation, maximum likelihood estimates of both the model parameters and the grouping are obtained simultaneously. The resulting algorithm performs global optimization and generates accurate results even when decisions can not be made using local context alone. An important feature of the algorithm is that the number of people in the scene is not modeled explicitly. As a result no prior knowledge or assumed distributions are required. The approach is shown to be robust with respect to partial occlusion, shadows, clutter, and can operate over a large range of challenging view angles including those that are parallel to the ground plane. Comparisons with existing crowd segmentation systems are made and the utility of coupling crowd segmentation with a temporal tracking system is demonstrated."
            },
            "slug": "Simultaneous-estimation-of-segmentation-and-shape-Rittscher-Tu",
            "title": {
                "fragments": [],
                "text": "Simultaneous estimation of segmentation and shape"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "The main focus of this work is the integration of feature grouping and model based segmentation into one consistent framework based on partitioning a given set of image features using a likelihood function that is parameterized on the shape and location of potential individuals in the scene."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2649483"
                        ],
                        "name": "M. Lee",
                        "slug": "M.-Lee",
                        "structuredName": {
                            "firstName": "Mun",
                            "lastName": "Lee",
                            "middleNames": [
                                "Wai"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 145
                            }
                        ],
                        "text": "\u2026this framework to other applications, e.g. speaker tracking in seminar videos (Wu et al., 2006) and conferee tracking in meeting videos (Wu and Nevatia, 2006c), and have achieved good scores in the VACE (http://www.ic-arda.org/InfoExploit/vace/) and CHIL\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 30
                            }
                        ],
                        "text": "In our previous paper (Wu and Nevatia, 2006a), we show results on a\nsubset, 23 sequences, only, as ground-truth for three sequences was not available at that time."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 107
                            }
                        ],
                        "text": "Part tracking has been used to track the pose of humans (Sigal et al., 2004; Ramanan et al., 2005; Lee and Nevatia, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12548071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76b8e3d11b5e3bff846ae606cbcb4aab1bf096ed",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Tracking body poses of multiple persons in monocular video is a challenging problem due to the high dimensionality of the state space and issues such as inter-occlusion of the persons' bodies. We proposed a three-stage approach with a multi-level state representation that enables a hierarchical estimation of 3D body poses. At the first stage, humans are tracked as blobs. In the second stage, parts such as face, shoulders and limbs are estimated and estimates are combined by grid-based belief propagation to infer 2D joint positions. The derived belief maps are used as proposal functions in the third stage to infer the 3D pose using data-driven Markov chain Monte Carlo. Experimental results on realistic indoor video sequences show that the method is able to track multiple persons during complex movement such as turning movement with inter-occlusion."
            },
            "slug": "Human-Pose-Tracking-Using-Multi-level-Structured-Lee-Nevatia",
            "title": {
                "fragments": [],
                "text": "Human Pose Tracking Using Multi-level Structured Models"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Experimental results on realistic indoor video sequences show that the proposed three-stage approach with a multi-level state representation that enables a hierarchical estimation of 3D body poses is able to track multiple persons during complex movement such as turning movement with inter-occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117396721"
                        ],
                        "name": "Constantine Papgeorgiou",
                        "slug": "Constantine-Papgeorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papgeorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Constantine Papgeorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801089"
                        ],
                        "name": "T. Evgeniou",
                        "slug": "T.-Evgeniou",
                        "structuredName": {
                            "firstName": "Theodoros",
                            "lastName": "Evgeniou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Evgeniou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 148
                            }
                        ],
                        "text": "\u2026detection represent a human as an integral whole, e.g. Papageorgiou et al.\u2019s SVMs detectors (Papageorgiou et al., 1998) (the positive sample set in Papageorgiou et al. (1998) is known as the MIT pedestrian sample set which is available online1), Felzenszwalb\u2019s shape models (Felzenszwalb, 2001),\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 122
                            }
                        ],
                        "text": "Many methods for static human detection represent a human as an integral whole, e.g. Papageorgiou et al.\u2019s SVMs detectors (Papageorgiou et al., 1998) (the positive sample set in Papageorgiou et al. (1998) is known as the MIT pedestrian sample set which is available online1), Felzenszwalb\u2019s shape\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 18
                            }
                        ],
                        "text": "\u2019s SVMs detectors (Papageorgiou et al., 1998) (the positive sample set in Papageorgiou et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 81
                            }
                        ],
                        "text": "Among these samples, 924 frontal/rear view ones are from the MIT pedestrian set (Papageorgiou et al., 1998) and the rest are from the Internet."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 123
                            }
                        ],
                        "text": "The results reported in Mohan et al. (2001) show that the part based human model is much better than the holistic model in Papageorgiou et al. (1998) for detection task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 148
                            }
                        ],
                        "text": "\u2026methods use spatially global features as in Gavrila (2000), Felzenszwalb (2001) and Leibe et al. (2005); others use spatially local features as in Papageorgiou et al. (1998), Mohan et al. (2001), Viola et al. (2003), Mikolajczyk et al. (2004), Wu et al. (2005), Leibe et al. (2005), and Dalal and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15099216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "193c7d756e030af8fc0a331857554247d8c75519",
            "isKey": true,
            "numCitedBy": 213,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In the near future, we can expect on-board automotive vision systems that inform or alert the driver about pedestrians, track surrounding vehicles, and read street signs. Object detection is fundamental to the success of this type of next-generation vision system. In this paper, w e present a trainable object detection system that automatically learns to detect objects of a certain class in unconstrained scenes. We apply our system to the task of pedestrian detection. Unlike previous approaches to pedestrian detection that rely heavily on hand-crafted models and motion information, our system learns the pedestrian model from examples and uses no motion cues. The system can easily be extended to include motion information. We review our previous system, describe a new system that exhibits significantly better performance, provide a comparison between using different combinations of feature sets with classifiers of varying complexity, and describe improvements that increase the system\u2019s processing speed by two orders of magnitude."
            },
            "slug": "A-TRAINABLE-PEDESTRIAN-DETECTION-SYSTEM-Papgeorgiou-Evgeniou",
            "title": {
                "fragments": [],
                "text": "A TRAINABLE PEDESTRIAN DETECTION SYSTEM"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A trainable object detection system that automatically learns to detect objects of a certain class in unconstrained scenes and learns the pedestrian model from examples and uses no motion cues."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 3
                            }
                        ],
                        "text": "In Ramanan et al. (2005) a human track is started only when a side view walking pose human is detected, and no termination strategy is mentioned."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 77
                            }
                        ],
                        "text": "Part tracking has been used to track the pose of humans (Sigal et al., 2004; Ramanan et al., 2005; Lee and Nevatia, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5574410,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14eacd0e48a160bfc935cd4d419772f0110b1a0f",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop an algorithm for finding and kinematically tracking multiple people in long sequences. Our basic assumption is that people tend to take on certain canonical poses, even when performing unusual activities like throwing a baseball or figure skating. We build a person detector that quite accurately detects and localizes limbs of people in lateral walking poses. We use the estimated limbs from a detection to build a discriminative appearance model; we assume the features that discriminate a figure in one frame will discriminate the figure in other frames. We then use the models as limb detectors in a pictorial structure framework, detecting figures in unrestricted poses in both previous and successive frames. We have run our tracker on hundreds of thousands of frames, and present and apply a methodology for evaluating tracking on such a large scale. We test our tracker on real sequences including a feature-length film, an hour of footage from a public park, and various sports sequences. We find that we can quite accurately automatically find and track multiple people interacting with each other while performing fast and unusual motions."
            },
            "slug": "Strike-a-pose:-tracking-people-by-finding-stylized-Ramanan-Forsyth",
            "title": {
                "fragments": [],
                "text": "Strike a pose: tracking people by finding stylized poses"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A person detector that quite accurately detects and localizes limbs of people in lateral walking poses is built, and an algorithm for finding and kinematically tracking multiple people in long sequences is developed."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144398147"
                        ],
                        "name": "L. Sigal",
                        "slug": "L.-Sigal",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Sigal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sigal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32830733"
                        ],
                        "name": "S. Bhatia",
                        "slug": "S.-Bhatia",
                        "structuredName": {
                            "firstName": "Sidharth",
                            "lastName": "Bhatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bhatia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145920814"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 57
                            }
                        ],
                        "text": "Part tracking has been used to track the pose of humans (Sigal et al., 2004; Ramanan et al., 2005; Lee and Nevatia, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14806670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc39b61661bc57c8239cd2678a09248c8d98e88f",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We pose the problem of 3D human tracking as one of inference in a graphical model. Unlike traditional kinematic tree representations, our model of the body is a collection of loosely-connected limbs. Conditional probabilities relating the 3D pose of connected limbs are learned from motion-captured training data. Similarly, we learn probabilistic models for the temporal evolution of each limb (forward and backward in time). Human pose and motion estimation is then solved with non-parametric belief propagation using a variation of particle filtering that can be applied over a general loopy graph. The loose-limbed model and decentralized graph structure facilitate the use of low-level visual cues. We adopt simple limb and head detectors to provide \"bottom-up\" information that is incorporated into the inference process at every time-step; these detectors permit automatic initialization and aid recovery from transient tracking failures. We illustrate the method by automatically tracking a walking person in video imagery using four calibrated cameras. Our experimental apparatus includes a marker-based motion capture system aligned with the coordinate frame of the calibrated cameras with which we quantitatively evaluate the accuracy of our 3D person tracker."
            },
            "slug": "Tracking-loose-limbed-people-Sigal-Bhatia",
            "title": {
                "fragments": [],
                "text": "Tracking loose-limbed people"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The problem of 3D human tracking as one of inference in a graphical model that is a collection of loosely-connected limbs and non-parametric belief propagation using a variation of particle filtering that can be applied over a general loopy graph is posed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46887580"
                        ],
                        "name": "Tao Zhao",
                        "slug": "Tao-Zhao",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 3
                            }
                        ],
                        "text": "In Zhao and Nevatia (2004a), a part-based representation is used for segmenting motion blobs by considering various articulations and their appearances but parts are not tracked explicitly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 164
                            }
                        ],
                        "text": "Because the joint hypotheses space is usually of high dimension, an efficient optimization algorithm, such as a particle filter (Isard and MacCormick, 2001), MCMC (Zhao and Nevatia, 2004a; Smith et al., 2005) or EM (Peter et al., 2005) is used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 56
                            }
                        ],
                        "text": "In this experiment, we compared our method with that in Zhao and Nevatia (2004a)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 81
                            }
                        ],
                        "text": "The only previous tracker for which we have an implementation in hand is that of Zhao and Nevatia (2004a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 160
                            }
                        ],
                        "text": "Also, as the cues for tracking are strong, we do not utilize statistical sampling techniques as in some of the previous work, e.g. (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 115
                            }
                        ],
                        "text": "Table 3 gives the comparative results at tracking level.4 It can be seen that our method outperforms the method of Zhao and Nevatia (2004a) when the resolution is good."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 140
                            }
                        ],
                        "text": "On the\nother hand, our method, which is based on frame by frame detection, can work with moving and/or zooming cameras, while the method of Zhao and Nevatia (2004a) can not."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 80
                            }
                        ],
                        "text": "We compare our results on the CAVIAR set with a previous system from our group (Zhao and Nevatia, 2004a)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "(Zhao and Nevatia, 2004b) track motion blobs and assume that each individual blob corresponds to one human."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 14
                            }
                        ],
                        "text": "The method of Zhao and Nevatia (2004a), which is based on 3D model and motion segmentation, is less view dependent and can work on lower resolution videos, while our method, which is based on 2D shape, requires higher resolution and does not work with large camera tilt angles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 194
                            }
                        ],
                        "text": "A trajectory is initialized when evidence from new observations can not be explained by the current hypotheses, as also in many previous methods (Davis et al., 2000; Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 34
                            }
                        ],
                        "text": "The comparison with the method in Zhao and Nevatia (2004a) is done on cases where both methods work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 49
                            }
                        ],
                        "text": "For tracking of human, some early methods, e.g. (Zhao and Nevatia, 2004b) track motion blobs and assume that each individual blob corresponds to one human."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 56
                            }
                        ],
                        "text": "Some of the recent methods (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005) try to fit multiple object hypotheses to explain the foreground or motion blobs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 91
                            }
                        ],
                        "text": "A number of systems have been developed in recent years, e.g. (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005), to segment multiple humans from motion blobs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1522788,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b60ea458dc5d571c7bc028d9fd98fb545c0070d1",
            "isKey": true,
            "numCitedBy": 564,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Tracking multiple humans in complex situations is challenging. The difficulties are tackled with appropriate knowledge in the form of various models in our approach. Human motion is decomposed into its global motion and limb motion. In the first part, we show how multiple human objects are segmented and their global motions are tracked in 3D using ellipsoid human shape models. Experiments show that it successfully applies to the cases where a small number of people move together, have occlusion, and cast shadow or reflection. In the second part, we estimate the modes (e.g., walking, running, standing) of the locomotion and 3D body postures by making inference in a prior locomotion model. Camera model and ground plane assumptions provide geometric constraints in both parts. Robust results are shown on some difficult sequences."
            },
            "slug": "Tracking-multiple-humans-in-complex-situations-Zhao-Nevatia",
            "title": {
                "fragments": [],
                "text": "Tracking multiple humans in complex situations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work shows how multiple human objects are segmented and their global motions are tracked in 3D using ellipsoid human shape models and estimates the modes (e.g., walking, running, standing) of the locomotion and 3D body postures by making inference in a prior locomotion model."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117538614"
                        ],
                        "name": "Kevin Smith",
                        "slug": "Kevin-Smith",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403029865"
                        ],
                        "name": "D. G\u00e1tica-P\u00e9rez",
                        "slug": "D.-G\u00e1tica-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "G\u00e1tica-P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G\u00e1tica-P\u00e9rez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719610"
                        ],
                        "name": "J. Odobez",
                        "slug": "J.-Odobez",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Odobez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odobez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 189
                            }
                        ],
                        "text": "Because the joint hypotheses space is usually of high dimension, an efficient optimization algorithm, such as a particle filter (Isard and MacCormick, 2001), MCMC (Zhao and Nevatia, 2004a; Smith et al., 2005) or EM (Peter et al., 2005) is used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 0
                            }
                        ],
                        "text": "(Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005), to segment multiple humans from motion blobs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 185
                            }
                        ],
                        "text": "Also, as the cues for tracking are strong, we do not utilize statistical sampling techniques as in some of the previous work, e.g. (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 163
                            }
                        ],
                        "text": "Because the joint hypotheses space is usually of high dimension, an efficient optimization algorithm, such as a particle filter (Isard and MacCormick, 2001), MCMC (Zhao and Nevatia, 2004a; Smith et al., 2005) or EM (Peter et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 219
                            }
                        ],
                        "text": "A trajectory is initialized when evidence from new observations can not be explained by the current hypotheses, as also in many previous methods (Davis et al., 2000; Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 81
                            }
                        ],
                        "text": "Some of the recent methods (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005) try to fit multiple object hypotheses to explain the foreground or motion blobs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 116
                            }
                        ],
                        "text": "A number of systems have been developed in recent years, e.g. (Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005), to segment multiple humans from motion blobs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2083508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f90d0d80404888f21b569bd543743c55da787c9",
            "isKey": true,
            "numCitedBy": 252,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a Bayesian framework for the fully automatic tracking of a variable number of interacting targets using a fixed camera. This framework uses a joint multi-object state-space formulation and a trans-dimensional Markov Chain Monte Carlo (MCMC) particle filter to recursively estimates the multi-object configuration and efficiently search the state-space. We also define a global observation model comprised of color and binary measurements capable of discriminating between different numbers of objects in the scene. We present results which show that our method is capable of tracking varying numbers of people through several challenging real-world tracking situations such as full/partial occlusion and entering/leaving the scene."
            },
            "slug": "Using-particles-to-track-varying-numbers-of-people-Smith-G\u00e1tica-P\u00e9rez",
            "title": {
                "fragments": [],
                "text": "Using particles to track varying numbers of interacting people"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A Bayesian framework for the fully automatic tracking of a variable number of interacting targets using a fixed camera and a trans-dimensional Markov Chain Monte Carlo particle filter to recursively estimates the multi-object configuration and efficiently search the state-space is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815078"
                        ],
                        "name": "S. Avidan",
                        "slug": "S.-Avidan",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Avidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Avidan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 104
                            }
                        ],
                        "text": "There is some existing work on online learning of classifiers for object detection and tracking, (e.g., Avidan, 2005; Grabner and Bischof, 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 22
                            }
                        ],
                        "text": "For example, recently Brostow and Cipolla (2006) proposed a method to detect independent motions in crowds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1638397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82c0dba2a7a175113050a6c0dbd409c93cc48996",
            "isKey": false,
            "numCitedBy": 1222,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider tracking as a binary classification problem, where an ensemble of weak classifiers is trained online to distinguish between the object and the background. The ensemble of weak classifiers is combined into a strong classifier using AdaBoost. The strong classifier is then used to label pixels in the next frame as either belonging to the object or the background, giving a confidence map. The peak of the map and, hence, the new position of the object, is found using mean shift. Temporal coherence is maintained by updating the ensemble with new weak classifiers that are trained online during tracking. We show a realization of this method and demonstrate it on several video sequences"
            },
            "slug": "Ensemble-Tracking-Avidan",
            "title": {
                "fragments": [],
                "text": "Ensemble Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "This work considers tracking as a binary classification problem, where an ensemble of weak classifiers is trained online to distinguish between the object and the background, and combines them into a strong classifier using AdaBoost."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 92
                            }
                        ],
                        "text": "For each part, a detector is learned by following the Viola-Jones approach applied to SIFT (Lowe, 1999) like orientation features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Dalal and Triggs (2005) compared several local features, including SIFT, wavelets, and Histogram of Oriented Gradient (HOG) descriptors for pedestrian detection."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": false,
            "numCitedBy": 16258,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083209039"
                        ],
                        "name": "Edgar Seemann",
                        "slug": "Edgar-Seemann",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Seemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edgar Seemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 89
                            }
                        ],
                        "text": "Some methods use spatially global features as in Gavrila (2000), Felzenszwalb (2001) and Leibe et al. (2005); others use spatially local features as in Papageorgiou et al. (1998), Mohan et al. (2001), Viola et al. (2003), Mikolajczyk et al. (2004), Wu et al. (2005), Leibe et al. (2005), and Dalal\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "However, of these only Leibe et al. (2005) incorporates explicit inter-object occlusion reasoning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 14
                            }
                        ],
                        "text": "The method of\nLeibe et al. (2005) has two main steps: the first generates hypotheses by evidence from local features, while the second verifies the hypotheses by constraints from the global features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 251
                            }
                        ],
                        "text": "\u2026spatially global features as in Gavrila (2000), Felzenszwalb (2001) and Leibe et al. (2005); others use spatially local features as in Papageorgiou et al. (1998), Mohan et al. (2001), Viola et al. (2003), Mikolajczyk et al. (2004), Wu et al. (2005), Leibe et al. (2005), and Dalal and Triggs (2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14395688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1854005a7178b2df6afaacdcf91bc35d90616075",
            "isKey": true,
            "numCitedBy": 932,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of detecting pedestrians in crowded real-world scenes with severe overlaps. Our basic premise is that this problem is too difficult for any type of model or feature alone. Instead, we present an algorithm that integrates evidence in multiple iterations and from different sources. The core part of our method is the combination of local and global cues via probabilistic top-down segmentation. Altogether, this approach allows examining and comparing object hypotheses with high precision down to the pixel level. Qualitative and quantitative results on a large data set confirm that our method is able to reliably detect pedestrians in crowded scenes, even when they overlap and partially occlude each other. In addition, the flexible nature of our approach allows it to operate on very small training sets."
            },
            "slug": "Pedestrian-detection-in-crowded-scenes-Leibe-Seemann",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection in crowded scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Qualitative and quantitative results on a large data set confirm that the core part of the method is the combination of local and global cues via probabilistic top-down segmentation that allows examining and comparing object hypotheses with high precision down to the pixel level."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 49
                            }
                        ],
                        "text": "Some methods use spatially global features as in Gavrila (2000), Felzenszwalb (2001) and Leibe et al. (2005); others use spatially local features as in Papageorgiou et al. (1998), Mohan et al. (2001), Viola et al. (2003), Mikolajczyk et al. (2004), Wu et al. (2005), Leibe et al. (2005), and Dalal\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 269
                            }
                        ],
                        "text": "\u2026et al. (1998) is known as the MIT pedestrian sample set which is available online1), Felzenszwalb\u2019s shape models (Felzenszwalb, 2001), Wu et al.\u2019s Markov Random Field based representation (Wu et al., 2005), and Gavrila et al.\u2019s edge templates (Gavrila and Philomin, 1999; Gavrila, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17435119,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79036203c360174b694314adab553aa00a6aeff3",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a prototype system for pedestrian detection on-board a moving vehicle. The system uses a generic two-step approach for efficient object detection. In the first step, contour features are used in a hierarchical template matching approach to efficiently \"lock\" onto candidate solutions. Shape matching is based on Distance Transforms. By capturing the objects shape variability by means of a template hierarchy and using a combined coarse-to-fine approach in shape and parameter space, this method achieves very large speed-ups compared to a brute-force method. We have measured gains of several orders of magnitude. The second step utilizes the richer set of intensity features in a pattern classification approach to verify the candidate solutions (i.e. using Radial Basis Functions). We present experimental results on pedestrian detection off-line and on-board our Urban Traffic Assistant vehicle and discuss the challenges that lie ahead."
            },
            "slug": "Pedestrian-Detection-from-a-Moving-Vehicle-Gavrila",
            "title": {
                "fragments": [],
                "text": "Pedestrian Detection from a Moving Vehicle"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper presents a prototype system for pedestrian detection on-board a moving vehicle that uses a generic two-step approach for efficient object detection using a hierarchical template matching approach and achieves very large speed-ups compared to a brute-force method."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 181
                            }
                        ],
                        "text": "Second, in Section 7.1.3, we evaluate our method with two public data sets, on which many previous papers report quantitative results (Mohan et al., 2001; Mikolajczyk et al., 2004; Dalal and Triggs, 2005); the samples in these\ntwo experiments are un-occluded ones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Dalal and Triggs (2005) trained a full-body detector with 509 positive samples and test with 200 images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Dalal and Triggs (2005) trained their classifiers on the INRIA training set and evaluated them on the INRIA test set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 30
                            }
                        ],
                        "text": "In Mikolajczyk et al. (2004), Dalal and Triggs (2005) and Mohan et al. (2001), the MIT pedestrian set is used to evaluate the methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Dalal and Triggs (2005) compared several local features, including SIFT, wavelets, and Histogram of Oriented Gradient (HOG) descriptors for pedestrian detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 64
                            }
                        ],
                        "text": "However it can be seen that our method is comparable to that in Dalal and Triggs (2005) in terms of classification accuracy, while the boosted cascade classifier is much more efficient computationally than the SVM classifier used in Dalal and Triggs (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 73
                            }
                        ],
                        "text": "Our experimental setup is comparable to that of Mohan et al. (2001), and Dalal and Triggs (2005)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 57
                            }
                        ],
                        "text": "Note that (Mohan et al., 2001; Mikolajczyk et al., 2004; Dalal and Triggs, 2005) did experiments on 64 pixel wide samples, while our method requires samples to be 24 pixel wide only and still have comparable performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 46
                            }
                        ],
                        "text": "It can be seen that the full-body detector of Dalal and Triggs (2005) achieved the highest accuracy, almost perfect, on this set, and our full-body detector is the second best one."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 57
                            }
                        ],
                        "text": "As near-ideal results were achieved on the MIT data set, Dalal and Triggs (2005) concluded that the MIT set is too easy and they collected their own data set, called the INRIA data set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 299,
                                "start": 276
                            }
                        ],
                        "text": "\u2026spatially global features as in Gavrila (2000), Felzenszwalb (2001) and Leibe et al. (2005); others use spatially local features as in Papageorgiou et al. (1998), Mohan et al. (2001), Viola et al. (2003), Mikolajczyk et al. (2004), Wu et al. (2005), Leibe et al. (2005), and Dalal and Triggs (2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": true,
            "numCitedBy": 29266,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762260"
                        ],
                        "name": "V. Philomin",
                        "slug": "V.-Philomin",
                        "structuredName": {
                            "firstName": "Vasanth",
                            "lastName": "Philomin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Philomin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 241
                            }
                        ],
                        "text": "\u2026et al. (1998) is known as the MIT pedestrian sample set which is available online1), Felzenszwalb\u2019s shape models (Felzenszwalb, 2001), Wu et al.\u2019s Markov Random Field based representation (Wu et al., 2005), and Gavrila et al.\u2019s edge templates (Gavrila and Philomin, 1999; Gavrila, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 766556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb490d879512b3d43b267e3ac8931c099a5a2fd3",
            "isKey": false,
            "numCitedBy": 760,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an efficient shape-based object detection method based on Distance Transforms and describes its use for real-time vision on-board vehicles. The method uses a template hierarchy to capture the variety of object shapes; efficient hierarchies can be generated offline for given shape distributions using stochastic optimization techniques (i.e. simulated annealing). Online, matching involves a simultaneous coarse-to-fine approach over the shape hierarchy and over the transformation parameters. Very large speed-up factors are typically obtained when comparing this approach with the equivalent brute-force formulation; we have measured gains of several orders of magnitudes. We present experimental results on the real-time detection of traffic signs and pedestrians from a moving vehicle. Because of the highly time sensitive nature of these vision tasks, we also discuss some hardware-specific implementations of the proposed method as far as SIMD parallelism is concerned."
            },
            "slug": "Real-time-object-detection-for-\"smart\"-vehicles-Gavrila-Philomin",
            "title": {
                "fragments": [],
                "text": "Real-time object detection for \"smart\" vehicles"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An efficient shape-based object detection method based on Distance Transforms is presented and its use for real-time vision on-board vehicles and some hardware-specific implementations of the proposed method as far as SIMD parallelism is concerned are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145551629"
                        ],
                        "name": "H. Grabner",
                        "slug": "H.-Grabner",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Grabner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Grabner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 118
                            }
                        ],
                        "text": "There is some existing work on online learning of classifiers for object detection and tracking, (e.g., Avidan, 2005; Grabner and Bischof, 2006)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16135648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "075bfb99ce2dbaa2005500dff90f893b7caa68c2",
            "isKey": false,
            "numCitedBy": 1114,
            "numCiting": 166,
            "paperAbstract": {
                "fragments": [],
                "text": "Boosting has become very popular in computer vision, showing impressive performance in detection and recognition tasks. Mainly off-line training methods have been used, which implies that all training data has to be a priori given; training and usage of the classifier are separate steps. Training the classifier on-line and incrementally as new data becomes available has several advantages and opens new areas of application for boosting in computer vision. In this paper we propose a novel on-line AdaBoost feature selection method. In conjunction with efficient feature extraction methods the method is real time capable. We demonstrate the multifariousness of the method on such diverse tasks as learning complex background models, visual tracking and object detection. All approaches benefit significantly by the on-line training."
            },
            "slug": "On-line-Boosting-and-Vision-Grabner-Bischof",
            "title": {
                "fragments": [],
                "text": "On-line Boosting and Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a novel on-line AdaBoost feature selection method and demonstrates the multifariousness of the method on such diverse tasks as learning complex background models, visual tracking and object detection."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143847264"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47974933"
                        ],
                        "name": "V. Singh",
                        "slug": "V.-Singh",
                        "structuredName": {
                            "firstName": "Vivek",
                            "lastName": "Singh",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3302569"
                        ],
                        "name": "Chi-Wei Chu",
                        "slug": "Chi-Wei-Chu",
                        "structuredName": {
                            "firstName": "Chi-Wei",
                            "lastName": "Chu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chi-Wei Chu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 100
                            }
                        ],
                        "text": "We have also applied this framework to other applications, e.g. speaker tracking in seminar videos (Wu et al., 2006) and conferee tracking in meeting videos (Wu and Nevatia, 2006c), and have achieved good scores in the VACE (http://www.ic-arda.org/InfoExploit/vace/) and CHIL\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 35
                            }
                        ],
                        "text": "speaker tracking in seminar videos (Wu et al., 2006) and conferee tracking in meeting videos (Wu and Nevatia, 2006c), and have achieved good scores in the VACE (http://www."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16451507,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0867c317a45ac8d675237b0d8b3e9d908e2bc1d3",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents evaluation results of a method for tracking speakers in seminars from multiple cameras. First, 2D human tracking and detection is done for each view. Then, 2D locations are converted to 3D based on the calibration parameters. Finally, cues from multiple cameras are integrated in a incremental way to refine the trajectories. We have developed two multi-view integration methods, which are evaluated and compared on the CHIL speaker tracking test set."
            },
            "slug": "Speaker-Tracking-in-Seminars-by-Human-Body-Wu-Singh",
            "title": {
                "fragments": [],
                "text": "Speaker Tracking in Seminars by Human Body Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Two multi-view integration methods for tracking speakers in seminars from multiple cameras are developed, which are evaluated and compared on the CHIL speaker tracking test set."
            },
            "venue": {
                "fragments": [],
                "text": "CLEAR"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3074803"
                        ],
                        "name": "H. Kruppa",
                        "slug": "H.-Kruppa",
                        "structuredName": {
                            "firstName": "Hannes",
                            "lastName": "Kruppa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kruppa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694554"
                        ],
                        "name": "M. C. Santana",
                        "slug": "M.-C.-Santana",
                        "structuredName": {
                            "firstName": "Modesto",
                            "lastName": "Santana",
                            "middleNames": [
                                "Castrill\u00f3n"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. C. Santana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 92
                            }
                        ],
                        "text": "We evaluate our edgelet based part detectors and compare with those based on Haar features (Kruppa et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 4
                            }
                        ],
                        "text": "0b (Kruppa et al., 2003) on this test set."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6030449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94631b0ff5e9d455901521705e622bc6dcb91777",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In visual surveillance face detection can be an important cue for initializing tracking algorithms. Recent work in psychophics hints at the importance of the local context of a face for robust detection, such as head contours and torso. This paper describes a detector that actively utilizes the idea of local context. The promise is to gain robustness that goes beyond the capabilities of traditional face detection making it particularly interesting for surveillance. The performance of the..."
            },
            "slug": "Fast-and-Robust-Face-Finding-via-Local-Context-Kruppa-Santana",
            "title": {
                "fragments": [],
                "text": "Fast and Robust Face Finding via Local Context"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A detector that actively utilizes the idea of local context to gain robustness that goes beyond the capabilities of traditional face detection making it particularly interesting for surveillance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 65
                            }
                        ],
                        "text": "Some methods use spatially global features as in Gavrila (2000), Felzenszwalb (2001) and Leibe et al. (2005); others use spatially local features as in Papageorgiou et al. (1998), Mohan et al. (2001), Viola et al. (2003), Mikolajczyk et al. (2004), Wu et al. (2005), Leibe et al. (2005), and Dalal\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 149
                            }
                        ],
                        "text": "\u2026positive sample set in Papageorgiou et al. (1998) is known as the MIT pedestrian sample set which is available online1), Felzenszwalb\u2019s shape models (Felzenszwalb, 2001), Wu et al.\u2019s Markov Random Field based representation (Wu et al., 2005), and Gavrila et al.\u2019s edge templates (Gavrila and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10410299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a626c9dd0a5f3dd36231c1784e77be886b98659",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider learning models for object recognition from examples. Our method is motivated by systems that use the Hausdorff distance as a shape comparison measure. Typically an object is represented in terms of a model shape. A new shape is classified as being an instance of the object when the Hausdorff distance between the model and the new shape is small. We show that such object concepts can be seen as halfspaces (linear threshold functions) in a transformed input space. This makes it possible to use a number of standard algorithms to learn object models from training examples. When a good model exists, we are guaranteed to find one that provides (with high probability) a recognition rule that is accurate. Our approach provides a measure which generalizes the Hausdorff distance in a number of interesting ways. To demonstrate our method we trained a system to detect people in images using a single shape model. The learning techniques can be extended to represent objects using multiple model shapes. In this way, we might be able to automatically learn a small set of canonical shapes that characterize the appearance of an object."
            },
            "slug": "Learning-models-for-object-recognition-Felzenszwalb",
            "title": {
                "fragments": [],
                "text": "Learning models for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The approach provides a measure which generalizes the Hausdorff distance in a number of interesting ways and might be able to automatically learn a small set of canonical shapes that characterize the appearance of an object."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804676"
                        ],
                        "name": "B. Kr\u00f6se",
                        "slug": "B.-Kr\u00f6se",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Kr\u00f6se",
                            "middleNames": [
                                "J.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kr\u00f6se"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9235290"
                        ],
                        "name": "A. Cemgil",
                        "slug": "A.-Cemgil",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Cemgil",
                            "middleNames": [
                                "Taylan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cemgil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927147"
                        ],
                        "name": "W. Zajdel",
                        "slug": "W.-Zajdel",
                        "structuredName": {
                            "firstName": "Wojtek",
                            "lastName": "Zajdel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Zajdel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144722584"
                        ],
                        "name": "Z. Zivkovic",
                        "slug": "Z.-Zivkovic",
                        "structuredName": {
                            "firstName": "Zoran",
                            "lastName": "Zivkovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Zivkovic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 146
                            }
                        ],
                        "text": "A trajectory is initialized when evidence from new observations can not be explained by the current hypotheses, as also in many previous methods (Davis et al., 2000; Isard and MacCormick, 2001; Zhao and Nevatia, 2004a; Smith et al., 2005; Peter et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "(Davis et al., 2000) build deformable silhouette models for pedestrians and track the models from edge features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 35
                            }
                        ],
                        "text": "Some discriminative methods, e.g. (Davis et al., 2000) build deformable silhouette models for pedestrians and track the models from edge features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8219557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b483ea0659c47c485bf68d5ff54874707dafa614",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In a human-inhabited environment it is essential that a robot which interacts with humans is able to keep track of them when they move around in the environment. This is not an easy job. Multiple people may be in the robot\u2019s vicinity, sometimes a person leaves the vicinity of the robot and reenters some time later. Two issues are essential in tracking: localization and identification. Multi-modal cues (audio, visual, maybe radar) may be used for the task. In this paper we restrict ourselves to visual cues and present our work to track people with a vision system."
            },
            "slug": "Tracking-Humans-Kr\u00f6se-Cemgil",
            "title": {
                "fragments": [],
                "text": "Tracking Humans"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper restricts ourselves to visual cues and presents the work to track people with a vision system to address localization and identification issues in tracking."
            },
            "venue": {
                "fragments": [],
                "text": "IFIP Congress Topical Sessions"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144528373"
                        ],
                        "name": "Chang Huang",
                        "slug": "Chang-Huang",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679380"
                        ],
                        "name": "H. Ai",
                        "slug": "H.-Ai",
                        "structuredName": {
                            "firstName": "Haizhou",
                            "lastName": "Ai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118204296"
                        ],
                        "name": "Yuan Li",
                        "slug": "Yuan-Li",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710195"
                        ],
                        "name": "S. Lao",
                        "slug": "S.-Lao",
                        "structuredName": {
                            "firstName": "Shihong",
                            "lastName": "Lao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 85
                            }
                        ],
                        "text": "We learn tree structured multiview part detectors by a boosting approach proposed by Huang et al. (2004, 2005) which is an enhanced version of Viola and Jones\u2019 framework (Viola and Jones, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 82
                            }
                        ],
                        "text": "The root node of the tree is learned by the vector boosting algorithm proposed in Huang et al. (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14705012,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "de3ba2bb8638e3f35670993d8d63835c841a8c89",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel tree-structured multiview face detector (MVFD), which adopts the coarse-to-fine strategy to divide the entire face space into smaller and smaller subspaces. For this purpose, a newly extended boosting algorithm named vector boosting is developed to train the predictors for the branching nodes of the tree that have multicomponents outputs as vectors. Our MVFD covers a large range of the face space, say, +/-45/spl deg/ rotation in plane (RIP) and +/-90/spl deg/ rotation off plane (ROP), and achieves high accuracy and amazing speed (about 40 ms per frame on a 320 /spl times/ 240 video sequence) compared with previous published works. As a result, by simply rotating the detector 90/spl deg/, 180/spl deg/ and 270/spl deg/, a rotation invariant (360/spl deg/ RIP) MVFD is implemented that achieves real time performance (11 fps on a 320 /spl times/ 240 video sequence) with high accuracy."
            },
            "slug": "Vector-boosting-for-rotation-invariant-multi-view-Huang-Ai",
            "title": {
                "fragments": [],
                "text": "Vector boosting for rotation invariant multi-view face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A novel tree-structured multiview face detector (MVFD) is proposed, which adopts the coarse-to-fine strategy to divide the entire face space into smaller and smaller subspaces and achieves high accuracy and amazing speed."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696931"
                        ],
                        "name": "H. Barrow",
                        "slug": "H.-Barrow",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Barrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144592244"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11843441"
                        ],
                        "name": "H. C. Wolf",
                        "slug": "H.-C.-Wolf",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Wolf",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. C. Wolf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The edgelet affinity function captures both intensity and shape information of the edge; it could be considered a variation of the standard Chamfer matching ( Barrow et al., 1977 )."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 158
                            }
                        ],
                        "text": "The edgelet affinity function captures both intensity and shape information of the edge; it could be considered a variation of the standard Chamfer matching (Barrow et al., 1977)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1621080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "358a97112cc60d6bfefb352b863fec8a86a39e28",
            "isKey": false,
            "numCitedBy": 873,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Parametric correspondence is a technique for matching images to a three dimensional symbolic reference map. An analytic camera model is used to predict the location and appearance of landmarks in the image, generating a projection for an assumed viewpoint. Correspondence is achieved by adjusting the parameters of the camera model until the appearances of the landmarks optimally match a symbolic description extracted from the image. \n \nThe matching of image and map features is performed rapidly by a new technique, called \"chamfer matching\", that compares the shapes of two collections of shape fragments, at a cost proportional to linear dimension, rather than area. These two techniques permit the matching of spatially extensive features on the basis of shape, which reduces the risk of ambiguous matches and the dependence on viewing conditions inherent in conventional image based correlation matching."
            },
            "slug": "Parametric-Correspondence-and-Chamfer-Matching:-Two-Barrow-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "Parametric Correspondence and Chamfer Matching: Two New Techniques for Image Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The matching of image and map features is performed rapidly by a new technique, called \"chamfer matching\", that compares the shapes of two collections of shape fragments, at a cost proportional to linear dimension, rather than area."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34751187"
                        ],
                        "name": "C. R. Wren",
                        "slug": "C.-R.-Wren",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Wren",
                            "middleNames": [
                                "Richard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. R. Wren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145271456"
                        ],
                        "name": "A. Azarbayejani",
                        "slug": "A.-Azarbayejani",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Azarbayejani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Azarbayejani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 214
                            }
                        ],
                        "text": "This approach is quite effective for detecting isolated moving objects when the camera is stationary, illumination is constant or varies slowly, and humans are the only moving objects; an early example is given in Wren et al. (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 214
                            }
                        ],
                        "text": "This approach is quite effective for detecting isolated moving objects when the camera is stationary, illumination is constant or varies slowly, and humans are the only moving objects; an early example is given in Wren et al. (1997). For a moving camera, there is apparent background motion which can be compensated for, in some cases, but errors in registration are likely in presence of parallax."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9458767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69b7efd02ea06e6aa372b5c1a46167e6a5366bfd",
            "isKey": false,
            "numCitedBy": 3549,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Pfinder is a real-time system for tracking and interpretation of people. It runs on a standard SGI Indy computer, and has performed reliably on thousands of people in many different physical locations. The system uses a multi-class statistical model of color and shape to obtain a 2-D representation of head and hands in a wide range of viewing conditions. These representations are useful for applications such as wireless interfaces, video databases, and low-bandwidth coding, without cumbersome wires or attached sensors."
            },
            "slug": "Pfinder:-real-time-tracking-of-the-human-body-Wren-Azarbayejani",
            "title": {
                "fragments": [],
                "text": "Pfinder: Real-Time Tracking of the Human Body"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Pfinder uses a multi-class statistical model of color and shape to obtain a 2-D representation of head and hands in a wide range of viewing conditions, useful for applications such as wireless interfaces, video databases, and low-bandwidth coding."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110926874"
                        ],
                        "name": "Chang Huang",
                        "slug": "Chang-Huang",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679380"
                        ],
                        "name": "H. Ai",
                        "slug": "H.-Ai",
                        "structuredName": {
                            "firstName": "Haizhou",
                            "lastName": "Ai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115595183"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710195"
                        ],
                        "name": "S. Lao",
                        "slug": "S.-Lao",
                        "structuredName": {
                            "firstName": "Shihong",
                            "lastName": "Lao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 28
                            }
                        ],
                        "text": "We use an enhanced version (Huang et al., 2004) of the original boosting method of Viola and Jones (2001) to learn the part detectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 38
                            }
                        ],
                        "text": "Finally, nested structured detectors (Huang et al., 2004) are constructed from these layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 85
                            }
                        ],
                        "text": "We learn tree structured multiview part detectors by a boosting approach proposed by Huang et al. (2004, 2005) which is an enhanced version of Viola and Jones\u2019 framework (Viola and Jones, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2249117,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e54e71084f00fb5bd8d7f046eeed0fbfab25e4b",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel nested cascade detector for multi-view face detection is presented. This nested cascade is learned by Schapire and Singer's to improved boosting algorithms that use real-valued confidence-rated weak classifiers (Schapire, R. E. and Singer, Y, 1999), where we use confidence-rated look-up-table (LUT) weak classifiers based on Haar features. Experiments show the system performance is significantly improved compared with previous methods."
            },
            "slug": "Boosting-nested-cascade-detector-for-multi-view-Huang-Ai",
            "title": {
                "fragments": [],
                "text": "Boosting nested cascade detector for multi-view face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A novel nested cascade detector for multi-view face detection is presented that uses confidence-rated look-up-table (LUT) weak classifiers based on Haar features and shows significantly improved performance compared with previous methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1915667"
                        ],
                        "name": "Y. Gdalyahu",
                        "slug": "Y.-Gdalyahu",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Gdalyahu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Gdalyahu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079194"
                        ],
                        "name": "G. Hayun",
                        "slug": "G.-Hayun",
                        "structuredName": {
                            "firstName": "Gaby",
                            "lastName": "Hayun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hayun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 0
                            }
                        ],
                        "text": "(Mohan et al., 2001; Mikolajczyk et al., 2004; Shashua et al., 2004), consider humans independently from each other and do not model inter-object occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 82
                            }
                        ],
                        "text": "The previous such approaches, e.g. (Mohan et al., 2001; Mikolajczyk et al., 2004; Shashua et al., 2004), consider humans independently from each other and do not model inter-object occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 15
                            }
                        ],
                        "text": "The methods of Shashua et al. (2004) and Mikolajczyk et al. (2004) both achieved better results than that of Mohan et al. (2001), but there is no direct comparison between (Shashua et al., 2004) and (Mikolajczyk et al., 2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Shashua et al. (2004) divide human body into nine regions, for each of which a classifier is learned based on features of orientation histograms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 50
                            }
                        ],
                        "text": "(2001), but there is no direct comparison between (Shashua et al., 2004) and (Mikolajczyk et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14981509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37a15ce03c26ec83d95bf4aaf756a41370d50353",
            "isKey": true,
            "numCitedBy": 404,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the functional and architectural breakdown of a monocular pedestrian detection system. We describe in detail our approach for single-frame classification based on a novel scheme of breaking down the class variability by repeatedly training a set of relatively simple classifiers on clusters of the training set. Single-frame classification performance results and system level performance figures for daytime conditions are presented with a discussion about the remaining gap to meet a daytime normal weather condition production system."
            },
            "slug": "Pedestrian-detection-for-driving-assistance-and-Shashua-Gdalyahu",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection for driving assistance systems: single-frame classification and system level performance"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The functional and architectural breakdown of a monocular pedestrian detection system is described and the approach for single-frame classification based on a novel scheme of breaking down the class variability by repeatedly training a set of relatively simple classifiers on clusters of the training set is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intelligent Vehicles Symposium, 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320582"
                        ],
                        "name": "Visvanathan Ramesh",
                        "slug": "Visvanathan-Ramesh",
                        "structuredName": {
                            "firstName": "Visvanathan",
                            "lastName": "Ramesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Visvanathan Ramesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 117
                            }
                        ],
                        "text": "Whenever data association fails (the detectors can not find the object or the affinity is low), a meanshift tracker (Comaniciu et al., 2001) is applied to track the parts individually."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 42
                            }
                        ],
                        "text": "If this fails again, a meanshift tracker (Comaniciu et al., 2001) is used to follow the object."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14661676,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7fc921ebf33ca27c60c1b72b9652f547935bc5ef",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two solutions for the scale selection problem in computer vision. The first one is completely nonparametric and is based on the the adaptive estimation of the normalized density gradient. Employing the sample point estimator, we define the Variable Bandwidth Mean Shift, prove its convergence, and show its superiority over the fixed bandwidth procedure. The second technique has a semiparametric nature and imposes a local structure on the data to extract reliable scale information. The local scale of the underlying density is taken as the bandwidth which maximizes the magnitude of the normalized mean shift vector. Both estimators provide practical tools for autonomous image and quasi real-time video analysis and several examples are shown to illustrate their effectiveness."
            },
            "slug": "The-variable-bandwidth-mean-shift-and-data-driven-Comaniciu-Ramesh",
            "title": {
                "fragments": [],
                "text": "The Variable Bandwidth Mean Shift and Data-Driven Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The sample point estimator is defined, prove its convergence, and show its superiority over the fixed bandwidth procedure, and an alternative approach for data-driven scale selection which imposes a local structure on the data is studied."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1836349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68c1bfe375dde46777fe1ac8f3636fb651e3f0f8",
            "isKey": false,
            "numCitedBy": 8626,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In an earlier paper, we introduced a new \"boosting\" algorithm called AdaBoost which, theoretically, can be used to significantly reduce the error of any learning algorithm that con- sistently generates classifiers whose performance is a little better than random guessing. We also introduced the related notion of a \"pseudo-loss\" which is a method for forcing a learning algorithm of multi-label concepts to concentrate on the labels that are hardest to discriminate. In this paper, we describe experiments we carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems. We performed two sets of experiments. The first set compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers (including decision trees and single attribute- value tests). We compared the performance of the two methods on a collection of machine-learning benchmarks. In the second set of experiments, we studied in more detail the performance of boosting using a nearest-neighbor classifier on an OCR problem."
            },
            "slug": "Experiments-with-a-New-Boosting-Algorithm-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "Experiments with a New Boosting Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper describes experiments carried out to assess how well AdaBoost with and without pseudo-loss, performs on real learning problems and compared boosting to Breiman's \"bagging\" method when used to aggregate various classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 145
                            }
                        ],
                        "text": "\u2026E is defined as\nif f\u0303 (E ; x, O) \u2208 bin j then h(w)(x) = 1 2 ln ( W\u0304 j+1 + \u03b5 W\u0304 j\u22121 + \u03b5 ) (5)\nwhere O is the origin of the patch x, \u03b5 is a smoothing factor (Schapire and Singer, 1999), and\nW\u0304 jc = P ( f\u0303 (E ; x, O) \u2208 bin j , y = c ) ,\nc = \u00b11, j = 1 . . . n (6)\nGiven the characteristic\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 34
                            }
                        ],
                        "text": "Then the real AdaBoost algorithm (Schapire and Singer, 1999) is used to learn strong classifiers, called layers, from the weak classifier pool."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 59
                            }
                        ],
                        "text": "According to the real-valued version of AdaBoost algorithm (Schapire and Singer, 1999), the weak classifier h(w) based on an edgelet feature E is defined as"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 60
                            }
                        ],
                        "text": "According to the real-valued version of AdaBoost algorithm (Schapire and Singer, 1999), the weak classifier h(w) based on an edgelet feature E is defined as\nif f\u0303 (E ; x, O) \u2208 bin j then h(w)(x) = 1 2 ln ( W\u0304 j+1 + \u03b5 W\u0304 j\u22121 + \u03b5 ) (5)\nwhere O is the origin of the patch x, \u03b5 is a smoothing factor\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 62
                            }
                        ],
                        "text": "where O is the origin of the patch x, \u03b5 is a smoothing factor (Schapire and Singer, 1999), and"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2329907,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a9309e056272ff2076f447df8dbc536f46fc466",
            "isKey": true,
            "numCitedBy": 1920,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe several improvements to Freund and Schapire's AdaBoost boosting algorithm, particularly in a setting in which hypotheses may assign confidences to each of their predictions. We give a simplified analysis of AdaBoost in this setting, and we show how this analysis can be used to find improved parameter settings as well as a refined criterion for training weak hypotheses. We give a specific method for assigning confidences to the predictions of decision trees, a method closely related to one used by Quinlan. This method also suggests a technique for growing decision trees which turns out to be identical to one proposed by Kearns and Mansour. We focus next on how to apply the new boosting algorithms to multiclass classification problems, particularly to the multi-label case in which each example may belong to more than one class. We give two boosting methods for this problem, plus a third method based on output coding. One of these leads to a new method for handling the single-label case which is simpler but as effective as techniques suggested by Freund and Schapire. Finally, we give some experimental results comparing a few of the algorithms discussed in this paper."
            },
            "slug": "Improved-Boosting-Algorithms-Using-Confidence-rated-Schapire-Singer",
            "title": {
                "fragments": [],
                "text": "Improved Boosting Algorithms Using Confidence-rated Predictions"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "Several improvements to Freund and Schapire's AdaBoost boosting algorithm are described, particularly in a setting in which hypotheses may assign confidences to each of their predictions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT' 98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109286205"
                        ],
                        "name": "J. Park",
                        "slug": "J.-Park",
                        "structuredName": {
                            "firstName": "Jong",
                            "lastName": "Park",
                            "middleNames": [
                                "Woung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Park"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 155
                            }
                        ],
                        "text": "Second, in Section 7.1.3, we evaluate our method with two public data sets, on which many previous papers report quantitative results (Mohan et al., 2001; Mikolajczyk et al., 2004; Dalal and Triggs, 2005); the samples in these\ntwo experiments are un-occluded ones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 0
                            }
                        ],
                        "text": "Papageorgiou et al.\u2019s SVMs detectors (Papageorgiou et al., 1998) (the positive sample set in Papageorgiou et al. (1998) is known as the MIT pedestrian sample set which is available online1), Felzenszwalb\u2019s shape models (Felzenszwalb, 2001), Wu et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 54
                            }
                        ],
                        "text": "When training with only 300 positive samples, like in Mikolajczyk et al. (2004), our method suffered from over-fitting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 111
                            }
                        ],
                        "text": "3, we evaluate our method with two public data sets, on which many previous papers report quantitative results (Mohan et al., 2001; Mikolajczyk et al., 2004; Dalal and Triggs, 2005); the samples in these"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 3
                            }
                        ],
                        "text": "In Mikolajczyk et al. (2004), Dalal and Triggs (2005) and Mohan et al. (2001), the MIT pedestrian set is used to evaluate the methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 38
                            }
                        ],
                        "text": "(2001), but inconsistent with that in Mikolajczyk et al. (2004). Mohan et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 331,
                                "start": 38
                            }
                        ],
                        "text": "(2001), but inconsistent with that in Mikolajczyk et al. (2004). Mohan et al. (2001) gave an explanation for the superiority of legs detector: the background of legs is usually road or grassland, which is relatively clutter-free compared to the background for head-shoulder. However, the legs detector of Mikolajczyk et al. (2004) is slightly inferior to their head-shoulder detector."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 30
                            }
                        ],
                        "text": "However, the legs detector of Mikolajczyk et al. (2004) is slightly inferior to their head-shoulder detector."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 0
                            }
                        ],
                        "text": "(Mohan et al., 2001; Mikolajczyk et al., 2004; Shashua et al., 2004), consider humans independently from each other and do not model inter-object occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 38
                            }
                        ],
                        "text": "(2001), but inconsistent with that in Mikolajczyk et al. (2004). Mohan et al. (2001) gave an explanation for the superiority of legs detector: the background of legs is usually road or grassland, which is relatively clutter-free compared to the background for head-shoulder."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 31
                            }
                        ],
                        "text": "Note that (Mohan et al., 2001; Mikolajczyk et al., 2004; Dalal and Triggs, 2005) did experiments on 64 pixel wide samples, while our method requires samples to be 24 pixel wide only and still have comparable performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Mikolajczyk et al. (2004) trained their head-shoulder/legs detector with 250/300 positive and 4,000 negative samples for each boosting stage, and evaluation was done with 400 positive samples and 200 negative images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 56
                            }
                        ],
                        "text": "The previous such approaches, e.g. (Mohan et al., 2001; Mikolajczyk et al., 2004; Shashua et al., 2004), consider humans independently from each other and do not model inter-object occlusion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 141
                            }
                        ],
                        "text": "If inter-object occlusion is present, the assumption of conditional independence between individual human appearances given the state, as in Mikolajczyk et al. (2004), is not valid and a more complex formulation is necessary."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 108
                            }
                        ],
                        "text": "The last observation is consistent with that reported in Mohan et al. (2001), but inconsistent with that in Mikolajczyk et al. (2004)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Mikolajczyk et al. (2004) divide human body into seven parts, face/head for frontal view, face/head for profile view, head-shoulder for frontal and rear view, head-shoulder for profile view, and legs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 41
                            }
                        ],
                        "text": "The methods of Shashua et al. (2004) and Mikolajczyk et al. (2004) both achieved better results than that of Mohan et al. (2001), but there is no direct comparison between (Shashua et al., 2004) and (Mikolajczyk et al., 2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 206
                            }
                        ],
                        "text": "\u2026spatially global features as in Gavrila (2000), Felzenszwalb (2001) and Leibe et al. (2005); others use spatially local features as in Papageorgiou et al. (1998), Mohan et al. (2001), Viola et al. (2003), Mikolajczyk et al. (2004), Wu et al. (2005), Leibe et al. (2005), and Dalal and Triggs (2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44302930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dec21c3b67a8bbfc8ec9e1326849afb29fce03a",
            "isKey": true,
            "numCitedBy": 6,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "..................................................................................................................4"
            },
            "slug": "Human-Detection-Park",
            "title": {
                "fragments": [],
                "text": "Human Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 0,
                "text": "This document summarizes current capabilities, research and operational priorities, and plans for further studies that were established at the 2015 USGS workshop on quantitative hazard assessments of earthquake-triggered landsliding and liquefaction in the Czech Republic."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Multimedia"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 28
                            }
                        ],
                        "text": "We use an enhanced version (Huang et al., 2004) of the original boosting method of Viola and Jones (2001) to learn the part detectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 38
                            }
                        ],
                        "text": "Finally, nested structured detectors (Huang et al., 2004) are constructed from these layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 82
                            }
                        ],
                        "text": "The root node of the tree is learned by the vector boosting algorithm proposed in Huang et al. (2005). The main advantage of this algorithm is that the features selected are shared among different view point categories of the same object type."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 85
                            }
                        ],
                        "text": "We learn tree structured multiview part detectors by a boosting approach proposed by Huang et al. (2004, 2005) which is an enhanced version of Viola and Jones\u2019 framework (Viola and Jones, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Boosting nested cascade"
            },
            "venue": {
                "fragments": [],
                "text": "vol. I,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 241
                            }
                        ],
                        "text": "\u2026et al. (1998) is known as the MIT pedestrian sample set which is available online1), Felzenszwalb\u2019s shape models (Felzenszwalb, 2001), Wu et al.\u2019s Markov Random Field based representation (Wu et al., 2005), and Gavrila et al.\u2019s edge templates (Gavrila and Philomin, 1999; Gavrila, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real-time object detection for"
            },
            "venue": {
                "fragments": [],
                "text": "Smart\" Vehicles. ICCV"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 118
                            }
                        ],
                        "text": "There is some existing work on online learning of classifiers for object detection and tracking, (e.g., Avidan, 2005; Grabner and Bischof, 2006)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Online boosting and vision. CVPR"
            },
            "venue": {
                "fragments": [],
                "text": "Online boosting and vision. CVPR"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "we show results on a subset, 23 sequences, only, as ground-truth for three sequences was not available at that time"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 85
                            }
                        ],
                        "text": "We learn tree structured multiview part detectors by a boosting approach proposed by Huang et al. (2004, 2005) which is an enhanced version of Viola and Jones\u2019 framework (Viola and Jones, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 82
                            }
                        ],
                        "text": "The root node of the tree is learned by the vector boosting algorithm proposed in Huang et al. (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vector boosting for rotation"
            },
            "venue": {
                "fragments": [],
                "text": "multi-view face detection. ICPR,"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 241
                            }
                        ],
                        "text": "\u2026et al. (1998) is known as the MIT pedestrian sample set which is available online1), Felzenszwalb\u2019s shape models (Felzenszwalb, 2001), Wu et al.\u2019s Markov Random Field based representation (Wu et al., 2005), and Gavrila et al.\u2019s edge templates (Gavrila and Philomin, 1999; Gavrila, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real - time object detection for \u201c Smart \u201d"
            },
            "venue": {
                "fragments": [],
                "text": "Vehicles . ICCV"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Experiments with a New Boosting"
            },
            "venue": {
                "fragments": [],
                "text": "vol. I,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 22
                            }
                        ],
                        "text": "For example, recently Brostow and Cipolla (2006) proposed a method to detect independent motions in crowds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Unsupervised bayesian detection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wu and Nevatia"
            },
            "venue": {
                "fragments": [],
                "text": "Wu and Nevatia"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In our previous paper (Wu and Nevatia, 2006a), we show results on a subset, 23 sequences, only, as ground-truth for three sequences was not available at that time"
            },
            "venue": {
                "fragments": [],
                "text": "In our previous paper (Wu and Nevatia, 2006a), we show results on a subset, 23 sequences, only, as ground-truth for three sequences was not available at that time"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 104
                            }
                        ],
                        "text": "There is some existing work on online learning of classifiers for object detection and tracking, (e.g., Avidan, 2005; Grabner and Bischof, 2006)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ensemble tracking. CVPR, vol. II"
            },
            "venue": {
                "fragments": [],
                "text": "Ensemble tracking. CVPR, vol. II"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 241
                            }
                        ],
                        "text": "\u2026et al. (1998) is known as the MIT pedestrian sample set which is available online1), Felzenszwalb\u2019s shape models (Felzenszwalb, 2001), Wu et al.\u2019s Markov Random Field based representation (Wu et al., 2005), and Gavrila et al.\u2019s edge templates (Gavrila and Philomin, 1999; Gavrila, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real-time object detection"
            },
            "venue": {
                "fragments": [],
                "text": "Algorithm. The 13th Conf. on Machine Learning,"
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 29,
            "methodology": 36,
            "result": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 52,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Detection-and-Tracking-of-Multiple,-Partially-by-of-Wu-Nevatia/49bdd3fb166e0faf7ad1c917aee32c22ebc0f9db?sort=total-citations"
}