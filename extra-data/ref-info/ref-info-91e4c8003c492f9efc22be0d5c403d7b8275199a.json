{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3214795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7417d7dcf6152736612e3f04ccc72731dc8d9505",
            "isKey": false,
            "numCitedBy": 418,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new approach to material classification under unknown viewpoint and illumination. Our texture model is based on the statistical distribution of clustered filter responses. However, unlike previous 3D texton representations, we use rotationally invariant filters and cluster in an extremely low dimensional space. Having built a texton dictionary, we present a novel method of classifying a single image without requiring any a priori knowledge about the viewing or illumination conditions under which it was photographed. We argue that using rotationally invariant filters while clustering in such a low dimensional space improves classification performance and demonstrate this claim with results on all 61 textures in the Columbia-Utrecht database. We then proceed to show how texture models can be further extended by compensating for viewpoint changes using weak isotropy.The new clustering and classification methods are compared to those of Leung and Malik (ICCV 1999), Schmid (CVPR 2001) and Cula and Dana (CVPR 2001), which are the current state-of-the-art approaches."
            },
            "slug": "Classifying-Images-of-Materials:-Achieving-and-Varma-Zisserman",
            "title": {
                "fragments": [],
                "text": "Classifying Images of Materials: Achieving Viewpoint and Illumination Independence"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper presents a novel method of classifying a single image without requiring any a priori knowledge about the viewing or illumination conditions under which it was photographed, and argues that using rotationally invariant filters while clustering in such a low dimensional space improves classification performance."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14915716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90d6e7f2202f754d8588f9536e3f5b4a24701f24",
            "isKey": false,
            "numCitedBy": 1713,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the recognition of surfaces made from different materials such as concrete, rug, marble, or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof. Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions.Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions. We also illustrate how the 3D texton model can be used to predict the appearance of materials under novel conditions."
            },
            "slug": "Representing-and-Recognizing-the-Visual-Appearance-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "Representing and Recognizing the Visual Appearance of Materials using Three-dimensional Textons"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A unified model to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions is provided."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35175118"
                        ],
                        "name": "F. Cohen",
                        "slug": "F.-Cohen",
                        "structuredName": {
                            "firstName": "Fernand",
                            "lastName": "Cohen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47774603"
                        ],
                        "name": "Z. Fan",
                        "slug": "Z.-Fan",
                        "structuredName": {
                            "firstName": "Zhigang",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Fan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29499256,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a6068764ea4742921c54afbe34143dd7ac41f2ca",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of classifying a textured image which might be subject to unknown rotation and magnification scale changes into one of C possible texture classes is discussed. The texture classes are modeled by Gaussian Markov random fields. A Bayes decision rule based on the generalized likelihood function is used to classify a given test sample. A maximum-likelihood estimate for the scale and rotation parameters for each of the C texture classes is computed under the assumption that the observed texture came from a particular unrotated and unscaled texture model. The test texture is allocated to the class with the highest generalized likelihood function. The classification power of the method is demonstrated through extensive experimental results on natural texture from the Brodatz album as well as for the problem of fabric inspection.<<ETX>>"
            },
            "slug": "Rotation-and-scale-invariant-texture-classification-Cohen-Fan",
            "title": {
                "fragments": [],
                "text": "Rotation and scale invariant texture classification"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The problem of classifying a textured image which might be subject to unknown rotation and magnification scale changes into one of C possible texture classes is discussed and the classification power of the method is demonstrated through extensive experimental results on natural texture from the Brodatz album as well as for the problem of fabric inspection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1988 IEEE International Conference on Robotics and Automation"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8038506"
                        ],
                        "name": "B. Ginneken",
                        "slug": "B.-Ginneken",
                        "structuredName": {
                            "firstName": "Bram",
                            "lastName": "Ginneken",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ginneken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 622815,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "16ba88cb3c3a0438bd9e5ace9096f9655ddc63df",
            "isKey": false,
            "numCitedBy": 1074,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we investigate the visual appearance of real-world surfaces and the dependence of appearance on imaging conditions. We present a BRDF (bidirectional reflectance distribution function) database with reflectance measurements for over 60 different samples, each observed with over 200 different combinations of viewing and source directions. We fit the BRDF measurements to two recent models to obtain a BRDF parameter database. These BRDF parameters can be directly used for both image analysis and image synthesis. Finally, we present a BTF (bidirectional texture function) database with image textures from over 60 different samples, each observed with over 200 different combinations of viewing and source directions. Each of these unique databases has important implications for a variety of vision algorithms and each is made publicly available."
            },
            "slug": "Reflectance-and-texture-of-real-world-surfaces-Dana-Ginneken",
            "title": {
                "fragments": [],
                "text": "Reflectance and texture of real-world surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The visual appearance of real-world surfaces and the dependence of appearance on imaging conditions is investigated and a BRDF (bidirectional reflectance distribution function) database with reflectance measurements for over 60 different samples, each observed with over 200 different combinations of viewing and source directions is presented."
            },
            "venue": {
                "fragments": [],
                "text": "TOGS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2592461"
                        ],
                        "name": "A. Barla",
                        "slug": "A.-Barla",
                        "structuredName": {
                            "firstName": "Annalisa",
                            "lastName": "Barla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712692"
                        ],
                        "name": "F. Odone",
                        "slug": "F.-Odone",
                        "structuredName": {
                            "firstName": "Francesca",
                            "lastName": "Odone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Odone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716824"
                        ],
                        "name": "A. Verri",
                        "slug": "A.-Verri",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Verri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Verri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11143982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf26a593ceef822f666e1b472253614f946a255e",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning one class at a time can be seen as an effective solution to classification problems in which only the positive examples are easily identifiable. A kernel method to accomplish this goal consists of a representation stage - which computes the smallest sphere in feature space enclosingthe positive examples - and a classification stage - which uses the obtained sphere as a decision surface to determine the positivity of new examples. In this paper we describe a kernel well suited to represent, identify, and recognize 3D objects from unconstrained images. The kernel we introduce, based on Hausdorff distance, is tailored to deal with grey-level image matching. The effectiveness of the proposed method is demonstrated on several data sets of faces and objects of artistic relevance, like statues."
            },
            "slug": "Hausdorff-Kernel-for-3D-Object-Acquisition-and-Barla-Odone",
            "title": {
                "fragments": [],
                "text": "Hausdorff Kernel for 3D Object Acquisition and Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The kernel introduced, based on Hausdorff distance, is tailored to deal with grey-level image matching and is demonstrated on several data sets of faces and objects of artistic relevance, like statues."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2672681"
                        ],
                        "name": "G. O. Cula",
                        "slug": "G.-O.-Cula",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Cula",
                            "middleNames": [
                                "Oana"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. O. Cula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7356365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b45dc2f11ed201f192d9bec153fcca1ca95e460",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A bidirectional texture function (BTF) describes image texture as it varies with viewing and illumination direction. Many real world surfaces such as skin, fur, gravel, etc. exhibit fine-scale geometric surface detail. Accordingly, variations in appearance with viewing and illumination direction may be quite complex due to local foreshortening, masking and shadowing. Representations of surface texture that support robust recognition must account for these effects. We construct a representation which captures the underlying statistical distribution of features in the image texture as well as the variations in this distribution with viewing and illumination direction. The representation combines clustering to learn characteristic image features and principle components analysis to reduce the space of feature histograms. This representation is based on a core image set as determined by a quantitative evaluation of importance of individual images in the overall representation. The result is a compact representation and a recognition method where a single novel image of unknown viewing and illumination direction can be classified efficiently. The CUReT (Columbia-Utrecht reflectance and texture) database is used as a test set for evaluation of these methods."
            },
            "slug": "Compact-representation-of-bidirectional-texture-Cula-Dana",
            "title": {
                "fragments": [],
                "text": "Compact representation of bidirectional texture functions"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A representation is constructed which captures the underlying statistical distribution of features in the image texture as well as the variations in this distribution with viewing and illumination direction and is a compact representation and a recognition method where a single novel image of unknown viewing and illuminated direction can be classified efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891864"
                        ],
                        "name": "Gyuri Dork\u00f3",
                        "slug": "Gyuri-Dork\u00f3",
                        "structuredName": {
                            "firstName": "Gyuri",
                            "lastName": "Dork\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyuri Dork\u00f3"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2895738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9b052482992bc9f9ed106cf8cd95dd4548016ac",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a kernel method that allows to combine color and shape information for appearance-based object recognition. It doesn't require to define a new common representation, but use the power of kernels to combine different representations together in an effective manner. These results are achieved using results of statistical mechanics of spin glasses combined with Markov random fields via kernel functions. Experiments show an increase in recognition rate up to 5.92% with respect to conventional strategies."
            },
            "slug": "How-to-Combine-Color-and-Shape-Information-for-3D-Caputo-Dork\u00f3",
            "title": {
                "fragments": [],
                "text": "How to Combine Color and Shape Information for 3D Object Recognition: Kernels do the Trick"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A kernel method is presented that allows to combine color and shape information for appearance-based object recognition using results of statistical mechanics of spin glasses combined with Markov random fields via kernel functions."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 456211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70284b4fe852f472d4576c30f97a6fddbfef2aee",
            "isKey": false,
            "numCitedBy": 532,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We question the role that large scale filter banks have traditionally played in texture classification. It is demonstrated that textures can be classified using the joint distribution of intensity values over extremely compact neighborhoods (starting from as small as 3 /spl times/ 3 pixels square), and that this outperforms classification using filter banks with large support. We develop a novel texton based representation, which is suited to modeling this joint neighborhood distribution for MRFs. The representation is learnt from training images, and then used to classify novel images (with unknown viewpoint and lighting) into texture classes. The power of the method is demonstrated by classifying over 2800 images of all 61 textures present in the Columbia-Utrecht database. The classification performance surpasses that of recent state-of-the-art filter bank based classifiers such as Leung & Malik, Cula & Dana, and Varma & Zisserman."
            },
            "slug": "Texture-classification:-are-filter-banks-necessary-Varma-Zisserman",
            "title": {
                "fragments": [],
                "text": "Texture classification: are filter banks necessary?"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel texton based representation is developed, which is suited to modeling this joint neighborhood distribution for MRFs, and it is demonstrated that textures can be classified using the joint distribution of intensity values over extremely compact neighborhoods."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144522420"
                        ],
                        "name": "T. Ojala",
                        "slug": "T.-Ojala",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Ojala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ojala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145298122"
                        ],
                        "name": "D. Harwood",
                        "slug": "D.-Harwood",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Harwood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harwood"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26881819,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5985014dda6d502469614aae17349b4d08f9f74c",
            "isKey": false,
            "numCitedBy": 6554,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-comparative-study-of-texture-measures-with-based-Ojala-Pietik\u00e4inen",
            "title": {
                "fragments": [],
                "text": "A comparative study of texture measures with classification based on featured distributions"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111068362"
                        ],
                        "name": "Seunghyup Shin",
                        "slug": "Seunghyup-Shin",
                        "structuredName": {
                            "firstName": "Seunghyup",
                            "lastName": "Shin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seunghyup Shin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696605"
                        ],
                        "name": "T. Nishita",
                        "slug": "T.-Nishita",
                        "structuredName": {
                            "firstName": "Tomoyuki",
                            "lastName": "Nishita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nishita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11467825"
                        ],
                        "name": "Sung-yong Shin",
                        "slug": "Sung-yong-Shin",
                        "structuredName": {
                            "firstName": "Sung-yong",
                            "lastName": "Shin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sung-yong Shin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17057484,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a6aa4552f2187447853425d0b91a94b19f2f3059",
            "isKey": false,
            "numCitedBy": 1404,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-pixel-based-texture-synthesis-by-non-parametric-Shin-Nishita",
            "title": {
                "fragments": [],
                "text": "On pixel-based texture synthesis by non-parametric sampling"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144602022"
                        ],
                        "name": "K. Kim",
                        "slug": "K.-Kim",
                        "structuredName": {
                            "firstName": "Kwang",
                            "lastName": "Kim",
                            "middleNames": [
                                "In"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121267347"
                        ],
                        "name": "K. Jung",
                        "slug": "K.-Jung",
                        "structuredName": {
                            "firstName": "Keechul",
                            "lastName": "Jung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Jung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115290599"
                        ],
                        "name": "Se Hyun Park",
                        "slug": "Se-Hyun-Park",
                        "structuredName": {
                            "firstName": "Se",
                            "lastName": "Park",
                            "middleNames": [
                                "Hyun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Se Hyun Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70261685"
                        ],
                        "name": "Hang-Joon Kim",
                        "slug": "Hang-Joon-Kim",
                        "structuredName": {
                            "firstName": "Hang-Joon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hang-Joon Kim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8993231,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "025bcbb4913c1ac4c6ec511369c5e62079322e48",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the application of support vector machines (SVMs) in texture classification. Instead of relying on an external feature extractor, the SVM receives the gray-level values of the raw pixels, as SVMs can generalize well even in high-dimensional spaces. Furthermore, it is shown that SVMs can incorporate conventional texture feature extraction methods within their own architecture, while also providing solutions to problems inherent in these methods. One-against-others decomposition is adopted to apply binary SVMs to multitexture classification, plus a neural network is used as an arbitrator to make final classifications from several one-against-others SVM outputs. Experimental results demonstrate the effectiveness of SVMs in texture classification."
            },
            "slug": "Support-Vector-Machines-for-Texture-Classification-Kim-Jung",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines for Texture Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Experimental results demonstrate the effectiveness of SVMs in texture classification, and it is shown that SVMs can incorporate conventional texture feature extraction methods within their own architecture, while also providing solutions to problems inherent in these methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145246674"
                        ],
                        "name": "A. Heyden",
                        "slug": "A.-Heyden",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Heyden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Heyden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2561175"
                        ],
                        "name": "G. Sparr",
                        "slug": "G.-Sparr",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "Sparr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sparr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145118299"
                        ],
                        "name": "M. Nielsen",
                        "slug": "M.-Nielsen",
                        "structuredName": {
                            "firstName": "Mads",
                            "lastName": "Nielsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nielsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153623949"
                        ],
                        "name": "P. Johansen",
                        "slug": "P.-Johansen",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Johansen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Johansen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19228750,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "435ace68aa855103d76f869a88d34fee0771383b",
            "isKey": false,
            "numCitedBy": 1087,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel algorithm for recovering a smooth manifold of unknown dimension and topology from a set of points known to belong to it. Numerous applications in computer vision can be naturally interpreted as instanciations of this fundamental problem. Recently, a non-iterative discrete approach, tensor voting, has been introduced to solve this problem and has been applied successfully to various applications. As an alternative, we propose a variational formulation of this problem in the continuous setting and derive an iterative algorithm which approximates its solutions. This method and tensor voting are somewhat the differential and integral form of one another. Although iterative methods are slower in general, the strength of the suggested method is that it can easily be applied when the ambient space is not Euclidean, which is important in many applications. The algorithm consists in solving a partial differential equation that performs a special anisotropic diffusion on an implicit representation of the known set of points. This results in connecting isolated neighbouring points. This approach is very simple, mathematically sound, robust and powerful since it handles in a homogeneous way manifolds of arbitrary dimension and topology, embedded in Euclidean or non-Euclidean spaces, with or without border. We shall present this approach and demonstrate both its benefits and shortcomings in two different contexts: (i) data visual analysis, (ii) skin detection in color images."
            },
            "slug": "Computer-Vision-\u2014-ECCV-2002-Heyden-Sparr",
            "title": {
                "fragments": [],
                "text": "Computer Vision \u2014 ECCV 2002"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A novel algorithm for recovering a smooth manifold of unknown dimension and topology from a set of points known to belong to it is presented and it can easily be applied when the ambient space is not Euclidean, which is important in many applications."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15208439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "400736e84b3b04ffa41542cf62b6546e57f590f7",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a framework for texture recognition based on local affine-invariant descriptors and their spatial layout. At modelling time, a generative model of local descriptors is learned from sample images using the EM algorithm. The EM framework allows the incorporation of unsegmented multitexture images into the training set. The second modelling step consists of gathering co-occurrence statistics of neighboring descriptors. At recognition time, initial probabilities computed from the generative model are refined using a relaxation step that incorporates co-occurrence statistics. Performance is evaluated on images of an indoor scene and pictures of wild animals."
            },
            "slug": "Affine-invariant-local-descriptors-and-neighborhood-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Affine-invariant local descriptors and neighborhood statistics for texture recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A framework for texture recognition based on local affine-invariant descriptors and their spatial layout is presented and initial probabilities computed from the generative model are refined using a relaxation step that incorporates co-occurrence statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716824"
                        ],
                        "name": "A. Verri",
                        "slug": "A.-Verri",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Verri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Verri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1375403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fda96d554f4e5a21e35bf33b9720141da47664b",
            "isKey": false,
            "numCitedBy": 865,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines (SVMs) have been recently proposed as a new technique for pattern recognition. Intuitively, given a set of points which belong to either of two classes, a linear SVM finds the hyperplane leaving the largest possible fraction of points of the same class on the same side, while maximizing the distance of either class from the hyperplane. The hyperplane is determined by a subset of the points of the two classes, named support vectors, and has a number of interesting theoretical properties. In this paper, we use linear SVMs for 3D object recognition. We illustrate the potential of SVMs on a database of 7200 images of 100 different objects. The proposed system does not require feature extraction and performs recognition on images regarded as points of a space of high dimension without estimating pose. The excellent recognition rates achieved in all the performed experiments indicate that SVMs are well-suited for aspect-based recognition."
            },
            "slug": "Support-Vector-Machines-for-3D-Object-Recognition-Pontil-Verri",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines for 3D Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The proposed system does not require feature extraction and performs recognition on images regarded as points of a space of high dimension without estimating pose, indicating that SVMs are well-suited for aspect-based recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739548"
                        ],
                        "name": "Mario Fritz",
                        "slug": "Mario-Fritz",
                        "structuredName": {
                            "firstName": "Mario",
                            "lastName": "Fritz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mario Fritz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901127"
                        ],
                        "name": "E. Hayman",
                        "slug": "E.-Hayman",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Hayman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hayman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270435"
                        ],
                        "name": "J. Eklundh",
                        "slug": "J.-Eklundh",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Eklundh",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eklundh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 39386437,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "e00cb4517022420d1bbd03a0e99a96467ce91528",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This document provides a brief Users\u2019 Guide to the KTH-TIPS image database (KTH is the abbreviation of our university, and TIPS stands for Textures under varying Illumination, Pose and Scale). The guide describes which materials are contained in the database (Section 2), how images were acquired (Section 3) and subsequently cropped to remove the background (Section 4), and we also discuss some non-ideal artifacts, like poor focus, in some pictures (Section 5). This document concludes by outlining how we intend to extend the database in the future (Section 6)."
            },
            "slug": "THE-KTH-TIPS-database-Fritz-Hayman",
            "title": {
                "fragments": [],
                "text": "THE KTH-TIPS database"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This guide describes which materials are contained in the KTH-TIPS database, how images were acquired and subsequently cropped to remove the background, and some non-ideal artifacts, like poor focus, in some pictures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23544307,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d09deeb2eb6b1175d13817284d967189a83dbdde",
            "isKey": false,
            "numCitedBy": 1463,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional classification approaches generalize poorly on image classification tasks, because of the high dimensionality of the feature space. This paper shows that support vector machines (SVM's) can generalize well on difficult image classification problems where the only features are high dimensional histograms. Heavy-tailed RBF kernels of the form K(x, y) = e(-rho)Sigma(i)/xia-yia/b with a < or = 1 and b < or = 2 are evaluated on the classification of images extracted from the Corel stock photo collection and shown to far outperform traditional polynomial or Gaussian radial basis function (RBF) kernels. Moreover, we observed that a simple remapping of the input x(i)-->x(i)(a) improves the performance of linear SVM's to such an extend that it makes them, for this problem, a valid alternative to RBF kernels."
            },
            "slug": "Support-vector-machines-for-histogram-based-image-Chapelle-Haffner",
            "title": {
                "fragments": [],
                "text": "Support vector machines for histogram-based image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is observed that a simple remapping of the input x(i)-->x(i)(a) improves the performance of linear SVM's to such an extend that it makes them, for this problem, a valid alternative to RBF kernels."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 723210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b02f474196fb9bd61fa3d418a7ba8ac500e8d422",
            "isKey": false,
            "numCitedBy": 2940,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of \u03b3-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure.Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation.In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments."
            },
            "slug": "Feature-Detection-with-Automatic-Scale-Selection-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Feature Detection with Automatic Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation and how it can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2296344"
                        ],
                        "name": "QingDong Fu",
                        "slug": "QingDong-Fu",
                        "structuredName": {
                            "firstName": "QingDong",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "QingDong Fu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3062639"
                        ],
                        "name": "L. Gu",
                        "slug": "L.-Gu",
                        "structuredName": {
                            "firstName": "Lie",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49096825"
                        ],
                        "name": "Yimin Cheng",
                        "slug": "Yimin-Cheng",
                        "structuredName": {
                            "firstName": "Yimin",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yimin Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16401099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58e47bd5905d01022f33965f81047867ef54d69e",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Face images are subject to changes in view and illumination. Such changes cause data distribution to be highly nonlinear and complex in the image space. It is desirable to learn a nonlinear mapping from the image space to a low dimensional space such that the distribution becomes simpler tighter and therefore more predictable for better modeling effaces. In this paper we present a kernel machine based approach for learning such nonlinear mappings. The aim is to provide an effective view-based representation for multi-view face detection and pose estimation. Assuming that the view is partitioned into a number of distinct ranges, one nonlinear view-subspace is learned for each (range of) view from a set of example face images of that view (range), by using kernel principal component analysis (KPCA). Projections of the data onto the view-subspaces are then computed as view-based nonlinear features. Multi-view face detection and pose estimation are performed by classifying a face into one of the facial views or into the nonface class, by using a multi-class kernel support vector classifier (KSVC). Experimental results show that fusion of evidences from multi-views can produce better results than using the result from a single view; and that our approach yields high detection and low false alarm rates in face detection and good accuracy in pose estimation, in comparison with the linear counterpart composed of linear principal component analysis (PCA) feature extraction and Fisher linear discriminant based classification (FLDC)."
            },
            "slug": "Kernel-machine-based-learning-for-multi-view-face-Li-Fu",
            "title": {
                "fragments": [],
                "text": "Kernel machine based learning for multi-view face detection and pose estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental results show that fusion of evidences from multi-views can produce better results than using the result from a single view, and that this kernel machine based approach for learning nonlinear mappings for multi-view face detection and pose estimation yields high detection and low false alarm rates."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102944324"
                        ],
                        "name": "Vapnik",
                        "slug": "Vapnik",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Vapnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17719593,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3473ce22ada00842b355883a5ddde5a8c7c76ba6",
            "isKey": false,
            "numCitedBy": 271,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional classification approaches generalize poorly on image classification tasks, because of the high dimensionality of the feature space. This paper shows that Support Vector Machines (SVM) can generalize well on difficult image classification problems where the only features are high dimensional histograms. Heavy-tailed RBF kernels of the form K(x,y) = e\u2212\u03c1 P i |x i \u2212y i | with a \u2264 1 and b \u2264 2 are evaluated on the classification of images extracted from the Corel Stock Photo Collection and shown to far outperform traditional polynomial or Gaussian RBF kernels. Moreover, we observed that a simple remapping of the input xi \u2192 x a i improves the performance of linear SVMs to such an extend that it makes them, for this problem, a valid alternative to RBF kernels. keywords: Support Vector Machines, Radial Basis Functions, Image Histogram, Image Classification, Corel."
            },
            "slug": "SVMs-for-Histogram-Based-Image-Classification-Chapelle-Haffner",
            "title": {
                "fragments": [],
                "text": "SVMs for Histogram Based Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper shows that Support Vector Machines (SVM) can generalize well on difficult image classification problems where the only features are high dimensional histograms and observes that a simple remapping of the input xi \u2192 x a i improves the performance of linear SVMs to such an extend that it makes them a valid alternative to RBF kernels."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326400"
                        ],
                        "name": "B. Julesz",
                        "slug": "B.-Julesz",
                        "structuredName": {
                            "firstName": "B\u00e9la",
                            "lastName": "Julesz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Julesz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4327694,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "8999355e47248bc60f5768fc2168fd28295b5f27",
            "isKey": false,
            "numCitedBy": 1772,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Research with texture pairs having identical second-order statistics has revealed that the pre-attentive texture discrimination system cannot globally process third- and higher-order statistics, and that discrimination is the result of a few local conspicuous features, called textons. It seems that only the first-order statistics of these textons have perceptual significance, and the relative phase between textons cannot be perceived without detailed scrutiny by focal attention."
            },
            "slug": "Textons,-the-elements-of-texture-perception,-and-Julesz",
            "title": {
                "fragments": [],
                "text": "Textons, the elements of texture perception, and their interactions"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Research with texture pairs having identical second-order statistics has revealed that the pre-attentive texture discrimination system cannot globally process third- and higher- order statistics, and that discrimination is the result of a few local conspicuous features, called textons."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2667432"
                        ],
                        "name": "D. Roobaert",
                        "slug": "D.-Roobaert",
                        "structuredName": {
                            "firstName": "Danny",
                            "lastName": "Roobaert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roobaert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682587"
                        ],
                        "name": "M. Zillich",
                        "slug": "M.-Zillich",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Zillich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zillich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270435"
                        ],
                        "name": "J. Eklundh",
                        "slug": "J.-Eklundh",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Eklundh",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eklundh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29736465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0cf70a08a6042f523b9b0716477c6c2c16b4b9f6",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Pursuing the goals of absolute simplicity of a detection/recognition system, a pure learning approach to background-invariance and visual 3D object detection/recognition is proposed. The approach relies on learning from examples only, and does not encode any domain knowledge (e.g. in the form of intermediate representations, or by solving segmentation or correspondence problems). To make the pure learning approach practically feasible, we propose the BW training method for teaching an object recognition system background-invariance. The method consist of pedagogically training the system, once with a black background and once with a white background. The method is formulated within the framework of support vector learning. Evaluation is performed with the Columbia Image (COIL) database, that is extended with different classes of cluttered backgrounds. Using this pure learning approach, a system is proposed that is able to perform 3D object detection/recognition successfully in real-world scenes, with varying illuminations and backgrounds. The system is able to perform this task in real-time."
            },
            "slug": "A-pure-learning-approach-to-background-invariant-Roobaert-Zillich",
            "title": {
                "fragments": [],
                "text": "A pure learning approach to background-invariant object recognition using pedagogical support vector learning"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The BW training method for teaching an object recognition system background-invariance is proposed, and a system is proposed that is able to perform 3D object detection/recognition successfully in real-world scenes, with varying illuminations and backgrounds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26883091"
                        ],
                        "name": "Topi M\u00e4enp\u00e4\u00e4",
                        "slug": "Topi-M\u00e4enp\u00e4\u00e4",
                        "structuredName": {
                            "firstName": "Topi",
                            "lastName": "M\u00e4enp\u00e4\u00e4",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Topi M\u00e4enp\u00e4\u00e4"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145962204"
                        ],
                        "name": "M. Pietik\u00e4inen",
                        "slug": "M.-Pietik\u00e4inen",
                        "structuredName": {
                            "firstName": "Matti",
                            "lastName": "Pietik\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pietik\u00e4inen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18070434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "515187168e1798aa217107dd8be2a89d66e261ed",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents two novel ways of extending the local binary pattern (LBP) texture analysis operator to multiple scales. First, large-scale texture patterns are detected by combining exponentially growing circular neighborhoods with Gaussian low-pass filtering. Second, cellular automata are proposed as a way of compactly encoding arbitrarily large circular neighborhoods. The performance of the extensions is evaluated in classifying natural textures from the Outex database."
            },
            "slug": "Multi-scale-Binary-Patterns-for-Texture-Analysis-M\u00e4enp\u00e4\u00e4-Pietik\u00e4inen",
            "title": {
                "fragments": [],
                "text": "Multi-scale Binary Patterns for Texture Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "Two novel ways of extending the local binary pattern (LBP) texture analysis operator to multiple scales are presented, combining exponentially growing circular neighborhoods with Gaussian low-pass filtering and cellular automata are proposed as a way of compactly encoding arbitrarily large circular neighborhoods."
            },
            "venue": {
                "fragments": [],
                "text": "SCIA"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10617783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b3dbc36ae4d8171f9a4179001e37299554f1652",
            "isKey": false,
            "numCitedBy": 344,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper makes two contributions: it provides (1) an operational definition of textons, the putative elementary units of texture perception, and (2) an algorithm for partitioning the image into disjoint regions of coherent brightness and texture, where boundaries of regions are defined by peaks in contour orientation energy and differences in texton densities across the contour. B. Julesz (1981) introduced the term texton, analogous to a phoneme in speech recognition, but did not provide an operational definition for gray-level images. We re-invent textons as frequently co-occurring combinations of oriented linear filter outputs. These can be learned using a K-means approach. By mapping each pixel to its nearest texton, the image can be analyzed into texton channels, each of which is a point set where discrete techniques such as Voronoi diagrams become applicable. Local histograms of texton frequencies can be used with a /spl chi//sup 2/ test for significant differences to find texture boundaries. Natural images contain both textured and untextured regions, so we combine this cue with that of the presence of peaks of contour energy derived from outputs of odd- and even-symmetric oriented Gaussian derivative filters. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on a statistical test for isotropy of Delaunay neighbors. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown."
            },
            "slug": "Textons,-contours-and-regions:-cue-integration-in-Malik-Belongie",
            "title": {
                "fragments": [],
                "text": "Textons, contours and regions: cue integration in image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "An operational definition of textons, the putative elementary units of texture perception, and an algorithm for partitioning the image into disjoint regions of coherent brightness and texture, where boundaries of regions are defined by peaks in contour orientation energy and differences in texton densities across the contour."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108313577"
                        ],
                        "name": "Sameer Singh",
                        "slug": "Sameer-Singh",
                        "structuredName": {
                            "firstName": "Sameer",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sameer Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809793"
                        ],
                        "name": "J. Haddon",
                        "slug": "J.-Haddon",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Haddon",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Haddon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002296"
                        ],
                        "name": "Markos Markou",
                        "slug": "Markos-Markou",
                        "structuredName": {
                            "firstName": "Markos",
                            "lastName": "Markou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markos Markou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1175022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a52c7418f6b3b0bcf2ca9190bc70c136b00296b1",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nearest-neighbour-classifiers-in-natural-scene-Singh-Haddon",
            "title": {
                "fragments": [],
                "text": "Nearest-neighbour classifiers in natural scene analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50591689"
                        ],
                        "name": "B. S. Manjunath",
                        "slug": "B.-S.-Manjunath",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Manjunath",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Manjunath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15171942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2989b07819dfd279222a3755d3b7862f1a1a7f53",
            "isKey": false,
            "numCitedBy": 4175,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Image content based retrieval is emerging as an important research area with application to digital libraries and multimedia databases. The focus of this paper is on the image processing aspects and in particular using texture information for browsing and retrieval of large image data. We propose the use of Gabor wavelet features for texture analysis and provide a comprehensive experimental evaluation. Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy. An application to browsing large air photos is illustrated."
            },
            "slug": "Texture-Features-for-Browsing-and-Retrieval-of-Data-Manjunath-Ma",
            "title": {
                "fragments": [],
                "text": "Texture Features for Browsing and Retrieval of Image Data"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Comparisons with other multiresolution texture features using the Brodatz texture database indicate that the Gabor features provide the best pattern retrieval accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718206"
                        ],
                        "name": "F. Graham",
                        "slug": "F.-Graham",
                        "structuredName": {
                            "firstName": "Fan",
                            "lastName": "Graham",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Graham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14503164,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb22aec624fe953764777bcf9beef9b83e59efed",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Fowlkes et al. [7] recently introduced an approximation to the Normalized Cut (NCut) grouping algorithm [18] based on random subsampling and the Nystrom extension. As presented, their method is restricted to the case where W, the weighted adjacency matrix, is positive definite. Although many common measures of image similarity (i.e. kernels) are positive definite, a popular example being Gaussian-weighted distance, there are important cases that are not. In this work, we present a modification to Nystrom-NCut that does not require W to be positive definite. The modification only affects the orthogonalization step, and in doing so it necessitates one additional O(m3) operation, where m is the number of random samples used in the approximation. As such it is of interest to know which kernels are positive definite and which are indefinite. In addressing this issue, we further develop connections between NCut and related methods in the kernel machines literature. We provide a proof that the Gaussian-weighted chi-squared kernel is positive definite, which has thus far only been conjectured. We also explore the performance of the approximation algorithm on a variety of grouping cues including contour, color and texture."
            },
            "slug": "Spectral-Partitioning-with-Indefinite-Kernels-Using-Belongie-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Spectral Partitioning with Indefinite Kernels Using the Nystr\u00f6m Extension"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A modification to Nystrom-NCut is presented that does not require W to be positive definite, and a proof that the Gaussian-weighted chi-squared kernel is positive definite is provided, which has thus far only been conjectured."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14727192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c04f8002e24a8c09bfbfedca3c6c346fe1e5d53",
            "isKey": false,
            "numCitedBy": 13352,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "From the publisher: This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software."
            },
            "slug": "An-Introduction-to-Support-Vector-Machines-and-Cristianini-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory, and will guide practitioners to updated literature, new applications, and on-line software."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1204938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32484f6d111bf21f1395a34a087991a9041dd0ae",
            "isKey": false,
            "numCitedBy": 1876,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new learning architecture: the Decision Directed Acyclic Graph (DDAG), which is used to combine many two-class classifiers into a multiclass classifier. For an N-class problem, the DDAG contains N(N - 1)/2 classifiers, one for each pair of classes. We present a VC analysis of the case when the node classifiers are hyperplanes; the resulting bound on the test error depends on N and on the margin achieved at the nodes, but not on the dimension of the space. This motivates an algorithm, DAGSVM, which operates in a kernel-induced feature space and uses two-class maximal margin hyperplanes at each decision-node of the DDAG. The DAGSVM is substantially faster to train and evaluate than either the standard algorithm or Max Wins, while maintaining comparable accuracy to both of these algorithms."
            },
            "slug": "Large-Margin-DAGs-for-Multiclass-Classification-Platt-Cristianini",
            "title": {
                "fragments": [],
                "text": "Large Margin DAGs for Multiclass Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm, DAGSVM, is presented, which operates in a kernel-induced feature space and uses two-class maximal margin hyperplanes at each decision-node of the DDAG, which is substantially faster to train and evaluate than either the standard algorithm or Max Wins, while maintaining comparable accuracy to both of these algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815078"
                        ],
                        "name": "S. Avidan",
                        "slug": "S.-Avidan",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Avidan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Avidan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8281525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "836d5ddbecdb51f9ca21255743e399a267f7f6a4",
            "isKey": false,
            "numCitedBy": 761,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Support Vector Tracking (SVT) integrates the Support Vector Machine (SVM) classifier into an optic-flow-based tracker. Instead of minimizing an intensity difference function between successive frames, SVT maximizes the SVM classification score. To account for large motions between successive frames, we build pyramids from the support vectors and use a coarse-to-fine approach in the classification stage. We show results of using SVT for vehicle tracking in image sequences."
            },
            "slug": "Support-vector-tracking-Avidan",
            "title": {
                "fragments": [],
                "text": "Support vector tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "Support Vector Tracking integrates the Support Vector Machine (SVM) classifier into an optic-flow-based tracker and maximizes the SVM classification score to account for large motions between successive frames."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": false,
            "numCitedBy": 26322,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52301815"
                        ],
                        "name": "N. S. Barnett",
                        "slug": "N.-S.-Barnett",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Barnett",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. S. Barnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1997442"
                        ],
                        "name": "S. Dragomir",
                        "slug": "S.-Dragomir",
                        "structuredName": {
                            "firstName": "Sever",
                            "lastName": "Dragomir",
                            "middleNames": [
                                "Silvestru"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dragomir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 116073922,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "98e84e80e7126805de225b263813bfb2cf596a26",
            "isKey": false,
            "numCitedBy": 8206,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "vii"
            },
            "slug": "Private-communication-Barnett-Dragomir",
            "title": {
                "fragments": [],
                "text": "Private communication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64718884,
            "fieldsOfStudy": [],
            "id": "c780910ff88632af24f11fd5e17ed8c86ea84828",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056954"
                        ],
                        "name": "A. Penirschke",
                        "slug": "A.-Penirschke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Penirschke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Penirschke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712844"
                        ],
                        "name": "M. Chantler",
                        "slug": "M.-Chantler",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Chantler",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chantler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144877016"
                        ],
                        "name": "M. Petrou",
                        "slug": "M.-Petrou",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Petrou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Petrou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117071824,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca5118d86d59841adfe44762a37bb086e292d2c8",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Illuminant-Rotation-Invariant-Classification-of-3D-Penirschke-Chantler",
            "title": {
                "fragments": [],
                "text": "Illuminant Rotation Invariant Classification of 3D Surface Textures using Lissajou's Ellepses"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "P. Brodatz. Textures. Dover"
            },
            "venue": {
                "fragments": [],
                "text": "P. Brodatz. Textures. Dover"
            },
            "year": 1966
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 34,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/On-the-Significance-of-Real-World-Conditions-for-Hayman-Caputo/91e4c8003c492f9efc22be0d5c403d7b8275199a?sort=total-citations"
}