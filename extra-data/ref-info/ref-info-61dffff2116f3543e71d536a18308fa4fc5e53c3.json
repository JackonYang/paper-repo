{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289329"
                        ],
                        "name": "S. Riezler",
                        "slug": "S.-Riezler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Riezler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riezler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5599296,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f34268b463e0219a57d049aac6fd165f4afc4d9",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 167,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses two central problems for probabilistic processing models: parameter estimation from incomplete data and efficient retrieval of most probable analyses. These questions have been answered satisfactorily only for probabilistic regular and context-free models. We address these problems for a more expressive probabilistic constraint logic programming model. We present a log-linear probability model for probabilistic constraint logic programming. On top of this model we define an algorithm to estimate the parameters and to select the properties of log-linear models from incomplete data. This algorithm is an extension of the improved iterative scaling algorithm of Della-Pietra, Della-Pietra, and Lafferty (1995). Our algorithm applies to log-linear models in general and is accompanied with suitable approximation methods when applied to large data spaces. Furthermore, we present an approach for searching for most probable analyses of the probabilistic constraint logic programming model. This method can be applied to the ambiguity resolution problem in natural language processing applications."
            },
            "slug": "Probabilistic-Constraint-Logic-Programming-Riezler",
            "title": {
                "fragments": [],
                "text": "Probabilistic Constraint Logic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "An algorithm to estimate the parameters and to select the properties of log-linear models from incomplete data and an approach for searching for most probable analyses of the probabilistic constraint logic programming model are presented."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b951b9f78b98a186ba259027996a48e4189d37e5",
            "isKey": false,
            "numCitedBy": 1305,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a technique for constructing random fields from a set of training samples. The learning paradigm builds increasingly complex fields by allowing potential functions, or features, that are supported by increasingly large subgraphs. Each feature has a weight that is trained by minimizing the Kullback-Leibler divergence between the model and the empirical distribution of the training data. A greedy algorithm determines how features are incrementally added to the field and an iterative scaling algorithm is used to estimate the optimal values of the weights. The random field models and techniques introduced in this paper differ from those common to much of the computer vision literature in that the underlying random fields are non-Markovian and have a large number of parameters that must be estimated. Relations to other learning approaches, including decision trees, are given. As a demonstration of the method, we describe its application to the problem of automatic word classification in natural language processing."
            },
            "slug": "Inducing-Features-of-Random-Fields-Pietra-Pietra",
            "title": {
                "fragments": [],
                "text": "Inducing Features of Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The random field models and techniques introduced in this paper differ from those common to much of the computer vision literature in that the underlying random fields are non-Markovian and have a large number of parameters that must be estimated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289329"
                        ],
                        "name": "S. Riezler",
                        "slug": "S.-Riezler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Riezler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riezler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60eb9c07a4e0b4016826ff08f4fcb91e966933c8",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Constraint logic grammars provide a powerful formalism for expressing complex logical descriptions of natural language phenomena in exact terms. Describing some of these phenomena may, however, require some form of graded distinctions which are not provided by such grammars. Recent approaches to weighted constraint logic grammars attempt to address this issue by adding numerical calculation schemata to the deduction scheme of the underlying CLP framework."
            },
            "slug": "Quantitative-Constraint-Logic-Programming-for-Riezler",
            "title": {
                "fragments": [],
                "text": "Quantitative Constraint Logic Programming for Weighted Grammar Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Current approaches to weighted constraint logic grammars attempt to address this issue by adding numerical calculation schemata to the deduction scheme of the underlying CLP framework."
            },
            "venue": {
                "fragments": [],
                "text": "LACL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144134436"
                        ],
                        "name": "K. Mark",
                        "slug": "K.-Mark",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Mark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111174146"
                        ],
                        "name": "Michael Miller",
                        "slug": "Michael-Miller",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862374"
                        ],
                        "name": "U. Grenander",
                        "slug": "U.-Grenander",
                        "structuredName": {
                            "firstName": "Ulf",
                            "lastName": "Grenander",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Grenander"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1882833"
                        ],
                        "name": "S. Abney",
                        "slug": "S.-Abney",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Abney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Abney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 53
                            }
                        ],
                        "text": "Figure 1 Statistical dependencies under the model of Mark et al. (1992)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16374706,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b72788ad36be617b19d0c33148becf5e89dae58a",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A new language model incorporating both N-gram and context-free ideas is proposed. This constrained context-free model is specified by a stochastic context-free prior distribution with N-gram frequency constraints. The resulting distribution is a Markov random field. Algorithms for sampling from this distribution and estimating the parameters of the model are presented."
            },
            "slug": "Parameter-Estimation-for-Constrained-Context-Free-Mark-Miller",
            "title": {
                "fragments": [],
                "text": "Parameter Estimation for Constrained Context-Free Language Models"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A new language model incorporating both N-gram and context-free ideas is proposed, specified by a stochastic context- free prior distribution with N- gram frequency constraints, which is a Markov random field."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895292"
                        ],
                        "name": "Chris Brew",
                        "slug": "Chris-Brew",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Brew",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Brew"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5316292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c17fcc6bc26a1911b36d93c7d7da4cdd9263a53",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we provide a probabilistic interpretation for typed feature structures very similar to those used by Pollard and Sag. We begin with a version of the interpretation which lacks a treatment of re-entrant feature structures, then provide an extended interpretation which allows them. We sketch algorithms allowing the numerical parameters of our probabilistic interpretations of HPSG to be estimated from corpora."
            },
            "slug": "Stochastic-HPSG-Brew",
            "title": {
                "fragments": [],
                "text": "Stochastic HPSG"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper begins with a version of the interpretation which lacks a treatment of re-entrant feature structures, then provides an extended interpretation which allows them, and sketches algorithms allowing the numerical parameters of the probabilistic interpretations of HPSG to be estimated from corpora."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48377731"
                        ],
                        "name": "G. Winkler",
                        "slug": "G.-Winkler",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Winkler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Winkler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45306254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "769a3188b73fdd9c5ea10970989827bd6d5c769d",
            "isKey": false,
            "numCitedBy": 697,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The book is mainly concerned with the mathematical foundations of Bayesian image analysis and its algorithms. This amounts to the study of Markov random fields and dynamic Monte Carlo algorithms like sampling, simulated annealing and stochastic gradient algorithms. The approach is introductory and elementary: given basic concepts from linear algebra and real analysis it is self-contained. No previous knowledge from image analysis is required. Knowledge of elementary probability theory and statistics is certainly beneficial but not absolutely necessary. The necessary background from imaging is sketched and illustrated by a number of concrete applications like restoration, texture segmentation and motion analysis."
            },
            "slug": "Image-analysis,-random-fields-and-dynamic-Monte-a-Winkler",
            "title": {
                "fragments": [],
                "text": "Image analysis, random fields and dynamic Monte Carlo methods: a mathematical introduction"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The book is mainly concerned with the mathematical foundations of Bayesian image analysis and its algorithms, which amounts to the study of Markov random fields and dynamic Monte Carlo algorithms like sampling, simulated annealing and stochastic gradient algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Applications of mathematics"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "The estimation algorithm is adapted from Della Pietra, Della Pietra, and Lafferty [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "Methods for doing both are given in a recent paper by Della Pietra, Della Pietra, and Lafferty [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "Recent work by Della Pietra, Della Pietra, and Lafferty [5] (henceforth, DDL) also applies random fields to natural language processing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 32
                            }
                        ],
                        "text": "In the application discussed by Della Pietra, Della Pietra, and Lafferty (representing English orthographic constraints), Gibbs sampling can be used to estimate the needed expectations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 115
                            }
                        ],
                        "text": "This work has greatly profited from the comments, criticism, and suggestions of a number of people, including John Lafferty, Stanley Peters, Hans Uszkoreit, and other members of the audience for talks I gave at Saarbru\u0308cken and Tu\u0308bingen."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inducing features of random fields. tech report"
            },
            "venue": {
                "fragments": [],
                "text": "CMU-CS-95-144, CMU,"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118600561"
                        ],
                        "name": "P. Lance",
                        "slug": "P.-Lance",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Lance",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lance"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 48
                            }
                        ],
                        "text": "The theory of random elds can be traced back to (Gibbs, 1902); indeed, the probability distributions involved are known as Gibbs distributions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 22080008,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "04747d6c04170260a0acb11e37188d84d4248683",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "[Elementary-principles].-Lance",
            "title": {
                "fragments": [],
                "text": "[Elementary principles]."
            },
            "venue": {
                "fragments": [],
                "text": "La Revue du praticien"
            },
            "year": 1956
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 50
                            }
                        ],
                        "text": "The theory of random fields can be traced back to Gibbs (1902); indeed, the probability distributions involved are known as Gibbs distributions. To my knowledge, the first application of random fields to natural language was Mark et al. (1992). The problem of interest was how to combine a stochastic contextfree grammar with n-gram language models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 50
                            }
                        ],
                        "text": "The theory of random fields can be traced back to Gibbs (1902); indeed, the probability distributions involved are known as Gibbs distributions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Elementary Principles of Statistical Mechanics"
            },
            "venue": {
                "fragments": [],
                "text": "Yale University Press, New Haven, CT."
            },
            "year": 1902
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic Constraint Logic Programming. Arbeitspapiere des Sonderforschungsbereichs 340, Bericht Nr"
            },
            "venue": {
                "fragments": [],
                "text": "Probabilistic Constraint Logic Programming. Arbeitspapiere des Sonderforschungsbereichs 340, Bericht Nr"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards probabilistic extensions of constraint-based grammars"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report Deliverable R1.2.B, DYANA-2."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Quantitative constraint logic programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of EACL-95"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of EACL-95"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "Maximum entropy distributions for contextfree languages are discussed in a paper by Miller and O\u2019Sullivan [4], though a number of technical questions arise that I do not wish to pursue here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Entropies, combinatorics and probabilities of context-free branching processes"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report ESSRL-90-16,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The fact that attribute-value grammars generate constrained languages makes Gibbs sampling inapplicable, but I show how a variant of Gibbs sampling, the Metropolis-Hastings algorithm, can be used instead."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Quantitative constraint logic programming for Abney Stochastic Attribute-Value Grammars weighted grammar applications. Talk given at LACL"
            },
            "venue": {
                "fragments": [],
                "text": "Quantitative constraint logic programming for Abney Stochastic Attribute-Value Grammars weighted grammar applications. Talk given at LACL"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Stochastic-Attribute-Value-Grammars-Abney/61dffff2116f3543e71d536a18308fa4fc5e53c3?sort=total-citations"
}