{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "(The detector in [9] is reported to employ 6061 features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "Of particular interest is the improvement over [9] even though we employ fewer features overall."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 84
                            }
                        ],
                        "text": "Figure 7 also depicts the ROC for a hard cascade trained in the manner described in [9] using the identical training set, feature set and based on the same boosting algorithm as that of the Soft Cascade."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2715202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63",
            "isKey": true,
            "numCitedBy": 17884,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection."
            },
            "slug": "Rapid-object-detection-using-a-boosted-cascade-of-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Rapid object detection using a boosted cascade of simple features"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates and the introduction of a new image representation called the \"integral image\" which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "Decrease the weights of all samples correctly classified byhj as in [10]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 235084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cb4d685b47001652b29dc41c1b3e786277e7647",
            "isKey": false,
            "numCitedBy": 4016,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features and yields extremely efficient classifiers [4]. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performance comparable to the best previous systems [16, 11, 14, 10, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second. Author email: fPaul.Viola,Mike.J.Jonesg@compaq.com c Compaq Computer Corporation, 2001 This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of the Cambridge Research Laboratory of Compaq Computer Corporation in Cambridge, Massachusetts; an acknowledgment of the authors and individual contributors to the work; and all applicable portions of the copyright notice. Copying, reproducing, or republishing for any other purpose shall require a license with payment of fee to the Cambridge Research Laboratory. All rights reserved. CRL Technical reports are available on the CRL\u2019s web page at http://crl.research.compaq.com. Compaq Computer Corporation Cambridge Research Laboratory One Cambridge Center Cambridge, Massachusetts 02142 USA"
            },
            "slug": "Robust-Real-time-Object-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-time Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates is described, with the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One important advantage of our method is that it enables systematic exploration of theROC Surface, which characterizes the trade-off between accuracy and speed for a given classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14133530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36cd88ed2c17a596001e9c7d89533ac46c28dec0",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a trainable object detector and its instantiations for detecting faces and cars at any size, location, and pose. To cope with variation in object orientation, the detector uses multiple classifiers, each spanning a different range of orientation. Each of these classifiers determines whether the object is present at a specified size within a fixed-size image window. To find the object at any location and size, these classifiers scan the image exhaustively.Each classifier is based on the statistics of localized parts. Each part is a transform from a subset of wavelet coefficients to a discrete set of values. Such parts are designed to capture various combinations of locality in space, frequency, and orientation. In building each classifier, we gathered the class-conditional statistics of these part values from representative samples of object and non-object images. We trained each classifier to minimize classification error on the training set by using Adaboost with Confidence-Weighted Predictions (Shapire and Singer, 1999). In detection, each classifier computes the part values within the image window and looks up their associated class-conditional probabilities. The classifier then makes a decision by applying a likelihood ratio test. For efficiency, the classifier evaluates this likelihood ratio in stages. At each stage, the classifier compares the partial likelihood ratio to a threshold and makes a decision about whether to cease evaluation\u2014labeling the input as non-object\u2014or to continue further evaluation. The detector orders these stages of evaluation from a low-resolution to a high-resolution search of the image. Our trainable object detector achieves reliable and efficient detection of human faces and passenger cars with out-of-plane rotation."
            },
            "slug": "Object-Detection-Using-the-Statistics-of-Parts-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "Object Detection Using the Statistics of Parts"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A trainable object detector achieves reliable and efficient detection of human faces and passenger cars with out-of-plane rotation."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "The results reported in [6] are comparable to our system."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "(Note that both [ 3] and [6] report results based on a reduced set with 5 images containing hand-drawn faces removed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2804322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "881f2d7b835a7d9dcf33ee2c3e5949c496c4f77b",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a cascaded method for object detection. This approach uses a novel organization of the first cascade stage called \"feature-centric\" evaluation which re-uses feature evaluations across multiple candidate windows. We minimize the cost of this evaluation through several simplifications: (1) localized lighting normalization, (2) representation of the classifier as an additive model and (3) discrete-valued features. Such a method also incorporates a unique feature representation. The early stages in the cascade use simple fast feature evaluations and the later stages use more complex discriminative features. In particular, we propose features based on sparse coding and ordinal relationships among filter responses. This combination of cascaded feature-centric evaluation with features of increasing complexity achieves both computational efficiency and accuracy. We describe object detection experiments on ten objects including faces and automobiles. These results include 97% recognition at equal error rate on the UIUC image database for car detection."
            },
            "slug": "Feature-centric-evaluation-for-efficient-cascaded-Schneiderman",
            "title": {
                "fragments": [],
                "text": "Feature-centric evaluation for efficient cascaded object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A cascaded method for object detection using a novel organization of the first cascade stage called \"feature-centric\" evaluation which re-uses feature evaluations across multiple candidate windows achieves both computational efficiency and accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808816"
                        ],
                        "name": "Jianxin Wu",
                        "slug": "Jianxin-Wu",
                        "structuredName": {
                            "firstName": "Jianxin",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxin Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31562428"
                        ],
                        "name": "M. D. Mullin",
                        "slug": "M.-D.-Mullin",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Mullin",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. D. Mullin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One important advantage of our method is that it enables systematic exploration of theROC Surface, which characterizes the trade-off between accuracy and speed for a given classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1886465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "349ed21e62643371342a050a9f25d23d0991ca0b",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Face detection is a canonical example of a rare event detection problem, in which target patterns occur with much lower frequency than non-targets. Out of millions of face-sized windows in an input image, for example, only a few will typically contain a face. Viola and Jones recently proposed a cascade architecture for face detection which successfully addresses the rare event nature of the task. A central part of their method is a feature selection algorithm based on AdaBoost. We present a novel cascade learning algorithm based on forward feature selection which is two orders of magnitude faster than the Viola-Jones approach and yields classifiers of equivalent quality. This faster method could be used for more demanding classification tasks, such as on-line learning."
            },
            "slug": "Learning-a-Rare-Event-Detection-Cascade-by-Direct-Wu-Rehg",
            "title": {
                "fragments": [],
                "text": "Learning a Rare Event Detection Cascade by Direct Feature Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel cascade learning algorithm based on forward feature selection which is two orders of magnitude faster than the Viola-Jones approach and yields classifiers of equivalent quality could be used for more demanding classification tasks, such as on-line learning."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111328101"
                        ],
                        "name": "Michael Jones",
                        "slug": "Michael-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2796017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b09ec0b350f8352bce46a2f5bf7ae97c83a7b9ca",
            "isKey": false,
            "numCitedBy": 11227,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the \u201cIntegral Image\u201d which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second."
            },
            "slug": "Robust-Real-Time-Face-Detection-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Robust Real-Time Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new image representation called the \u201cIntegral Image\u201d is introduced which allows the features used by the detector to be computed very quickly and a method for combining classifiers in a \u201ccascade\u201d which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684626"
                        ],
                        "name": "B. Heisele",
                        "slug": "B.-Heisele",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Heisele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Heisele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981539"
                        ],
                        "name": "Thomas Serre",
                        "slug": "Thomas-Serre",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Serre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Serre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066338222"
                        ],
                        "name": "S. Prentice",
                        "slug": "S.-Prentice",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Prentice",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Prentice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One important advantage of our method is that it enables systematic exploration of theROC Surface, which characterizes the trade-off between accuracy and speed for a given classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13885207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "432ed109ba59746af864af219cf4a2c533cecf44",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hierarchical-classification-and-feature-reduction-Heisele-Serre",
            "title": {
                "fragments": [],
                "text": "Hierarchical classification and feature reduction for fast face detection with support vector machines"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069928477"
                        ],
                        "name": "Rong Xiao",
                        "slug": "Rong-Xiao",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144850567"
                        ],
                        "name": "Long Zhu",
                        "slug": "Long-Zhu",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "In addition, the Soft Cascade shows an improvement over [ 12] despite the fact that [12] utilizes several optimizations to eliminate redundancy in the selected features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Xiao et al [12] propose the Boosting Chain which addresses the first disadvantage of the cascade, that is, that subsequent stages are unable to make use of information obtained in evaluating prior stages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5093465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76b9c2e83cd61029e36f1397286ac687d26957a6",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A general classification framework, called boosting chain, is proposed for learning boosting cascade. In this framework, a \"chain\" structure is introduced to integrate historical knowledge into successive boosting learning. Moreover, a linear optimization scheme is proposed to address the problems of redundancy in boosting learning and threshold adjusting in cascade coupling. By this means, the resulting classifier consists of fewer weak classifiers yet achieves lower error rates than boosting cascade in both training and test. Experimental comparisons of boosting chain and boosting cascade are provided through a face detection problem. The promising results clearly demonstrate the effectiveness made by boosting chain."
            },
            "slug": "Boosting-chain-learning-for-object-detection-Xiao-Zhu",
            "title": {
                "fragments": [],
                "text": "Boosting chain learning for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A linear optimization scheme is proposed to address the problems of redundancy in boosting learning and threshold adjusting in cascade coupling, and the resulting classifier consists of fewer weak classifiers yet achieves lower error rates than boosting cascade in both training and test."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3430625"
                        ],
                        "name": "R. F\u00e9raud",
                        "slug": "R.-F\u00e9raud",
                        "structuredName": {
                            "firstName": "Rapha\u00ebl",
                            "lastName": "F\u00e9raud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. F\u00e9raud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3118328"
                        ],
                        "name": "O. Bernier",
                        "slug": "O.-Bernier",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Bernier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Bernier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35094984"
                        ],
                        "name": "J. Viallet",
                        "slug": "J.-Viallet",
                        "structuredName": {
                            "firstName": "Jean-Emmanuel",
                            "lastName": "Viallet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Viallet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586567"
                        ],
                        "name": "M. Collobert",
                        "slug": "M.-Collobert",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collobert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "F\u00e9raud et al [1] propose a four stage cascade that includes a motion filter, color filter, a neural network and a PCA-based classifier."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33451369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebfab3c7d0fdffc3d2f570c105e7a4e43997d04c",
            "isKey": false,
            "numCitedBy": 355,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting faces in images with complex backgrounds is a difficult task. Our approach, which obtains state of the art results, is based on a neural network model: the constrained generative model (CGM). Generative, since the goal of the learning process is to evaluate the probability that the model has generated the input data, and constrained since some counter-examples are used to increase the quality of the estimation performed by the model. To detect side view faces and to decrease the number of false alarms, a conditional mixture of networks is used. To decrease the computational time cost, a fast search algorithm is proposed. The level of performance reached, in terms of detection accuracy and processing time, allows us to apply this detector to a real world application: the indexing of images and videos."
            },
            "slug": "A-Fast-and-Accurate-Face-Detector-Based-on-Neural-F\u00e9raud-Bernier",
            "title": {
                "fragments": [],
                "text": "A Fast and Accurate Face Detector Based on Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The level of performance reached, in terms of detection accuracy and processing time, allows us to apply this detector to a real world application: the indexing of images and videos."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46968797"
                        ],
                        "name": "Jie Sun",
                        "slug": "Jie-Sun",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Sun et al [8] propose a method for picking values for some of these parameters that optimize the detection accuracy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 741060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e40c95e3f18447a3534bef9b8c23942d6d02448",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Face detection methods based on cascade architecture have demonstrated fast and robust performance. Cascade learning is aided by the modularity of the architecture in which nodes are chained together to form a cascade. In this paper we present two new cascade learning results which address the decoupled nature of the cascade learning task. First, we introduce a cascade indifference curve framework, which connects the learning objectives for a node to the overall cascade performance. We derive a new cost function for node learning, which yields fully-automatic stopping conditions and improved detection performance. Second, we introduce the concept of perturbation bias, which leverages the statistical differences between target and non-target classes in a detection problem to obtain improved performance and robustness. We derive necessary and sufficient conditions for the success of the method and present experimental results."
            },
            "slug": "Automatic-cascade-training-with-perturbation-bias-Sun-Rehg",
            "title": {
                "fragments": [],
                "text": "Automatic cascade training with perturbation bias"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A cascade indifference curve framework is introduced, which connects the learning objectives for a node to the overall cascade performance, and a new cost function for node learning is derived, which yields fully-automatic stopping conditions and improved detection performance."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2651359"
                        ],
                        "name": "ZhenQiu Zhang",
                        "slug": "ZhenQiu-Zhang",
                        "structuredName": {
                            "firstName": "ZhenQiu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ZhenQiu Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Schneiderman [6]* Xiao et al [12] Li/Zhang [ 3 ]*"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Li et al [ 3 ] propose a backtrack-based strategy for weeding out weak features called FloatBoost, which could be utilized in Step 4. We do not use it because of its performance when thousands of features are involved and also because, as discussed above, working hard to remove optimally weak features is not necessary, since the problem changes as we go along."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(Note that both [ 3 ] and [6] report results based on a reduced set with 5 images containing hand-drawn faces removed.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The Soft Cascade ROC performs better than [ 3 ], although [3] also eliminates feature redundancy through FloatBoost backtracking and employs a much richer set of primitive features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The Soft Cascade ROC performs better than [3], although [ 3 ] also eliminates feature redundancy through FloatBoost backtracking and employs a much richer set of primitive features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Subsequent work has refined and extended the Viola-Jones detector [ 3 , 6, 11, 12, 8], while retaining the fundamental structure of the cascade."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13894144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc890611cb8c94024c8086b82716f4a90e272e42",
            "isKey": true,
            "numCitedBy": 583,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel learning procedure, called FloatBoost, is proposed for learning a boosted classifier for achieving the minimum error rate. FloatBoost learning uses a backtrack mechanism after each iteration of AdaBoost learning to minimize the error rate directly, rather than minimizing an exponential function of the margin as in the traditional AdaBoost algorithms. A second contribution of the paper is a novel statistical model for learning best weak classifiers using a stagewise approximation of the posterior probability. These novel techniques lead to a classifier which requires fewer weak classifiers than AdaBoost yet achieves lower error rates in both training and testing, as demonstrated by extensive experiments. Applied to face detection, the FloatBoost learning method, together with a proposed detector pyramid architecture, leads to the first real-time multiview face detection system reported."
            },
            "slug": "FloatBoost-learning-and-statistical-face-detection-Li-Zhang",
            "title": {
                "fragments": [],
                "text": "FloatBoost learning and statistical face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Applied to face detection, the FloatBoost learning method, together with a proposed detector pyramid architecture, leads to the first real-time multiview face detection system reported."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One important advantage of our method is that it enables systematic exploration of theROC Surface, which characterizes the trade-off between accuracy and speed for a given classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 221284382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84bb60b83f82ad847e19d96403ad0011abfc888f",
            "isKey": false,
            "numCitedBy": 1888,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": "Boosting is a general method for improving the accuracy of any given learning algorithm. Focusing primarily on the AdaBoost algorithm, this chapter overviews some of the recent work on boosting including analyses of AdaBoost\u2019s training error and generalization error; boosting\u2019s connection to game theory and linear programming; the relationship between boosting and logistic regression; extensions of AdaBoost for multiclass classification problems; methods of incorporating human knowledge into boosting; and experimental and applied work using boosting."
            },
            "slug": "The-Boosting-Approach-to-Machine-Learning-An-Schapire",
            "title": {
                "fragments": [],
                "text": "The Boosting Approach to Machine Learning An Overview"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This chapter overviews some of the recent work on boosting including analyses of AdaBoost's training error and generalization error; boosting\u2019s connection to game theory and linear programming; the relationship between boosting and logistic regression; extensions of Ada boost for multiclass classification problems; methods of incorporating human knowledge into boosting; and experimental and applied work using boosting."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022386739"
                        ],
                        "name": "Peter Barlett",
                        "slug": "Peter-Barlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Barlett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Barlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740222"
                        ],
                        "name": "Wee Sun Lee",
                        "slug": "Wee-Sun-Lee",
                        "structuredName": {
                            "firstName": "Wee",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wee Sun Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 152
                            }
                        ],
                        "text": "The justification for the above choices is as follows: AdaBoost has been shown as a very effective learning method with good generalization performance [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 573509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d19272112b50547614479a0c409fca66e3b05f7",
            "isKey": false,
            "numCitedBy": 2844,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the surprising recurring phenomena observed in experiments with boosting is that the test error of the generated classifier usually does not increase as its size becomes very large, and often is observed to decrease even after the training error reaches zero. In this paper, we show that this phenomenon is related to the distribution of margins of the training examples with respect to the generated voting classification rule, where the margin of an example is simply the difference between the number of correct votes and the maximum number of votes received by any incorrect label. We show that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error. We also show theoretically and experimentally that boosting is especially effective at increasing the margins of the training examples. Finally, we compare our explanation to those based on the bias-variance"
            },
            "slug": "Boosting-the-margin:-A-new-explanation-for-the-of-Schapire-Freund",
            "title": {
                "fragments": [],
                "text": "Boosting the margin: A new explanation for the effectiveness of voting methods"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that techniques used in the analysis of Vapnik's support vector classifiers and of neural networks with small weights can be applied to voting methods to relate the margin distribution to the test error."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 9,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 13,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Robust-object-detection-via-soft-cascade-Bourdev-Brandt/9a0024fbad7fcda8af1d241064f0948a8365b969?sort=total-citations"
}