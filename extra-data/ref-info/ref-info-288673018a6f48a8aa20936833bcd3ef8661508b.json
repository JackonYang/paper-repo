{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1839745"
                        ],
                        "name": "Y. Tijerino",
                        "slug": "Y.-Tijerino",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Tijerino",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Tijerino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730612"
                        ],
                        "name": "Deryle W. Lonsdale",
                        "slug": "Deryle-W.-Lonsdale",
                        "structuredName": {
                            "firstName": "Deryle",
                            "lastName": "Lonsdale",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deryle W. Lonsdale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We organize the new knowledge we gain from \u201cunderstanding\u201d tables as an ontology and thus we call our information-gathering engine TANGO (Table ANalysis for Generating Ontologies) [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18095618,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0154fc2dbf38387911b9aaa7f08f76338c6e8879",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We often need to access and reorganize information available in multiple tables in diverse Web pages. To understand tables, we rely on acquired expertise, background information, and practice. Current computerized tools seldom consider the structure and content in the context of other tables with related information. This paper addresses the table processing issue by developing a new framework to table understanding that applies an ontology-based conceptual modeling extraction approach to: (i) understand a table's structure and conceptual content to the extent possible; (ii) discover the constraints that hold between concepts extracted from the table; (iii) match the recognized concepts with ones from a more general specification of related concepts; and (iv) merge the resulting structure with other similar knowledge representations for use in future situations. The result is a formalized method of processing the format and content of tables while incrementally building a relevant reusable conceptual ontology."
            },
            "slug": "Ontology-generation-from-tables-Tijerino-Embley",
            "title": {
                "fragments": [],
                "text": "Ontology generation from tables"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A new framework to table understanding is developed that applies an ontology-based conceptual modeling extraction approach to understand a table's structure and conceptual content to the extent possible and discover the constraints that hold between concepts extracted from the table."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Web Information Systems Engineering, 2003. WISE 2003."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69065731"
                        ],
                        "name": "Nicola Guarino",
                        "slug": "Nicola-Guarino",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Guarino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicola Guarino"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6921227,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "5109faf8ff0b152263b7531163fbceedf6112530",
            "isKey": false,
            "numCitedBy": 1166,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The purpose of this paper is to defend the systematic introduction of formal ontological principles in the current practice of knowledge engineering, to explore the various relationships between ontology and knowledge representation, and to present the recent trends in this promising research area. According to the \"modelling view\" of knowledge acquisition proposed by Clancey, the modelling activity must establish a correspondence between a knowledge base and two separate subsystems: the agent's behaviour (i.e. the problem-solving expertise ) and its own environment (the problem domain ). Current knowledge modelling methodologies tend to focus on the former sub-system only, viewing domain knowledge as strongly dependent on the particular task at hand: in fact, AI researchers seem to have been much more interested in the nature of reasoning rather than in the nature of the real world. Recently, however, the potential value of task-independent knowledge bases (or \"ontologies\") suitable to large scale integration has been underlined in many ways. In this paper, we compare the dichotomy between reasoning and representation to the philosophical distinction between epistemology and ontology. We introduce the notion of the ontological level, intermediate between the epistemological and the conceptual levels discussed by Brachman, as a way to characterize a knowledge representation formalism taking into account the intended meaning of its primitives. We then discuss some formal ontologic distinctions which may play an important role for such purpose."
            },
            "slug": "Formal-ontology,-conceptual-analysis-and-knowledge-Guarino",
            "title": {
                "fragments": [],
                "text": "Formal ontology, conceptual analysis and knowledge representation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The notion of the ontological level is introduced, intermediate between the epistemological and the conceptual levels discussed by Brachman, as a way to characterize a knowledge representation formalism taking into account the intended meaning of its primitives."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Hum. Comput. Stud."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3104575"
                        ],
                        "name": "Y. Kalfoglou",
                        "slug": "Y.-Kalfoglou",
                        "structuredName": {
                            "firstName": "Yannis",
                            "lastName": "Kalfoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kalfoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3133609"
                        ],
                        "name": "M. Schorlemmer",
                        "slug": "M.-Schorlemmer",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Schorlemmer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schorlemmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 100
                            }
                        ],
                        "text": "Although data, schema and ontology integration has been explored in great depth by many in the past [6,26,42], this is still an open area of research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 593561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb56151564b58e731ee21b3f68fac47dc11b2a97",
            "isKey": false,
            "numCitedBy": 1500,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "Ontology mapping is seen as a solution provider in today's landscape of ontology research. As the number of ontologies that are made publicly available and accessible on the Web increases steadily, so does the need for applications to use them. A single ontology is no longer enough to support the tasks envisaged by a distributed environment like the Semantic Web. Multiple ontologies need to be accessed from several applications. Mapping could provide a common layer from which several ontologies could be accessed and hence could exchange information in semantically sound manners. Developing such mappings has been the focus of a variety of works originating from diverse communities over a number of years. In this article we comprehensively review and present these works. We also provide insights on the pragmatics of ontology mapping and elaborate on a theoretical approach for defining ontology mapping."
            },
            "slug": "Ontology-mapping:-the-state-of-the-art-Kalfoglou-Schorlemmer",
            "title": {
                "fragments": [],
                "text": "Ontology mapping: the state of the art"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article comprehensively reviews and provides insights on the pragmatics of ontology mapping and elaborate on a theoretical approach for defining ontology mapped."
            },
            "venue": {
                "fragments": [],
                "text": "The Knowledge Engineering Review"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734117"
                        ],
                        "name": "Peter Spyns",
                        "slug": "Peter-Spyns",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Spyns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Spyns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733861"
                        ],
                        "name": "R. Meersman",
                        "slug": "R.-Meersman",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Meersman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Meersman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764681"
                        ],
                        "name": "Mustafa Jarrar",
                        "slug": "Mustafa-Jarrar",
                        "structuredName": {
                            "firstName": "Mustafa",
                            "lastName": "Jarrar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mustafa Jarrar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "If we could automate the process, or at least make the process semiautomatic, we could significantly\nimprove our chances of making the Semantic Web a reality."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6082120,
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy"
            ],
            "id": "221da285b72f6272c2d7332a547d1e034a60e154",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Ontologies in current computer science parlance are computer based resources that represent agreed domain semantics. Unlike data models, the fundamental asset of ontologies is their relative independence of particular applications, i.e. an ontology consists of relatively generic knowledge that can be reused by different kinds of applications/tasks. The first part of this paper concerns some aspects that help to understand the differences and similarities between ontologies and data models. In the second part we present an ontology engineering framework that supports and favours the genericity of an ontology. We introduce the DOGMA ontology engineering approach that separates \"atomic\" conceptual relations from \"predicative\" domain rules. A DOGMA ontology consists of an ontology base that holds sets of intuitive context-specific conceptual relations and a layer of \"relatively generic\" ontological commitments that hold the domain rules. This constitutes what we shall call the double articulation of a DOGMA ontology 1."
            },
            "slug": "Data-modelling-versus-ontology-engineering-Spyns-Meersman",
            "title": {
                "fragments": [],
                "text": "Data modelling versus ontology engineering"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The DOGMA ontology engineering approach is introduced that separates \"atomic\" conceptual relations from \"predicative\" domain rules and a layer of \"relatively generic\" ontological commitments that hold the domain rules."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122552957"
                        ],
                        "name": "Timothy Adam Chartrand",
                        "slug": "Timothy-Adam-Chartrand",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Chartrand",
                            "middleNames": [
                                "Adam"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy Adam Chartrand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [8] we have also successfully experimented with modified soundex matching, Levenshtein edit-distance, and longest common subsequence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12575626,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfa8cc4c2c6164039b831d1d936123315bd535ac",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "ONTOLOGY-BASED EXTRACTION OF RDF DATA FROM THE WORLD WIDE WEB Tim Chartrand Department of Computer Science Master of Science The simplicity and proliferation of the World Wide Web (WWW) has taken the availability of information to an unprecedented level. The next generation of the Web, the Semantic Web, seeks to make information more usable by machines by introducing a more rigorous structure based on ontologies. One hinderance to the Semantic Web is the lack of existing semantically marked-up data. Until there is a critical mass of Semantic Web data, few people will develop and use Semantic Web applications. This project helps promote the Semantic Web by providing content. We apply existing information-extraction techniques, in particular, the BYU ontologybased data-extraction system, to extract information from the WWW based on a Semantic Web ontology to produce Semantic Web data with respect to that ontology. As an example of how the generated Semantic Web data can be used, we provide an application to browse the extracted data and the source documents together. In this sense, the extracted data is superimposed over or is an index over the source documents. Our experiments with ontologies in four application domains show that our approach can indeed extract Semantic Web data from the WWW with precision and recall similar to that achieved by the underlying information extraction system and make that data accessible to Semantic Web applications."
            },
            "slug": "Ontology-Based-Extraction-of-RDF-Data-from-the-Wide-Chartrand",
            "title": {
                "fragments": [],
                "text": "Ontology-Based Extraction of RDF Data from the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This project applies existing information-extraction techniques to extract information from the WWW based on a Semantic Web ontology to produceSemantic Web data with respect to that ontology, and experiments with ontologies in four application domains show that this approach can indeed extract SemanticWeb data from theWWW with precision and recall similar to that achieved by the underlying information extraction system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679913"
                        ],
                        "name": "D. McGuinness",
                        "slug": "D.-McGuinness",
                        "structuredName": {
                            "firstName": "Deborah",
                            "lastName": "McGuinness",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. McGuinness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748956"
                        ],
                        "name": "R. Fikes",
                        "slug": "R.-Fikes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Fikes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fikes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116302175"
                        ],
                        "name": "James Rice",
                        "slug": "James-Rice",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rice",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Rice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37609882"
                        ],
                        "name": "S. Wilder",
                        "slug": "S.-Wilder",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Wilder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wilder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[36]) and comparing and aligning ontologies (e."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5319529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b549860adc102548358d0ff1bf51ee4c73e5585",
            "isKey": false,
            "numCitedBy": 699,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Large-scale ontologies are becoming an essential component of many applications including standard search (such as Yahoo and Lycos), ecommerce (such as Amazon and eBay), configuration (such as Dell and PC-Order), and government intelligence (such as DARPA\u2019s High Performance Knowledge Base (HPKB) program). The ontologies are becoming so large that it is not uncommon for distributed teams of people with broad ranges of training to be in charge of the ontology development, design, and maintenance. Standard ontologies (such as UNSPSC) are emerging as well which need to be integrated into large application ontologies, sometimes by people who do not have much training in knowledge representation. This process has generated needs for tools that support broad ranges of users in (1) merging of ontological terms from varied sources, (2) diagnosis of coverage and correctness of ontologies, and (3) maintaining ontologies over time. In this paper, we present a new merging and diagnostic ontology environment called Chimaera, which was developed to address these issues in the context of HPKB. We also report on some initial tests of its effectiveness in merging tasks."
            },
            "slug": "An-Environment-for-Merging-and-Testing-Large-McGuinness-Fikes",
            "title": {
                "fragments": [],
                "text": "An Environment for Merging and Testing Large Ontologies"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new merging and diagnostic ontology environment called Chimaera is presented, which was developed to address issues in the context of HPKB and some initial tests of its effectiveness in merging tasks are reported on."
            },
            "venue": {
                "fragments": [],
                "text": "KR"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145723023"
                        ],
                        "name": "C. Tao",
                        "slug": "C.-Tao",
                        "structuredName": {
                            "firstName": "Cui",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742211"
                        ],
                        "name": "Stephen W. Liddle",
                        "slug": "Stephen-W.-Liddle",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Liddle",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen W. Liddle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "4. Although we have spent much effort in understanding tables, our approach described in [ 20 ] was mainly to understand tables based on an intermediate schema."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Expected values. Using constant value recognizers in data frames, we have shown that finding and matching expected values in value sets provides significant leverage in schema matching [ 20 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "distinguish labels from values in tables, decompose or compose value strings for matching, and determine whether value sets are unions or subsets of other value sets [ 20 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We choose it because: (1) it is fully formal in terms of first-order predicate calculus [19], (2) it covers the typical ontological properties of interest\u2014ISA hierarchies, part/whole hierarchies, relationships, and concepts including lexical appearance, representation, and computational manipulation, and (3) it has specialized tools for ontology creation and manipulation, ontological table understanding [ 20 ], ontological data extraction, ..."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Other web tables, however, pose problems such as tables displayed piecemeal, tables spanning multiple pages, tables with no   tag, folded tables, tables with factored rows, tables with linked subtables, and table rows with additional linked row values, all of which we have worked with in previous research [ 20 ] related to data extraction from tables.4 Some tables, more difficult to interpret, include features such as tables ..."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Using ideas developed in [ 20 ], for example, we can distinguish label text versus value text from the World Factbook in 266"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5406402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b777c808a71ed4bd8c9da4f1a2475110b15d23f7",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automating-the-extraction-of-data-from-HTML-tables-Embley-Tao",
            "title": {
                "fragments": [],
                "text": "Automating the extraction of data from HTML tables with unknown structure"
            },
            "venue": {
                "fragments": [],
                "text": "Data Knowl. Eng."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145887845"
                        ],
                        "name": "D. M. Campbell",
                        "slug": "D.-M.-Campbell",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Campbell",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Campbell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158090475"
                        ],
                        "name": "Y. S. Jiang",
                        "slug": "Y.-S.-Jiang",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Jiang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. S. Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742211"
                        ],
                        "name": "Stephen W. Liddle",
                        "slug": "Stephen-W.-Liddle",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Liddle",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen W. Liddle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143743807"
                        ],
                        "name": "Yiu-Kai Ng",
                        "slug": "Yiu-Kai-Ng",
                        "structuredName": {
                            "firstName": "Yiu-Kai",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiu-Kai Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144259075"
                        ],
                        "name": "D. Quass",
                        "slug": "D.-Quass",
                        "structuredName": {
                            "firstName": "Dallan",
                            "lastName": "Quass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Quass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108985589"
                        ],
                        "name": "Randy D. Smith",
                        "slug": "Randy-D.-Smith",
                        "structuredName": {
                            "firstName": "Randy",
                            "lastName": "Smith",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Randy D. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [8] we proposed a way to bridge the gap between the current web and the Semantic Web by semiautomatically converting Resource Description Framework Schemas (RDFS\u2019s) and DAML+OIL ontologies into data extraction ontologies [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3217704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "156a5992d338d2bf7ba8f5af50be8985fabe93fb",
            "isKey": false,
            "numCitedBy": 412,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Conceptual-Model-Based-Data-Extraction-from-Web-Embley-Campbell",
            "title": {
                "fragments": [],
                "text": "Conceptual-Model-Based Data Extraction from Multiple-Record Web Pages"
            },
            "venue": {
                "fragments": [],
                "text": "Data Knowl. Eng."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32072466"
                        ],
                        "name": "T. Gruber",
                        "slug": "T.-Gruber",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Gruber",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gruber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our ontologies fit the standard definition for an ontology as Tom Gruber describes them in [23] \u201cAn ontology is a formal, explicit specification of a shared conceptualization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1652449,
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy"
            ],
            "id": "69cfb48c45b59243d60342b796dbac35e9efd6bc",
            "isKey": false,
            "numCitedBy": 8779,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in Artificial Intelligence is exploring the use of formal ontologies as a way of specifying content-specific agreements for the sharing and reuse of knowledge among software entities. We take an engineering perspective on the development of such ontologies. Formal ontologies are viewed as designed artifacts, formulated for specific purposes and evaluated against objective design criteria. We describe the role of ontologies in supporting knowledge sharing activities, and then present a set of criteria to guide the development of ontologies for these purposes. We show how these criteria are applied in case studies from the design of ontologies for engineering mathematics and bibliographic data. Selected design decisions are discussed, and alternative representation choices and evaluated against the design criteria."
            },
            "slug": "Toward-principles-for-the-design-of-ontologies-used-Gruber",
            "title": {
                "fragments": [],
                "text": "Toward principles for the design of ontologies used for knowledge sharing?"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The role of ontology in supporting knowledge sharing activities is described, and a set of criteria to guide the development of ontologies for these purposes are presented, and it is shown how these criteria are applied in case studies from the design ofOntologies for engineering mathematics and bibliographic data."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Hum. Comput. Stud."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707920"
                        ],
                        "name": "J. Biskup",
                        "slug": "J.-Biskup",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Biskup",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Biskup"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Further, recognition that Object is a common hypernym for thousands of terms would prompt an IDS (Issue/Default/Suggestion) statement [4] raising the Issue that the term Object is likely to be far too general, stating that the Default is to do nothing, and making a Suggestion that the user choose a more meaningful name."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In [4] we studied constraints in the context of schema matching."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We use three basic approaches to conflict resolution: (1) automatic adjustment based on constraint satisfaction, (2) synergistic adjustment based on IDS statements [4], and (3)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In using this evidence we look not only for direct matches as is common in most schema matching techniques [2,13,31,42], but also for indirect matches [4,50]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2286967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68380580fce82c538ed8389d85ad5591167c9418",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Extracting-information-from-heterogeneous-sources-Biskup-Embley",
            "title": {
                "fragments": [],
                "text": "Extracting information from heterogeneous information sources using ontologically specified target views"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Syst."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69065731"
                        ],
                        "name": "Nicola Guarino",
                        "slug": "Nicola-Guarino",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Guarino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicola Guarino"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60071847,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5660bd8df219d3b520f91661e5efc34fb3c1810d",
            "isKey": false,
            "numCitedBy": 541,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Research on ontology is becoming increasingly widespread in the computer science community. While this term has been rather confined to the philosophical sphere in the past, it is now gaining a specific role in areas such as Artificial Intelligence, Computational Linguistics, and Databases. Its importance has been recognized in fields as diverse as knowledge engineering, knowledge representation, qualitative modeling, language engineering, database design, information integration, object-oriented analysis, information retrieval and extraction, knowledge management and organization, agent-based systems design. Current applications areas are disparate, including enterprise integration, natural language translation, medicine, mechanical engineering, electronic commerce, geographic information systems, legal information systems, and biological information systems. Various workshops addressing the engineering aspects of ontology have been held in the recent years. However, ontology by 'its very nature' ought to be a unifying discipline. Insights in this field have potential impact on the whole area of information systems (taking this term in its broadest sense), as testified by the interest recently shown by international standards organizations. In order to provide a solid general foundation for this work, it is therefore important to focus on the common scientific principles and open problems arising from current tools, methodologies, and applications of ontology."
            },
            "slug": "Formal-Ontology-in-Information-Systems-:-of-the-Guarino",
            "title": {
                "fragments": [],
                "text": "Formal Ontology in Information Systems : Proceedings of the First International Conference(FOIS'98), June 6-8, Trento, Italy"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is important to focus on the common scientific principles and open problems arising from current tools, methodologies, and applications of ontology to provide a solid general foundation for this work."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2724566"
                        ],
                        "name": "S. Bergamaschi",
                        "slug": "S.-Bergamaschi",
                        "structuredName": {
                            "firstName": "Sonia",
                            "lastName": "Bergamaschi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bergamaschi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143916599"
                        ],
                        "name": "S. Castano",
                        "slug": "S.-Castano",
                        "structuredName": {
                            "firstName": "Silvana",
                            "lastName": "Castano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Castano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782351"
                        ],
                        "name": "M. Vincini",
                        "slug": "M.-Vincini",
                        "structuredName": {
                            "firstName": "Maurizio",
                            "lastName": "Vincini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vincini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 107
                            }
                        ],
                        "text": "In using this evidence we look not only for direct matches as is common in most schema matching techniques [2,13,31,42], but also for indirect matches [4,50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9012288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5fc8a64a05ae1f8f148a2fee15c75d7bee2ea2f",
            "isKey": false,
            "numCitedBy": 301,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Providing an integrated access to multiple heterogeneous sources is a challenging issue in global information systems for cooperation and interoperability. In this context, two fundamental problems arise. First, how to determine if the sources contain semantically related information, that is, information related to the same or similar real-world concept(s). Second, how to handle semantic heterogeneity to support integration and uniform query interfaces. Complicating factors with respect to conventional view integration techniques are related to the fact that the sources to be integrated already exist and that semantic heterogeneity occurs on the large-scale, involving terminology, structure, and context of the involved sources, with respect to geographical, organizational, and functional aspects related to information use. Moreover, to meet the requirements of global, Internet-based information systems, it is important that tools developed for supporting these activities are semi-automatic and scalable as much as possible.\nThe goal of this paper is to describe the MOMIS [4, 5] (Mediator envirOnment for Multiple Information Sources) approach to the integration and query of multiple, heterogeneous information sources, containing structured and semistructured data. MOMIS has been conceived as a joint collaboration between University of Milano and Modena in the framework of the INTERDATA national research project, aiming at providing methods and tools for data management in Internet-based information systems. Like other integration projects [1, 10, 14], MOMIS follows a \u201csemantic approach\u201d to information integration based on the conceptual schema, or metadata, of the information sources, and on the following architectural elements: i) a common object-oriented data model, defined according to the ODL<subscrpt><italic>I</italic><supscrpt>3</supscrpt></subscrpt> language, to describe source schemas for integration purposes.  The data model and ODL<subscrpt><italic>I</italic><supscrpt>3</supscrpt></subscrpt> have been defined in MOMIS as subset of the ODMG-93 ones, following the proposal for a standard mediator language developed by the <italic>I</italic><supscrpt>3</supscrpt>/POB working group [7]. In addition, ODL<subscrpt><italic>I</italic><supscrpt>3</supscrpt></subscrpt> introduces new constructors to support the semantic integration process [4, 5]; ii) one or more wrappers, to translate schema descriptions into the common ODL<subscrpt><italic>I</italic><supscrpt>3</supscrpt></subscrpt> representation; iii) a mediator and a query-processing component, based on two pre-existing tools, namely ARTEMIS [8] and ODB-Tools [3] (available on Internet at http://sparc20.dsi.unimo.it/), to provide an <italic>I</italic><supscrpt>3</supscrpt> architecture for integration and query optimization. In this paper, we focus on capturing and reasoning about semantic aspects of schema descriptions of heterogeneous information sources for supporting integration and query optimization. Both semistructured and structured data sources are taken into account [5]. A Common Thesaurus is constructed, which has the role of a shared ontology for the information sources. The Common Thesaurus is built by analyzing ODL<subscrpt><italic>I</italic><supscrpt>3</supscrpt></subscrpt> descriptions of the sources, by exploiting the Description Logics OLCD (Object Language with Complements allowing Descriptive cycles) [2, 6], derived from KL-ONE family [17]. The knowledge in the Common Thesaurus is then exploited for the identification of semantically related information in ODL<subscrpt><italic>I</italic><supscrpt>3</supscrpt></subscrpt> descriptions of different sources and for their integration at the global level. Mapping rules and integrity constraints are defined at the global level to express the relationships holding between the integrated description and the sources descriptions.  ODB-Tools, supporting OLCD and description logic inference techniques, allows the analysis of sources descriptions for generating a consistent Common Thesaurus and provides support for semantic optimization of queries at the global level, based on defined mapping rules and integrity constraints."
            },
            "slug": "Semantic-integration-of-semistructured-and-data-Bergamaschi-Castano",
            "title": {
                "fragments": [],
                "text": "Semantic integration of semistructured and structured data sources"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper focuses on capturing and reasoning about semantic aspects of schema descriptions of heterogeneous information sources for supporting integration and query optimization and introduces new constructors to support the semantic integration process."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8982662"
                        ],
                        "name": "R. Mizoguchi",
                        "slug": "R.-Mizoguchi",
                        "structuredName": {
                            "firstName": "Riichiro",
                            "lastName": "Mizoguchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mizoguchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144952433"
                        ],
                        "name": "M. Ikeda",
                        "slug": "M.-Ikeda",
                        "structuredName": {
                            "firstName": "Mitsuru",
                            "lastName": "Ikeda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ikeda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: ontology, table understanding, ontology generation, semantic web"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12358548,
            "fieldsOfStudy": [
                "Computer Science",
                "Philosophy"
            ],
            "id": "c6a86fa5741453b35737b501e93bf8e2e54ba80a",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The main objectives of this paper include to propose a new research field called \"Ontology Engineering\" and to show it can be a basic research of content-oriented research and provides such technologies that are badly needed. We begin the paper by discussing what an ontology is. We next analyze the depth of the ontology use in eight levels followed by the discussion on what concrete advantages ontology can give in the real-world problem solving. The next topic is the classification of ontologies. On the basis of the discussion, we present the scope of ontology engineering. Finally, we exemplify ontology engineering by summarizing"
            },
            "slug": "Towards-Ontology-Engineering-Mizoguchi-Ikeda",
            "title": {
                "fragments": [],
                "text": "Towards Ontology Engineering"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The main objectives of this paper include to propose a new research field called \"Ontology Engineering\" and to show it can be a basic research of content-oriented research and provides such technologies that are badly needed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171323607"
                        ],
                        "name": "Li Xu",
                        "slug": "Li-Xu",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We choose it because: (1) it is fully formal in terms of first-order predicate calculus [19], (2) it covers the typical ontological properties of interest\u2014ISA hierarchies, part/whole hierarchies, relationships, and concepts including lexical appearance, representation, and computational manipulation, and (3) it has specialized tools for ontology creation and manipulation, ontological table understanding [20], ontological data extraction, and ontological data integration [50]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In using this evidence we look not only for direct matches as is common in most schema matching techniques [2,13,31,42], but also for indirect matches [4,50]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We [50] and others [7,13,31,37] have developed matching algorithms based on structural context."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16661418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a483824bf8e4a93396893e612ed027fbd2d1f8a8",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Automating schema matching is challenging. Previous approaches (e.g. [DDH01, RB01]) to automating schema matching focus on computing direct matches between two schemas. Schemas, however, rarely match directly. Thus, to complete the task of schema matching, we must also compute indirect matches. In this paper, we focus on recognizing expected values as a technique to discover many direct and indirect matches between a source schema and a target schema. This technique relies on domain ontologies, which must be handcrafted. The benefits appear to justify the cost as demonstrated in the experiments we have conducted over a real-world application. The experiments show that this technique increases the results by an increase about 20 percentage points, yielding an overall result above 90% precision and recall for both direct and indirect matches."
            },
            "slug": "Using-Domain-Ontologies-to-Discover-Direct-and-for-Xu-Embley",
            "title": {
                "fragments": [],
                "text": "Using Domain Ontologies to Discover Direct and Indirect Matches for Schema Elements"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper focuses on recognizing expected values as a technique to discover many direct and indirect matches between a source schema and a target schema and shows that the benefits appear to justify the cost as demonstrated in the experiments conducted over a real-world application."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747414"
                        ],
                        "name": "E. Rahm",
                        "slug": "E.-Rahm",
                        "structuredName": {
                            "firstName": "Erhard",
                            "lastName": "Rahm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rahm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737944"
                        ],
                        "name": "P. Bernstein",
                        "slug": "P.-Bernstein",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Bernstein",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bernstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 100
                            }
                        ],
                        "text": "Although data, schema and ontology integration has been explored in great depth by many in the past [6,26,42], this is still an open area of research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 107
                            }
                        ],
                        "text": "In using this evidence we look not only for direct matches as is common in most schema matching techniques [2,13,31,42], but also for indirect matches [4,50]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10500613,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "580221d63ae75bdc7d68829916cf608e44a56b27",
            "isKey": false,
            "numCitedBy": 3761,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. Schema matching is a basic problem in many database application domains, such as data integration, E-business, data warehousing, and semantic query processing. In current implementations, schema matching is typically performed manually, which has significant limitations. On the other hand, previous research papers have proposed many techniques to achieve a partial automation of the match operation for specific application domains. We present a taxonomy that covers many of these existing approaches, and we describe the approaches in some detail. In particular, we distinguish between schema-level and instance-level, element-level and structure-level, and language-based and constraint-based matchers. Based on our classification we review some previous match implementations thereby indicating which part of the solution space they cover. We intend our taxonomy and review of past work to be useful when comparing different approaches to schema matching, when developing a new match algorithm, and when implementing a schema matching component."
            },
            "slug": "A-survey-of-approaches-to-automatic-schema-matching-Rahm-Bernstein",
            "title": {
                "fragments": [],
                "text": "A survey of approaches to automatic schema matching"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A taxonomy is presented that distinguishes between schema-level and instance-level, element- level and structure- level, and language-based and constraint-based matchers and is intended to be useful when comparing different approaches to schema matching, when developing a new match algorithm, and when implementing a schema matching component."
            },
            "venue": {
                "fragments": [],
                "text": "The VLDB Journal"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3030274"
                        ],
                        "name": "A. Doan",
                        "slug": "A.-Doan",
                        "structuredName": {
                            "firstName": "AnHai",
                            "lastName": "Doan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740213"
                        ],
                        "name": "Pedro M. Domingos",
                        "slug": "Pedro-M.-Domingos",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Domingos",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro M. Domingos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8997922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9011405b759b492b1132aea7b6165c9d1b0513e7",
            "isKey": false,
            "numCitedBy": 894,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A data-integration system provides access to a multitude of data sources through a single mediated schema. A key bottleneck in building such systems has been the laborious manual construction of semantic mappings between the source schemas and the mediated schema. We describe LSD, a system that employs and extends current machine-learning techniques to semi-automatically find such mappings. LSD first asks the user to provide the semantic mappings for a small set of data sources, then uses these mappings together with the sources to train a set of learners. Each learner exploits a different type of information either in the source schemas or in their data. Once the learners have been trained, LSD finds semantic mappings for a new data source by applying the learners, then combining their predictions using a meta-learner. To further improve matching accuracy, we extend machine learning techniques so that LSD can incorporate domain constraints as an additional source of knowledge, and develop a novel learner that utilizes the structural information in XML documents. Our approach thus is distinguished in that it incorporates multiple types of knowledge. Importantly, its architecture is extensible to additional learners that may exploit new kinds of information. We describe a set of experiments on several real-world domains, and show that LSD proposes semantic mappings with a high degree of accuracy."
            },
            "slug": "Reconciling-schemas-of-disparate-data-sources:-a-Doan-Domingos",
            "title": {
                "fragments": [],
                "text": "Reconciling schemas of disparate data sources: a machine-learning approach"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "LSD is a system that employs and extends current machine-learning techniques to semi-automatically find semantic mappings between the source schemas and the mediated schema, and its architecture is extensible to additional learners that may exploit new kinds of information."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702212"
                        ],
                        "name": "T. Milo",
                        "slug": "T.-Milo",
                        "structuredName": {
                            "firstName": "Tova",
                            "lastName": "Milo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Milo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10272731"
                        ],
                        "name": "Sagit Zohar",
                        "slug": "Sagit-Zohar",
                        "structuredName": {
                            "firstName": "Sagit",
                            "lastName": "Zohar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sagit Zohar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We [50] and others [7,13,31,37] have developed matching algorithms based on structural context."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13395093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1a647721a518c6f4f3ff8bc9122294432745361",
            "isKey": false,
            "numCitedBy": 487,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "A broad spectrum of data is available on the Web in distinct heterogeneous sources, and stored under different formats. As the number of systems that utilize this heterogeneous data grows, the importance of data translation and conversion mechanisms increases greatly. In this paper we present a new translation system, based on schema-matching, aimed at simplifying the intricate task of data conversion. We observe that in many cases the schema of the data in the source system is very similar to that of the target system. In such cases, much of the translation work can be done automatically, based on the schemas similarity. This saves a lot of effort for the user, limiting the amount of programming needed. We define common schema and data models, in which schemas and data (resp.) from many common models can be represented. Using a rule-based method, the source schema is compared with the target one, and each component in the source schema is matched with a corresponding component in the target schema. Then, based on the matching achieved, data instances of the source schema can be translated to instances of the target schema. We show that our schema-based translation system allows a convenient specification and customization of data conversions, and can be easily combined with the traditional data-based translation languages."
            },
            "slug": "Using-Schema-Matching-to-Simplify-Heterogeneous-Milo-Zohar",
            "title": {
                "fragments": [],
                "text": "Using Schema Matching to Simplify Heterogeneous Data Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a new translation system, based on schema-matching, aimed at simplifying the intricate task of data conversion, and shows that it allows a convenient specification and customization of data conversions, and can be easily combined with the traditional data-based translation languages."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35161586"
                        ],
                        "name": "A. Cal\u00ec",
                        "slug": "A.-Cal\u00ec",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Cal\u00ec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cal\u00ec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733846"
                        ],
                        "name": "Diego Calvanese",
                        "slug": "Diego-Calvanese",
                        "structuredName": {
                            "firstName": "Diego",
                            "lastName": "Calvanese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diego Calvanese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719219"
                        ],
                        "name": "Giuseppe De Giacomo",
                        "slug": "Giuseppe-De-Giacomo",
                        "structuredName": {
                            "firstName": "Giuseppe",
                            "lastName": "De Giacomo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Giuseppe De Giacomo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729232"
                        ],
                        "name": "M. Lenzerini",
                        "slug": "M.-Lenzerini",
                        "structuredName": {
                            "firstName": "Maurizio",
                            "lastName": "Lenzerini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lenzerini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Although data, schema and ontology integration has been explored in great depth by many in the past [6,26,42], this is still an open area of research."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 741838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05db4189b7c0cccfc5f020e64d64240460e7d346",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "There are basically two approaches for designing a data integration system. In the global-as-view (GAV) approach, one maps the concepts in the global schema to views over the sources, whereas in the local-as-view (LAV) approach, one maps the sources into views over the global schema. The goal of this paper is to relate the two approaches with respect to their expressive power. The analysis is carried out in a relational database setting, where both the queries on the global schema, and the views in the mapping are conjunctive queries. We introduce the notion of query-preserving transformation, and query-reducibility between data integration systems, and we show that, when no integrity constraints are allowed in global schema, the LAV and the GAV approaches are incomparable. We then consider the addition of integrity constraints in the global schema, and present techniques for query-preserving transformations in both directions. Finally, we show that our results imply that we can always transform any system following the GLAV approach (a generalization of both LAV and GAV) into a query-preserving GAV system."
            },
            "slug": "On-the-Expressive-Power-of-Data-Integration-Systems-Cal\u00ec-Calvanese",
            "title": {
                "fragments": [],
                "text": "On the Expressive Power of Data Integration Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper introduces the notion of query-preserving transformation, and query-reducibility between data integration systems, and shows that, when no integrity constraints are allowed in global schema, the LAV and the GAV approaches are incomparable."
            },
            "venue": {
                "fragments": [],
                "text": "ER"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143916599"
                        ],
                        "name": "S. Castano",
                        "slug": "S.-Castano",
                        "structuredName": {
                            "firstName": "Silvana",
                            "lastName": "Castano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Castano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716333"
                        ],
                        "name": "V. D. Antonellis",
                        "slug": "V.-D.-Antonellis",
                        "structuredName": {
                            "firstName": "Valeria",
                            "lastName": "Antonellis",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Antonellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702365"
                        ],
                        "name": "M. Fugini",
                        "slug": "M.-Fugini",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Fugini",
                            "middleNames": [
                                "Grazia"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fugini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747714"
                        ],
                        "name": "B. Pernici",
                        "slug": "B.-Pernici",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Pernici",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Pernici"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13544725,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96a4edc84191e8fad89636a58df8f9576d0bdc6b",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of analyzing and classifying conceptual schemas is becomig increasingly important due to the availability of a large number of schemas related to existing applications. The purposes of schema analysis and classification activities can be different: to extract information on intensional properties of legacy systems in order to restructure or migrate to new architectures; to build libraries of reference conceptual components to be used in building new applications in a given domain; and to identify information flows and possible replication of data in an organization. This article proposes a set of techniques for schema analysis and classification to be used separately or in combination. The techniques allow the analyst to derive significant properties from schemas, with human intervention limited as far as possible. In particular, techniques for associating descriptors with schemas, for abstracting reference conceptual schemas based on schema clustering, and for determining schema similarity are presented. A methodology for systematic schema analysis is illustrated, with the purpose of identifying and abstracting into reference components the similar and potentially reusable parts of a set of schemas. Experiences deriving from the application of the proposed techniques and methodology on a large set of Entity-Relationship conceptual schemas of information systems in the Italian Public Administration domain are described"
            },
            "slug": "Conceptual-schema-analysis:-techniques-and-Castano-Antonellis",
            "title": {
                "fragments": [],
                "text": "Conceptual schema analysis: techniques and applications"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A set of techniques for schema analysis and classification to be used separately or in combination are presented, allowing the analyst to derive significant properties from schemas, with human intervention limited as far as possible."
            },
            "venue": {
                "fragments": [],
                "text": "TODS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145802082"
                        ],
                        "name": "R. Chiang",
                        "slug": "R.-Chiang",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Chiang",
                            "middleNames": [
                                "H.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3067877"
                        ],
                        "name": "T. M. Barron",
                        "slug": "T.-M.-Barron",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Barron",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. M. Barron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764975"
                        ],
                        "name": "V. Storey",
                        "slug": "V.-Storey",
                        "structuredName": {
                            "firstName": "Veda",
                            "lastName": "Storey",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Storey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The literature describes many techniques for reverse engineering relational databases and schemas into conceptual models and entity-relationship models [9,25,35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15388725,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5066ed811791845cb95b741480fb15fd43d7c3c4",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Reverse-Engineering-of-Relational-Databases:-of-an-Chiang-Barron",
            "title": {
                "fragments": [],
                "text": "Reverse Engineering of Relational Databases: Extraction of an EER Model from a Relational Database"
            },
            "venue": {
                "fragments": [],
                "text": "Data Knowl. Eng."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108717697"
                        ],
                        "name": "Wen-Syan Li",
                        "slug": "Wen-Syan-Li",
                        "structuredName": {
                            "firstName": "Wen-Syan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-Syan Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2935513"
                        ],
                        "name": "Chris Clifton",
                        "slug": "Chris-Clifton",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Clifton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Clifton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[29]) have successfully used machine-learned rules to match object sets based on value characteristics such as alphanumeric features including length, alpha/numeric ratio, space/nonspace ratio and numeric features such as mean and variance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8035776,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1c31185fc354df44870e40075dbb3f895119160",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "One important step in integrating heterogeneous databases is matching equivalent attributes: Determining which fields in two databases refer to the same data. The meaning of information may be embodied within a. database model, a conceptual schema, application programs, or data contents. Integration involves extracting semantics, expressing them as metadata, and matching semantically equivalent data elements. We present a procedure using a classifier to categorize attributes according to their field specifications and data values, then train a neural network to recognize similar attributes. In our technique, the knowledge of how to match equivalent data elements is \u201cdiscovered\u201d from metadata , not \u201cpre-programmed\u201d."
            },
            "slug": "Semantic-Integration-in-Heterogeneous-Databases-Li-Clifton",
            "title": {
                "fragments": [],
                "text": "Semantic Integration in Heterogeneous Databases Using Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents a procedure using a classifier to categorize attributes according to their field specifications and data values, then train a neural network to recognize similar attributes and present a technique to match equivalent data elements."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6313909"
                        ],
                        "name": "A. Burgun",
                        "slug": "A.-Burgun",
                        "structuredName": {
                            "firstName": "Anita",
                            "lastName": "Burgun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Burgun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1950081"
                        ],
                        "name": "O. Bodenreider",
                        "slug": "O.-Bodenreider",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Bodenreider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Bodenreider"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[5])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1186524,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e936cb1d0135c66cc18d017cabbb523ac7c2c28",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Objectives : The objective of this study is to compare how a general terminological system (WordNet) and a domain-specific one (UMLS) represent linguistic and knowledge phenomena at three different levels: terms, concepts, and semantic classes. Methods : For one general class (ANIMAL ) and one domain-specific class (HEALTH DISORDER ), the set of concepts corresponding to the class was established. Then, for each semantic class, the corresponding terms were mapped from one system to the other, both ways. Results : Only 2% of the domain-specific concepts from UMLS were found in WordNet, but 83% of the domain-specific concepts from WordNet were found in the UMLS. Concept overlap between the two systems varies from 48% to 97%. Discussion : Missing terms in both systems are discussed, as well as granularity and knowledge organization issues."
            },
            "slug": "Comparing-terms,-concepts-and-semantic-classes-in-Burgun-Bodenreider",
            "title": {
                "fragments": [],
                "text": "Comparing terms, concepts and semantic classes in WordNet and the Unified Medical Language System"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "This study compares how a general terminological system (WordNet) and a domain-specific one (UMLS) represent linguistic and knowledge phenomena at three different levels: terms, concepts, and semantic classes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47748991"
                        ],
                        "name": "M. Kantola",
                        "slug": "M.-Kantola",
                        "structuredName": {
                            "firstName": "Martti",
                            "lastName": "Kantola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kantola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712654"
                        ],
                        "name": "H. Mannila",
                        "slug": "H.-Mannila",
                        "structuredName": {
                            "firstName": "Heikki",
                            "lastName": "Mannila",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Mannila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724448"
                        ],
                        "name": "Kari-Jouko R\u00e4ih\u00e4",
                        "slug": "Kari-Jouko-R\u00e4ih\u00e4",
                        "structuredName": {
                            "firstName": "Kari-Jouko",
                            "lastName": "R\u00e4ih\u00e4",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kari-Jouko R\u00e4ih\u00e4"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934593"
                        ],
                        "name": "H. Siirtola",
                        "slug": "H.-Siirtola",
                        "structuredName": {
                            "firstName": "Harri",
                            "lastName": "Siirtola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Siirtola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 92
                            }
                        ],
                        "text": "the table values for constraints such as functional dependencies and inclusion dependencies [27,34]; by observing mandatory and optional patterns in the data; by using lexicons to find hypernyms/hyponyms and kind-of relationships among terms; and by using data frames to recognize values in labels, tables with multiple concept values in a column, and tables with columns whose values should be split into two or more concepts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 56
                            }
                        ],
                        "text": "It is possible, using constraint mining as described in [27,34], to determine that Country and Religion together functionally determine Percent."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 18
                            }
                        ],
                        "text": "Constraint mining [27,34] leads to an understanding that the relationship"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19780594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbaaa58a1cf085f2b15803eee7efec4cdcc0de2f",
            "isKey": true,
            "numCitedBy": 116,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of discovering the functional and inclusion dependencies that a given database instance satisfies. This technique is used in a database design tool that uses example databases to give feedback to the designer. If the examples show deficiencies in the design, the designer can directly modify the examples. the tool then infers new dependencies and the database schema can be modified, if necessary. the discovery of the functional and inclusion dependencies can also be used in analyzing an existing database. the problem of inferring functional dependencies has several connections to other topics in knowledge discovery and machine learning. In this article we discuss the use of examples in the design of databases, and give an overview of the complexity results and algorithms that have been developed for this problem. \u00a9 1992 John Wiley & Sons, Inc."
            },
            "slug": "Discovering-functional-and-inclusion-dependencies-Kantola-Mannila",
            "title": {
                "fragments": [],
                "text": "Discovering functional and inclusion dependencies in relational databases"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article discusses the use of examples in the design of databases, and gives an overview of the complexity results and algorithms that have been developed for this problem."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Intell. Syst."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073827406"
                        ],
                        "name": "David Jackman",
                        "slug": "David-Jackman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jackman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Jackman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171323607"
                        ],
                        "name": "Li Xu",
                        "slug": "Li-Xu",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We [18] and others (e."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We have successfully experimented with machine-learned decision trees over WordNet features such as synonyms,9 word senses, and hypernyms/hyponyms [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12366951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ec5cac81b5650a3c7ff38a187147a7147b7b0ed",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Automating semantic matching of attributes for the purpose of information integration is challenging, and the dynamics of the Web further exacerbate this problem. Believing that many facets of metadata can contribute to a resolution, we present a framework for multifaceted exploitation of metadata in which we gather information about potential matches from various facets of metadata and combine this information to generate and place confidence values on potential attribute matches. To make the framework apply in the highly dynamic Web environment, we base our process largely on machine learning. Experiments we have conducted are encouraging, showing that when the combination of facets converges as expected, the results are highly reliable."
            },
            "slug": "Multifaceted-Exploitation-of-Metadata-for-Attribute-Embley-Jackman",
            "title": {
                "fragments": [],
                "text": "Multifaceted Exploitation of Metadata for Attribute Match Discovery in Information Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents a framework for multifaceted exploitation of metadata in which information about potential matches from various facets of metadata is gathered and combined to generate and place confidence values on potential attribute matches."
            },
            "venue": {
                "fragments": [],
                "text": "Workshop on Information Integration on the Web"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2224716"
                        ],
                        "name": "J. Madhavan",
                        "slug": "J.-Madhavan",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Madhavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737944"
                        ],
                        "name": "P. Bernstein",
                        "slug": "P.-Bernstein",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Bernstein",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747414"
                        ],
                        "name": "E. Rahm",
                        "slug": "E.-Rahm",
                        "structuredName": {
                            "firstName": "Erhard",
                            "lastName": "Rahm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rahm"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In using this evidence we look not only for direct matches as is common in most schema matching techniques [2,13,31,42], but also for indirect matches [4,50]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We [50] and others [7,13,31,37] have developed matching algorithms based on structural context."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1456533,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ff9bf4d58358fc008b059028a3e33919d12b335",
            "isKey": false,
            "numCitedBy": 1570,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Schema matching is a critical step in many applications, such as XML message mapping, data warehouse loading, and schema integration. In this paper, we investigate algorithms for generic schema matching, outside of any particular data model or application. We first present a taxonomy for past solutions, showing that a rich range of techniques is available. We then propose a new algorithm, Cupid, that discovers mappings between schema elements based on their names, data types, constraints, and schema structure, using a broader set of techniques than past approaches. Some of our innovations are the integrated use of linguistic and structural matching, context-dependent matching of shared types, and a bias toward leaf structure where much of the schema content resides. After describing our algorithm, we present experimental results that compare Cupid to two other schema matching systems."
            },
            "slug": "Generic-Schema-Matching-with-Cupid-Madhavan-Bernstein",
            "title": {
                "fragments": [],
                "text": "Generic Schema Matching with Cupid"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a new algorithm, Cupid, that discovers mappings between schema elements based on their names, data types, constraints, and schema structure, using a broader set of techniques than past approaches."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144221846"
                        ],
                        "name": "Robert Baumgartner",
                        "slug": "Robert-Baumgartner",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Baumgartner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Baumgartner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730314"
                        ],
                        "name": "S. Flesca",
                        "slug": "S.-Flesca",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Flesca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Flesca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684745"
                        ],
                        "name": "G. Gottlob",
                        "slug": "G.-Gottlob",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Gottlob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gottlob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Lixto [1] is a commercial effort in the EU to develop commercial-grade tools for the construction and use of the Semantic Web."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Others have recognized the importance of this conversion and are working on research and commercial efforts to address this particular issue [1,39,43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 432493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35a38da0b7079bb61ef29bb27915ada2c4665e0a",
            "isKey": false,
            "numCitedBy": 590,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present new techniques for supervised wrapper generation and automated web information extraction, and a system called Lixto implementing these techniques. Our system can generate wrappers which translate relevant pieces of HTML pages into XML. Lixto, of which a working prototype has been implemented, assists the user to semi-automatically create wrapper programs by providing a fully visual and interactive user interface. In this convenient user-interface very expressive extraction programs can be created. Internally, this functionality is reected by the new logicbased declarative language Elog. Users never have to deal with Elog and even familiarity with HTML is not required. Lixto can be used to create an \\XML-Companion\" for an HTML web page with changing content, containing the continually updated XML translation of the relevant information."
            },
            "slug": "Visual-Web-Information-Extraction-with-Lixto-Baumgartner-Flesca",
            "title": {
                "fragments": [],
                "text": "Visual Web Information Extraction with Lixto"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Lixto, of which a working prototype has been implemented, assists the user to semi-automatically create wrapper programs by providing a fully visual and interactive user interface that helps to create very expressive extraction programs."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2133842521"
                        ],
                        "name": "Ke Wang",
                        "slug": "Ke-Wang",
                        "structuredName": {
                            "firstName": "Ke",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ke Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145532847"
                        ],
                        "name": "Huiqing Liu",
                        "slug": "Huiqing-Liu",
                        "structuredName": {
                            "firstName": "Huiqing",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huiqing Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Others have derived constraints from typed hierarchies [41] and recurrent subpatterns [47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Tables have a particular spatial layout of material [47] that carries significant meaning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52857898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "493257636a7239f63c08b29511b7c8f7fa498b7a",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "To formulate a meaningful query on semistructured data, such as on the Web, that matches some of the source's structure, we need first to discover something about how the information is represented in the source. This is referred to as schema discovery and was considered for a single object recently. In the case of multiple objects, the task of schema discovery is to identify typical structuring information of those objects as a whole. We motivate the schema discovery in this general setting and propose a framework and algorithm for it. We apply the framework to a real Web database, the Internet Movies Database, to discover typical schema of most voted movies."
            },
            "slug": "Schema-Discovery-for-Semistructured-Data-Wang-Liu",
            "title": {
                "fragments": [],
                "text": "Schema Discovery for Semistructured Data"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work motivates the schema discovery in this general setting and proposes a framework and algorithm for it and applies the framework to a real Web database, the Internet Movies Database, to discover typical schema of most voted movies."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30699745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cd207fa19e51db1d6eadb0e5e70f1c5b8d1ecd0",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are the only acceptable means of communicating certain types of structured data. A precise definition of \"tabularity\" remains elusive because some bureaucratic forms, multicolumn text layouts, and schematic drawings share many characteristics of tables. There are significant differences between typeset tables, electronic files designed for display of tables, and tables in symbolic form intended for information retrieval. Although most research to date has addressed the extraction of low-level geometric information from scanned raster images of paper tables, the recent trend toward the analysis of tables in electronic form may pave the way to a higherl evel of table understanding. \n \nRecent research on table composition and table analysis has improved ourunde rstanding of the distinction between the logical and physical structures of tables, and has led to improved formalisms for modeling tables. The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display. \n \nAlthough tables are not a conventional format for conveying the primary content of technical papers, here we attempt to subdue our natural garrulity by adopting this genre to communicate what we have to say about tables entirely in tabular form."
            },
            "slug": "A-Tabular-Survey-of-Automated-Table-Processing-Lopresti-Nagy",
            "title": {
                "fragments": [],
                "text": "A Tabular Survey of Automated Table Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791194"
                        ],
                        "name": "M. Schoop",
                        "slug": "M.-Schoop",
                        "structuredName": {
                            "firstName": "Mareike",
                            "lastName": "Schoop",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schoop"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2748525"
                        ],
                        "name": "A. Becks",
                        "slug": "A.-Becks",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Becks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Becks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761310"
                        ],
                        "name": "C. Quix",
                        "slug": "C.-Quix",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Quix",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Quix"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144627127"
                        ],
                        "name": "T. Burwick",
                        "slug": "T.-Burwick",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Burwick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Burwick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49943313"
                        ],
                        "name": "C. Engels",
                        "slug": "C.-Engels",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Engels",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Engels"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744383"
                        ],
                        "name": "M. Jarke",
                        "slug": "M.-Jarke",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Jarke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jarke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "SEWASIE [43] is an integrated Semantic Web environment that allows advanced search capabilities for small and medium enterprises in the EU."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Others have recognized the importance of this conversion and are working on research and commercial efforts to address this particular issue [1,39,43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11251215,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1f686dbe307bf3f05cb4ea22085417228a48e0b",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The SEWASIE project within the Semantic Web Action Line of the European IST Programme focuses on the question how to assist networks of small and medium enterprises (so-called Integrated Economies) in enhancing their intra-and inter-organisational information management capabilities. While the project also includes novel techniques for semantic enrichment, query management, and presentation techniques in multi-lingual information acquisition from the web, this paper addresses the question how to further exploit the acquired information; firstly, by linking it into more established decision support environments based on OLAP technologies; secondly, by using it as a basis to engage in negotiations concerning inter-organisational cooperation across European countries. Specific application domains studied within the project include financial reporting and controlling systems for the intraorganisational aspects, and fashion design applications as a typical example of inter-organisational cooperation."
            },
            "slug": "Enhancing-Decision-and-Negotiation-Support-in-Web-Schoop-Becks",
            "title": {
                "fragments": [],
                "text": "Enhancing Decision and Negotiation Support in Enterprise Networks Through Semantic Web Technologies"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper addresses the question how to further exploit the acquired information by linking it into more established decision support environments based on OLAP technologies and using it as a basis to engage in negotiations concerning inter-organisational cooperation across European countries."
            },
            "venue": {
                "fragments": [],
                "text": "XSW"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35078820"
                        ],
                        "name": "F. D. Marchi",
                        "slug": "F.-D.-Marchi",
                        "structuredName": {
                            "firstName": "Fabien",
                            "lastName": "Marchi",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. Marchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3148280"
                        ],
                        "name": "St\u00e9phane Lopes",
                        "slug": "St\u00e9phane-Lopes",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Lopes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phane Lopes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1852297"
                        ],
                        "name": "Jean-Marc Petit",
                        "slug": "Jean-Marc-Petit",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Petit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Marc Petit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699022"
                        ],
                        "name": "F. Toumani",
                        "slug": "F.-Toumani",
                        "structuredName": {
                            "firstName": "Farouk",
                            "lastName": "Toumani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Toumani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2422034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d92a78ce9fb00a171845f7ce85f17a5a837e2e00",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Whereas physical database tuning has received a lot of attention over the last decade, logical database tuning seems to be under-studied. We have developed a project called DBA Companion devoted to the understanding of logical database constraints from which logical database tuning can be achieved.In this setting, two main data mining issues need to be addressed: the first one is the design of efficient algorithms for functional dependencies and inclusion dependencies inference and the second one is about the interestingness of the discovered knowledge. In this paper, we point out some relationships between database analysis and data mining. In this setting, we sketch the underlying themes of our approach. Some database applications that could benefit from our project are also described, including logical database tuning."
            },
            "slug": "Analysis-of-existing-databases-at-the-logical-the-Marchi-Lopes",
            "title": {
                "fragments": [],
                "text": "Analysis of existing databases at the logical level: the DBA companion project"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Some relationships between database analysis and data mining are pointed out and some database applications that could benefit from the project are described, including logical database tuning."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399766127"
                        ],
                        "name": "V. Markowitz",
                        "slug": "V.-Markowitz",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Markowitz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Markowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746603"
                        ],
                        "name": "J. Makowsky",
                        "slug": "J.-Makowsky",
                        "structuredName": {
                            "firstName": "Johann",
                            "lastName": "Makowsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 152
                            }
                        ],
                        "text": "The literature describes many techniques for reverse engineering relational databases and schemas into conceptual models and entity-relationship models [9,25,35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31572461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2cfcd43a593a4dbbb71bf07307d96997641804b",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Relational schemas consisting of relation-schemes, key dependencies and key-based inclusion dependencies (referential integrity constraints) are considered. Schemas of this form are said to be entity-relationship (EER)-convertible if they can be associated with an EER schema. A procedure that determines whether a relational schema is EER-convertible is developed. A normal form is proposed for relational schemas representing EER object structures. For EER-convertible relational schemas, the corresponding normalization procedure is presented. The procedures can be used for analyzing the semantics of existing relational databases and for converting relational database schemas into object-oriented database schemas. >"
            },
            "slug": "Identifying-Extended-Entity-Relationship-Object-in-Markowitz-Makowsky",
            "title": {
                "fragments": [],
                "text": "Identifying Extended Entity-Relationship Object Structures in Relational Schemas"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A procedure that determines whether a relational schema is EER-convertible is developed, a normal form is proposed for relational schemas representing EER object structures, and the corresponding normalization procedure is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Software Eng."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This auxiliary information includes dictionaries and lexical data (including WordNet [22], natural language parsers, and data frames [14], which are similar in intent to the base knowledge for ontologies proposed in [44]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": false,
            "numCitedBy": 13573,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771093"
                        ],
                        "name": "Svetlozar Nestorov",
                        "slug": "Svetlozar-Nestorov",
                        "structuredName": {
                            "firstName": "Svetlozar",
                            "lastName": "Nestorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Svetlozar Nestorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69026873"
                        ],
                        "name": "S. Abiteboul",
                        "slug": "S.-Abiteboul",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Abiteboul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Abiteboul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84095744"
                        ],
                        "name": "R. Motwani",
                        "slug": "R.-Motwani",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Motwani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Motwani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "Others have derived constraints from typed hierarchies [41] and recurrent subpatterns [47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2990663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0e7c72c646bcbdaa00cea58fad5b94058e706eb",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Semistructured data is characterized by the lack of any fixed and rigid schema, although typically the data has some implicit structure. While the lack of fixed schema makes extracting semistructured data fairly easy and an attractive goal, presenting and querying such data is greatly impaired. Thus, a critical problem is the discovery of the structure implicit in semistructured data and, subsequently, the recasting of the raw data in terms of this structure. In this paper, we consider a very general form of semistructured data based on labeled, directed graphs. We show that such data can be typed using the greatest fixpoint semantics of monadic datalog programs. We present an algorithm for approximate typing of semistructured data. We establish that the general problem of finding an optimal such typing is NP-hard, but present some heuristics and techniques based on clustering that allow efficient and near-optimal treatment of the problem. We also present some preliminary experimental results."
            },
            "slug": "Extracting-schema-from-semistructured-data-Nestorov-Abiteboul",
            "title": {
                "fragments": [],
                "text": "Extracting schema from semistructured data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is established that the general problem of finding an optimal form of semistructured data based on labeled, directed graphs is NP-hard, but some heuristics and techniques based on clustering that allow efficient and near-optimal treatment of the problem are presented."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We have also had some experience working with this more general table transformation problem\u2014indeed, we have been invited to write a survey of table-processing work [ 17 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10215983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8eb9090db385fd6fa77f02736f48d7c98a8d6a5",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 110,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are a ubiquitous form of communication. While everyone seems to know what a table is, a precise, analytical definition of \u201ctabularity\u201d remains elusive because some bureaucratic forms, multicolumn text layouts, and schematic drawings share many characteristics of tables. There are significant differences between typeset tables, electronic files designed for display of tables, and tables in symbolic form intended for information retrieval. Most past research has addressed the extraction of low-level geometric information from raster images of tables scanned from printed documents, although there is growing interest in the processing of tables in electronic form as well. Recent research on table composition and table analysis has improved our understanding of the distinction between the logical and physical structures of tables, and has led to improved formalisms for modeling tables. This review, which is structured in terms of generalized paradigms for table processing, indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "slug": "Table-processing-paradigms:-a-research-survey-Embley-Hurst",
            "title": {
                "fragments": [],
                "text": "Table-processing paradigms: a research survey"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This review, which is structured in terms of generalized paradigms for table processing, indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2994348"
                        ],
                        "name": "S. Clyde",
                        "slug": "S.-Clyde",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clyde",
                            "middleNames": [
                                "Wright"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clyde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459390"
                        ],
                        "name": "S. Woodfield",
                        "slug": "S.-Woodfield",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Woodfield",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Woodfield"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Congruency principles [10,24] attempt to ensure that all objects in an object set have the same properties; the objects in an object set are congruent when this principle holds and are otherwise incongruent."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3046926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14427443a74644c85a08eba0be68c1b71d3de1a9",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A new concept for assessing the quality of object classes in analysis models, called object-class congruency, is formally defined and discussed. Object-class congruency is based on the idea that immediate and inherited properties defined for an object class should match the common properties of the class's members. A semantic model with a formal definition is used to formalize these concepts. In addition to defining object-class congruency, two semantic-preserving transformations that convert incongruent classes into congruent classes are given. It is also explained why object-class congruency leads to better abstraction of real-world concepts and to better implementation, extension, and reuse."
            },
            "slug": "Improving-the-quality-of-systems-and-domain-through-Clyde-Embley",
            "title": {
                "fragments": [],
                "text": "Improving the quality of systems and domain analysis through object class congruency"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new concept for assessing the quality of object classes in analysis models, called object-class congruency, is formally defined and discussed, and two semantic-preserving transformations that convert incongruent classes into congruent classes are given."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Symposium and Workshop on Engineering of Computer-Based Systems"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152312240"
                        ],
                        "name": "Ming Xu",
                        "slug": "Ming-Xu",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [21], we introduced an interactive approach for reverse engineering, upon which we expand further in this paper."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17106391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c0bb6f4ed0f6f9f57ce58f0cb9656d24d091333",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Approaches to relational database reverse engineering often expect that the input has desirable characteristics and that it is complete; they also often fail to provide formal guarantees that their results are faithful to the initial input. Both of these problems can be addressed by using an incremental approach based on a formally defined target model. The incremental approach we propose in this paper quickly produces an initial model instance that is provably equivalent to the original relational database, which is assumed to be correct but may lack desirable characteristics and may be incomplete. The approach then proceeds incrementally using provably correct transformations. These incremental transformations allow for user interaction to provide needed information that may be missing or hard to obtain because the input lacks some desirable characteristics."
            },
            "slug": "Relational-database-reverse-engineering:-a-approach-Embley-Xu",
            "title": {
                "fragments": [],
                "text": "Relational database reverse engineering: a model-centric, transformational, interactive approach formalized in model theory"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The incremental approach proposed in this paper quickly produces an initial model instance that is provably equivalent to the original relational database, which is assumed to be correct but may lack desirable characteristics and may be incomplete."
            },
            "venue": {
                "fragments": [],
                "text": "Database and Expert Systems Applications. 8th International Conference, DEXA '97. Proceedings"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791339"
                        ],
                        "name": "Valter Crescenzi",
                        "slug": "Valter-Crescenzi",
                        "structuredName": {
                            "firstName": "Valter",
                            "lastName": "Crescenzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valter Crescenzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785690"
                        ],
                        "name": "G. Mecca",
                        "slug": "G.-Mecca",
                        "structuredName": {
                            "firstName": "Giansalvatore",
                            "lastName": "Mecca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mecca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796590"
                        ],
                        "name": "P. Merialdo",
                        "slug": "P.-Merialdo",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Merialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Merialdo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Identify Columns: Analysis of patterns using techniques described in [11] leads TANGO to the segmentation shown in Table 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15075203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3dd1f9f7795b31493d98d9f260d37aad07550f6e",
            "isKey": false,
            "numCitedBy": 1157,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper investigates techniques for extracting data from HTML sites through the use of automatically generated wrappers. To automate the wrapper generation and the data extraction process, the paper develops a novel technique to compare HTML pages and generate a wrapper based on their similarities and dierences. Experimental results on real-life data-intensive Web sites confirm the feasibility of the approach."
            },
            "slug": "RoadRunner:-Towards-Automatic-Data-Extraction-from-Crescenzi-Mecca",
            "title": {
                "fragments": [],
                "text": "RoadRunner: Towards Automatic Data Extraction from Large Web Sites"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel technique to compare HTML pages and generate a wrapper based on their similarities and dierences is developed, which confirms the feasibility of the approach on real-life data-intensive Web sites."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We have chosen to use OSM [19] for the representation of our ontologies in TANGO because of the richness this representation affords us.6 OSM is an expressive objectoriented model for system analysis, specification, design, implementation, and evolution [ 15 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5229741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "097baa637f9c660a7a875b1a7984fa7ee3c1fd08",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nFEATURES: \nTakes an object-oriented approach to modeling and developing database applications. Provides a seamless way to move from analysis through specification and design into implementation. Focuses on concepts and principles that provide a sound theoretical foundation for database application development. Presents several case studies (Oracle, UniSQL, O2, ObjectStore, and Ode), that show how to turn theory into practice."
            },
            "slug": "Object-database-development-concepts-and-principles-Embley",
            "title": {
                "fragments": [],
                "text": "Object database development - concepts and principles"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This book focuses on concepts and principles that provide a sound theoretical foundation for database application development and presents several case studies that show how to turn theory into practice."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145249669"
                        ],
                        "name": "D. Maier",
                        "slug": "D.-Maier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Maier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789064"
                        ],
                        "name": "L. Delcambre",
                        "slug": "L.-Delcambre",
                        "structuredName": {
                            "firstName": "Lois",
                            "lastName": "Delcambre",
                            "middleNames": [
                                "M.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Delcambre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In addition, the prototype system superimposes the metadata of the extracted information over the document for direct access to data in context, as suggested in [33]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12564735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54d59a5ddecb8a86b236bd84cdf55050ef85d2d0",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "It has existed for several millennia, in the form of commentaries on religious books, law and literature. We see it today in concordances, citation indexes and genome maps. You probably have created some of it, as a bookmark file in your web browser. The \u201cit\u201d we refer to is superimposed information: data \u201cplaced over\u201d existing information sources to help organize, access, connect and reuse information elements in those sources."
            },
            "slug": "Superimposed-Information-for-the-Internet-Maier-Delcambre",
            "title": {
                "fragments": [],
                "text": "Superimposed Information for the Internet"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Superimposed information is data \u201cplaced over\u201d existing information sources to help organize, access, connect and reuse information elements in those sources."
            },
            "venue": {
                "fragments": [],
                "text": "WebDB"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47401171"
                        ],
                        "name": "Jeannett Martin",
                        "slug": "Jeannett-Martin",
                        "structuredName": {
                            "firstName": "Jeannett",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeannett Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113043861"
                        ],
                        "name": "R. Veel",
                        "slug": "R.-Veel",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Veel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Veel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141873539,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "a69be36b212d1f4282e1006330893a3cd97da1d7",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Reading Science looks at the distinctive language of science and technology and the role it plays in building up scientific understandings of the world. It brings together discourse analysis and critical theory for the first time in a single volume. This edited collection examines science discourse from a number of perspectives, drawing on new rhetoric, functional linguistics and critical theory. It explores this language in research and industrial contexts as well as in educational settings and in popular science writing and science fiction. The papers also include consideration of the role of images (tables and figures) in science writing and the importance of reading science discourse as multi-modal text. The internationally renowned contributors include M. A. K. Halliday, Charles Bazerman and Jay Lemke."
            },
            "slug": "Reading-Science:-Critical-and-Functional-on-of-Martin-Veel",
            "title": {
                "fragments": [],
                "text": "Reading Science: Critical and Functional Perspectives on Discourses of Science"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "This auxiliary information includes dictionaries and lexical data (including WordNet [22], natural language parsers, and data frames [14], which are similar in intent to the base knowledge for ontologies proposed in [44]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36636619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fe9665485693a4b942a260b369c71158305264a",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Processing everyday data items such as dollar amounts, time, dates, and account numbers constitutes a significant portion of real-world computer applications. Programmers involved with everyday data items confront the drudgery of writing routines to recognize, validate, transform, store, retrieve, manipulate, and display these items and also the challenge to develop user-friendly data-entry systems and insure data integrity. They usually meet these challenges using various and sundry ad hoc techniques."
            },
            "slug": "Programming-with-data-frames-for-everyday-data-Embley",
            "title": {
                "fragments": [],
                "text": "Programming with data frames for everyday data items"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Today's programmers confront the drudgery of writing routines to recognize, validate, transform, store, retrieve, manipulate, and display these items and also the challenge to develop user-friendly data-entry systems and insure data integrity."
            },
            "venue": {
                "fragments": [],
                "text": "AFIPS '80"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1931887"
                        ],
                        "name": "B. D. Kurtz",
                        "slug": "B.-D.-Kurtz",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Kurtz",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Kurtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459390"
                        ],
                        "name": "S. Woodfield",
                        "slug": "S.-Woodfield",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Woodfield",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Woodfield"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We choose it because: (1) it is fully formal in terms of first-order predicate calculus [19], (2) it covers the typical ontological properties of interest\u2014ISA hierarchies, part/whole hierarchies, relationships, and concepts including lexical appearance, representation, and computational manipulation, and (3) it has specialized tools for ontology creation and manipulation, ontological table understanding [20], ontological data extraction, and ontological data integration [50]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We have chosen to use OSM [19] for the representation of our ontologies in TANGO because of the richness this representation affords us."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For a complete description of OSM formal semantics, the reader should consult the appendix on [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5398752,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5c17fd917ce77c29f5c7e710b1cc3ea406c23a5",
            "isKey": false,
            "numCitedBy": 350,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction. 2. The Object-Relationship Model. 3. Object Behavior Models. 4. Building the System Specification. 5. Verifying the System Specification. 6. Preparing for System Design. 7. Two Case Studies."
            },
            "slug": "Object-oriented-systems-analysis-a-model-driven-Embley-Kurtz",
            "title": {
                "fragments": [],
                "text": "Object-oriented systems analysis - a model-driven approach"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The Object-Relationship Model is used as a guide for system design, and the Object Behavior Models are used for modeling human interaction with the system."
            },
            "venue": {
                "fragments": [],
                "text": "Yourdon Press Computing series"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145249669"
                        ],
                        "name": "D. Maier",
                        "slug": "D.-Maier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Maier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Using a standard, formal definition of a relational database table [ 32 ], we can define a canonical table as follows."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 215753726,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dca5a035bf1d99e5e01adc77d6ed9f2338f254f5",
            "isKey": false,
            "numCitedBy": 1791,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "1. The method of operating a water-cooled neutronic reactor having a graphite moderator which comprises flowing a gaseous mixture of carbon dioxide and helium, in which the helium comprises 40-60 volume percent of the mixture, in contact with the graphite moderator."
            },
            "slug": "The-Theory-of-Relational-Databases-Maier",
            "title": {
                "fragments": [],
                "text": "The Theory of Relational Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The method of operating a water-cooled neutronic reactor having a graphite moderator which comprises flowing a gaseous mixture of carbon dioxide and helium, in which the helium comprises 40-60 volume percent of the mixture, in contact with thegraphite moderator."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Partial canonicalized table for world religious populations [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "These mappings and matchings strongly suggest that the two ternary Population relationship sets 3(a) from [12] and 3(b) from [49] match."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Partial page of world religious populations [12]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "The fact that someone apparently took the trouble to reorganize the information in [12] in a structure different from its source [49] is interesting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "dlbeck.com"
            },
            "venue": {
                "fragments": [],
                "text": "www.dlbeck.com/population.htm."
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403176300"
                        ],
                        "name": "Tim Berners-Lee",
                        "slug": "Tim-Berners-Lee",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Berners-Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Berners-Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701341"
                        ],
                        "name": "J. Hendler",
                        "slug": "J.-Hendler",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hendler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hendler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35003282"
                        ],
                        "name": "O. Lassila",
                        "slug": "O.-Lassila",
                        "structuredName": {
                            "firstName": "Ora",
                            "lastName": "Lassila",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Lassila"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56818714,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57820e6f974d198bf4bbdf26ae7e1063bac190c3",
            "isKey": false,
            "numCitedBy": 8577,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Semantic-Web\"-in-Scientific-American-Berners-Lee-Hendler",
            "title": {
                "fragments": [],
                "text": "The Semantic Web\" in Scientific American"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2537776"
                        ],
                        "name": "Jean-Luc Hainaut",
                        "slug": "Jean-Luc-Hainaut",
                        "structuredName": {
                            "firstName": "Jean-Luc",
                            "lastName": "Hainaut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Luc Hainaut"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The literature describes many techniques for reverse engineering relational databases and schemas into conceptual models and entity-relationship models [9,25,35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9830537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91c6216b5fbfa3993af98ea88d5c41c4ef165768",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Database-Reverse-Engineering:-Models,-Techniques,-Hainaut",
            "title": {
                "fragments": [],
                "text": "Database Reverse Engineering: Models, Techniques, and Strategies"
            },
            "venue": {
                "fragments": [],
                "text": "ER"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "MoA [39] is an effort sponsored by the Korean Ministry of Information to allow mapping and merging of distributed OWL ontologies and content."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 141
                            }
                        ],
                        "text": "Others have recognized the importance of this conversion and are working on research and commercial efforts to address this particular issue [1,39,43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MoA\u2014An OWL ontology merging and alignment tool"
            },
            "venue": {
                "fragments": [],
                "text": "http://mknows. etri.re.kr/moa/index.html."
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "WordNet"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The World Factbook\u20142003"
            },
            "venue": {
                "fragments": [],
                "text": "The World Factbook\u20142003"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conceptual schema analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Lamke [28] describes tables as \u201corganizational resources to enable meaningful relations to be recovered from bare thematic items in the absence of grammatical constructions,\u201d and argues that there is always \u201can implied grammar\u201d and a recoverable textual sentence or paragraph for every table."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiplying meaning: Visual and verbal semiotics in scientific text"
            },
            "venue": {
                "fragments": [],
                "text": "J. Martin and R. Veel (eds.), Reading Science: Critical and Functional Perspectives on Discourses of Science. Routledge, 1998, pp. 87\u2013113."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "Our table analysis approach to ontology generation addresses the principled creation of ontologies based on the content of canonicalized tables."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A tabular survey of table processing"
            },
            "venue": {
                "fragments": [],
                "text": "Graphics Recognition\u2014Recent Advances"
            },
            "year": 1941
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Partial canonicalized table for US topographical maps [46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TopoZone"
            },
            "venue": {
                "fragments": [],
                "text": "www.topozone.com."
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Partial canonicalized table for most spoken languages [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The 30 most spoken languages of the world"
            },
            "venue": {
                "fragments": [],
                "text": "www.krysstal.com/spoken.html, 2003."
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "Partial canonicalized table for largest populations [48]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "WorldAtlas.Com"
            },
            "venue": {
                "fragments": [],
                "text": "2003, www.worldatlas.com/geoquiz/thelist.htm."
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards principles for the design of ontologies used for knowledge sharing Formal Ontology in Conceptual Analysis and Knowledge Representation"
            },
            "venue": {
                "fragments": [],
                "text": "Towards principles for the design of ontologies used for knowledge sharing Formal Ontology in Conceptual Analysis and Knowledge Representation"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Schema discovery for semistructured data , \u201d in Proceedings of the Third International Conference on Knowledge Discovery and Data Mining"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards ontology engineering , \u201d in proceedings of the Joint 1997 Pacific Asian Conference on Expert Systems / Singapore International Conference on Intelligent Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "Other similar principles of formal ontology construction also apply [24], as well as related work on merging ontologies (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 22
                            }
                        ],
                        "text": "Congruency principles [10,24] attempt to ensure that all objects in an object set have the same properties; the objects in an object set are congruent when this principle holds and are otherwise incongruent."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Formal ontologies and information systems"
            },
            "venue": {
                "fragments": [],
                "text": "N. Guarino (ed.), Proceedings of the First International Conference on Formal Ontology in Information Systems (FOIS98). Trento, Italy, 1998, pp. 3\u201315.  284  TIJERINO ET AL."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Using a standard, formal definition of a relational database table [32], we can define a canonical table as follows."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Theory of Relational Databases, Computer Science Press, Inc"
            },
            "venue": {
                "fragments": [],
                "text": "Rockville, Maryland,"
            },
            "year": 1983
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 22,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 60,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Towards-Ontology-Generation-from-Tables-Tijerino-Embley/288673018a6f48a8aa20936833bcd3ef8661508b?sort=total-citations"
}