{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145328018"
                        ],
                        "name": "M. Oren",
                        "slug": "M.-Oren",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Oren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "est operator\u201d or some other automatic method to select a small set of features to use [ 81 ][39][82]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "resentation divide input space with a hyperplane, conic section[19][ 81 ][82], etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7967646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd0534a87e09b3d64b7e7462e2684c60c9aca1f5",
            "isKey": false,
            "numCitedBy": 837,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes. This problem poses several challenges. People are highly non-rigid objects with a high degree of variability in size, shape, color, and texture. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or on motion. The detection technique is based on the novel idea of the wavelet template that defines the shape of an object in terms of a subset of the wavelet coefficients of the image. It is invariant to changes in color and texture and can be used to robustly define a rich and complex class of objects such as people. We show how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "slug": "Pedestrian-detection-using-wavelet-templates-Oren-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection using wavelet templates"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes and shows how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8989489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d781d5e651e12bf666cf993ae307db785113b9ae",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >"
            },
            "slug": "Recognition-by-Linear-Combinations-of-Models-Ullman-Basri",
            "title": {
                "fragments": [],
                "text": "Recognition by Linear Combinations of Models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed and it is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "developed a weaker representation based on a subset of localized eigenvectors [ 76 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We noticed such an improvement in an earlier method based on eigenvector responses [ 76 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1060186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbe488bb190d75f4b665d43e306bcab1ab228890",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe an algorithm for object recognition that explicitly models and estimated the posterior probability function, P(object/image). We have chosen a functional form of the posterior probability function that captures the joint statistics of local appearance and position on the object as well as the statistics of local appearance in the visual world at large. We use a discrete representation of local appearance consisting of approximately 10/sup 6/ patterns. We compute an estimate of P(object/image) in closed form by counting the frequency of occurrence of these patterns over various sets of training images. We have used this method for detecting human faces from frontal and profile views. The algorithm for frontal views has shown a detection rate of 93.0% with 88 false alarms on a set of 125 images containing 483 faces combining the MIT test set of Sung and Poggio with the CMU test sets of Rowley, Baluja, and Kanade. The algorithm for detection of profile views has also demonstrated promising results."
            },
            "slug": "Probabilistic-modeling-of-local-appearance-and-for-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "Probabilistic modeling of local appearance and spatial relationships for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "An algorithm for object recognition that explicitly models and estimated the posterior probability function, P(object/image) in closed form is described, which captures the joint statistics of local appearance and position on the object as well as the statistics ofLocal appearance in the visual world at large."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2023498"
                        ],
                        "name": "Thomas D. Rikert",
                        "slug": "Thomas-D.-Rikert",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Rikert",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas D. Rikert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17251623,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25bb1db7eff259fcc4e906f81184a1e07db9ff29",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an approach to object detection which is based on recent work in statistical models for texture synthesis and recognition. Our method follows the texture recognition work of De Bonet and Viola (1998). We use feature vectors which capture the joint occurrence of local features at multiple resolutions. The distribution of feature vectors for a set of training images of an object class is estimated by clustering the data and then forming a mixture of Gaussian models. The mixture model is further refined by determining which clusters are the most discriminative for the class and retaining only those clusters. After the model is learned, test images are classified by computing the likelihood of their feature vectors with respect to the model. We present promising results in applying our technique to face detection and car detection."
            },
            "slug": "A-cluster-based-statistical-model-for-object-Rikert-Jones",
            "title": {
                "fragments": [],
                "text": "A cluster-based statistical model for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper presents an approach to object detection which is based on recent work in statistical models for texture synthesis and recognition, and presents promising results in applying the technique to face detection and car detection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145328018"
                        ],
                        "name": "M. Oren",
                        "slug": "M.-Oren",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Oren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "est operator\u201d or some other automatic method to select a small set of features to use [81][39][ 82 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "resentation divide input space with a hyperplane, conic section[19][81][ 82 ], etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6476085,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76f560991d56ad689ec32f9e9d13291e0193f4cf",
            "isKey": false,
            "numCitedBy": 1604,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a general trainable framework for object detection in static images of cluttered scenes. The detection technique we develop is based on a wavelet representation of an object class derived from a statistical analysis of the class instances. By learning an object class in terms of a subset of an overcomplete dictionary of wavelet basis functions, we derive a compact representation of an object class which is used as an input to a support vector machine classifier. This representation overcomes both the problem of in-class variability and provides a low false detection rate in unconstrained environments. We demonstrate the capabilities of the technique in two domains whose inherent information content differs significantly. The first system is face detection and the second is the domain of people which, in contrast to faces, vary greatly in color, texture, and patterns. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or motion-based segmentation. The paper also presents a motion-based extension to enhance the performance of the detection algorithm over video sequences. The results presented here suggest that this architecture may well be quite general."
            },
            "slug": "A-general-framework-for-object-detection-Papageorgiou-Oren",
            "title": {
                "fragments": [],
                "text": "A general framework for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A general trainable framework for object detection in static images of cluttered scenes based on a wavelet representation of an object class derived from a statistical analysis of the class instances and a motion-based extension to enhance the performance of the detection algorithm over video sequences is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 9
                            }
                        ],
                        "text": "Sung and Poggio developed one of the first methods for frontal face detection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "78 mal set of hand-picked features, such as the eyes, nose, mouth on a face or a minimal set determined by an automatic method [39], [81], [82], [83]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 18
                            }
                        ],
                        "text": "[18] K-K Sung, T. Poggio.\u201d"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 18
                            }
                        ],
                        "text": "80\n9.2.1 Sung and Poggio [18] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80 9.2.2 Rowley, Baluja, and Kanade [14] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .81 9.2.3 Osuna, Freund, and Girosi [19] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.4 Moghaddam and Pentland [12] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.5 Colmenarez and Huang [20] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .84 9.2.6 Burl and Perona [26] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .86 9.2.7 Roth, Yang, Ahuja [38] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .89\n9.3 Summary of Previous Methods for Car Detection . . . . . . . . . . . . . . . . . . . . . . . . . ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Papageorgiou, Poggio [83] In this method the Haar wavelet transform is taken of each input region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 32
                            }
                        ],
                        "text": "100\n[83] C. P. Papageorgiou, T. Poggio."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 510,
                                "start": 504
                            }
                        ],
                        "text": "I would also like to thank the many people with whom I had valuable discussions, provided helpful feedback on my research, and provided technical assistance including Chris Lee, Alan Lipton, Rahul Sukthankar, Tim Doebler, Larry Ray, Farhana Kagalwala, David LaRose, Michael Nechyba, Frank Dellaert, Mark Ollis, Simon Baker, Teck Khim Ng, Chris Diehl, Dennis Strewlow, Martin Martin, Dongmei Zhang, YingLi Tian, Bob Collins, Jeff Cohn, Terence Sim, Dave Duggins, Tom Drayer, Yanxi Liu, Tsuhan Chen, Tommy Poggio, Huang Fu Jie, Steve Seitz, Sundar Vedula, Jeff Schneider, Geoff Gordon, and Marina Meila."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 207
                            }
                        ],
                        "text": "Below in Table 10 we compare our face detectors (wavelet-based and eigenvector-based [76]) with those results reported by others on the combined frontal face test set combining the test images from Sung and Poggio [18] and Rowley, Baluja, and Kanade [14]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "This algorithm works under a very similar principle to support vector machines [15] as used by [19] [81], [82], [83] by giving more weight to the training examples that are closet to the decision boundary between the two classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 36
                            }
                        ],
                        "text": "[82]C. P. Papageorgiou, M. Oren, T. Poggio."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Representation of Local Appearance using Wavelets Haar wavelets [81], [82], [83], Gaussian pyramid representation [84] and Gabor wavelets [78], [79] are all multi-resolution based representations that have been used in object recognition/detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 28
                            }
                        ],
                        "text": "Fredercio Girosi and Tomaso Poggio."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 150
                            }
                        ],
                        "text": "In all their algorithms, each 20x20 input region is pre-processed to correct for differences in\nlighting conditions using the same method as Sung and Poggio [18]: a linear function of intensity is fit to the region and subtracted out, then histogram normalization is performed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "[81], [82], [83] achieve partition of input space into conic sections."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 46
                            }
                        ],
                        "text": "This method performs quite well on the Sung & Poggio and Rowley, Baluja, Kanade Test set."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 54
                            }
                        ],
                        "text": "[81] M. Oren, C. Papageorgiou, P. Sinha, E. Osuna, T. Poggio."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 20
                            }
                        ],
                        "text": "Soon after Sung and Poggio\u2019s algorithm, Rowley, Baluja, and Kanade developed a slightly\nmore accurate method for frontal face detection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Other methods represent geometry rigidly [14], [19], [81], [82], [83], [38] and may be brittle to small variation in the part positions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 134
                            }
                        ],
                        "text": "90\n9.3.1 Rajagopalan, Burlina, Chellappa [44] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .90 9.3.2 Papageorgiou, Poggio [83] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\n10 Conclusion 91\nReferences 95\n1\nChapter 1."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17401288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17efd600baf55c77cff5375805cf0336b8e76375",
            "isKey": true,
            "numCitedBy": 73,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a general, trainable architecture for object detection that has previously been applied to face and people detection with a new application to car detection in static images. Our technique is a learning based approach that uses a set of labeled training data from which an implicit model of an object class { here, cars { is learned. Instead of pixel representations that may be noisy and therefore not provide a compact representation for learning, our training images are transformed from pixel space to that of Haar wavelets that respond to local, oriented, multiscale intensity di erences. These feature vectors are then used to train a support vector machine classi er. The detection of cars in images is an important step in applications such as tra c monitoring, driver assistance systems, and surveillance, among others. We show several examples of car detection on out-of-sample images and show an ROC curve that highlights the performance of our system. Copyright c Massachusetts Institute of Technology, 1999 This report describes research done within the Center for Biological and Computational Learning in the Department of Brain and Cognitive Sciences and at the Arti cial Intelligence Laboratory at the Massachusetts Institute of Technology. This research is sponsored by ONR/MURI grant N00014-95-1-0600. Additional support is provided by Eastman Kodak Company, DaimlerChrysler, Siemens Corporate Research, Inc. and AT&T."
            },
            "slug": "A-Trainable-Object-Detection-System:-Car-Detection-Papageorgiou-Poggio",
            "title": {
                "fragments": [],
                "text": "A Trainable Object Detection System: Car Detection in Static Images"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "This paper describes a general, trainable architecture for object detection that has previously been applied to face and people detection with a new application to car detection in static images that uses a set of labeled training data from which an implicit model of an object class { here, cars { is learned."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3453447"
                        ],
                        "name": "J. Mundy",
                        "slug": "J.-Mundy",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Mundy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mundy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46980900"
                        ],
                        "name": "C. Coelho",
                        "slug": "C.-Coelho",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Coelho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Coelho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39451362"
                        ],
                        "name": "A. Heller",
                        "slug": "A.-Heller",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Heller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Heller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144760431"
                        ],
                        "name": "Charlie Rothwell",
                        "slug": "Charlie-Rothwell",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Rothwell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie Rothwell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ture representation and emphasize geometric relationships [32][41][45][ 46 ][47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13518062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a999b14b19c0a5741141dee02a6e252c82bd49b",
            "isKey": false,
            "numCitedBy": 449,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Invariant descriptors are shape descriptors that are unaffected by object pose, by perspective projection, or by the intrinsic parameters of the camera. These descriptors can be constructed using the methods of invariant theory, which are briefly surveyed. A range of applications of invariant descriptors in 3D model-based vision is demonstrated. First, a model-based vision system that recognizes curved plane objects irrespective of their pose is demonstrated. Curves are not reduced to polyhedral approximations but are handled as objects in their own right. Models are generated directly from image data. Once objects have been recognized, their pose can be computed. Invariant descriptors for 3D objects with plane faces are described. All these ideas are demonstrated using images of real scenes. The stability of a range of invariant descriptors to measurement error is treated in detail. >"
            },
            "slug": "Invariant-Descriptors-for-3D-Object-Recognition-and-Forsyth-Mundy",
            "title": {
                "fragments": [],
                "text": "Invariant Descriptors for 3D Object Recognition and Pose"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A model-based vision system that recognizes curved plane objects irrespective of their pose is demonstrated and the stability of a range of invariant descriptors to measurement error is treated in detail."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Sung and Poggio developed one of the first methods for frontal face detection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 9
                            }
                        ],
                        "text": "80\n9.2.1 Sung and Poggio [18] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80 9.2.2 Rowley, Baluja, and Kanade [14] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .81 9.2.3 Osuna, Freund, and Girosi [19] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.4 Moghaddam and Pentland [12] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.5 Colmenarez and Huang [20] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .84 9.2.6 Burl and Perona [26] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .86 9.2.7 Roth, Yang, Ahuja [38] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .89\n9.3 Summary of Previous Methods for Car Detection . . . . . . . . . . . . . . . . . . . . . . . . . ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 214
                            }
                        ],
                        "text": "Below in Table 10 we compare our face detectors (wavelet-based and eigenvector-based [76]) with those results reported by others on the combined frontal face test set combining the test images from Sung and Poggio [18] and Rowley, Baluja, and Kanade [14]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Mixture models [18][40] are also attractive because they can achieve complicated boundaries in input space but are also susceptible to local minima."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "To date, several researchers [14][18][19][20][38] have had success developing algorithms that work for frontal views of faces, but none, to our knowledge, have had success with profile (side) views except [87] (below we will compare our performance with [87])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Sung and Poggio [18] Sung and Poggio developed one of the first methods for frontal face detection."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "To select non-object samples that resemble the object, we used bootstrapping [18][14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "Table 10: Frontal Face Detection on Sung & Poggio and Rowley [18] & Baluja & Kanade Combined Test Set [14] Detection Rate False Detections Schneiderman and Kanade* (wavelet) 94."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 141
                            }
                        ],
                        "text": "In all their algorithms, each 20x20 input region is pre-processed to correct for differences in\nlighting conditions using the same method as Sung and Poggio [18]: a linear function of intensity is fit to the region and subtracted out, then histogram normalization is performed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "There are many ways to do this such as linear projection methods[5][29][30], and resolution reduction methods[14][18], or simply by hand selecting features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 46
                            }
                        ],
                        "text": "This method performs quite well on the Sung & Poggio and Rowley, Baluja, Kanade Test set."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "[14][18] And if so what and how do we select images and weight them?"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 11
                            }
                        ],
                        "text": "Soon after Sung and Poggio\u2019s algorithm, Rowley, Baluja, and Kanade developed a slightly\nmore accurate method for frontal face detection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] and [14] use artificial neural networks (multilayer perceptrons) as part of their discriminant functions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "In all their algorithms, each 20x20 input region is pre-processed to correct for differences in lighting conditions using the same method as Sung and Poggio [18]: a linear function of intensity is fit to the region and subtracted out, then histogram normalization is performed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": true,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46817286"
                        ],
                        "name": "F. Stein",
                        "slug": "F.-Stein",
                        "structuredName": {
                            "firstName": "Fridtjof",
                            "lastName": "Stein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3463966"
                        ],
                        "name": "G. Medioni",
                        "slug": "G.-Medioni",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Medioni",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Medioni"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7000203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ef554b855d29292238ffafbc3f5479f4b9527b6",
            "isKey": false,
            "numCitedBy": 569,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present an approach for the recognition of multiple 3-D object models from three 3-D scene data. The approach uses two different types of primitives for matching: small surface patches, where differential properties can be reliably computed, and lines corresponding to depth or orientation discontinuities. These are represented by splashes and 3-D curves, respectively. It is shown how both of these primitives can be encoded by a set of super segments, consisting of connected linear segments. These super segments are entered into a table and provide the essential mechanism for fast retrieval and matching. The issues of robustness and stability of the features are addressed in detail. The acquisition of the 3-D models is performed automatically by computing splashes in highly structured areas of the objects and by using boundary and surface edges for the generation of 3-D curves. The authors present results with the current system (3-D object recognition based on super segments) and discuss further extensions. >"
            },
            "slug": "Structural-Indexing:-Efficient-3-D-Object-Stein-Medioni",
            "title": {
                "fragments": [],
                "text": "Structural Indexing: Efficient 3-D Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The approach uses two different types of primitives for matching: small surface patches, where differential properties can be reliably computed, and lines corresponding to depth or orientation discontinuities, which are represented by splashes and 3-D curves, respectively."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "are algorithms that represent the object\u2019s appearance as a collections of parts (edges, corners, complex features) [9][ 10 ][39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1645354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40584f481ced3f5f4cee60362ca36854279158b3",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Objects can be represented by regions of local structure as well as dependencies between these regions. The appearance of local structure can be characterized by a vector of local features measured by local operators such as Gaussian derivatives or Gabor filters. This paper presents a technique in which the appearance of objects is represented by the joint statistics of local neighborhood operators. A probabilistic technique based on joint statistics is developed for the identification of multiple objects at arbitrary positions and orientations. Furthermore, by incorporating structural dependencies, a procedure for probabilistic localization of objects is obtained. The current recognition system runs at approximately 10 Hz on a Silicon 02. Experimental results are provided and an application using a head mounted camera is described."
            },
            "slug": "Probabilistic-object-recognition-and-localization-Schiele-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic object recognition and localization"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A Probabilistic technique based on joint statistics is developed for the identification of multiple objects at arbitrary positions and orientations and by incorporating structural dependencies, a procedure for probabilistic localization of objects is obtained."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .81 9.2.3 Osuna, Freund, and Girosi [19] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.4 Moghaddam and Pentland [12] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.5 Colmenarez and Huang [20] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .84 9.2.6 Burl and Perona [ 26 ] . ..."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "or some other relatively small subset of the visual information [ 26 ][4][40]? Do we use an \u201cinter-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "levels. 9.2.6. Burl and Perona [ 26 ] Burl and Perona have developed a method for face detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9204636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "044779db85dc83e2633951791b29bc311cfbae53",
            "isKey": true,
            "numCitedBy": 133,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new framework for recognizing planar object classes, which is based on local feature detectors and a probabilistic model of the spatial arrangement of the features. The allowed object deformations are represented through shape statistics, which are learned from examples. Instances of an object in an image are detected by finding the appropriate features in the correct spatial configuration. The algorithm is robust with respect to partial occlusion, detector false alarms, and missed features. A 94% success rate was achieved for the problem of locating quasi-frontal views of faces in cluttered scenes."
            },
            "slug": "Recognition-of-planar-object-classes-Burl-Perona",
            "title": {
                "fragments": [],
                "text": "Recognition of planar object classes"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new framework for recognizing planar object classes is presented, which is based on local feature detectors and a probabilistic model of the spatial arrangement of the features, and the allowed object deformations are represented through shape statistics, which are learned from examples."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061525227"
                        ],
                        "name": "J. Krumm",
                        "slug": "J.-Krumm",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Krumm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Krumm"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 172
                            }
                        ],
                        "text": "This may be one of the reasons, some researchers have tried to improve the eigenimage approach [5][30] by using templates of smaller size to describe specific features [35][34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31345140,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e34811036f0a9121a222f0defd7682317958011",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Planar pose measurement from images is an important problem for automated assembly and inspection. In addition to accuracy and robustness, ease of use is very important for real world applications. Recently, Murase and Nayar have presented the \"parametric eigenspace \" for object recognition and pose measurement based on training images. Although their system is easy to use, it has potential problems with background clutter and partial occlusions. We present an algorithm that is robust in these terms. It uses several small features on the object rather than a monolithic template. These \"eigenfeatures\" are matched using a median statistic, giving the system robustness in the face of background clutter and partial occlusions. We demonstrate our algorithm's pose measurement accuracy with a controlled test, and we demonstrate its detection robustness on cluttered images with the objects of interest partially occluded."
            },
            "slug": "Eigenfeatures-for-planar-pose-measurement-of-Krumm",
            "title": {
                "fragments": [],
                "text": "Eigenfeatures for planar pose measurement of partially occluded objects"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work presents an algorithm that is robust in these terms, which uses several small features on the object rather than a monolithic template, giving the system robustness in the face of background clutter and partial occlusions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "9.2.1 Sung and Poggio [18] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80 9.2.2 Rowley, Baluja, and Kanade [14] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .81 9.2.3 Osuna, Freund, and Girosi [19] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.4 Moghaddam and Pentland [ 12 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ..."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9242811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e49ad8354bdd2fd6e8babd348df9e9a5b30bf3a6",
            "isKey": true,
            "numCitedBy": 461,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for a unimodal distributions) and a multivariate Mixture-of-Gaussians model (for multimodal distributions). These probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition. This learning technique is tested in experiments with modeling and subsequent detection of human faces and non-rigid objects such as hands.<<ETX>>"
            },
            "slug": "Probabilistic-visual-learning-for-object-detection-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic visual learning for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "An unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and a multivariate Mixture-of-Gaussians model is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783224"
                        ],
                        "name": "A. Colmenarez",
                        "slug": "A.-Colmenarez",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Colmenarez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Colmenarez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80 9.2.2 Rowley, Baluja, and Kanade [14] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .81 9.2.3 Osuna, Freund, and Girosi [19] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.4 Moghaddam and Pentland [12] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.5 Colmenarez and Huang [ 20 ] ..."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9192390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e744c3eef4fbc4ac52b2458eb2d545a4432bcb86",
            "isKey": true,
            "numCitedBy": 196,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a visual learning technique that maximizes the discrimination between positive and negative examples in a training set. We demonstrate our technique in the context of face detection with complex background without color or motion information, which has proven to be a challenging problem. We use a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics. Then, we convert the learning process into an optimization, selecting the Markov process that optimizes the information-based discrimination between the two classes. The detection process is carried out by computing the likelihood ratio using the probability model obtained from the learning procedure. We show that because of the discrete nature of these models, the detection process is at least two orders of magnitude less computationally expensive than neural network approaches. However, no improvement in terms of correct-answer/false-alarm tradeoff is achieved."
            },
            "slug": "Face-detection-with-information-based-maximum-Colmenarez-Huang",
            "title": {
                "fragments": [],
                "text": "Face detection with information-based maximum discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A visual learning technique that maximizes the discrimination between positive and negative examples in a training set by using a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1893913"
                        ],
                        "name": "K. Ohba",
                        "slug": "K.-Ohba",
                        "structuredName": {
                            "firstName": "Kohtaro",
                            "lastName": "Ohba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ohba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739452"
                        ],
                        "name": "K. Ikeuchi",
                        "slug": "K.-Ikeuchi",
                        "structuredName": {
                            "firstName": "Katsushi",
                            "lastName": "Ikeuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ikeuchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14480367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e7c5a92da6d8d78d906ca8ed2913fe513299cae",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method for recognizing partially occluded specularity objects for bin-picking tasks using the eigen-space analysis. Although effective in recognizing an isolated object, as was shown by Murase and Nayar, the current method can not be applied to partially occluded objects that are typical in bin-picking tasks. The analysis also requires that the object is centered in an image before recognition. These limitations of the eigen-space analysis are due to the fact that the whole appearance of an object is utilized as a template for the analysis. We propose a new method, referred to as the \"eigen-window\" method, that stores multiple partial appearances of an object in the eigen-space. Such partial appearances require a large number of memory space. To reduce the memory requirement by avoiding redundant windows and to select only effective windows to be stored, a similarity measure among windows is developed. Using a pose clustering method among windows, the method determines the pose of an object. We have implemented the method and verify the validity of the method."
            },
            "slug": "Recognition-of-the-multi-specularity-objects-using-Ohba-Ikeuchi",
            "title": {
                "fragments": [],
                "text": "Recognition of the multi-specularity objects using the eigen-window"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new method is proposed, referred to as the \"eigen-window\" method, that stores multiple partial appearances of an object in the eigen-space that reduces the memory requirement by avoiding redundant windows and to select only effective windows to be stored."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "At the other extreme, others use a minimalist feature representation and emphasize geometric relationships [32][41][45][46][47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1530384,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4462c82748d81489f4f453f516754438b35a8cec",
            "isKey": false,
            "numCitedBy": 961,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "With contributions from Tomas LozanoPerez and Daniel P. Huttenlocher.An intelligent system must know \"what \"the objects are and \"where \"they are in its environment. Examples of this ubiquitous problem in computer vision arise in tasks involving hand-eye coordination (such as assembling or sorting), inspection tasks, gauging operations, and in navigation and localization of mobile robots. This book describes an extended series of experiments into the role of geometry in the critical area of object recognition. It provides precise definitions of the recognition and localization problems, describes the methods used to address them, analyzes the solutions to these problems, and addresses the implications of this analysis.The solution to problems of object recognition are of fundamental importance in many real applications and versions of the techniques described here are already being used in industrial settings. Although a number of questions remain to be solved, the authors provide a valuable framework for understanding both the strengths and limitations of using object shape to guide recognition.W. Eric L. Grimson is Matsushita Associate Professor in the Department of Electrical Engineering and Computer Science at MIT.Contents: Introduction. Recognition as a Search Problem. Searching for Correspondences. Two-Dimensional Constraints. Three-Dimensional Constraints. Verifying Hypotheses. Controlling the Search Explosion. Selecting Subspaces of the Search Space. Empirical Testing. The Combinatorics of the Matching Process. The Combinatorics of Hough Transforms. The Combinatorics of Verification. The Combinatorics of Indexing. Evaluating the Methods. Recognition from Libraries. Parameterized Objects. The Role of Grouping. Sensing Strategies. Applications. The Next Steps."
            },
            "slug": "Object-recognition-by-computer-the-role-of-Grimson",
            "title": {
                "fragments": [],
                "text": "Object recognition by computer - the role of geometric constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This book describes an extended series of experiments into the role of geometry in the critical area of object recognition, providing precise definitions of the recognition and localization problems, the methods used to address them, the solutions to these problems, and the implications of this analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 149
                            }
                        ],
                        "text": "At the other extreme there are algorithms that represent the object\u2019s appearance as a collections of parts (edges, corners, complex features) [9][10][39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 226
                            }
                        ],
                        "text": "Say the eyes, nose, and mouth on a face or some other relatively small subset of the visual information [26][4][40]? Do we use an \u201cinterest operator\u201d or some other automatic method to select a small set of features to use [81][39][82]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "78 mal set of hand-picked features, such as the eyes, nose, mouth on a face or a minimal set determined by an automatic method [39], [81], [82], [83]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 383591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c32094848051d78435d83e4b050357f1f915d2bb",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a new Bayesian framework for visual object recognition which is based on the insight that images of objects can be modeled as a conjunction of local features. This framework can be used to both derive an object recognition algorithm and an algorithm for learning the features themselves. The overall approach, called complex feature recognition or CFR, is unique for several reasons: it is broadly applicable to a wide range of object types, it makes constructing object models easy, it is capable of identifying either the class or the identity of an object, and it is computationally efficient--requiring time proportional to the size of the image. Instead of a single simple feature such as an edge, CFR uses a large set of complex features that are learned from experience with model objects. The response of a single complex feature contains much more class information than does a single edge. This significantly reduces the number of possible correspondences between the model and the image. In addition, CFR takes advantage of a type of image processing called \"oriented energy\". Oriented energy is used to efficiently pre-process the image to eliminate some of the difficulties associated with changes in lighting and pose."
            },
            "slug": "Complex-Feature-Recognition:-A-Bayesian-Approach-to-Viola",
            "title": {
                "fragments": [],
                "text": "Complex Feature Recognition: A Bayesian Approach for Learning to Recognize Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A new Bayesian framework for visual object recognition which is based on the insight that images of objects can be modeled as a conjunction of local features, and uses a large set of complex features that are learned from experience with model objects."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Mixture models [18][40] are also attractive because they can achieve complicated boundaries in input space but are also susceptible to local minima."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Sampling of Local Appearance Most methods that use an local appearance representation [26], [4], [40], [78], [79] use a mini-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "Say the eyes, nose, and mouth on a face or some other relatively small subset of the visual information [26][4][40]? Do we use an \u201cinterest operator\u201d or some other automatic method to select a small set of features to use [81][39][82]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 483975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b312560b79929540734067e58de46966b96130",
            "isKey": false,
            "numCitedBy": 1684,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands."
            },
            "slug": "Probabilistic-Visual-Learning-for-Object-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic Visual Learning for Object Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An unsupervised technique for visual learning is presented, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152292143"
                        ],
                        "name": "Jeffrey R. Huang",
                        "slug": "Jeffrey-R.-Huang",
                        "structuredName": {
                            "firstName": "Jeffrey R.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey R. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145699982"
                        ],
                        "name": "S. Gutta",
                        "slug": "S.-Gutta",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Gutta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gutta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143979395"
                        ],
                        "name": "H. Wechsler",
                        "slug": "H.-Wechsler",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wechsler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wechsler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17638560,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e3ccd490466445790e246cf7e993d450ee354ba",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper proposes a novel algorithm for face detection using decision trees (DT) and shows its generality and feasibility using a database consisting of 2340 face images from the FERET database (corresponding to 817 subjects and including 190 sets of duplicates) over a semi-uniform background. The approach used for face detection involves three main stages, those of location, cropping, and post-processing. The first stage finds a rough approximation for the possible location of the face box, the second stage will refine it, and the last stage decider whether a face is present in the image and if the answer is positive would normalize the face image. The algorithm does not require multiple (scale) templates and the accuracy achieved is 96%. Accuracy is based on the visual observation that the face box includes both eyes, nose, and mouth, and that the top side of the box is below the hairline. Experiments were also performed to assess the accuracy of the algorithm in rejecting images where no face is present. Using a small database of 25 images of various but complex backgrounds the algorithm failed on two images for an overall accuracy rate of 92%."
            },
            "slug": "Detection-of-human-faces-using-decision-trees-Huang-Gutta",
            "title": {
                "fragments": [],
                "text": "Detection of human faces using decision trees"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A novel algorithm for face detection using decision trees (DT) is proposed and its generality and feasibility is shown using a database consisting of 2340 face images from the FERET database over a semi-uniform background."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.4 Moghaddam and Pentland [12] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.5 Colmenarez and Huang [20] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .84 9.2.6 Burl and Perona [26] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .86 9.2.7 Roth, Yang, Ahuja [ 38 ] ..."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "report 63% recognition on their training set. 9.2.7. Roth, Yang, Ahuja [ 38 ]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1709452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23234a0f211a44d9706b2570d474427b8f899ec1",
            "isKey": true,
            "numCitedBy": 354,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel learning approach for human face detection using a network of linear units is presented. The SNoW learning architecture is a sparse network of linear functions over a pre-defined or incrementally learned feature space and is specifically tailored for learning in the presence of a very large number of features. A wide range of face images in different poses, with different expressions and under different lighting conditions are used as a training set to capture the variations of human faces. Experimental results on commonly used benchmark data sets of a wide range of face images show that the SNoW-based approach outperforms methods that use neural networks, Bayesian methods, support vector machines and others. Furthermore, learning and evaluation using the SNoW-based method are significantly more efficient than with other methods."
            },
            "slug": "A-SNoW-Based-Face-Detector-Yang-Roth",
            "title": {
                "fragments": [],
                "text": "A SNoW-Based Face Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results on commonly used benchmark data sets of a wide range of face images show that the SNoW-based approach outperforms methods that use neural networks, Bayesian methods, support vector machines and others."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3132132"
                        ],
                        "name": "Z. Gigus",
                        "slug": "Z.-Gigus",
                        "structuredName": {
                            "firstName": "Ziv",
                            "lastName": "Gigus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Gigus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729041"
                        ],
                        "name": "J. Canny",
                        "slug": "J.-Canny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canny",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canny"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144615067"
                        ],
                        "name": "R. Seidel",
                        "slug": "R.-Seidel",
                        "structuredName": {
                            "firstName": "Raimund",
                            "lastName": "Seidel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Seidel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "One possible answer is to select viewpoints from aspect graphs if the object has well-defined surfaces [62]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10007530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37ab487dc4de414fc20bb071b15f5acdf3c152df",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The aspect graph is one of the approaches to representing of 3-D shape for the purposes of object recognition. In this approach, the viewing space of an object is partitioned into regions, such that in each region the topology of the line drawing of the object does not change. The viewing data of an object is the partition of the viewing space together with a representative view in each region, We present an efficient algorithm for computing the viewing data for line drawings of polyhedral objects under orthographic projection. For an object of size O(n) whose partition of size O(m), the algorithm runs O(n4 log n t m log m) time. Using a novel data structure, we construct the set of all views in optimal O(m) time and space."
            },
            "slug": "Efficiently-Computing-And-Representing-Aspect-Of-Gigus-Canny",
            "title": {
                "fragments": [],
                "text": "Efficiently Computing and Representing Aspect Graphs of Polyhedral Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents an efficient algorithm for computing the viewing data for line drawings of polyhedral objects under orthographic projection, and constructs the set of all views in optimal O(m) time and space."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145893752"
                        ],
                        "name": "J. Fellous",
                        "slug": "J.-Fellous",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Fellous",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fellous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721722"
                        ],
                        "name": "N. Kr\u00fcger",
                        "slug": "N.-Kr\u00fcger",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Kr\u00fcger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kr\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Other methods use graph based matching techniques where nodes represent features and edges represent distances between feature pairs [78][79]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "Representation of Local Appearance using Wavelets Haar wavelets [81], [82], [83], Gaussian pyramid representation [84] and Gabor wavelets [78], [79] are all multi-resolution based representations that have been used in object recognition/detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "Sampling of Local Appearance Most methods that use an local appearance representation [26], [4], [40], [78], [79] use a mini-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "Also unlike the Gaussian pyramid representation [84] and Gabor wavelets [78], [79] our wavelet representation has no redundancy; that is the transform is the same size as the original image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10223132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c27487c3e0894b65e976a287e6f8c9aa40f089c",
            "isKey": true,
            "numCitedBy": 2135,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for recognizing human faces from single images out of a large database containing one image per person. Faces are represented by labeled graphs, based on a Gabor wavelet transform. Image graphs of new faces are extracted by an elastic graph matching process and can be compared by a simple similarity function. The system differs from Lades et al. (1993) in three respects. Phase information is used for accurate node positioning. Object-adapted graphs are used to handle large rotations in depth. Image graph extraction is based on a novel data structure, the bunch graph, which is constructed from a small set of sample image graphs."
            },
            "slug": "Face-recognition-by-elastic-bunch-graph-matching-Wiskott-Fellous",
            "title": {
                "fragments": [],
                "text": "Face recognition by elastic bunch graph matching"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A system for recognizing human faces from single images out of a large database containing one image per person, based on a Gabor wavelet transform, which differs from Lades et al. (1993) in three respects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "This may be one of the reasons, some researchers have tried to improve the eigenimage approach [5][30] by using templates of smaller size to describe specific features [35][34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 171
                            }
                        ],
                        "text": "Local Appearance Versus Global Appearance Much work in object recognition treats the appearance of the object in terms of full-sized rigid templates including the work of [5],[6], [30], [44], [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "There are many ways to do this such as linear projection methods[5][29][30], and resolution reduction methods[14][18], or simply by hand selecting features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "First, the global methods that involve dimensionality reduction [5],[6], [30] will end up emphasizing the coarse attributes of object appearance rather than the distinctive nature of the smaller parts such as the eyes, nose, and mouth on a face."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "appearance of parts - There are many algorithms that treat the object\u2019s appearance as one monolithic quantity such as [30][29][5][6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": true,
            "numCitedBy": 14954,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189439"
                        ],
                        "name": "J. Vorbr\u00fcggen",
                        "slug": "J.-Vorbr\u00fcggen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Vorbr\u00fcggen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vorbr\u00fcggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075388397"
                        ],
                        "name": "J. Lange",
                        "slug": "J.-Lange",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "Other methods use graph based matching techniques where nodes represent features and edges represent distances between feature pairs [78][79]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "Representation of Local Appearance using Wavelets Haar wavelets [81], [82], [83], Gaussian pyramid representation [84] and Gabor wavelets [78], [79] are all multi-resolution based representations that have been used in object recognition/detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "Sampling of Local Appearance Most methods that use an local appearance representation [26], [4], [40], [78], [79] use a mini-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "Also unlike the Gaussian pyramid representation [84] and Gabor wavelets [78], [79] our wavelet representation has no redundancy; that is the transform is the same size as the original image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1266405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb52984078d75ec5655962dc94dc7848182286b",
            "isKey": true,
            "numCitedBy": 2069,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented. The dynamic link architecture exploits correlations in the fine-scale temporal structure of cellular signals to group neurons dynamically into higher-order entities. These entities represent a rich structure and can code for high-level objects. To demonstrate the capabilities of the dynamic link architecture, a program was implemented that can recognize human faces and other objects from video images. Memorized objects are represented by sparse graphs, whose vertices are labeled by a multiresolution description in terms of a local power spectrum, and whose edges are labeled by geometrical distance vectors. Object recognition can be formulated as elastic graph matching, which is performed here by stochastic optimization of a matching cost function. The implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images. The performance of the program is evaluated by a statistical analysis of recognition results from a portrait gallery comprising images of 87 persons. >"
            },
            "slug": "Distortion-Invariant-Object-Recognition-in-the-Link-Lades-Vorbr\u00fcggen",
            "title": {
                "fragments": [],
                "text": "Distortion Invariant Object Recognition in the Dynamic Link Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented and the implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computers"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "Modular viewpoint-based models [4][30][29] decompose appearance into separate 2D models corresponding to different viewpoints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "Sampling of Local Appearance Most methods that use an local appearance representation [26], [4], [40], [78], [79] use a mini-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "There can be a small finite number of viewpoints [4] or the 2D information could be represented as a continuous function of the 3D pose of the object [30][29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "Say the eyes, nose, and mouth on a face or some other relatively small subset of the visual information [26][4][40]? Do we use an \u201cinterest operator\u201d or some other automatic method to select a small set of features to use [81][39][82]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 136280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf5d558220d39698ce96d59ee5772e8e1a0663",
            "isKey": true,
            "numCitedBy": 2234,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated.<<ETX>>"
            },
            "slug": "View-based-and-modular-eigenspaces-for-face-Pentland-Moghaddam",
            "title": {
                "fragments": [],
                "text": "View-based and modular eigenspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer, which yields higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685300"
                        ],
                        "name": "J. Hespanha",
                        "slug": "J.-Hespanha",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Hespanha",
                            "middleNames": [
                                "Pedro"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hespanha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In particular, we decompose the image in frequency, orientation, space, and geometry."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30582,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be86da00efdd8c2a7fdeb2334605796c24b370f0",
            "isKey": false,
            "numCitedBy": 11721,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a face recognition algorithm which is insensitive to large variation in lighting direction and facial expression. Taking a pattern classification approach, we consider each pixel in an image as a coordinate in a high-dimensional space. We take advantage of the observation that the images of a particular face, under varying illumination but fixed pose, lie in a 3D linear subspace of the high dimensional image space-if the face is a Lambertian surface without shadowing. However, since faces are not truly Lambertian surfaces and do indeed produce self-shadowing, images will deviate from this linear subspace. Rather than explicitly modeling this deviation, we linearly project the image into a subspace in a manner which discounts those regions of the face with large deviation. Our projection method is based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variation in lighting and facial expressions. The eigenface technique, another method based on linearly projecting the image space to a low dimensional subspace, has similar computational requirements. Yet, extensive experimental results demonstrate that the proposed \"Fisherface\" method has error rates that are lower than those of the eigenface technique for tests on the Harvard and Yale face databases."
            },
            "slug": "Eigenfaces-vs.-Fisherfaces:-Recognition-Using-Class-Belhumeur-Hespanha",
            "title": {
                "fragments": [],
                "text": "Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A face recognition algorithm which is insensitive to large variation in lighting direction and facial expression is developed, based on Fisher's linear discriminant and produces well separated classes in a low-dimensional subspace, even under severe variations in lighting and facial expressions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 778478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ab46391005cea85fa5c204b6e77a9c870fdbaed",
            "isKey": false,
            "numCitedBy": 8403,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. We propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world. These methods are based on a new tracking algorithm that extends previous Newton-Raphson style search methods to work under affine image transformations. We test performance with several simulations and experiments.<<ETX>>"
            },
            "slug": "Good-features-to-track-Shi-Tomasi",
            "title": {
                "fragments": [],
                "text": "Good features to track"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2627529"
                        ],
                        "name": "M. Wheeler",
                        "slug": "M.-Wheeler",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Wheeler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wheeler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739452"
                        ],
                        "name": "K. Ikeuchi",
                        "slug": "K.-Ikeuchi",
                        "structuredName": {
                            "firstName": "Katsushi",
                            "lastName": "Ikeuchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ikeuchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "At the other extreme, others use a minimalist feature representation and emphasize geometric relationships [32][41][45][46][47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28136797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47af049ed695809f18c8ab3e34a28d677d9e2438",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In an effort to make object recognition efficient and accurate enough for applications, the authors have developed three techniques; sensor modeling, probabilistic hypothesis generation, and robust localization-which form the basis of a probabilistic object recognition algorithm. To minimize recognition time, these techniques exploit prior knowledge to reduce the number of verifications (the most expensive and critical part of the algorithm) required during recognition. The approach utilizes statistical constraints generated by modeling the entire sensing process, resulting in more accurate constraints on matches. Hypotheses are pruned by a probabilistic algorithm which selects matches based on image evidence and prior statistical constraints. The reliability of the verification decision is increased by robust localization. The authors have implemented these techniques in a system for recognizing polyhedral objects in range images. The results demonstrate accurate recognition while greatly limiting the number of verifications performed.<<ETX>>"
            },
            "slug": "Sensor-modeling,-probabilistic-hypothesis-and-for-Wheeler-Ikeuchi",
            "title": {
                "fragments": [],
                "text": "Sensor modeling, probabilistic hypothesis generation, and robust localization for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "In an effort to make object recognition efficient and accurate enough for applications, the authors have developed three techniques; sensor modeling, probabilistic hypothesis generation, and robust localization-which form the basis of a Probabilistic object recognition algorithm to minimize recognition time."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE 2nd CAD-Based Vision Workshop"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143891066"
                        ],
                        "name": "A. Rajagopalan",
                        "slug": "A.-Rajagopalan",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Rajagopalan",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rajagopalan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765936"
                        ],
                        "name": "P. Burlina",
                        "slug": "P.-Burlina",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Burlina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burlina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "9.3.1 Rajagopalan, Burlina, Chellappa [ 44 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .90 9.3.2 Papageorgiou, Poggio [83] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .90"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "9.3.1. Rajagopalan, Burlina, Chellappa [ 44 ]"
                    },
                    "intents": []
                }
            ],
            "corpusId": 9082654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fceb0aef12166bdcc2957e7d8954a93726b1f31c",
            "isKey": true,
            "numCitedBy": 68,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes a scheme for detecting vehicles in images. The proposed method approximately models the unknown distribution of the images of vehicles by learning higher order statistics (HOS) information of the 'vehicle class' from sample images. Given a test image, statistical information about the background is learnt 'on the fly'. An HOS-based decision measure then classifies test patterns as vehicles or otherwise. When tested on real images of aerial views of vehicular activity, the method gives good results even on complicated scenes. It does not require any a priori information about the site. However, it is amenable to augmentation with contextual information. The method can serve as an important step towards building an automated roadway monitoring system."
            },
            "slug": "Higher-order-statistical-learning-for-vehicle-in-Rajagopalan-Burlina",
            "title": {
                "fragments": [],
                "text": "Higher order statistical learning for vehicle detection in images"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The proposed method approximately models the unknown distribution of the images of vehicles by learning higher order statistics (HOS) information of the 'vehicle class' from sample images by learning 'on the fly' statistical information about the background."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14659058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "992c10fb6aa8ff278d33b7d7bf05acd41133ddf0",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "The processing of spatial information by the visual system shows a number of similarities to the wavelet transforms that have become popular in applied mathematics. Over the last decade, a range of studies have focused on the question of \u2018why\u2019 the visual system would evolve this strategy of coding spatial information. One such approach has focused on the relationship between the visual code and the statistics of natural scenes under the assumption that the visual system has evolved this strategy as a means of optimizing the representation of its visual environment. This paper reviews some of this literature and looks at some of the statistical properties of natural scenes that allow this code to be efficient. It is argued that such wavelet codes are efficient because they increase the independence of the vectors' outputs (i.e. they increase the independence of the responses of the visual neurons) by finding the sparse structure available in the input. Studies with neural networks that attempt to maximize the \u2018sparsity\u2019 of the representation have been shown to produce vectors (neural receptive fields) that have many of the properties of a wavelet representation. It is argued that the visual environment has the appropriate sparse structure to make this sparse output possible. It is argued that these sparse/independent representations make it computationally easier to detect and represent the higher\u2013order structure present in complex environmental data."
            },
            "slug": "Wavelets,-vision-and-the-statistics-of-natural-Field",
            "title": {
                "fragments": [],
                "text": "Wavelets, vision and the statistics of natural scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper reviews some of the statistical properties of natural scenes that allow the visual code to be efficient and argues that such wavelet codes are efficient because they increase the independence of the vectors' outputs by finding the sparse structure available in the input."
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical Transactions of the Royal Society of London. Series A: Mathematical, Physical and Engineering Sciences"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3096453"
                        ],
                        "name": "Y. Lamdan",
                        "slug": "Y.-Lamdan",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Lamdan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lamdan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "Others depend on a coordinate system defined by two or three features [26][32] and may be sensitive to any errors in these feature positions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "At the other extreme, others use a minimalist feature representation and emphasize geometric relationships [32][41][45][46][47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20693764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce5271110e0b1ef852fd3bd3ed57b1932e08642e",
            "isKey": false,
            "numCitedBy": 966,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A general method for model-based object recognition in occluded scenes is presented. It is based on geometric hashing. The method stands out for its efficiency. We describe the general framework of the method and illustrate its applications for various recogni- tion problems both in 3-D and 2-D. Special attention is given to the recognition of 3-D objects in occluded scenes from 2-D gray scale images. New experimental results are included for this important case."
            },
            "slug": "Geometric-Hashing:-A-General-And-Efficient-Scheme-Lamdan-Wolfson",
            "title": {
                "fragments": [],
                "text": "Geometric Hashing: A General And Efficient Model-based Recognition Scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A general method for model-based object recognition in occluded scenes is presented based on geometric hashing, which stands out for its efficiency and applications both in 3-D and 2-D."
            },
            "venue": {
                "fragments": [],
                "text": "[1988 Proceedings] Second International Conference on Computer Vision"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2306148"
                        ],
                        "name": "M. W. Koch",
                        "slug": "M.-W.-Koch",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Koch",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. W. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145021156"
                        ],
                        "name": "M. M. Moya",
                        "slug": "M.-M.-Moya",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Moya",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. M. Moya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2322936"
                        ],
                        "name": "L. Hostetler",
                        "slug": "L.-Hostetler",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Hostetler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hostetler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2943517"
                        ],
                        "name": "R. Fogler",
                        "slug": "R.-Fogler",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Fogler",
                            "middleNames": [
                                "Joseph"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fogler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27820353,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b655ffbeb9ef2ecf387b81832a5e4ec0cf4dea1",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cueing,-feature-discovery,-and-one-class-learning-Koch-Moya",
            "title": {
                "fragments": [],
                "text": "Cueing, feature discovery, and one-class learning for synthetic aperture radar automatic target recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 128
                            }
                        ],
                        "text": "80\n9.2.1 Sung and Poggio [18] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80 9.2.2 Rowley, Baluja, and Kanade [14] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .81 9.2.3 Osuna, Freund, and Girosi [19] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.4 Moghaddam and Pentland [12] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.5 Colmenarez and Huang [20] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .84 9.2.6 Burl and Perona [26] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .86 9.2.7 Roth, Yang, Ahuja [38] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .89\n9.3 Summary of Previous Methods for Car Detection . . . . . . . . . . . . . . . . . . . . . . . . . ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 250
                            }
                        ],
                        "text": "Below in Table 10 we compare our face detectors (wavelet-based and eigenvector-based [76]) with those results reported by others on the combined frontal face test set combining the test images from Sung and Poggio [18] and Rowley, Baluja, and Kanade [14]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "To date, several researchers [14][18][19][20][38] have had success developing algorithms that work for frontal views of faces, but none, to our knowledge, have had success with profile (side) views except [87] (below we will compare our performance with [87])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "Or do we model it explicitly using real-imagery.[14][18] And if so what and how do we select images and weight them?"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 56
                            }
                        ],
                        "text": "Acknowledgments\nI would like to thank my advisor, Takeo Kanade, for his guidance in this research."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "To select non-object samples that resemble the object, we used bootstrapping [18][14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 43
                            }
                        ],
                        "text": "Henry A. Rowley, Shumeet Baluja, and Takeo Kanade."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "Table 10: Frontal Face Detection on Sung & Poggio and Rowley [18] & Baluja & Kanade Combined Test Set [14] Detection Rate False Detections Schneiderman and Kanade* (wavelet) 94."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 78
                            }
                        ],
                        "text": "We compared the performance of our detectors with that reported by Rowley and Kanade [87] on a test set of profile views selected from a set of proprietary images Kodak provided to Carnegie Mellon University."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "There are many ways to do this such as linear projection methods[5][29][30], and resolution reduction methods[14][18], or simply by hand selecting features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 14
                            }
                        ],
                        "text": "The method of Rowley, Baluja, and Kanade uses a 20x20 input region that is presented to a multilayer perceptron neural network system for classification."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 25
                            }
                        ],
                        "text": "[76] H. Schneiderman, T. Kanade."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 73
                            }
                        ],
                        "text": "This method performs quite well on the Sung & Poggio and Rowley, Baluja, Kanade Test set."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 39
                            }
                        ],
                        "text": "Soon after Sung and Poggio\u2019s algorithm, Rowley, Baluja, and Kanade developed a slightly\nmore accurate method for frontal face detection."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "Rowley, Baluja, and Kanade [14] Soon after Sung and Poggio\u2019s algorithm, Rowley, Baluja, and Kanade developed a slightly more accurate method for frontal face detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "[18] and [14] use artificial neural networks (multilayer perceptrons) as part of their discriminant functions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "Other methods represent geometry rigidly [14], [19], [81], [82], [83], [38] and may be brittle to small variation in the part positions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771659"
                        ],
                        "name": "R. Freund",
                        "slug": "R.-Freund",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Freund",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "resentation divide input space with a hyperplane, conic section[ 19 ][81][82], etc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "9.2.1 Sung and Poggio [18] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80 9.2.2 Rowley, Baluja, and Kanade [14] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .81 9.2.3 Osuna, Freund, and Girosi [ 19 ] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82 9.2.4 Moghaddam and Pentland [12] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ..."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2845602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9008cdacbdcff8a218a6928e94fe7c6dfc237b24",
            "isKey": true,
            "numCitedBy": 2841,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points."
            },
            "slug": "Training-support-vector-machines:-an-application-to-Osuna-Freund",
            "title": {
                "fragments": [],
                "text": "Training support vector machines: an application to face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets is presented, and the feasibility of the approach on a face detection problem that involves a data set of 50,000 data points is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34925745"
                        ],
                        "name": "D. Casasent",
                        "slug": "D.-Casasent",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Casasent",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Casasent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2772332"
                        ],
                        "name": "L. Neiberg",
                        "slug": "L.-Neiberg",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Neiberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Neiberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "object\u2019s appearance as one monolithic quantity such as [30][ 29 ][5][6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ber of viewpoints [4] or the 2D information could be represented as a continuous function of the 3D pose of the object [30][ 29 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Modular viewpoint-based models [4][30][ 29 ] decompose appearance"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "to do this such as linear projection methods[5][ 29 ][30], and resolution reduction meth-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8513572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de2b96acb3d092e6b505719a0040109c44a52342",
            "isKey": true,
            "numCitedBy": 68,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Classifier-and-shift-invariant-automatic-target-Casasent-Neiberg",
            "title": {
                "fragments": [],
                "text": "Classifier and shift-invariant automatic target recognition neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958806"
                        ],
                        "name": "S. A. Rizvi",
                        "slug": "S.-A.-Rizvi",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Rizvi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Rizvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 497801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "791e530f6a4098bb39696d1476032821a7a1c569",
            "isKey": false,
            "numCitedBy": 2334,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. To date, 14,126 images from 1199 individuals are included in the FERET database, which is divided into development and sequestered portions. In September 1996, the FERET program administered the third in a series of FERET face-recognition tests. The primary objectives of the third test were to (1) assess the state of the art, (2) identify future areas of research, and (3) measure algorithm performance on large databases."
            },
            "slug": "The-FERET-evaluation-methodology-for-algorithms-Phillips-Moon",
            "title": {
                "fragments": [],
                "text": "The FERET evaluation methodology for face-recognition algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69521536"
                        ],
                        "name": "S. Liberty",
                        "slug": "S.-Liberty",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Liberty",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Liberty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29457912,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fb38f320a127d31a086ddcd616cd9080e3de0453",
            "isKey": false,
            "numCitedBy": 2248,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Most of the signal processing that we will study in this course involves local operations on a signal, namely transforming the signal by applying linear combinations of values in the neighborhood of each sample point. You are familiar with such operations from Calculus, namely, taking derivatives and you are also familiar with this from optics namely blurring a signal. We will be looking at sampled signals only. Let's start with a few basic examples. Local difference Suppose we have a 1D image and we take the local difference of intensities, DI(x) = 1 2 (I(x + 1) \u2212 I(x \u2212 1)) which give a discrete approximation to a partial derivative. (We compute this for each x in the image.) What is the effect of such a transformation? One key idea is that such a derivative would be useful for marking positions where the intensity changes. Such a change is called an edge. It is important to detect edges in images because they often mark locations at which object properties change. These can include changes in illumination along a surface due to a shadow boundary, or a material (pigment) change, or a change in depth as when one object ends and another begins. The computational problem of finding intensity edges in images is called edge detection. We could look for positions at which DI(x) has a large negative or positive value. Large positive values indicate an edge that goes from low to high intensity, and large negative values indicate an edge that goes from high to low intensity. Example Suppose the image consists of a single (slightly sloped) edge:"
            },
            "slug": "Linear-systems-Liberty",
            "title": {
                "fragments": [],
                "text": "Linear systems"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763529"
                        ],
                        "name": "P. Cosman",
                        "slug": "P.-Cosman",
                        "structuredName": {
                            "firstName": "Pamela",
                            "lastName": "Cosman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cosman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145876744"
                        ],
                        "name": "M. Vetterli",
                        "slug": "M.-Vetterli",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Vetterli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vetterli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "Finally, an inter-orientation / inter-frequency attribute has no restrictions on which the bands from which it draws is coefficients [61]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9307657,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "a2531a801a1df4e65f53794bb56b52718b6dc472",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 209,
            "paperAbstract": {
                "fragments": [],
                "text": "Subband and wavelet decompositions are powerful tools in image coding because of their decorrelating effects on image pixels, the concentration of energy in a few coefficients, their multirate/multiresolution framework, and their frequency splitting, which allows for efficient coding matched to the statistics of each frequency band and to the characteristics of the human visual system. Vector quantization (VQ) provides a means of converting the decomposed signal into bits in a manner that takes advantage of remaining inter and intraband correlation as well as of the more flexible partitions of higher dimensional vector spaces. Since 1988, a growing body of research has examined the use of VQ for subband/wavelet transform coefficients. We present a survey of these methods."
            },
            "slug": "Vector-quantization-of-image-subbands:-a-survey-Cosman-Gray",
            "title": {
                "fragments": [],
                "text": "Vector quantization of image subbands: a survey"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680943"
                        ],
                        "name": "C. Goerick",
                        "slug": "C.-Goerick",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Goerick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Goerick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981620"
                        ],
                        "name": "D. Noll",
                        "slug": "D.-Noll",
                        "structuredName": {
                            "firstName": "Detlev",
                            "lastName": "Noll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Noll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113434322"
                        ],
                        "name": "M. Werner",
                        "slug": "M.-Werner",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Werner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Werner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 24886862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22735967474a629b6d6791c698981a312637638c",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Artificial-neural-networks-in-real-time-car-and-Goerick-Noll",
            "title": {
                "fragments": [],
                "text": "Artificial neural networks in real-time car detection and tracking applications"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066894"
                        ],
                        "name": "Hans P. Moravec",
                        "slug": "Hans-P.-Moravec",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Moravec",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hans P. Moravec"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 128525458,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "93b376bd451db8ed94a18c556da16f25a3e7961b",
            "isKey": false,
            "numCitedBy": 1053,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The Stanford AI Lab cart is a card-table sized mobile robot controlled remotely through a radio link, and equipped with a TV camera and transmitter. A computer has been programmed to drive the cart through cluttered indoor and outdoor spaces, gaining its knowledge of the world entirely from images broadcast by the onboard TV system. The cart uses several kinds of stereo to locate objects around it in 3D and to deduce its own motion. It plans an obstacle avoiding path to a desired destination on the basis of a model built with this information. The plan changes as the cart perceives new obstacles on its journey. The system is reliable for short runs, but slow. The cart moves one meter every ten to fifteen minutes, in lurches. After rolling a meter it stops, takes some pictures and thinks about them for a long time. Then it plans a new path, executes a little of it, and pauses again. The program has successfully driven the cart through several 20 meter indoor courses (each taking about five hours) complex enough to necessitate three or four avoiding swerves. A less successful outdoor run, in which the cart skirted two obstacles but collided with a third, was also done. Harsh lighting (very bright surfaces next to very dark shadows) giving poor pictures and movement of shadows during the cart's creeping progress were major reasons for the poorer outdoor performance. The action portions of these runs were filmed by computer controlled cameras. (Author)"
            },
            "slug": "Obstacle-avoidance-and-navigation-in-the-real-world-Moravec",
            "title": {
                "fragments": [],
                "text": "Obstacle avoidance and navigation in the real world by a seeing robot rover"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29832393"
                        ],
                        "name": "K. Arun",
                        "slug": "K.-Arun",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Arun",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Arun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750392"
                        ],
                        "name": "T. Huang",
                        "slug": "T.-Huang",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698852"
                        ],
                        "name": "S. Blostein",
                        "slug": "S.-Blostein",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Blostein",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Blostein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "Using these feature points, we applied the translation, scaling, and rotation [7] that brought each image into alignment with the prototype."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8724100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "691d0a287a2515ebe5019cda498dcb6d24dfd5a4",
            "isKey": false,
            "numCitedBy": 3495,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Two point sets {pi} and {p'i}; i = 1, 2,..., N are related by p'i = Rpi + T + Ni, where R is a rotation matrix, T a translation vector, and Ni a noise vector. Given {pi} and {p'i}, we present an algorithm for finding the least-squares solution of R and T, which is based on the singular value decomposition (SVD) of a 3 \u00d7 3 matrix. This new algorithm is compared to two earlier algorithms with respect to computer time requirements."
            },
            "slug": "Least-Squares-Fitting-of-Two-3-D-Point-Sets-Arun-Huang",
            "title": {
                "fragments": [],
                "text": "Least-Squares Fitting of Two 3-D Point Sets"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "An algorithm for finding the least-squares solution of R and T, which is based on the singular value decomposition (SVD) of a 3 \u00d7 3 matrix, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2316129"
                        ],
                        "name": "M. Meil\u0103",
                        "slug": "M.-Meil\u0103",
                        "structuredName": {
                            "firstName": "Marina",
                            "lastName": "Meil\u0103",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meil\u0103"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768120"
                        ],
                        "name": "T. Jebara",
                        "slug": "T.-Jebara",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Jebara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jebara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "Similarly, other methods [74] may work for this purpose as well."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 872496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f9d6be4fee69c9a859c9055b09f2ee94864f5b7",
            "isKey": false,
            "numCitedBy": 291,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general framework for discriminative estimation based on the maximum entropy principle and its extensions. All calculations involve distributions over structures and/or parameters rather than specific settings and reduce to relative entropy projections. This holds even when the data is not separable within the chosen parametric class, in the context of anomaly detection rather than classification, or when the labels in the training set are uncertain or incomplete. Support vector machines are naturally subsumed under this class and we provide several extensions. We are also able to estimate exactly and efficiently discriminative distributions over tree structures of class-conditional models within this framework. Preliminary experimental results are indicative of the potential in these techniques."
            },
            "slug": "Maximum-Entropy-Discrimination-Jaakkola-Meil\u0103",
            "title": {
                "fragments": [],
                "text": "Maximum Entropy Discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A general framework for discriminative estimation based on the maximum entropy principle and its extensions is presented and preliminary experimental results are indicative of the potential in these techniques."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144293919"
                        ],
                        "name": "A. Pandya",
                        "slug": "A.-Pandya",
                        "structuredName": {
                            "firstName": "Abhijit",
                            "lastName": "Pandya",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pandya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66854827"
                        ],
                        "name": "Robert B. Macy",
                        "slug": "Robert-B.-Macy",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Macy",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Macy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58481212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d48c541188711db4f359202f464b09a5f754fb91",
            "isKey": false,
            "numCitedBy": 301,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThe addition of artificial neural network computing to traditionalpattern recognition has given rise to a new, different, and more powerful methodology that is presented in this interesting book. This is a practical guide to the application of artificial neural networks. \nGeared toward the practitioner, Pattern Recognition with Neural Networks in C++ covers pattern classification and neural network approaches within the same framework. Through the book's presentation of underlying theory and numerous practical examples, readers gain an understanding that will allow them to make judicious design choices rendering neural application predictable and effective. \nThe book provides an intuitive explanation of each method for each network paradigm. This discussion is supported by a rigorous mathematical approach where necessary. \nC++ has emerged as a rich and descriptive means by which concepts, models, or algorithms can be precisely described. For many of the neural network models discussed, C++ programs are presented for the actual implementation. Pictorial diagrams and in-depth discussions explain each topic. Necessary derivative steps for the mathematical models are included so that readers can incorporate new ideas into their programs as the field advances with new developments. For each approach, the authors clearly state the known theoretical results, the known tendencies of the approach, and their recommendations for getting the best results from the method. \nThe material covered in the book is accessible to working engineers with little or no explicit background in neural networks. However, the material is presented in sufficient depth so that those with prior knowledge will find this book beneficial. Pattern Recognition with Neural Networks in C++ is also suitable for courses in neural networks at an advanced undergraduate or graduate level. This book is valuable for academic as well as practical research."
            },
            "slug": "Pattern-Recognition-with-Neural-Networks-in-C++-Pandya-Macy",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition with Neural Networks in C++"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Pattern Recognition with Neural Networks in C++ covers pattern classification and neural network approaches within the same framework and provides an intuitive explanation of each method for each network paradigm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750195"
                        ],
                        "name": "E. Trucco",
                        "slug": "E.-Trucco",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Trucco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Trucco"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "At the other extreme, others use a minimalist feature representation and emphasize geometric relationships [32][41][45][46][47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61003302,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "2fdf3b848d2dded13caa0351376dae861a31f640",
            "isKey": false,
            "numCitedBy": 414,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Geometric Invariance in Computer Vision, edited by Joseph L. Mundy and Andrew Zisserman, the MIT Press, 1992, $70.95 in Europe."
            },
            "slug": "Geometric-Invariance-in-Computer-Vision-Trucco",
            "title": {
                "fragments": [],
                "text": "Geometric Invariance in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Geometric Invariance in Computer Vision, edited by Joseph L. Mundy and Andrew Zisserman, the MIT Press, 1992, $70.95 in Europe."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260481"
                        ],
                        "name": "F. Scarselli",
                        "slug": "F.-Scarselli",
                        "structuredName": {
                            "firstName": "Franco",
                            "lastName": "Scarselli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Scarselli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16496125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "513a4542d439b3b4451550a2feb00389c52fcf1e",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Discusses the ability of multilayer perceptrons (MLPs) to model the probability distribution of data in typical pattern recognition and verification problems. It is proven that multilayer perceptrons with sigmoidal units and a number of hidden units less or equal than the number of inputs are unable to model patterns distributed in typical clusters, since these networks draw open separation surfaces in the pattern space. When using more hidden units than inputs, the separation surfaces can be closed but, unfortunately it is proven that determining whether or not a MLP draws closed separation surfaces in the pattern space is NP-hard. The major conclusion of the paper is somewhat opposite to what is believed and reported in many application papers: MLPs are definitely not adequate for applications of pattern recognition requiring a reliable rejection and, especially, they are not adequate for pattern verification tasks."
            },
            "slug": "Are-Multilayer-Perceptrons-Adequate-for-Pattern-and-Gori-Scarselli",
            "title": {
                "fragments": [],
                "text": "Are Multilayer Perceptrons Adequate for Pattern Recognition and Verification?"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is proven that multilayer perceptrons with sigmoidal units and a number of hidden units less or equal than the number of inputs are unable to model patterns distributed in typical clusters, since these networks draw open separation surfaces in the pattern space."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "We can also view this equation as a \u201csimple\u201d or \u201cnaive\u201d Bayes classifier [63]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6134427,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aab43c9c33af00b718cf2ae374b861d49862a563",
            "isKey": false,
            "numCitedBy": 15726,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine Learning is the study of methods for programming computers to learn. Computers are applied to a wide range of tasks, and for most of these it is relatively easy for programmers to design and implement the necessary software. However, there are many tasks for which this is difficult or impossible. These can be divided into four general categories. First, there are problems for which there exist no human experts. For example, in modern automated manufacturing facilities, there is a need to predict machine failures before they occur by analyzing sensor readings. Because the machines are new, there are no human experts who can be interviewed by a programmer to provide the knowledge necessary to build a computer system. A machine learning system can study recorded data and subsequent machine failures and learn prediction rules. Second, there are problems where human experts exist, but where they are unable to explain their expertise. This is the case in many perceptual tasks, such as speech recognition, hand-writing recognition, and natural language understanding. Virtually all humans exhibit expert-level abilities on these tasks, but none of them can describe the detailed steps that they follow as they perform them. Fortunately, humans can provide machines with examples of the inputs and correct outputs for these tasks, so machine learning algorithms can learn to map the inputs to the outputs. Third, there are problems where phenomena are changing rapidly. In finance, for example, people would like to predict the future behavior of the stock market, of consumer purchases, or of exchange rates. These behaviors change frequently, so that even if a programmer could construct a good predictive computer program, it would need to be rewritten frequently. A learning program can relieve the programmer of this burden by constantly modifying and tuning a set of learned prediction rules. Fourth, there are applications that need to be customized for each computer user separately. Consider, for example, a program to filter unwanted electronic mail messages. Different users will need different filters. It is unreasonable to expect each user to program his or her own rules, and it is infeasible to provide every user with a software engineer to keep the rules up-to-date. A machine learning system can learn which mail messages the user rejects and maintain the filtering rules automatically. Machine learning addresses many of the same research questions as the fields of statistics, data mining, and psychology, but with differences of emphasis. Statistics focuses on understanding the phenomena that have generated the data, often with the goal of testing different hypotheses about those phenomena. Data mining seeks to find patterns in the data that are understandable by people. Psychological studies of human learning aspire to understand the mechanisms underlying the various learning behaviors exhibited by people (concept learning, skill acquisition, strategy change, etc.)."
            },
            "slug": "Machine-learning-Dietterich",
            "title": {
                "fragments": [],
                "text": "Machine learning"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Machine learning addresses many of the same research questions as the fields of statistics, data mining, and psychology, but with differences of emphasis."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145833095"
                        ],
                        "name": "S. Kothari",
                        "slug": "S.-Kothari",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Kothari",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kothari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681982"
                        ],
                        "name": "H. Oh",
                        "slug": "H.-Oh",
                        "structuredName": {
                            "firstName": "Heekuck",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Oh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 177751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbc0a468ab103ae29717703d4aa9f682f6a2b664",
            "isKey": false,
            "numCitedBy": 15337,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Networks-for-Pattern-Recognition-Kothari-Oh",
            "title": {
                "fragments": [],
                "text": "Neural Networks for Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "For instance, [72] gives an upper bound on the error when the output of the classifier is continuous but bounded."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "Instead, we minimize Zt numerically in terms of \u03b1t, since Zt is strictly quadratic (see [72] for proof)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "Following the development of [72], the algorithm works as follows."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "To do so, we use the AdaBoost algorithm [70], [72] to explicitly reduce classification error."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "AdaBoost [70][71][72][73]is a method for training a classifier to have low classification error on the training set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2329907,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a9309e056272ff2076f447df8dbc536f46fc466",
            "isKey": true,
            "numCitedBy": 1918,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe several improvements to Freund and Schapire's AdaBoost boosting algorithm, particularly in a setting in which hypotheses may assign confidences to each of their predictions. We give a simplified analysis of AdaBoost in this setting, and we show how this analysis can be used to find improved parameter settings as well as a refined criterion for training weak hypotheses. We give a specific method for assigning confidences to the predictions of decision trees, a method closely related to one used by Quinlan. This method also suggests a technique for growing decision trees which turns out to be identical to one proposed by Kearns and Mansour. We focus next on how to apply the new boosting algorithms to multiclass classification problems, particularly to the multi-label case in which each example may belong to more than one class. We give two boosting methods for this problem, plus a third method based on output coding. One of these leads to a new method for handling the single-label case which is simpler but as effective as techniques suggested by Freund and Schapire. Finally, we give some experimental results comparing a few of the algorithms discussed in this paper."
            },
            "slug": "Improved-Boosting-Algorithms-Using-Confidence-rated-Schapire-Singer",
            "title": {
                "fragments": [],
                "text": "Improved Boosting Algorithms Using Confidence-rated Predictions"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "Several improvements to Freund and Schapire's AdaBoost boosting algorithm are described, particularly in a setting in which hypotheses may assign confidences to each of their predictions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT' 98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "AdaBoost [70][71][72][73]is a method for training a classifier to have low classification error on the training set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14669208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "814cf172298d11db0ac9b839440ed8f3db93e438",
            "isKey": false,
            "numCitedBy": 762,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has shown that combining multiple versions of unstable classifiers such as trees or neural nets results in reduced test set error. One of the more effective is bagging (Breiman [1996a]) Here, modified training sets are formed by resampling from the original training set, classifiers constructed using these training sets and then combined by voting. Freund and Schapire [1995,1996] propose an algorithm the basis of which is to adaptively resample and combine (hence the acronym-arcing) so that the weights in the resampling are increased for those cases most often misclassified and the combining is done by weighted voting. Arcing is more successful than bagging in test set error reduction. We explore two arcing algorithms, compare them to each other and to bagging, and try to understand how arcing works. We introduce the definitions of bias and variance for a classifier as components of the test set error. Unstable classifiers can have low bias on a large range of data sets. Their problem is high variance. Combining multiple versions either through bagging or arcing reduces variance significantly"
            },
            "slug": "Arcing-Classifiers-Breiman",
            "title": {
                "fragments": [],
                "text": "Arcing Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two arcing algorithms are explored, they are compared to each other and to bagging, and the definitions of bias and variance for a classifier as components of the test set error are introduced."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 123349680,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc394d074c8504671eb37926d14a3df4a07520a0",
            "isKey": false,
            "numCitedBy": 933,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has shown that combining multiple versions of unstable classifiers such as trees or neural nets results in reduced test set error. One of the more effective is bagging. Here, modified training sets are formed by resampling from the original training set, classifiers constructed using these training sets and then combined by voting. Freund and Schapire propose an algorithm the basis of which is to adaptively resample and combine (hence the acronym arcing) so that the weights in the resampling are increased for those cases most often misclassified and the combining is done by weighted voting. Arcing is more successful than bagging in test set error reduction. We explore two arcing algorithms, compare them to each other and to bagging, and try to understand how arcing works. We introduce the definitions of bias and variance for a classifier as components of the test set error. Unstable classifiers can have low bias on a large range of data sets. Their problem is high variance. Combining multiple versions either through bagging or arcing reduces variance significantly."
            },
            "slug": "Arcing-classifier-(with-discussion-and-a-rejoinder-Breiman",
            "title": {
                "fragments": [],
                "text": "Arcing classifier (with discussion and a rejoinder by the author)"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two arcing algorithms are explored, compared to each other and to bagging, and the definitions of bias and variance for a classifier as components of the test set error are introduced."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "To do so, we use the AdaBoost algorithm [70], [72] to explicitly reduce classification error."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "AdaBoost [70][71][72][73]is a method for training a classifier to have low classification error on the training set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6644398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccf5208521cb8c35f50ee8873df89294b8ed7292",
            "isKey": false,
            "numCitedBy": 13123,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line."
            },
            "slug": "A-decision-theoretic-generalization-of-on-line-and-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "A decision-theoretic generalization of on-line learning and an application to boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The model studied can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting, and it is shown that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121473402"
                        ],
                        "name": "P. Vaidyanathan",
                        "slug": "P.-Vaidyanathan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Vaidyanathan",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vaidyanathan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780112"
                        ],
                        "name": "R. Coifman",
                        "slug": "R.-Coifman",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Coifman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Coifman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066341997"
                        ],
                        "name": "Y. Meyer",
                        "slug": "Y.-Meyer",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Meyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Meyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1650408984"
                        ],
                        "name": "S. Quake",
                        "slug": "S.-Quake",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Quake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Quake"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "Several books describe their design [58][59]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "We use a three level transform with a biorthogonal 5/3 wavelet filterbank1 [58], producing 10 subbands, as shown in Figures 15 and 16."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1687407,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3847cc53a2c7d736ac8bf879df601fe8db17fb12",
            "isKey": false,
            "numCitedBy": 1164,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Wavelet and short-time Fourier analysis is introduced in the context of frequency decompositions. Wavelet type frequency decompositions are associated with lter banks, and using this fact, lter bank theory is used to construct multiplicity M wavelet frames and tight frames. The way in which lter banks lead to decomposition and recomposition of arbitrary separable Hilbert spaces is also described. E cient computational structures for both lter banks and wavelets are also discussed. Contact Address: Ramesh A. Gopinath Department of EE, A235 Rice University, Houston, TX-77251 Phone (713) 527-8750 x3577 email: ramesh@rice.edu This work was supported by AFOSR under grant 90-0334 funded by DARPA Appears in Wavelets: A Tutorial in Theory and Applications, ed. C.K.Chui, Academic Press WAVELETS AND FILTER BANKS R.A.Gopinath and C.S.Burrus Department of Electrical and Computer Engineering, Rice University, Houston, TX-77251 CML TR-91-20 30th September '91"
            },
            "slug": "Wavelets-and-Filter-Banks-Vaidyanathan-Coifman",
            "title": {
                "fragments": [],
                "text": "Wavelets and Filter Banks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145876744"
                        ],
                        "name": "M. Vetterli",
                        "slug": "M.-Vetterli",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Vetterli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vetterli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2442915"
                        ],
                        "name": "J. Kovacevic",
                        "slug": "J.-Kovacevic",
                        "structuredName": {
                            "firstName": "Jelena",
                            "lastName": "Kovacevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kovacevic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10506924,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "5216ea733e562541b33a7f97dab0de072b2e8827",
            "isKey": false,
            "numCitedBy": 2896,
            "numCiting": 313,
            "paperAbstract": {
                "fragments": [],
                "text": "First published in 1995, Wavelets and Subband Coding offered a unified view of the exciting field of wavelets and their discrete-time cousins, filter banks, or subband coding. The book developed the theory in both continuous and discrete time, and presented important applications. During the past decade, it filled a useful need in explaining a new view of signal processing based on flexible time-frequency analysis and its applications. Since 2007, the authors now retain the copyright and allow open access to the book."
            },
            "slug": "Wavelets-and-Subband-Coding-Vetterli-Kovacevic",
            "title": {
                "fragments": [],
                "text": "Wavelets and Subband Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "Wavelets and Subband Coding offered a unified view of the exciting field of wavelets and their discrete-time cousins, filter banks, or subband coding and developed the theory in both continuous and discrete time."
            },
            "venue": {
                "fragments": [],
                "text": "Prentice Hall Signal Processing Series"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1847175"
                        ],
                        "name": "M. Minsky",
                        "slug": "M.-Minsky",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Minsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Minsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2434678"
                        ],
                        "name": "S. Papert",
                        "slug": "S.-Papert",
                        "structuredName": {
                            "firstName": "Seymour",
                            "lastName": "Papert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Papert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[17] documents the limitations of linear discriminators and, in particular, linear discriminators cannot represent exclusive-or and parity type functions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59654342,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "89ef34a30564e095b9c72f641109b0443fb6109a",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This is likewise one of the factors by obtaining the soft documents of this perceptrons an introduction to computational geometry expanded edition by online. You might not require more era to spend to go to the book instigation as competently as search for them. In some cases, you likewise accomplish not discover the notice perceptrons an introduction to computational geometry expanded edition that you are looking for. It will categorically squander the time."
            },
            "slug": "Perceptrons:-An-Introduction-to-Computational-Minsky-Papert",
            "title": {
                "fragments": [],
                "text": "Perceptrons: An Introduction to Computational Geometry, Expanded Edition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "You might not require more era to spend to go to the book instigation as competently as search for the soft documents of this perceptrons an introduction to computational geometry expanded edition by online."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32913617"
                        ],
                        "name": "M. L\u00e9vesque",
                        "slug": "M.-L\u00e9vesque",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "L\u00e9vesque",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. L\u00e9vesque"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 215711504,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "0842bc47d833df488aa391aa2b8854013f9da195",
            "isKey": false,
            "numCitedBy": 1766,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "discusses the characterization of the products of these newly isolated oncogenes. Each of these reviews concludes by examining the directions for future experiments; the subsequent article then often describes that research. The series of four articles permits the reader to get a sense of the length of time, the number of researchers, and the huge effort necessary to make significant advances. The book is written at a level which can be understood by anyone with some background in biology. It assumes very little, and most articles are self-explanatory. As Friedberg is careful to point out, this book is not meant to cover all of cancer biology rigorously or comprehensively, but instead to convey several important concepts. As such, it is an excellent, easily read volume for anyone, especially students, wishing to learn about cancer biology; it would be very useful as a fast overview of the field which will make subsequent reading of more detailed articles much easier. So well written and easy to read that it is both enjoyable and informative, this book is highly recommended to anyone interested in learning about cancer biology."
            },
            "slug": "Perception-L\u00e9vesque",
            "title": {
                "fragments": [],
                "text": "Perception"
            },
            "venue": {
                "fragments": [],
                "text": "The Yale Journal of Biology and Medicine"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90716724"
                        ],
                        "name": "T. Martinez",
                        "slug": "T.-Martinez",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Martinez",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Martinez"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "It is not clear whether such decision boundaries will be good for separating two or more classes in a high dimensional space [51][52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14842477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2059139942834d72776d873575747edf3c2a0fb1",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Demands for applications requiring massive parallelism in symbolic environments have given rebirth to research in models labeled as neural networks. These models are made up of many simple nodes which are highly interconnected such that computation takes place as data flows amongst the nodes of the network. To present, most models have proposed nodes based on simple analog functions, where inputs are multiplied by weights and summed, the total then optionally being transformed by an arbitrary function at the node. Learning in these systems is accomplished by adjusting the weights on the input lines. This paper discusses the use of digital (boolean) nodes as a primitive building block in connectionist systems. Digital nodes naturally engender new paradigms and mechanisms for learning and processing in connectionist networks. The digital nodes are used as the basic building block of a class of models called ASOCS (Adaptive Self-Organizing Concurrent Systems). These models combine massive parallelism with the ability to adapt in a self-organizing fashion. Basic features of standard neural network learning algorithms and those proposed using digital nodes are compared and contrasted. The latter mechanisms can lead to vastly improved efficiency for many applications."
            },
            "slug": "Digital-Neural-Networks-Martinez",
            "title": {
                "fragments": [],
                "text": "Digital Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper discusses the use of digital (boolean) nodes as a primitive building block in connectionist systems, and basic features of standard neural network learning algorithms and those proposed using digital nodes are compared and contrasted."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1988 IEEE International Conference on Systems, Man, and Cybernetics"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143986204"
                        ],
                        "name": "I. Kononenko",
                        "slug": "I.-Kononenko",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Kononenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kononenko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1590400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "343115f687957110e56dfdf430a65ee4490a77ab",
            "isKey": false,
            "numCitedBy": 374,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In the paper the algorithm of the 'naive' Bayesian classifier (that assumes the independence of attributes) is extended to detect the dependencies between attributes. The idea is to optimize the tradeoff between the 'non-naivety' and the reliability of approximations of probabilities. Experiments in four medical diagnostic problems are described. In two domains where by the experts opinion the attributes are in fact independent the semi- naive Bayesian classifier achieved the same classification accuracy as naive Bayes. In two other domains the semi-naive Bayesian classifier slightly outperformed the naive Bayesian classifier."
            },
            "slug": "Semi-Naive-Bayesian-Classifier-Kononenko",
            "title": {
                "fragments": [],
                "text": "Semi-Naive Bayesian Classifier"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The algorithm of the 'naive' Bayesian classifier (that assumes the independence of attributes) is extended to detect the dependencies between attributes to optimize the tradeoff between the 'non-naivety' and the reliability of approximations of probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "EWSL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88295667"
                        ],
                        "name": "emontmej",
                        "slug": "emontmej",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "emontmej",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "emontmej"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1618022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d260a65afc4d3a90a96248e7fa0e0e3b779285ee",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The talk describes the \u00a3 120M UK \u2018e-Science\u2019 initiative and begins by defining what is meant by the term e-Science. The majority of the \u00a3 120M, some \u00a3 85M, is for the support of large-scale e-Science projects in many areas of science and engineering. The infrastructure needed to support such projects needs to allow sharing of distributed and heterogeneous computational and data resources and support effective collaboration between groups of scientists. Such an infrastructure is commonly referred to as the Grid. The remaining funds, some \u00a3 35M, constitute the e-Science \u2018Core Program\u2019 and is intended to encourage the development of robust and generic Grid middleware in collaboration with industry. The key elements of the Core Program will be described including the construction of a UK e-Science Grid. In addition, the talk will include a description of the pilot projects that have so far received funding. These span a range of disciplines from particle physics and astronomy to engineering and healthcare. We conclude with some remarks about the need to develop a data architecture for the Grid that will allow federated access to relational databases as well as flat files. H. Zima et al. (Eds.): ISHPC 2002, LNCS 2327, p. 6, 2002. c \u00a9 Springer-Verlag Berlin Heidelberg 2002 SPEC HPC2002: The Next High-Performance Computer Benchmark"
            },
            "slug": "High-Performance-Computing-emontmej",
            "title": {
                "fragments": [],
                "text": "High Performance Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The key elements of the Core Program will be described including the construction of a UK e-Science Grid and the need to develop a data architecture for the Grid that will allow federated access to relational databases as well as flat files."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103837182"
                        ],
                        "name": "Neil Gershenfeld",
                        "slug": "Neil-Gershenfeld",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Gershenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neil Gershenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6536338,
            "fieldsOfStudy": [
                "Education",
                "Art"
            ],
            "id": "0a833d95d86be8bac0bb315897666d0bd9f7b815",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Actively promoting a unique, antidisciplinary culture, the MIT Media Lab (http://www.media.mit.edu) encourages an unconventional mixing and matching of seemingly disparate research areas. Since opening its doors in 1985, the Lab has pioneered such areas as wearable computing, tangible interfaces, and a\ue000ective computing. Today, faculty members, research sta\ue000, and students at the Lab work in more than 25 research groups on some 350 projects that range from digital approaches for treating neurological disorders; to a stackable, electric car for sustainable cities; to smart prostheses; to advanced imaging technologies that can \"see around a corner.\" The Lab is supported by more than 70 sponsors, including some of the world's leading corporations. These sponsors provide a majority of the Lab's approximately $45 million annual operating budget. Research at the Media Lab is tightly coupled with the graduate academic Program in Media Arts and Sciences (http:// catalog.mit.edu/schools/architecture-planning/media-artssciences), which o\ue000ers master's and doctoral degrees."
            },
            "slug": "MIT-Media-Lab-Gershenfeld",
            "title": {
                "fragments": [],
                "text": "MIT-Media Lab"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Since opening its doors in 1985, the MIT Media Lab has pioneered such areas as wearable computing, tangible interfaces, and a\ue000ective computing."
            },
            "venue": {
                "fragments": [],
                "text": "ICMC"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1847175"
                        ],
                        "name": "M. Minsky",
                        "slug": "M.-Minsky",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Minsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Minsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2434678"
                        ],
                        "name": "S. Papert",
                        "slug": "S.-Papert",
                        "structuredName": {
                            "firstName": "Seymour",
                            "lastName": "Papert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Papert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5400596,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f74ded11f72099d16591a1191d72262ae6b5f14a",
            "isKey": false,
            "numCitedBy": 3040,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Cambridge, Mass.: MIT Press, 1972. 2nd. ed. The book's aim is to seek general results from the close study of abstract version of devices known as perceptrons"
            },
            "slug": "Perceptrons-an-introduction-to-computational-Minsky-Papert",
            "title": {
                "fragments": [],
                "text": "Perceptrons - an introduction to computational geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The aim of this book is to seek general results from the close study of abstract version of devices known as perceptrons."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "Probability functions and classification function for a hypothetical classification problem (adapted from [27]) A"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "If we represent the probabilities accurately in this region, the classification boundary will be as precise as possible[15][27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9584248,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "877a887e7af7daebcb685e4d7b5e80f764035581",
            "isKey": false,
            "numCitedBy": 4042,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Title Type pattern recognition with neural networks in c++ PDF pattern recognition and neural networks PDF neural networks for pattern recognition advanced texts in econometrics PDF neural networks for applied sciences and engineering from fundamentals to complex pattern recognition PDF an introduction to biological and artificial neural networks for pattern recognition spie tutorial text vol tt04 tutorial texts in optical engineering PDF"
            },
            "slug": "Pattern-Recognition-and-Neural-Networks-LeCun-Bengio",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition and Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737063"
                        ],
                        "name": "I. Daubechies",
                        "slug": "I.-Daubechies",
                        "structuredName": {
                            "firstName": "Ingrid",
                            "lastName": "Daubechies",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Daubechies"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "linear phase) [60], but there has not been rigorous verification of this."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58524360,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "7e63bf9af3f70abd5771c06d459a0d3fbfbb2909",
            "isKey": false,
            "numCitedBy": 15553,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction Preliminaries and notation The what, why, and how of wavelets The continuous wavelet transform Discrete wavelet transforms: Frames Time-frequency density and orthonormal bases Orthonormal bases of wavelets and multiresolutional analysis Orthonormal bases of compactly supported wavelets More about the regularity of compactly supported wavelets Symmetry for compactly supported wavelet bases Characterization of functional spaces by means of wavelets Generalizations and tricks for orthonormal wavelet bases References Indexes."
            },
            "slug": "Ten-Lectures-on-Wavelets-Daubechies",
            "title": {
                "fragments": [],
                "text": "Ten Lectures on Wavelets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a meta-analyses of the wavelet transforms of Coxeter\u2019s inequality and its applications to multiresolutional analysis and orthonormal bases."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11079833"
                        ],
                        "name": "S. Sutherland",
                        "slug": "S.-Sutherland",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Sutherland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sutherland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35236366,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "ef46c51a9f9db65311accbfa5405b1d0dc280f93",
            "isKey": false,
            "numCitedBy": 444,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Vision and Visual Dysfunction.General editor: John Cronly-Dillon. Macmillan: 1991. 17 volumes. Approximately 5,000 pages. \u00a31,250, $2,295."
            },
            "slug": "Eye,-brain-and-vision-Sutherland",
            "title": {
                "fragments": [],
                "text": "Eye, brain and vision"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3985917"
                        ],
                        "name": "H. Bastian",
                        "slug": "H.-Bastian",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Bastian",
                            "middleNames": [
                                "Charlton"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bastian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4120647,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "2f1f4a22a906e57c81241c16a7c2fc982d9d44c6",
            "isKey": false,
            "numCitedBy": 1338,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "VERY different meanings have been attached to the words sensation and perception by different writers; and this diversity of meaning is to be met with in physiological as well as in more strictly philosophical works. Yet it is most important that we should come to a definite understanding upon the subject, in order to know whether certain physiologists have been warranted in assigning sensation and perception to different parts of the brain, as functions of separate portions of this principal organ of mind."
            },
            "slug": "Sensation-and-Perception.\u2014I-Bastian",
            "title": {
                "fragments": [],
                "text": "Sensation and Perception.\u2014I"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1869
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144047174"
                        ],
                        "name": "B. Kumar",
                        "slug": "B.-Kumar",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Kumar",
                            "middleNames": [
                                "V.",
                                "K.",
                                "Vijaya"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kumar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10734630,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "6b925d49136ddc799afcf88487b577cfdb3d5824",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 107,
            "paperAbstract": {
                "fragments": [],
                "text": "A tutorial survey is presented of the many composite filter designs proposed for distortion-invariant optical pattern recognition. Remarks are made throughout regarding areas for further investigation."
            },
            "slug": "Tutorial-survey-of-composite-filter-designs-for-Kumar",
            "title": {
                "fragments": [],
                "text": "Tutorial survey of composite filter designs for optical correlators."
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A tutorial survey is presented of the many composite filter designs proposed for distortion-invariant optical pattern recognition and remarks are made regarding areas for further investigation."
            },
            "venue": {
                "fragments": [],
                "text": "Applied optics"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "If we represent the probabilities accurately in this region, the classification boundary will be as precise as possible[15][27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "This algorithm works under a very similar principle to support vector machines [15] as used by [19] [81], [82], [83] by giving more weight to the training examples that are closet to the decision boundary between the two classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "(This concept of selecting samples near the decision boundary is similar to the way support vector machines (SVMs) [15][24] work."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51921883"
                        ],
                        "name": "Refractor",
                        "slug": "Refractor",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Refractor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Refractor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "This representation captures each sample\u2019s relative position with respect to all the others and implicitly captures many geometric properties [57]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208793436,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "c3a24b0b38922c4f3a825edb97cc470a4ca7af75",
            "isKey": false,
            "numCitedBy": 3113,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision-Refractor",
            "title": {
                "fragments": [],
                "text": "Vision"
            },
            "venue": {
                "fragments": [],
                "text": "The Lancet"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1993044131"
                        ],
                        "name": "\u674e\u5e7c\u5347",
                        "slug": "\u674e\u5e7c\u5347",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\u674e\u5e7c\u5347",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u674e\u5e7c\u5347"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6622887"
                        ],
                        "name": "F. G. J. Hayhoe",
                        "slug": "F.-G.-J.-Hayhoe",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Hayhoe",
                            "middleNames": [
                                "G.",
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. G. J. Hayhoe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 222242179,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "0e9a7789ec7cfc34a1bb953530a0e57bd0e8d018",
            "isKey": false,
            "numCitedBy": 40974,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The following is a fundamental reading list for doctoral candidates to use as a guide in preparing for their comprehensive examination in the field of Modernism. A student is expected to have read widely in the field; to be thoroughly familiar with the major writers; and to read widely in the journal literature. The following reading list is suggestive rather than definitive, a list for the student and Committee on Studies to begin with. The list has four sections: \u2022 Poetry \u2022 Drama \u2022 Fiction \u2022 Secondary Sources"
            },
            "slug": "Ph-\u674e\u5e7c\u5347-Hayhoe",
            "title": {
                "fragments": [],
                "text": "Ph"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "Modular viewpoint-based models [4][30][29] decompose appearance into separate 2D models corresponding to different viewpoints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 192
                            }
                        ],
                        "text": "Local Appearance Versus Global Appearance Much work in object recognition treats the appearance of the object in terms of full-sized rigid templates including the work of [5],[6], [30], [44], [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "There are many ways to do this such as linear projection methods[5][29][30], and resolution reduction methods[14][18], or simply by hand selecting features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "appearance of parts - There are many algorithms that treat the object\u2019s appearance as one monolithic quantity such as [30][29][5][6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "There can be a small finite number of viewpoints [4] or the 2D information could be represented as a continuous function of the 3D pose of the object [30][29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classifier and Shift-invariant Automatic Target Recogntion"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks.\u201dNeural Networks  "
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Representation of Local Appearance using Wavelets Haar wavelets [81], [82], [83], Gaussian pyramid representation [84] and Gabor wavelets [78], [79] are all multi-resolution based representations that have been used in object recognition/detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Some approaches do not model the geometry among local areas [84][9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "Also unlike the Gaussian pyramid representation [84] and Gabor wavelets [78], [79] our wavelet representation has no redundancy; that is the transform is the same size as the original image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "At one extreme, some representations do not model spatial relationships [9][84]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Cluster-Based Model for Object Detection."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544594"
                        ],
                        "name": "J. Frisby",
                        "slug": "J.-Frisby",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Frisby",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Frisby"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143520256,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ce3bdb7cea0935025e541e56c3f6ebacb9cf29ae",
            "isKey": false,
            "numCitedBy": 280,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Seeing:-Illusion,-Brain-and-Mind-Frisby",
            "title": {
                "fragments": [],
                "text": "Seeing: Illusion, Brain and Mind"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2353436"
                        ],
                        "name": "T. Niblett",
                        "slug": "T.-Niblett",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Niblett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Niblett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43140291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9414d6f32edefe583ed98300f97e1d355584a43",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Constructing-Decision-Trees-in-Noisy-Domains-Niblett",
            "title": {
                "fragments": [],
                "text": "Constructing Decision Trees in Noisy Domains"
            },
            "venue": {
                "fragments": [],
                "text": "EWSL"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7814856,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7085b6daecc2aefdb9c30283f69ce21d7b0780ca",
            "isKey": false,
            "numCitedBy": 1075,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Solid-shape-Koenderink",
            "title": {
                "fragments": [],
                "text": "Solid shape"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1991940"
                        ],
                        "name": "J. Proakis",
                        "slug": "J.-Proakis",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Proakis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Proakis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "This idea is similar to using more data to improve the accuracy of a statistical estimate [56]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2072334,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7eeb730524a8e980f91c923b8e1d026b17883e38",
            "isKey": false,
            "numCitedBy": 7906,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probability,-random-variables-and-stochastic-Proakis",
            "title": {
                "fragments": [],
                "text": "Probability, random variables and stochastic processes"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144441876"
                        ],
                        "name": "J. Lira",
                        "slug": "J.-Lira",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Lira",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 54157570,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d13d8dfe7bcb841959273909bbc363000bb5517a",
            "isKey": false,
            "numCitedBy": 1458,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Two-dimensional-signal-and-image-processing-Lira",
            "title": {
                "fragments": [],
                "text": "Two dimensional signal and image processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3235255"
                        ],
                        "name": "H. Goldstine",
                        "slug": "H.-Goldstine",
                        "structuredName": {
                            "firstName": "Herman",
                            "lastName": "Goldstine",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Goldstine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47965200"
                        ],
                        "name": "F. Murray",
                        "slug": "F.-Murray",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Murray",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41224665"
                        ],
                        "name": "J. Neumann",
                        "slug": "J.-Neumann",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Neumann",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Neumann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27870363,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "53d263e5b1118e804f76d4c52d4d28297ad912ae",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Jacobi-Method-for-Real-Symmetric-Matrices-Goldstine-Murray",
            "title": {
                "fragments": [],
                "text": "The Jacobi Method for Real Symmetric Matrices"
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1959
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Report on the 1995 Workshop on 3-D Object Recognition in Computer Vision Object Recogntion in Computer Vision. International NSF-ARPA Workshop, Dec., '94"
            },
            "venue": {
                "fragments": [],
                "text": "Leccture Notes in Computer Science"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "In contrast, methods that use a set of hand-picked features step through the image in irregular increments and incur additional computational cost by doing so [80]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "Since main memory access can be as long as 100 clock cycles[80], these operations will lead to significant performance degradation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "High Performance Computing (2nd Ed)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computational Studies for Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the second Europena working session on learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Networks for Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Clarendon Press. Oxford,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lecture notes for MIT Course 9.520: Learning, Approximation, and Networks (class 9)"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture notes for MIT Course 9.520: Learning, Approximation, and Networks (class 9)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Measure for Concept Dissimilarity and Its Applications in Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Conference on Computing and Information"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bill Gates' Other CEO"
            },
            "venue": {
                "fragments": [],
                "text": "Bill Gates' Other CEO"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perception (3rd Edition)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sensation and Perception (4th Edition)"
            },
            "venue": {
                "fragments": [],
                "text": "Brooks / Cole Publishing"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Report on the 1995 Workshop on 3-D Object Recognition in Computer Vision."
            },
            "venue": {
                "fragments": [],
                "text": "Object Recogntion in Computer Vision. International NSF-ARPA Workshop,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lectures on Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gordon.Theories of Visual Perception"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bill Gates' Other CEO"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 175
                            }
                        ],
                        "text": "Local Appearance Versus Global Appearance Much work in object recognition treats the appearance of the object in terms of full-sized rigid templates including the work of [5],[6], [30], [44], [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 129
                            }
                        ],
                        "text": "appearance of parts - There are many algorithms that treat the object\u2019s appearance as one monolithic quantity such as [30][29][5][6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "First, the global methods that involve dimensionality reduction [5],[6], [30] will end up emphasizing the coarse attributes of object appearance rather than the distinctive nature of the smaller parts such as the eyes, nose, and mouth on a face."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eigenfaces vs"
            },
            "venue": {
                "fragments": [],
                "text": "Fisherfaces: Recognition Using Class Specific Linear Projection. PAMI. 19:7 pp. 711-720. July,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wavelets and Filter Banks. Wellesley -Cambridge Press"
            },
            "venue": {
                "fragments": [],
                "text": "Wavelets and Filter Banks. Wellesley -Cambridge Press"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Goldstein.Sensation and Perception  (4th Edition)"
            },
            "venue": {
                "fragments": [],
                "text": "Brooks / Cole Publishing"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ten Lectures on Wavelets. CBMS-NSF Regional Conference Series in Applied Mathematics 61"
            },
            "venue": {
                "fragments": [],
                "text": "Ten Lectures on Wavelets. CBMS-NSF Regional Conference Series in Applied Mathematics 61"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lecture notes for MIT Course 9"
            },
            "venue": {
                "fragments": [],
                "text": "Learning, Approximation, and Networks"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Illusion, Brain, and Mind"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 36,
            "methodology": 27,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 96,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/A-statistical-approach-to-3d-object-detection-to-Schneiderman-Kanade/3737d479a5764eecef0cee5081e64f5f884508b1?sort=total-citations"
}