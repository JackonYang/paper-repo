{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5733118"
                        ],
                        "name": "A. Conway",
                        "slug": "A.-Conway",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Conway",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Conway"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42019065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44e29d6e54fc2971b7ec16b7cd65f6ff33388190",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a syntactic approach to deducing the logical structure of printed documents from their physical layout. Page layout is described by a two-dimensional grammar, similar to a context-free string grammar, and a chart parser is used to parse segmented page images according to the grammar. This process is part of a system which reads scanned document images and produces computer-readable text in a logical mark-up format such as SGML. The system is briefly outlined, the grammar formalism and the parsing algorithm are described in detail, and some experimental results are reported.<<ETX>>"
            },
            "slug": "Page-grammars-and-page-parsing.-A-syntactic-to-Conway",
            "title": {
                "fragments": [],
                "text": "Page grammars and page parsing. A syntactic approach to document layout recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A syntactic approach to deducing the logical structure of printed documents from their physical layout by a two-dimensional grammar, similar to a context-free string grammar, and a chart parser is used to parse segmented page images according to the grammar."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36738748"
                        ],
                        "name": "Debashish Niyogi",
                        "slug": "Debashish-Niyogi",
                        "structuredName": {
                            "firstName": "Debashish",
                            "lastName": "Niyogi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Debashish Niyogi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 2314813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9349824a7e0a513667071df1c07833adb6f197bb",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The analysis of a document image to derive a symbolic description of its structure and contents involves using spatial domain knowledge to classify the different printed blocks (e.g., text paragraphs), group them into logical units (e.g., newspaper stories), and determine the reading order of the text blocks within each unit. These steps describe the conversion of the physical structure of a document into its logical structure. We have developed a computational model for document logical structure derivation, in which a rule-based control strategy utilizes the data obtained from analyzing a digitized document image, and makes inferences using a multi-level knowledge base of document layout rules. The knowledge-based document logical structure derivation system (DeLoS) based on this model consists of a hierarchical rule-based control system to guide the block classification, grouping and read-ordering operations; a global data structure to store the document image data and incremental inferences; and a domain knowledge base to encode the rules governing document layout."
            },
            "slug": "Knowledge-based-derivation-of-document-logical-Niyogi-Srihari",
            "title": {
                "fragments": [],
                "text": "Knowledge-based derivation of document logical structure"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A computational model for document logical structure derivation is developed, in which a rule-based control strategy utilizes the data obtained from analyzing a digitized document image, and makes inferences using a multi-level knowledge base of document layout rules."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529659"
                        ],
                        "name": "Yuka Tateisi",
                        "slug": "Yuka-Tateisi",
                        "structuredName": {
                            "firstName": "Yuka",
                            "lastName": "Tateisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuka Tateisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065731852"
                        ],
                        "name": "Nohuyasu Itoh",
                        "slug": "Nohuyasu-Itoh",
                        "structuredName": {
                            "firstName": "Nohuyasu",
                            "lastName": "Itoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nohuyasu Itoh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46950111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2924edf2ca9a467d247fba911b7bc66f5c86bb51",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of stochastic syntactic analysis is applied to extracting the logical structure of a printed document from its physical layout and keywords indicating logical components. The document is parsed as a sentence consisting of text lines and graphic objects according to a stochastic regular grammar with attributes. By using stochastic analysis, the parser can retain possible results in order of their probability, and thus, if ambiguity occurs, it selects an optimal result more appropriately than deterministic systems. A mark up system applying the method was constructed, and 87% of the logical components of manuals and 82% of those of technical papers are correctly marked up. The rate improved to 89% when the second candidates were considered, showing the advantage of the authors' approach over the deterministic approach."
            },
            "slug": "Using-stochastic-syntactic-analysis-for-extracting-Tateisi-Itoh",
            "title": {
                "fragments": [],
                "text": "Using stochastic syntactic analysis for extracting a logical structure from a document image"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A method of stochastic syntactic analysis is applied to extracting the logical structure of a printed document from its physical layout and keywords indicating logical components, and 87% of the logical components of manuals and 82% of those of technical papers are correctly marked up."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 12th IAPR International Conference on Pattern Recognition, Vol. 3 - Conference C: Signal Processing (Cat. No.94CH3440-5)"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 83
                            }
                        ],
                        "text": "Surveys of page segmentation algorithms can be found in O'Gorman and Kasturi20 and Jain and Yu.3 A recent workshop21 was devoted to addressing issues related to physical layout analysis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "Surveys of page segmentation algorithms can be found in O'Gorman and Kasturi(20) and Jain and Yu.(3) A recent workshop(21) was devoted to addressing issues related to physical layout analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46138594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b39beea0f761152e65fac0e498af387821d887f1",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Transforming a paper document to its electronic version in a form suitable for efficient storage, retrieval, and interpretation continues to be a challenging problem. An efficient representation scheme for document images is necessary to solve this problem. Document representation involves techniques of thresholding, skew detection, geometric layout analysis, and logical layout analysis. The derived representation can then be used in document storage and retrieval. Page segmentation is an important stage in representing document images obtained by scanning journal pages. The performance of a document understanding system greatly depends on the correctness of page segmentation and labeling of different regions such as text, tables, images, drawings, and rulers. We use the traditional bottom-up approach based on the connected component extraction to efficiently implement page segmentation and region identification. A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis. Our algorithm has a high accuracy and takes approximately 1.4 seconds on a SGI Indy workstation for model creation, including orientation estimation, segmentation, and labeling (text, table, image, drawing, and ruler) for a 2550/spl times/3300 image of a typical journal page scanned at 300 dpi. This method is applicable to documents from various technical journals and can accommodate moderate amounts of skew and noise."
            },
            "slug": "Document-Representation-and-Its-Application-to-Page-Jain-Yu",
            "title": {
                "fragments": [],
                "text": "Document Representation and Its Application to Page Decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270291"
                        ],
                        "name": "S. Tsujimoto",
                        "slug": "S.-Tsujimoto",
                        "structuredName": {
                            "firstName": "Shuichi",
                            "lastName": "Tsujimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tsujimoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3358140"
                        ],
                        "name": "H. Asada",
                        "slug": "H.-Asada",
                        "structuredName": {
                            "firstName": "Haruo",
                            "lastName": "Asada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Asada"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62682454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5818edaaf099fd0d55344f9ee23f6609bb72367",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A document understanding method based on the tree representation of document structures is proposed. It is shown that documents have an obvious hierarchical structure in their geometry which is represented by a tree. A small number of rules are introduced to transform the geometric structure into the logical structure which represents the semantics. The virtual field separator technique is employed to utilize the information carried by special constituents of documents such as field separators and frames, keeping the number of transformation rules small. Experimental results on a variety of document formats have shown that the proposed method is applicable to most of the documents commonly encountered in daily use, although there is still room for further refinement of the transformation rules.<<ETX>>"
            },
            "slug": "Understanding-multi-articled-documents-Tsujimoto-Asada",
            "title": {
                "fragments": [],
                "text": "Understanding multi-articled documents"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental results on a variety of document formats have shown that the proposed method is applicable to most of the documents commonly encountered in daily use, although there is still room for further refinement of the transformation rules."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings. 10th International Conference on Pattern Recognition"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780258"
                        ],
                        "name": "Jisheng Liang",
                        "slug": "Jisheng-Liang",
                        "structuredName": {
                            "firstName": "Jisheng",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jisheng Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Liang et al.(24) propose a performance metric for evaluating document structure extraction algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 141
                            }
                        ],
                        "text": "A rigorous empirical comparison of ve document physical layout analysis using the PSET software package22 can be found in Mao and Kanungo.23 Liang et al.24 propose a performance metric for evaluating document structure extraction algorithms."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3356036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c348c7104d0a7ac360ae64fe221d83def52c48b3",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a performance metric for the document structure extraction algorithms by finding the correspondences between detected entities and ground truth. We describe a method for determining an algorithm's optimal tuning parameters. We evaluate a group of document layout analysis algorithms on 1600 images from the UW-III Document Image Database, and the quantitative performance measures in terms of the rates of correct, miss, false, merging, splitting, and spurious detections are reported."
            },
            "slug": "Performance-Evaluation-of-Document-Structure-Liang-Phillips",
            "title": {
                "fragments": [],
                "text": "Performance Evaluation of Document Structure Extraction Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A method for determining an algorithm's optimal tuning parameters and the correspondences between detected entities and ground truth is described, and a group of document layout analysis algorithms are evaluated."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34736316"
                        ],
                        "name": "K. Summers",
                        "slug": "K.-Summers",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Summers",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Summers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42137386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69e8dc0a769b5ef941cf8b6c66265d2f33c8b222",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic derivation of logical document structure from generic layout would enable the development of many highly flexible electronic document manipulation tools. This problem can be divided into the segmentation of text into pieces and the classification of these pieces as particular logical structures. This paper proposes an approach to the classification of logical document structures, according to their distance from predefined prototypes. The prototypes consider linguistic information minimally, thus relying minimally on the accuracy of OCR and decreasing language-dependence. Different classes of logical structures and the differences in the requisite information for classifying them are discussed. A prototype format is proposed, existing prototypes and a distance measurement are described, and performance results are provided."
            },
            "slug": "Near-wordless-document-structure-classification-Summers",
            "title": {
                "fragments": [],
                "text": "Near-wordless document structure classification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes an approach to the classification of logical document structures, according to their distance from predefined prototypes, thus relying minimally on the accuracy of OCR and decreasing language-dependence."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2178570"
                        ],
                        "name": "ChunChen Lin",
                        "slug": "ChunChen-Lin",
                        "structuredName": {
                            "firstName": "ChunChen",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ChunChen Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2051086"
                        ],
                        "name": "Y. Niwa",
                        "slug": "Y.-Niwa",
                        "structuredName": {
                            "firstName": "Yosihiro",
                            "lastName": "Niwa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Niwa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144219897"
                        ],
                        "name": "S. Narita",
                        "slug": "S.-Narita",
                        "structuredName": {
                            "firstName": "Seinosuke",
                            "lastName": "Narita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Narita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "Lin 1997 235 book pages two types of errors, N/S reported for 235 pages yes none et al.(8) identi cation rate"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Lin et al.8 proposed a method of analyzing the logical structure of book pages using contents page information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 761,
                                "start": 758
                            }
                        ],
                        "text": "1993 text area document style tree not body, caption, header various in uence rules parameters mentioned footer documents Tateisi and Itoh(37) 1994 stochastic grammars, none grammar rules not headings, paragraph, not physical zones mentioned list item mentioned available Niyogi and Srihari(6) 1995 rule-based, rules rules, tree not title, story, sub-story, newspaper knowledge-based mentioned photo, caption, graph pages Summers(33) 1995 logical prototype, none logical prototypes not paragraph, heading, technical matching, physical mentioned list item reports zones available Dengel and Dubiel(39) 1996 logical structure none GTree not sender, recipient, date letters learning, physical mentioned logo, subject, footer zones available body-text Lin et al.(8) 1997 OCR and rule document style logical labels not headline, content, book based parameters mentioned gure, table, page number, pages head-foot Ishitani(9) 1999 emergent computation, document style logical labels not headline, header, footer various rule based parameters mentioned note, caption, program, documents formula, title, list Kim et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Lin et al.(8) proposed a method of analyzing the logical structure of book pages using contents page information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Lin et al.(8) used two types of labeling errors and an identi cation rate to report the experimental results of their algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "Lin et al.8 used two types of labeling errors and an identi cation rate to report the experimental results of their algorithm."
                    },
                    "intents": []
                }
            ],
            "corpusId": 39618296,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "163c624937731a7acbc9e977a72bfc34d5827c46",
            "isKey": true,
            "numCitedBy": 43,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Numerous studies have so far been carried out extensively for the analysis of document image structure, with particular emphasis placed on media conversion and layout analysis. For the conversion of a collection of books in a library into the form of hypertext documents, a logical structure extraction technology is indispensable, in addition to document layout analysis. The table of contents of a book generally involves very concise and faithful information to represent the logical structure of the entire book. That is to say, we can efficiently analyze the logical structure of a book by making full use of its contents pages. This paper proposes a new approach for document logical structure analysis to convert document images and contents information into an electronic document. First, the contents pages of a book are analyzed to acquire the overall document logical structure. Thereafter, we are able to use this information to acquire the logical structure of all the pages of the book by analyzing consecutive pages of a portion of the book. Test results demonstrate very high discrimination rates: up to 97.6% for the headline structure, 99.4% for the text structure, 97.8% for the page-number structure and almost 100% for the head-foot structure."
            },
            "slug": "Logical-structure-analysis-of-book-document-images-Lin-Niwa",
            "title": {
                "fragments": [],
                "text": "Logical structure analysis of book document images using contents information"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A new approach for document logical structure analysis to convert document images and contents information into an electronic document by analyzing consecutive pages of a portion of the book."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22995244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d85097da36118fbccfeb7802abf89bf4b4c63a3e",
            "isKey": false,
            "numCitedBy": 728,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Page layout analysis is a document processing technique used to determine the format of a page. This paper describes the document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components. The method yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks. It is advantageous over many other methods in three main ways: independence from skew angle, independence from different text spacings, and the ability to process local regions of different text orientations within the same image. Results of the method shown for several different page formats and for randomly oriented subpages on the same image illustrate the versatility of the method. We also discuss the differences, advantages, and disadvantages of the docstrum with respect to other lay-out methods. >"
            },
            "slug": "The-Document-Spectrum-for-Page-Layout-Analysis-O'Gorman",
            "title": {
                "fragments": [],
                "text": "The Document Spectrum for Page Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components, yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266621"
                        ],
                        "name": "M. Viswanathan",
                        "slug": "M.-Viswanathan",
                        "structuredName": {
                            "firstName": "Mahesh",
                            "lastName": "Viswanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Viswanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 2530196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62a53caea5213ea177298d7b2aff292b1386c37a",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Gobbledoc, a system providing remote access to stored documents, which is based on syntactic document analysis and optical character recognition (OCR), is discussed. In Gobbledoc, image processing, document analysis, and OCR operations take place in batch mode when the documents are acquired. The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described. The process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools is also described. Syntactic analysis is used in Gobbledoc to divide each page into labeled rectangular blocks. Blocks labeled text are converted by OCR to obtain a secondary (ASCII) document representation. Since such symbolic files are better suited for computerized search than for human access to the document content and because too many visual layout clues are lost in the OCR process (including some special characters), Gobbledoc preserves the original block images for human browsing. Storage, networking, and display issues specific to document images are also discussed.<<ETX>>"
            },
            "slug": "A-prototype-document-image-analysis-system-for-Nagy-Seth",
            "title": {
                "fragments": [],
                "text": "A prototype document image analysis system for technical journals"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The document image acquisition process and the knowledge base that must be entered into the system to process a family of page images are described, and the process by which the X-Y tree data structure converts a 2-D page-segmentation problem into a series of 1-D string-parsing problems that can be tackled using conventional compiler tools."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40497000"
                        ],
                        "name": "R. Brugger",
                        "slug": "R.-Brugger",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Brugger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brugger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3163684"
                        ],
                        "name": "Abdel Wahab Zramdini",
                        "slug": "Abdel-Wahab-Zramdini",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Zramdini",
                            "middleNames": [
                                "Wahab"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel Wahab Zramdini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Brugger et al.38 described a document logical structure model based on a statistical representation of patterns in a document class, i.e. on generalized N -grams."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 182
                            }
                        ],
                        "text": "Ingold 1991 rule based, none EBNF grammars, not mentioned title, paragraph, section, not and Armangil(35) physical zones presentation rules chapter mentioned available Brugger et al.(38) 1993 N -gram model, none tree not mentioned not memo physical zones mentioned pages available Conway(36) 1993 page grammar page grammars context-free SGML title, heading, paragraph, not string grammar gure mentioned"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Brugger et al.(38) described a document logical structure model based on a statistical representation of patterns in a document class, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "ve memo pages N/S N/S N/S no none Brugger et al.(38) 1993 | one for training, four for testing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41326691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfee9175efcbf193e0546b56af8d8dfcf374eb92",
            "isKey": true,
            "numCitedBy": 33,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present and discuss a novel approach to modeling logical structures of documents, based on a statistical representation of patterns in a document class. An efficient and error tolerant recognition heuristics adapted to the model is proposed. The statistical approach permits easily automated and incremental learning of the model. The approach has been partially evaluated on a prototype. A discussion of the results achieved by the prototype is finally made."
            },
            "slug": "Modeling-documents-for-structure-recognition-using-Brugger-Zramdini",
            "title": {
                "fragments": [],
                "text": "Modeling documents for structure recognition using generalized N-grams"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A novel approach to modeling logical structures of documents, based on a statistical representation of patterns in a document class, is presented and an efficient and error tolerant recognition heuristics adapted to the model are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751773"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mukkai",
                            "lastName": "Krishnamoorthy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266621"
                        ],
                        "name": "M. Viswanathan",
                        "slug": "M.-Viswanathan",
                        "structuredName": {
                            "firstName": "Mahesh",
                            "lastName": "Viswanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Viswanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Krishnamoorthy et al.(30) proposed a document logical structure recognition method that recursively applies grammars to horizontal and vertical projection pro les of the page."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Krishnamoorthy et al.30 proposed a metric based on the percentage of area labeled and missed labels."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Krishnamoorthy et al.(30) proposed a metric based on the percentage of area labeled and missed labels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 28
                            }
                        ],
                        "text": "200 Proc. of SPIE Vol. 5010\nKrishnamoorthy et al.30 proposed a document logical structure recognition method that recursively applies grammars to horizontal and vertical projection pro les of the page."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 28
                            }
                        ],
                        "text": "198 Proc. of SPIE Vol. 5010\nKrishnamoorthy et al.30 describe a hierarchical document page segmentation algorithm that constructs a tree in which each node represents an axis-parallel rectangle."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Krishnamoorthy et al.(30) describe a hierarchical document page segmentation algorithm that constructs a tree in which each node represents an axis-parallel rectangle."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "Krishnamoorthy 1993 page parsing, block grammar, block grammar, not title, author, abstract journal et al.(30) block grammar tree tree mentioned pages Saitoh et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "21 IBM journal Krishnamoorthy 1993 pages for training, % area labeled, N/S reported for each of no none et al.(30) 12 IBM/PAMI missed labels 12 IBM journal pages for testing and IEEE PAMI pages"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16107554,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "717a4ae91ad20667f7ac03ce5538eff36313c299",
            "isKey": true,
            "numCitedBy": 163,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for extracting alternating horizontal and vertical projection profiles are from nested sub-blocks of scanned page images of technical documents is discussed. The thresholded profile strings are parsed using the compiler utilities Lex and Yacc. The significant document components are demarcated and identified by the recursive application of block grammars. Backtracking for error recovery and branch and bound for maximum-area labeling are implemented with Unix Shell programs. Results of the segmentation and labeling process are stored in a labeled x-y tree. It is shown that families of technical documents that share the same layout conventions can be readily analyzed. Results from experiments in which more than 20 types of document entities were identified in sample pages from two journals are presented. >"
            },
            "slug": "Syntactic-Segmentation-and-Labeling-of-Digitized-Krishnamoorthy-Nagy",
            "title": {
                "fragments": [],
                "text": "Syntactic Segmentation and Labeling of Digitized Pages from Technical Journals"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that families of technical documents that share the same layout conventions can be readily analyzed and backtracking for error recovery and branch and bound for maximum-area labeling are implemented with Unix Shell programs."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066251026"
                        ],
                        "name": "T. Saitoh",
                        "slug": "T.-Saitoh",
                        "structuredName": {
                            "firstName": "Takashi",
                            "lastName": "Saitoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Saitoh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2147734"
                        ],
                        "name": "Michiyoshi Tachikawa",
                        "slug": "Michiyoshi-Tachikawa",
                        "structuredName": {
                            "firstName": "Michiyoshi",
                            "lastName": "Tachikawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michiyoshi Tachikawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40073528"
                        ],
                        "name": "Toshifumi Yamaai",
                        "slug": "Toshifumi-Yamaai",
                        "structuredName": {
                            "firstName": "Toshifumi",
                            "lastName": "Yamaai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshifumi Yamaai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "Saitoh et al.(7) presented a system for document segmentation, text area classi cation and ordering."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Saitoh et al.7 presented a system for document segmentation, text area classi cation and ordering."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "Saitoh et al.(7) used three criteria to show the results of their algorithm, based on three proposed ways of using their experimental results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Saitoh 1993 393 Japanese/ six criteria based N/S results reported yes none et al.(7) English pages on result usage based on for testing three criteria"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "block grammar tree tree mentioned pages Saitoh et al.(7) 1993 text area document style tree not body, caption, header various in uence rules parameters mentioned footer documents Tateisi and Itoh(37) 1994 stochastic grammars, none grammar rules not headings, paragraph, not physical zones mentioned list item mentioned available Niyogi and Srihari(6) 1995 rule-based, rules rules, tree not title, story, sub-story, newspaper knowledge-based mentioned photo, caption, graph pages Summers(33) 1995 logical prototype, none logical prototypes not paragraph, heading, technical matching, physical mentioned list item reports zones available Dengel and Dubiel(39) 1996 logical structure none GTree not sender, recipient, date letters learning, physical mentioned logo, subject, footer zones available body-text Lin et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Saitoh et al.7 used three criteria to show the results of their algorithm, based on three proposed ways of using their experimental results."
                    },
                    "intents": []
                }
            ],
            "corpusId": 35158310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5c32f8cbf6183b8214f08c947c77a51769b8029",
            "isKey": true,
            "numCitedBy": 24,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for document image segmentation and ordering text areas is described and applied to both Japanese and English complex printed page layouts. There is no need to make any assumption about the shape of blocks, hence the segmentation technique can handle not only skewed images without skew-correction but also documents where column are not rectangular. In this technique, on the bottom-up strategy, the connected components are extracted from the reduced image, and classified according to their local information. The connected components are merged into lines, and lines are merged into areas. Extracted text areas are classified as body, caption, header, and footer. A tree graph of the layout of body texts is made, and we get the order of texts by preorder traversal on the graph. The authors introduce the influence range of each node, a procedure for the title part, and extraction of the white horizontal separator. Making it possible to get good results on various documents. The total system is fast and compact.<<ETX>>"
            },
            "slug": "Document-image-segmentation-and-text-area-ordering-Saitoh-Tachikawa",
            "title": {
                "fragments": [],
                "text": "Document image segmentation and text area ordering"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A system for document image segmentation and ordering text areas is described and applied to both Japanese and English complex printed page layouts that can handle not only skewed images without skew-correction but also documents where column are not rectangular."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28689838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed11aa01933bb23a019129c44a35bc32b593e6cd",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to accurately detect those areas in plain text documents that consist of contiguous text is an important pre- process to many applications. This paper introduces a novel method that uses both spatial and linguistic knowledge in an accurate manner to provide an initial analysis of the document. This initial analysis may then be extended to provide a complete analysis of the text areas in the document."
            },
            "slug": "Layout-and-language:-an-efficient-algorithm-for-on-Hurst",
            "title": {
                "fragments": [],
                "text": "Layout and language: an efficient algorithm for detecting text blocks based on spatial and linguistic evidence"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper introduces a novel method that uses both spatial and linguistic knowledge in an accurate manner to provide an initial analysis of the document that may then be extended to provide a completeAnalysis of the text areas in the document."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695526"
                        ],
                        "name": "S. Mao",
                        "slug": "S.-Mao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1725865,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "730af7f2d19d37724119e00f48bc5ae7363fa86a",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. Empirical performance evaluation of page segmentation algorithms has become increasingly important due to the numerous algorithms that are being proposed each year. In order to choose between these algorithms for a specific domain it is important to empirically evaluate their performance. To accomplish this task the document image analysis community needs: i) standardized document image datasets with groundtruth; ii) evaluation metrics that are agreed upon by researchers; and iii) freely available software for evaluating new algorithms and replicating other researchers' results. In an earlier paper (IEEE Transactions on Pattern Analysis and Machine Intelligence 2001) we published evaluation results for various popular page segmentation algorithms using the University of Washington dataset. In this paper we describe the software architecture of the PSET evaluation package, which was used to evaluate the segmentation algorithms. The description of the architecture will allow researchers to understand the software better, replicate our results, evaluate new algorithms, experiment with new metrics and datasets, etc. The software is written using the C language on the SUN/UNIX platform and is being made available to researchers at no cost."
            },
            "slug": "Software-architecture-of-PSET:-a-page-segmentation-Mao-Kanungo",
            "title": {
                "fragments": [],
                "text": "Software architecture of PSET: a page segmentation evaluation toolkit"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The software architecture of the PSET evaluation package, which was used to evaluate the segmentation algorithms, is described to allow researchers to understand the software better, replicate the results, evaluate new algorithms, experiment with new metrics and datasets, etc."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34878566"
                        ],
                        "name": "H. Fujisawa",
                        "slug": "H.-Fujisawa",
                        "structuredName": {
                            "firstName": "Hiromichi",
                            "lastName": "Fujisawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Fujisawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737939"
                        ],
                        "name": "Y. Nakano",
                        "slug": "Y.-Nakano",
                        "structuredName": {
                            "firstName": "Yasuaki",
                            "lastName": "Nakano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nakano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6572034"
                        ],
                        "name": "K. Kurino",
                        "slug": "K.-Kurino",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Kurino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kurino"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62753568,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "118c2465b0f00736c743883be62a45eca580cf8c",
            "isKey": false,
            "numCitedBy": 255,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A pattern-oriented segmentation method for optical character recognition that leads to document structure analysis is presented. As a first example, segmentation of handwritten numerals that touch are treated. Connected pattern components are extracted, and spatial interrelations between components are measured and grouped into meaningful character patterns. Stroke shapes are analyzed and a method of finding the touching positions that separates about 95% of connected numerals correctly is described. Ambiguities are handled by multiple hypotheses and verification by recognition. An extended form of pattern-oriented segmentation, tabular form recognition, is considered. Images of tabular forms are analyzed, and frames in the tabular structure are extracted. By identifying semantic relationships between label frames and data frames, information on the form can be properly recognized. >"
            },
            "slug": "Segmentation-methods-for-character-recognition:-to-Fujisawa-Nakano",
            "title": {
                "fragments": [],
                "text": "Segmentation methods for character recognition: from segmentation to document structure analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A pattern- oriented segmentation method for optical character recognition that leads to document structure analysis is presented, and an extended form of pattern-oriented segmentation, tabular form recognition, is considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2461436"
                        ],
                        "name": "Jiangying Zhou",
                        "slug": "Jiangying-Zhou",
                        "structuredName": {
                            "firstName": "Jiangying",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangying Zhou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23410608,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "999e76f9115af2741b0cd973d875163ae714d5da",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Page-segmentation-and-classification-Pavlidis-Zhou",
            "title": {
                "fragments": [],
                "text": "Page segmentation and classification"
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13615381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d91e0d202fa23b7a2e81c5b3b04eb4cc5327b0f9",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs. The physical reader of the paper document is the scanner just like the physical reader of the floppy is the floppy drive and the physical reader of the tape cartridge is the tape cartridge drive, and the physical reader of the CDROM is the CDROM drive. In the survey presented, we restrict ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences. Understanding such documents involves estimating the rotation skew of each document page, determining the geometric page layout, labeling blocks as text or non-text, determining the read order for text blocks, recognizing the text of text blocks through an OCR system, determining the logical page layout, and formatting the data and information of the document in a suitable way for use by a word processing system or by an information retrieval system.<<ETX>>"
            },
            "slug": "Document-image-understanding:-geometric-and-logical-Haralick",
            "title": {
                "fragments": [],
                "text": "Document image understanding: geometric and logical layout"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs and restricts ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757030"
                        ],
                        "name": "Berrin A. Yanikoglu",
                        "slug": "Berrin-A.-Yanikoglu",
                        "structuredName": {
                            "firstName": "Berrin",
                            "lastName": "Yanikoglu",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berrin A. Yanikoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820595"
                        ],
                        "name": "L. Vincent",
                        "slug": "L.-Vincent",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16994816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23b63ccfe44badde2b162d26cd836839f2133a6f",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new approach for evaluating page segmentation algorithms. Unlike techniques that rely on OCR output, our method is region-based: the segmentation output, described as a set of regions together with their types, output order etc., is matched against the pre-stored set of ground-truth regions. Misclassifications, splitting, and merging of regions are among the errors that are detected by the system. Each error is weighted individually for a particular application and a global estimate of segmentation quality is derived. The system can be customized to benchmark specific aspects of segmentation (e.g., headline detection) and according to the type of error correction that might follow (e.g., re-typing). Segmentation ground-truth files are quickly and easily generated and edited using GroundsKeeper, an X-Window based tool that allows one to view a document, manually draw regions (arbitrary polygons) on it, and specify information about each region (e.g., type, parent)."
            },
            "slug": "Ground-truthing-and-benchmarking-document-page-Yanikoglu-Vincent",
            "title": {
                "fragments": [],
                "text": "Ground-truthing and benchmarking document page segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This work describes a new approach for evaluating page segmentation algorithms that is region-based: the segmentation output, described as a set of regions together with their types, output order etc., is matched against the pre-stored set of ground-truth regions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260288"
                        ],
                        "name": "L. Fletcher",
                        "slug": "L.-Fletcher",
                        "structuredName": {
                            "firstName": "Lloyd",
                            "lastName": "Fletcher",
                            "middleNames": [
                                "Alan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Fletcher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2685456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b08e547ba4edb60902d1708a5593d71f075aa7f1",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described. It is intended for use in an automated system for document analysis. The principal parts of the algorithm are the generation of connected components and the application of the Hough transform in order to group components into logical character strings that can then be separated from the graphics. The algorithm outputs two images, one containing text strings and the other graphics. These images can then be processed by suitable character recognition and graphics recognition systems. The performance of the algorithm, both in terms of its effectiveness and computational efficiency, was evaluated using several test images and showed superior performance compared to other techniques. >"
            },
            "slug": "A-Robust-Algorithm-for-Text-String-Separation-from-Fletcher-Kasturi",
            "title": {
                "fragments": [],
                "text": "A Robust Algorithm for Text String Separation from Mixed Text/Graphics Images"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described and showed superior performance compared to other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277321"
                        ],
                        "name": "K. Kise",
                        "slug": "K.-Kise",
                        "structuredName": {
                            "firstName": "Koichi",
                            "lastName": "Kise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kise"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064863306"
                        ],
                        "name": "A. Sato",
                        "slug": "A.-Sato",
                        "structuredName": {
                            "firstName": "Akinori",
                            "lastName": "Sato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40411993"
                        ],
                        "name": "M. Iwata",
                        "slug": "M.-Iwata",
                        "structuredName": {
                            "firstName": "Motoi",
                            "lastName": "Iwata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23399574,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "be80678c0eeedf754647a8b9adccd5d6d9be3e86",
            "isKey": false,
            "numCitedBy": 275,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method of page segmentation based on the approximated area Voronoi diagram. The characteristics of the proposed method are as follows: (1) The Voronoi diagram enables us to obtain the candidates of boundaries of document components from page images with non-Manhattan layout and a skew. (2) The candidates are utilized to estimate the intercharacter and interline gaps without the use of domain-specific parameters to select the boundaries. From the experimental results for 128 images with non-Manhattan layout and the skew of 0\u00b0~45\u00b0 as well as 98 images with Manhattan layout, we have confirmed that the method is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis."
            },
            "slug": "Segmentation-of-Page-Images-Using-the-Area-Voronoi-Kise-Sato",
            "title": {
                "fragments": [],
                "text": "Segmentation of Page Images Using the Area Voronoi Diagram"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is confirmed that the proposed method of page segmentation based on the approximated area Voronoi diagram is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32225756"
                        ],
                        "name": "R. Kashi",
                        "slug": "R.-Kashi",
                        "structuredName": {
                            "firstName": "Ramanujan",
                            "lastName": "Kashi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859740"
                        ],
                        "name": "G. Wilfong",
                        "slug": "G.-Wilfong",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Wilfong",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Wilfong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7630958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af42cc46f93bc9cf413770af4f7243f54a31336e",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. While techniques for evaluating the performance of lower-level document analysis tasks such as optical character recognition have gained acceptance in the literature, attempts to formalize the problem for higher-level algorithms, while receiving a fair amount of attention in terms of theory, have generally been less successful in practice, perhaps owing to their complexity. In this paper, we introduce intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition. We also present the results of several small experiments, demonstrating how well the methodologies work and the useful sorts of feedback they provide. We first consider the table detection problem. Here algorithms can yield various classes of errors, including non-table regions improperly labeled as tables (insertion errors), tables missed completely (deletion errors), larger tables broken into a number of smaller ones (splitting errors), and groups of smaller tables combined to form larger ones (merging errors). This leads naturally to the use of an edit distance approach for assessing the results of table detection. Next we address the problem of evaluating table structure recognition. Our model is based on a directed acyclic attribute graph, or table DAG. We describe a new paradigm, \u201cgraph probing,\u201d for comparing the results returned by the recognition system and the representation created during ground-truthing. Probing is in fact a general concept that could be applied to other document recognition tasks as well."
            },
            "slug": "Evaluating-the-performance-of-table-processing-Hu-Kashi",
            "title": {
                "fragments": [],
                "text": "Evaluating the performance of table processing algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An intuitive, easy-to-implement evaluation schemes for the related problems of table detection and table structure recognition are introduced and a new paradigm, \u201cgraph probing,\u201d is described for comparing the results returned by the recognition system and the representation created during ground-truthing."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3168116"
                        ],
                        "name": "Wen-jann Yang",
                        "slug": "Wen-jann-Yang",
                        "structuredName": {
                            "firstName": "Wen-jann",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-jann Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117208225"
                        ],
                        "name": "Venu Govindaraju",
                        "slug": "Venu-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Venu Govindaraju"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Srihari et al.40 proposed a information-theory-based method for automatic address interpretation in postal address elds of mail pieces."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "3% logical Ishitani(9) 1999 150 pages from N/S N/S object extraction no none various sources accuracy Srihari et al.(40) 1999 US postal address N/S N/S ZIP code, city name no none directory state, stree name Kim et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Srihari et al.(40) proposed a information-theory-based method for automatic address interpretation in postal address elds of mail pieces."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18695630,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b683bc4332a2940eb09e17def5ea8118725c1438",
            "isKey": true,
            "numCitedBy": 14,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper concerns a study of information content in postal address fields for automatic address interpretation. Information provided by a combination of address components and information interaction among components is characterized in terms of Shannon's entropy. The efficiency of assignment strategies for determining a delivery point code can be compared by the propagation of uncertainty in address components. The quantity of redundancy between components can be computed from the information provided by these components. This information is useful in developing a strategy for selecting a useful component for recovering the value of an uncertain component. The uncertainty of a component based on another known component can be measured by conditional entropy. By ranking the uncertainty quantity, the effective processing flow for determining the value of a candidate component can be constructed."
            },
            "slug": "Information-theoretic-analysis-of-postal-address-Srihari-Yang",
            "title": {
                "fragments": [],
                "text": "Information theoretic analysis of postal address fields for automatic address interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper concerns a study of information content in postal address fields for automatic address interpretation in terms of Shannon's entropy, which shows how the quantity of redundancy between components can be computed from the information provided by these components."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88581765"
                        ],
                        "name": "Jongwoo Kim",
                        "slug": "Jongwoo-Kim",
                        "structuredName": {
                            "firstName": "Jongwoo",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jongwoo Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1939973"
                        ],
                        "name": "D. Le",
                        "slug": "D.-Le",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Le",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145116486"
                        ],
                        "name": "G. Thoma",
                        "slug": "G.-Thoma",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Thoma",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Thoma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 49
                            }
                        ],
                        "text": "Other postal address analysis methods include.41\nKim et al.32 proposed a rule-based automated labeling module in MARS system (Medical Article Record System) to extract bibliographic records for the MEDLINE database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Kim et al.(32) proposed a rule-based automated labeling module in MARS system (Medical Article Record System) to extract bibliographic records for the MEDLINE database."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "1999 US postal address N/S N/S ZIP code, city name no none directory state, stree name Kim et al.(32) 2001 over 11,000 pages from labeling N/S 96."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 352,
                                "start": 348
                            }
                        ],
                        "text": "1997 OCR and rule document style logical labels not headline, content, book based parameters mentioned gure, table, page number, pages head-foot Ishitani(9) 1999 emergent computation, document style logical labels not headline, header, footer various rule based parameters mentioned note, caption, program, documents formula, title, list Kim et al.(32) 2001 OCR and rule zones logical labels database tables title, author biomedical journals based a\u00c6liation, abstract"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42416133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92bf165b5e8fed0ed530bb9c75e4dc5a0010b28f",
            "isKey": true,
            "numCitedBy": 45,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The National Library of Medicine (NLM) is developing an automated system to produce bibliographic records for its MEDLINER database. This system, named Medical Article Record System (MARS), employs document image analysis and understanding techniques and optical character recognition (OCR). This paper describes a key module in MARS called the Automated Labeling (AL) module, which labels all zones of interest (title, author, affiliation, and abstract) automatically. The AL algorithm is based on 120 rules that are derived from an analysis of journal page layouts and features extracted from OCR output. Experiments carried out on more than 11,000 articles in over 1,000 biomedical journals show the accuracy of this rule-based algorithm to exceed 96%."
            },
            "slug": "Automated-labeling-in-document-images-Kim-Le",
            "title": {
                "fragments": [],
                "text": "Automated labeling in document images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Automated Labeling (AL) module, which labels all zones of interest (title, author, affiliation, and abstract) automatically, is described, which is based on 120 rules that are derived from an analysis of journal page layouts and features extracted from OCR output."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107761635"
                        ],
                        "name": "S. Jones",
                        "slug": "S.-Jones",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Jones",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798254"
                        ],
                        "name": "S. Fortune",
                        "slug": "S.-Fortune",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Fortune",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fortune"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 95
                            }
                        ],
                        "text": "The X Y -cut-based algorithm of Nagy et al.17 and the shape-directed-covers-based algorithm of Baird et al.18 are top-down algorithms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "and the shape-directed-covers-based algorithm of Baird et al.(18) are top-down algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62735730,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbe0be8a26a0e9d8889f7f09ded38000faa357ba",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A technique for image segmentation using shape-directed covers is described and applied to the fully automatic analysis of complex printed-page layouts. The structure of the background (white space) is analyzed, assisted by an enumeration of all maximal white rectangles. For this enumeration, the most computationally expensive step, an algorithm has been developed that, aside from a sort, achieves an expected runtime linear in the number of black connected components. The crucial engineering decision is the specification of a partial order on white rectangles to express domain-specific knowledge of preferred shapes and sizes. This order determines a sequence of partial covers of the background, and thus, a sequence of nested page segmentations. In experimental trials on Manhattan layouts, good segmentations often occur early in this sequence, using a simple and uniform shape-direction rule. This is a global-to-local strategy, which for some tasks is superior to strategies currently emphasized in the literature, including bottom-up and top-down.<<ETX>>"
            },
            "slug": "Image-segmentation-by-shape-directed-covers-Baird-Jones",
            "title": {
                "fragments": [],
                "text": "Image segmentation by shape-directed covers"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A technique for image segmentation using shape-directed covers is described and applied to the fully automatic analysis of complex printed-page layouts, which for some tasks is superior to strategies currently emphasized in the literature, including bottom-up and top-down."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings. 10th International Conference on Pattern Recognition"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074272618"
                        ],
                        "name": "Taku A. Tokuyasu",
                        "slug": "Taku-A.-Tokuyasu",
                        "structuredName": {
                            "firstName": "Taku",
                            "lastName": "Tokuyasu",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taku A. Tokuyasu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720816"
                        ],
                        "name": "P. Chou",
                        "slug": "P.-Chou",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Chou",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Chou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17046681,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0b2eaec514b394dc9da50c060f521bf120246c5",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Turbo recognition (TR) is a communication theory approach to the analysis of rectangular layouts, in the spirit of Document Image Decoding. The TR algorithm, inspired by turbo decoding, is based on a generative model of image production, in which two grammars are used simultaneously to describe structure in orthogonal (horizontal and vertical directions. This enables TR to strictly embody non-local constraints that cannot be taken into account by local statistical methods. This basis in finite state grammars also allows TR to be quickly retargetable to new domains. We illustrate some of the capabilities of TR with two examples involving realistic images. While TR, like turbo decoding, is not guaranteed to recover the statistically optimal solution, we present an experiment that demonstrates its ability to produce optimal or near-optimal results on a simple yet nontrivial example, the recovery of a filled rectangle in the midst of noise. Unlike methods such as stochastic context free grammars and exhaustive search, which are often intractable beyond small images, turbo recognition scales linearly with image size, suggesting TR as an efficient yet near-optimal approach to statistical layout analysis."
            },
            "slug": "Turbo-recognition:-a-statistical-approach-to-layout-Tokuyasu-Chou",
            "title": {
                "fragments": [],
                "text": "Turbo recognition: a statistical approach to layout analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An experiment is presented that demonstrates TR's ability to produce optimal or near-optimal results on a simple yet nontrivial example, the recovery of a filled rectangle in the midst of noise."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695526"
                        ],
                        "name": "S. Mao",
                        "slug": "S.-Mao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "A rigorous empirical comparison of ve document physical layout analysis using the PSET software package(22) can be found in Mao and Kanungo.(23) Liang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 122
                            }
                        ],
                        "text": "A rigorous empirical comparison of ve document physical layout analysis using the PSET software package22 can be found in Mao and Kanungo.23 Liang et al.24 propose a performance metric for evaluating document structure extraction algorithms."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5453548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82328a31d7366c4ecfd339deeae41c3152b43c98",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "While numerous page segmentation algorithms have been proposed in the literature, there is lack of comparative evaluation of these algorithms. In the existing performance evaluation methods, two crucial components are usually missing: 1) automatic training of algorithms with free parameters and 2) statistical and error analysis of experimental results. We use the following five-step methodology to quantitatively compare the performance of page segmentation algorithms: 1) first, we create mutually exclusive training and test data sets with groundtruth, 2) we then select a meaningful and computable performance metric, 3) an optimization procedure is then used to search automatically for the optimal parameter values of the segmentation algorithms on the training data set, 4) the segmentation algorithms are then evaluated on the test data set, and, finally, 5) a statistical and error analysis is performed to give the statistical significance of the experimental results. In particular, instead of the ad hoc and manual approach typically used in the literature for training algorithms, we pose the automatic training of algorithms as an optimization problem and use the simplex algorithm to search for the optimal parameter value. A paired-model statistical analysis and an error analysis are then conducted to provide confidence intervals for the experimental results of the algorithms. This methodology is applied to the evaluation of live page segmentation algorithms of which, three are representative research algorithms and the other two are well-known commercial products, on 978 images from the University of Washington III data set. It is found that the performance indices of the Voronoi, Docstrum, and Caere segmentation algorithms are not significantly different from each other, but they are significantly better than that of ScanSoft's segmentation algorithm, which, in turn, is significantly better than that of X-Y cut."
            },
            "slug": "Empirical-Performance-Evaluation-Methodology-and-to-Mao-Kanungo",
            "title": {
                "fragments": [],
                "text": "Empirical Performance Evaluation Methodology and Its Application to Page Segmentation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The performance indices of the Voronoi, Docstrum, and Caere segmentation algorithms are not significantly different from each other, but they are significantly better than that of ScanSoft's segmentation algorithm, which, in turn, is significantly betterthan that of X-Y cut."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39475266"
                        ],
                        "name": "Huanfeng Ma",
                        "slug": "Huanfeng-Ma",
                        "structuredName": {
                            "firstName": "Huanfeng",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huanfeng Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403841205"
                        ],
                        "name": "Burcu Karagol-Ayan",
                        "slug": "Burcu-Karagol-Ayan",
                        "structuredName": {
                            "firstName": "Burcu",
                            "lastName": "Karagol-Ayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Burcu Karagol-Ayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737250"
                        ],
                        "name": "D. Oard",
                        "slug": "D.-Oard",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Oard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Oard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 160
                            }
                        ],
                        "text": "Physical layout and logical structure analysis algorithms based on stochastic language models\n204 Proc. of SPIE Vol. 5010\nhave been recently proposed in.45, 46 Doermann et al.47 proposed a method for lexicon acquisition from bilingual dictionaries based on learning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "46 Doermann et al.(47) proposed a method for lexicon acquisition from bilingual dictionaries based on learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27901485,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "272c8e0ef2300b799e482c458fd9b1597f7508e6",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Bilingual dictionaries hold great potential as a source of lexical resources for training automated systems for optical character recognition, machine translation and cross-language information retrieval. In this work we describe a system for extracting term lexicons from printed copies of bilingual dictionaries. We describe our approach to page and definition segmentation and entry parsing. We have used the approach to parse a number of dictionaries and demonstrate the results for retrieval using a French-English Dictionary to generate a translation lexicon and a corpus of English queries applied to French documents to evaluation cross-language IR."
            },
            "slug": "Translation-lexicon-acquisition-from-bilingual-Doermann-Ma",
            "title": {
                "fragments": [],
                "text": "Translation lexicon acquisition from bilingual dictionaries"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work describes a system for extracting term lexicons from printed copies of bilingual dictionaries and uses the approach to page and definition segmentation and entry parsing to parse a number of dictionaries."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695526"
                        ],
                        "name": "S. Mao",
                        "slug": "S.-Mao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11802672,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "596b676da30480e158a33d669132a206bbb179c1",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Electronic bilingual lexicons are crucial for machine translation, cross-lingual information retrieval and speech recognition. For low-density languages, however, the availability of electronic bilingual lexicons is questionable. One solution is to acquire electronic lexicons from printed bilingual dictionaries. While manual data entry is a possibility, automatic acquisition of lexicons from scanned images of bilingual dictionaries would expedite the prototyping process of cross-language systems. Printed dictionaries have a logical model that defines the syntax of the dictionary entries \u2013 i.e. order of the dictionary entry, its part of speech, its pronunciation and its definition. In this article we propose an algorithm to automatically extract bilingual dictionary entries based on stochastic language models. We demonstrate this algorithm on a printed Chinese-English dictionary. This work can be easily used for extracting information from other tabular structures like telephone books, catalogs, etc."
            },
            "slug": "Stochastic-Language-Models-for-Automatic-of-from-Mao-Kanungo",
            "title": {
                "fragments": [],
                "text": "Stochastic Language Models for Automatic Acquisition of Lexicons from Printed Bilingual Dictionaries"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This article proposes an algorithm to automatically extract bilingual dictionary entries based on stochastic language models and demonstrates this algorithm on a printed Chinese-English dictionary."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3333419"
                        ],
                        "name": "G. Kopec",
                        "slug": "G.-Kopec",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Kopec",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kopec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720816"
                        ],
                        "name": "P. Chou",
                        "slug": "P.-Chou",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Chou",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Chou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17899690,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "944db1fc7f65d13a77cf9c70679ee2ff4ef5fba8",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe a communication theory approach to document image reconstruction, patterned after the use of hidden Markov models in speech recognition. A document recognition problem is viewed as consisting of three elements-an image generator, a noisy channel, and an image decoder. A document image generator is a Markov source which combines a message source with an imager. The message source produces a string of symbols which contains the information to be transmitted. The imager is modeled as a finite-state transducer, which converts the message into an ideal bitmap. The channel transforms the ideal image into a noisy observed image. The decoder estimates the message from the observed image by finding the a posteriori most probable path through the combined source and channel models using a Viterbi-like algorithm. Application of the proposed method to decoding telephone yellow pages is described.<<ETX>>"
            },
            "slug": "Document-image-decoding-using-Markov-source-models-Kopec-Chou",
            "title": {
                "fragments": [],
                "text": "Document Image Decoding Using Markov Source Models"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A communication theory approach to document image reconstruction, patterned after the use of hidden Markov models in speech recognition, is described, and application of the proposed method to decoding telephone yellow pages is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 620082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce3b569e18670f6c10e61aa9a8bda7c30fd37411",
            "isKey": false,
            "numCitedBy": 554,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "The contributions to document image analysis of 99 papers published in the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) are clustered, summarized, interpolated, interpreted, and evaluated."
            },
            "slug": "Twenty-Years-of-Document-Image-Analysis-in-PAMI-Nagy",
            "title": {
                "fragments": [],
                "text": "Twenty Years of Document Image Analysis in PAMI"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The contributions to document image analysis of 99 papers published in the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) are clustered, summarized, interpolated, interpreted, and evaluated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688357"
                        ],
                        "name": "S. V. Rice",
                        "slug": "S.-V.-Rice",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Rice",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. V. Rice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15307178"
                        ],
                        "name": "F. Jenkins",
                        "slug": "F.-Jenkins",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Jenkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jenkins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688975"
                        ],
                        "name": "T. Nartker",
                        "slug": "T.-Nartker",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Nartker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nartker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17017303,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fae039cc89b2cd453acb85d208e021907528b062",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "For four years, ISRI has conducted an annual test of optical character recognition (OCR) systems known as \u201cpage readers.\u201d These systems accept as input a bitmapped image of any document page, and attempt to identify the machine-printed characters on the page. In the annual test, we measure the accuracy of this process by comparing the text that is produced as output with the correct text. The goals of the test include:"
            },
            "slug": "The-Fourth-Annual-Test-of-OCR-Accuracy-Rice-Jenkins",
            "title": {
                "fragments": [],
                "text": "The Fourth Annual Test of OCR Accuracy"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The annual test of optical character recognition systems known as \u201cpage readers\u201d accepts as input a bitmapped image of any document page, and attempts to identify the machine-printed characters on the page."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2499975"
                        ],
                        "name": "J. Kanai",
                        "slug": "J.-Kanai",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Kanai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kanai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688357"
                        ],
                        "name": "S. V. Rice",
                        "slug": "S.-V.-Rice",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Rice",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. V. Rice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688975"
                        ],
                        "name": "T. Nartker",
                        "slug": "T.-Nartker",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Nartker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nartker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30733052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bd99ebf0bbe9a8513350d9eae4f3570c99d559b",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Many current optical character recognition (OCR) systems attempt to decompose printed pages into a set of zones, each containing a single column of text, before converting the characters into coded form. The authors present a methodology for automatically assessing the accuracy of such decompositions, and demonstrate its use in evaluating six OCR systems. >"
            },
            "slug": "Automated-Evaluation-of-OCR-Zoning-Kanai-Rice",
            "title": {
                "fragments": [],
                "text": "Automated Evaluation of OCR Zoning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A methodology for automatically assessing the accuracy of optical character recognition decompositions is presented, and its use in evaluating six OCR systems is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10796472"
                        ],
                        "name": "James H. Martin",
                        "slug": "James-H.-Martin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martin",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James H. Martin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5073927,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "894149cb66e8af4a20c82840ea3f774888644fa6",
            "isKey": false,
            "numCitedBy": 3257,
            "numCiting": 356,
            "paperAbstract": {
                "fragments": [],
                "text": "is one of the most recognizablecharacters in 20th century cinema. HAL is an arti\ufb01cial agent capable of such advancedlanguage behavior as speaking and understanding English, and at a crucial moment inthe plot, even reading lips. It is now clear that HAL\u2019s creator, Arthur C. Clarke, wasa little optimistic in predicting when an arti\ufb01cial agent such as HAL would be avail-able. But just how far off was he? What would it take to create at least the language-relatedpartsofHAL?WecallprogramslikeHALthatconversewithhumansinnatural"
            },
            "slug": "Speech-and-Language-Processing-Jurafsky-Martin",
            "title": {
                "fragments": [],
                "text": "Speech and Language Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Kreich et al.5 used a generalized Hamming metric to compute a con dence measure for matches between a document physical layout and logical structure knowledge base and a document object."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "Kreich et al.(5) 1991 one page confidence measure N/S N/S no none"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "Kreich et al.(5) 1991 knowledge based analysis document style parameters logical labels not given sender, date, reference not mentioned Fisher(12) rule-based rules, tree rules, labeling MIF section heading, figure, figure caption, page heading, page footings not mentioned"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Kreich et al.5 described an experimental environment called SODA (System for O\u00c6ce Document Analysis) for model-based document analysis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "Kreich et al.(5) used a generalized Hamming metric to compute a confidence measure for matches between a document physical layout and logical structure knowledge base and a document object."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "Kreich et al.(5) described an experimental environment called SODA (System for Office Document Analysis) for model-based document analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An experimental environment for model based document analysis,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Document Analysis and Recognition,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 143
                            }
                        ],
                        "text": "1991 top-down layout model tree tree ODA title, author, patent and relaxation labeling a\u00c6liation, body applications column, block Kreich et al.(5) 1991 knowledge based document style logical labels not given sender, date, reference not analysis parameters mentioned Fisher(12) rule-based rules, tree rules, labeling MIF section heading, gure, not gure caption, page heading, mentioned page footings Derrien-Peden(34) 1991 frame and macrotree rules, labeling MML title, list, paragraph not typographical based abstract mentioned"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "Kreich 1991 one page con dence N/S N/S no none et al.(5) measure Fisher(12) 1991 one page N/S N/S N/S no none"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Kreich et al.5 used a generalized Hamming metric to compute a con dence measure for matches between a document physical layout and logical structure knowledge base and a document object."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "Kreich et al.(5) described an experimental environment called SODA (System for O\u00c6ce Document Analysis) for model-based document analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Kreich et al.5 described an experimental environment called SODA (System for O\u00c6ce Document Analysis) for model-based document analysis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "Kreich et al.(5) used a generalized Hamming metric to compute a con dence measure for matches between a document physical layout and logical structure knowledge base and a document object."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maderlechner, \\An experimental environment for model based document"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Document Analysis and Recognition,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 28
                            }
                        ],
                        "text": "202 Proc. of SPIE Vol. 5010\nYamashita et al.11 described a cost function based metric for selecting the result with the least cost."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Yamashita et al.11 proposed a model-based method for logical structure analysis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Yamashita et al.(11) proposed a model-based method for logical structure analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Yamashita et al.(11) 1991 top-down layout model and relaxation labeling tree tree ODA title, author, affiliation, body column, block patent applications"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Yamashita et al.(11) described a cost function based metric for selecting the result with the least cost."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Yamashita et al.(11) 1991 77 Japanese patent application front pages cost function N/S 59/77 accuracy yes none"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A model based layout understanding method for the document recognition system,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Document Analysis and Recognition,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 28
                            }
                        ],
                        "text": "202 Proc. of SPIE Vol. 5010\nYamashita et al.11 described a cost function based metric for selecting the result with the least cost."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 0
                            }
                        ],
                        "text": "Yamashita et al.11 proposed a model-based method for logical structure analysis."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Yamashita 1991 77 Japanese cost N/S 59/77 yes none et al.(11) patent application function accuracy front pages"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 227
                            }
                        ],
                        "text": "Tsujimoto 1990 mapping a physical block dominating tree not mentioned title, abstract, sub-title, various and Asada(10) tree to a logical one rules, tree paragraph, header, footer documents page number, caption Yamashita et al.(11) 1991 top-down layout model tree tree ODA title, author, patent and relaxation labeling a\u00c6liation, body applications column, block Kreich et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Yamashita et al.(11) proposed a model-based method for logical structure analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Yamashita et al.(11) described a cost function based metric for selecting the result with the least cost."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Toyokawa, \\A model based layout understanding method for the document recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Document Analysis and Recognition,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46391416,
            "fieldsOfStudy": [],
            "id": "d6ddc3eec5641b882c3918a94beb9e6d0701a24a",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Block segmentation and text extraction in mixed text/image documents"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Image Process."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6575783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c43505cc450b647f6f3b4a6f9004ae7d414e2bea",
            "isKey": false,
            "numCitedBy": 340,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Document-Image-Analysis-O'Gorman-Kasturi",
            "title": {
                "fragments": [],
                "text": "Document Image Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Frame-based system for macro-typographical structure analysis in scientific papers,"
            },
            "venue": {
                "fragments": [],
                "text": "in Pro\u00ad ceedings of International Conference on Document Analysis and Recognition,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Frame-based system for macro-typographical structure analysis in scienti c papers,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Document Analysis and Recognition,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic language model for style - directed physical layout analysis of document images"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing . To appear ."
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Armangil, \\A top-down document analysis method for logical structure recognition,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Document Analysis and Recognition,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A top-down document analysis method for logical structure recognition,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Document Analysis and Recognition,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Logical structure descriptions of segmented document images,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Document Analysis and Recognition,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic detection of address blocks on irregular mail pieces"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Con \u00ad ference on Computer Vision and Pattern Recognition"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic detection of address blocks on irregular mail pieces"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Con\u00ad ference on Computer Vision and Pattern Recognition"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document Layout Interpretation and its Applications"
            },
            "venue": {
                "fragments": [],
                "text": "Document Layout Interpretation and its Applications"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "Other postal address analysis methods include.(41)"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mulgaonkar, \\Automatic detection of address blocks on irregular mail pieces,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic language model for style-directed physical layout analysis of document images"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Style-directed document segmentation,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2001 Symposium on Document Image Understanding Technology,"
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 52,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Document-structure-analysis-algorithms:-a-survey-Mao-Rosenfeld/633fd1e2bd089c2c402244037876e879861d6739?sort=total-citations"
}