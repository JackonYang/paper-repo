{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34931109"
                        ],
                        "name": "R. Baddeley",
                        "slug": "R.-Baddeley",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Baddeley",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Baddeley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160279"
                        ],
                        "name": "P. Hancock",
                        "slug": "P.-Hancock",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hancock",
                            "middleNames": [
                                "J.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hancock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "We have investigated the PCs that result from anisotropic synthetic images: Brownian fractals and Gaussian ltered random noise [1]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "This nding is explored in more detail in a companion paper [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16109464,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4ba54bf31c417fb7241f47869e012a82b0b3d6ca",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural net method is used to extract principal components from real-world images. The initial components are a Gaussian followed by horizontal and vertical operators, starting with the first derivative and moving to successively higher orders. Two of the components are \u2018bar-detectors\u2019. Their measured orientation selectivity is similar to that suggested by Foster & Ward (Proc. R. Soc. Lond. B 243, 75 (1991)) to account for brief-exposure psychophysical data. In tests with noise images, the ratio of sensitivity between the two components is controlled by the degree of anisotropy in the image."
            },
            "slug": "A-statistical-analysis-of-natural-images-matches-Baddeley-Hancock",
            "title": {
                "fragments": [],
                "text": "A statistical analysis of natural images matches psychophysically derived orientation tuning curves"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A neural net method is used to extract principal components from real-world images and two of the components are \u2018bar-detectors\u2019, which are similar to that suggested by Foster & Ward to account for brief-exposure psychophysical data."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Royal Society of London. Series B: Biological Sciences"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577641"
                        ],
                        "name": "R. Linsker",
                        "slug": "R.-Linsker",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Linsker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Linsker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 8
                            }
                        ],
                        "text": "Linsker [6, 7] looked at the development of a multi-layer system given only random input."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1527671,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16d70e8af45ca0ae2c1bb73f3be6628518d40b8f",
            "isKey": false,
            "numCitedBy": 1417,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The emergence of a feature-analyzing function from the development rules of simple, multilayered networks is explored. It is shown that even a single developing cell of a layered network exhibits a remarkable set of optimization properties that are closely related to issues in statistics, theoretical physics, adaptive signal processing, the formation of knowledge representation in artificial intelligence, and information theory. The network studied is based on the visual system. These results are used to infer an information-theoretic principle that can be applied to the network as a whole, rather than a single cell. The organizing principle proposed is that the network connections develop in such a way as to maximize the amount of information that is preserved when signals are transformed at each processing stage, subject to certain constraints. The operation of this principle is illustrated for some simple cases.<<ETX>>"
            },
            "slug": "Self-organization-in-a-perceptual-network-Linsker",
            "title": {
                "fragments": [],
                "text": "Self-organization in a perceptual network"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "It is shown that even a single developing cell of a layered network exhibits a remarkable set of optimization properties that are closely related to issues in statistics, theoretical physics, adaptive signal processing, the formation of knowledge representation in artificial intelligence, and information theory."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2363971"
                        ],
                        "name": "J. Hertz",
                        "slug": "J.-Hertz",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hertz",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hertz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46486898"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50760571"
                        ],
                        "name": "R. Palmer",
                        "slug": "R.-Palmer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Palmer",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Palmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 23
                            }
                        ],
                        "text": "This rule can be shown [10, 5] to produce a weight vector corresponding to the eigenvector of the correlation matrix of all the inputs which has maximal eigenvalue; that is, it extracts the principal component of the input data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38623065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c0cbbd275bb43e09f0527a31ddd61824eca295b",
            "isKey": false,
            "numCitedBy": 6517,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis book is a comprehensive introduction to the neural network models currently under intensive study for computational applications. It is a detailed, logically-developed treatment that covers the theory and uses of collective computational networks, including associative memory, feed forward networks, and unsupervised learning. It also provides coverage of neural network applications in a variety of problems of both theoretical and practical interest."
            },
            "slug": "Introduction-to-the-theory-of-neural-computation-Hertz-Krogh",
            "title": {
                "fragments": [],
                "text": "Introduction to the theory of neural computation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book is a detailed, logically-developed treatment that covers the theory and uses of collective computational networks, including associative memory, feed forward networks, and unsupervised learning."
            },
            "venue": {
                "fragments": [],
                "text": "The advanced book program"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726997"
                        ],
                        "name": "E. Oja",
                        "slug": "E.-Oja",
                        "structuredName": {
                            "firstName": "Erkki",
                            "lastName": "Oja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Oja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 23
                            }
                        ],
                        "text": "This rule can be shown [10, 5] to produce a weight vector corresponding to the eigenvector of the correlation matrix of all the inputs which has maximal eigenvalue; that is, it extracts the principal component of the input data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "Sanger's net is a generalisation of a single-unit rule proposed by Oja [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "[10] E. Oja."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16577977,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3e00dd12caea7c4dab1633a35d1da3cb2e76b420",
            "isKey": false,
            "numCitedBy": 2357,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A simple linear neuron model with constrained Hebbian-type synaptic modification is analyzed and a new class of unconstrained learning rules is derived. It is shown that the model neuron tends to extract the principal component from a stationary input vector sequence."
            },
            "slug": "Simplified-neuron-model-as-a-principal-component-Oja",
            "title": {
                "fragments": [],
                "text": "Simplified neuron model as a principal component analyzer"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A simple linear neuron model with constrained Hebbian-type synaptic modification is analyzed and a new class of unconstrained learning rules is derived."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of mathematical biology"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29895535"
                        ],
                        "name": "D. Foster",
                        "slug": "D.-Foster",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Foster",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Foster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430694"
                        ],
                        "name": "P. Ward",
                        "slug": "P.-Ward",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Ward",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ward"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 196
                            }
                        ],
                        "text": "An unexpected result is that the orientation tuning curves of the two \\bar-detector\" components (four and six) give a good match to a model derived from psychophysical research by Foster and Ward [4]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "For the natural images, components resemble derivatives of Gaussian operators, similar to those found in visual cortex and inferred from psychophysics [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "[4] D.H. Foster and P.A. Ward."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 178
                            }
                        ],
                        "text": "An unexpected result is that theorientation tuning curves of the two \\bar-detector\" components (four and six) give a goodmatch to a model derived from psychophysical research by Foster and Ward [4]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 31826888,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d5322f24a705706e1fc164405248e5a9eff0c9f0",
            "isKey": true,
            "numCitedBy": 172,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual detection of a line target differing in orientation from a background of lines may be achieved speedily and effortlessly. Such performance is assumed to occur early in vision and to involve filter mechanisms acting in parallel over the visual field. This study establishes orientational limits on this performance and analytically derives some generic properties of the underlying filters. It was found that, in brief displays, target orientation detection thresholds increased approximately linearly with background orientation, from minima at 0\u00b0 (vertical) and 90\u00b0, whereas background orientation detection thresholds decreased approximately linearly with target orientation, from maxima at 0\u00b0 and 90\u00b0. Target and background threshold functions were exactly antisymmetric. These data are shown to indicate a model of early line processing dominated by two classes of orientation-sensitive filter with axes close to the vertical and horizontal and orientation-tuning half-widths each of approximately 30\u00b0 at half-height."
            },
            "slug": "Asymmetries-in-oriented-line-detection-indicate-two-Foster-Ward",
            "title": {
                "fragments": [],
                "text": "Asymmetries in oriented-line detection indicate two orthogonal filters in early vision"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Royal Society of London. Series B: Biological Sciences"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807117"
                        ],
                        "name": "T. Sanger",
                        "slug": "T.-Sanger",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Sanger",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sanger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 69
                            }
                        ],
                        "text": "Figure 1: The 15 natural images used in the experiment.2 Related workSanger has applied his algorithm to natural images [13], with the aim of doing data compres-sion."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 52
                            }
                        ],
                        "text": "We are using a neural network technique developed bySanger [13] that is able to nd a good approximation to the solutions within a few hours ona 1 MFlop workstation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 10
                            }
                        ],
                        "text": "[13] T.D. Sanger."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Sanger's net is a generalisation of a single-unit rule proposed by Oja [10]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Sanger [13] extended the algorithm to multiple output units in a way that extractsthe principal components in sequence. wij = yj(xi jXk=1 ykwik)The net thus consists of a small number of output units each receiving inputs from, in ourcase, all 4096 input units."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Sanger [13] extended the algorithm to multiple output units in a way that extracts the principal components in sequence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "2 Related work Sanger has applied his algorithm to natural images [13], with the aim of doing data compression."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "We are using a neural network technique developed by Sanger [13] that is able to nd a good approximation to the solutions within a few hours on a 1 MFlop workstation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10138295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "709b4bfc5198336ba5d70da987889a157f695c1e",
            "isKey": true,
            "numCitedBy": 1524,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-unsupervised-learning-in-a-single-layer-Sanger",
            "title": {
                "fragments": [],
                "text": "Optimal unsupervised learning in a single-layer linear feedforward neural network"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35311005"
                        ],
                        "name": "Professor Dr. Guy A. Orban",
                        "slug": "Professor-Dr.-Guy-A.-Orban",
                        "structuredName": {
                            "firstName": "Professor",
                            "lastName": "Orban",
                            "middleNames": [
                                "Dr.",
                                "Guy",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Professor Dr. Guy A. Orban"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22328025,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "0d203a310374d13e482288dc034186f7c1d0dfac",
            "isKey": false,
            "numCitedBy": 397,
            "numCiting": 257,
            "paperAbstract": {
                "fragments": [],
                "text": "1 The Visual System of Cat and Monkey Compared.- 1.1 The Basic Layout of the Visual System in Cat, Owl Monkey, and Rhesus Monkey.- 1.1.1 The Retina.- 1.1.2 The Optic Chiasm and Optic Tract.- 1.1.3 The Dorsal Lateral Geniculate Nucleus (dLGN).- 1.1.4 Visual Cortex.- 1.1.5 Pulvinar.- 1.1.6 Callosal Connections.- 1.2 Quantitative Aspects of the Retino-Geniculo-Cortical Projections.- 1.2.1 The Overall Numbers of Cells in the Visual Pathway.- 1.2.2 Distribution of Retinal Cell Populations.- 1.2.3 Magnification Factors.- 1.3 Conclusion.- 2 The Visual Cortical Areas of the Cat.- 2.1 Description of the Visual Cortical Areas.- 2.1.1 Area 17: The Prototype of Visual Cortical Areas.- 2.1.2 Areas 18 and 19.- 2.1.3 The Lateral Suprasylvian Areas.- 2.1.4 Areas 20 and 21.- 2.1.5 Additional Visual Areas?.- 2.2 The Levels of Processing in the Visual Cortical System of the Cat.- 2.3 Additional Observations on the Retinotopic Organization in the Primary Complex.- 2.3.1 Variability of the 3 Cortical Maps.- 2.3.2 RF Scatter.- 2.3.3 The 17-18 Border and the Question of the Naso-Temporal Overlap.- 2.3.4 The 18-19 Border and the Question of the Visual Field Islands.- 2.4 Conclusion.- 3 Afferent Projections to Areas 17, 18, 19 of the Cat: Evidence for Parallel Input.- 3.1 The Relay of Retinal Afferents: The Dorsal Lateral Geniculate Nuclear Complex.- 3.2 The Geniculocortical Projection.- 3.3 Functional Streams in the Retino-Geniculocortical Projection.- 3.3.1 Functional Properties of Retinal and Geniculate X, Y, W Cells.- 3.3.2 Correlation with Retinal Morphology.- 3.3.3 Separation of Functional Streams at LGN Level.- 3.3.4 Correlation with LGN Morphological Types.- 3.3.5 Distribution of Functional Streams in dLGN Nuclear Complex.- 3.3.6 Input to Different Areas of Primary Visual Complex.- 3.4 Physiological Identification of the Functional Type of Afferents to Areas 17, 18 and 19.- 3.5 The Termination of Geniculate Afferents in the Visual Cortex.- 3.6 Other Subcortical Afferents: Pulvinar-Lateralis Posterior Complex, Intralaminar Nuclei, Claustrum, and Brainstem.- 3.7 The Ipsilateral Corticocortical Connections.- 3.8 The Connections Through the Corpus Callosum.- 3.9 Conclusion.- 4 Receptive Field Organization in Areas 17, 18 and 19 of the Cat.- 4.1 Twenty Years with the Simple-Complex-Hypercomplex Scheme.- 4.2 Criteria for Classifying Cortical RFs.- 4.2.1 The ON-OFF Overlap or the Parcellation of the RF into Subregions.- 4.2.2 Position Test.- 4.2.3 RF Dimensions.- 4.2.4 End-Stopping or the Hypercomplex Property.- 4.3 The A, B, C, S Scheme.- 4.3.1 Properties and Distribution of Cell Types.- 4.3.2 The S and A Families.- 4.3.3 Responses to Other Stimuli.- 4.4 Correspondence of the A, B, C, S Scheme with Other Classification Schemes.- 4.5 Conclusion.- 5 Parameter Specificity of Visual Cortical Cells and Coding of Visual Parameters.- 5.1 The Tuned Cells as Bandpass Filters: The Multichannel Representation of a Parameter.- 5.2 Are All Tuned Cells Simple (Passive) Bandpass Filters or Are Some of Them Active Filters?.- 5.3 Cells with Thresholds as High-Pass Filters: Single or Multichannel Representation of a Parameter.- 5.4 Conclusion.- 6 Influence of Luminance and Contrast on Cat Visual Cortical Neurons.- 6.1 Contrast-Response Curves Obtained with Sinusoidal Gratings.- 6.2 Contrast-Response Curves Obtained with Slits.- 6.3 The Extreme Contrast Sensitivity at the 18-19 Border.- 6.4 Influence of Contrast and Luminance on Other Response Properties.- 6.5 Conclusion.- 7 Coding of Spatial Parameters by Cat Visual Cortical Neurons: Influence of Stimulus Orientation, Length, Width, and Spatial Frequency.- 7.1 Orientation Tuning of Cortical Cells.- 7.1.1 Definitions and Criteria.- 7.1.2 Quantitative Determinations: Orientation-Response Curves.- 7.1.3 Qualitative Determination: Hand-Plotting.- 7.1.4 Distribution of Preferred Orientations.- 7.1.5 Orientation Columns.- 7.1.6 Conclusion.- 7.2 Influence of Stimulus Length on Cortical Cells.- 7.3 Selectivity of Cortical Neurons for Spatial Frequency and Stimulus Width.- 7.3.1 Selectivity for Spatial Frequency.- 7.3.2 Spatial Frequency and Coding of Stimulus Dimensions.- 7.3.3 Linearity of Cortical Cells.- 7.3.4 The Visual Cortex as a Fourier Analyzer.- 7.3.5 Spatial Frequency: Conclusion.- 7.4 Spatial Parameters: Conclusion.- 8 Coding of Spatio-Temporal Parameters by Cat Visual Cortical Neurons: Influence of Stimulus Velocity Direction and Amplitude of Movement.- 8.1 Influence of Stimulus Velocity.- 8.2 Influence of the Direction of Movement.- 8.3 Influence of Stimulus Movement Amplitude.- 8.4 Conclusion.- 9 Binocular Interactions in Cat Visual Cortical Cells and Coding of Parameters Involved in Static and Dynamic Depth Perception.- 9.1 The Binocularity of Cortical Cells and the Ocular Dominance Scheme.- 9.2 Position Disparity Tuning Curves and the Coding of Static Depth.- 9.3 Orientation Disparity, Another Mechanism for Static Depth Discrimination?.- 9.4 Neuronal Mechanisms Underlying Dynamic Depth Perception (Motion in Depth).- 9.5 Conclusion.- 10 The Output of the Cat Visual Cortex.- 10.1 The Projections of Layer V to the Superior Colliculus, Pons, Pretectum, and Pulvinar-LP Complex.- 10.2 The Projections of Layer VI to the dLGN and the Claustrum.- 10.3 The Commissural Projections.- 10.4 The Associative Corticocortical Projections.- 10.5 Conclusion.- 11 Correlation Between Geniculate Afferents and Visual Cortical Response Properties in the Cat.- 11.1 Electrical Stimulation of the Visual Pathways.- 11.2 The Question of ON or OFF Cell Input to Cortical S Cells.- 11.3 Other Attempts to Identify the LGN Input to Cortical Cells.- 11.4 Conclusion.- 12 Intracortical Mechanisms Underlying Properties of Cat Visual Cortical Cells.- 12.1 The Role of Intracortical Inhibition.- 12.1.1 Orientation Selectivity.- 12.1.2 Direction Selectivity.- 12.1.3 End-Stopping.- 12.1.4 Ocular Dominance.- 12.1.5 Velocity Upper Cut-Off.- 12.1.6 Absence of Response to Two-Dimensional Noise.- 12.2 Properties of the Intracortical Inhibitions.- 12.3 The Structural Counterpart of Inhibitions.- 12.4 Conclusion.- 13 Non-Visual Influences on Cat Visual Cortex.- 13.1 Non-Visual Sensory Inputs to the Visual Cortex.- 13.2 Influence of Eye Movements on Visual Cortical Cells.- 13.3 The Influence of Sleep and Anesthesia.- 14 Response Properties of Monkey Striate Neurons.- 14.1 Retinotopic Organization of Area 17.- 14.2 The Input-Output Relations of Monkey Striate Cortex.- 14.3 Receptive Field Organization and Size.- 14.4 Color Specificity in Monkey Striate Cortex.- 14.5 Influence of Light Intensity and Contrast on Monkey Striate Neurons.- 14.6 Influence of Spatial Parameters.- 14.7 Influence of Spatio-Temporal Parameters.- 14.8 Ocular Dominance Distribution and Depth Sensitivity.- 14.9 Columnar Organization and Functional Architecture of Striate Cortex.- 14.10 Correlation Between Response Properties and Afferent Input.- 14.11 Conclusion.- 15 Conclusion: Signification of Visual Cortical Function in Perception.- 15.1 Operating Principles in Cat Visual Cortex.- 15.1.1 Retinotopic Organization.- 15.1.2 Filtering.- 15.1.3 \"Columnar\" Organization.- 15.1.4 Distributed Processing in the Primary Complex.- 15.1.5 Changes with Eccentricity.- 15.1.6 Parallel Streams Within each Area.- 15.2 The Cat and Monkey Visual Cortex as a Model: The Question of the Relationship Between Animal Physiology and Human Visual Perception.- 15.3 The Role of the Primary Visual Cortex in Visual Perception: The Significance of Parameter Specificities for Object Recognition.- References."
            },
            "slug": "Neuronal-Operations-in-the-Visual-Cortex-Orban",
            "title": {
                "fragments": [],
                "text": "Neuronal Operations in the Visual Cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The Visual System of Cat and Monkey Compared, a comparison of the Basic Layout of the Visual System in Cat, Owl Monkey, and Rhesus Monkey, reveals a similar structure to the Retinotopic Organization in the Primary Complex."
            },
            "venue": {
                "fragments": [],
                "text": "Studies of Brain Function"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758194"
                        ],
                        "name": "K. Miller",
                        "slug": "K.-Miller",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Miller",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 32
                            }
                        ],
                        "text": "Linsker's system has been shown [8, 9] to converge to the PCs of the input under some parameter regimes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122033076,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fe46ed12f8365aedc71e0da68f5395d826627a7",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Linsker has reported the development of structured receptive fields in simulations of a Hebb-type synaptic plasticity rule in a feedforward linear network. The synapses develop under dynamics determined by a matrix that is closely related to the covariance matrix of input cell activities. The authors analyse the dynamics of the learning rule in terms of the eigenvectors of this matrix. These eigenvectors represent independently evolving weight structures. Some general theorems are presented regarding the properties of these eigenvectors and their eigenvalues. For a general covariance matrix four principal parameter regimes are predicted.We concentrate on the Gaussian covariances at layer \u212c\u2192\ud835\udc9e of Linsker's network. Analytic and numerical solutions for the eigenvectors at this layer are presented. Three eigenvectors dominate the dynamics: a DC eigenvector, in which all synapses have the same sign; a bi-lobed, oriented eigenvector; and a circularly symmetric, centre-surround eigenvector. Analysis of the circu..."
            },
            "slug": "Analysis-of-Linsker's-application-of-Hebbian-rules-Mackay-Miller",
            "title": {
                "fragments": [],
                "text": "Analysis of Linsker's application of Hebbian rules to linear networks"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The authors analyse the dynamics of the learning rule of a Hebb-type synaptic plasticity rule in a feedforward linear network in terms of the eigenvectors of this matrix, which represent independently evolving weight structures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577641"
                        ],
                        "name": "R. Linsker",
                        "slug": "R.-Linsker",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Linsker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Linsker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 8
                            }
                        ],
                        "text": "Linsker [6, 7] looked at the development of a multi-layer system given only random input."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60683349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1094e087102df1686de0a21d7e2cc233d1821386",
            "isKey": false,
            "numCitedBy": 208,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "From-basic-network-principles-to-neural-Linsker",
            "title": {
                "fragments": [],
                "text": "From basic network principles to neural architecture"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Barrow [2] looked at the possibility of learning the receptive elds of primary visual cortex cells."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning receptive elds"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Neural  Networks, (San Diego 1987), IEEE, New York,"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 1,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 10,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/The-principal-components-of-natural-images-Hancock-Baddeley/7dcfa42cfe3b59becb441844b72558b361693608?sort=total-citations"
}