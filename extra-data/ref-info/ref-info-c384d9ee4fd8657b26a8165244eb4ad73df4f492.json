{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716902"
                        ],
                        "name": "Marti A. Hearst",
                        "slug": "Marti-A.-Hearst",
                        "structuredName": {
                            "firstName": "Marti",
                            "lastName": "Hearst",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marti A. Hearst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15763200,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "dbfd191afbbc8317577cbc44afe7156df546e143",
            "isKey": false,
            "numCitedBy": 3647,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for the automatic acquisition of the hyponymy lexical relation from unrestricted text. Two goals motivate the approach: (i) avoidance of the need for pre-encoded knowledge and (ii) applicability across a wide range of text. We identify a set of lexico-syntactic patterns that are easily recognizable, that occur frequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest. We describe a method for discovering these patterns and suggest that other lexical relations will also be acquirable in this way. A subset of the acquisition algorithm is implemented and the results are used to augment and critique the structure of a large hand-built thesaurus. Extensions and applications to areas such as information retrieval are suggested."
            },
            "slug": "Automatic-Acquisition-of-Hyponyms-from-Large-Text-Hearst",
            "title": {
                "fragments": [],
                "text": "Automatic Acquisition of Hyponyms from Large Text Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A set of lexico-syntactic patterns that are easily recognizable, that occur frequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest are identified."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3278929"
                        ],
                        "name": "Stephen D. Richardson",
                        "slug": "Stephen-D.-Richardson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Richardson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen D. Richardson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [21], Richardson extracted semantic relationships (e.g., hypernym, location, material and purpose) from dictionary definitions using a parser and constructed a semantic network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58411801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02e2589ef2c1541fd15a92bc3831a45e28db6fc9",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation describes the creation of a large-scale, richly structured lexical knowledge base (LKB) from complex structures of labeled semantic relations. These structures were automatically extracted using a natural language parser from the definitions and example sentences contained in two machine readable dictionaries. The structures were then completely inverted and propagated across all of the relevant headwords in the dictionaries to create the LKB. \nA method is described for efficiently accessing salient paths of semantic relations between words in the LKB using weights assigned to those paths. The weights are based on a unique computation called averaged vertex probability. Extended paths, created by joining sub-paths from two different semantic relation structures, are allowed in order to increase the coverage of the information in the LKB. \nA novel procedure is used to determine the similarity between words in the LKB based on the patterns of the semantic relation paths connecting those words. The patterns were obtained by extensive training using word pairs from an online thesaurus and a specially created anti-thesaurus. \nThe similarity procedure and the path accessing mechanism are used in a procedure to infer semantic relations that are not explicitly stored in the LKB. In particular, the utility of such inferences is discussed in the context of disambiguating phrasal attachments in a natural language understanding system. \nQuantitative results indicate that the size and coverage of the LKB created in this research and the effectiveness of the methods for accessing explicit and implicit information contained therein represent significant progress toward the development of a truly broad-coverage semantic component for natural language processing."
            },
            "slug": "Determining-similarity-and-inferring-relations-in-a-Richardson",
            "title": {
                "fragments": [],
                "text": "Determining similarity and inferring relations in a lexical knowledge base"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Quantitative results indicate that the size and coverage of the LKB created in this research and the effectiveness of the methods for accessing explicit and implicit information contained therein represent significant progress toward the development of a truly broad-coverage semantic component for natural language processing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763338"
                        ],
                        "name": "M. Rajman",
                        "slug": "M.-Rajman",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Rajman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rajman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740190"
                        ],
                        "name": "Romaric Besan\u00e7on",
                        "slug": "Romaric-Besan\u00e7on",
                        "structuredName": {
                            "firstName": "Romaric",
                            "lastName": "Besan\u00e7on",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Romaric Besan\u00e7on"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60960056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eba5bcf2676112eeff0d953754ffde515e69031b",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In the general framework of knowledge discovery, Data Mining techniques are usually dedicated to information extraction from structured databases. Text Mining techniques, on the other hand, are dedicated to information extraction from unstructured textual data and Natural Language Processing (NLP) can then be seen as an interesting tool for the enhancement of information extraction procedures. In this paper, we present two examples of Text Mining tasks, association extraction and prototypical document extraction, along with several related NLP techniques."
            },
            "slug": "Text-Mining:-Natural-Language-techniques-and-Text-Rajman-Besan\u00e7on",
            "title": {
                "fragments": [],
                "text": "Text Mining: Natural Language techniques and Text Mining applications"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents two examples of Text Mining tasks, association extraction and prototypical document extraction, along with several related NLP techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923461"
                        ],
                        "name": "Shian-Hua Lin",
                        "slug": "Shian-Hua-Lin",
                        "structuredName": {
                            "firstName": "Shian-Hua",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shian-Hua Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145667265"
                        ],
                        "name": "C. Shih",
                        "slug": "C.-Shih",
                        "structuredName": {
                            "firstName": "Chi-Sheng",
                            "lastName": "Shih",
                            "middleNames": [
                                "Daniel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Shih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125046394"
                        ],
                        "name": "M. Chen",
                        "slug": "M.-Chen",
                        "structuredName": {
                            "firstName": "Meng",
                            "lastName": "Chen",
                            "middleNames": [
                                "Chang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143608739"
                        ],
                        "name": "Jan-Ming Ho",
                        "slug": "Jan-Ming-Ho",
                        "structuredName": {
                            "firstName": "Jan-Ming",
                            "lastName": "Ho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan-Ming Ho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689992"
                        ],
                        "name": "M. Ko",
                        "slug": "M.-Ko",
                        "structuredName": {
                            "firstName": "Ming-Tat",
                            "lastName": "Ko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143515968"
                        ],
                        "name": "Yueh-Ming Huang",
                        "slug": "Yueh-Ming-Huang",
                        "structuredName": {
                            "firstName": "Yueh-Ming",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yueh-Ming Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "Many text mining algorithms aim at finding association rules between terms [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13341735,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "c9b9915851e89c4a54fe63eb85c6974c4c704576",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a system that extracts and generalizes terms from Internet documents to represent classification knowledge of a given class hierarchy. We propose a measurement to evaluate the importance of a term with respect to a class in the class hierarchy, and denote it as support. With a given threshold, terms with high supports are sifted as keywords of a class, and terms with low supports are filtered out. To further enhance the recall of this approach, Mining Association Rules technique is applied to mine the association between terms. An inference model is composed of these association relations and the previously computed supports of the terms in the class. To increase the recall rate of the keyword selection process. we then present a polynomialtime inference algorithm to promote a term, strongly associated to a known keyword, to a keyword. According to our experiment results on the collected Internet documents from Yam search engine, we show that the proposed methods In the paper contribute to refine the classification knowledge and increase the recall of keyword selection."
            },
            "slug": "Extracting-classification-knowledge-of-Internet-a-Lin-Shih",
            "title": {
                "fragments": [],
                "text": "Extracting classification knowledge of Internet documents with mining term associations: a semantic approach"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A system that extracts and generalizes terms from Internet documents to represent classification knowledge of a given class hierarchy and presents a polynomialtime inference algorithm to promote a term, strongly associated to a known keyword, to a keyword."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "Many algorithms have been proposed to mine textual data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6713452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5eb328cf7e94995199e4c82a1f4d0696430a80b5",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data."
            },
            "slug": "Distributional-Clustering-of-English-Words-Pereira-Tishby",
            "title": {
                "fragments": [],
                "text": "Distributional Clustering of English Words"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deterministic annealing is used to find lowest distortion sets of clusters: as the annealed parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145864794"
                        ],
                        "name": "Ronen Feldman",
                        "slug": "Ronen-Feldman",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Feldman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronen Feldman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716503"
                        ],
                        "name": "M. Fresko",
                        "slug": "M.-Fresko",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Fresko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fresko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097208827"
                        ],
                        "name": "Yakkov Kinar",
                        "slug": "Yakkov-Kinar",
                        "structuredName": {
                            "firstName": "Yakkov",
                            "lastName": "Kinar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yakkov Kinar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682750"
                        ],
                        "name": "Yehuda Lindell",
                        "slug": "Yehuda-Lindell",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Lindell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yehuda Lindell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346879"
                        ],
                        "name": "Orly Liphstat",
                        "slug": "Orly-Liphstat",
                        "structuredName": {
                            "firstName": "Orly",
                            "lastName": "Liphstat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Orly Liphstat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763338"
                        ],
                        "name": "M. Rajman",
                        "slug": "M.-Rajman",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Rajman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rajman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2012715"
                        ],
                        "name": "Jonathan Schler",
                        "slug": "Jonathan-Schler",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Schler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Schler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360279"
                        ],
                        "name": "Oren Zamir",
                        "slug": "Oren-Zamir",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Zamir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Zamir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "Some of them are considered to be uninterpretable even by humans [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14785458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "776111bab0b15da9067484a96f4b1f621c5d5364",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowledge Discovery in Databases (KDD) focuses on the computerized exploration of large amounts of data and on the discovery of interesting patterns within them. While most work on KDD has been concerned with structured databases, there has been little work on handling the huge amount of information that is available only in unstructured textual form. Previous work in text mining focused at the word or the tag level. This paper presents an approach to performing text mining at the term level. The mining process starts by preprocessing the document collection and extracting terms from the documents. Each document is then represented by a set of terms and annotations characterizing the document. Terms and additional higher-level entities are then organized in a hierarchical taxonomy. In this paper we will describe the Term Extraction module of the Document Explorer system, and provide experimental evaluation performed on a set of 52,000 documents published by Reuters in the years 1995\u20131996."
            },
            "slug": "Text-Mining-at-the-Term-Level-Feldman-Fresko",
            "title": {
                "fragments": [],
                "text": "Text Mining at the Term Level"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes the Term Extraction module of the Document Explorer system, and provides experimental evaluation performed on a set of 52,000 documents published by Reuters in the years 1995\u20131996."
            },
            "venue": {
                "fragments": [],
                "text": "PKDD"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145175167"
                        ],
                        "name": "J. Robin",
                        "slug": "J.-Robin",
                        "structuredName": {
                            "firstName": "Jacques",
                            "lastName": "Robin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Robin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "The generation community has focused mainly on rule-based text transformations in order to meet external constraints such as length and readability [11][18][22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19091184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b947f31028c542bbbc75f64773f5e8488977109",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatically summarizing vast amounts of on-line quantitative data with a short natural language paragraph has a wide range of real-world applications. However, this specific task raises a number of difficult issues that are quite distinct from the generic task of language generation: conciseness, complex sentences, floating concepts, historical background, paraphrasing power and implicit content. \nIn this thesis, I address these specific issues by proposing a new generation model in which a first pass builds a draft containing only the essential new facts to report and a second pass incrementally revises this draft to opportunistically add as many background facts as can fit within the space limit. This model requires a new type of linguistic knowledge: revision operations, which specifies the various ways a draft can be transformed in order to concisely accommodate a new piece of information. I present an in-depth corpus analysis of human-written sports summaries that resulted in an extensive set of such revision operations. I also present the implementation, based on functional unification grammars, of the system scSTREAK, which relies on these operations to incrementally generate complex sentences summarizing basketball games. This thesis also contains two quantitative evaluations. The first shows that the new revision-based generation model is far more robust than the one-pass model of previous generators. The second evaluation demonstrates that the revision operations acquired during the corpus analysis and implemented in scSTREAK are, for the most part, portable to at least one other quantitative domain (the stock market). \nscSTREAK is the first report generator that systematically places the facts which it summarizes in their historical perspective. It is more concise than previous systems thanks to its ability to generate more complex sentences and to opportunistically convey facts by adding a few words to carefully chosen draft constituents. The revision operations on which scSTREAK is based constitute the first set of corpus-based linguistic knowledge geared towards incremental generation. The evaluation presented in this thesis is also the first attempt to quantitatively assess the robustness of a new generation model and the portability of a new type of linguistic knowledge."
            },
            "slug": "Revision-based-generation-of-natural-language-and-Robin",
            "title": {
                "fragments": [],
                "text": "Revision-based generation of natural language summaries providing historical background: corpus-based analysis, design, implementation and evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This thesis presents a new generation model in which a first pass builds a draft containing only the essential new facts to report and a second pass incrementally revises this draft to opportunistically add as many background facts as can fit within the space limit."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35400286"
                        ],
                        "name": "Z. Harris",
                        "slug": "Z.-Harris",
                        "structuredName": {
                            "firstName": "Zellig",
                            "lastName": "Harris",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 101
                            }
                        ],
                        "text": "Most algorithms for computing word similarity from text corpus are based on a principle known as the Distributional Hypothesis [7]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 24
                            }
                        ],
                        "text": "Instead of applying the Distributional Hypothesis to words, we apply it to paths in dependency trees."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 48
                            }
                        ],
                        "text": "Our experimental results show that the Extended Distributional Hypothesis can indeed be used to discover very useful inference\nrules, many of which, though easily recognizable, are difficult for humans to recall."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 27
                            }
                        ],
                        "text": "We introduced the Extended Distributional Hypothesis, which states that paths in dependency trees have similar meanings if they tend to connect similar sets of words."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 55
                            }
                        ],
                        "text": "We make an assumption that this is an extension to the Distributional Hypothesis:\nExtended Distributional Hypothesis:\nIf two paths tend to occur in similar contexts, the meanings of the paths tend to be similar."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "1 Underlying Assumption Most algorithms for computing word similarity from text corpus are based on a principle known as the Distributional Hypothesis [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 16
                            }
                        ],
                        "text": "By the Extended Distributional Hypothesis, we can then claim that the two paths have similar meaning."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 164
                            }
                        ],
                        "text": "Algorithms for finding similar words assume the Distributional Hypothesis, which states that words that occurred in the same contexts tend to have similar meanings [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 50
                            }
                        ],
                        "text": "To compute the path similarity using the Extended Distributional Hypothesis, we need to collect the frequency counts of all paths in a corpus and the slot fillers for the paths."
                    },
                    "intents": []
                }
            ],
            "corpusId": 86680084,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "decd9bc0385612bdf936928206d83730718e737e",
            "isKey": true,
            "numCitedBy": 2644,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "For the purposes of the present discussion, the term structure will be used in the following non-rigorous sense: A set of phonemes or a set of data is structured in respect to some feature, to the extent that we can form in terms of that feature some organized system of statements which describes the members of the set and their interrelations (at least up to some limit of complexity). In this sense, language can be structured in respect to various independent features. And whether it is structured (to more than a trivial extent) in respect to, say, regular historical change, social intercourse, meaning, or distribution - or to what extent it is structured in any of these respects - is a matter decidable by investigation. Here we will discuss how each language can be described in terms of a distributional structure, i.e. in terms of the occurrence of parts (ultimately sounds) relative to other parts, and how this description is complete without intrusion of other features such as history or meaning. It goes without saying that other studies of language - historical, psychological, etc.-are also possible, both in relation to distributional structure and independently of it."
            },
            "slug": "Distributional-Structure-Harris",
            "title": {
                "fragments": [],
                "text": "Distributional Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This discussion will discuss how each language can be described in terms of a distributional structure, i.e. in Terms of the occurrence of parts relative to other parts, and how this description is complete without intrusion of other features such as history or meaning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723684"
                        ],
                        "name": "Peter G. Anick",
                        "slug": "Peter-G.-Anick",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Anick",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter G. Anick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2554782"
                        ],
                        "name": "S. Tipirneni",
                        "slug": "S.-Tipirneni",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Tipirneni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tipirneni"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "It has been shown that such query expansion does promote effective retrieval [1][2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6058816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "019ef56f6b2147d0fa05a19e2972e6cecc73d956",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new linguistic approach to the construction of terminological feedback for use in interactive query refinement. The method exploits the tendency for key domain concepts within result sets to participate in families of semantically related lexical compounds. We outline an algorithm for computing a ranked list of result set \u201cthemes\u201d and describe a web application, the Paraphrase Search Assistant, designed to make use of the theme extraction algorithm to support a recognition-based, iterative information seeking dialog."
            },
            "slug": "The-paraphrase-search-assistant:-terminological-for-Anick-Tipirneni",
            "title": {
                "fragments": [],
                "text": "The paraphrase search assistant: terminological feedback for iterative information seeking"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An algorithm for computing a ranked list of result set \u201cthemes\u201d and a web application designed to make use of the theme extraction algorithm to support a recognition-based, iterative information seeking dialog are described."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104341046"
                        ],
                        "name": "L. Dekang",
                        "slug": "L.-Dekang",
                        "structuredName": {
                            "firstName": "Lu",
                            "lastName": "Dekang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Dekang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "Some algorithms use the words that occurred in a fixed window of a given word as its context while others use the dependency relationships of a given word as its context [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 186
                            }
                        ],
                        "text": "3 Similarity between Two Paths Once the triple database is created, the similarity between two paths can be computed in the same way that the similarity between two words is computed in [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "Our algorithm is a generalization of previous algorithms for finding similar words [10][15][19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "The similarity measure proposed in [15] takes this into account by computing the mutual information between a feature and a path."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Following [15], the mutual information between a path slot and its filler can be computed by the formula:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14760279,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a432b8036514ab8d54ea9a5cc3771702522e6afb",
            "isKey": true,
            "numCitedBy": 180,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A collocation is a habitual word combination. Collocational knowledge is essential for many tasks in natural language processing. We present a method for extracting collocations from text corpora. By comparison with the SUSANNE corpus, we show that both high precision and broad coverage can be achieved with our method. Finally, we describe an application of the automatically extracted collocations for computing word similarities."
            },
            "slug": "Extracting-collocations-from-text-corpora-Dekang",
            "title": {
                "fragments": [],
                "text": "Extracting collocations from text corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A method for extracting collocations from text corpora with high precision and broad coverage is presented and an application of the automatically extracted collocations for computing word similarities is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3215185"
                        ],
                        "name": "G. Sampson",
                        "slug": "G.-Sampson",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Sampson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sampson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12621734,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "9cdbb0be2f0a9bdd9b69e044f0680affb373a507",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer processing of natural language is a burgeoning field, but until now there has been no agreement on a standardized classification of the diverse structural elements that occur in real-life language material. This book attempts to define a \"Linnaean taxonomy\" for the English language: an annotation scheme, the SUSANNE scheme, which yields a labelled constituency structure for any string of English, comprehensively identifying all of its surface and logical structural properties. The structure is specified with sufficient rigour that analysts working independently must produce identical annotations for a given example. The scheme is based on large sample of real-life use of British and American written and spoken English. The book also describes the SUSANNE electronic corpus of English which is annotated in accordance with the scheme. It is freely available as a research resource to anyone working at a computer conected to Internet, and since 1992 has come into widespread use in academic and commerical research environments on four continents."
            },
            "slug": "English-for-the-Computer:-The-SUSANNE-Corpus-and-Sampson",
            "title": {
                "fragments": [],
                "text": "English for the Computer: The SUSANNE Corpus and Analytic Scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This book attempts to define a \"Linnaean taxonomy\" for the English language: an annotation scheme, the SUSANNE scheme, which yields a labelled constituency structure for any string of English, comprehensively identifying all of its surface and logical structural properties."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145212976"
                        ],
                        "name": "C\u00e9cile Paris",
                        "slug": "C\u00e9cile-Paris",
                        "structuredName": {
                            "firstName": "C\u00e9cile",
                            "lastName": "Paris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C\u00e9cile Paris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69036062"
                        ],
                        "name": "W. Swartout",
                        "slug": "W.-Swartout",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Swartout",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Swartout"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847871"
                        ],
                        "name": "W. Mann",
                        "slug": "W.-Mann",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Mann",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Mann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "The generation community has focused mainly on rule-based text transformations in order to meet external constraints such as length and readability [11][18][22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13355900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "572cb39ec0eb6e61e29d4a9c109ab943df82ea2e",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the aims of Natural Language Processing is to facilitate .the use of computers by allowing their users to communicate in natural language. There are two important aspects to person-machine communication: understanding and generating. While natural language understanding has been a major focus of research, natural language generation is a relatively new and increasingly active field of research. This book presents an overview of the state of the art in natural language generation, describing both new results and directions for new research. The principal emphasis of natural language generation is not only to facili tate the use of computers but also to develop a computational theory of human language ability. In doing so, it is a tool for extending, clarifying and verifying theories that have been put forth in linguistics, psychology and sociology about how people communicate. A natural language generator will typically have access to a large body of knowledge from which to select information to present to users as well as numer of expressing it. Generating a text can thus be seen as a problem of ous ways decision-making under multiple constraints: constraints from the propositional knowledge at hand, from the linguistic tools available, from the communicative goals and intentions to be achieved, from the audience the text is aimed at and from the situation and past discourse. Researchers in generation try to identify the factors involved in this process and determine how best to represent the factors and their dependencies."
            },
            "slug": "Natural-Language-Generation-in-Artificial-and-Paris-Swartout",
            "title": {
                "fragments": [],
                "text": "Natural Language Generation in Artificial Intelligence and Computational Linguistics"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This book presents an overview of the state of the art in natural language generation, describing both new results and directions for new research."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21169546"
                        ],
                        "name": "Donald Hindle",
                        "slug": "Donald-Hindle",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hindle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Hindle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Many algorithms have been proposed to mine textual data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15862538,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "f3f3dcfcaa960ec201e0381f4d026e57e64bea76",
            "isKey": false,
            "numCitedBy": 689,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of determining the similarity of nouns on the basis of a metric derived from the distribution of subject, verb and object in a large text corpus is described. The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification."
            },
            "slug": "Noun-Classification-from-Predicate-Argument-Hindle",
            "title": {
                "fragments": [],
                "text": "Noun Classification from Predicate-Argument Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227843"
                        ],
                        "name": "M. Meteer",
                        "slug": "M.-Meteer",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Meteer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meteer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2729817"
                        ],
                        "name": "V. Shaked",
                        "slug": "V.-Shaked",
                        "structuredName": {
                            "firstName": "Varda",
                            "lastName": "Shaked",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Shaked"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "The generation community has focused mainly on rule-based text transformations in order to meet external constraints such as length and readability [11][18][22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5076418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16fcf74245d98ff681c336edbf6f2af5c18664a8",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new dimension to paraphrasing text in which characteristics of the original text motivate strategies for effective paraphrasing. Our system combines two existing robust components: the IRUS-II natural language understanding system and the SPOKESMAN generation system. We describe the architecture of the system and enhancements made to these components to facilitate paraphrasing. We particularly look at how levels of representation in these two systems are used by specialists in the paraphraser which define potential problems and paraphrasing strategies. Finally, we look at the role of paraphrasing in a cooperative dialog system. We will focus here on paraphrasing in the context of natural language interfaces and particularly on how multiple interpretations introduced by various kinds of ambiguity can be conbasted in paraphrases using both sentence structure and highlighting and formating the text itself."
            },
            "slug": "Strategies-for-Effective-Paraphrasing-Meteer-Shaked",
            "title": {
                "fragments": [],
                "text": "Strategies for Effective Paraphrasing"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new dimension to paraphrasing text in which characteristics of the original text motivate strategies for effective paraphrase is presented, which combines two existing robust components: the IRUS-II natural language understanding system and the SPOKESMAN generation system."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744669"
                        ],
                        "name": "U. Hahn",
                        "slug": "U.-Hahn",
                        "structuredName": {
                            "firstName": "Udo",
                            "lastName": "Hahn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Hahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2003934"
                        ],
                        "name": "Klemens Schnattinger",
                        "slug": "Klemens-Schnattinger",
                        "structuredName": {
                            "firstName": "Klemens",
                            "lastName": "Schnattinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klemens Schnattinger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1743489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4adef6d5951172dfce9d49e8672d960d11b6f8de",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a methodology for automating the maintenance of domain-specific taxonomies based on natural language text understanding. A given ontology is incrementally updated as new concepts are acquired from real-world texts. The acquisition process is centered around the linguistic and conceptual \"quality\" of various forms of evidence underlying the generation and refinement of concept hypotheses. On the basis of the quality of evidence, concept hypotheses are ranked according to credibility and the most credible ones are selected for assimilation into the domain knowledge base."
            },
            "slug": "Towards-Text-Knowledge-Engineering-Hahn-Schnattinger",
            "title": {
                "fragments": [],
                "text": "Towards Text Knowledge Engineering"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work introduces a methodology for automating the maintenance of domain-specific taxonomies based on natural language text understanding and ranks concept hypotheses according to credibility and the most credible ones are selected for assimilation into the domain knowledge base."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145216926"
                        ],
                        "name": "B. Larsen",
                        "slug": "B.-Larsen",
                        "structuredName": {
                            "firstName": "Bjornar",
                            "lastName": "Larsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Larsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939759"
                        ],
                        "name": "Chinatsu Aone",
                        "slug": "Chinatsu-Aone",
                        "structuredName": {
                            "firstName": "Chinatsu",
                            "lastName": "Aone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chinatsu Aone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207587242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc34c28ee40356b4d7bbe7be7d173a2436a89688",
            "isKey": false,
            "numCitedBy": 969,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Clustering is a powerful technique for large-scale topic discovery from text. It involves two phases: first, feature extraction maps each document or record to a point in high-dimensional space, then clustering algorithms automatically group the points into a hierarchy of clusters. We describe an unsupervised, near-linear time text clustering system that offers a number of algorithm choices for each phase. We introduce a methodology for measuring the quality of a cluster hierarchy in terms of FMeasure, and present the results of experiments comparing different algorithms. The evaluation considers some feature selection parameters (tfidfand feature vector length) but focuses on the clustering algorithms, namely techniques from Scatter/Gather (buckshot, fractionation, and split/join) and kmeans. Our experiments suggest that continuous center adjustment contributes more to cluster quality than seed selection does. It follows that using a simpler seed selection algorithm gives a better time/quality tradeoff. We describe a refinement to center adjustment, \u201cvector average damping,\u201d that further improves cluster quality. We also compare the near-linear time algorithms to a group average greedy agglomerative clustering algorithm to demonstrate the time/quality tradeoff quantitatively."
            },
            "slug": "Fast-and-effective-text-mining-using-linear-time-Larsen-Aone",
            "title": {
                "fragments": [],
                "text": "Fast and effective text mining using linear-time document clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An unsupervised, near-linear time text clustering system that offers a number of algorithm choices for each phase, and a refinement to center adjustment, \u201cvector average damping,\u201d that further improves cluster quality."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 169
                            }
                        ],
                        "text": "For example, Figure 1 shows the dependency tree for the sentence \u201cJohn found a solution to the problem\u201d, generated by a broadcoverage English parser called Minipar1 [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9541345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d431d03433275a68bd4ccd6b97af665bb979294d",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Overgeneration is the main source of computational complexity in previous principle-based parsers. This paper presents a message passing algorithm for principle-based parsing that avoids the overgeneration problem. This algorithm has been implemented in C++ and successfully tested with example sentences from (van Riemsdijk and Williams, 1986)."
            },
            "slug": "Principle-Based-Parsing-without-Overgeneration-Lin",
            "title": {
                "fragments": [],
                "text": "Principle-Based Parsing without Overgeneration"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A message passing algorithm for principle-based parsing that avoids the overgeneration problem is presented and has been implemented in C++ and successfully tested with example sentences from (van Riemsdijk and Williams, 1986)."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795294"
                        ],
                        "name": "M. Dras",
                        "slug": "M.-Dras",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "Dras [4] described syntactic Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14483333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aed8f80672e77b0d2470e2999d3d8caf1a364093",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In applications such as translation and paraphrase, operations are carried out on grammars at the meta level. This paper shows how a meta-grammar, defining structure at the meta level, is useful in the case of such operations; in particular, how it solves problems in the current definition of Synchronous TAG (Shieber, 1994) caused by ignoring such structure in mapping between grammars, for applications such as translation. Moreover, essential properties of the formalism remain unchanged."
            },
            "slug": "A-Meta-Level-Grammar:-Redefining-Synchronous-TAG-Dras",
            "title": {
                "fragments": [],
                "text": "A Meta-Level Grammar: Redefining Synchronous TAG for Translation and Paraphrase"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This paper shows how a meta-grammar, defining structure at the meta level, is useful in the case of such operations; in particular, how it solves problems in the current definition of Synchronous TAG caused by ignoring such structure in mapping between grammars."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1412391493"
                        ],
                        "name": "L. Ungar",
                        "slug": "L.-Ungar",
                        "structuredName": {
                            "firstName": "Lyle",
                            "lastName": "Ungar",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ungar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207699574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8856b09c032ed4f10ef8367a8f7088fbb891ec2b",
            "isKey": false,
            "numCitedBy": 1152,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "important problems involve clustering large datasets. Although naive implementations of clustering are computa- tionally expensive, there are established ecient techniques for clustering when the dataset has either (1) a limited num- ber of clusters, (2) a low feature dimensionality, or (3) a small number of data points. However, there has been much less work on methods of eciently clustering datasets that are large in all three ways at once|for example, having millions of data points that exist in many thousands of di- mensions representing many thousands of clusters. We present a new technique for clustering these large, high- dimensional datasets. The key idea involves using a cheap, approximate distance measure to eciently divide the data into overlapping subsets we call canopies .T hen cluster- ing is performed by measuring exact distances only between points that occur in a common canopy. Using canopies, large clustering problems that were formerly impossible become practical. Under reasonable assumptions about the cheap distance metric, this reduction in computational cost comes without any loss in clustering accuracy. Canopies can be applied to many domains and used with a variety of cluster- ing approaches, including Greedy Agglomerative Clustering, K-means and Expectation-Maximization. We present ex- perimental results on grouping bibliographic citations from the reference sections of research papers. Here the canopy approach reduces computation time over a traditional clus- tering approach by more than an order of magnitude and decreases error in comparison to a previously used algorithm by 25%."
            },
            "slug": "Efficient-clustering-of-high-dimensional-data-sets-McCallum-Nigam",
            "title": {
                "fragments": [],
                "text": "Efficient clustering of high-dimensional data sets with application to reference matching"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents a new technique for clustering large datasets, using a cheap, approximate distance measure to eciently divide the data into overlapping subsets the authors call canopies, and presents ex- perimental results on grouping bibliographic citations from the reference sections of research papers."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754680"
                        ],
                        "name": "Michael Elhadad",
                        "slug": "Michael-Elhadad",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Elhadad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Elhadad"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "Barzilay et al. [3] analyzed 200 two-sentence themes from a corpus and extracted seven lexico-syntactic paraphrasing rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7031344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f13d65762d257230438e4661fe9ba8962727521",
            "isKey": false,
            "numCitedBy": 470,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to automatically generate a concise summary by identifying and synthesizing similar elements across related text from a set of multiple documents. Our approach is unique in its usage of language generation to reformulate the wording of the summary."
            },
            "slug": "Information-Fusion-in-the-Context-of-Multi-Document-Barzilay-McKeown",
            "title": {
                "fragments": [],
                "text": "Information Fusion in the Context of Multi-Document Summarization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This approach is unique in its usage of language generation to reformulate the wording of the summary by identifying and synthesizing similar elements across related text from a set of multiple documents."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145848824"
                        ],
                        "name": "Karen Sp\u00e4rck Jones",
                        "slug": "Karen-Sp\u00e4rck-Jones",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Sp\u00e4rck Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Sp\u00e4rck Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144959176"
                        ],
                        "name": "J. Tait",
                        "slug": "J.-Tait",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tait"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "[24] Sparck Jones, K. and Tait, J. I. 1984."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "Morphological variant query expansion was treated by Sparck Jones and Tait [24] and Jacquemin [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33551203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af75c2df0281280792e1fd486d41ddf23dc8127e",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes research designed to improve automatic pre\u2010coordinate term indexing by applying powerful general\u2010purpose language analysis techniques to identify term sources in requests, and to generate variant expressions of the concepts involved for document text searching."
            },
            "slug": "Automatic-Search-Term-variant-Generation-Jones-Tait",
            "title": {
                "fragments": [],
                "text": "Automatic Search Term variant Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The paper describes research designed to improve automatic pre\u2010coordinate term indexing by applying powerful general\u2010purpose language analysis techniques to identify term sources in requests, and to generate variant expressions of the concepts involved for document text searching."
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2246473"
                        ],
                        "name": "D. G. Hays",
                        "slug": "D.-G.-Hays",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hays",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G. Hays"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "A dependency relationship [8] is an asymmetric binary relationship between a word called head, and another word called modifier."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 145050024,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "17cb4f318dc53b3c09dab637bd46897039d88046",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Dependency-Theory:-A-Formalism-and-Some-Hays",
            "title": {
                "fragments": [],
                "text": "Dependency Theory: A Formalism and Some Observations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": "Most of them focus on document clustering [13], identifying prototypical documents [20], or finding term associations [14] and hyponym relationships [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distributional Structure The Philosophy of Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "Distributional Structure The Philosophy of Linguistics"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 17
                            }
                        ],
                        "text": "Boston, MA.\n[12] Jacquemin, C., Klavans, J. L., and Tzoukermann, E. 1999."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "Morphological variant query expansion was treated by Sparck Jones and Tait [24] and Jacquemin [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NLP for Term Variant Extraction: A Synergy of Morphology, Lexicon, and Syntax"
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Information Retrieval, T. Strzalkowski"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "Many algorithms have been proposed to mine textual data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Extracting Collocations from Text Corpora. Workshop on Computational Terminology"
            },
            "venue": {
                "fragments": [],
                "text": "Extracting Collocations from Text Corpora. Workshop on Computational Terminology"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "The generation community has focused mainly on rule-based text transformations in order to meet external constraints such as length and readability [11][18][22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Natural Language Generation in Artificial Intelligence and Computational Linguistics. Kluwer"
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Generation in Artificial Intelligence and Computational Linguistics. Kluwer"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "It has been shown that such query expansion does promote effective retrieval [1][2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phrase-based infase-bas retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Information Processing & Management"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/DIRT-\u2013-Discovery-of-Inference-Rules-from-Text-Lin-Pantel/c384d9ee4fd8657b26a8165244eb4ad73df4f492?sort=total-citations"
}