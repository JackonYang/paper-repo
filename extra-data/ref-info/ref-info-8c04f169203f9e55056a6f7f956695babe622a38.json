{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 45
                            }
                        ],
                        "text": "The initial implementation of this approach (Lowe, 1999) simply located keypoints at the location and scale of the central sample point."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 28
                            }
                        ],
                        "text": "Earlier work by the author (Lowe, 1999) extended the local feature approach to achieve scale invariance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 93
                            }
                        ],
                        "text": "More details on applications of these features to recognition are available in other pape rs (Lowe, 1999; Lowe, 2001; Se, Lowe and Little, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 82
                            }
                        ],
                        "text": "To efficiently detect stable keypoint locations in scale space, we have proposed (Lowe, 1999) using scalespace extrema in the difference-of-Gaussian function convolved with the image, D(x, y, \u03c3 ), which can be computed from the difference of two nearby scales separated by a constant multiplicative\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 93
                            }
                        ],
                        "text": "More details on applications of these features to recognition are available in other papers (Lowe, 1999, 2001; Se et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 82
                            }
                        ],
                        "text": "To efficiently detect stable keypoint locations in scale spa ce, we have proposed (Lowe, 1999) using scale-space extrema in the difference-of-Gaussian f unction convolved with the image, D(x, y, \u03c3), which can be computed from the difference of two nearby scal e separated by a constant multiplicative factor k:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 44
                            }
                        ],
                        "text": "The initial implementation of this approach (Lowe, 1999) si mply located keypoints at the location and scale of the central sample point."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": false,
            "numCitedBy": 16255,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Mikolajczyk et al. (2003) have developed a new descriptor that uses local edges while ignoring unrelated nearby edges, providing the ability to find stable features even near the boundaries of narrow shapes superimposed on background clutter."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10816036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e80772f40e8ef924727c6c24168cadc3be0b856",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe an approach to recognizing poorly textured objects, that may contain holes and tubular parts, in cluttered scenes under arbitrary viewing conditions. To this end we develop a number of novel components. First, we introduce a new edge-based local feature detector that is invariant to similarity transformations. The features are localized on edges and a neighbourhood is estimated in a scale invariant manner. Second, the neighbourhood descriptor computed for foreground features is not affected by background clutter, even if the feature is on an object boundary. Third, the descriptor generalizes Lowe's SIFT method to edges. An object model is learnt from a single training image. The object is then recognized in new images in a series of steps which apply progressively tighter geometric restrictions. A final contribution of this work is to allow sufficient flexibility in the geometric representation that objects in the same visual class can be recognized. Results are demonstrated for various object classes including bikes and rackets."
            },
            "slug": "Shape-recognition-with-edge-based-features-Mikolajczyk-Zisserman",
            "title": {
                "fragments": [],
                "text": "Shape recognition with edge-based features"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "An approach to recognizing poorly textured objects, that may contain holes and tubular parts, in cluttered scenes under arbitrary viewing conditions is described and a new edge-based local feature detector that is invariant to similarity transformations is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 556474,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9188b661f2ae65a080676617cc83b7d09773c59f",
            "isKey": false,
            "numCitedBy": 588,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "There have been important recent advances in object recognition through the matching of invariant local image features. However, the existing approaches are based on matching to individual training images. This paper presents a method for combining multiple images of a 3D object into a single model representation. This provides for recognition of 3D objects from any viewpoint, the generalization of models to non-rigid changes, and improved robustness through the combination of features acquired under a range of imaging conditions. The decision of whether to cluster a training image into an existing view representation or to treat it as a new view is based on the geometric accuracy of the match to previous model views. A new probabilistic model is developed to reduce the false positive matches that would otherwise arise due to loosened geometric constraints on matching 3D and non-rigid models. A system has been developed based on these approaches that is able to robustly recognize 3D objects in cluttered natural images in sub-second times."
            },
            "slug": "Local-feature-view-clustering-for-3D-object-Lowe",
            "title": {
                "fragments": [],
                "text": "Local feature view clustering for 3D object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a method for combining multiple images of a 3D object into a single model representation that provides for recognition of 3D objects from any viewpoint, the generalization of models to non-rigid changes, and improved robustness through the combination of features acquired under a range of imaging conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144735785"
                        ],
                        "name": "Matthew A. Brown",
                        "slug": "Matthew-A.-Brown",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Brown",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew A. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Carneiro and Jepson (2002) describe phase-based local features that represent the phase rather than the magnitude of local spatial frequencies, which is likely to provide improved invariance to illumination."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2420060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45cb5262b1fb9f149e8f4171e0b1e52d748e062d",
            "isKey": false,
            "numCitedBy": 746,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper approaches the problem of \u00afnding correspondences between images in which there are large changes in viewpoint, scale and illumi- nation. Recent work has shown that scale-space `interest points' may be found with good repeatability in spite of such changes. Further- more, the high entropy of the surrounding image regions means that local descriptors are highly discriminative for matching. For descrip- tors at interest points to be robustly matched between images, they must be as far as possible invariant to the imaging process. In this work we introduce a family of features which use groups of interest points to form geometrically invariant descriptors of image regions. Feature descriptors are formed by resampling the image rel- ative to canonical frames de\u00afned by the points. In addition to robust matching, a key advantage of this approach is that each match implies a hypothesis of the local 2D (projective) transformation. This allows us to immediately reject most of the false matches using a Hough trans- form. We reject remaining outliers using RANSAC and the epipolar constraint. Results show that dense feature matching can be achieved in a few seconds of computation on 1GHz Pentium III machines."
            },
            "slug": "Invariant-Features-from-Interest-Point-Groups-Brown-Lowe",
            "title": {
                "fragments": [],
                "text": "Invariant Features from Interest Point Groups"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work introduces a family of features which use groups of interest points to form geometrically invariant descriptors of image regions to ensure robust matching between images in which there are large changes in viewpoint, scale and illumi- nation."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 102
                            }
                        ],
                        "text": "Therefore, we have used an approximate algorithm, called the Best-Bin-First (BBF) algorithm (Beis and Lowe, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15626261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67f693427d956c0dbc822e7f3452aee8ca36204b",
            "isKey": false,
            "numCitedBy": 767,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints. Unlike conventional stereo matching approaches we assume no prior knowledge about the relative camera positions and orientations. In fact in our application this is the information we wish to determine from the image feature matches. Features are detected in two or more images and characterised using affine texture invariants. The problem of window effects is explicitly addressed by our method-our feature characterisation is invariant to linear transformations of the image data including rotation, stretch and skew. The feature matching process is optimised for a structure-from-motion application where we wish to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "slug": "Reliable-feature-matching-across-widely-separated-Baumberg",
            "title": {
                "fragments": [],
                "text": "Reliable feature matching across widely separated views"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints that is optimised for a structure-from-motion application where it wishes to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 93161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1054962da302e12c743b7373b68e7679a32984b",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognition systems attempt to recover information about the identity of observed objects and their location in the environment. A fundamental problem in recognition is pose estimation. This is the problem of using a correspondence between some portions of an object model and some portions of an image to determine whether the image contains an instance of the object, and, in case it does, to determine the transformation that relates the model to the image. The current approaches to this problem are divided into methods that use \u201cglobal\u201d properties of the object (e.g., centroid and moments of inertia) and methods that use \u201clocal\u201d properties of the object (e.g., corners and line segments). Global properties are sensitive to occlusion and, specifically, to self occlusion. Local properties are difficult to locate reliably, and their matching involves intensive computation.We present a novel method for recognition that uses region information. In our approach the model and the image are divided into regions. Given a match between subsets of regions (without any explicit correspondence between different pieces of the regions) the alignment transformation is computed. The method applies to planar objects under similarity, affine, and projective transformations and to projections of 3-D objects undergoing affine and projective transformations. The new approach combines many of the advantages of the previous two approaches, while avoiding some of their pitfalls. Like the global methods, our approach makes use of region information that reflects the true shape of the object. But like local methods, our approach can handle occlusion."
            },
            "slug": "Recognition-Using-Region-Correspondences-Basri-Jacobs",
            "title": {
                "fragments": [],
                "text": "Recognition Using Region Correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The new approach combines many of the advantages of the previous two approaches, while avoiding some of their pitfalls, and makes use of region information that reflects the true shape of the object."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738392"
                        ],
                        "name": "Arthur R. Pope",
                        "slug": "Arthur-R.-Pope",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Pope",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arthur R. Pope"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Pope and Lowe (2000) used features based on the hierarchical grouping of image contours, which are particularly useful for objects lacking detailed texture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1439451,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d1e696747a5452364579bea583196ed8bc2b254",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe how to model the appearance of a 3-D object using multiple views, learn such a model from training images, and use the model for object recognition. The model uses probability distributions to describe the range of possible variation in the object's appearance. These distributions are organized on two levels. Large variations are handled by partitioning training images into clusters corresponding to distinctly different views of the object. Within each cluster, smaller variations are represented by distributions characterizing uncertainty in the presence, position, and measurements of various discrete features of appearance. Many types of features are used, ranging in abstraction from edge segments to perceptual groupings and regions. A matching procedure uses the feature uncertainty information to guide the search for a match between model and image. Hypothesized feature pairings are used to estimate a viewpoint transformation taking account of feature uncertainty. These methods have been implemented in an object recognition system, OLIVER. Experiments show that OLIVER is capable of learning to recognize complex objects in cluttered images, while acquiring models that represent those objects using relatively few views."
            },
            "slug": "Probabilistic-Models-of-Appearance-for-3-D-Object-Pope-Lowe",
            "title": {
                "fragments": [],
                "text": "Probabilistic Models of Appearance for 3-D Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This work describes how to model the appearance of a 3-D object using multiple views, learn such a model from training images, and use the model for object recognition, and demonstrates that OLIVER is capable of learning to recognize complex objects in cluttered images, while acquiring models that represent those objects using relatively few views."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 40
                            }
                        ],
                        "text": "The research of Weber et al. (2000) and Fergus et al. (2003) has shown the potential of this approach by learning small sets of local features that are suited to recognizing generic classes of objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": false,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700928"
                        ],
                        "name": "O. Chum",
                        "slug": "O.-Chum",
                        "structuredName": {
                            "firstName": "Ond\u0159ej",
                            "lastName": "Chum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067522034"
                        ],
                        "name": "Martin Urban",
                        "slug": "Martin-Urban",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Urban",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Urban"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758039"
                        ],
                        "name": "T. Pajdla",
                        "slug": "T.-Pajdla",
                        "structuredName": {
                            "firstName": "Tom\u00e1s",
                            "lastName": "Pajdla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pajdla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 55
                            }
                        ],
                        "text": "In what appears to be the most affineinvariant method, Mikolajczyk (2002) has proposed and run detailed experiments with the Harris-affine detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Matas et al. (2002) have shown that their maximally-stable extremal regions can produce large numbers of matching features with good stability."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2104851,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9d5ea177c7fcaf88ec6f56cbeb3e9b74c08e98a3",
            "isKey": false,
            "numCitedBy": 3922,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied. A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under 1. continuous (and thus projective) transformation of image coordinates and 2. monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely-invariant stable subset of extremal regions, the maximally stable extremal regions (MSER). A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences. The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5\u00d7), illumination conditions, out-of-plane rotation, occlusion , locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained."
            },
            "slug": "Robust-Wide-Baseline-Stereo-from-Maximally-Stable-Matas-Chum",
            "title": {
                "fragments": [],
                "text": "Robust Wide Baseline Stereo from Maximally Stable Extremal Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints, is studied and an efficient and practically fast detection algorithm is presented for an affinely-invariant stable subset of extremal regions, the maximally stable extremal region (MSER)."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145575177"
                        ],
                        "name": "G. Carneiro",
                        "slug": "G.-Carneiro",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Carneiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Carneiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 55
                            }
                        ],
                        "text": "Some of the first work in this area was by Crowley and Parker (1984), who developed a representation that identified peaks and ridges in scale space and linked these into a tree structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17771627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f691349c928b1d65546f243075d5e8995b82f958",
            "isKey": false,
            "numCitedBy": 113,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new type of local feature based on the phase and amplitude responses of complex-valued steerable filters. The design of this local feature is motivated by a desire to obtain feature vectors which are semi-invariant under common image deformations, yet distinctive enough to provide useful identity information. A recent proposal for such local features involves combining differential invariants to particular image deformations, such as rotation. Our approach differs in that we consider a wider class of image deformations, including the addition of noise, along with both global and local brightness variations. We use steerable filters to make the feature robust to rotation. And we exploit the fact that phase data is often locally stable with respect to scale changes, noise, and common brightness changes. We provide empirical results comparing our local feature with one based on differential invariants. The results show that our phase-based local feature leads to better performance when dealing with common illumination changes and 2-D rotation, while giving comparable effects in terms of scale changes."
            },
            "slug": "Phase-Based-Local-Features-Carneiro-Jepson",
            "title": {
                "fragments": [],
                "text": "Phase-Based Local Features"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The results show that the phase-based local feature leads to better performance when dealing with common illumination changes and 2-D rotation, while giving comparable effects in terms of scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687022"
                        ],
                        "name": "J. Crowley",
                        "slug": "J.-Crowley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crowley",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crowley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Schiele and Crowley (2000) have proposed the use of multidimensional histograms summarizing the distribution of measurements within image regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Schiele and Crowley (2000)  have proposed the use of multidimensional histograms summarizing the distribution of measurements within image regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2551159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd232cf2ab28cc0ba06942875f14206f04ebbae0",
            "isKey": false,
            "numCitedBy": 496,
            "numCiting": 109,
            "paperAbstract": {
                "fragments": [],
                "text": "The appearance of an object is composed of local structure. This local structure can be described and characterized by a vector of local features measured by local operators such as Gaussian derivatives or Gabor filters. This article presents a technique where appearances of objects are represented by the joint statistics of such local neighborhood operators. As such, this represents a new class of appearance based techniques for computer vision. Based on joint statistics, the paper develops techniques for the identification of multiple objects at arbitrary positions and orientations in a cluttered scene. Experiments show that these techniques can identify over 100 objects in the presence of major occlusions. Most remarkably, the techniques have low complexity and therefore run in real-time."
            },
            "slug": "Recognition-without-Correspondence-using-Receptive-Schiele-Crowley",
            "title": {
                "fragments": [],
                "text": "Recognition without Correspondence using Multidimensional Receptive Field Histograms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article presents a technique where appearances of objects are represented by the joint statistics of such local neighborhood operators, which represents a new class of appearance based techniques for computer vision."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 175
                            }
                        ],
                        "text": "Recently, there has been an impressive body of work on extending local features to be invariant to full affine transformations (Baumberg, 2000; Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8571961,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c7a96155f10f152cae0866102c061cdf6da02e8",
            "isKey": false,
            "numCitedBy": 1683,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images."
            },
            "slug": "An-Affine-Invariant-Interest-Point-Detector-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "An Affine Invariant Interest Point Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel approach for detecting affine invariant interest points that can deal with significant affine transformations including large scale changes and shows an excellent performance in the presence of large perspective transformations including significant scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51064498"
                        ],
                        "name": "Zhengyou Zhang",
                        "slug": "Zhengyou-Zhang",
                        "structuredName": {
                            "firstName": "Zhengyou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengyou Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702017"
                        ],
                        "name": "R. Deriche",
                        "slug": "R.-Deriche",
                        "structuredName": {
                            "firstName": "Rachid",
                            "lastName": "Deriche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Deriche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Zhang et al. (1995) showed that it was possible to match Harris corners over a large image range by using a correlation window around each corner to select likely matches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5858737,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3ec4ceea040b7b4129ee5d71b4f95539bf876b7",
            "isKey": false,
            "numCitedBy": 1625,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Robust-Technique-for-Matching-two-Uncalibrated-of-Zhang-Deriche",
            "title": {
                "fragments": [],
                "text": "A Robust Technique for Matching two Uncalibrated Images Through the Recovery of the Unknown Epipolar Geometry"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116168"
                        ],
                        "name": "J. Beis",
                        "slug": "J.-Beis",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Beis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": "Therefore, we have used an approximate algorithm, called the Best-Bin-First (BBF) algorithm (Beis and Lowe, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 270664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef05b72c9e5b267811d4a069fb1d8038f0e36bbd",
            "isKey": false,
            "numCitedBy": 1093,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Shape indexing is a way of making rapid associations between features detected in an image and object models that could have produced them. When model databases are large, the use of high-dimensional features is critical, due to the improved level of discrimination they can provide. Unfortunately, finding the nearest neighbour to a query point rapidly becomes inefficient as the dimensionality of the feature space increases. Past indexing methods have used hash tables for hypothesis recovery, but only in low-dimensional situations. In this paper we show that a new variant of the k-d tree search algorithm makes indexing in higher-dimensional spaces practical. This Best Bin First, or BBF search is an approximate algorithm which finds the nearest neighbour for a large fraction of the queries, and a very close neighbour in the remaining cases. The technique has been integrated into a fully developed recognition system, which is able to detect complex objects in real, cluttered scenes in just a few seconds."
            },
            "slug": "Shape-indexing-using-approximate-nearest-neighbour-Beis-Lowe",
            "title": {
                "fragments": [],
                "text": "Shape indexing using approximate nearest-neighbour search in high-dimensional spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper shows that a new variant of the k-d tree search algorithm makes indexing in higher-dimensional spaces practical, and is integrated into a fully developed recognition system, which is able to detect complex objects in real, cluttered scenes in just a few seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687022"
                        ],
                        "name": "J. Crowley",
                        "slug": "J.-Crowley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crowley",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780629"
                        ],
                        "name": "A. Parker",
                        "slug": "A.-Parker",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Parker",
                            "middleNames": [
                                "Cline"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Parker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 43
                            }
                        ],
                        "text": "Some of the first work in this area was by Crowley and Parker (1984), who developed a representation that identified peaks and ridges in scale space and linked these into a tree structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14348919,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "252347ef2f962dde7f4c6c0467014e18bdc2cd4f",
            "isKey": false,
            "numCitedBy": 349,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper defines a multiple resolution representation for the two-dimensional gray-scale shapes in an image. This representation is constructed by detecting peaks and ridges in the difference of lowpass (DOLP) transform. Descriptions of shapes which are encoded in this representation may be matched efficiently despite changes in size, orientation, or position. Motivations for a multiple resolution representation are presented first, followed by the definition of the DOLP transform. Techniques are then presented for encoding a symbolic structural description of forms from the DOLP transform. This process involves detecting local peaks and ridges in each bandpass image and in the entire three-dimensional space defined by the DOLP transform. Linking adjacent peaks in different bandpass images gives a multiple resolution tree which describes shape. Peaks which are local maxima in this tree provide landmarks for aligning, manipulating, and matching shapes. Detecting and linking the ridges in each DOLP bandpass image provides a graph which links peaks within a shape in a bandpass image and describes the positions of the boundaries of the shape at multiple resolutions. Detecting and linking the ridges in the DOLP three-space describes elongated forms and links the largest peaks in the tree. The principles for determining the correspondence between symbols in pairs of such descriptions are then described. Such correspondence matching is shown to be simplified by using the correspondence at lower resolutions to constrain the possible correspondence at higher resolutions."
            },
            "slug": "A-Representation-for-Shape-Based-on-Peaks-and-in-of-Crowley-Parker",
            "title": {
                "fragments": [],
                "text": "A Representation for Shape Based on Peaks and Ridges in the Difference of Low-Pass Transform"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A multiple resolution representation for the two-dimensional gray-scale shapes in an image is defined by detecting peaks and ridges in the difference of lowpass (DOLP) transform and the principles for determining the correspondence between symbols in pairs of such descriptions are described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110604335"
                        ],
                        "name": "Markus Weber",
                        "slug": "Markus-Weber",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8970876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cf1527807ebb16020b04d4166e7ba8d27652302",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features). The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. The method achieves very good classification results on human faces and rear views of cars."
            },
            "slug": "Unsupervised-Learning-of-Models-for-Recognition-Weber-Welling",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Models for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method to learn object class models from unlabeled and unsegmented cluttered cluttered scenes for the purpose of visual object recognition that achieves very good classification results on human faces and rear views of cars."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40309692"
                        ],
                        "name": "C. G. Harris",
                        "slug": "C.-G.-Harris",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40365651"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stephens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1694378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6818668fb895d95861a2eb9673ddc3a41e27b3b3",
            "isKey": false,
            "numCitedBy": 14111,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed."
            },
            "slug": "A-Combined-Corner-and-Edge-Detector-Harris-Stephens",
            "title": {
                "fragments": [],
                "text": "A Combined Corner and Edge Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem the authors are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work."
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31614700"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randal",
                            "lastName": "Nelson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715388"
                        ],
                        "name": "A. Selinger",
                        "slug": "A.-Selinger",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Selinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Selinger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 16403521,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50b77b2bc08199fe04150929d4df3d66727f96e8",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Large-scale-tests-of-a-keyed,-appearance-based-3-D-Nelson-Selinger",
            "title": {
                "fragments": [],
                "text": "Large-scale tests of a keyed, appearance-based 3-D object recognition system"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 114
                            }
                        ],
                        "text": "The problem of identifying an appropriate and consistent scale for feature detection has been studied in depth by Lindeberg (1993, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 92
                            }
                        ],
                        "text": "The initial image is incrementally convolved with Gaussians to produce images separated by a constant factor k in scale space, shown stacked in the left column."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11998035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8385d733a5d41f79ec6cc34be147ec39f592de56",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents: (i) a multiscale representation of grey-level shape called the scale-space primal sketch, which makes explicit both features in scale-space and the relations between structures at different scales, (ii) a methodology for extracting significant blob-like image structures from this representation, and (iii) applications to edge detection, histogram analysis, and junction classification demonstrating how the proposed method can be used for guiding later-stage visual processes.The representation gives a qualitative description of image structure, which allows for detection of stable scales and associated regions of interest in a solely bottom-up data-driven way. In other words, it generates coarse segmentation cues, and can hence be seen as preceding further processing, which can then be properly tuned. It is argued that once such information is available, many other processing tasks can become much simpler. Experiments on real imagery demonstrate that the proposed theory gives intuitive results."
            },
            "slug": "Detecting-salient-blob-like-image-structures-and-a-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Detecting salient blob-like image structures and their scales with a scale-space primal sketch: A method for focus-of-attention"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A multiscale representation of grey-level shape called the scale-space primal sketch is presented, which gives a qualitative description of image structure, which allows for detection of stable scales and associated regions of interest in a solely bottom-up data-driven way."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740078"
                        ],
                        "name": "A. Shokoufandeh",
                        "slug": "A.-Shokoufandeh",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Shokoufandeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shokoufandeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144555425"
                        ],
                        "name": "I. Marsic",
                        "slug": "I.-Marsic",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Marsic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Marsic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779136"
                        ],
                        "name": "S. Dickinson",
                        "slug": "S.-Dickinson",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Dickinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dickinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3032287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f3a2e8aafef284c76c1238922b2118587e54e0a",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "View-based-object-recognition-using-saliency-maps-Shokoufandeh-Marsic",
            "title": {
                "fragments": [],
                "text": "View-based object recognition using saliency maps"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 138
                            }
                        ],
                        "text": "This least-squares approach could readily be extended to solving for 3D pose and internal parameters of articulated and flexible objects (Lowe, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18882836,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d11bf8b06cf96d90e1ee3dd6467c5c92ac53e9a1",
            "isKey": false,
            "numCitedBy": 999,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Model-based recognition and motion tracking depend upon the ability to solve for projection and model parameters that will best fit a 3-D model to matching 2-D image features. The author extends current methods of parameter solving to handle objects with arbitrary curved surfaces and with any number of internal parameters representing articulation, variable dimensions, or surface deformations. Numerical stabilization methods are developed that take account of inherent inaccuracies in the image measurements and allow useful solutions to be determined even when there are fewer matches than unknown parameters. The Levenberg-Marquardt method is used to always ensure convergence of the solution. These techniques allow model-based vision to be used for a much wider class of problems than was possible with previous methods. Their application is demonstrated for tracking the motion of curved, parameterized objects. >"
            },
            "slug": "Fitting-Parameterized-Three-Dimensional-Models-to-Lowe",
            "title": {
                "fragments": [],
                "text": "Fitting Parameterized Three-Dimensional Models to Images"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Current methods of parameter solving are extended to handle objects with arbitrary curved surfaces and with any number of internal parameters representing articulation, variable dimensions, or surface deformations to allow model-based vision to be used for a much wider class of problems than was possible with previous methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 205
                            }
                        ],
                        "text": "Recently, there has been an impressive body of work on extending local features to be invariant to full affine transformations (Baumberg, 2000; Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recently, there has been an impressive body of work on extending local features to be invariant to full affine transformations (Baumberg, 2000; Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002;  Schaffalitzky and Zisserman, 2002;  Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1699616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e81996384b030b580a0e02c0dc367d59c0c15ba",
            "isKey": false,
            "numCitedBy": 697,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been considerable success in automated reconstruction for image sequences where small baseline algorithms can be used to establish matches across a number of images. In contrast in the case of widely separated views, methods have generally been restricted to two or three views.In this paper we investigate the problem of establishing relative viewpoints given a large number of images where no ordering information is provided. A typical application would be where images are obtained from different sources or at different times: both the viewpoint (position, orientation, scale) and lighting conditions may vary significantly over the data set.Such a problem is not fundamentally amenable to exhaustive pair wise and triplet wide baseline matching because this would be prohibitively expensive as the number of views increases. Instead, we investiate how a combination of image invariants, covariants, and multiple view relations can be used in concord to enable efficient multiple view matching. The result is a matching algorithm which is linear in the number of views.The methods are illustrated on several real image data sets. The output enables an image based technique for navigating in a 3D scene, moving from one image to whichever image is the next most appropriate."
            },
            "slug": "Multi-view-Matching-for-Unordered-Image-Sets,-or-Do-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Multi-view Matching for Unordered Image Sets, or \"How Do I Organize My Holiday Snaps?\""
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper invests how a combination of image invariants, covariants, and multiple view relations can be used in concord to enable efficient multiple view matching and produces a matching algorithm which is linear in the number of views."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2766153"
                        ],
                        "name": "S. Se",
                        "slug": "S.-Se",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Se",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Se"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710980"
                        ],
                        "name": "J. Little",
                        "slug": "J.-Little",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Little"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2544578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6aeafde8e2564c22d4d131bd3d7fd62696575fdd",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We have previously developed a mobile robot system which uses scale invariant visual landmarks to localize and simultaneously build a 3D map of the environment In this paper, we look at global localization, also known as the kidnapped robot problem, where the robot localizes itself globally, without any prior location estimate. This is achieved by matching distinctive landmarks in the current frame to a database map. A Hough transform approach and a random sample consensus (RANSAC) approach for global localization are compared, showing that RANSAC is much more efficient. Moreover, robust global localization can be achieved by matching a small sub-map of the local region built from multiple frames."
            },
            "slug": "Global-localization-using-distinctive-visual-Se-Lowe",
            "title": {
                "fragments": [],
                "text": "Global localization using distinctive visual features"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A Hough transform approach and a random sample consensus approach for global localization are compared, showing that RANSAC is much more efficient and robust global localization can be achieved by matching a small sub-map of the local region built from multiple frames."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2624076"
                        ],
                        "name": "Q. Luong",
                        "slug": "Q.-Luong",
                        "structuredName": {
                            "firstName": "Quang-Tuan",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2582003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9643cd37f8b36dfb8a4c8bcd087843dec40d6635",
            "isKey": false,
            "numCitedBy": 578,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we analyze in some detail the geometry of a pair of cameras, i.e., a stereo rig. Contrarily to what has been done in the past and is still done currently, for example in stereo or motion analysis, we do not assume that the intrinsic parameters of the cameras are known (coordinates of the principal points, pixels aspect ratio and focal lengths). This is important for two reasons. First, it is more realistic in applications where these parameters may vary according to the task (active vision). Second, the general case considered here, captures all the relevant information that is necessary for establishing correspondences between two pairs of images. This information is fundamentally projective and is hidden in a confusing manner in the commonly used formalism of the Essential matrix introduced by Longuet-Higgins (1981). This paper clarifies the projective nature of the correspondence problem in stereo and shows that the epipolar geometry can be summarized in one 3\u00d73 matrix of rank 2 which we propose to call the Fundamental matrix.After this theoretical analysis, we embark on the task of estimating the Fundamental matrix from point correspondences, a task which is of practical importance. We analyze theoretically, and compare experimentally using synthetic and real data, several methods of estimation. The problem of the stability of the estimation is studied from two complementary viewpoints. First we show that there is an interesting relationship between the Fundamental matrix and three-dimensional planes which induce homographies between the images and create unstabilities in the estimation procedures. Second, we point to a deep relation between the unstability of the estimation procedure and the presence in the scene of so-called critical surfaces which have been studied in the context of motion analysis. Finally we conclude by stressing the fact that we believe that the Fundamental matrix will play a crucial role in future applications of three-dimensional Computer Vision by greatly increasing its versatility, robustness and hence applicability to real difficult problems."
            },
            "slug": "The-fundamental-matrix:-Theory,-algorithms,-and-Luong-Faugeras",
            "title": {
                "fragments": [],
                "text": "The fundamental matrix: Theory, algorithms, and stability analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper clarifies the projective nature of the correspondence problem in stereo and shows that the epipolar geometry can be summarized in one 3\u00d73 matrix of rank 2 which is proposed to call the Fundamental matrix, a task which is of practical importance."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8909922"
                        ],
                        "name": "N. Intrator",
                        "slug": "N.-Intrator",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Intrator",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Intrator"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 43
                            }
                        ],
                        "text": "A better approach has been demonstrated by Edelman et al. (1997). Their proposed representation was based upon a model of biological vision, in particular of complex neurons in primary visual cortex."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 43
                            }
                        ],
                        "text": "A better approach has been demonstrated by Edelman et al. (1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13632243,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9347996c6a11a8ea47d97df6e0c6c739ad68864a",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Nearest-neighbor correlation-based similarity computation in the space of outputs of complex-type receptive fields can support robust recognition of 3D objects. Our experiments with four collections of objects resulted in mean recognition rates between 84% (for subordinate-level discrimination among 15 quadruped animal shapes) and 94% (for basic-level recognition of 20 everyday objects), over a 40deg X 40deg range of viewpoints, centered on a stored canonical view and related to it by rotations in depth (comparable figures were obtained for image-plane translations). This result has interesting implications for the design of a front end to an artificial object recognition system, and for the understanding of the faculty of object recognition in primate vision."
            },
            "slug": "Complex-cells-and-Object-Recognition-Edelman-Intrator",
            "title": {
                "fragments": [],
                "text": "Complex cells and Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "Nearest-neighbor correlation-based similarity computation in the space of outputs of complex-type receptive fields can support robust recognition of 3D objects and has interesting implications for the design of a front end to an artificial object recognition system and the understanding of the faculty of object recognition in primate vision."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3304188"
                        ],
                        "name": "B. Funt",
                        "slug": "B.-Funt",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Funt",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Funt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789486"
                        ],
                        "name": "G. Finlayson",
                        "slug": "G.-Finlayson",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Finlayson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Finlayson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 177
                            }
                        ],
                        "text": "The features described in this paper use only a monochrome intensity image, so further distinctiveness could be derived from including illumination-invariant color descriptors (Funt and Finlayson, 1995; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37339880,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "11c4c7af9938b05b366c93aea70ad4e5075f6148",
            "isKey": false,
            "numCitedBy": 694,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Objects can be recognized on the basis of their color alone by color indexing, a technique developed by Swain-Ballard (1991) which involves matching color-space histograms. Color indexing fails, however, when the incident illumination varies either spatially or spectrally. Although this limitation might be overcome by preprocessing with a color constancy algorithm, we instead propose histogramming color ratios. Since the ratios of color RGB triples from neighboring locations are relatively insensitive to changes in the incident illumination, this circumvents the need for color constancy preprocessing. Results of tests with the new color-constant-color-indexing algorithm on synthetic and real images show that it works very well even when the illumination varies spatially in its intensity and color. >"
            },
            "slug": "Color-Constant-Color-Indexing-Funt-Finlayson",
            "title": {
                "fragments": [],
                "text": "Color Constant Color Indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Results of tests with the new color-constant-color-indexing algorithm show that it works very well even when the illumination varies spatially in its intensity and color, which circumvents the need for color constancy preprocessing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 145
                            }
                        ],
                        "text": "Fortunately, much better performance can be obtained by clustering features in pose space using the Hough transform (Hough, 1962; Ballard, 1981; Grimson, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1530384,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4462c82748d81489f4f453f516754438b35a8cec",
            "isKey": false,
            "numCitedBy": 961,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "With contributions from Tomas LozanoPerez and Daniel P. Huttenlocher.An intelligent system must know \"what \"the objects are and \"where \"they are in its environment. Examples of this ubiquitous problem in computer vision arise in tasks involving hand-eye coordination (such as assembling or sorting), inspection tasks, gauging operations, and in navigation and localization of mobile robots. This book describes an extended series of experiments into the role of geometry in the critical area of object recognition. It provides precise definitions of the recognition and localization problems, describes the methods used to address them, analyzes the solutions to these problems, and addresses the implications of this analysis.The solution to problems of object recognition are of fundamental importance in many real applications and versions of the techniques described here are already being used in industrial settings. Although a number of questions remain to be solved, the authors provide a valuable framework for understanding both the strengths and limitations of using object shape to guide recognition.W. Eric L. Grimson is Matsushita Associate Professor in the Department of Electrical Engineering and Computer Science at MIT.Contents: Introduction. Recognition as a Search Problem. Searching for Correspondences. Two-Dimensional Constraints. Three-Dimensional Constraints. Verifying Hypotheses. Controlling the Search Explosion. Selecting Subspaces of the Search Space. Empirical Testing. The Combinatorics of the Matching Process. The Combinatorics of Hough Transforms. The Combinatorics of Verification. The Combinatorics of Indexing. Evaluating the Methods. Recognition from Libraries. Parameterized Objects. The Role of Grouping. Sensing Strategies. Applications. The Next Steps."
            },
            "slug": "Object-recognition-by-computer-the-role-of-Grimson",
            "title": {
                "fragments": [],
                "text": "Object recognition by computer - the role of geometric constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This book describes an extended series of experiments into the role of geometry in the critical area of object recognition, providing precise definitions of the recognition and localization problems, the methods used to address them, the solutions to these problems, and the implications of this analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2766153"
                        ],
                        "name": "S. Se",
                        "slug": "S.-Se",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Se",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Se"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710980"
                        ],
                        "name": "J. Little",
                        "slug": "J.-Little",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Little"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 141
                            }
                        ],
                        "text": "These keypoints have also been applied to the problem of robot localization and mapping, which has been presented in detail in other papers (Se et al., 2001)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1157575,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb88cae3f3a196012bbf6cd2e7480e66b8a6ec31",
            "isKey": false,
            "numCitedBy": 586,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A key component of a mobile robot system is the ability to localize itself accurately and build a map of the environment simultaneously. In this paper, a vision-based mobile robot localization and mapping algorithm is described which uses scale-invariant image features as landmarks in unmodified dynamic environments. These 3D landmarks are localized and robot ego-motion is estimated by matching them, taking into account the feature viewpoint variation. With our Triclops stereo vision system, experiments show that these features are robustly matched between views, 3D landmarks are tracked, robot pose is estimated and a 3D map is built."
            },
            "slug": "Vision-based-mobile-robot-localization-and-mapping-Se-Lowe",
            "title": {
                "fragments": [],
                "text": "Vision-based mobile robot localization and mapping using scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A vision-based mobile robot localization and mapping algorithm is described which uses scale-invariant image features as landmarks in unmodified dynamic environments which are localized and robot ego-motion is estimated by matching them, taking into account the feature viewpoint variation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697493"
                        ],
                        "name": "Y. Aloimonos",
                        "slug": "Y.-Aloimonos",
                        "structuredName": {
                            "firstName": "Yiannis",
                            "lastName": "Aloimonos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Aloimonos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867195"
                        ],
                        "name": "I. Weiss",
                        "slug": "I.-Weiss",
                        "structuredName": {
                            "firstName": "Isaac",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064008635"
                        ],
                        "name": "A. Bandyopadhyay",
                        "slug": "A.-Bandyopadhyay",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Bandyopadhyay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bandyopadhyay"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 37
                            }
                        ],
                        "text": "The Moravec detector was improved by Harris and Stephens (1988) to make it more repeatable under small image variations and near edges."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 108
                            }
                        ],
                        "text": "The eigenvalues of H are proportional to the principal curvatures of D. Borrowing from the approach used by Harris and Stephens (1988), we can avoid explicitly computing the eigenvalues, as we are only concerned with their ratio."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 25458585,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e65d5ca2a2efe6f5756f579029def41fac4b374e",
            "isKey": false,
            "numCitedBy": 1031,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate several basic problems in vision under the assumption that the observer is active. An observer is called active when engaged in some kind of activity whose purpose is to control the geometric parameters of the sensory apparatus. The purpose of the activity is to manipulate the constraints underlying the observed phenomena in order to improve the quality of the perceptual results. For example a monocular observer that moves with a known or unknown motion or a binocular observer that can rotate his eyes and track environmental objects are just two examples of an observer that we call active. We prove that an active observer can solve basic vision problems in a much more efficient way than a passive one. Problems that are ill-posed and nonlinear for a passive observer become well-posed and linear for an active observer. In particular, the problems of shape from shading and depth computation, shape from contour, shape from texture, and structure from motion are shown to be much easier for an active observer than for a passive one. It has to be emphasized that correspondence is not used in our approach, i.e., active vision is not correspondence of features from multiple viewpoints. Finally, active vision here does not mean active sensing, and this paper introduces a general methodology, a general framework in which we believe low-level vision problems should be addressed."
            },
            "slug": "Active-vision-Aloimonos-Weiss",
            "title": {
                "fragments": [],
                "text": "Active vision"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is proved that an active observer can solve basic vision problems in a much more efficient way than a passive one, and a general methodology is introduced, a general framework in which low-level vision problems should be addressed."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 21
                            }
                        ],
                        "text": "It has been shown by Koenderink (1984) and Lindeberg (1994) that under a variety of reasonable assumptions the only possible scale-space kernel is the Gaussian function."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 149
                            }
                        ],
                        "text": "In addition, the difference-of-Gaussian function provides a close approximation to the scale-normalized Laplacian of Gaussian, \u03c3 2\u22072G, as studied by Lindeberg (1994). Lindeberg showed that the normalization of the Laplacian with the factor \u03c3 2 is required for true scale invariance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 340,
                                "start": 149
                            }
                        ],
                        "text": "In addition, the difference-of-Gaussian function provides a close approximation to the scale-normalized Laplacian of Gaussian, \u03c3 2\u22072G, as studied by Lindeberg (1994). Lindeberg showed that the normalization of the Laplacian with the factor \u03c3 2 is required for true scale invariance. In detailed experimental comparisons, Mikolajczyk (2002) found that the maxima and minima of \u03c3 2\u22072G produce the most stable image features compared to a range of other possible image functions, such as the gradient, Hessian, or Harris corner function."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206775432,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "58b6b9e9f5472048468bac161bdaa3ae99eecd01",
            "isKey": false,
            "numCitedBy": 2002,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In practice the relevant details of images exist only over a restricted range of scale. Hence it is important to study the dependence of image structure on the level of resolution. It seems clear enough that visual perception treats images on several levels of resolution simultaneously and that this fact must be important for the study of perception. However, no applicable mathematically formulated theory to deal with such problems appers to exist. In this paper it is shown that any image can be embedded in a one-parameter family of derived images (with resolution as the parameter) in essentially only one unique way if the constraint that no spurious detail should be generated when the resolution is diminished, is applied. The structure of this family is governed by the well known diffusion equation (a parabolic, linear, partial differential equation of the second order). As such the structure fits into existing theories that treat the front end of the visual system as a continuous tack of homogeneous layer, characterized by iterated local processing schemes. When resolution is decreased the images becomes less articulated because the extrem (\u201clight and dark blobs\u201d) disappear one after the other. This erosion of structure is a simple process that is similar in every case. As a result any image can be described as a juxtaposed and nested set of light and dark blobs, wherein each blod has a limited range of resolution in which it manifests itself. The structure of the family of derived images permits a derivation of the sampling density required to sample the image at multiple scales of resolution. The natural scale along the resolution axis (leading to an informationally uniform sampling density) is logarithmic, thus the structure is apt for the description of size invariances."
            },
            "slug": "The-structure-of-images-Koenderink",
            "title": {
                "fragments": [],
                "text": "The structure of images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that any image can be embedded in a one-parameter family of derived images (with resolution as the parameter) in essentially only one unique way if the constraint that no spurious detail should be generated when the resolution is diminished, is applied."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82993128"
                        ],
                        "name": "D. Pritchard",
                        "slug": "D.-Pritchard",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Pritchard",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pritchard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752192"
                        ],
                        "name": "W. Heidrich",
                        "slug": "W.-Heidrich",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Heidrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Heidrich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 71
                            }
                        ],
                        "text": "This approach contrasts with th e orientation invariant descriptors of Schmid and Mohr (1997), in which each image property is bas ed on a rotationally invariant measure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 150
                            }
                        ],
                        "text": "If a wide range of affine invariance is desired, such as for a surface that is known to be planar, then a simple solution is to adopt the approach of Pritchard and Heidrich (2003) in which additional SIFT features are generated from 4 affine-transformed versions of the training image corresponding\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3236642,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ed86dc54c72fbafe03da1e9400cb0f1382c560c",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent years have seen an increased interest in motion capture systems. Current systems, however, are limitedto only a few degrees of freedom, so that effectively only the motion of linked rigid bodies can be acquired. Wepresent a system for the capture of deformable surfaces, most notably moving cloth, including both geometry andparameterisation. We recover geometry using stereo correspondence, and use the Scale Invariant Feature Transform(SIFT) to identify an arbitrary pattern printed on the cloth, even in the presence of fast motion. We describea novel seed\u2010and\u2010grow approach to adapt the SIFT algorithm to deformable geometry. Finally, we interpolatefeature points to parameterise the complete geometry."
            },
            "slug": "Cloth-Motion-Capture-Pritchard-Heidrich",
            "title": {
                "fragments": [],
                "text": "Cloth Motion Capture"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel seed\u2010and\u2010grow approach is described to adapt the SIFT algorithm to deformable geometry, and feature points are interpolated to parameterise the complete geometry."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809905"
                        ],
                        "name": "A. Witkin",
                        "slug": "A.-Witkin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Witkin",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Witkin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7096897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a26f893c224ed6e3df1f37479de0e774a4cae237",
            "isKey": false,
            "numCitedBy": 2873,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Scale-Space-Filtering-Witkin",
            "title": {
                "fragments": [],
                "text": "Scale-Space Filtering"
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724709"
                        ],
                        "name": "S. Arya",
                        "slug": "S.-Arya",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Arya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Arya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709509"
                        ],
                        "name": "D. Mount",
                        "slug": "D.-Mount",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mount",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mount"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 58
                            }
                        ],
                        "text": "This priority search order was first examined by Arya and Mount (1993), and they provide further study of its computational properties in Arya et al. (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1143910,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b654d0a3de9acd9db6982d39bcf25e8ece9a31e6",
            "isKey": false,
            "numCitedBy": 407,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of n points in d-dimensional Euclidean space, S \u2282 E, and a query point q \u2208 E, we wish to determine the nearest neighbor of q, that is, the point of S whose Euclidean distance to q is minimum. The goal is to preprocess the point set S, such that queries can be answered as efficiently as possible. We assume that the dimension d is a constant independent of n. Although reasonably good solutions to this problem exist when d is small, as d increases the performance of these algorithms degrades rapidly. We present a randomized algorithm for approximate nearest neighbor searching. Given any set of n points S \u2282 E, and a constant \u01eb > 0, we produce a data structure, such that given any query point, a point of S will be reported whose distance from the query point is at most a factor of (1 + \u01eb) from that of the true nearest neighbor. Our algorithm runs in O(log n) expected time and requires O(n log n) space. The data structure can be built in O(n) expected time. The constant factors depend on d and \u01eb. Because of the practical importance of nearest neighbor searching in higher dimensions, we have implemented a practical variant of this algorithm, and show empirically that for many point distributions this variant of the algorithm finds the nearest neighbor in moderately large dimension significantly faster than existing practical approaches."
            },
            "slug": "Approximate-nearest-neighbor-queries-in-fixed-Arya-Mount",
            "title": {
                "fragments": [],
                "text": "Approximate nearest neighbor queries in fixed dimensions"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A practical variant of this algorithm is implemented, and it is shown empirically that for many point distributions this variant of the algorithm finds the nearest neighbor in moderately large dimension significantly faster than existing practical approaches."
            },
            "venue": {
                "fragments": [],
                "text": "SODA '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17173992"
                        ],
                        "name": "B. Wrobel",
                        "slug": "B.-Wrobel",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Wrobel",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Wrobel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 96
                            }
                        ],
                        "text": "A more general solution would be to solve for the fundamental matrix (Luong and Faugeras, 1996; Hartley and Zisserman, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44793400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "339093c7ed71919ce59a7e78979a77abd25bad0c",
            "isKey": false,
            "numCitedBy": 16322,
            "numCiting": 222,
            "paperAbstract": {
                "fragments": [],
                "text": "Downloading the book in this website lists can give you more advantages. It will show you the best book collections and completed collections. So many books can be found in this website. So, this is not only this multiple view geometry in computer vision. However, this book is referred to read because it is an inspiring book to give you more chance to get experiences and also thoughts. This is simple, read the soft file of the book and you get it."
            },
            "slug": "Multiple-View-Geometry-in-Computer-Vision-Wrobel",
            "title": {
                "fragments": [],
                "text": "Multiple View Geometry in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This book is referred to read because it is an inspiring book to give you more chance to get experiences and also thoughts and it will show the best book collections and completed collections."
            },
            "venue": {
                "fragments": [],
                "text": "K\u00fcnstliche Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066894"
                        ],
                        "name": "Hans P. Moravec",
                        "slug": "Hans-P.-Moravec",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Moravec",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hans P. Moravec"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18232715,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "e3bc3249755cdc7d1c787809fabb14918704df2a",
            "isKey": false,
            "numCitedBy": 291,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The Stanford AI Lab cart is a remotely controlled TV equipped mobile robot. A computer program has driven the cart through cluttered spaces, gaining its knowledge of the world entirely from images broadcast by the onboard TV system. \n \nThe cart uses several kinds of stereo to locate objects around it in 3D and to deduce its own motion. It plans an obstacle avoiding path to a desired destination on the basis of a model built with this information. The plan changes as the cart perceives new obstacles on its journey. \n \nThe system is reliable for short runs, but slow. The cart moves one meter every ten to fifteen minutes, in lurches. After rolling a meter it stops, takes some pictures and thinks about them for a long time. Then it plans a new path, executes a little of it. and pauses again. \n \nIt has successfully driven the cart through several 20 meter courses (each taking about five hours) complex enough to necessitate three or four avoiding swerves. Some weaknesses and possible improvements were suggested by these and other, less successful, runs."
            },
            "slug": "Rover-Visual-Obstacle-Avoidance-Moravec",
            "title": {
                "fragments": [],
                "text": "Rover Visual Obstacle Avoidance"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The Stanford AI Lab cart is a remotely controlled TV equipped mobile robot that uses several kinds of stereo to locate objects around it in 3D and to deduce its own motion."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696575"
                        ],
                        "name": "J. Bentley",
                        "slug": "J.-Bentley",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Bentley",
                            "middleNames": [
                                "Louis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bentley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2236311"
                        ],
                        "name": "R. Finkel",
                        "slug": "R.-Finkel",
                        "structuredName": {
                            "firstName": "Raphael",
                            "lastName": "Finkel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Finkel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 109
                            }
                        ],
                        "text": "Our keypoint descriptor has a 128-dimensional feature vector, and the best algorithms, such as the k-d tree (Friedman et al., 1977) provide no speedup over exhaustive search for more than about 10 dimensional spaces."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10811510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cab3c73f1b2140231b98944c720100b356d91b28",
            "isKey": false,
            "numCitedBy": 2964,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm and data structure are presented for searching a file containing N records, each described by k real valued keys, for the m closest matches or nearest neighbors to a given query record. The computation required to organize the file is proportional to kNlogN. The expected number of records examined in each search is independent of the file size. The expected computation to perform each search is proportional to logN. Empirical evidence suggests that except for very small files, this algorithm is considerably faster than other methods."
            },
            "slug": "An-Algorithm-for-Finding-Best-Matches-in-Expected-Friedman-Bentley",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Finding Best Matches in Logarithmic Expected Time"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An algorithm and data structure are presented for searching a file containing N records, each described by k real valued keys, for the m closest matches or nearest neighbors to a given query record."
            },
            "venue": {
                "fragments": [],
                "text": "TOMS"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724709"
                        ],
                        "name": "S. Arya",
                        "slug": "S.-Arya",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Arya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Arya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709509"
                        ],
                        "name": "D. Mount",
                        "slug": "D.-Mount",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mount",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mount"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712586"
                        ],
                        "name": "N. Netanyahu",
                        "slug": "N.-Netanyahu",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Netanyahu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Netanyahu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37746341"
                        ],
                        "name": "R. Silverman",
                        "slug": "R.-Silverman",
                        "structuredName": {
                            "firstName": "Ruth",
                            "lastName": "Silverman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Silverman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736712"
                        ],
                        "name": "A. Wu",
                        "slug": "A.-Wu",
                        "structuredName": {
                            "firstName": "Angela",
                            "lastName": "Wu",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 138
                            }
                        ],
                        "text": "This priority search order was first examined by Arya and Mount (1993), and they provide further study of its computational properties in Arya et al. (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8193729,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "219101fe724232acc330ff0910152931538f85c7",
            "isKey": false,
            "numCitedBy": 2723,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": "Consider a set of <italic>S</italic> of <italic>n</italic> data points  in real <italic>d</italic>-dimensional space, R<supscrpt>d</supscrpt>, where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess <italic>S</italic> into a data structure, so that given any query point <italic>q</italic><inline-equation> <f>\u2208</f></inline-equation> R<supscrpt>d</supscrpt>, is the closest point of S to <italic>q</italic> can be reported quickly. Given any positive real \u03b5, data point <italic>p</italic> is a (1 +\u03b5)-<italic>approximate nearest neighbor</italic> of <italic>q</italic> if its distance from <italic>q</italic> is within a factor of (1 + \u03b5) of the distance to the true nearest neighbor. We show that it is possible to preprocess a    set of <italic>n</italic> points in     R<supscrpt>d</supscrpt> in <italic>O(dn</italic> log <italic>n</italic>) time and <italic>O(dn)</italic> space, so that given a query point <italic> q</italic> <inline-equation> <f>\u2208</f></inline-equation> R<supscrpt>d</supscrpt>, and \u03b5 > 0, a (1 + \u03b5)-approximate nearest neighbor of <italic>q</italic> can be computed in <italic>O</italic>(<italic>c</italic><subscrpt><italic>d</italic>, \u03b5</subscrpt> log <italic>n</italic>) time, where <italic>c<subscrpt>d,\u03b5</subscrpt></italic>\u2264<italic>d</italic> <inline-equation> <f><fen lp=\"ceil\">1 + 6d/<g>e</g><rp post=\"ceil\"></fen></f></inline-equation>;<supscrpt>d</supscrpt> is a factor depending only on dimension and \u03b5. In general, we show that given an integer <italic>k</italic> \u2265 1, (1 + \u03b5)-approximations  to the  <italic>k</italic> nearest neighbors of <italic>q</italic> can  be computed in additional <italic>O(kd</italic> log <italic>n</italic>) time."
            },
            "slug": "An-optimal-algorithm-for-approximate-nearest-fixed-Arya-Mount",
            "title": {
                "fragments": [],
                "text": "An optimal algorithm for approximate nearest neighbor searching fixed dimensions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that it is possible to preprocess a set of data points in real D-dimensional space in O(kd) time and in additional space, so that given a query point q, the closest point of S to S to q can be reported quickly."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 55
                            }
                        ],
                        "text": "In what appears to be the most affineinvariant method, Mikolajczyk (2002) has proposed and run detailed experiments with the Harris-affine detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 38
                            }
                        ],
                        "text": "In detailed experimental comparisons, Mikolajczyk (2002) found that the maxima and minima of \u03c3 2\u22072G produce the most stable image features compared to a range of other possible image functions, such as the gradient, Hessian, or Harris corner function."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 300,
                                "start": 281
                            }
                        ],
                        "text": "The affine frames are are also more sensitive to noise than those of the scale-invariant features, so in practice the affine features have lower repeatability than the scale-invariant features unless the affine distortion is greater than about a 40 degree tilt of a planar surface (Mikolajczyk, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 279
                            }
                        ],
                        "text": "\u2026affine frames are are also more sensitive to noise than those of the scale-invariant features, so in practice the affine features have lower repeatability than the scale-invariant features unless the affine distortion is greater than about a 40 degree tilt of a planar surface (Mikolajczyk, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10531237,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "81e0b2275413d77ca21edc0442393d298db804b1",
            "isKey": true,
            "numCitedBy": 91,
            "numCiting": 136,
            "paperAbstract": {
                "fragments": [],
                "text": "Une des approches dominantes pour la reconnaissance d'objets est basee sur les caracteristiques locales. La methode utilise la description locale calculee au voisinage de points d'interet. La detection de points d'interet est une premiere etape dans le processus de la mise en correspondance et de la reconnaissance. L'approche par apparences locales a permis d'ameliorer et d'accelerer considerablement la recherche d'images dans des bases de donnees. Dans cette these, nous proposons une nouvelle approche pour la detection de points caracteristiques d'une image. Cette approche est invariante aux transformations geometriques et photometriques, qui apparaissent frequemment entre les images prises dans des conditions differentes. Nous nous concentrons sur le probleme d'invariance aux transformations affines. Cette transformation est particulierement importante parce qu'elle permet de s'affranchir des problemes de changements perspectives. Les approches precedentes apportent des solutions partielles, car certains parametres de points d'interet ne sont pas estimes de facon invariante aux changements affines. Nous avons propose une solution generique a ces problemes. Notre methode est reellement invariante aux transformations affines, y compris aux changements d'echelle importants. Les images sont caracterisees par des ensembles de descripteurs calcules en des points caracteristiques detectes automatiquement. Une mesure de ressemblance permet d'etablir des correspondances entre les points. Ces correspondances sont ensuite utilisees pour calculer la geometrie qui lie les images. Dans le contexte de la recherche d'images les descripteurs sont utilises pour retrouver des points similaires dans la base et par consequent des images similaires aux images requetes. Les resultats experimentaux pour la mise en correspondance et la recherche d'images montrent que notre approche est tres robuste et efficace meme dans les cas de changements importants. Plusieurs etudes comparatives effectuees dans cette these montrent l'avantage de cette methode par rapport aux approches existantes presentees recemment dans la litterature."
            },
            "slug": "Detection-of-local-features-invariant-to-affines-Mikolajczyk",
            "title": {
                "fragments": [],
                "text": "Detection of local features invariant to affines transformations"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Une des approches dominantes pour the reconnaissance d'objets est basee sur les caracteristiques locales, y compris aux changements d'echelle importants, que notre approche est tres robuste and efficace meme dans les cas of changements importants."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 43
                            }
                        ],
                        "text": "It has been shown by Koenderink (1984) and Lindeberg (1994) that under a variety of reasonable assumptions the only possible scale-space kernel is the Gaussian function."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 114
                            }
                        ],
                        "text": "The problem of identifying an appropriate and consistent scale for feature detection has been studied in depth by Lindeberg (1993, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 146
                            }
                        ],
                        "text": "In addition, the difference-of-Gaussian function provides a close approximation to the scale-normalized Laplacian of Gaussian, \u03c3 2\u22072G, as studied by Lindeberg (1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14361759,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "75fa9982cb3f92e1b0fe67cebf23a4b862f8bd2f",
            "isKey": false,
            "numCitedBy": 1373,
            "numCiting": 160,
            "paperAbstract": {
                "fragments": [],
                "text": "An inherent property of objects in the world is that they only exist as meaningful entities over certain ranges of scale. If one aims at describing the structure of unknown real-world signals, then ..."
            },
            "slug": "Scale-Space-Theory-:-A-Basic-Tool-for-Analysing-at-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Scale-Space Theory : A Basic Tool for Analysing Structures at Different Scales"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 48
                            }
                        ],
                        "text": "However, recently Brown has developed a method (Brown and Lowe, 2002) for fitting a 3D quadratic function to the local sample points to determine the interpolated location of the maximum, and his experiments showed that this provides a substantial improvement to matching and stability."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 240
                            }
                        ],
                        "text": "Recently, there has been an impressive body of work on extending local features to be invariant to full affine transformations (Baumberg, 2000; Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 36
                            }
                        ],
                        "text": "A more general approach is given in Brown and Lowe (2002), in which the initial solution is based on a similarity transform, which then progresses to solution for the fundamental matrix in those cases in which a sufficient number of matches are found."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 203
                            }
                        ],
                        "text": "The features described in this paper use only a monochrome intensity image, so further distinctiveness could be derived from including illumination-invariant color descriptors (Funt and Finlayson, 1995; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 128
                            }
                        ],
                        "text": "Recently, there has been an impressive body of work on extend ing local features to be invariant to full affine transformations (Baumberg, 2000; T uytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman , 2002; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 47
                            }
                        ],
                        "text": "However, recently Brown has developed a method (Brown and Lowe, 2002) for fitting a 3D quadratic func tion to the local sample points to determine the interpolated location of the maximu m, and his experiments showed that this provides a substantial improvement to matching an d stability."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Invariant features from inter"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3972,
                                "start": 38
                            }
                        ],
                        "text": "sensitive to local image distortions such as 3D viewpoint ch ange. This current paper provides a more in-depth development and analysis of this earlier wor k, while also presenting a number of improvements in stability and feature invariance. There is a considerable body of previous research on identif ying representations that are stable under scale change. Some of the first work in this area w as by Crowley and Parker (1984), who developed a representation that identified peak s and ridges in scale space and linked these into a tree structure. The tree structure could then be matched between images with arbitrary scale change. More recent work on graph-base d matching by Shokoufandeh, Marsic and Dickinson (1999) provides more distinctive feat ure descriptors using wavelet coefficients. The problem of identifying an appropriate and co nsistent scale for feature detection has been studied in depth by Lindeberg (1993, 1994). He descr ib this as a problem of scale selection, and we make use of his results below. Recently, there has been an impressive body of work on extend ing local features to be invariant to full affine transformations (Baumberg, 2000; T uytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman , 2002; Brown and Lowe, 2002). This allows for invariant matching to features on a planar su rface under changes in orthographic 3D projection, in most cases by resampling the image in a local affine frame. However, none of these approaches are yet fully affine invariant , as hey start with initial feature scales and locations selected in a non-affine-invariant man ner due to the prohibitive cost of exploring the full affine space. The affine frames are are also more sensitive to noise than those of the scale-invariant features, so in practice the af fine features have lower repeatability than the scale-invariant features unless the affine distort ion is greater than about a 40 degree tilt of a planar surface (Mikolajczyk, 2002). Wider affine in variance may not be important for many applications, as training views are best taken at least every 30 degrees rotation in viewpoint (meaning that recognition is within 15 degrees of the c losest training view) in order to capture non-planar changes and occlusion effects for 3D obj ects. While the method to be presented in this paper is not fully affi ne invariant, a different approach is used in which the local descriptor allows relati ve feature positions to shift significantly with only small changes in the descriptor. This appr oach not only allows the descriptors to be reliably matched across a considerable range of af fine distortion, but it also makes the features more robust against changes in 3D viewpoint for non-planar surfaces. Other advantages include much more efficient feature extraction a nd the ability to identify larger numbers of features. On the other hand, affine invariance is a valu ble property for matching planar surfaces under very large view changes, and further r es a ch should be performed on the best ways to combine this with non-planar 3D viewpoint in variance in an efficient and stable manner. Many other feature types have been proposed for use in recogn ition, some of which could be used in addition to the features described in this paper to p ovide further matches under differing circumstances. One class of features are those th at make use of image contours or region boundaries, which should make them less likely to be d isrupted by cluttered backgrounds near object boundaries. Matas et al., (2002) have shown that their maximally-stable extremal regions can produce large numbers of matching feat ures with good stability. Mikolajczyk et al., (2003) have developed a new descriptor that uses local edges while ignoring unrelated nearby edges, providing the ability to find stable features even near the boundaries of narrow shapes superimposed on background clutter. Nelso n and Selinger (1998) have shown good results with local features based on groupings of image contours."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 724,
                                "start": 38
                            }
                        ],
                        "text": "sensitive to local image distortions such as 3D viewpoint ch ange. This current paper provides a more in-depth development and analysis of this earlier wor k, while also presenting a number of improvements in stability and feature invariance. There is a considerable body of previous research on identif ying representations that are stable under scale change. Some of the first work in this area w as by Crowley and Parker (1984), who developed a representation that identified peak s and ridges in scale space and linked these into a tree structure. The tree structure could then be matched between images with arbitrary scale change. More recent work on graph-base d matching by Shokoufandeh, Marsic and Dickinson (1999) provides more distinctive feat ure descriptors using wavelet coefficients."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1488,
                                "start": 37
                            }
                        ],
                        "text": "The development of image matching by using a set of local inte res points can be traced back to the work of Moravec (1981) on stereo matching using a corne r detector. The Moravec detector was improved by Harris and Stephens (1988) to make i t more repeatable under small image variations and near edges. Harris also showed its valu e for efficient motion tracking and 3D structure from motion recovery (Harris, 1992), and th e Harris corner detector has since been widely used for many other image matching tasks. W hile these feature detectors are usually called corner detectors, they are not selecting just corners, but rather any image location that has large gradients in all directions at a pred etermined scale. The initial applications were to stereo and short-range mot ion tracking, but the approach was later extended to more difficult problems. Zhang et al. (1995) showed that it was possible to match Harris corners over a large image range by using a correlation window around each corner to select likely matches. Outliers were then rem ov d by solving for a fundamental matrix describing the geometric constraints betwee n th two views of rigid scene and removing matches that did not agree with the majority soluti n. At the same time, a similar approach was developed by Torr (1995) for long-range motion matching, in which geometric constraints were used to remove outliers for rigid objects m oving within an image. The ground-breaking work of Schmid and Mohr (1997) showed th at invariant local feature matching could be extended to general image recognitio n pr blems in which a feature was matched against a large database of images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 878,
                                "start": 37
                            }
                        ],
                        "text": "The development of image matching by using a set of local inte res points can be traced back to the work of Moravec (1981) on stereo matching using a corne r detector. The Moravec detector was improved by Harris and Stephens (1988) to make i t more repeatable under small image variations and near edges. Harris also showed its valu e for efficient motion tracking and 3D structure from motion recovery (Harris, 1992), and th e Harris corner detector has since been widely used for many other image matching tasks. W hile these feature detectors are usually called corner detectors, they are not selecting just corners, but rather any image location that has large gradients in all directions at a pred etermined scale. The initial applications were to stereo and short-range mot ion tracking, but the approach was later extended to more difficult problems. Zhang et al. (1995) showed that it was possible to match Harris corners over a large image range by using a correlation window around each corner to select likely matches."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1302,
                                "start": 37
                            }
                        ],
                        "text": "The development of image matching by using a set of local inte res points can be traced back to the work of Moravec (1981) on stereo matching using a corne r detector. The Moravec detector was improved by Harris and Stephens (1988) to make i t more repeatable under small image variations and near edges. Harris also showed its valu e for efficient motion tracking and 3D structure from motion recovery (Harris, 1992), and th e Harris corner detector has since been widely used for many other image matching tasks. W hile these feature detectors are usually called corner detectors, they are not selecting just corners, but rather any image location that has large gradients in all directions at a pred etermined scale. The initial applications were to stereo and short-range mot ion tracking, but the approach was later extended to more difficult problems. Zhang et al. (1995) showed that it was possible to match Harris corners over a large image range by using a correlation window around each corner to select likely matches. Outliers were then rem ov d by solving for a fundamental matrix describing the geometric constraints betwee n th two views of rigid scene and removing matches that did not agree with the majority soluti n. At the same time, a similar approach was developed by Torr (1995) for long-range motion matching, in which geometric constraints were used to remove outliers for rigid objects m oving within an image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 431,
                                "start": 38
                            }
                        ],
                        "text": "sensitive to local image distortions such as 3D viewpoint ch ange. This current paper provides a more in-depth development and analysis of this earlier wor k, while also presenting a number of improvements in stability and feature invariance. There is a considerable body of previous research on identif ying representations that are stable under scale change. Some of the first work in this area w as by Crowley and Parker (1984), who developed a representation that identified peak s and ridges in scale space and linked these into a tree structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 37
                            }
                        ],
                        "text": "The development of image matching by using a set of local inte res points can be traced back to the work of Moravec (1981) on stereo matching using a corne r detector. The Moravec detector was improved by Harris and Stephens (1988) to make i t more repeatable under small image variations and near edges."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3575,
                                "start": 38
                            }
                        ],
                        "text": "sensitive to local image distortions such as 3D viewpoint ch ange. This current paper provides a more in-depth development and analysis of this earlier wor k, while also presenting a number of improvements in stability and feature invariance. There is a considerable body of previous research on identif ying representations that are stable under scale change. Some of the first work in this area w as by Crowley and Parker (1984), who developed a representation that identified peak s and ridges in scale space and linked these into a tree structure. The tree structure could then be matched between images with arbitrary scale change. More recent work on graph-base d matching by Shokoufandeh, Marsic and Dickinson (1999) provides more distinctive feat ure descriptors using wavelet coefficients. The problem of identifying an appropriate and co nsistent scale for feature detection has been studied in depth by Lindeberg (1993, 1994). He descr ib this as a problem of scale selection, and we make use of his results below. Recently, there has been an impressive body of work on extend ing local features to be invariant to full affine transformations (Baumberg, 2000; T uytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman , 2002; Brown and Lowe, 2002). This allows for invariant matching to features on a planar su rface under changes in orthographic 3D projection, in most cases by resampling the image in a local affine frame. However, none of these approaches are yet fully affine invariant , as hey start with initial feature scales and locations selected in a non-affine-invariant man ner due to the prohibitive cost of exploring the full affine space. The affine frames are are also more sensitive to noise than those of the scale-invariant features, so in practice the af fine features have lower repeatability than the scale-invariant features unless the affine distort ion is greater than about a 40 degree tilt of a planar surface (Mikolajczyk, 2002). Wider affine in variance may not be important for many applications, as training views are best taken at least every 30 degrees rotation in viewpoint (meaning that recognition is within 15 degrees of the c losest training view) in order to capture non-planar changes and occlusion effects for 3D obj ects. While the method to be presented in this paper is not fully affi ne invariant, a different approach is used in which the local descriptor allows relati ve feature positions to shift significantly with only small changes in the descriptor. This appr oach not only allows the descriptors to be reliably matched across a considerable range of af fine distortion, but it also makes the features more robust against changes in 3D viewpoint for non-planar surfaces. Other advantages include much more efficient feature extraction a nd the ability to identify larger numbers of features. On the other hand, affine invariance is a valu ble property for matching planar surfaces under very large view changes, and further r es a ch should be performed on the best ways to combine this with non-planar 3D viewpoint in variance in an efficient and stable manner. Many other feature types have been proposed for use in recogn ition, some of which could be used in addition to the features described in this paper to p ovide further matches under differing circumstances. One class of features are those th at make use of image contours or region boundaries, which should make them less likely to be d isrupted by cluttered backgrounds near object boundaries. Matas et al., (2002) have shown that their maximally-stable extremal regions can produce large numbers of matching feat ures with good stability."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 37
                            }
                        ],
                        "text": "The development of image matching by using a set of local inte res points can be traced back to the work of Moravec (1981) on stereo matching using a corne r detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3727,
                                "start": 38
                            }
                        ],
                        "text": "sensitive to local image distortions such as 3D viewpoint ch ange. This current paper provides a more in-depth development and analysis of this earlier wor k, while also presenting a number of improvements in stability and feature invariance. There is a considerable body of previous research on identif ying representations that are stable under scale change. Some of the first work in this area w as by Crowley and Parker (1984), who developed a representation that identified peak s and ridges in scale space and linked these into a tree structure. The tree structure could then be matched between images with arbitrary scale change. More recent work on graph-base d matching by Shokoufandeh, Marsic and Dickinson (1999) provides more distinctive feat ure descriptors using wavelet coefficients. The problem of identifying an appropriate and co nsistent scale for feature detection has been studied in depth by Lindeberg (1993, 1994). He descr ib this as a problem of scale selection, and we make use of his results below. Recently, there has been an impressive body of work on extend ing local features to be invariant to full affine transformations (Baumberg, 2000; T uytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman , 2002; Brown and Lowe, 2002). This allows for invariant matching to features on a planar su rface under changes in orthographic 3D projection, in most cases by resampling the image in a local affine frame. However, none of these approaches are yet fully affine invariant , as hey start with initial feature scales and locations selected in a non-affine-invariant man ner due to the prohibitive cost of exploring the full affine space. The affine frames are are also more sensitive to noise than those of the scale-invariant features, so in practice the af fine features have lower repeatability than the scale-invariant features unless the affine distort ion is greater than about a 40 degree tilt of a planar surface (Mikolajczyk, 2002). Wider affine in variance may not be important for many applications, as training views are best taken at least every 30 degrees rotation in viewpoint (meaning that recognition is within 15 degrees of the c losest training view) in order to capture non-planar changes and occlusion effects for 3D obj ects. While the method to be presented in this paper is not fully affi ne invariant, a different approach is used in which the local descriptor allows relati ve feature positions to shift significantly with only small changes in the descriptor. This appr oach not only allows the descriptors to be reliably matched across a considerable range of af fine distortion, but it also makes the features more robust against changes in 3D viewpoint for non-planar surfaces. Other advantages include much more efficient feature extraction a nd the ability to identify larger numbers of features. On the other hand, affine invariance is a valu ble property for matching planar surfaces under very large view changes, and further r es a ch should be performed on the best ways to combine this with non-planar 3D viewpoint in variance in an efficient and stable manner. Many other feature types have been proposed for use in recogn ition, some of which could be used in addition to the features described in this paper to p ovide further matches under differing circumstances. One class of features are those th at make use of image contours or region boundaries, which should make them less likely to be d isrupted by cluttered backgrounds near object boundaries. Matas et al., (2002) have shown that their maximally-stable extremal regions can produce large numbers of matching feat ures with good stability. Mikolajczyk et al., (2003) have developed a new descriptor that uses local edges while ignoring unrelated nearby edges, providing the ability to find stable features even near the boundaries of narrow shapes superimposed on background clutter."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An optimal algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 55
                            }
                        ],
                        "text": "In what appears to be the most affineinvariant method, Mikolajczyk (2002) has proposed and run detailed experiments with the Harris-affine detector."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 38
                            }
                        ],
                        "text": "In detailed experimental comparisons, Mikolajczyk (2002) found that the maxima and minima of \u03c3 2\u22072G produce the most stable image features compared to a range of other possible image functions, such as the gradient, Hessian, or Harris corner function."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 279
                            }
                        ],
                        "text": "\u2026affine frames are are also more sensitive to noise than those of the scale-invariant features, so in practice the affine features have lower repeatability than the scale-invariant features unless the affine distortion is greater than about a 40 degree tilt of a planar surface (Mikolajczyk, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 302,
                                "start": 283
                            }
                        ],
                        "text": "The affine frames are are also more sensitive to noise than those of the scale-invariant features, so in practice the af fine features have lower repeatability than the scale-invariant features unless the affine distort ion is greater than about a 40 degree tilt of a planar surface (Mikolajczyk, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 116694354,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c2ccfff437fa0d341db6fa3a77114186d9629019",
            "isKey": true,
            "numCitedBy": 77,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Detection-of-local-features-invariant-to-affine-:-Mikolajczyk",
            "title": {
                "fragments": [],
                "text": "Detection of local features invariant to affine transformations : application to matching and recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98533720"
                        ],
                        "name": "C. Harris",
                        "slug": "C.-Harris",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Harris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117944059,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "7da6a6ae6d1dd46087cc3b8e0af165fda1ece75b",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Geometry-from-visual-motion-Harris",
            "title": {
                "fragments": [],
                "text": "Geometry from visual motion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3328526"
                        ],
                        "name": "C. D. Krause",
                        "slug": "C.-D.-Krause",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Krause",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32551447"
                        ],
                        "name": "Junxia Xie",
                        "slug": "Junxia-Xie",
                        "structuredName": {
                            "firstName": "Junxia",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junxia Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47417000"
                        ],
                        "name": "Y. Jia",
                        "slug": "Y.-Jia",
                        "structuredName": {
                            "firstName": "Yiwei",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3917299"
                        ],
                        "name": "Erwen Mei",
                        "slug": "Erwen-Mei",
                        "structuredName": {
                            "firstName": "Erwen",
                            "lastName": "Mei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erwen Mei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052794648"
                        ],
                        "name": "M. A. Bopp",
                        "slug": "M.-A.-Bopp",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Bopp",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Bopp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5228626"
                        ],
                        "name": "R. Hochstrasser",
                        "slug": "R.-Hochstrasser",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Hochstrasser",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hochstrasser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6706129"
                        ],
                        "name": "S. Pestka",
                        "slug": "S.-Pestka",
                        "structuredName": {
                            "firstName": "Sidney",
                            "lastName": "Pestka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pestka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122438164"
                        ],
                        "name": "R. Wood",
                        "slug": "R.-Wood",
                        "structuredName": {
                            "firstName": "Rupert",
                            "lastName": "Wood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wood"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 43
                            }
                        ],
                        "text": "A better approach has been demonstrated by Edelman et al. (1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 86210522,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "8a84f9a9cf6ce55c4e25d3b201e2f0b0543ad7e6",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 101,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Complex-in-Cells-Krause-Xie",
            "title": {
                "fragments": [],
                "text": "Complex in Cells"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143750012"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60509877,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae954b89b906dbab214d03556ce94c5adf3c0676",
            "isKey": false,
            "numCitedBy": 956,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multiple-view-geometry-in-computer-visiond-Hartley-Zisserman",
            "title": {
                "fragments": [],
                "text": "Multiple view geometry in computer visiond"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Mikolajczyk et al. (2003) have developed a new descriptor that uses local edges while ignoring unrelated nearby edges, providing the ability to find stable features even near the boundaries of narrow shapes superimposed on background clutter."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape recognition with edgebased features"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 128
                            }
                        ],
                        "text": "Recently, there has been an impressive body of work on extend ing local features to be invariant to full affine transformations (Baumberg, 2000; T uytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman , 2002; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 175
                            }
                        ],
                        "text": "Recently, there has been an impressive body of work on extending local features to be invariant to full affine transformations (Baumberg, 2000; Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An affine invariant int"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 138
                            }
                        ],
                        "text": "This least-squares approach could readily be extended to solving for 3D pose and internal parameters of articulated and flexible objects (Lowe, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fitting parameterized threedimensionalmodels to images"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . on Pattern Analysis and Machine Intelligence"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lowe In British Machine Vision Conference"
            },
            "venue": {
                "fragments": [],
                "text": "Lowe In British Machine Vision Conference"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Basri and Jacobs (1997) have demonstrated the value of extracting local region boundaries for recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition using region c"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 10
                            }
                        ],
                        "text": "Basri and Jacobs (1997) have demonstrated the value of extracting local region boundaries for recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalizing the Hough transform to detect arbitrary patterns"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 71
                            }
                        ],
                        "text": "This approach contrasts with th e orientation invariant descriptors of Schmid and Mohr (1997), in which each image property is bas ed on a rotationally invariant measure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 205
                            }
                        ],
                        "text": "Recently, there has been an impressive body of work on extending local features to be invariant to full affine transformations (Baumberg, 2000; Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multi-view matc"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 70
                            }
                        ],
                        "text": "A more general solution would be to solve for the fun damental matrix (Luong and Faugeras, 1996; Hartley and Zisserman, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 70
                            }
                        ],
                        "text": "A more general solution would be to solve for the fundamental matrix (Luong and Faugeras, 1996; Hartley and Zisserman, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The fundamental matri"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 16
                            }
                        ],
                        "text": "The research of Weber et al. (2000) and Fergus et al. (2003) has shown the potential of this approach by learning small sets of local features that are suited to recognizing generic classes of objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo based on local , affinely invariant regions"
            },
            "venue": {
                "fragments": [],
                "text": "British Machine Vision Conference"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 28
                            }
                        ],
                        "text": "The ground-breaking work of Schmid and Mohr (1997) showed that invariant local feature matching could be extended to general image recognition problems in which a feature was matched against a large database of images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 70
                            }
                        ],
                        "text": "This approach contrasts with the orientation invariant descriptors of Schmid and Mohr (1997), in which each image property is based on a rotationally invariant measure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Local grayvalue invariants fo"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 138
                            }
                        ],
                        "text": "This least-squares approach could readily be extended to solving for 3D pose and internal parameters of articulated and flexible objects (Lowe, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 139
                            }
                        ],
                        "text": "This least-squares a ppro ch could readily be extended to solving for 3D pose and internal parameters of articulate d and flexible objects (Lowe, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fitting parameterized three-dimensional"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Pope and Lowe (2000) used features based on the hierarchical grouping of image contours, which are particularly useful for objects lacking detailed texture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic models of app"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "At the same time, a similar approach was developed by Torr (1995) for long-range motion matching, in which geometric constraints were used to remove outliers for rigid objects moving within an image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Motion segmentation and outlier detection, Ph.D"
            },
            "venue": {
                "fragments": [],
                "text": "Thesis, Dept. of Engineering Science,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo b"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 114
                            }
                        ],
                        "text": "The problem of identifying an appropriate and consistent scale for feature detection has been studied in depth by Lindeberg (1993, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detecting salient bloblike image structures and their scales with a scale - space primal sketch : a method for focusofattention"
            },
            "venue": {
                "fragments": [],
                "text": "I ternational Journal of Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 49
                            }
                        ],
                        "text": "This priority search order was first examined by Arya and Mount (1993), and they provide further study of its computational properties in Arya et al. (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approximate nearest neighbo"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 93
                            }
                        ],
                        "text": "Therefore, we have used an approximate algorithm, c alled the Best-Bin-First (BBF) algorithm (Beis and Lowe, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 93
                            }
                        ],
                        "text": "Therefore, we have used an approximate algorithm, called the Best-Bin-First (BBF) algorithm (Beis and Lowe, 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape indexing using approxima"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 128
                            }
                        ],
                        "text": "Recently, there has been an impressive body of work on extend ing local features to be invariant to full affine transformations (Baumberg, 2000; T uytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman , 2002; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 128
                            }
                        ],
                        "text": "Recently, there has been an impressive body of work on extending local features to be invariant to full affine transformations (Baumberg, 2000; Tuytelaars and Van Gool, 2000; Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reliable feature matching across widely"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 14
                            }
                        ],
                        "text": "Adjacent image scales are subtracted to produce the difference-of-Gaussian images shown on the right."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wide baseline stereo based on local, affinely invariant regions"
            },
            "venue": {
                "fragments": [],
                "text": "British Machine Vision Conference, Bristol, UK, pp. 412\u2013422."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 177
                            }
                        ],
                        "text": "The features described in this paper use only a monochrome intensity image, so further distinctiveness could be derived from including illumination-invariant color descriptors (Funt and Finlayson, 1995; Brown and Lowe, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Color constant color"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 43
                            }
                        ],
                        "text": "Some of the first work in this area was by Crowley and Parker (1984), who developed a representation that identified peaks and ridges in scale space and linked these into a tree structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A representation for sh"
            },
            "venue": {
                "fragments": [],
                "text": "Vision (ECCV),Copenhagen,"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "At the same time, a similar approach was developed by Torr (1995) for long-range motion matching, in which geometric constraints were used to remove outliers for rigid objects moving within an image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Motion Segmentation and Outlier Detection"
            },
            "venue": {
                "fragments": [],
                "text": "Motion Segmentation and Outlier Detection"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 145
                            }
                        ],
                        "text": "Fortunately, much better performance can be obtained by clustering features in pose space using the Hough transform (Hough, 1962; Ballard, 1981; Grimson, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1990.Object Recognition by Computer: The Role of Geometric Const"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phase-based local feat"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "At the same time, a similar approach was developed by Torr (1995) for long-range motion matching, in which geometric constraints were used to remove outliers for rigid objects moving within an image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1995.Motion Segmentation and Outlier Detection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 130
                            }
                        ],
                        "text": "Fortunately, much better performance can be obtained by clustering features in pose space using the Hough transform (Hough, 1962; Ballard, 1981; Grimson, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalizing the Hough transform to detect arbitrary patterns"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition, 13(2):111\u2013122."
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Complex cellsand object recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalizing the Hough transform to detect arbitrary patterns"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 117
                            }
                        ],
                        "text": "Fortunately, much better performance can be obtained by clustering features in pose space using the Hough transform (Hough, 1962; Ballard, 1981; Grimson, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Method and means for recognizing complex patterns"
            },
            "venue": {
                "fragments": [],
                "text": "U.S. Patent 3069654."
            },
            "year": 1962
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 41,
            "methodology": 23
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 75,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Distinctive-Image-Features-from-Scale-Invariant-Lowe/8c04f169203f9e55056a6f7f956695babe622a38?sort=total-citations"
}