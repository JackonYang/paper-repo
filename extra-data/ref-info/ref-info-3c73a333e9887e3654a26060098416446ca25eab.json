{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107918894"
                        ],
                        "name": "Chunmei Liu",
                        "slug": "Chunmei-Liu",
                        "structuredName": {
                            "firstName": "Chunmei",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chunmei Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683416"
                        ],
                        "name": "Chunheng Wang",
                        "slug": "Chunheng-Wang",
                        "structuredName": {
                            "firstName": "Chunheng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chunheng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145841729"
                        ],
                        "name": "Ruwei Dai",
                        "slug": "Ruwei-Dai",
                        "structuredName": {
                            "firstName": "Ruwei",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruwei Dai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Candidate CCs are extracted by the proposed method in [10] based on edge contour properties, then text-free components are pruned by analysis of wavelet coefficients."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "The method introduced in [10] produces a statistical-based feature vector using the Sobel edge map and applies kmeans algorithm to classify image regions into text and non-text parts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9821585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04925a1e7566a1ace8a4603ef5917b5f5bcb31ff",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, an algorithm is proposed for detecting texts in images and video frames. It is performed by three steps: edge detection, text candidate detection and text refinement detection. Firstly, it applies edge detection to get four edge maps in horizontal, vertical, up-right, and up-left direction. Secondly, the feature is extracted from four edge maps to represent the texture property of text. Then k-means algorithm is applied to detect the initial text candidates. Finally, the text areas are identified by the empirical rules analysis and refined through project profile analysis. Experimental results demonstrate that the proposed approach could efficiently be used as an automatic text detection system, which is robust for font size, font color, background complexity and language."
            },
            "slug": "Text-detection-in-images-based-on-unsupervised-of-Liu-Wang",
            "title": {
                "fragments": [],
                "text": "Text detection in images based on unsupervised classification of edge-based features"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results demonstrate that the proposed approach could efficiently be used as an automatic text detection system, which is robust for font size, font color, background complexity and language."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785083"
                        ],
                        "name": "Michael R. Lyu",
                        "slug": "Michael-R.-Lyu",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lyu",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael R. Lyu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3332642"
                        ],
                        "name": "Jiqiang Song",
                        "slug": "Jiqiang-Song",
                        "structuredName": {
                            "firstName": "Jiqiang",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiqiang Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052052370"
                        ],
                        "name": "Min Cai",
                        "slug": "Min-Cai",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Cai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "As examples of such methods, the technique introduced in [1] applies Sobel edge detector in all Y, U, and V channels, then invariant features such as edge strength, edge density, and edge\u2019s horizontal distribution are considered."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12862847,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f64a1d2e366eb476be69cc431f053dcaa22935a",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Text detection is fundamental to video information retrieval and indexing. Existing methods cannot handle well those texts with different contrast or embedded in a complex background. To handle these difficulties, this paper proposes an efficient text detection approach, which is based on invariant features, such as edge strength, edge density, and horizontal distribution. First, it applies edge detection and uses a low threshold to filter out definitely non-text edges. Then, a local threshold is selected to both keep low-contrast text and simplify complex background of high-contrast text. Next, two text-area enhancement operators are proposed to highlight those areas with either high edge strength or high edge density. Finally, coarse-to-fine detection locates text regions efficiently. Experimental results show that this approach is robust for contrast, font-size, font-color, language, and background complexity."
            },
            "slug": "A-new-approach-for-video-text-detection-Lyu-Song",
            "title": {
                "fragments": [],
                "text": "A new approach for video text detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes an efficient text detection approach, which is based on invariant features, such as edge strength, edge density, and horizontal distribution, and it applies edge detection and uses a low threshold to filter out definitely non-text edges."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. International Conference on Image Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2522004"
                        ],
                        "name": "J. Gllavata",
                        "slug": "J.-Gllavata",
                        "structuredName": {
                            "firstName": "Julinda",
                            "lastName": "Gllavata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gllavata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738703"
                        ],
                        "name": "R. Ewerth",
                        "slug": "R.-Ewerth",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Ewerth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ewerth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685922"
                        ],
                        "name": "B. Freisleben",
                        "slug": "B.-Freisleben",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Freisleben",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Freisleben"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "A k-means classification is applied in wavelet domain in [5] in order to detect the horizontally aligned texts in an image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 31975917,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "593e78f18ba5f5577b34ed81663db3e5d7d569cd",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Text localization and recognition in images is important for searching information in digital photo archives, video databases and Web sites. However, since text is often printed against a complex background, it is often difficult to detect. In this paper, a robust text localization approach is presented, which can automatically detect horizontally aligned text with different sizes, fonts, colors and languages. First, a wavelet transform is applied to the image and the distribution of high-frequency wavelet coefficients is considered to statistically characterize text and non-text areas. Then, the k-means algorithm is used to classify text areas in the image. The detected text areas undergo a projection analysis in order to refine their localization. Finally, a binary segmented text image is generated, to be used as input to an OCR engine. The detection performance of our approach is demonstrated by presenting experimental results for a set of video frames taken from the MPEG-7 video test set."
            },
            "slug": "Text-detection-in-images-based-on-unsupervised-of-Gllavata-Ewerth",
            "title": {
                "fragments": [],
                "text": "Text detection in images based on unsupervised classification of high-frequency wavelet coefficients"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A robust text localization approach is presented, which can automatically detect horizontally aligned text with different sizes, fonts, colors and languages and is demonstrated by presenting experimental results for a set of video frames taken from the MPEG-7 video test set."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152526333"
                        ],
                        "name": "Ming Zhao",
                        "slug": "Ming-Zhao",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116066317"
                        ],
                        "name": "Shutao Li",
                        "slug": "Shutao-Li",
                        "structuredName": {
                            "firstName": "Shutao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shutao Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145193332"
                        ],
                        "name": "J. Kwok",
                        "slug": "J.-Kwok",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kwok",
                            "middleNames": [
                                "Tin-Yau"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kwok"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "The introduced method in [29] benefits from two learned"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18340818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f5f802bf01c8632dda4586b05bc86fc4878326f",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-detection-in-images-using-sparse-with-Zhao-Li",
            "title": {
                "fragments": [],
                "text": "Text detection in images using sparse representation with discriminative dictionaries"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744575"
                        ],
                        "name": "P. Shivakumara",
                        "slug": "P.-Shivakumara",
                        "structuredName": {
                            "firstName": "Palaiahnakote",
                            "lastName": "Shivakumara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Shivakumara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715066"
                        ],
                        "name": "T. Phan",
                        "slug": "T.-Phan",
                        "structuredName": {
                            "firstName": "Trung",
                            "lastName": "Phan",
                            "middleNames": [
                                "Quy"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Phan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679749"
                        ],
                        "name": "C. Tan",
                        "slug": "C.-Tan",
                        "structuredName": {
                            "firstName": "Chew",
                            "lastName": "Tan",
                            "middleNames": [
                                "Lim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [23] the CCs are found by k-means clustering in the Fourier-Laplacian domain."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 196066575,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1755d99d89dee5915df1df4a7991b87138e93c78",
            "isKey": false,
            "numCitedBy": 296,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a method based on the Laplacian in the frequency domain for video text detection. Unlike many other approaches which assume that text is horizontally-oriented, our method is able to handle text of arbitrary orientation. The input image is first filtered with Fourier-Laplacian. K-means clustering is then used to identify candidate text regions based on the maximum difference. The skeleton of each connected component helps to separate the different text strings from each other. Finally, text string straightness and edge density are used for false positive elimination. Experimental results show that the proposed method is able to handle graphics text and scene text of both horizontal and nonhorizontal orientation."
            },
            "slug": "A-Laplacian-Approach-to-Multi-Oriented-Text-in-Shivakumara-Phan",
            "title": {
                "fragments": [],
                "text": "A Laplacian Approach to Multi-Oriented Text Detection in Video"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results show that the proposed method is able to handle graphics text and scene text of both horizontal and nonhorizontal orientation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49177577"
                        ],
                        "name": "Huizhong Chen",
                        "slug": "Huizhong-Chen",
                        "structuredName": {
                            "firstName": "Huizhong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huizhong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778174"
                        ],
                        "name": "Sam S. Tsai",
                        "slug": "Sam-S.-Tsai",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Tsai",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sam S. Tsai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701294"
                        ],
                        "name": "Georg Schroth",
                        "slug": "Georg-Schroth",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Schroth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georg Schroth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12600623"
                        ],
                        "name": "David M. Chen",
                        "slug": "David-M.-Chen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chen",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2026212"
                        ],
                        "name": "R. Grzeszczuk",
                        "slug": "R.-Grzeszczuk",
                        "structuredName": {
                            "firstName": "Radek",
                            "lastName": "Grzeszczuk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grzeszczuk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739786"
                        ],
                        "name": "B. Girod",
                        "slug": "B.-Girod",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Girod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Girod"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "A CC-based algorithm is introduced in [2], which employs Maximally Stable Extremal Regions (MSER) as the basic letter candidates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11311196,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6cb3153e5773053916a27bf3ab4530705a6bcf80",
            "isKey": false,
            "numCitedBy": 444,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting text in natural images is an important prerequisite. In this paper, we propose a novel text detection algorithm, which employs edge-enhanced Maximally Stable Extremal Regions as basic letter candidates. These candidates are then filtered using geometric and stroke width information to exclude non-text objects. Letters are paired to identify text lines, which are subsequently separated into words. We evaluate our system using the ICDAR competition dataset and our mobile document database. The experimental results demonstrate the excellent performance of the proposed method."
            },
            "slug": "Robust-text-detection-in-natural-images-with-Stable-Chen-Tsai",
            "title": {
                "fragments": [],
                "text": "Robust text detection in natural images with edge-enhanced Maximally Stable Extremal Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A novel text detection algorithm is proposed, which employs edge-enhanced Maximally Stable Extremal Regions as basic letter candidates and Letters are paired to identify text lines, which are subsequently separated into words."
            },
            "venue": {
                "fragments": [],
                "text": "2011 18th IEEE International Conference on Image Processing"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144602022"
                        ],
                        "name": "K. Kim",
                        "slug": "K.-Kim",
                        "structuredName": {
                            "firstName": "Kwang",
                            "lastName": "Kim",
                            "middleNames": [
                                "In"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121267347"
                        ],
                        "name": "K. Jung",
                        "slug": "K.-Jung",
                        "structuredName": {
                            "firstName": "Keechul",
                            "lastName": "Jung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Jung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152675651"
                        ],
                        "name": "J. Kim",
                        "slug": "J.-Kim",
                        "structuredName": {
                            "firstName": "Jin",
                            "lastName": "Kim",
                            "middleNames": [
                                "Hyung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "A support vector machine (SVM) classifier is used in [7] to generate text maps from the gray-level features of all local areas."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17901853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14bbcdc1744cc5982ffb64ea4755a72921d98d08",
            "isKey": false,
            "numCitedBy": 503,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "The current paper presents a novel texture-based method for detecting texts in images. A support vector machine (SVM) is used to analyze the textural properties of texts. No external texture feature extraction module is used, but rather the intensities of the raw pixels that make up the textural pattern are fed directly to the SVM, which works well even in high-dimensional spaces. Next, text regions are identified by applying a continuously adaptive mean shift algorithm (CAMSHIFT) to the results of the texture analysis. The combination of CAMSHIFT and SVMs produces both robust and efficient text detection, as time-consuming texture analyses for less relevant pixels are restricted, leaving only a small part of the input image to be texture-analyzed."
            },
            "slug": "Texture-Based-Approach-for-Text-Detection-in-Images-Kim-Jung",
            "title": {
                "fragments": [],
                "text": "Texture-Based Approach for Text Detection in Images Using Support Vector Machines and Continuously Adaptive Mean Shift Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The combination of CAMSHIFT and SVMs produces both robust and efficient text detection, as time-consuming texture analyses for less relevant pixels are restricted, leaving only a small part of the input image to be texture-analyzed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38340927"
                        ],
                        "name": "Yi-Feng Pan",
                        "slug": "Yi-Feng-Pan",
                        "structuredName": {
                            "firstName": "Yi-Feng",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi-Feng Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761961"
                        ],
                        "name": "Xinwen Hou",
                        "slug": "Xinwen-Hou",
                        "structuredName": {
                            "firstName": "Xinwen",
                            "lastName": "Hou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinwen Hou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689269"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "As an example, the proposed method in [18] is a hybrid technique whose first step detects text regions in each layer of image pyramid and projects the text confidence and scale information back to the original image followed by a local binarization to generate candidate text components."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10564829,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a79f43246bed540084ca2d1fcf99a68c69820747",
            "isKey": false,
            "numCitedBy": 410,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Text detection and localization in natural scene images is important for content-based image analysis. This problem is challenging due to the complex background, the non-uniform illumination, the variations of text font, size and line orientation. In this paper, we present a hybrid approach to robustly detect and localize texts in natural scene images. A text region detector is designed to estimate the text existing confidence and scale information in image pyramid, which help segment candidate text components by local binarization. To efficiently filter out the non-text components, a conditional random field (CRF) model considering unary component properties and binary contextual component relationships with supervised parameter learning is proposed. Finally, text components are grouped into text lines/words with a learning-based energy minimization method. Since all the three stages are learning-based, there are very few parameters requiring manual tuning. Experimental results evaluated on the ICDAR 2005 competition dataset show that our approach yields higher precision and recall performance compared with state-of-the-art methods. We also evaluated our approach on a multilingual image dataset with promising results."
            },
            "slug": "A-Hybrid-Approach-to-Detect-and-Localize-Texts-in-Pan-Hou",
            "title": {
                "fragments": [],
                "text": "A Hybrid Approach to Detect and Localize Texts in Natural Scene Images"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A hybrid approach to robustly detect and localize texts in natural scene images using a text region detector, a conditional random field model, and a learning-based energy minimization method are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785083"
                        ],
                        "name": "Michael R. Lyu",
                        "slug": "Michael-R.-Lyu",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lyu",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael R. Lyu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3332642"
                        ],
                        "name": "Jiqiang Song",
                        "slug": "Jiqiang-Song",
                        "structuredName": {
                            "firstName": "Jiqiang",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiqiang Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052052370"
                        ],
                        "name": "Min Cai",
                        "slug": "Min-Cai",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Cai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "The proposed method in [13] also takes advantage of image pyramids to find local thresholds to detect text areas."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18648576,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e14cf92ecb1589d21324d934b2009451e602d1be",
            "isKey": false,
            "numCitedBy": 371,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Text in video is a very compact and accurate clue for video indexing and summarization. Most video text detection and extraction methods hold assumptions on text color, background contrast, and font style. Moreover, few methods can handle multilingual text well since different languages may have quite different appearances. This paper performs a detailed analysis of multilingual text characteristics, including English and Chinese. Based on the analysis, we propose a comprehensive, efficient video text detection, localization, and extraction method, which emphasizes the multilingual capability over the whole processing. The proposed method is also robust to various background complexities and text appearances. The text detection is carried out by edge detection, local thresholding, and hysteresis edge recovery. The coarse-to-fine localization scheme is then performed to identify text regions accurately. The text extraction consists of adaptive thresholding, dam point labeling, and inward filling. Experimental results on a large number of video images and comparisons with other methods are reported in detail."
            },
            "slug": "A-comprehensive-method-for-multilingual-video-text-Lyu-Song",
            "title": {
                "fragments": [],
                "text": "A comprehensive method for multilingual video text detection, localization, and extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A comprehensive, efficient video text detection, localization, and extraction method, which emphasizes the multilingual capability over the whole processing, and is also robust to various background complexities and text appearances."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Circuits and Systems for Video Technology"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3314902"
                        ],
                        "name": "Edward K. Wong",
                        "slug": "Edward-K.-Wong",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Wong",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward K. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50133585"
                        ],
                        "name": "Minya Chen",
                        "slug": "Minya-Chen",
                        "structuredName": {
                            "firstName": "Minya",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minya Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "Assuming that the horizontal gradient value of text regions is higher than that of other parts of the image, the proposed method in [27] thresholds the variance of gradient values to identify text-regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20048852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5b1f30c7f3f172c6e230a49315c8c0040a6c4b4",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-new-robust-algorithm-for-video-text-extraction-Wong-Chen",
            "title": {
                "fragments": [],
                "text": "A new robust algorithm for video text extraction"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143827634"
                        ],
                        "name": "H. Takahashi",
                        "slug": "H.-Takahashi",
                        "structuredName": {
                            "firstName": "Hiroki",
                            "lastName": "Takahashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Takahashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2865018"
                        ],
                        "name": "M. Nakajima",
                        "slug": "M.-Nakajima",
                        "structuredName": {
                            "firstName": "Masayuki",
                            "lastName": "Nakajima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nakajima"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "The method introduced in [25] finds candidate text regions utilizing Canny edge detector, then a region pruning step is carried out by means of an adjacency graph and some heuristic rules based on local components features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18464089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b25ce94743a451caba3f3264acebf28f54ee1de7",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A graph-based texts extraction scheme using region similarities is proposed. In graph-based text extraction method, region graph is generated based on the extracted character element regions from edge images. The edge weights of the graph are defined by their representative colors, positions, area sizes and aspect ratios of their bounding boxes. The MST is obtained from the graph, since sets of similar regions are the most significant factors in texts extraction techniques. Then, texts blocks with small edge weights are obtained from the MST. Finally, texts regions which satisfy texts conditions are extracted from these subsets. The proposed method extracts texts under complex shadows and low contrast images."
            },
            "slug": "Region-graph-based-text-extraction-from-outdoor-Takahashi-Nakajima",
            "title": {
                "fragments": [],
                "text": "Region graph based text extraction from outdoor images"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A graph-based texts extraction scheme using region similarities is proposed, which extracts texts under complex shadows and low contrast images."
            },
            "venue": {
                "fragments": [],
                "text": "Third International Conference on Information Technology and Applications (ICITA'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121267347"
                        ],
                        "name": "K. Jung",
                        "slug": "K.-Jung",
                        "structuredName": {
                            "firstName": "Keechul",
                            "lastName": "Jung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Jung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144602022"
                        ],
                        "name": "K. Kim",
                        "slug": "K.-Kim",
                        "structuredName": {
                            "firstName": "Kwang",
                            "lastName": "Kim",
                            "middleNames": [
                                "In"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 213
                            }
                        ],
                        "text": "Text detection is still a challenging issue due to unconstrained color, sizes, alignments of characters, lighting and also various shapes of fonts, even though various methods have been proposed in the past years [6, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5999466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cedf72be1fe814ef2ee9d65633dc3226f80f0785",
            "isKey": false,
            "numCitedBy": 936,
            "numCiting": 100,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-information-extraction-in-images-and-video:-a-Jung-Kim",
            "title": {
                "fragments": [],
                "text": "Text information extraction in images and video: a survey"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126798"
                        ],
                        "name": "B. Epshtein",
                        "slug": "B.-Epshtein",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Epshtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Epshtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20592981"
                        ],
                        "name": "E. Ofek",
                        "slug": "E.-Ofek",
                        "structuredName": {
                            "firstName": "Eyal",
                            "lastName": "Ofek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ofek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743988"
                        ],
                        "name": "Y. Wexler",
                        "slug": "Y.-Wexler",
                        "structuredName": {
                            "firstName": "Yonatan",
                            "lastName": "Wexler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wexler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "Specifically, our approach outperforms the SWT-based method introduced in [4] already shown to have a good performance compared to several other existing methods [4] including the participating algorithms in ICDAR 2003 [12] and ICDAR 2005 [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "A useful operator is defined in [4] to find stroke width of each image pixel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "The technique applies SWT introduced in [4] in order to obtain reasonable text CCs and text features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8890220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39c4ae83b5c92e0fa55de1ec7e5cf12589c408db",
            "isKey": false,
            "numCitedBy": 1470,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel image operator that seeks to find the value of stroke width for each image pixel, and demonstrate its use on the task of text detection in natural images. The suggested operator is local and data dependent, which makes it fast and robust enough to eliminate the need for multi-scale computation or scanning windows. Extensive testing shows that the suggested scheme outperforms the latest published algorithms. Its simplicity allows the algorithm to detect texts in many fonts and languages."
            },
            "slug": "Detecting-text-in-natural-scenes-with-stroke-width-Epshtein-Ofek",
            "title": {
                "fragments": [],
                "text": "Detecting text in natural scenes with stroke width transform"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A novel image operator is presented that seeks to find the value of stroke width for each image pixel, and its use on the task of text detection in natural images is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115196978"
                        ],
                        "name": "Huiping Li",
                        "slug": "Huiping-Li",
                        "structuredName": {
                            "firstName": "Huiping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huiping Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3272081"
                        ],
                        "name": "O. Kia",
                        "slug": "O.-Kia",
                        "structuredName": {
                            "firstName": "Omid",
                            "lastName": "Kia",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "The proposed technique in [8] employs the first and second-order moments of wavelet coefficients of local regions as features, then a classification is performed by means of neural networks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15485643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8f5c282dc11937d29183b955dc3e4fbb677571b",
            "isKey": false,
            "numCitedBy": 652,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Text that appears in a scene or is graphically added to video can provide an important supplemental source of index information as well as clues for decoding the video's structure and for classification. In this work, we present algorithms for detecting and tracking text in digital video. Our system implements a scale-space feature extractor that feeds an artificial neural processor to detect text blocks. Our text tracking scheme consists of two modules: a sum of squared difference (SSD)-based module to find the initial position and a contour-based module to refine the position. Experiments conducted with a variety of video sources show that our scheme can detect and track text robustly."
            },
            "slug": "Automatic-text-detection-and-tracking-in-digital-Li-Doermann",
            "title": {
                "fragments": [],
                "text": "Automatic text detection and tracking in digital video"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents algorithms for detecting and tracking text in digital video that implements a scale-space feature extractor that feeds an artificial neural processor to detect text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3148558"
                        ],
                        "name": "S. Zhong",
                        "slug": "S.-Zhong",
                        "structuredName": {
                            "firstName": "Sifen",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zhong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 40
                            }
                        ],
                        "text": "On the other hand, it has been shown in [17, 28] that finding local maxima of wavelet transform coefficients is similar to the multiscale Canny edge detector operator."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 5698299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f42d06ff2160dae7412c299619c04f63395b784b",
            "isKey": false,
            "numCitedBy": 3302,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A multiscale Canny edge detection is equivalent to finding the local maxima of a wavelet transform. The authors study the properties of multiscale edges through the wavelet theory. For pattern recognition, one often needs to discriminate different types of edges. They show that the evolution of wavelet local maxima across scales characterize the local shape of irregular structures. Numerical descriptors of edge types are derived. The completeness of a multiscale edge representation is also studied. The authors describe an algorithm that reconstructs a close approximation of 1-D and 2-D signals from their multiscale edges. For images, the reconstruction errors are below visual sensitivity. As an application, a compact image coding algorithm that selects important edges and compresses the image data by factors over 30 has been implemented. >"
            },
            "slug": "Characterization-of-Signals-from-Multiscale-Edges-Mallat-Zhong",
            "title": {
                "fragments": [],
                "text": "Characterization of Signals from Multiscale Edges"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The authors describe an algorithm that reconstructs a close approximation of 1-D and 2-D signals from their multiscale edges and shows that the evolution of wavelet local maxima across scales characterize the local shape of irregular structures."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145481009"
                        ],
                        "name": "G. Peyr\u00e9",
                        "slug": "G.-Peyr\u00e9",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Peyr\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Peyr\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "For more details about bandlets the reader is referred to [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 48
                            }
                        ],
                        "text": "(a) (b) (c) (d) (e) Figure 1: Bandlet transform [16, 24]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Bandlet transform [16] exploits such anisotropic regularity."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6137971,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "0639afbdc91c1295d3b2fcac85274cf5d2cdd389",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This article reviews bandlet approaches to geometric image representations. Orthogonal bandlets using an adaptive segmentation and a local geometric flow well suited to capture the anisotropic regularity of edge structures. They are constructed with a \u201cbandletization\u201d which is a local orthogonal transformation applied to wavelet coefficients. The approximation in these bandlet bases exhibits an asymptotically optimal decay for images that are regular outside a set of regular edges. These bandlets can be used to perform image compression and noise removal. More flexible orthogonal bandlets with less vanishing moments are constructed with orthogonal grouplets that group wavelet coefficients alon a multiscale association field. Applying a translation invariant grouplet transform over a translation invariant wavelet frame leads to state of the art results for image denoising and super-resolution."
            },
            "slug": "A-review-of-Bandlet-methods-for-geometrical-image-Mallat-Peyr\u00e9",
            "title": {
                "fragments": [],
                "text": "A review of Bandlet methods for geometrical image representation"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This article reviews bandlet approaches to geometric image representations using an adaptive segmentation and a local geometric flow well suited to capture the anisotropic regularity of edge structures to lead to state of the art results for image denoising and super-resolution."
            },
            "venue": {
                "fragments": [],
                "text": "Numerical Algorithms"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144752865"
                        ],
                        "name": "Jian Liang",
                        "slug": "Jian-Liang",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115196978"
                        ],
                        "name": "Huiping Li",
                        "slug": "Huiping-Li",
                        "structuredName": {
                            "firstName": "Huiping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huiping Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 213
                            }
                        ],
                        "text": "Text detection is still a challenging issue due to unconstrained color, sizes, alignments of characters, lighting and also various shapes of fonts, even though various methods have been proposed in the past years [6, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5053740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82b6f95e805a92887f8efccf5a0dc8d5783676f5",
            "isKey": false,
            "numCitedBy": 457,
            "numCiting": 131,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.The increasing availability of high-performance, low-priced, portable digital imaging devices has created a tremendous opportunity for supplementing traditional scanning for document image acquisition. Digital cameras attached to cellular phones, PDAs, or wearable computers, and standalone image or video devices are highly mobile and easy to use; they can capture images of thick books, historical manuscripts too fragile to touch, and text in scenes, making them much more versatile than desktop scanners. Should robust solutions to the analysis of documents captured with such devices become available, there will clearly be a demand in many domains. Traditional scanner-based document analysis techniques provide us with a good reference and starting point, but they cannot be used directly on camera-captured images. Camera-captured images can suffer from low resolution, blur, and perspective distortion, as well as complex layout and interaction of the content and background. In this paper we present a survey of application domains, technical challenges, and solutions for the analysis of documents captured by digital cameras. We begin by describing typical imaging devices and the imaging process. We discuss document analysis from a single camera-captured image as well as multiple frames and highlight some sample applications under development and feasible ideas for future development."
            },
            "slug": "Camera-based-analysis-of-text-and-documents:-a-Liang-Doermann",
            "title": {
                "fragments": [],
                "text": "Camera-based analysis of text and documents: a survey"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A survey of application domains, technical challenges, and solutions for the analysis of documents captured by digital cameras, and some sample applications under development and feasible ideas for future development is presented."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39319377"
                        ],
                        "name": "Yu Zhong",
                        "slug": "Yu-Zhong",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "In the same vein, the proposed method in [30] applies frequency domain coefficients obtained by discrete cosine transform (DCT) to extract features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6781817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7721138e41d82fedabca59c9a66e67d9b7053f3",
            "isKey": false,
            "numCitedBy": 330,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to automatically locate captions in MPEG video. Caption text regions are segmented from the background using their distinguishing texture characteristics. This method first locates candidate text regions directly in the DCT compressed domain, and then reconstructs the candidate regions for further refinement in the spatial domain. Therefore, only a small amount of decoding is required. The proposed algorithm achieves about 4.0% false reject rate and less than 5.7% false positive rate on a variety of MPEG compressed video containing more than 42,000 frames."
            },
            "slug": "Automatic-caption-localization-in-compressed-video-Zhong-Zhang",
            "title": {
                "fragments": [],
                "text": "Automatic caption localization in compressed video"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This method first locates candidate text regions directly in the DCT compressed domain, and then reconstructs the candidate regions for further refinement in the spatial domain, so that only a small amount of decoding is required."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1845031"
                        ],
                        "name": "E. L. Pennec",
                        "slug": "E.-L.-Pennec",
                        "structuredName": {
                            "firstName": "Erwan",
                            "lastName": "Pennec",
                            "middleNames": [
                                "Le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. L. Pennec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 26
                            }
                        ],
                        "text": "The earlier bandlet bases [20, 21] have been improved by a multi-scale geometry defined over wavelet coefficients [15, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2112160,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67b1cc159aacf2f30239577e6cf7a741b64f31e0",
            "isKey": false,
            "numCitedBy": 929,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a new class of bases, called bandelet bases, which decompose the image along multiscale vectors that are elongated in the direction of a geometric flow. This geometric flow indicates directions in which the image gray levels have regular variations. The image decomposition in a bandelet basis is implemented with a fast subband-filtering algorithm. Bandelet bases lead to optimal approximation rates for geometrically regular images. For image compression and noise removal applications, the geometric flow is optimized with fast algorithms so that the resulting bandelet basis produces minimum distortion. Comparisons are made with wavelet image compression and noise-removal algorithms."
            },
            "slug": "Sparse-geometric-image-representations-with-Pennec-Mallat",
            "title": {
                "fragments": [],
                "text": "Sparse geometric image representations with bandelets"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A new class of bases are introduced, called bandelet bases, which decompose the image along multiscale vectors that are elongated in the direction of a geometric flow, which leads to optimal approximation rates for geometrically regular images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 239
                            }
                        ],
                        "text": "Specifically, our approach outperforms the SWT-based method introduced in [4] already shown to have a good performance compared to several other existing methods [4] including the participating algorithms in ICDAR 2003 [12] and ICDAR 2005 [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "The effectiveness of this method is reported in ICDAR 2005 results [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 99
                            }
                        ],
                        "text": "We followed the same evaluation scheme by means of Precision and Recall used in ICDAR competitions [11, 12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "We evaluated our approach on the ICDAR text locating contest dataset [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1842569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbf50fe5622253f401e892ed943a18033e18b7b9",
            "isKey": true,
            "numCitedBy": 318,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the results of the ICDAR 2005 competition for locating text in camera captured scenes. For this we used the same data as the ICDAR 2003 competition, which has been kept private until now. This allows a direct comparison with the 2003 entries. The main result is that the leading 2005 entry has improved significantly on the leading 2003 entry, with an increase in average f-score from 0.5 to 0.62, where the f-score is the same adapted information retrieval measure used for the 2003 competition. The paper also discusses the Web-based deployment and evaluation of text locating systems, and one of the leading entries has now been deployed in this way. This mode of usage could lead to more complete and more immediate knowledge of the strengths and weaknesses of each newly developed system."
            },
            "slug": "ICDAR-2005-text-locating-competition-results-Lucas",
            "title": {
                "fragments": [],
                "text": "ICDAR 2005 text locating competition results"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The main result is that the leading 2005 entry has improved significantly on the leading 2003 entry, with an increase in average f- score from 0.5 to 0.62, where the f-score is the same adapted information retrieval measure used for the 2003 competition."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87531536"
                        ],
                        "name": "A. Panaretos",
                        "slug": "A.-Panaretos",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Panaretos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Panaretos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073684197"
                        ],
                        "name": "Luis Sosa",
                        "slug": "Luis-Sosa",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Sosa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis Sosa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052189571"
                        ],
                        "name": "Anthony Tang",
                        "slug": "Anthony-Tang",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108862960"
                        ],
                        "name": "Shirley Wong",
                        "slug": "Shirley-Wong",
                        "structuredName": {
                            "firstName": "Shirley",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shirley Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114080648"
                        ],
                        "name": "Robert Young",
                        "slug": "Robert-Young",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 219
                            }
                        ],
                        "text": "Specifically, our approach outperforms the SWT-based method introduced in [4] already shown to have a good performance compared to several other existing methods [4] including the participating algorithms in ICDAR 2003 [12] and ICDAR 2005 [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 99
                            }
                        ],
                        "text": "We followed the same evaluation scheme by means of Precision and Recall used in ICDAR competitions [11, 12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6379469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce39eb5cc1049a1060a499d6b6e94c8b2ec11da1",
            "isKey": false,
            "numCitedBy": 591,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the robust reading competitions forICDAR 2003. With the rapid growth in research over thelast few years on recognizing text in natural scenes, thereis an urgent need to establish some common benchmarkdatasets, and gain a clear understanding of the current stateof the art. We use the term robust reading to refer to text imagesthat are beyond the capabilities of current commercialOCR packages. We chose to break down the robust readingproblem into three sub-problems, and run competitionsfor each stage, and also a competition for the best overallsystem. The sub-problems we chose were text locating,character recognition and word recognition.By breaking down the problem in this way, we hope togain a better understanding of the state of the art in eachof the sub-problems. Furthermore, our methodology involvesstoring detailed results of applying each algorithm toeach image in the data sets, allowing researchers to study indepth the strengths and weaknesses of each algorithm. Thetext locating contest was the only one to have any entries.We report the results of this contest, and show cases wherethe leading algorithms succeed and fail."
            },
            "slug": "ICDAR-2003-robust-reading-competitions-Lucas-Panaretos",
            "title": {
                "fragments": [],
                "text": "ICDAR 2003 robust reading competitions"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The robust reading problem was broken down into three sub-problems, and competitions for each stage, and also a competition for the best overall system, which was the only one to have any entries."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101586654"
                        ],
                        "name": "W. Zhang",
                        "slug": "W.-Zhang",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Zhang",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107488974"
                        ],
                        "name": "Q. Zhang",
                        "slug": "Q.-Zhang",
                        "structuredName": {
                            "firstName": "Q.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46962092"
                        ],
                        "name": "C. Yang",
                        "slug": "C.-Yang",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 40
                            }
                        ],
                        "text": "On the other hand, it has been shown in [17, 28] that finding local maxima of wavelet transform coefficients is similar to the multiscale Canny edge detector operator."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 108610608,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "1a347d291e1cf934c5f2ddf5021b7d121203e4ba",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A despeckling algorithm of a synthetic aperture radar (SAR) image is proposed, which can effectively preserve edges while cleanly despeckling. The proposed algorithm is robust, simple, and effective, without any a priori information, which employs multiscale products in stationary bandlet transform (SBT) domain to detect edges, and utilises SBT to denoise the edge-removed image. Experimental results show that the visual quality and evaluation indexes of the proposed algorithm outperform that of Lee filtering."
            },
            "slug": "Edge-detection-with-multiscale-products-for-SAR-Zhang-Zhang",
            "title": {
                "fragments": [],
                "text": "Edge detection with multiscale products for SAR image despeckling"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2599292"
                        ],
                        "name": "J. Mairal",
                        "slug": "J.-Mairal",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Mairal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mairal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699339"
                        ],
                        "name": "G. Sapiro",
                        "slug": "G.-Sapiro",
                        "structuredName": {
                            "firstName": "Guillermo",
                            "lastName": "Sapiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sapiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "Also, the text and non-text regions are distinguished by the reconstruction error function defined in [14] for the dictionary patches and the original image patches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "The dictionaries are generated using the platform introduced in [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 428083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a072cbdee54b83c8df43a431065f009d2cd2e70",
            "isKey": false,
            "numCitedBy": 818,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse signal models have been the focus of much recent research, leading to (or improving upon) state-of-the-art results in signal, image, and video restoration. This article extends this line of research into a novel framework for local image discrimination tasks, proposing an energy formulation with both sparse reconstruction and class discrimination components, jointly optimized during dictionary learning. This approach improves over the state of the art in texture segmentation experiments using the Brodatz database, and it paves the way for a novel scene analysis and recognition framework based on simultaneously learning discriminative and reconstructive dictionaries. Preliminary results in this direction using examples from the Pascal VOC06 and Graz02 datasets are presented as well."
            },
            "slug": "Discriminative-learned-dictionaries-for-local-image-Mairal-Bach",
            "title": {
                "fragments": [],
                "text": "Discriminative learned dictionaries for local image analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This article proposes an energy formulation with both sparse reconstruction and class discrimination components, jointly optimized during dictionary learning, for local image discrimination tasks, and paves the way for a novel scene analysis and recognition framework based on simultaneously learning discriminative and reconstructive dictionaries."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37756048"
                        ],
                        "name": "Jinshan Tang",
                        "slug": "Jinshan-Tang",
                        "structuredName": {
                            "firstName": "Jinshan",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinshan Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3054963"
                        ],
                        "name": "Jeonghoon Kim",
                        "slug": "Jeonghoon-Kim",
                        "structuredName": {
                            "firstName": "Jeonghoon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeonghoon Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802088"
                        ],
                        "name": "E. Peli",
                        "slug": "E.-Peli",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Peli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Peli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 47
                            }
                        ],
                        "text": "More complex contrast analysis can be found in [19, 26] by employing discrete cosine transform and wavelets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13159662,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "c812a82e72b8a9078d71445ec320350dfac5be7c",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "An image enhancement algorithm for low-vision patients was developed for images compressed using the JPEG standard. The proposed algorithm enhances the images in the discrete cosine transform domain by weighting the quantization table in the decoder. Our specific implementation increases the contrast at all bands of frequencies by an equal factor. The enhancement algorithm has four advantages: 1) low computational cost; 2) suitability for real-time application; 3) ease of adjustment by end-users (for example, adjusting a single parameter); and 4) less severe block artifacts as compared with conventional (post compression) enhancements. Experiments with visually impaired patients show improved perceived image quality at moderate levels of enhancement but rejection of artifacts caused by higher levels of enhancement."
            },
            "slug": "Image-enhancement-in-the-JPEG-domain-for-people-Tang-Kim",
            "title": {
                "fragments": [],
                "text": "Image enhancement in the JPEG domain for people with vision impairment"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experiments with visually impaired patients show improved perceived image quality at moderate levels of enhancement but rejection of artifacts caused by higher levels of Enhancement, suggesting a need for further research into this area."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Biomedical Engineering"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1845031"
                        ],
                        "name": "E. L. Pennec",
                        "slug": "E.-L.-Pennec",
                        "structuredName": {
                            "firstName": "Erwan",
                            "lastName": "Pennec",
                            "middleNames": [
                                "Le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. L. Pennec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 26
                            }
                        ],
                        "text": "The earlier bandlet bases [20, 21] have been improved by a multi-scale geometry defined over wavelet coefficients [15, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13017359,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "974b50edc233d80f93012a2663e3cd2f82403868",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Finding efficient geometric representations of images is a central issue to improving image compression and noise removal algorithms. We introduce bandelet orthogonal bases and frames that are adapted to the geometric regularity of an image. Images are approximated by finding a best bandelet basis or frame that produces a sparse representation. For functions that are uniformly regular outside a set of edge curves that are geometrically regular, the main theorem proves that bandelet approximations satisfy an optimal asymptotic error decay rate. A bandelet image compression scheme is derived. For computational applications, a fast discrete bandelet transform algorithm is introduced, with a fast best basis search which preserves asymptotic approximation and coding error decay rates."
            },
            "slug": "Bandelet-Image-Approximation-and-Compression-Pennec-Mallat",
            "title": {
                "fragments": [],
                "text": "Bandelet Image Approximation and Compression"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "For functions that are uniformly regular outside a set of edge curves that are geometrically regular, the main theorem proves that bandelet approximations satisfy an optimal asymptotic error decay rate."
            },
            "venue": {
                "fragments": [],
                "text": "Multiscale Model. Simul."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145481009"
                        ],
                        "name": "G. Peyr\u00e9",
                        "slug": "G.-Peyr\u00e9",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Peyr\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Peyr\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 114
                            }
                        ],
                        "text": "The earlier bandlet bases [20, 21] have been improved by a multi-scale geometry defined over wavelet coefficients [15, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3444489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "910dbccd118f38dfa65446cdb14ac89604850acc",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the construction of second generation bandelet bases and their application to 3D geometry compression. This new coding scheme is orthogonal and the corresponding basis functions are regular. In our method, surfaces are decomposed in a bandelet basis with a fast bandeletization algorithm that removes the geometric redundancy of orthogonal wavelet coefficients. The resulting transform coding scheme has an error decay that is asymptotically optimal for geometrically regular surfaces. We then use these bandelet bases to perform geometry image and normal map compression. Numerical tests show that for complex surfaces bandelets bring an improvement of 1.5dB to 2dB over state of the art compression schemes."
            },
            "slug": "Surface-compression-with-geometric-bandelets-Peyr\u00e9-Mallat",
            "title": {
                "fragments": [],
                "text": "Surface compression with geometric bandelets"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper describes the construction of second generation bandelet bases and their application to 3D geometry compression and has an error decay that is asymptotically optimal for geometrically regular surfaces."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145481009"
                        ],
                        "name": "G. Peyr\u00e9",
                        "slug": "G.-Peyr\u00e9",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Peyr\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Peyr\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8946083,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "2a5c3557ea65f3d543cc1fbf50bad92b654f9017",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces orthogonal bandelet bases to approximate images having some geometrical regularity. These bandelet bases are computed by applying parametrized Alpert transform operators over an orthogonal wavelet basis. These bandeletization operators depend upon a multiscale geometric flow that is adapted to the image at each wavelet scale. This bandelet construction has a hierarchical structure over wavelet coefficients taking advantage of existing regularity among these coefficients. It is proved that C\u03b1\u2010images having singularities along C\u03b1\u2010curves are approximated in a best orthogonal bandelet basis with an optimal asymptotic error decay. Fast algorithms and compression applications are described. \u00a9 2008 Wiley Periodicals, Inc."
            },
            "slug": "Orthogonal-bandelet-bases-for-geometric-images-Peyr\u00e9-Mallat",
            "title": {
                "fragments": [],
                "text": "Orthogonal bandelet bases for geometric images approximation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is proved that C \u03b1\u2010images having singularities along C\u03b1\u2010curves are approximated in a best orthogonal bandelet basis with an optimal asymptotic error decay."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145020548"
                        ],
                        "name": "E. Reinhard",
                        "slug": "E.-Reinhard",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Reinhard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Reinhard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144033462"
                        ],
                        "name": "P. Shirley",
                        "slug": "P.-Shirley",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Shirley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Shirley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2821129"
                        ],
                        "name": "M. Ashikhmin",
                        "slug": "M.-Ashikhmin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ashikhmin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ashikhmin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4997851"
                        ],
                        "name": "T. Troscianko",
                        "slug": "T.-Troscianko",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Troscianko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Troscianko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "We simply use the local mean \u03bcL and standard deviation \u03c3L of the image intensity to estimate the contrast value of a CC with its background [22]; CL = \u03c3L/\u03bcL."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2867083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ba265ecd7942fce8ec80792df56c6be01cf2a0b",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The class of all natural images is an extremely small fraction of all possible images. Some of the structure of natural images can be modeled statistically, revealing striking regularities. Moreover, the human visual system appears to be optimized to view natural images. Images that do not behave statistically as natural images are harder for the human visual system to interpret. This paper reviews second order image statistics as well as their implications for computer graphics. We show that these statistics are predominantly due to geometric modeling, while being largely unaffected by the choice of rendering parameters. As a result, second order image statistics are useful for modeling applications, which we show in direct examples (recursive random displacement terrain modeling and solid texture synthesis). Finally, we present an image reconstruction filter based on second order image statistics."
            },
            "slug": "Second-order-image-statistics-in-computer-graphics-Reinhard-Shirley",
            "title": {
                "fragments": [],
                "text": "Second order image statistics in computer graphics"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that second order image statistics are predominantly due to geometric modeling, while being largely unaffected by the choice of rendering parameters, and useful for modeling applications, which are shown in direct examples."
            },
            "venue": {
                "fragments": [],
                "text": "APGV '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802088"
                        ],
                        "name": "E. Peli",
                        "slug": "E.-Peli",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Peli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Peli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 47
                            }
                        ],
                        "text": "More complex contrast analysis can be found in [19, 26] by employing discrete cosine transform and wavelets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14033042,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "9399d319cdebcdf222f10796fefccc881ab030e5",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "A previous study tested the validity of simulations of the appearance of a natural image (from different observation distances) generated by using a visual model and contrast sensitivity functions of the individual observers [J. Opt. Soc. Am. A 13, 1131 (1996)]. Deleting image spatial-frequency components that should be undetectable made the simulations indistinguishable from the original images at distances larger than the simulated distance. The simulated observation distance accurately predicted the distance at which the simulated image could be discriminated from the original image. Owing to the 1/f characteristic of natural images' spatial spectra, the individual contrast sensitivity functions (CSF's) used in the simulations of the previous study were actually tested only over a narrow range of retinal spatial frequencies. To test the CSF's over a wide range of frequencies, the same simulations and testing procedure were applied to five contrast versions of the images (10-300%). This provides a stronger test of the model, of the simulations, and specifically of the CSF's used. The relevant CSF for a discrimination task was found to be obtained by using 1-octave Gabor stimuli measured in a contrast detection task. The relevant CSF data had to be measured over a range of observation distances, owing to limitations of the displays."
            },
            "slug": "Contrast-sensitivity-function-and-image-Peli",
            "title": {
                "fragments": [],
                "text": "Contrast sensitivity function and image discrimination."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "To test the CSF's over a wide range of frequencies, the same simulations and testing procedure were applied to five contrast versions of the images (10-300%)."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics, image science, and vision"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The earlier bandlet bases [20, 21] have been improved by a multi-scale geometry defined over wavelet coefficients [15, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 53235069,
            "fieldsOfStudy": [],
            "id": "6e57a976010e1a513fcc87ac160cc3af79c8e6db",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Surface compression with geometric bandelets"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "2(c)) is equivalent to edge positions in the original signal (image)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Orthogonal bandlets bases for geometric image approximation"
            },
            "venue": {
                "fragments": [],
                "text": "Commun. Pure Appl. Math"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 48
                            }
                        ],
                        "text": "(a) (b) (c) (d) (e) Figure 1: Bandlet transform [16, 24]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 114
                            }
                        ],
                        "text": "The earlier bandlet bases [20, 21] have been improved by a multi-scale geometry defined over wavelet coefficients [15, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Orthogonal bandlets bases for geometric image approximation"
            },
            "venue": {
                "fragments": [],
                "text": "Commun. Pure Appl. Math.,"
            },
            "year": 2008
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 22,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 32,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Image-Text-Detection-Using-a-Bandlet-Based-Edge-and-Mosleh-Bouguila/3c73a333e9887e3654a26060098416446ca25eab?sort=total-citations"
}