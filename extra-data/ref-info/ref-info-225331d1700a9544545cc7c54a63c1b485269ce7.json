{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 5901461,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "36e62f8048fb590d06457bcf18153e8931eb1fbe",
            "isKey": false,
            "numCitedBy": 204,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Note-on-the-Number-of-Queries-Needed-to-Identify-Angluin",
            "title": {
                "fragments": [],
                "text": "A Note on the Number of Queries Needed to Identify Regular Languages"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144342820"
                        ],
                        "name": "E. M. Gold",
                        "slug": "E.-M.-Gold",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Gold",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. M. Gold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 46
                            }
                        ],
                        "text": "It is also related to the method used by Gold [4,5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "Gold [4] has shown that the problem of finding a dfa of a minimum number of states compatible with a given finite set of positive and negative examples is NP-hard."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8943792,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "9dfa951bec812bd7b8c905c587bca50b7883a10f",
            "isKey": false,
            "numCitedBy": 802,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Complexity-of-Automaton-Identification-from-Given-Gold",
            "title": {
                "fragments": [],
                "text": "Complexity of Automaton Identification from Given Data"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700623"
                        ],
                        "name": "N. Jones",
                        "slug": "N.-Jones",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Jones",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2199440"
                        ],
                        "name": "William T. Laaser",
                        "slug": "William-T.-Laaser",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Laaser",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William T. Laaser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": ") The satisliability and equivalence problems for these sentences can be solved in polynomial time, making them an attractive class [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12251817,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "80aac474447dc7feac0380f38309f38e62cd7108",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The results of Cook and Karp ([K], [C]) aroused considerable interest for at least two reasons. First, the answer to a long-standing open question which had seemed peculiar to automata theory\u2014whether deterministic and nondeterministic polynomial-time-bounded Turing machines are equivalent in power\u2014was seen to be exactly equivalent to determining whether any of several familiar combinatorial problems can be solved by polynomial-time algorithms. Second, the existence of complete problems for NP1 made it possible to replace an entire class of questions by a question about a single representative.Thus all of these combinatorial and automata-theoretic problems were essentially restatements of a single problem, such as: can satisfiability of a propositional formula be decided in polynomial time.\n The main purpose of this paper is to introduce several problems which are complete for P, the class of languages recognizable in deterministic polynomial time. Any such language has the property that if it is recognizable in space logk(\u2022), then every language in P is so recognizable. Thus a problem complete for P will serve to differentiate those sets in P which are not recognizable in logarithmic space from those which are, providing such differentiation is possible. A problem of this type was first presented by Cook in [C2], concerning solvable path systems."
            },
            "slug": "Complete-problems-for-deterministic-polynomial-time-Jones-Laaser",
            "title": {
                "fragments": [],
                "text": "Complete problems for deterministic polynomial time"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Several problems which are complete for P, the class of languages recognizable in deterministic polynomial time, are introduced, to serve to differentiate those sets in P which are not recognizable in logarithmic space from those which are, providing such differentiation is possible."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '74"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 103
                            }
                        ],
                        "text": "However, we show later in the paper that using the criterion of approximate identification proposed by Valiant [S], we may substitute a random sampling oracle for the ability to answer questions of the second type, removing some of the limitations of the assumption of minimal adequacy of the Teacher."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 46
                            }
                        ],
                        "text": "The stochastic setting we use was proposed by Valiant [8] and generalized by Blumer et al. [3]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "If we instead postulate a stochastic setting analogous to that proposed by Valiant [8] and require only that the Learner get an approximately correct hypothesis with high probability, then this aspect of the Teacher can be replaced by a random sampling oracle."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "The stochastic setting we use was proposed by Valiant [8] and generalized by Blumer et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12837541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fc0c7afc6bb27fb3752eae0ea5869413b1259b7",
            "isKey": true,
            "numCitedBy": 1646,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learned using it in a reasonable (polynomial) number of steps. Although inherent algorithmic complexity appears to set serious limits to the range of concepts that can be learned, we show that there are some important nontrivial classes of propositional concepts that can be learned in a realistic sense."
            },
            "slug": "A-theory-of-the-learnable-Valiant",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper regards learning as the phenomenon of knowledge acquisition in the absence of explicit programming, and gives a precise methodology for studying this phenomenon from a computational viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2647026"
                        ],
                        "name": "A. Blumer",
                        "slug": "A.-Blumer",
                        "structuredName": {
                            "firstName": "Anselm",
                            "lastName": "Blumer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blumer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5225434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29b6251c84def0cbd35397c71fada0d22cd9409c",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend Valiant's learnability model to learning classes of concepts defined by regions in Euclidean space E\". Our methods lead to a unified treatment of some of Valiant's results, along with previous results of Pearl and Devroye and Wagner on distribution-free convergence of certain pattern recognition algorithms. We show that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned. Using this parameter, we analyze the complexity and closure properties of learnable classes. Authors A. Blumer and D. Haussler gratefully acknowledge the support of NSF grant IST-8317918, author A. Ehrenfeucht the support of NSF grant MCS-8305245, and author M. Warmuth the support of the Faculty Research Committee of the University of California at Santa Cruz. Part of this work was done while A. Blumer was visiting the University of California at Santa Cruz and M. Warmuth the Univer-"
            },
            "slug": "Classifying-learnable-geometric-concepts-with-the-Blumer-Ehrenfeucht",
            "title": {
                "fragments": [],
                "text": "Classifying learnable geometric concepts with the Vapnik-Chervonenkis dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '86"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143752440"
                        ],
                        "name": "E. Shapiro",
                        "slug": "E.-Shapiro",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Shapiro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "The idea of a minimally adequate Teacher is related to Shapiro\u2019s assumptions about the kinds of queries a user can answer in Prolog program debugging [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60699326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e36f22685b8d3db73532d3104b325cea5288a66",
            "isKey": false,
            "numCitedBy": 1280,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The thesis lays a theoretical framework for program debugging, with the goal of partly mechanizing this activity. In particular, we formalize and develop algorithmic solutions to the following two questions: (1) How do we identify a bug in a program that behaves incorrectly? (2) How do we fix a bug, once one is identified? \nWe develop interactive diagnosis algorithms that identify a bug in a program that behaves incorrectly, and implement them in Prolog for the diagnosis of Prolog programs. Their performance suggests that they can be the backbone of debugging aids that go far beyond what is offered by current programming environments. \nWe develop an inductive inference algorithm that synthesizes logic programs from examples of their behavior. The algorithm incorporates the diagnosis algorithms as a component. It is incremental, and progresses by debugging a program with respect to the examples. The Model Inference System is a Prolog implementation of the algorithm. Its range of applications and efficiency is comparable to existing systems for program synthesis from examples and grammatical inference. \nWe develop an algorithm that can fix a bug that has been identified, and integrate it with the diagnosis algorithms to form an interactive debugging system. By restricting the class of bugs we attempt to correct, the system can debug programs that are too complex for the Model Inference System to synthesize."
            },
            "slug": "Algorithmic-Program-Debugging-Shapiro",
            "title": {
                "fragments": [],
                "text": "Algorithmic Program Debugging"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm that can fix a bug that has been identified, and integrate it with the diagnosis algorithms to form an interactive debugging system that can debug programs that are too complex for the Model Inference System to synthesize."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911738"
                        ],
                        "name": "D. Angluin",
                        "slug": "D.-Angluin",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Angluin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Angluin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152471016"
                        ],
                        "name": "Carl H. Smith",
                        "slug": "Carl-H.-Smith",
                        "structuredName": {
                            "firstName": "Carl H.",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carl H. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3209224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6524a6b8e6091c0a11d665180a5ad94bbf1d3b4",
            "isKey": false,
            "numCitedBy": 900,
            "numCiting": 190,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been a great deal of theoretical and experimental work in computer science on inductive inference systems, that is, systems that try to infer general rules from examples. However, a complete and applicable theory of such systems is still a distant goal. This survey highlights and explains the main ideas that have been developed in the study of inductive inference, with special emphasis on the relations between the general theory and the specific algorithms and implementations. 154 references."
            },
            "slug": "Inductive-Inference:-Theory-and-Methods-Angluin-Smith",
            "title": {
                "fragments": [],
                "text": "Inductive Inference: Theory and Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This survey highlights and explains the main ideas that have been developed in the study of inductive inference, with special emphasis on the relations between the general theory and the specific algorithms and implementations."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144342820"
                        ],
                        "name": "E. M. Gold",
                        "slug": "E.-M.-Gold",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Gold",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. M. Gold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 46
                            }
                        ],
                        "text": "It is also related to the method used by Gold [4,5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "Gold [4] has shown that the problem of finding a dfa of a minimum number of states compatible with a given finite set of positive and negative examples is NP-hard."
                    },
                    "intents": []
                }
            ],
            "corpusId": 119851170,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "74fc7eb9e8e0934861ba55ca951f4427c61c7de8",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "System-identification-via-state-characterization-Gold",
            "title": {
                "fragments": [],
                "text": "System identification via state characterization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120727777,
            "fieldsOfStudy": [],
            "id": "00b77c9de475ae21e4cb80165ee994c11b478f2e",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Complete Problems for Deterministic Polynomial Time"
            },
            "venue": {
                "fragments": [],
                "text": "Theor. Comput. Sci."
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inductive inference : Theory and methods , Compuf"
            },
            "venue": {
                "fragments": [],
                "text": "Surveys"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable , Comm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inductive inference : Theory and methods , Compuf"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 3,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 12,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-Regular-Sets-from-Queries-and-Angluin/225331d1700a9544545cc7c54a63c1b485269ce7?sort=total-citations"
}