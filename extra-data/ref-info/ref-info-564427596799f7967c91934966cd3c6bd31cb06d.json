{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145539951"
                        ],
                        "name": "J. Pollack",
                        "slug": "J.-Pollack",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Pollack",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pollack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "For some examples see the papers of Touretzky [33], Pollack [27], or Smolensky [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "In Pollack's [27] recursive auto-associative memories (RAAM's) items, associations, and recursive associations are all represented in the same vector space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 770011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a835df43fdc2f79126319f6fa033bb42147c6f6",
            "isKey": false,
            "numCitedBy": 948,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recursive-Distributed-Representations-Pollack",
            "title": {
                "fragments": [],
                "text": "Recursive Distributed Representations"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806116"
                        ],
                        "name": "D. Touretzky",
                        "slug": "D.-Touretzky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Touretzky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Touretzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3134735"
                        ],
                        "name": "S. Geva",
                        "slug": "S.-Geva",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Geva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geva"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Simple frame-like structures can be represented using convolution encoding in a manner analogous to cross products of roles and fillers in Hinton [ll] or the frames of DUCS [ 34 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Nonrecursive variable binding can also be implemented easily in other types of associative memory, e.g., the triplespace of BoltzCONS [35], or the outer product of roles and fillers in DUCS [ 34 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41169053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88eaafa4cce01f954c9fd5e2a0f5ddde66fae920",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : We describe a representation for frame-like concept structures in a neural network called DUCS. Slot names and slot fillers are diffuse patterns of activation spread over a collection of units. Our choice of a distributed representation gives rise to certain useful properties not shared by conventional frame systems. One of these is the ability to encode fine semantic distinctions as subtle variations on the canonical pattern for a slot. DUCS typically maintains several concepts simultaneously in its concept memory; it can retrieve a concept given one or more slots as cues. We show how Hinton's notion of a 'reduced description' can be used to make one concept fill a slot in another. Keywords: Artificial intelligence, Machine learning, Connectionsim, Short-term memory, Distributed representation, Frames."
            },
            "slug": "A-distributed-connectionist-representation-for-Touretzky-Geva",
            "title": {
                "fragments": [],
                "text": "A distributed connectionist representation for concept structures"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This work describes a representation for frame-like concept structures in a neural network called DUCS and shows how Hinton's notion of a 'reduced description' can be used to make one concept fill a slot in another."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806116"
                        ],
                        "name": "D. Touretzky",
                        "slug": "D.-Touretzky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Touretzky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Touretzky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2662167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f70d2ff213a964621cb080f141ceed6359b84199",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "BoltzCONS:-Dynamic-Symbol-Structures-in-a-Network-Touretzky",
            "title": {
                "fragments": [],
                "text": "BoltzCONS: Dynamic Symbol Structures in a Connectionist Network"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40756494"
                        ],
                        "name": "J. Metcalfe",
                        "slug": "J.-Metcalfe",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Metcalfe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Metcalfe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 41426049,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "08703471946563df9b9682999b4a04d2d1ec4142",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, a highly interactive model of association formation, storage, and retrieval is described. Items, represented as sets of features, are associated by the operation of convolution. The associations are stored by being superimposed in a composite memory trace. Retrieval occurs when a cue item is correlated with the composite trace. The retrieved items are intrinsically noisy, may be ambiguous, and may under certain conditions be systematically distorted from their encoded form. A discrete response is selected by matching the retrieved item to all of the items in semantic memory. The model yields several new predictions about errors in single-trial cued recall that depend on similarity relations among the to-be-remembered items, and also about the efficacy of extralist cues. Experiments are presented that test these predictions against human recall. The model is then applied to several well-known results: prototype abstraction, the A-B A-D paradigm\u2014including the independence of the B and D responses\u2014 and the Osgood transfer surface."
            },
            "slug": "A-composite-holographic-associative-recall-model-Metcalfe",
            "title": {
                "fragments": [],
                "text": "A composite holographic associative recall model"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A highly interactive model of association formation, storage, and retrieval that is applied to several well-known results, yielding several new predictions about errors in single-trial cued recall that depend on similarity relations among the to-be-remembered items, and also about the efficacy of extralist cues."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "I. INTRODUCTION ISTRIBUTED representations [13] are attractive for a D number of reasons."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 50027191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3106e66537a0c8f53278e553bcb38f0b0992ec0e",
            "isKey": false,
            "numCitedBy": 1243,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a \u0302 network of simple computing elements and some entities to be represented, the most straightforward scheme is to use one computing element for each entity. This is called a local representation. It is easy to understand and easy to implement because the structure of the physical network mirrors the structure of the knowledge it contains. This report describes a different type of representation that is less familiar and harder to think about than local representations. Each entity is represented by a pattern of activity distributed over many computing elements, and each computing element is involved in representing many different entities. The strength of this more complicated kind of representation does not lie in its notational convenience or its ease of implementation in a conventional computer, but rather in the efficiency with which it makes use of the processing abilities of networks of simple, neuron-like computing elements. Every representational scheme has its good and bad points. Distributed representations are no exception. Some desirable properties like content-addressable memory and automatic generalization arise very naturally from the use of patterns of activity as representations. Other properties, like the ability to temporarily store a large set of arbitrary associations, are much harder to achieve. The best psychological evidence for distributed representations is the degree to which their strengths and weaknesses match those of the human mind. ^This research was supported by a grant from the System Development Foundation. I thank Jim Anderson, Dave Ackley Dana Ballard, Francis Crick, Scott Fahlman, Jerry Feldman, Christopher Longuet-Higgins, Don Norman, Terry Sejnowski, and Tim Shallice for helpful discussions. Jay McClelland and Dave Rumelhart helped me refine and rewrite many of the ideas presented here A substantially revised version of this report will appear as a chapter by Hinton, McClelland and Rumelhart in Parallel Distributed Processing: Explorations in the micro-structure of cognition, edited by McClelland and Rumelhart)"
            },
            "slug": "Distributed-Representations-Hinton-McClelland",
            "title": {
                "fragments": [],
                "text": "Distributed Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This report describes a different type of representation that is less familiar and harder to think about than local representations, which makes use of the processing abilities of networks of simple, neuron-like computing elements."
            },
            "venue": {
                "fragments": [],
                "text": "The Philosophy of Artificial Intelligence"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1516909860"
                        ],
                        "name": "D. Touretzky",
                        "slug": "D.-Touretzky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Touretzky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Touretzky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16032366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33b5978384dd535b7fc18563e1ca9f8f77067658",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Coarse-coded symbol memories have appeare d in several neural net work symbol processing models. T hey are st atic memories that use overlap ping codes to store mu ltiple items simultaneo usly. In order to determine how t hese models would scale, one must first have some understanding of the mathematics of coarse-coded represe ntations . The general struct ure of coarse-coded symbo l memories is defined, and their strengths and weaknesses are discussed . Memory schemes can be characterized by their memory size, symbol-set size, and capacity. We derive mathematical relationships between these par ameters for various memory schemes, using both analysis and numerical method s. We find a simple linear relat ionship between the resources allocated to the syste m and the capacity t hey yield . The predicted capacity of one of the schemes is compar ed wit h actual measur ements of the coar secoded working memory of DCP S, Touret zky and Hinto n's dist ributed connectionist product ion system. Finally we provide a heurist ic algorithm for generating receptive fields which is efficient and pro duces good results in practice."
            },
            "slug": "Coarse-Coded-Symbol-Memories-and-Their-Properties-Rosenfeld-Touretzky",
            "title": {
                "fragments": [],
                "text": "Coarse-Coded Symbol Memories and Their Properties"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The predicted capacity of one of the schemes is compared with the actual measur ements of the coar secoded working memory of DCP S, Touret zky and Hinto n's dist ributed connectionist product ion system, and a simple linear relat ionship between the resources allocated to the syste m and the capacity is found."
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87252295"
                        ],
                        "name": "J. Slack",
                        "slug": "J.-Slack",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Slack",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Slack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2018*Slack [ 31 ] suggests a distributed memory representation for Fees involving convolution products that is similar to the representation suggested here, except that it uses noncircular convolution, and thus does not work with fixed width vectors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16519273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "440ac3ce47af9d6d653626838f0dd43eb6935b78",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper begins by defining a class of distributed memory machines which have useful properties as retrieval and filtering devices. These memory mechanisms store large numbers of associations on a single composite vector. They provide a natural format for encoding the syntactic and semantic constraints associated with linguistic elements. A computational architecture for parsing natural language is proposed which utilises the retrieval and associative features of these devices. The parsing mechanism is based on the principles of Lexical Functional Grammar and the paper demonstrates how these principles can be derived from the properties of the memory mechanisms."
            },
            "slug": "A-Parsing-Architecture-Based-on-Distributed-Memory-Slack",
            "title": {
                "fragments": [],
                "text": "A Parsing Architecture Based on Distributed Memory Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The paper demonstrates how principles of Lexical Functional Grammar can be derived from the properties of the memory mechanisms of distributed memory machines."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298207"
                        ],
                        "name": "P. Kanerva",
                        "slug": "P.-Kanerva",
                        "structuredName": {
                            "firstName": "Pentti",
                            "lastName": "Kanerva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kanerva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57931704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcdb9bd64e3d7885c10938291153257b94f3df91",
            "isKey": false,
            "numCitedBy": 1008,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nMotivated by the remarkable fluidity of memory the way in which items are pulled spontaneously and effortlessly from our memory by vague similarities to what is currently occupying our attention Sparse Distributed Memory presents a mathematically elegant theory of human long term memory. \nThe book, which is self contained, begins with background material from mathematics, computers, and neurophysiology; this is followed by a step by step development of the memory model. The concluding chapter describes an autonomous system that builds from experience an internal model of the world and bases its operation on that internal model. Close attention is paid to the engineering of the memory, including comparisons to ordinary computer memories. \nSparse Distributed Memory provides an overall perspective on neural systems. The model it describes can aid in understanding human memory and learning, and a system based on it sheds light on outstanding problems in philosophy and artificial intelligence. Applications of the memory are expected to be found in the creation of adaptive systems for signal processing, speech, vision, motor control, and (in general) robots. Perhaps the most exciting aspect of the memory, in its implications for research in neural networks, is that its realization with neuronlike components resembles the cortex of the cerebellum. \nPentti Kanerva is a scientist at the Research Institute for Advanced Computer Science at the NASA Ames Research Center and a visiting scholar at the Stanford Center for the Study of Language and Information. A Bradford Book."
            },
            "slug": "Sparse-Distributed-Memory-Kanerva",
            "title": {
                "fragments": [],
                "text": "Sparse Distributed Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Pentti Kanerva's Sparse Distributed Memory presents a mathematically elegant theory of human long term memory that resembles the cortex of the cerebellum, and provides an overall perspective on neural systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152137393"
                        ],
                        "name": "B. Murdock",
                        "slug": "B.-Murdock",
                        "structuredName": {
                            "firstName": "Bennet",
                            "lastName": "Murdock",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Murdock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53366703,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e515bd5fb9e29f82abc0238e9ab3dc9b238a2124",
            "isKey": false,
            "numCitedBy": 970,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "A theory for the storage and retrieval of item and associative information is presented. In the theory, items or events are represented as random vectors. Convolution is used as the storage operation, and correlation is used as the retrieval operation. A distributed-memory system is assumed; all information is stored in a common memory vector. The theory applies to both recognition and recall and covers both accuracy and latency. Noise in the decision stage necessitates a two-criterion decision system, and over time the criteria converge until a decision is reached. Performance is predicted from the moments (expectation and variance) of the similarity distributions, and these can be derived from the theory. Several alternative models with varying degrees of distributed memory are considered, and expressions for signal-to-noise ratio and relative efficiency are derived."
            },
            "slug": "A-Theory-for-the-Storage-and-Retrieval-of-Item-and-Murdock",
            "title": {
                "fragments": [],
                "text": "A Theory for the Storage and Retrieval of Item and Associative Information."
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A theory for the storage and retrieval of item and associative information is presented, and expressions for signal-to-noise ratio and relative efficiency are derived."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3221701"
                        ],
                        "name": "E. Weber",
                        "slug": "E.-Weber",
                        "structuredName": {
                            "firstName": "Elke",
                            "lastName": "Weber",
                            "middleNames": [
                                "U."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Weber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Extensive tables of variances for dot products of various convolution products have been compiled by Weber [ 36 ] for aperiodic convolution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61324032,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "9e8b23b11a381db0a9e1f3eefad0569868e0594f",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Expectation-and-variance-of-item-resemblance-in-a-Weber",
            "title": {
                "fragments": [],
                "text": "Expectation and variance of item resemblance distributions in a convolution-correction model of distributed memory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1516909860"
                        ],
                        "name": "D. Touretzky",
                        "slug": "D.-Touretzky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Touretzky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Touretzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Touretzky and Hinton [35] and Rosenfield and Touretzky [28] discussed binary-OR memories? which can be viewed as a nonlinear version of an addition memories."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 15
                            }
                        ],
                        "text": "Unfortunately, Hinton does not suggest any concrete way of performing the reduction and expansion mappings."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Touretzky and Hinton [35] and Touretzky [33] describe systems based on this idea."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "Binary-OR memories were used in the model of Touretzky and Hinton [35]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Hinton [12] discusses this problem and proposes a framework in which \" reduced descriptions \" are used to represent parts and objects in a part-whole hierarchy (a frame-like representation )."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 189
                            }
                        ],
                        "text": "I call these holographic reduced representations (IBR's), since convolution and correlation based memories are closely related to holographic storage, and they provide an implementation of Hinton's [ 121 reduced descriptions."
                    },
                    "intents": []
                }
            ],
            "corpusId": 142795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2641de9a59d4f176a6e088d79846576e5ff9513",
            "isKey": true,
            "numCitedBy": 173,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "DCPS is a connectionist production system interpreter that uses distributed representations. As a connectionist model it consists of many simple, richly interconnected neuron-like computing units that cooperate to solve problems in parallel. One motivation for constructing DCPS was to demonstrate that connectionist models are capable of representing and using explicit rules. A second motivation was to show how \u201ccoarse coding\u201d or \u201cdistributed representations\u201d can be used to construct a working memory that requires far fewer units than the number of different facts that can potentially be stored. The simulation we present is intended as a detailed demonstration of the feasibility of certain ideas and should not be viewed as a full implementation of production systems. Our current model only has a few of the many interesting emergent properties that we eventually hope to demonstrate: It is damage-resistant, it performs matching and variable binding by massively parallel constraint satisfaction, and the capacity of its working memory is dependent on the similarity of the items being stored."
            },
            "slug": "A-Distributed-Connectionist-Production-System-Touretzky-Hinton",
            "title": {
                "fragments": [],
                "text": "A Distributed Connectionist Production System"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The simulation of DCPS is intended as a detailed demonstration of the feasibility of certain ideas and should not be viewed as a full implementation of production systems."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859277"
                        ],
                        "name": "T. Plate",
                        "slug": "T.-Plate",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Plate",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Plate"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13629215,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebf62950d733a4a8f9ecd8d3752dee8d13fc8e6d",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Holographic Recurrent Networks (HRNs) are recurrent networks which incorporate associative memory techniques for storing sequential structure. HRNs can be easily and quickly trained using gradient descent techniques to generate sequences of discrete outputs and trajectories through continuous space. The performance of HRNs is found to be superior to that of ordinary recurrent networks on these sequence generation tasks."
            },
            "slug": "Holographic-Recurrent-Networks-Plate",
            "title": {
                "fragments": [],
                "text": "Holographic Recurrent Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "Holographic Recurrent Networks are recurrent networks which incorporate associative memory techniques for storing sequential structure and the performance of HRNs is found to be superior to that of ordinary recurrent networks on sequence generation tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34925745"
                        ],
                        "name": "D. Casasent",
                        "slug": "D.-Casasent",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Casasent",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Casasent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2341494"
                        ],
                        "name": "B. Telfer",
                        "slug": "B.-Telfer",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Telfer",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Telfer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9562944,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c584ffaf939c7459692d3832a60780895cb9108",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Most associative memory work has concentrated on autoassociative memories (AAMs). These associative processors provide reduced noise and error correction in their output data. We will consider heteroassociative memories (HAMs), which are needed to provide decisions on the class of the input data and inferences for subsequent processing. We derive new equations for the storage capacity and noise performance of HAMs, emphasize how they differ from those derived for AAMs, suggest new performance measures to be used, and show how different recollection vector encodings can improve HAM performance."
            },
            "slug": "Key-and-recollection-vector-effects-on-memory-Casasent-Telfer",
            "title": {
                "fragments": [],
                "text": "Key and recollection vector effects on heteroassociative memory performance."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work derive new equations for the storage capacity and noise performance of HAMs, emphasize how they differ from those derived for AAMs, suggest new performance measures to be used, and show how different recollection vector encodings can improve HAM performance."
            },
            "venue": {
                "fragments": [],
                "text": "Applied optics"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50213662"
                        ],
                        "name": "A. Fisher",
                        "slug": "A.-Fisher",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Fisher",
                            "middleNames": [
                                "Douglas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30898980"
                        ],
                        "name": "W. Lippincott",
                        "slug": "W.-Lippincott",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Lippincott",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lippincott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49684676"
                        ],
                        "name": "J. Lee",
                        "slug": "J.-Lee",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Lee",
                            "middleNames": [
                                "N."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 214
                            }
                        ],
                        "text": "Convolution-correlation memories (sometimes referred to as holographic-like memories) and matrix memories have been regarded as alternative methods for implementing heteroassociative memory [37], [19], [23], [30], [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 218
                            }
                        ],
                        "text": "Convolutiodcorrelation (holographic) memories have been generally regarded as inferior to matrix style associative memories for associating pairs of items, for reasons concerning capacity and constraints (see [37] and [8])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "Hetero-associative memories, e.g., holographic memories and matrix memories [37], [8], [22], [5], [38], store a set of pairs of items."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33108371,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "611d101974ee5cd732bacfba17dd29d6054d9807",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical associative, parallel-processing architectures are being developed using a multimodule approach, where a number of smaller, adaptive, associative modules are nonlinearly interconnected and cascaded under the guidance of a variety of organizational principles to structure larger architectures for solving specific problems. A number of novel optical implementations with versatile adaptive learning capabilities are presented for the individual associative modules, including holographic configurations and five specific electrooptic configurations. The practical issues involved in real optical architectures are analyzed, and actual laboratory optical implementations of associative modules based on Hebbian and Widrow-Hoff learning rules are discussed, including successful experimental demonstrations of their operation."
            },
            "slug": "Optical-implementations-of-associative-networks-Fisher-Lippincott",
            "title": {
                "fragments": [],
                "text": "Optical implementations of associative networks with versatile adaptive learning capabilities."
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The practical issues involved in real optical architectures are analyzed, and actual laboratory optical implementations of associative modules based on Hebbian and Widrow-Hoff learning rules are discussed, including successful experimental demonstrations of their operation."
            },
            "venue": {
                "fragments": [],
                "text": "Applied optics"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "Auto-associative memories, e.g., Hopfield networks [14], store an unordered set of items."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 18
                            }
                        ],
                        "text": "For example, in a Hopfield memory (a matrix style memory) items are represented on unit activations (a vector ) and associations are represented on connections weights Manuscript received August 1991; revised April 1993."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "Hopfield networks are probably not a good candidate because of their low capacity in terms of the dimension of the vectors being stored."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "In some models the encoding and decoding operations are bilinear, e.g., Murdock [19], in others the decoding operation in nonlinear, e.g., Hopfield [14], and in others all the operations are nonlinear, e.g., Willshaw [37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 784288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98b4d4e24aab57ab4e1124ff8106909050645cfa",
            "isKey": true,
            "numCitedBy": 16694,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices."
            },
            "slug": "Neural-networks-and-physical-systems-with-emergent-Hopfield",
            "title": {
                "fragments": [],
                "text": "Neural networks and physical systems with emergent collective computational abilities."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A model of a system having a large number of simple equivalent components, based on aspects of neurobiology but readily adapted to integrated circuits, produces a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7544770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71dd4d477ca17b4db3b270d25225822ff3a41fac",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mapping-Part-Whole-Hierarchies-into-Connectionist-Hinton",
            "title": {
                "fragments": [],
                "text": "Mapping Part-Whole Hierarchies into Connectionist Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30754464"
                        ],
                        "name": "E. Paek",
                        "slug": "E.-Paek",
                        "structuredName": {
                            "firstName": "Eung",
                            "lastName": "Paek",
                            "middleNames": [
                                "Gi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Paek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784553"
                        ],
                        "name": "D. Psaltis",
                        "slug": "D.-Psaltis",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Psaltis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Psaltis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62174304,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "68580853fd500e755a35f80674c79e8c25b048d0",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An experimental demonstration of a holographic associative memory is presented. The system utilizes an array of classic VanderLugt correlators to implement in parallel the inner product between an input and a set of stored reference images. Each inner product is used to read out an associated image. Theoretical analysis of the system is given, and experimental results are shown."
            },
            "slug": "Optical-Associative-Memory-Using-Fourier-Transform-Paek-Psaltis",
            "title": {
                "fragments": [],
                "text": "Optical Associative Memory Using Fourier Transform Holograms"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An experimental demonstration of a holographic associative memory that utilizes an array of classic VanderLugt correlators to implement in parallel the inner product between an input and a set of stored reference images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40227361"
                        ],
                        "name": "D. Willshaw",
                        "slug": "D.-Willshaw",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Willshaw",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Willshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "Hetero-associative memories, e.g., holographic memories and matrix memories [37], [8], [22], [5], [38], store a set of pairs of items."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7952277,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "aab62d743b83c705e0a61d09dcf1f39caeacdeb5",
            "isKey": false,
            "numCitedBy": 224,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "A recent article (Stanton and Sejnowski 1989) on long-term synaptic depression in the hippocampus has reopened the issue of the computational efficiency of particular synaptic learning rules (Hebb 1949; Palm 1988a; Morris and Willshaw 1989) homosynaptic versus heterosynaptic and monotonic versus nonmonotonic changes in synaptic efficacy. We have addressed these questions by calculating and maximizing the signal-to-noise ratio, a measure of the potential fidelity of recall, in a class of associative matrix memories. Up to a multiplicative constant, there are three optimal rules, each providing for synaptic depression such that positive and negative changes in synaptic efficacy balance out. For one rule, which is found to be the Stent-Singer rule (Stent 1973; Rauschecker and Singer 1979), the depression is purely heterosynaptic; for another (Stanton and Sejnowski 1989), the depression is purely homosynaptic; for the third, which is a generalization of the first two, and has a higher signal-to-noise ratio, it is both heterosynaptic and homosynaptic. The third rule takes the form of a covariance rule (Sejnowski 1977a,b) and includes, as a special case, the prescription due to Hopfield (1982) and others (Willshaw 1971; Kohonen 1972)."
            },
            "slug": "Optimal-Plasticity-from-Matrix-Memories:-What-Goes-Willshaw-Dayan",
            "title": {
                "fragments": [],
                "text": "Optimal Plasticity from Matrix Memories: What Goes Up Must Come Down"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "Calculating and maximizing the signal-to-noise ratio, a measure of the potential fidelity of recall, in a class of associative matrix memories, addresses the issue of the computational efficiency of particular synaptic learning rules homosynaptic versus heterosyaptic and monotonic versus nonmonotonic changes in synaptic efficacy."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38663378"
                        ],
                        "name": "J. Fodor",
                        "slug": "J.-Fodor",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Fodor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fodor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194015"
                        ],
                        "name": "Z. Pylyshyn",
                        "slug": "Z.-Pylyshyn",
                        "structuredName": {
                            "firstName": "Zenon",
                            "lastName": "Pylyshyn",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Pylyshyn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29043627,
            "fieldsOfStudy": [
                "Philosophy",
                "Psychology"
            ],
            "id": "56cbfcbfffd8c54bd8477d10b6e0e17e097b97c7",
            "isKey": false,
            "numCitedBy": 3540,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Connectionism-and-cognitive-architecture:-A-Fodor-Pylyshyn",
            "title": {
                "fragments": [],
                "text": "Connectionism and cognitive architecture: A critical analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Cognition"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "Smolensky suggests placing a hard limit on the depth of recursion in order to keep the size of the association space tractable (e.g., no structure can be more than four levels deep)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 191
                            }
                        ],
                        "text": "The problem of representing compositional structure' in distributed representations, however , has been for some time a prominent concern of both proponents and critics of connectionism [9], [32], [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "For some examples see the papers of Touretzky [33], Pollack [27], or Smolensky [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Smolensky [32] proposes Tensorproduct memories, which use a generalized outer product as the associative operator."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 125580247,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9438172bfbb74a6a4ea4242b180d4335bb1f18b7",
            "isKey": true,
            "numCitedBy": 642,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: 1. Introduction, 2. Connectionist Representation and Tensor Product Binding: Definition and Examples, 3. Tensor Product Representation: Properties, 4. Conclusion"
            },
            "slug": "Tensor-Product-Variable-Binding-and-the-of-Symbolic-Hinton",
            "title": {
                "fragments": [],
                "text": "Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This chapter contains sections titled connectionist Representation and Tensor Product Binding: Definition and Examples, and tensor Product Representation: Properties."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789165"
                        ],
                        "name": "N. Benvenuto",
                        "slug": "N.-Benvenuto",
                        "structuredName": {
                            "firstName": "Nevio",
                            "lastName": "Benvenuto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Benvenuto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701870"
                        ],
                        "name": "F. Piazza",
                        "slug": "F.-Piazza",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Piazza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Piazza"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There has been some research on creating adapting neural network architectures to wok with units with complex valued activations (e.g., [ 2 ])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12255726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a76e79bff7fa8e90cd6b2595cff6fb1b5665b084",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A recursive algorithm for updating the coefficients of a neural network structure for complex signals is presented. Various complex activation functions are considered and a practical definition is proposed. The method, associated to a mean-square-error criterion, yields the complex form of the conventional backpropagation algorithm. >"
            },
            "slug": "On-the-complex-backpropagation-algorithm-Benvenuto-Piazza",
            "title": {
                "fragments": [],
                "text": "On the complex backpropagation algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A recursive algorithm for updating the coefficients of a neural network structure for complex signals is presented and the method yields the complex form of the conventional backpropagation algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32200093"
                        ],
                        "name": "D. Elliott",
                        "slug": "D.-Elliott",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Elliott",
                            "middleNames": [],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Elliott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59753712,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "ed2f09c22f6fe51ab1cd0e6c76ce01e214679986",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "D.F. Elliott, Transforms and Transform Properties. P.P. Vaidyanathan, Design and Implementation of Digital FIR Fil ters. F.J . Harr is, Multirate FIR Filters for Interpolating and Desampling. N.A. Pashtoon, IIR Digital Filters. P.P. Vaidyanathan, Low-Noise and Low-Sensitivity Digital Filters. P. Yip and K.R. Rao, Fast Discrete Transforms. D.F. Elliott, Fast Fourier Transforms. F.J. Harris, Time Domain Signal Processing with the DFT. J.A. Cadzow, Spectral Analysis. M.T. Silvia, Deconvolution. M.T.Silvia, Time Delay Estimation. N. Ahmed, Adaptive Filtering. G.H. Hostetter, Recursive Estimation. L. Mintzer, Mechanization of Digital Signal Processors. F.J. Harris, Window Generation Computer Program. Each chapter includes references. Index."
            },
            "slug": "Handbook-of-Digital-Signal-Processing:-Engineering-Elliott",
            "title": {
                "fragments": [],
                "text": "Handbook of Digital Signal Processing: Engineering Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This book discusses the design and implementation of Digital FIR Filters for Interpolating and Desampling, and the role of Fourier Transforms in this process."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19357,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30583738"
                        ],
                        "name": "R. Gabel",
                        "slug": "R.-Gabel",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gabel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gabel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113581327"
                        ],
                        "name": "R. Roberts",
                        "slug": "R.-Roberts",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Roberts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Roberts"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53760139,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a91c6d1c8c39237c89bbec612a7d844d543a073a",
            "isKey": false,
            "numCitedBy": 164,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Linear Systems. Discrete-Time Systems. Continuous-Time Systems. The Z-Transform. Fourier Analysis. The Laplace Transform. An Introduction to the Design of Digital Filters. Suggested Readings. Appendices. Glossary. Index."
            },
            "slug": "Signals-and-linear-systems-Gabel-Roberts",
            "title": {
                "fragments": [],
                "text": "Signals and linear systems"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This book discusses linear Systems, Discrete-Time Systems, and Continuous-Time systems, and an Introduction to the Design of Digital Filters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152137393"
                        ],
                        "name": "B. Murdock",
                        "slug": "B.-Murdock",
                        "structuredName": {
                            "firstName": "Bennet",
                            "lastName": "Murdock",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Murdock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "In some models the encoding and decoding operations are bilinear, e.g., Murdock [19], in others the decoding operation in nonlinear, e.g., Hopfield [14], and in others all the operations are nonlinear, e.g., Willshaw [37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Murdock [19], [21], and Lewandowsky and Murdock [17] propose a chaining method of representing sequences in a single memory trace and model a large number of psychological phenomena with it."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "Convolution-correlation memories (sometimes referred to as holographic-like memories) and matrix memories have been regarded as alternative methods for implementing heteroassociative memory [37], [19], [23], [30], [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 15
                            }
                        ],
                        "text": "Eich [ 181 and Murdock [20] both describe methods based on aperiodic convolution."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Murdock uses infinite-dimensional vectors."
                    },
                    "intents": []
                }
            ],
            "corpusId": 144922340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "043d855df364a2676b1be9305ea433f82c5c8d7c",
            "isKey": true,
            "numCitedBy": 213,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-distributed-memory-model-for-serial-order-Murdock",
            "title": {
                "fragments": [],
                "text": "A distributed memory model for serial-order information."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47648537"
                        ],
                        "name": "R. Pike",
                        "slug": "R.-Pike",
                        "structuredName": {
                            "firstName": "Ray",
                            "lastName": "Pike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pike"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 202
                            }
                        ],
                        "text": "Convolution-correlation memories (sometimes referred to as holographic-like memories) and matrix memories have been regarded as alternative methods for implementing heteroassociative memory [37], [19], [23], [30], [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62557045,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90513071f24aa327ac4c9809b220ee7782e05d39",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Comparison-of-convolution-and-matrix-distributed-Pike",
            "title": {
                "fragments": [],
                "text": "Comparison of convolution and matrix distributed memory systems for associative recall and recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46352825"
                        ],
                        "name": "J. Eich",
                        "slug": "J.-Eich",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Eich",
                            "middleNames": [
                                "Metcalfe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eich"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 197652487,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "450f1eddcb53d477fc87525e9d25919651911e2c",
            "isKey": false,
            "numCitedBy": 359,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-composite-holographic-associative-recall-model.-Eich",
            "title": {
                "fragments": [],
                "text": "A composite holographic associative recall model."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2573193"
                        ],
                        "name": "S. Lewandowsky",
                        "slug": "S.-Lewandowsky",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Lewandowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lewandowsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152137393"
                        ],
                        "name": "B. Murdock",
                        "slug": "B.-Murdock",
                        "structuredName": {
                            "firstName": "Bennet",
                            "lastName": "Murdock",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Murdock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Murdock [19], [21], and Lewandowsky and Murdock [ 17 ] propose a chaining method of representing sequences in a single memory trace and model a large number of psychological phenomena with it. The technique used stores both item and pair information in the memory frace, for example, if the sequence of vectors to be stored is abE, then the trace is"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 143145540,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6819a8d119afc3af1494725e16837a9c2534f226",
            "isKey": false,
            "numCitedBy": 465,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Memory-for-Serial-Order-Lewandowsky-Murdock",
            "title": {
                "fragments": [],
                "text": "Memory for Serial Order"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115326739"
                        ],
                        "name": "Alan R. Jones",
                        "slug": "Alan-R.-Jones",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Jones",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan R. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The fastest way to compute convolution is via fast Fourier transforms (FFT\u2019 s) [ 4 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10916470,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4b05410e7625abc5804460c2de24c81729170ed",
            "isKey": false,
            "numCitedBy": 1436,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Fast-Fourier-Transform-Jones",
            "title": {
                "fragments": [],
                "text": "Fast Fourier Transform"
            },
            "venue": {
                "fragments": [],
                "text": "SIGP"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748557"
                        ],
                        "name": "P. Smolensky",
                        "slug": "P.-Smolensky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Smolensky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Smolensky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762553"
                        ],
                        "name": "G. Legendre",
                        "slug": "G.-Legendre",
                        "structuredName": {
                            "firstName": "Geraldine",
                            "lastName": "Legendre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Legendre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2845294"
                        ],
                        "name": "Y. Miyata",
                        "slug": "Y.-Miyata",
                        "structuredName": {
                            "firstName": "Yoshiro",
                            "lastName": "Miyata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Miyata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 67370937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a33dd8f84d36f57debfd85972577a6138d9ca82",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Principles-for-an-Integrated-Connectionist/Symbolic-Smolensky-Legendre",
            "title": {
                "fragments": [],
                "text": "Principles for an Integrated Connectionist/Symbolic Theory of Higher Cognition ; CU-CS-600-92"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Holographic Reduced Representations,"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Rep. CRGTR-91-1, Dept. Comp. Sci., Univ. of Toronto,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Principles for an integrated connectionisthymbolic theory of higher cognition"
            },
            "venue": {
                "fragments": [],
                "text": "Sparse Distributed Memory"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Principles for an integrated connectionisthymbolic theory of higher cognition"
            },
            "venue": {
                "fragments": [],
                "text": "Univ. of Colorado at Boulder"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PLATE: HOLOGRAPHIC REDUCED REPRESENTATIONS"
            },
            "venue": {
                "fragments": [],
                "text": "PLATE: HOLOGRAPHIC REDUCED REPRESENTATIONS"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 34,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Holographic-reduced-representations-Plate/564427596799f7967c91934966cd3c6bd31cb06d?sort=total-citations"
}