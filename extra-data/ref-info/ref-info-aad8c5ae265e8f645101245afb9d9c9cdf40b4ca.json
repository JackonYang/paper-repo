{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 216
                            }
                        ],
                        "text": "Of those using tree banks as a starting point, a significant sub-community is interested in using them to support supervised learning schemes so that the grammar/parser can be created with minimal human intervention [1,2,5,6,8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 153
                            }
                        ],
                        "text": ", when longer sentences are allowed into the testing corpus, The only data point that matches our current results is one for an earlier grammars of ours [5], and that only for very short sentences."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "85A- The tree-bank grammar @ - The PCFG of [5] 17 - The transformational"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18791110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "407d55ee40f1bdb10745155fde211d566c2d0c71",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a language model in which the probability of a sentence is the sum of the individual parse probabilities, and these are calculated using a probabilistic context-free grammar (PCFG) plus statistics on individual words and how they fit into parses. We have used the model to improve syntactic disambiguation. After training on Wall Street Journal (WSJ) text we tested on about 200 WSJ sentence restricted to the 5400 most common words from our training. We observed a 41\\ performance of our PCFG without the use of the word statistics."
            },
            "slug": "Parsing-with-Context-Free-Grammars-and-Word-Charniak",
            "title": {
                "fragments": [],
                "text": "Parsing with Context-Free Grammars and Word Statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A language model in which the probability of a sentence is the sum of the individual parse probabilities, and these are calculated using a probabilistic context-free grammar (PCFG) plus statistics on individual words and how they fit into parses is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 608,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0a14be7e7f5614b91d0f648ae5f2baafc6d7036",
            "isKey": false,
            "numCitedBy": 717,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic natural language parsers have shown themselves to be inadequate for processing highly-ambiguous large-vocabulary text, as is evidenced by their poor performance on domains like the Wall Street Journal, and by the movement away from parsing-based approaches to text-processing in general. In this paper, I describe SPATTER, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result. This work is based on the following premises: (1) grammars are too complex and detailed to develop manually for most interesting domains; (2) parsing models must rely heavily on lexical and contextual information to analyze sentences accurately; and (3) existing n-gram modeling techniques are inadequate for parsing models. In experiments comparing SPATTER with IBM's computer manuals parser, SPATTER significantly outperforms the grammar-based parser. Evaluating SPATTER against the Penn Treebank Wall Street Journal corpus using the PARSEVAL measures, SPATTER achieves 86% precision, 86% recall, and 1.3 crossing brackets per sentence for sentences of 40 words or less, and 91% precision, 90% recall, and 0.5 crossing brackets for sentences between 10 and 20 words in length."
            },
            "slug": "Statistical-Decision-Tree-Models-for-Parsing-Magerman",
            "title": {
                "fragments": [],
                "text": "Statistical Decision-Tree Models for Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "SPATTER is described, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764192"
                        ],
                        "name": "R. Bod",
                        "slug": "R.-Bod",
                        "structuredName": {
                            "firstName": "Rens",
                            "lastName": "Bod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bod"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 216
                            }
                        ],
                        "text": "Of those using tree banks as a starting point, a significant sub-community is interested in using them to support supervised learning schemes so that the grammar/parser can be created with minimal human intervention [1,2,5,6,8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41474267,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e220a7818ea5bdcec7ed704c517ef3a048bab92d",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In Data Oriented Parsing (DOP), an annotated language corpus is used as a virtual stochastic grammar. An input string is parsed by combining subtrees from the corpus. As a consequence, one parse tree can usually be generated by several derivations that involve different subtrees. This leads to a statistics where the probability of a parse is equal to the sum of the probabilities of all its derivations. In (Scha, 1990) an informal introduction to DOP is given, while (Bod, 1992) provides a formalization of the theory. In this paper we show that the maximum probability parse can be estimated in polynomial time by applying Monte Carlo techniques. The model was tested on a set of hand-parsed strings from the Air Travel Information System (ATIS) corpus. Preliminary experiments yield 96% test set parsing accuracy."
            },
            "slug": "Using-an-Annotated-Language-Corpus-as-a-Virtual-Bod",
            "title": {
                "fragments": [],
                "text": "Using an Annotated Language Corpus as a Virtual Stochastic Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The maximum probability parse can be estimated in polynomial time by applying Monte Carlo techniques and the model was tested on a set of hand-parsed strings from the ATIS corpus."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "This tendency has been exploited by Brill\u2019s [2] \u201ctransformational parser,\u201d which starts with the rightbranching analysis of the sentence and then tries to improve on it."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 216
                            }
                        ],
                        "text": "Of those using tree banks as a starting point, a significant sub-community is interested in using them to support supervised learning schemes so that the grammar/parser can be created with minimal human intervention [1,2,5,6,8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 981718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad120a6635aeb1f0fbf798e5a1b97b65e25b716e",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new technique for parsing free text: a transformational grammar1 is automatically learned that is capable of accurately parsing text into binary-branching syntactic trees with nonterminals unlabelled. The algorithm works by beginning in a very naive state of knowledge about phrase structure. By repeatedly comparing the results of bracketing in the current state to proper bracketing provided in the training corpus, the system learns a set of simple structural transformations that can be applied to reduce error. After describing the algorithm, we present results and compare these results to other recent results in automatic grammar induction."
            },
            "slug": "Automatic-Grammar-Induction-and-Parsing-Free-Text:-Brill",
            "title": {
                "fragments": [],
                "text": "Automatic Grammar Induction and Parsing Free Text: A Transformation-Based Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A transformational grammar is automatically learned that is capable of accurately parsing text into binary-branching syntactic trees with nonterminals unlabelled, and a set of simple structural transformations can be applied to reduce error."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": false,
            "numCitedBy": 8177,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 2
                            }
                        ],
                        "text": ", [4] ), and p(N\u2019 ] Q-r) and p(i!k I NZ) are estimated by gathering statistics from the training corpus."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5371566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b84276fe751ca4f1389549281383b151a746107b",
            "isKey": false,
            "numCitedBy": 1140,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nEugene Charniak breaks new ground in artificial intelligence research by presenting statistical language processing from an artificial intelligence point of view in a text for researchers and scientists with a traditional computer science background. \nNew, exacting empirical methods are needed to break the deadlock in such areas of artificial intelligence as robotics, knowledge representation, machine learning, machine translation, and natural language processing (NLP). It is time, Charniak observes, to switch paradigms. This text introduces statistical language processing techniques -- word tagging, parsing with probabilistic context free grammars, grammar induction, syntactic disambiguation, semantic word classes, word-sense disambiguation -- along with the underlying mathematics and chapter exercises. \nCharniak points out that as a method of attacking NLP problems, the statistical approach has several advantages. It is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning: \"one simply gathers statistics.\" \nLanguage, Speech, and Communication"
            },
            "slug": "Statistical-language-learning-Charniak",
            "title": {
                "fragments": [],
                "text": "Statistical language learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Eugene Charniak points out that as a method of attacking NLP problems, the statistical approach has several advantages and is grounded in real text and therefore promises to produce usable results, and it offers an obvious way to approach learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329862"
                        ],
                        "name": "Sharon A. Caraballo",
                        "slug": "Sharon-A.-Caraballo",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Caraballo",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sharon A. Caraballo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6243853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24e5031c567464b858f86c6ca46331f153399bc6",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Best-first parsing methods for natural language try to parse efficiently by considering the most likely constituents first. Some figure of merit is needed by which to compare the likelihood of constituents, and the choice of this figure has a substantial impact on the efficiency of the parser. While several parsers described in the literature have used such techniques, there is little published data on their efficacy, much less attempts to judge their relative merits. We propose and evaluate several figures of merit for best-first parsing, and we identify an easily computable figure of merit that provides excellent performance on various measures and two different grammars."
            },
            "slug": "Figures-of-Merit-for-Best-First-Probabilistic-Chart-Caraballo-Charniak",
            "title": {
                "fragments": [],
                "text": "New Figures of Merit for Best-First Probabilistic Chart Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes and evaluates several figures of merit for best-first parsing, and identifies an easily computable figure of merit that provides excellent performance on various measures and two different grammars."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705097"
                        ],
                        "name": "F. Pereira",
                        "slug": "F.-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "Carlos",
                                "Neves"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725500"
                        ],
                        "name": "Yves Schabes",
                        "slug": "Yves-Schabes",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Schabes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yves Schabes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 63967455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15e4843e2c55843b5c5b429f89dad3d99e801f02",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information (constituent bracketing) in a partially parsed corpus. Experiments on formal and natural language parsed corpora show that the new algorithm can achieve faster convergence and better modeling of hierarchical structure than the original one. In particular, over 90% test set bracketing accuracy was achieved for grammars inferred by our algorithm from a training set of handparsed part-of-speech strings for sentences in the Air Travel Information System spoken language corpus. Finally, the new algorithm has better time complexity than the original one when sufficient bracketing is provided."
            },
            "slug": "Inside-Outside-Reestimation-From-Partially-Corpora-Pereira-Schabes",
            "title": {
                "fragments": [],
                "text": "Inside-Outside Reestimation From Partially Bracketed Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information (constituent bracketing) in a partially parsed corpus to achieve faster convergence and better modeling of hierarchical structure than the original one."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical decision-tree"
            },
            "venue": {
                "fragments": [],
                "text": "Statistical decision-tree"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 9,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Tree-Bank-Grammars-Charniak/aad8c5ae265e8f645101245afb9d9c9cdf40b4ca?sort=total-citations"
}