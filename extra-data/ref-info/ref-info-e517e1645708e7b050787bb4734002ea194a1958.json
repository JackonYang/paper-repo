{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708425"
                        ],
                        "name": "Jay J. Jiang",
                        "slug": "Jay-J.-Jiang",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Jiang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jay J. Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075147"
                        ],
                        "name": "D. Conrath",
                        "slug": "D.-Conrath",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Conrath",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Conrath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 287
                            }
                        ],
                        "text": "Various measures of semantic similarity between wor d pairs have been proposed, some using statistical (unsupervised learning from text) techniques [16, 17, 18], some using lexical databases (hand-built) [19, 20], and some hybrid approaches, combining statistics and lexical information [21, 22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 120
                            }
                        ],
                        "text": "Hybrid approaches attempt to address this problem by supplementing sparse data with information from a lexical d tabase [21, 22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1359050,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b64e068a8face2540fc436af40dbcd2b0912bbf",
            "isKey": false,
            "numCitedBy": 3339,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach for measuring semantic similarity/distance between words and concepts. It combines a lexical taxonomy structure with corpus statistical information so that the semantic distance between nodes in the semantic space constructed by the taxonomy can be better quantified with the computational evidence derived from a distributional analysis of corpus data. Specifically, the proposed measure is a combined approach that inherits the edge-based approach of the edge counting scheme, which is then enhanced by the node-based approach of the information content calculation. When tested on a common data set of word pair similarity ratings, the proposed approach outperforms other computational models. It gives the highest correlation value (r = 0.828) with a benchmark based on human similarity judgements, whereas an upper bound (r = 0.885) is observed when human subjects replicate the same task."
            },
            "slug": "Semantic-Similarity-Based-on-Corpus-Statistics-and-Jiang-Conrath",
            "title": {
                "fragments": [],
                "text": "Semantic Similarity Based on Corpus Statistics and Lexical Taxonomy"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper presents a new approach for measuring semantic similarity/distance between words and concepts that combines a lexical taxonomy structure with corpus statistical information so that the semantic distance between nodes in the semantic space constructed by the taxonomy can be better quantified with the computational evidence derived from a distributional analysis of corpus data."
            },
            "venue": {
                "fragments": [],
                "text": "ROCLING/IJCLCLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746017"
                        ],
                        "name": "G. Grefenstette",
                        "slug": "G.-Grefenstette",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grefenstette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grefenstette"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 147
                            }
                        ],
                        "text": "Various measures of semantic similarity between word pairs have been proposed, some using statistical (unsupervised learning from text) techniques [16, 17, 18], some using lexical databases (hand-built) [19, 20], and some hybrid approaches, combining statistics and lexical information [21, 22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17908075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2d7252950d51f67fb4613c6a364be48baa709b5",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "As more and more text becomes readily available in electronic form, much interest is being generated by finding ways of automatically extracting information from subsets of this text. While manual indexing and automatic keyword indexing are well known, both have drawbacks. Recent research on robust syntactic analysis and statistical correlations promises that some of the intuitive advantages of manual indexing can be retained in a fully automatic system. Here I present an experiment performed with my system SEXTANT which extracts semantically similar words from raw text. Using statistical methods combined with robust syntactic analysis, SEXTANT was able to find many of the intuitive pairings between semantically similar words studied by Deese [Deese, 1954]."
            },
            "slug": "Finding-Semantic-Similarity-in-Raw-Text:-the-Deese-Grefenstette",
            "title": {
                "fragments": [],
                "text": "Finding Semantic Similarity in Raw Text: the Deese Antonyms"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Using statistical methods combined with robust syntactic analysis, SEXTANT was able to find many of the intuitive pairings between semantically similar words studied by Deese [Deese, 1954]."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145165877"
                        ],
                        "name": "P. Hanks",
                        "slug": "P.-Hanks",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Hanks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hanks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21169546"
                        ],
                        "name": "Donald Hindle",
                        "slug": "Donald-Hindle",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hindle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Hindle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 47
                            }
                        ],
                        "text": "PMI-IR uses Pointwise Mutual Information (PMI) [1, 2], as follows:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 156
                            }
                        ],
                        "text": "Pointwise Mutual Information (PMI) has primarily be en applied to analysis of collocation, but there have been some applications to co - c urrence analysis [1, 2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 71
                            }
                        ],
                        "text": "The algorithm, called PMI-IR, uses Pointwise Mutual Inf ormation (PMI) [1, 2] to analyze statistical data collected by Information Retrieval (IR)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5981342,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "ccd5898c79f90c25e24222410d5613edfd007985",
            "isKey": false,
            "numCitedBy": 414,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "The computational tools available for studying machine-readable corpora are at present still rather primitive. In the more advanced lexicographic organizations, there are concordancing programs (see figure below), which are basically KWIC (key word in context (Aho et al., 1988, p. 122), (Salton, 1989, p. 384)) indexes with additional features such as the ability to extend the context, sort leftwards as well as rightwards, and so on. There is very little interactive software. The lack of interactive software is perhaps part of the reason why dictionaries produced in the United States pay little attention to machine-readable corpora, and are based on collections of selected citations, augmented by introspection, rather than analysis of whole texts. The situation is somewhat different in Britain. British lexicographers, especially those working on dictionaries for foreign learners, are beginning to depend heavily on machine-readable corpora. They use these corpora and the basic concordancing tool mentioned above to fill in detailed syntactic descriptions (prompting a move, that will probably dominate lexicography in the 1990s, towards more thorough descriptions of lexical syntax). In the Cobuild project of the 1980s, for example, the typical procedure was that a lexicographer was given the concordances for a word or group of words, marked up the printout with colored pens in order to identify the salient senses, and then wrote syntactic descriptions and definitions."
            },
            "slug": "Using-Statistics-in-Lexical-Analysis-Church-Gale",
            "title": {
                "fragments": [],
                "text": "Using Statistics in Lexical Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The computational tools available for studying machine-readable corpora are at present still rather primitive and use these corpora and the basic concordancing tool mentioned above to fill in detailed syntactic descriptions (prompting a move, towards more thorough descriptions of lexical syntax)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There are several well-known lexical database systems that include synonym information, such as WordNet [12], BRICO [13], and EuroWordNet [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": false,
            "numCitedBy": 13575,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143922219"
                        ],
                        "name": "Raymond Richardson",
                        "slug": "Raymond-Richardson",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Richardson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680223"
                        ],
                        "name": "A. Smeaton",
                        "slug": "A.-Smeaton",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Smeaton",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeaton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149336473"
                        ],
                        "name": "J. Murphy",
                        "slug": "J.-Murphy",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Murphy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Murphy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 203
                            }
                        ],
                        "text": "Various measures of semantic similarity between word pairs have been proposed, some using statistical (unsupervised learning from text) techniques [16, 17, 18], some using lexical databases (hand-built) [19, 20], and some hybrid approaches, combining statistics and lexical information [21, 22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14717926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd43f1dd66646c8b7abd1053fbfc7b447d7cb21e",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose the use of WordNet as a knowledge base in an information retrieval task. The application areas range from information filtering and document retrieval to multimedia retrieval and data sharing in large scale distributed database systems. The WordNet derived knowledge base makes semantic knowledge available which can be used in overcoming many problems associated with the richness of natural language. A semantic similarity measure is also proposed which can be used as an alternative to pattern matching in the comparison process."
            },
            "slug": "Using-WordNet-as-a-Knowledge-Base-for-Measuring-Richardson-Smeaton",
            "title": {
                "fragments": [],
                "text": "Using WordNet as a Knowledge Base for Measuring Semantic Similarity between Words"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This paper proposes the use of WordNet as a knowledge base in an information retrieval task and proposes a semantic similarity measure which can be used as an alternative to pattern matching in the comparison process."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2271549"
                        ],
                        "name": "M. Berry",
                        "slug": "M.-Berry",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Berry",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Berry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2172308"
                        ],
                        "name": "Todd A. Letsche",
                        "slug": "Todd-A.-Letsche",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Letsche",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Todd A. Letsche"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 93
                            }
                        ],
                        "text": "In Section 7, I discuss the interpretation of the results and their significance for LSA and LSI."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "Although there have been some positive results using LSI for IR [8], the results from TREC2 and TREC3 (Text Retrieval Conferences 2 and 3) did not show an advantage to LSI over other leading IR techniques [26]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "To apply LSA to the TOEFL questions, an encyclopedia was used to create a matrix of 61,000 words by 30,473 articles [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 210
                            }
                        ],
                        "text": "Recall the sample TOEFL question: Given the problem word levied and the four alternative words imposed, believed, requested, correlated, which of the alternatives is most similar in meaning to the problem word [8]? Table 1 shows in detail how score 3"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 238
                            }
                        ],
                        "text": "When they applied LSA to the TOEFL questions, Landauer and Dumais used an encyclopedia as the text source, to build a matrix X with 61,000 rows (words) and 30,473 columns (chunks of text; each chunk was one article from the encyclopedia) [6, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "I hypothesize that this query expansion achieves essentially the same effect as LSI, so there is no apparent advantage to LSI when it is compared to an IR system that uses query expansion."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "The hope is that LSI can improve the performance of IR by, in essence, automatically expanding a query with synonyms [7]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "In this paper, I discuss the implications of the new unsupervised learning algorithm and the synonym test results for LSA and LSI."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Latent Semantic Indexing (LSI) applies LSA to Information Retrieval."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "correlated, which of the alternatives is most similar in meaning to the problem word [8]? Let problem represent the problem word and { choice1, choice2, ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "The performance of LSA on the TOEFL test has been widely cited as evidence for the value of LSA and (by relation) LSI."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "The hypothesis implies that LSI will tend to perform better than an IR system without query expansion, but there will be no significant difference between an IR system with LSI and an IR system with query expansion (assuming all other factors are equal)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 104
                            }
                        ],
                        "text": "Another popular statistical approach to measuring semantic similarity is Latent Semantic Analysis (LSA) [6, 7, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "It has been conjectured that the TREC queries are unusually long and detailed, so there is little room for improvement by LSI [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 125
                            }
                        ],
                        "text": "LSA uses the Singular Value Decomposition (SVD) to analyze the statistical relationships among words in a collection of text [6, 7, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "A variation on this algorithm has been applied to information retrieval, where it is known as Latent Semantic Indexing (LSI) [7]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "Table 2 shows the scores calculated by LSA for the same example [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5241605,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c6c555b634fe5f68a274f8ae4423f19c0c5ed07",
            "isKey": true,
            "numCitedBy": 150,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Currently, most approaches to retrieving textual materials from scientific databases depend on a lexical match between words in users\u2019 requests and those in or assigned to documents in a database. Because of the tremendous diversity in the words people use to describe the same document, lexical methods are necessarily incomplete and imprecise. Using the singular value decomposition (SVD), one can take advantage of the implicit higher-order structure in the association of terms with documents by determining the SVD of large sparse term by document matrices. Terms and documents represented by 200-300 of the largest singular vectors are then matched against user queries. We call this retrieval method Latent Semantic Indexing (LSI) because the subspace represents important associative relationships between terms and documents that are not evident in individual documents. LSI is a completely automatic yet intelligent indexing method, widely applicable, and a promising way to improve users\u2019 access to many kinds of textual materials, or to documents and services for which textual descriptions are available. A survey of the computational requirements for managing LSI-encoded databases as well as current and future applications of LSI is presented."
            },
            "slug": "Computational-Methods-for-Intelligent-Information-Berry-Dumais",
            "title": {
                "fragments": [],
                "text": "Computational Methods for Intelligent Information Access"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A survey of the computational requirements for managing LSI-encoded databases as well as current and future applications of LSI is presented, with a promising way to improve users\u2019 access to many kinds of textual materials."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE/ACM SC95 Conference"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 147
                            }
                        ],
                        "text": "Various measures of semantic similarity between word pairs have been proposed, some using statistical (unsupervised learning from text) techniques [16, 17, 18], some using lexical databases (hand-built) [19, 20], and some hybrid approaches, combining statistics and lexical information [21, 22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15698938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd1901f34cc3673072264104885d70555b1a4cdc",
            "isKey": false,
            "numCitedBy": 1928,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Bootstrapping semantics from text is one of the greatest challenges in natural language learning. We first define a word similarity measure based on the distributional pattern of words. The similarity measure allows us to construct a thesaurus using a parsed corpus. We then present a new evaluation methodology for the automatically constructed thesaurus. The evaluation results show that the thesaurus is significantly closer to WordNet than Roget Thesaurus is."
            },
            "slug": "Automatic-Retrieval-and-Clustering-of-Similar-Words-Lin",
            "title": {
                "fragments": [],
                "text": "Automatic Retrieval and Clustering of Similar Words"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A word similarity measure based on the distributional pattern of words allows the automatically constructed thesaurus to be significantly closer to WordNet than Roget Thesaurus is."
            },
            "venue": {
                "fragments": [],
                "text": "COLING-ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797754"
                        ],
                        "name": "U. Zernik",
                        "slug": "U.-Zernik",
                        "structuredName": {
                            "firstName": "Uri",
                            "lastName": "Zernik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Zernik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58067384,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6a7d1669748c30ef108d7874edaf4c8cac73a01c",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Contents: U. Zernik, Introduction. Part I:Lexical Senses. P. Jacobs, Making Sense of Lexical Acquisition. R. Krovetz, Lexical Acquisition and Information Retrieval. B. Slator, Using Context for Sense Preference. U. Zernik, Tagging Word Sense In Corpus. Part II:Lexical Statistics. K. Church, W. Gale, P. Hanks, D. Hindle, Using Statistics in Lexical Analysis. F. Smadja, Macrocoding the Lexicon with Co-Occurrence Knowledge. N. Calzolari, Lexical Databases and Textual Corpora: Perspectives of Integration for a Lexical Knowledge-Base. Part III:Lexical Representation. R. Beckwith, C. Fellbaum, D. Gross, G. Miller, WordNet: A Lexical Database Organized on Psycholinguistic Principles. B. Atkins, B. Levin, Admitting Impediments. B. Dorr, Conceptual Basis of the Lexicon in Machine Translation. M. Dyer, Lexical Acquisition Through Symbol Recirculation. Part IV:Lexical Semantics. P. Velardi, Acquiring a Semantic Lexicon for Natural Language Processing. L. Braden-Harder, W. Zadrozny, Lexicons for Broad Coverage Semantics. J. Martin, Representing and Acquiring Metaphor-Based Polysemy."
            },
            "slug": "Lexical-Acquisition:-Exploiting-On-Line-Resources-a-Zernik",
            "title": {
                "fragments": [],
                "text": "Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book discusses Lexical Acquisition Through Symbol Recirculation, Lexical Representation, and Lexicons for Broad Coverage Semantics, which are concerned with the acquisition of semantic meaning in the Lexical Knowledge-Base."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145165877"
                        ],
                        "name": "P. Hanks",
                        "slug": "P.-Hanks",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Hanks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hanks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 154
                            }
                        ],
                        "text": "Pointwise Mutual Information (PMI) has primarily been applied to analysis of collocation, but there have been some applications to co-occurrence analysis [1, 2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 47
                            }
                        ],
                        "text": "PMI-IR uses Pointwise Mutual Information (PMI) [1, 2], as follows:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 70
                            }
                        ],
                        "text": "The algorithm, called PMI-IR, uses Pointwise Mutual Information (PMI) [1, 2] to analyze statistical data collected by Information Retrieval (IR)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9558665,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "9e2caa39ac534744a180972a30a320ad0ae41ea3",
            "isKey": false,
            "numCitedBy": 4363,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The term word association is used in a very particular sense in the psycholinguistic literature. (Generally speaking, subjects respond quicker than normal to the word nurse if it follows a highly associated word such as doctor. ) We will extend the term to provide the basis for a statistical description of a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/content word) to lexico-syntactic co-occurrence constraints between verbs and prepositions (content word/function word). This paper will propose an objective measure based on the information theoretic notion of mutual information, for estimating word association norms from computer readable corpora. (The standard method of obtaining word association norms, testing a few thousand subjects on a few hundred words, is both costly and unreliable.) The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "slug": "Word-Association-Norms,-Mutual-Information-and-Church-Hanks",
            "title": {
                "fragments": [],
                "text": "Word Association Norms, Mutual Information and Lexicography"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144890574"
                        ],
                        "name": "James Allan",
                        "slug": "James-Allan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Allan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145163573"
                        ],
                        "name": "A. Singhal",
                        "slug": "A.-Singhal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singhal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "Most of the TREC systems use a technique called query expansion [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14683127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97ad6e18573c1472a74f9c9d3624a764e69013ae",
            "isKey": false,
            "numCitedBy": 620,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The Smart information retrieval project emphasizes completely automatic approaches to the understanding and retrieval of large quantities of text. We continue our work in TREC 3, performing runs in the routing, ad-hoc, and foreign language environments. Our major focus is massive query expansion : adding from 300 to 530 terms to each query. These terms come from known relevant documents in the case of routing, and from just the top retrieved documents in the case of ad-hoc and Spanish. This approach improves effectiveness from 7% to 25% in the various experiments. Other ad-hoc work extends our investigations into combining global similarities, giving an overall indication of how a document matches a query, with local similarities identifying a smaller part of the document which matches the query. Using an overlapping text window definition of local, we achieve a 16% improvement."
            },
            "slug": "Automatic-Query-Expansion-Using-SMART:-TREC-3-Buckley-Salton",
            "title": {
                "fragments": [],
                "text": "Automatic Query Expansion Using SMART: TREC 3"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work continues the work in TREC 3, performing runs in the routing, ad-hoc, and foreign language environments, with a major focus on massive query expansion, adding from 300 to 530 terms to each query."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144102674"
                        ],
                        "name": "C. Papadimitriou",
                        "slug": "C.-Papadimitriou",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Papadimitriou",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papadimitriou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145503401"
                        ],
                        "name": "P. Raghavan",
                        "slug": "P.-Raghavan",
                        "structuredName": {
                            "firstName": "Prabhakar",
                            "lastName": "Raghavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Raghavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145955092"
                        ],
                        "name": "H. Tamaki",
                        "slug": "H.-Tamaki",
                        "structuredName": {
                            "firstName": "Hisao",
                            "lastName": "Tamaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Tamaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737804"
                        ],
                        "name": "S. Vempala",
                        "slug": "S.-Vempala",
                        "structuredName": {
                            "firstName": "Santosh",
                            "lastName": "Vempala",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vempala"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "A fast SVD algorithm can find a rank k approximation to an m by n matrix X in time O(mk(2)) [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1479546,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "546fdb984bd63214dac8f552ef8d8ae6fa7c7d1a",
            "isKey": false,
            "numCitedBy": 1050,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Latent semantic indexing LSI is an information retrieval technique based on the spectral analysis of the term document matrix whose empirical success had heretofore been without rigorous prediction and explanation We prove that under certain conditions LSI does succeed in capturing the underlying semantics of the corpus and achieves improved retrieval performance We also propose the technique of random projection as a way of speeding up LSI We complement our theorems with encouraging experimental results We also argue that our results may be viewed in a more general framework as a theoretical basis for the use of spectral methods in a wider class of applications such as collaborative ltering"
            },
            "slug": "Latent-semantic-indexing:-a-probabilistic-analysis-Papadimitriou-Raghavan",
            "title": {
                "fragments": [],
                "text": "Latent semantic indexing: a probabilistic analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is proved that under certain conditions LSI does succeed in capturing the underlying semantics of the corpus and achieves improved retrieval performance."
            },
            "venue": {
                "fragments": [],
                "text": "PODS '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Another popular statistical approach to measuring semantic similarity is Latent Semantic Analysis (LSA) [ 6 , 7, 8]. I will discuss this approach in the next section."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Landauer and Dumais [ 6 ] note that, \u201c\u2026 we have been told that the average score is adequate for admission to many universities.\u201d"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "When they applied LSA to the TOEFL questions, Landauer and Dumais used an encyclopedia as the text source, to build a matrix X with 61,000 rows (words) and 30,473 columns (chunks of text; each chunk was one article from the encyclopedia) [ 6 , 8]. They used SVD to generate a reduced matrix of rank 300."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Landauer and Dumais claim that mutual information analysis would obtain a score of about 37% on the TOEFL questions, given the same source text and chunk size as they used for LSA (footnote 5 in [ 6 ])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "To compress the 61,000 by 30,473 matrix used for the TOEFL questions to a matrix of rank 300 required about three hours of computation on a Unix workstation [ 6 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "LSA achieves a score of 64.4% (51.5/80) on the 80 TOEFL questions [ 6 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "They claim that the score of 36.8%, using the original matrix, \u201c\u2026 is similar to what would be obtained by a mutual information analysis\u2026\u201d (see footnote 5 in [ 6 ])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Table 3. Results of the TOEFL experiments, including LSA results from [ 6 ]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "LSA uses the Singular Value Decomposition (SVD) to analyze the statistical relationships among words in a collection of text [ 6 , 7, 8]. The first step is to use the text to construct a matrix X, in which the row vectors represent words and the column vectors Lecture Notes in Computer Science 6"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Although it might be a challenge to scale LSA up to this volume of text, PMI can easily be scaled down to the encyclopedia text that is used by Landauer and Dumais [ 6 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Landauer and Dumais [ 6 ] write, regarding this score for LSA, \u201cWe know of no other fully automatic application of a knowledge acquisition and representation model, one that does not depend on knowledge being entered by a human but only on its acquisition from the kinds of experience on which a human relies, that has been capable of performing well on a full scale test used for adults.\u201d It is interesting that PMI-IR, which is conceptually ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1144461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68dd4b89ce1407372a29d05ca9e4e1a2e0513617",
            "isKey": true,
            "numCitedBy": 5789,
            "numCiting": 210,
            "paperAbstract": {
                "fragments": [],
                "text": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched."
            },
            "slug": "A-Solution-to-Plato's-Problem:-The-Latent-Semantic-Landauer-Dumais",
            "title": {
                "fragments": [],
                "text": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116657970"
                        ],
                        "name": "J. Lee",
                        "slug": "J.-Lee",
                        "structuredName": {
                            "firstName": "Joon",
                            "lastName": "Lee",
                            "middleNames": [
                                "Ho"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714259"
                        ],
                        "name": "Myoung-Ho Kim",
                        "slug": "Myoung-Ho-Kim",
                        "structuredName": {
                            "firstName": "Myoung-Ho",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Myoung-Ho Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110392249"
                        ],
                        "name": "Yoon-Joon Lee",
                        "slug": "Yoon-Joon-Lee",
                        "structuredName": {
                            "firstName": "Yoon-Joon",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoon-Joon Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 203
                            }
                        ],
                        "text": "Various measures of semantic similarity between word pairs have been proposed, some using statistical (unsupervised learning from text) techniques [16, 17, 18], some using lexical databases (hand-built) [19, 20], and some hybrid approaches, combining statistics and lexical information [21, 22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20403380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "604ea32f139a36631d8cc9f79e678baa4b38db08",
            "isKey": false,
            "numCitedBy": 337,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "There have been several document ranking methods to calculate the conceptual distance or closeness between a Boolean query and a document. Though they provide good retrieval effectiveness in many cases, they do not support effective weighting schemes for queries and documents and also have several problems resulting from inappropriate evaluation of Boolean operators. We propose a new method called Knowledge\u2010Based Extended Boolean Model (kb\u2010ebm) in which Salton's extended Boolean model is incorporated. kb\u2010ebm evaluates weighted queries and documents effectively, and avoids the problems of the previous methods. kb\u2010ebm provides high quality document rankings by using term dependence information from is\u2010a hierarchies The performance experiments show that the proposed method closely simulates human behaviour."
            },
            "slug": "Information-Retrieval-Based-on-Conceptual-Distance-Lee-Kim",
            "title": {
                "fragments": [],
                "text": "Information Retrieval Based on Conceptual Distance in is-a Hierarchies"
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2365155"
                        ],
                        "name": "S. Deerwester",
                        "slug": "S.-Deerwester",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Deerwester",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Deerwester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737579"
                        ],
                        "name": "G. Furnas",
                        "slug": "G.-Furnas",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Furnas",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Furnas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3154682"
                        ],
                        "name": "R. Harshman",
                        "slug": "R.-Harshman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Harshman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Harshman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 104
                            }
                        ],
                        "text": "Another popular statistical approach to measuring semantic similarity is Latent Semantic Analysis (LSA) [6, 7, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "A variation on this algorithm has been applied to information retrieval, where it is known as Latent Semantic Indexing (LSI) [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 125
                            }
                        ],
                        "text": "LSA uses the Singular Value Decomposition (SVD) to analyze the statistical relationships among words in a collection of text [6, 7, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 117
                            }
                        ],
                        "text": "The hope is that LSI can improve the performance of IR by, in essence, automatically expanding a query with synonyms [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3252915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20a80a7356859daa4170fb4da6b87b84adbb547f",
            "isKey": true,
            "numCitedBy": 7019,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising."
            },
            "slug": "Indexing-by-Latent-Semantic-Analysis-Deerwester-Dumais",
            "title": {
                "fragments": [],
                "text": "Indexing by Latent Semantic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new method for automatic indexing and retrieval to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680292"
                        ],
                        "name": "P. Resnik",
                        "slug": "P.-Resnik",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Resnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 287
                            }
                        ],
                        "text": "Various measures of semantic similarity between wor d pairs have been proposed, some using statistical (unsupervised learning from text) techniques [16, 17, 18], some using lexical databases (hand-built) [19, 20], and some hybrid approaches, combining statistics and lexical information [21, 22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 120
                            }
                        ],
                        "text": "Hybrid approaches attempt to address this problem by supplementing sparse data with information from a lexical d tabase [21, 22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7872315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e89ac6de1ed1c63f26168b1afea9b64e0c766f4",
            "isKey": false,
            "numCitedBy": 2273,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a measure of semantic similarity in an IS-A taxonomy based on the notion of shared information content. Experimental evaluation against a benchmark set of human similarity judgments demonstrates that the measure performs better than the traditional edge-counting approach. The article presents algorithms that take advantage of taxonomic similarity in resolving syntactic and semantic ambiguity, along with experimental results demonstrating their effectiveness."
            },
            "slug": "Semantic-Similarity-in-a-Taxonomy:-An-Measure-and-Resnik",
            "title": {
                "fragments": [],
                "text": "Semantic Similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This article presents a measure of semantic similarity in an IS-A taxonomy based on the notion of shared information content that performs better than the traditional edge-counting approach."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791713"
                        ],
                        "name": "P. Vossen",
                        "slug": "P.-Vossen",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Vossen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vossen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "There are several well-known lexical database syste m that include synonym information, such as WordNet [12], BRICO [13], and EuroWor dNet [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46489335,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "b791d488eef45ef79da812f7569fc2cc83196aa5",
            "isKey": false,
            "numCitedBy": 1088,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction to EuroWordNet P. Vossen. The Linguistic Design of the EuroWordNet Database A. Alonge, et al. Compatibility in Interpretation of Relations in EuroWordNet P. Vossen, et al. A Semantic Network of English: The Mother of All WordNets C. Fellbaum. Cross-Linguistic Alignment of Wordnets with an Inter-Lingual-Index W. Peters, et al."
            },
            "slug": "EuroWordNet:-A-multilingual-database-with-lexical-Vossen",
            "title": {
                "fragments": [],
                "text": "EuroWordNet: A multilingual database with lexical semantic networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Cross-Linguistic Alignment of Wordnets with an Inter-Lingual-Index W. Peters, et al."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Netherlands"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "Several authors have observed that PMI is especially sensitive to the sparse data problem [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Statistical approaches to synonym recognition are based on co-occurrence [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "1 For an explanation of the term pointwise mutual information, see [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 307,
                                "start": 304
                            }
                        ],
                        "text": "Manning and Sch\u00fctze distinguish between co-occurrence (or association) and collocation: collocation refers to \u201cgrammatically bound elements that occur in a particular order\u201d, but co-occurrence and association refer to \u201cthe more general phenomenon of words that are likely to be used in the same context\u201d [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "There are many different measures of the degree to which two words co-occur [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "The PMI-IR algorithm, like LSA, is based on co-occurrence [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52800448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084c55d6432265785e3ff86a2e900a49d501c00a",
            "isKey": true,
            "numCitedBy": 7802,
            "numCiting": 294,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications."
            },
            "slug": "Foundations-of-statistical-natural-language-Manning-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Foundations of statistical natural language processing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear and provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 147
                            }
                        ],
                        "text": "Various measures of semantic similarity between word pairs have been proposed, some using statistical (unsupervised learning from text) techniques [16, 17, 18], some using lexical databases (hand-built) [19, 20], and some hybrid approaches, combining statistics and lexical information [21, 22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3211177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d24afe3a62331ebfad400c3fec77c836d2b99db",
            "isKey": false,
            "numCitedBy": 307,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Representations for semantic information about words are necessary for many applications of neural networks in natural language processing. This paper describes an efficient, corpus-based method for inducing distributed semantic representations for a large number of words (50,000) from lexical coccurrence statistics by means of a large-scale linear regression. The representations are successfully applied to word sense disambiguation using a nearest neighbor method."
            },
            "slug": "Word-Space-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Word Space"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An efficient, corpus-based method for inducing distributed semantic representations for a large number of words from lexical coccurrence statistics by means of a large-scale linear regression is described."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786259"
                        ],
                        "name": "S. Brin",
                        "slug": "S.-Brin",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Brin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Brin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84095744"
                        ],
                        "name": "R. Motwani",
                        "slug": "R.-Motwani",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Motwani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Motwani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742391"
                        ],
                        "name": "J. Ullman",
                        "slug": "J.-Ullman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ullman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696775"
                        ],
                        "name": "S. Tsur",
                        "slug": "S.-Tsur",
                        "structuredName": {
                            "firstName": "Shalom",
                            "lastName": "Tsur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tsur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "The most closely related work is the use of interest to discover interesting associations in large databases [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15385590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5074ceb346cfc5f5c139ac77ec359c8e1e83e029",
            "isKey": false,
            "numCitedBy": 2213,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of analyzing market-basket data and present several important contributions. First, we present a new algorithm for finding large itemsets which uses fewer passes over the data than classic algorithms, and yet uses fewer candidate itemsets than methods based on sampling. We investigate the idea of item reordering, which can improve the low-level efficiency of the algorithm. Second, we present a new way of generating \u201cimplication rules,\u201d which are normalized based on both the antecedent and the consequent and are truly implications (not simply a measure of co-occurrence), and we show how they produce more intuitive results than other methods. Finally, we show how different characteristics of real data, as opposed by synthetic data, can dramatically affect the performance of the system and the form of the results."
            },
            "slug": "Dynamic-itemset-counting-and-implication-rules-for-Brin-Motwani",
            "title": {
                "fragments": [],
                "text": "Dynamic itemset counting and implication rules for market basket data"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A new algorithm for finding large itemsets which uses fewer passes over the data than classic algorithms, and yet uses fewer candidate itemsets than methods based on sampling and a new way of generating \u201cimplication rules\u201d which are normalized based on both the antecedent and the consequent."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067046494"
                        ],
                        "name": "Kenneth B. Haase",
                        "slug": "Kenneth-B.-Haase",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Haase",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth B. Haase"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "There are several well-known lexical database systems that include synonym information, such as WordNet [12], BRICO [13], and EuroWordNet [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13470851,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "02391cc4221be3fe808d2cfc4bd35c1d8b755df7",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "BRICO is a broad-coverage ontology built by combining a variety of on-line resources. The initial English ontology has recently been extended to include Spanish, Italian, French, German, and Dutch, and additional extensions are planned. This paper discusses the creation and extension of the interlingual ontology, together with some prototype applications of the database."
            },
            "slug": "Interlingual-BRICO-Haase",
            "title": {
                "fragments": [],
                "text": "Interlingual BRICO"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The creation and extension of the interlingual ontology, together with some prototype applications of the database are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IBM Syst. J."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97426272"
                        ],
                        "name": "B. Steele",
                        "slug": "B.-Steele",
                        "structuredName": {
                            "firstName": "Brett",
                            "lastName": "Steele",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Steele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7278047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2ade7ad915ce8e4e1532a562a3108021a179c6f",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 3150,
            "paperAbstract": {
                "fragments": [],
                "text": "as indicated in a notice appearing later in this work. This electronic representation of RAND intellectual property is provided for noncommercial use only. Permission is required from RAND to reproduce, or reuse in another form, any of our research documents. Limited Electronic Distribution Rights Visit RAND at www.rand.org Explore RAND National Defense Research Institute View document details For More Information This PDF document was made available from www.rand.org as a public service of the RAND Corporation."
            },
            "slug": "For-More-Information-Steele",
            "title": {
                "fragments": [],
                "text": "For More Information"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This electronic representation of RAND intellectual property is provided for noncommercial use only and is required from RAND to reproduce, or reuse in another form, any of the authors' research documents."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the National Cancer Institute"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644080671"
                        ],
                        "name": "BrinSergey",
                        "slug": "BrinSergey",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "BrinSergey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "BrinSergey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643859026"
                        ],
                        "name": "MotwaniRajeev",
                        "slug": "MotwaniRajeev",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "MotwaniRajeev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "MotwaniRajeev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643807360"
                        ],
                        "name": "D. UllmanJeffrey",
                        "slug": "D.-UllmanJeffrey",
                        "structuredName": {
                            "firstName": "D",
                            "lastName": "UllmanJeffrey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. UllmanJeffrey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643993412"
                        ],
                        "name": "TsurShalom",
                        "slug": "TsurShalom",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "TsurShalom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "TsurShalom"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "The mo st closely related work is the use of interest to discover interesting associations in large data b ses [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215915540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e37500f8239ba01f07d1c5a916c90d542d015174",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of analyzing market-basket data and present several important contributions. First, we present a new algorithm for finding large itemsets which uses fewer passes over the da..."
            },
            "slug": "Dynamic-itemset-counting-and-implication-rules-for-BrinSergey-MotwaniRajeev",
            "title": {
                "fragments": [],
                "text": "Dynamic itemset counting and implication rules for market basket data"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work considers the problem of analyzing market-basket data and presents a new algorithm for finding large itemsets which uses fewer passes over the baskets and presents several important contributions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 239
                            }
                        ],
                        "text": "I evaluate the performance of P MI-IR using 80 synonym test questions from the Test of English as a Foreign Languag e (TOEFL) [4] and 50 synonym test questions from a collection of tests for stude nts of English as a Second Language (ESL) [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 231
                            }
                        ],
                        "text": "I evaluate the performance of PMI-IR using 80 synonym test questions from the Test of English as a Foreign Language (TOEFL) [4] and 50 synonym test questions from a collection of tests for students of English as a Second Language (ESL) [5]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "The results with the ESL questions support the view that this performance is not a chance occurrence."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "For example [5], \u201cEvery year in the early spring farmers [tap] maple syrup from their trees (drain; boil; knock; rap)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "To validate the performance of PMI-IR on the TOEFL questions, I obtained another set of 50 synonym test questions [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "There is no context for the TOEFL questions, but the ESL questions involve context."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "The experiments with the TOEFL questions and the ESL questions are presented in Sections 5 and 6, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "To address this issue, I chose only one context word from each ESL question."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "2 For the ESL questions, score4 requires extra queries to select the context word."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "For a given ESL question, I automatically selected the context word by first eliminating the problem word (tap), the alternatives (drain, boil, knock, rap), and stop words (in, the, from, their)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "PMI-IR obtains a score of 73.75% on the 80 TOEFL questions (59/80) and 74% on the 50 ESL questions (37/50)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Basic 2000 Words - Synonym Match 1"
            },
            "venue": {
                "fragments": [],
                "text": "Interactive JavaScript Quizzes for ESL Students, http://www.aitech.ac.jp/~iteslj/quizz  es/js/dt/mc-2000-01syn.html"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Landauer and Dumais [6] write, regarding this score for LSA, \u201cWe know of no other fully automatic application of a knowledge acquisition and representation model, one that does not depend on knowledge being entered by a human but only on its acquisition from the kinds of experience on which a human relies, that has been capable of performing well on a full scale test used for adults.\u201d"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 166
                            }
                        ],
                        "text": "Although it might be a challenge to scale LSA up to t his volume of text, PMI can easily be scaled down to the encyclopedia text that is use d by Landauer and Dumais [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 125
                            }
                        ],
                        "text": "LSA uses the Singular Value Decomposition (SVD) to analyze the statistical relationships among words in a collection of text [6, 7, 8] ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 46
                            }
                        ],
                        "text": "When they applied LSA to the TOEFL questions, Landauer and Dumais used an encyclopedia as the text source, to build a matrix X with 61,000 rows (words) and 30,473 columns (chunks of text; each chunk was one article from the encyclopedia) [6, 8]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "Landau er and Dumais [6] note that, \u201c."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 105
                            }
                        ],
                        "text": "Another popular statistical approach to measuring s emantic similarity is Latent Semantic Analysis (LSA) [6, 7, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Landauer and Dumais [6] write, regarding this score for LSA, \u201cWe know of no other fully auto matic application of a knowledge acquisition and representation model, one that does n t depend on knowledge being entered by a human but only on its acquisition from the kinds of experience on which a human relies, that has been capable of performing well on a full scale test used for adults."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 195
                            }
                        ],
                        "text": "Landauer and Dumais claim that mutual information analysis would obtain a score of about 37% on the TOEFL questions, given the same source text and chunk size as they used for LSA (footnote 5 in [6]) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 144
                            }
                        ],
                        "text": "Although it might be a challenge to scale LSA up to this volume of text, PMI can easily be scaled down to the encyclopedia text that is used by Landauer and Dumais [6]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "Results of the TOEFL experiments, including LSA r esults from [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Landauer and Dumais claim that mutual information analysis would obtain a score of about 37% on the TOEFL questions, given the same source text and chunk size as they used for LSA (footnote 5 in [6])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Landauer and Dumais [6] note that, \u201c\u2026 we have been told that the average score is adequate for admission to many universities.\u201d"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 239
                            }
                        ],
                        "text": "When they applied LSA to the TOEFL questions, Landa uer and Dumais used an encyclopedia as the text source, to build a matrix X with 61,000 rows (words) and 30,473 columns (chunks of text; each chunk was one article from the encyclopedia) [6, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 158
                            }
                        ],
                        "text": "To compress the 61,000 by 30,473 matrix used for the TOEF L questions to a matrix of rank 300 required about three hours of computation on a Unix workstation [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Solution to Plat o\u2019s Problem: The Latent Semantic Analysis Theory of the Acquisition, Induction, and Represent ation of Knowledge"
            },
            "venue": {
                "fragments": [],
                "text": "Psychological Review, 104"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "The PMI-IR algorithm, like LSA, is based on co-occu rrence [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "words that are likely to be used in the same contex t\u201d [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "Several authors have observed that PMI is especiall y sensitive to the sparse data problem [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "Statistical approaches to synonym recognition are b ased on co-occurrence [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "1 For an explanation of the term pointwise mutual information, see [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "There are many different measures of the degree to which two words co-occur [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Foundations of Stati  s ical Natural Language Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Cambridge, Massachusetts: MIT Press"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144191879"
                        ],
                        "name": "J. Firth",
                        "slug": "J.-Firth",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Firth",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Firth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "The core idea is that \u201ca word is characterized by the company it kee ps\u201d [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208093066,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "88b3959b6f5333e5358eac43970a5fa29b54642c",
            "isKey": false,
            "numCitedBy": 1923,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Synopsis-of-Linguistic-Theory,-1930-1955-Firth",
            "title": {
                "fragments": [],
                "text": "A Synopsis of Linguistic Theory, 1930-1955"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745798"
                        ],
                        "name": "Barbara Maria Di Eugenio",
                        "slug": "Barbara-Maria-Di-Eugenio",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Di Eugenio",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barbara Maria Di Eugenio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47147237"
                        ],
                        "name": "Johanna D. Moore",
                        "slug": "Johanna-D.-Moore",
                        "structuredName": {
                            "firstName": "Johanna",
                            "lastName": "Moore",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johanna D. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730942"
                        ],
                        "name": "P. Jordan",
                        "slug": "P.-Jordan",
                        "structuredName": {
                            "firstName": "Pamela",
                            "lastName": "Jordan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695558"
                        ],
                        "name": "R. Thomason",
                        "slug": "R.-Thomason",
                        "structuredName": {
                            "firstName": "Richmond",
                            "lastName": "Thomason",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Thomason"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 164636851,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "f525ce63d0a2613b15833322f378c1963ada1061",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "36th-Annual-Meeting-of-the-Association-for-and-17th-Eugenio-Moore",
            "title": {
                "fragments": [],
                "text": "36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, COLING-ACL '98, August 10-14, 1998, Universit\u00e9 de Montr\u00e9al, Montr\u00e9al, Quebec, Canada. Proceedings of the Conference."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 204
                            }
                        ],
                        "text": "Various measures of semantic similarity between wor d pairs have been proposed, some using statistical (unsupervised learning from text) techniques [16, 17, 18], some using lexical databases (hand-built) [19, 20], and some hybrid approaches, combining statistics and lexical information [21, 22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Re  tri val Based on Conceptual Distance in ISA Hierarchies"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Documentation, 49"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "AltaVista: AltaVista Advanced Search Cheat Sheet, AltaVista Company"
            },
            "venue": {
                "fragments": [],
                "text": "AltaVista: AltaVista Advanced Search Cheat Sheet, AltaVista Company"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Search Engine Sizes. SearchEngineWatch.com, internet.com Corporation"
            },
            "venue": {
                "fragments": [],
                "text": "Search Engine Sizes. SearchEngineWatch.com, internet.com Corporation"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "There are several well-known lexical database syste m that include synonym information, such as WordNet [12], BRICO [13], and EuroWor dNet [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 120
                            }
                        ],
                        "text": "In a large collection of scientific and technical journals, I found that only about 70% of the authors\u2019 keywords were in WordNet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 96
                            }
                        ],
                        "text": "There are several well-known lexical database systems that include synonym information, such as WordNet [12], BRICO [13], and EuroWordNet [14]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "WordNet: An Electronic Lexi  cal Database"
            },
            "venue": {
                "fragments": [],
                "text": "Cambridge, Massachusetts: MIT Press"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Basic 2000 Words -Synonym Match 1. In: Interactive JavaScript Quizzes for ESL Students"
            },
            "venue": {
                "fragments": [],
                "text": "Basic 2000 Words -Synonym Match 1. In: Interactive JavaScript Quizzes for ESL Students"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 205
                            }
                        ],
                        "text": "Although there have been some positive results using LSI for IR [8], the results from TREC2 and TREC3 (Text Retrieval Conferences 2 and 3) did not show an advantage to LSI over other leading IR techniques [26]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparison Between TREC2 and TREC3"
            },
            "venue": {
                "fragments": [],
                "text": "The Third Text REtrieval Conference (TREC3), National Institute of Standards and Technology Special Publication"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "AltaVista indexes 350 million web pages [24] (but only a fraction of them are in English)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 234
                            }
                        ],
                        "text": "suppose that there are about one million English wo rds, then to go from m \u2248 50,000 to m \u2248 1,000,000 is an increase by a factor of 20, so it seems possible for SVD to be applied to the same corpus as AltaVista, 350 millio n web pages [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Search Engine Sizes"
            },
            "venue": {
                "fragments": [],
                "text": "SearchEngine  Watch.com, internet.com Corporation, Darien, Connecticut, http://searchenginewatch.com/r  epo ts/sizes.html"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "WordNet: An Electronic Lexical Database For more information"
            },
            "venue": {
                "fragments": [],
                "text": "WordNet: An Electronic Lexical Database For more information"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 20,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 35,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Mining-the-Web-for-Synonyms:-PMI-IR-versus-LSA-on-Turney/e517e1645708e7b050787bb4734002ea194a1958?sort=total-citations"
}