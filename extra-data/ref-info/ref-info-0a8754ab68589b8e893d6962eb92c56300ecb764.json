{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27068580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd36aa1fcfb2fc07d34adddab03a5872bf5519b4",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recognition-of-printed-text-under-realistic-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Recognition of printed text under realistic conditions"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2768852"
                        ],
                        "name": "W. Sakoda",
                        "slug": "W.-Sakoda",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Sakoda",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Sakoda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2461436"
                        ],
                        "name": "Jiangying Zhou",
                        "slug": "Jiangying-Zhou",
                        "structuredName": {
                            "firstName": "Jiangying",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangying Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "topographic characteristics (saddles, ridges, planes ...) from the underlying continuous surface computed from the digitized gray-scale image [Wang93] [ Sak93 ] [Rocha941 [Trier96].0ther methods process gray-level information directly for the recognition without segmentation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7497922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "318f1ffbfbe3871fe52d79995c588b3ef7c15e54",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for recognizing degraded text is described. One application domain is postal address blocks, where the system must function with varying and unspecified fonts, dot matrix printing, and poor print quality. The design achieves tolerance to differing contrast and degraded print via gray-scale analysis, and omnifont capability and good performance on touching and broken characters by encoding character shapes as graphs. Experimental results on address blocks supplied by the US Postal Service are presented. Experiments on subsampling the data indicate that the performance at 100 dpi is very close to that of the original 300 dpi.<<ETX>>"
            },
            "slug": "Refinement-and-testing-of-a-character-recognition-Sakoda-Zhou",
            "title": {
                "fragments": [],
                "text": "Refinement and testing of a character recognition system based on feature extraction in grayscale space"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A method for recognizing degraded text and achieves tolerance to differing contrast and degraded print via gray-scale analysis, and omnifont capability and good performance on touching and broken characters by encoding character shapes as graphs."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152718968"
                        ],
                        "name": "Li Wang",
                        "slug": "Li-Wang",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32554888,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "658f7d47c1d268c7e676906892826ae2f8bcbab8",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for feature extraction directly from gray-scale images of scanned documents without the usual step of binarization is presented. This approach eliminates binarization by extracting features directly from gray-scale images. In this method, a digitized gray-scale image is treated as a noisy sampling of the underlying continuous surface and desired features are obtained by extracting and assembling topographic characteristics of this surface. The advantages and effectiveness of the approach are both shown theoretically and demonstrated through preliminary experiments of the proposed method. >"
            },
            "slug": "Direct-Gray-Scale-Extraction-of-Features-for-Wang-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Direct Gray-Scale Extraction of Features for Character Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A method for feature extraction directly from gray-scale images of scanned documents without the usual step of binarization is presented and the advantages and effectiveness are both shown theoretically and demonstrated through preliminary experiments of the proposed method."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10639741"
                        ],
                        "name": "H. Yamada",
                        "slug": "H.-Yamada",
                        "structuredName": {
                            "firstName": "Hiromitsu",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Yamada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686714"
                        ],
                        "name": "Kazuhiko Yamamoto",
                        "slug": "Kazuhiko-Yamamoto",
                        "structuredName": {
                            "firstName": "Kazuhiko",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhiko Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47765674"
                        ],
                        "name": "Taiichi Saito",
                        "slug": "Taiichi-Saito",
                        "structuredName": {
                            "firstName": "Taiichi",
                            "lastName": "Saito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taiichi Saito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3311358"
                        ],
                        "name": "Katsumi Hosokawa",
                        "slug": "Katsumi-Hosokawa",
                        "structuredName": {
                            "firstName": "Katsumi",
                            "lastName": "Hosokawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katsumi Hosokawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152856428"
                        ],
                        "name": "Hidenobu Yanagisawa",
                        "slug": "Hidenobu-Yanagisawa",
                        "structuredName": {
                            "firstName": "Hidenobu",
                            "lastName": "Yanagisawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hidenobu Yanagisawa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 60930192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3bdee35da83e6b844f1516b19a104072258d2087",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "As a recognition method of characters stamped on the metal, a process without binarization is proposed. Segmentation and recognition are performed simultaneously by exhaustive pattern matching at every location using multi-angled parallel matching method, where multiple directional planes and graylevel feature are combined as an input feature. The effectiveness is proved by experiments for laser-marked alphanumerics.<<ETX>>"
            },
            "slug": "Laser-marked-alphanumeric-character-recognition-by-Yamada-Yamamoto",
            "title": {
                "fragments": [],
                "text": "Laser-marked alphanumeric character recognition by multi-angled parallel matching method"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "As a recognition method of characters stamped on the metal, a process without binarization is proposed, where multiple directional planes and graylevel feature are combined as an input feature."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794025"
                        ],
                        "name": "\u00c9. Lecolinet",
                        "slug": "\u00c9.-Lecolinet",
                        "structuredName": {
                            "firstName": "\u00c9ric",
                            "lastName": "Lecolinet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. Lecolinet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2762290,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef143fd02fc50dd93dacf1a805dd072bf3a0d71f",
            "isKey": false,
            "numCitedBy": 923,
            "numCiting": 143,
            "paperAbstract": {
                "fragments": [],
                "text": "Character segmentation has long been a critical area of the OCR process. The higher recognition rates for isolated characters vs. those obtained for words and connected character strings well illustrate this fact. A good part of recent progress in reading unconstrained printed and written text may be ascribed to more insightful handling of segmentation. This paper provides a review of these advances. The aim is to provide an appreciation for the range of techniques that have been developed, rather than to simply list sources. Segmentation methods are listed under four main headings. What may be termed the \"classical\" approach consists of methods that partition the input image into subimages, which are then classified. The operation of attempting to decompose the image into classifiable units is called \"dissection.\" The second class of methods avoids dissection, and segments the image either explicitly, by classification of prespecified windows, or implicitly by classification of subsets of spatial features collected from the image as a whole. The third strategy is a hybrid of the first two, employing dissection together with recombination rules to define potential segments, but using classification to select from the range of admissible segmentation possibilities offered by these subimages. Finally, holistic approaches that avoid segmentation by recognizing entire character strings as units are described."
            },
            "slug": "A-Survey-of-Methods-and-Strategies-in-Character-Casey-Lecolinet",
            "title": {
                "fragments": [],
                "text": "A Survey of Methods and Strategies in Character Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "H holistic approaches that avoid segmentation by recognizing entire character strings as units are described, including methods that partition the input image into subimages, which are then classified."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682986"
                        ],
                        "name": "R. Mullot",
                        "slug": "R.-Mullot",
                        "structuredName": {
                            "firstName": "R\u00e9my",
                            "lastName": "Mullot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mullot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144925238"
                        ],
                        "name": "C. Olivier",
                        "slug": "C.-Olivier",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Olivier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Olivier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "134138337"
                        ],
                        "name": "J. Bourdon",
                        "slug": "J.-Bourdon",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bourdon",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bourdon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40269893"
                        ],
                        "name": "P. Courtellemont",
                        "slug": "P.-Courtellemont",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Courtellemont",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Courtellemont"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685183"
                        ],
                        "name": "J. Labiche",
                        "slug": "J.-Labiche",
                        "structuredName": {
                            "firstName": "Jacques",
                            "lastName": "Labiche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Labiche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346993"
                        ],
                        "name": "Y. Lecourtier",
                        "slug": "Y.-Lecourtier",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Lecourtier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lecourtier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63650619,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0f6287be1d8217ca589ab73fd6a4dff8d3a55c61",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Three methods of character area localization in noisy images are proposed, constituting the first treatment of automatic recognition of container or wagon identity numbers, or registration plates of cars. The first method, implemented on a two-transputer network, involves a cognitive approach to segmentation, by the search for vertical segments. The second method, based on signal processing, realizes an AR-modeling of the image background, and uses a rupture detection process. The third method is based on the localization of pertinent transitions, i.e. an increase of the gray level crossing over a given percentage of the scale. These methods have been compared on photographs (512*512 pixels on 256 gray levels) of containers and registration plates. The three methods, debugged and checked with the same images, are shown to give good results.<<ETX>>"
            },
            "slug": "Automatic-extraction-methods-of-container-identity-Mullot-Olivier",
            "title": {
                "fragments": [],
                "text": "Automatic extraction methods of container identity number and registration plates of cars"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "Three methods of character area localization in noisy images are proposed, constituting the first treatment of automatic recognition of container or wagon identity numbers, or registration plates of cars, on a two-transputer network."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IECON '91: 1991 International Conference on Industrial Electronics, Control and Instrumentation"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3154470"
                        ],
                        "name": "A. Elms",
                        "slug": "A.-Elms",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Elms",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Elms"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46949932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1380e8f75e4a6f40f79cef062414ee8e004af2bf",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The recognition of a printed word is traditionally limited by its segmentation into individual characters due to the noise introduced by facsimile transmission, photocopying, handling or ageing. In this paper, a character recogniser is described which does not require a prior segmentation of the word, and is thus suited to the recognition of noisy text images. A novel method is described whereby hidden Markov models are used to recognise a horizontal \"profile\" of a word generated from an analysis of each vertical line of pixels in its image."
            },
            "slug": "A-connected-character-recogniser-using-level-of-Elms",
            "title": {
                "fragments": [],
                "text": "A connected character recogniser using level building of HMMs"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel method is described whereby hidden Markov models are used to recognise a horizontal \"profile\" of a word generated from an analysis of each vertical line of pixels in its image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 12th IAPR International Conference on Pattern Recognition, Vol. 3 - Conference C: Signal Processing (Cat. No.94CH3440-5)"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258400"
                        ],
                        "name": "\u00d8. Trier",
                        "slug": "\u00d8.-Trier",
                        "structuredName": {
                            "firstName": "\u00d8ivind",
                            "lastName": "Trier",
                            "middleNames": [
                                "Due"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00d8. Trier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48717516"
                        ],
                        "name": "T. Taxt",
                        "slug": "T.-Taxt",
                        "structuredName": {
                            "firstName": "Torfinn",
                            "lastName": "Taxt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Taxt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38156129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8291558cd7af28f12e56a19418bf2146451fad48",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates how gray scale information can be used in a hydrographic map understanding system to improve the system performance. To process gray scale scanned map images, we have implemented a topographic analysis method and a binary analysis method. In addition, deconvolution of the gray scale map image was used as an optional preprocessing step for both the methods. Both the methods process the input image by extracting binary print components, recognizing long lines, splitting touching digits and recognizing the digits. The topographic analysis extracts the information by computing topographic labels for each pixel, while the binary analysis is based on locally adaptive thresholding of the gray scale image. The performance of each method was evaluated by measuring the recognition performance of the digit recognition module. Experimental results indicate that the computationally intensive deconvolution and topographic analysis does not improve system performance. The same high performance is achieved by binary analysis, provided a high quality locally adaptive binary method is used."
            },
            "slug": "Gray-scale-processing-of-hydrographic-maps-Trier-Taxt",
            "title": {
                "fragments": [],
                "text": "Gray scale processing of hydrographic maps"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Experimental results indicate that the computationally intensive deconvolution and topographic analysis does not improve system performance, but the same high performance is achieved by binary analysis, provided a high quality locally adaptive binary method is used."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 8,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Robust-multifont-OCR-system-from-gray-level-images-Lebourgeois/0a8754ab68589b8e893d6962eb92c56300ecb764?sort=total-citations"
}