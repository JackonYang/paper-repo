{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Jain and Yu [10] use the traditional bottom-up approach based on the connected component extraction to efficiently implement page segmentation and region identification."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46138594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b39beea0f761152e65fac0e498af387821d887f1",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Transforming a paper document to its electronic version in a form suitable for efficient storage, retrieval, and interpretation continues to be a challenging problem. An efficient representation scheme for document images is necessary to solve this problem. Document representation involves techniques of thresholding, skew detection, geometric layout analysis, and logical layout analysis. The derived representation can then be used in document storage and retrieval. Page segmentation is an important stage in representing document images obtained by scanning journal pages. The performance of a document understanding system greatly depends on the correctness of page segmentation and labeling of different regions such as text, tables, images, drawings, and rulers. We use the traditional bottom-up approach based on the connected component extraction to efficiently implement page segmentation and region identification. A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis. Our algorithm has a high accuracy and takes approximately 1.4 seconds on a SGI Indy workstation for model creation, including orientation estimation, segmentation, and labeling (text, table, image, drawing, and ruler) for a 2550/spl times/3300 image of a typical journal page scanned at 300 dpi. This method is applicable to documents from various technical journals and can accommodate moderate amounts of skew and noise."
            },
            "slug": "Document-Representation-and-Its-Application-to-Page-Jain-Yu",
            "title": {
                "fragments": [],
                "text": "Document Representation and Its Application to Page Decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780258"
                        ],
                        "name": "Jisheng Liang",
                        "slug": "Jisheng-Liang",
                        "structuredName": {
                            "firstName": "Jisheng",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jisheng Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Ha et al. [3], Liang et al. [ 4 ] describe an algorithm based on recursive cutting of connected component projection profiles for segmenting binary document images into zones; zones are classified as textual and nontextual; then the text zones are decomposed to text blocks, text lines, and words."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16777771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e5f3263d6670e98b5f0b7c929501eb1cd1d36f2",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents an efficient technique for document page layout structure extraction and classification by analyzing the spatial configuration of the bounding boxes of different entities on the given image. The algorithm segments an image into a list of homogeneous zones. The classification algorithm labels each zone as test, table, line-drawing, halftone, ruling, or noise. The text lines and words are extracted within text zones and neighboring text lines are merged to form text blocks. The tabular structure is further decomposed into row and column items. Finally, the document layout hierarchy is produced from these extracted entities."
            },
            "slug": "Document-layout-structure-extraction-using-bounding-Liang-Ha",
            "title": {
                "fragments": [],
                "text": "Document layout structure extraction using bounding boxes of different entitles"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "An efficient technique for document page layout structure extraction and classification by analyzing the spatial configuration of the bounding boxes of different entities on the given image by segments an image into a list of homogeneous zones."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Third IEEE Workshop on Applications of Computer Vision. WACV'96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111237291"
                        ],
                        "name": "Su S. Chen",
                        "slug": "Su-S.-Chen",
                        "structuredName": {
                            "firstName": "Su",
                            "lastName": "Chen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su S. Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63629817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "068bc334298658330e9df2ceebeb5f4c76b60b90",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The aim of this study is to apply solid statistical methods to systematically model and extract various layout structures on document images, such as words, text lines and text blocks. \nWe first establish the computation theory of the recursive morphological transforms, namely the recursive erosion transform, the recursive dilation transform, the recursive opening transform, and the recursive closing transform. The transforms serve as a set of powerful tools for the document image shape analysis. \nThen we describe our efforts to construct a series of carefully ground-truthed document image databases, such as the UW English document image database (I). The database offers a platform based on which we can develop, train and evaluate our document layout analysis system. \nWe present three sub-components of our document layout analysis system. They are the text skew estimation, the word segmentation, and the object spatial analysis: \nThe text skew estimation finds the text skew angle of a document image. We develop an automatic text skew estimation algorithm using the recursive opening and closing transforms. It computes the estimated text skew angles which are within 0.5$\\sp\\circ$ of the true text skew angles with a probability of 0.95 on real images. \nThe word segmentation detects all the words on a document image. We describe a word segmentation algorithm that utilizes the recursive closing transform. We derive the quantitative measures, such as the rates of miss, false, correct, splitting, merging and spurious detections, to evaluate its performance. The results show that the algorithm correctly detects the words on a document image at a rate of about 95%. \nThe object spatial analysis treats the detected words as atomic and employs a probabilistic linear displacement model (PLDM) and an augmented PLDM model to model and extract the text lines and text blocks in a document image. By gathering statistics from a large population of document images, we are able to validate our models and determine the proper model parameters. The correct text line and text block detection rates are about 92% and 81% respectively."
            },
            "slug": "Document-layout-analysis-using-recursive-transforms-Chen",
            "title": {
                "fragments": [],
                "text": "Document layout analysis using recursive morphological transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "The aim of this study is to apply solid statistical methods to systematically model and extract various layout structures on document images, such as words, text lines and text blocks, through the computation theory of the recursive morphological transforms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34286355"
                        ],
                        "name": "Shin-Ywan Wang",
                        "slug": "Shin-Ywan-Wang",
                        "structuredName": {
                            "firstName": "Shin-Ywan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shin-Ywan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3128300"
                        ],
                        "name": "T. Yagasaki",
                        "slug": "T.-Yagasaki",
                        "structuredName": {
                            "firstName": "Toshiaki",
                            "lastName": "Yagasaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Yagasaki"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Wang and Yagasaki [9] present a page segmentation method called block selection which segments the page image into categorized blocks and provides a tree structure to represent the page blocks for selection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5434785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1997866ee54ab0b22c90d3d6086932e40a5118e",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a page segmentation method called block selection which not only segments the page image into categorized blocks but also provides a novel tree structure to represent the page blocks for selection. Block selection, more than classifying the text and nontext areas only, can identify the major document elements, such as text, picture, table, frame and line. This ability fits block selection into a wider range of document processing applications. In order to make the usage of block selection more practical to various document styles, many restrictions set on the document by some existing technologies are freed. The language on the document could be English-like, Kanji-like or both. The direction of text could be horizontal, vertical, slanted, or mixed. The editing style of the document is unconstrained. No skew correction is involved regardless of the document style. The formed blocks are described by a hierarchical tree to reflect the page arrangement in the \"object\" sense. This structural result can be efficiently used for further storage, retrieval or other manipulation purposes. The possible applications using this proposed method are discussed."
            },
            "slug": "Block-selection:-a-method-for-segmenting-a-page-of-Wang-Yagasaki",
            "title": {
                "fragments": [],
                "text": "Block selection: a method for segmenting a page image of various editing styles"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A page segmentation method called block selection is presented which not only segments the page image into categorized blocks but also provides a novel tree structure to represent the page blocks for selection that can be efficiently used for further storage, retrieval or other manipulation purposes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6826352,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebbbb7c50c5a5bc6f402230c8c77b83c83db4b48",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation of document images can be performed by projecting image pixels. This pixel projection approach is one of widely used top-down segmentation methods and is based on the assumption that the document image has been correctly deskewed. Unfortunately, the pixel projection approach is computationally inefficient. It is because each symbol is not treated as a computational unit. In this paper, we explain a new technique which is highly tactical in the profiling analysis. Instead of projecting image pixels, we first compute the bounding box of each connected component in a document image and then we project those bounding boxes. Using the new technique, this paper describes how to extract words, text lines, and text blocks (e.g., paragraphs). This bounding box projection approach has many advantages over the pixel projection approach. It is less computationally involved. When applied to text zones, it is also possible to infer from the projection profiles how bounding boxes (and, therefore, primitive symbols) are aligned and/or where significant horizontal and vertical gaps are present. Since the new technique manipulates only bounding boxes, it can be applied to any noncursive language documents."
            },
            "slug": "Document-page-decomposition-using-bounding-boxes-of-Ha-Phillips",
            "title": {
                "fragments": [],
                "text": "Document page decomposition using bounding boxes of connected components of black pixels"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper describes how to extract words, text lines, and text blocks (e.g., paragraphs) using a new technique which is highly tactical in the profiling analysis and has many advantages over the pixel projection approach."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642099"
                        ],
                        "name": "F. Dubiel",
                        "slug": "F.-Dubiel",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Dubiel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Dubiel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Dengel and Dubiel [6] developed a system for partitioning raster images of business letters into logically labeled area items."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19200855,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ea4167f9eb9ad893be32ba35147fe4539b6cdd4",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system which is capable of learning the presentation of document logical structures, exemplarily shown for business letters. Presenting a set of instances to the system, it clusters them into structural concepts and induces a concept hierarchy. This concept hierarchy is taken as a source for classifying future input. The paper introduces the different learning steps, describes how the resulting concept hierarchy is applied for logical labeling and reports on the results."
            },
            "slug": "Clustering-and-classification-of-document-machine-Dengel-Dubiel",
            "title": {
                "fragments": [],
                "text": "Clustering and classification of document structure-a machine learning approach"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A system capable of learning the presentation of document logical structures, exemplarily shown for business letters, is described, which clusters them into structural concepts and induces a concept hierarchy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 226
                            }
                        ],
                        "text": "However, it is clear that many of the early works on document analysis systems provide illustrative results and hardly any have their techniques tested on significant sized data sets and give quantitative performance measures [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13615381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d91e0d202fa23b7a2e81c5b3b04eb4cc5327b0f9",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs. The physical reader of the paper document is the scanner just like the physical reader of the floppy is the floppy drive and the physical reader of the tape cartridge is the tape cartridge drive, and the physical reader of the CDROM is the CDROM drive. In the survey presented, we restrict ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences. Understanding such documents involves estimating the rotation skew of each document page, determining the geometric page layout, labeling blocks as text or non-text, determining the read order for text blocks, recognizing the text of text blocks through an OCR system, determining the logical page layout, and formatting the data and information of the document in a suitable way for use by a word processing system or by an information retrieval system.<<ETX>>"
            },
            "slug": "Document-image-understanding:-geometric-and-logical-Haralick",
            "title": {
                "fragments": [],
                "text": "Document image understanding: geometric and logical layout"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs and restricts ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1896610"
                        ],
                        "name": "S. Randriamasy",
                        "slug": "S.-Randriamasy",
                        "structuredName": {
                            "firstName": "Sabine",
                            "lastName": "Randriamasy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Randriamasy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820595"
                        ],
                        "name": "L. Vincent",
                        "slug": "L.-Vincent",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Randriamasy and Vincent [18] proposed a pixel-level and region-based approach to compare segmentation results and manually generated regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6941199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f05833210f2b2e2f495594aeb98ff66e30c8fa1",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for automatically evaluating the quality of document page segmentation algorithms is introduced. Many different zoning techniques are now available but there is no robust method available to benchmark and evaluate them reliably. Our proposed strategy is a region-based approach, in which segmentation results are compared with manually generated \"ground truth files\", describing all possible correct segmentations. A segmentation ground truthing scheme has been proposed. The evaluation of segmentation quality is achieved by testing the overlap between the two sets of regions. In fact, the regions are defined as the \"black\" pixels contained in the extracted polygons. An explicit specification of segmentation errors and a numerical evaluation are derived. The algorithm is simple and fast, and provides a multi-level output for each segmentation.<<ETX>>"
            },
            "slug": "Benchmarking-page-segmentation-algorithms-Randriamasy-Vincent",
            "title": {
                "fragments": [],
                "text": "Benchmarking page segmentation algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A method for automatically evaluating the quality of document page segmentation algorithms is introduced, in which segmentation results are compared with manually generated \"ground truth files\", describing all possible correct segmentations."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3055160"
                        ],
                        "name": "David J. Ittner",
                        "slug": "David-J.-Ittner",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ittner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Ittner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "Ittner and Baird [5] developed a system for isolating blocks, lines, words, and symbols within images of machine-printed textual documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5360061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bc5bf7115142885992f99516169ea24bf18b529",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for isolating blocks, lines, words, and symbols within images of machine-printed textual documents that is, to a large existent, independent of language and writing system is described. This is achieved by exploiting a small number of nearly universal typesetting and layout conventions. The system does not require prior knowledge of page orientation (module 90/spl deg/), and copes well with nonzero skew and shear angles (within 10/spl deg/). Also it locates blocks of text without reliance on detailed a priori layout models, and in spite of unknown or mixed horizontal and vertical text-line orientations. Within blocks, it infers text-line orientation and isolates lines, without knowledge of the language, symbol set, text sizes, or the number of text lines. Segmentation into words and symbols, and determination of reading order, normally require some knowledge of the language: this is held to minimum by relying on shape-driven algorithms. The underlying algorithms are based on Fourier theory, digital signal processing, computational geometry, and statistical decision theory. Most of the computation occurs within algorithms that possess unambiguous semantics (that is, heuristics are kept to a minimum). The effectiveness of the method on English, Japanese, Hebrew, Thai, and Korean documents is discussed.<<ETX>>"
            },
            "slug": "Language-free-layout-analysis-Ittner-Baird",
            "title": {
                "fragments": [],
                "text": "Language-free layout analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A system for isolating blocks, lines, words, and symbols within images of machine-printed textual documents that is, to a large existent, independent of language and writing system is described, achieved by exploiting a small number of nearly universal typesetting and layout conventions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1971263"
                        ],
                        "name": "K. Etemad",
                        "slug": "K.-Etemad",
                        "structuredName": {
                            "firstName": "Kamran",
                            "lastName": "Etemad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Etemad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13] present an algorithm for layoutindependent document page segmentation based on document texture using multiscale feature vectors and fuzzy local decision information."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27678281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95dffcc92bda88d9f4f5b112d100f43951745b8c",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for layout-independent document page segmentation based on document texture using multiscale feature vectors and fuzzy local decision information. Multiscale feature vectors are classified locally using a neural network to allow soft/fuzzy multi-class membership assignments. Segmentation is performed by integrating soft local decision vectors to reduce their \"ambiguities\"."
            },
            "slug": "Multiscale-Segmentation-of-Unstructured-Document-Etemad-Doermann",
            "title": {
                "fragments": [],
                "text": "Multiscale Segmentation of Unstructured Document Pages Using Soft Decision Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "An algorithm for layout-independent document page segmentation based on document texture using multiscale feature vectors and fuzzy local decision information is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277321"
                        ],
                        "name": "K. Kise",
                        "slug": "K.-Kise",
                        "structuredName": {
                            "firstName": "Koichi",
                            "lastName": "Kise",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kise"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064863306"
                        ],
                        "name": "A. Sato",
                        "slug": "A.-Sato",
                        "structuredName": {
                            "firstName": "Akinori",
                            "lastName": "Sato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40411993"
                        ],
                        "name": "M. Iwata",
                        "slug": "M.-Iwata",
                        "structuredName": {
                            "firstName": "Motoi",
                            "lastName": "Iwata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8] present a method of page segmentation based on the approximated area Voronoi diagram."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 23399574,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "be80678c0eeedf754647a8b9adccd5d6d9be3e86",
            "isKey": false,
            "numCitedBy": 275,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method of page segmentation based on the approximated area Voronoi diagram. The characteristics of the proposed method are as follows: (1) The Voronoi diagram enables us to obtain the candidates of boundaries of document components from page images with non-Manhattan layout and a skew. (2) The candidates are utilized to estimate the intercharacter and interline gaps without the use of domain-specific parameters to select the boundaries. From the experimental results for 128 images with non-Manhattan layout and the skew of 0\u00b0~45\u00b0 as well as 98 images with Manhattan layout, we have confirmed that the method is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis."
            },
            "slug": "Segmentation-of-Page-Images-Using-the-Area-Voronoi-Kise-Sato",
            "title": {
                "fragments": [],
                "text": "Segmentation of Page Images Using the Area Voronoi Diagram"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "It is confirmed that the proposed method of page segmentation based on the approximated area Voronoi diagram is effective for extraction of body text regions, and it is as efficient as other methods based on connected component analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144964966"
                        ],
                        "name": "D. Dori",
                        "slug": "D.-Dori",
                        "structuredName": {
                            "firstName": "Dov",
                            "lastName": "Dori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dori"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The text line extraction algorithm described in this paper is evaluated on a total of 1,600 scanned images from the UW-III Document Image Database [23], [ 24 ], [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206774383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db39e919eb934b70e2cd76ddfbe4cd88138e4acd",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Producing a database of scanned document images for development or evaluation of OCR and document image understanding algorithms is neither easy nor inexpensive. The authors first briefly describe the makeup of a database of scanned document images of scientific and technical documents written in English which are being produced in a CD-ROM format. Then, the authors concentrate on the implementation methodology used to prepare the database. The methodology gives the protocols for each step of the database preparation, and the error model used for the estimation of the ground-truth errors that may exist in the database is discussed.<<ETX>>"
            },
            "slug": "The-implementation-methodology-for-a-CD-ROM-English-Phillips-Ha",
            "title": {
                "fragments": [],
                "text": "The implementation methodology for a CD-ROM English document database"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The authors first briefly describe the makeup of a database of scanned document images of scientific and technical documents written in English which are being produced in a CD-ROM format and concentrate on the implementation methodology used to prepare the database."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741916"
                        ],
                        "name": "M. Garris",
                        "slug": "M.-Garris",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Garris",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Garris [17] proposed a scoring method which computes the coverage and efficiency of zone segmentation algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16555647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8087d6c784d46534bb796d32f2342a0c8e9d2fc7",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces scoring methods developed to automatically assess the performance of document recognition systems, specifically, to evaluate the spatial correspondence of zones produced by a document segmentor. Two different approaches are discussed. The first approach (based on zone overlap and nearest-neighbors) is better applied to merged zones, whereas the second approach (based on zone alignments) is better applied to nested zones (such as those found in tables and graphs). Definitions of coverage and efficiency error are presented, and scoring results on real system output is provided that validates the usefulness of these methods to compare different document recognition algorithms. Currently, no standard testing procedures exist for measuring and comparing algorithms within a complex document recognition system. Scoring methods, like the ones introduced in this paper, serve as design and validations tools, expediting the development and deployment of document analysis technology for system developers and end users."
            },
            "slug": "Evaluating-spatial-correspondence-of-zones-in-Garris",
            "title": {
                "fragments": [],
                "text": "Evaluating spatial correspondence of zones in document recognition systems"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper introduces scoring methods developed to automatically assess the performance of document recognition systems, specifically, to evaluate the spatial correspondence of zones produced by a document segmentor."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., International Conference on Image Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700821"
                        ],
                        "name": "F. Esposito",
                        "slug": "F.-Esposito",
                        "structuredName": {
                            "firstName": "Floriana",
                            "lastName": "Esposito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Esposito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738657"
                        ],
                        "name": "D. Malerba",
                        "slug": "D.-Malerba",
                        "structuredName": {
                            "firstName": "Donato",
                            "lastName": "Malerba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Malerba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467353"
                        ],
                        "name": "G. Semeraro",
                        "slug": "G.-Semeraro",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Semeraro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Semeraro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35702208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8f460360e932140827d341b2d1bfa65cb614b4a",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A study on the possibility of adopting a supervised inductive learning approach to the problem of document understanding is presented. A representation language used to describe a page layout is introduced and the opportunity of extending such a language by means of intentionally defined predicates is discussed. Experimental results obtained by using a well-known learning system, FOCL, are presented. They confirm the exigency of redefining the problem of document understanding in terms of a new strategy of supervised inductive learning, called contextual learning. Some experiments in which a dependence hierarchy between concepts is defined show that contextual rules increase predictive accuracy and decrease learning time for labeling problems like document understanding.<<ETX>>"
            },
            "slug": "Automated-acquisition-of-rules-for-document-Esposito-Malerba",
            "title": {
                "fragments": [],
                "text": "Automated acquisition of rules for document understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Experimental results obtained by using a well-known learning system, FOCL, confirm the exigency of redefining the problem of document understanding in terms of a new strategy of supervised inductive learning, called contextual learning."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111237291"
                        ],
                        "name": "Su S. Chen",
                        "slug": "Su-S.-Chen",
                        "structuredName": {
                            "firstName": "Su",
                            "lastName": "Chen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su S. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "If skew angle skew is larger than the threshold, thresholdskew, we rotate the page by\u00ff skew, using the technique given in [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14079548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a24502cae14f773dc2628bf286a0205b3ef9d1e5",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an algorithm to estimate the text skew angle in a document image. The algorithm utilizes the recursive morphological transforms and yields accurate estimates of text skew angles on a large document image data set. The algorithm computes the optimal parameter settings on the fly without any human interaction. In this automatic mode, experimental results indicate that the algorithm generates estimated text skew angles within 0.5/spl deg/ of the true text skew angles with a probability of 99%. To process a 300 dpi document image, the algorithm takes 10 seconds on SUN Sparc 10 machines."
            },
            "slug": "Automatic-text-skew-estimation-in-document-images-Chen-Haralick",
            "title": {
                "fragments": [],
                "text": "Automatic text skew estimation in document images"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The algorithm utilizes the recursive morphological transforms and yields accurate estimates of text skew angles on a large document image data set and computes the optimal parameter settings on the fly without any human interaction."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141168"
                        ],
                        "name": "P. W. Palumbo",
                        "slug": "P.-W.-Palumbo",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Palumbo",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. W. Palumbo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064971340"
                        ],
                        "name": "Jung Soh",
                        "slug": "Jung-Soh",
                        "structuredName": {
                            "firstName": "Jung",
                            "lastName": "Soh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jung Soh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145912825"
                        ],
                        "name": "R. Sridhar",
                        "slug": "R.-Sridhar",
                        "structuredName": {
                            "firstName": "Ramalingam",
                            "lastName": "Sridhar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sridhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3145150"
                        ],
                        "name": "V. Demjanenko",
                        "slug": "V.-Demjanenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Demjanenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Demjanenko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Palumbo et al. [ 12 ] developed a postal automation system that locates and interprets destination address blocks on letter mail pieces with a high success rate and high speed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16249736,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "3a9e7bd7f8911d5b2d7b4a5a755dfd4f6770589b",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The CEDAR real-time address block location system, which determines candidates for the location of the destination address from a scanned mail piece image, is described. For each candidate destination address block (DAB), the address block location (ABL) system determines the line segmentation, global orientation, block skew, an indication of whether the address appears to be handwritten or machine printed, and a value indicating the degree of confidence that the block actually contains the destination address. With 20-MHz Sparc processors, the average time per mail piece for the combined hardware and software system components is 0.210 seconds. The system located 89.0% of the addresses as the top choice. Recent developments in the system include the use of a top-down segmentation tool, address syntax analysis using only connected component data, and improvements to the segmentation refinement routines. This has increased top choice performance to 91.4%.<<ETX>>"
            },
            "slug": "Postal-address-block-location-in-real-time-Palumbo-Srihari",
            "title": {
                "fragments": [],
                "text": "Postal address block location in real time"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Recent developments in the CEDAR real-time address block location system include the use of a top-down segmentation tool, address syntax analysis using only connected component data, and improvements to the segmentation refinement routines."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111237291"
                        ],
                        "name": "Su S. Chen",
                        "slug": "Su-S.-Chen",
                        "structuredName": {
                            "firstName": "Su",
                            "lastName": "Chen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su S. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "The text line extraction algorithm described in this paper is evaluated on a total of 1,600 scanned images from the UW-III Document Image Database [23], [24], [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "The algorithm was evaluated on the 1,600 scanned document images of the UW-III database [23], [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3258255,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de1580d4cc0c47e4985c8ce52d106c6a7432ff70",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The design of a comprehensive standard document database for machine-printed documents is presented. The effort to produce a series of carefully ground-truthed document databases to be issued on CD-ROMs is described in detail. The databases can be utilized by the OCR and document understanding community as a common platform to develop, test, and evaluate their algorithms.<<ETX>>"
            },
            "slug": "CD-ROM-document-database-standard-Phillips-Chen",
            "title": {
                "fragments": [],
                "text": "CD-ROM document database standard"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The design of a comprehensive standard document database for machine-printed documents is presented and can be utilized by the OCR and document understanding community as a common platform to develop, test, and evaluate their algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2499975"
                        ],
                        "name": "J. Kanai",
                        "slug": "J.-Kanai",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Kanai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kanai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688357"
                        ],
                        "name": "S. V. Rice",
                        "slug": "S.-V.-Rice",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Rice",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. V. Rice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688975"
                        ],
                        "name": "T. Nartker",
                        "slug": "T.-Nartker",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Nartker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nartker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Kanai et al. [ 16 ] proposed a text based method to evaluate the zone segmentation performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30733052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bd99ebf0bbe9a8513350d9eae4f3570c99d559b",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Many current optical character recognition (OCR) systems attempt to decompose printed pages into a set of zones, each containing a single column of text, before converting the characters into coded form. The authors present a methodology for automatically assessing the accuracy of such decompositions, and demonstrate its use in evaluating six OCR systems. >"
            },
            "slug": "Automated-Evaluation-of-OCR-Zoning-Kanai-Rice",
            "title": {
                "fragments": [],
                "text": "Automated Evaluation of OCR Zoning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A methodology for automatically assessing the accuracy of optical character recognition decompositions is presented, and its use in evaluating six OCR systems is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1604429801"
                        ],
                        "name": "Robert M. Haralock",
                        "slug": "Robert-M.-Haralock",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralock",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert M. Haralock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809809"
                        ],
                        "name": "L. Shapiro",
                        "slug": "L.-Shapiro",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Shapiro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 253
                            }
                        ],
                        "text": "Controlled experiments are an important component of computer vision, for the controlled experiment demonstrates that the algorithm, designed by the computer-vision researcher, recognizes, locates, and measures what it is designed to do from image data [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61087042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9eaaecf23f3a4b7822e4bcca924e02cd5b4dc4e",
            "isKey": false,
            "numCitedBy": 3343,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach. The discussion in \"Volume I\" focuses on image in, and image out or feature set out. \"Volume II\" covers the higher level techniques of illumination, perspective projection, analytical photogrammetry, motion, image matching, consistent labeling, model matching, and knowledge-based vision systems."
            },
            "slug": "Computer-and-Robot-Vision-Haralock-Shapiro",
            "title": {
                "fragments": [],
                "text": "Computer and Robot Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15208137,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "baf4491be1f4c1de7ecb03bf81325f6f09bda9c6",
            "isKey": false,
            "numCitedBy": 9488,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "IS B N 0-523108-5) C opright (C ) 19-1992 by C am bidge U nirsity P rss. P rogram s C opright (C ) 19-1992 by N um eical R eipes S ftw are. P rm ission is grnted or inrnet uers to m ke ne pper cpy or teir ow n peonal use. F uther repruction, or ny coying of m acineredable fles (inluding his one) to ny srver om pter, is sictly proibited. T o oder N um eical R eipes boks, disettes, or C D R O M s visit w esite hp://w w w .n.com or call 1-8072-7423 (N orth A m erica oly), or snd em il to trde@ cu.cam .ac.uk (otside N orth A m eca). Numerical Recipes in C"
            },
            "slug": "Numerical-recipes-in-C++:-the-art-of-scientific-2nd-Press",
            "title": {
                "fragments": [],
                "text": "Numerical recipes in C++: the art of scientific computing, 2nd Edition (C++ ed., print. is corrected to software version 2.10)"
            },
            "tldr": {
                "abstractSimilarityScore": 32,
                "text": "F uther repruction, or ny coying of m acineredable fles (inluding his one) to ny srver om pter, is sictly proibited."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48590121"
                        ],
                        "name": "S. Teukolsky",
                        "slug": "S.-Teukolsky",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Teukolsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teukolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608024"
                        ],
                        "name": "W. Vetterling",
                        "slug": "W.-Vetterling",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vetterling",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vetterling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35046585"
                        ],
                        "name": "B. Flannery",
                        "slug": "B.-Flannery",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Flannery",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flannery"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "This equation can be solved by the bracketing and bisection method [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61769312,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ca2832d2c30287a9ee5b8584cc498d2b1cb14753",
            "isKey": false,
            "numCitedBy": 16689,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Note: Includes bibliographical references, 3 appendixes and 2 indexes.- Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08"
            },
            "slug": "Numerical-recipes-in-C-Press-Teukolsky",
            "title": {
                "fragments": [],
                "text": "Numerical recipes in C"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Diskette v 2.06, 3.5''[1.44M] for IBM PC, PS/2 and compatibles [DOS] Reference Record created on 2004-09-07, modified on 2016-08-08."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861837498"
                        ],
                        "name": "G. G. Stokes",
                        "slug": "G.-G.-Stokes",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Stokes",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. G. Stokes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[4] describe an algorithm based on recursive cutting of connected component projection profiles for segmenting binary document images into zones; zones are classified as textual and nontextual; then the text zones are decomposed to text blocks, text lines, and words."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 221060727,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "90006064cafcb0a9ad8a30cffeb56efe7e14129b",
            "isKey": false,
            "numCitedBy": 672630,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "however (for it was the literal soul of the life of the Redeemer, John xv. io), is the peculiar token of fellowship with the Redeemer. That love to God (what is meant here is not God\u2019s love to men) is described in such a case as a perfect love (love that has been perfected), involves no difficulty, for the simple reason that the proposition is purely hypothetical. We must, of course, also take the &dquo;keeping&dquo; in all its stringency. John knows right well that the case supposed here ncver becomes full reality. &dquo; Hereb)\u2019,&dquo; i.e. from the actual realization of love to God. &dquo; TIli7i 7e)e are ill Hinz &dquo;"
            },
            "slug": "\"J.\"-Stokes",
            "title": {
                "fragments": [],
                "text": "\"J.\""
            },
            "venue": {
                "fragments": [],
                "text": "The New Yale Book of Quotations"
            },
            "year": 2021
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "Only the algorithm of Chen [11] takes a systematic approach to integrating the evidence sources they use."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Chen [11] describes a text word, line, and block segmentation algorithm for horizontal rectangular layouts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Only the algorithm of\nChen [11] takes a systematic approach to integrating the\nevidence sources they use."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDocument Layout Analysis Using Recursive Morphological Transforms,o"
            },
            "venue": {
                "fragments": [],
                "text": "PhD thesis, Univ. of Washington,"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "The classic example of this approach is Nagy and Seth's X-Y tree [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59683040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc45263226de157763006aef70b681dbac744dcc",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "HIERARCHICAL-REPRESENTATION-OF-OPTICALLY-SCANNED-Nagy-Seth",
            "title": {
                "fragments": [],
                "text": "HIERARCHICAL REPRESENTATION OF OPTICALLY SCANNED DOCUMENTS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[16] proposed a text based method to evaluate the zone segmentation performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and G"
            },
            "venue": {
                "fragments": [],
                "text": "Nagy, aAutomated Evaluation of OCR Zoning,o IEEE Trans. Pattern Analysis and Machine Intelligence, pp. 86-90, vol. 17"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "The text line extraction algorithm described in this paper is evaluated on a total of 1,600 scanned images from the UW-III Document Image Database [23], [24], [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "The algorithm was evaluated on the 1,600 scanned document images of the UW-III database [23], [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aUser's Reference Manual for the UW English/ Technical Document Image Database III"
            },
            "venue": {
                "fragments": [],
                "text": "Image Database Manual,o technical document, UW III"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and G"
            },
            "venue": {
                "fragments": [],
                "text": "Semeraro, aAutomated Acquisition of Rules for Document Understanding,o Proc. Second Int'l Conf. Document Analysis and Recognition, pp. 650-654"
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 15
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/An-Optimization-Methodology-for-Document-Structure-Liang-Phillips/38055c85deb833ca2ab91190c98feff82eae4f03?sort=total-citations"
}