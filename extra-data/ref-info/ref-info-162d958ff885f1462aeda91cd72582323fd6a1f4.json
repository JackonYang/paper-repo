{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144050629"
                        ],
                        "name": "J. Ben",
                        "slug": "J.-Ben",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Ben",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ben"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2975061"
                        ],
                        "name": "C. Nohl",
                        "slug": "C.-Nohl",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Nohl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nohl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 59
                            }
                        ],
                        "text": "One of the most important ones is called \u201chit and deflect\u201d [115]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44352152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "065b0af1bc05ea4f1fbd2afc50a96b0ef1698c8d",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method, \u201cShortest Path Segmentation\u201d (SPS), which combines dynamic programming and a neural net recognizer for segmenting and recognizing character strings. We describe the application of this method to two problems: recognition of handwritten ZIP Codes, and recognition of handwritten words. For the ZIP Codes, we also used the method to automatically segment the images during training: the dynamic programming stage both performs the segmentation and provides inputs and desired outputs to the neural network. Results are reported for a test set of 2642 unsegmented handwritten 212 dpi binary ZIP Code (5- and 9-digit) images. For handwritten word recognition, we combined SPS with a \u201cSpace Displacement Neural Network\u201d approach, in which a single-character-recognition network is extended over the entire word image, and in which SPS techniques are then used to rank order a given lexicon. We report results on a test set of 3000 300 ppi gray scale word images, extracted from images of live mail pieces, for lexicons of size 10, 100, and 1000. Representing the problem as a graph as proposed in this paper has advantages beyond the efficient finding of the final optimal segmentation, or the automatic segmentation of images during training. We can also easily extend the technique to generate K \u201crunner up\u201d answers (for example, by finding the K shortest paths). This paper will also describe applications of some of these ideas."
            },
            "slug": "Off-Line-Recognition-of-Handwritten-Postal-Words-Burges-Ben",
            "title": {
                "fragments": [],
                "text": "Off Line Recognition of Handwritten Postal Words Using Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A method, \u201cShortest Path Segmentation\u201d (SPS), which combines dynamic programming and a neural net recognizer for segmenting and recognizing character strings is described, and applications of some of these ideas are described."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35091394"
                        ],
                        "name": "Yuchun Lee",
                        "slug": "Yuchun-Lee",
                        "structuredName": {
                            "firstName": "Yuchun",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuchun Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44713185,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9697881f7c675bfe719c0b2e23ffb6be38ddd754",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Results of recent research suggest that carefully designed multilayer neural networks with local receptive fields and shared weights may be unique in providing low error rates on handwritten digit recognition tasks. This study, however, demonstrates that these networks, radial basis function (RBF) networks, and k nearest-neighbor (kNN) classifiers, all provide similar low error rates on a large handwritten digit database. The backpropagation network is overall superior in memory usage and classification time but can provide false positive classifications when the input is not a digit. The backpropagation network also has the longest training time. The RBF classifier requires more memory and more classification time, but less training time. When high accuracy is warranted, the RBF classifier can generate a more effective confidence judgment for rejecting ambiguous inputs. The simple kNN classifier can also perform handwritten digit recognition, but requires a prohibitively large amount of memory and is much slower at classification. Nevertheless, the simplicity of the algorithm and fast training characteristics makes the kNN classifier an attractive candidate in hardware-assisted classification tasks. These results on a large, high input dimensional problem demonstrate that practical constraints including training time, memory usage, and classification time often constrain classifier selection more strongly than small differences in overall error rate."
            },
            "slug": "Handwritten-Digit-Recognition-Using-K-Radial-Basis-Lee",
            "title": {
                "fragments": [],
                "text": "Handwritten Digit Recognition Using K Nearest-Neighbor, Radial-Basis Function, and Backpropagation Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "These results on a large, high input dimensional problem demonstrate that practical constraints including training time, memory usage, and classification time often constrain classifier selection more strongly than small differences in overall error rate."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114709889"
                        ],
                        "name": "I. Poujaud",
                        "slug": "I.-Poujaud",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Poujaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Poujaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3078169"
                        ],
                        "name": "L. Personnaz",
                        "slug": "L.-Personnaz",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Personnaz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Personnaz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097910"
                        ],
                        "name": "G. Dreyfus",
                        "slug": "G.-Dreyfus",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Dreyfus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Dreyfus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116525682"
                        ],
                        "name": "Y. Le Cun",
                        "slug": "Y.-Le-Cun",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Le Cun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Le Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2093637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "590bd948e06e9d07e305fe175c2a86d751ccac2d",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An evaluation is made of several neural network classifiers, comparing their performance on a typical problem, namely handwritten digit recognition. For this purpose, the authors use a database of handwritten digits, with relatively uniform handwriting styles. The authors propose a novel way of organizing the network architectures by training several small networks so as to deal separately with subsets of the problem, and then combining the results. This approach works in conjunction with various techniques including: layered networks with one or several layers of adaptive connections, fully connected recursive networks, ad hoc networks with no adaptive connections, and architectures with second-degree polynomial decision surfaces.<<ETX>>"
            },
            "slug": "Comparing-different-neural-network-architectures-Guyon-Poujaud",
            "title": {
                "fragments": [],
                "text": "Comparing different neural network architectures for classifying handwritten digits"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The authors propose a novel way of organizing the network architectures by training several small networks so as to deal separately with subsets of the problem, and then combining the results."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1848627"
                        ],
                        "name": "U. Bodenhausen",
                        "slug": "U.-Bodenhausen",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Bodenhausen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Bodenhausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2561818"
                        ],
                        "name": "S. Manke",
                        "slug": "S.-Manke",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Manke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Manke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "In speech recognition, where the recognizer is at least one order of magnitude smaller, replicated convolutional networks are easier to implement, for instance in Haffner\u2019s multistate TDNN model [78], [85]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18990153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92a9311686e48d5d20fbfcdc21362251b121096c",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors applied an automatic structure optimization (ASO) algorithm to the optimization of multistate time-delay neural networks (MSTDNNs), an extension of the TDNN. These networks allow the recognition of sequences of ordered events that have to be observed jointly. For example, in many speech recognition systems the recognition of words is decomposed into the recognition of sequences of phonemes or phonemelike units. In handwritten character recognition the recognition of characters can be decomposed into the joined recognition of characteristic strokes, etc. The combination of the proposed ASO algorithm with the MSTDNN was applied successfully to speech recognition and handwritten character recognition tasks with varying amounts of training data.<<ETX>>"
            },
            "slug": "Connectionist-architectural-learning-for-high-and-Bodenhausen-Manke",
            "title": {
                "fragments": [],
                "text": "Connectionist architectural learning for high performance character and speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "The authors applied an automatic structure optimization (ASO) algorithm to the optimization of multistate time-delay neural networks (MSTDNNs), an extension of the TDNN, which was applied successfully to speech recognition and handwritten character recognition tasks with varying amounts of training data."
            },
            "venue": {
                "fragments": [],
                "text": "1993 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 46949455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f807c11196e524d421706f2e471575389c73623",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A new system for the recognition of handwritten text is described. The system goes from raw, binary scanned images of census forms to ASCII transcriptions of the fields contained within the forms. The first step is to locate and extract the handwritten input from the forms. Then, a large number of character subimages are extracted and individual classified using a MLP (multilayer perceptron). A Viterbi-like algorithm is used to assemble the individual classified character subimages into optimal interpretations of an input string, taking into account both the quality of the overall segmentation and the degree to which each character subimage of the segmentation matches a character model. The system uses two different statistical language models, one based on a phrase dictionary and the other based on a simple word grammar. Hypotheses from recognition based on each language model are integrated using a decision tree classifier. Results from the application of the system to the recognition of handwritten responses on US census forms are reported."
            },
            "slug": "A-system-for-the-off-line-recognition-of-text-Breuel",
            "title": {
                "fragments": [],
                "text": "A system for the off-line recognition of handwritten text"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A new system for the recognition of handwritten text that goes from raw, binary scanned images of census forms to ASCII transcriptions of the fields contained within the forms, using two different statistical language models."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 12th IAPR International Conference on Pattern Recognition, Vol. 3 - Conference C: Signal Processing (Cat. No.94CH3440-5)"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189439"
                        ],
                        "name": "J. Vorbr\u00fcggen",
                        "slug": "J.-Vorbr\u00fcggen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Vorbr\u00fcggen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vorbr\u00fcggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075388397"
                        ],
                        "name": "J. Lange",
                        "slug": "J.-Lange",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "that would solve the so-called feature binding problem [87]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[87], LeNet-5 exhibits these properties to a large extent."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1266405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb52984078d75ec5655962dc94dc7848182286b",
            "isKey": false,
            "numCitedBy": 2069,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented. The dynamic link architecture exploits correlations in the fine-scale temporal structure of cellular signals to group neurons dynamically into higher-order entities. These entities represent a rich structure and can code for high-level objects. To demonstrate the capabilities of the dynamic link architecture, a program was implemented that can recognize human faces and other objects from video images. Memorized objects are represented by sparse graphs, whose vertices are labeled by a multiresolution description in terms of a local power spectrum, and whose edges are labeled by geometrical distance vectors. Object recognition can be formulated as elastic graph matching, which is performed here by stochastic optimization of a matching cost function. The implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images. The performance of the program is evaluated by a statistical analysis of recognition results from a portrait gallery comprising images of 87 persons. >"
            },
            "slug": "Distortion-Invariant-Object-Recognition-in-the-Link-Lades-Vorbr\u00fcggen",
            "title": {
                "fragments": [],
                "text": "Distortion Invariant Object Recognition in the Dynamic Link Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented and the implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computers"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145840115"
                        ],
                        "name": "S. Lawrence",
                        "slug": "S.-Lawrence",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Lawrence",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lawrence"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144288586"
                        ],
                        "name": "A. Back",
                        "slug": "A.-Back",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Back",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Back"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2883848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86890c82b589e24007c56e1f40c5f928a0e04183",
            "isKey": false,
            "numCitedBy": 2716,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer."
            },
            "slug": "Face-recognition:-a-convolutional-neural-network-Lawrence-Giles",
            "title": {
                "fragments": [],
                "text": "Face recognition: a convolutional neural-network approach"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A hybrid neural-network for human face recognition which compares favourably with other methods and analyzes the computational complexity and discusses how new classes could be added to the trained recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2561818"
                        ],
                        "name": "S. Manke",
                        "slug": "S.-Manke",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Manke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Manke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1848627"
                        ],
                        "name": "U. Bodenhausen",
                        "slug": "U.-Bodenhausen",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Bodenhausen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Bodenhausen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "such as TDNN\u2019s [44], [111]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "time domain [44], [110], [111]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 501377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bdbc5a8a5ccb718007f0c1999ea7546deb0b473",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Shows how the multi-state time delay neural network (MS-TDNN), which is already used successfully in continuous speech recognition tasks, can be applied both to online single character and cursive (continuous) handwriting recognition. The MS-TDNN integrates the high accuracy single character recognition capabilities of a TDNN with a non-linear time alignment procedure (dynamic time warping algorithm) for finding stroke and character boundaries in isolated, handwritten characters and words. In this approach each character is modelled by up to 3 different states and words are represented as a sequence of these characters. The authors describe the basic MS-TDNN architecture and the input features used in the paper, and present results (up to 97.7% word recognition rate) both on writer dependent/independent, single character recognition tasks and writer dependent, cursive handwriting tasks with varying vocabulary sizes up to 20000 words.<<ETX>>"
            },
            "slug": "A-connectionist-recognizer-for-on-line-cursive-Manke-Bodenhausen",
            "title": {
                "fragments": [],
                "text": "A connectionist recognizer for on-line cursive handwriting recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The MS-TDNN integrates the high accuracy single character recognition capabilities of a TDNN with a non-linear time alignment procedure (dynamic time warping algorithm) for finding stroke and character boundaries in isolated, handwritten characters and words."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ICASSP '94. IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "Globally trained, variablesize TDNN/HMM hybrids have been used for speech recognition and online handwriting recognition [67], [77], [89], [90]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "Experiments in speech recognition with hybrids of NN\u2019s and HMM\u2019s also showed marked improvements brought by global training [29], [67], [77], [84]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Several authors have proposed such methods to train NN/HMM speech recognizers at the word or sentence level [29], [67], [71]\u2013[78]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "Furthermore, it can be shown that separate training is suboptimal [67]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "The recent history of automatic speech recognition [28], [67] is here to remind us that training a recognizer by optimizing a global criterion (at the word or sentence level) is much preferable to merely training it on hand-segmented phonemes or other units."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 223
                            }
                        ],
                        "text": "Numerous authors in speech recognition have used gradient-based learning methods that integrate graphbased statistical models (notably HMM\u2019s) with acoustic recognition modules, mainly Gaussian mixture models, but also NN\u2019s [67], [78], [98], [99]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61008692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a02df6b956612047a9493baba5218f01ed44af00",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Connectionist models Learning theory The back-propagation algorithm Introduction to back-propagation Formal description Heuristics to improve convergence and generalization Extensions Integrating domain knowledge and learning from examples Automatic speech recognition Importance of pre-processing input data Input coding. Input invariances Importance of architecture constraints on the network Modularization Output coding Sequence analysis Introduction Time delay neural networks Recurrent networks BPS Supervision of a recurrent network does not need to be everywhere Problems with training of recurrent networks Dynamic programming post-processors Hidden Markov models Integrating ANNs with other systems Advantages and disadvantages of current algorithms for ANNs Modularization and joint optimization Radial basis functions and local representation Radial basis funtions networks Neurobiological plausibility Relation to vector quantization, clustering and semi-continuous HMMs Methodology Experiments on phoneme recognition with RBFs Density estimation with a neural network Relation between input PDF and output PDF Density estimation Conclusion Post-processors based on dynamic programming ANN/DP hybrids ANN/HMM Hybrids ANN/HMM Hybrid: Phoneme recognition experiments ANN/HMM hybrid: online handwriting recognition experiments."
            },
            "slug": "Neural-networks-for-speech-and-sequence-recognition-Bengio",
            "title": {
                "fragments": [],
                "text": "Neural networks for speech and sequence recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents post-processors based on dynamic programming ANN/DP hybrids ANN/HMM Hybrids, and experiments on phoneme recognition with RBFs and online handwriting recognition experiments."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3145585"
                        ],
                        "name": "O. Matan",
                        "slug": "O.-Matan",
                        "structuredName": {
                            "firstName": "Ofer",
                            "lastName": "Matan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Matan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "SDNN Space displacement neural network."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 202
                            }
                        ],
                        "text": "Although the idea of SDNN is quite old, and very attractive by its simplicity, it has not generated wide interest until recently because as stated above it puts enormous demands on the recognizer [26], [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "A replicated convolutional network, also called a Space Displacement Neural Network or SDNN [27], is shown in Figure 23."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 195
                            }
                        ],
                        "text": "its ability to correctly recognize a well-centered character in its input eld, even in the presence of other characters besides it, while rejecting images containing no centered characters [26], [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3260890,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "464e8d981df7f326c3af6e9d7bd627f83e438816",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a feed-forward network architecture for recognizing an unconstrained handwritten multi-digit string. This is an extension of previous work on recognizing isolated digits. In this architecture a single digit recognizer is replicated over the input. The output layer of the network is coupled to a Viterbi alignment module that chooses the best interpretation of the input. Training errors are propagated through the Viterbi module. The novelty in this procedure is that segmentation is done on the feature maps developed in the Space Displacement Neural Network (SDNN) rather than the input (pixel) space."
            },
            "slug": "Multi-Digit-Recognition-Using-a-Space-Displacement-Matan-Burges",
            "title": {
                "fragments": [],
                "text": "Multi-Digit Recognition Using a Space Displacement Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A feed-forward network architecture for recognizing an unconstrained handwritten multi-digit string with segmentation done on the feature maps developed in the Space Displacement Neural Network rather than the input (pixel) space."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3145585"
                        ],
                        "name": "O. Matan",
                        "slug": "O.-Matan",
                        "structuredName": {
                            "firstName": "Ofer",
                            "lastName": "Matan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Matan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116525682"
                        ],
                        "name": "Y. Le Cun",
                        "slug": "Y.-Le-Cun",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Le Cun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Le Cun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326170"
                        ],
                        "name": "C. E. Stenard",
                        "slug": "C.-E.-Stenard",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Stenard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. E. Stenard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2975061"
                        ],
                        "name": "C. Nohl",
                        "slug": "C.-Nohl",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Nohl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nohl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144050629"
                        ],
                        "name": "J. Ben",
                        "slug": "J.-Ben",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Ben",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ben"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61729936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32315b101afe9bacb725cf80944884e7ac053245",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe a method which combines dynamic programming and a neural network recognizer for segmenting and recognizing character strings. The method selects the optimal consistent combination of cuts from a set of candidate cuts generated using heuristics. The optimal segmentation is found by representing the image, the candidate segments, and their scores as a graph in which the shortest path corresponds to the optimal interpretation. The scores are given by neural net outputs for each segment. A significant advantage of the method is that the labor required to segment images manually is eliminated. The system was trained on approximately 7000 unsegmented handwritten zip codes provided by the United States Postal Service. The system has achieved a per-zip-code raw recognition rate of 81% on a 2368 handwritten zip-code test set.<<ETX>>"
            },
            "slug": "Shortest-path-segmentation:-a-method-for-training-a-Burges-Matan",
            "title": {
                "fragments": [],
                "text": "Shortest path segmentation: a method for training a neural network to recognize character strings"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A method which combines dynamic programming and a neural network recognizer for segmenting and recognizing character strings and has achieved a per-zip-code raw recognition rate of 81% on a 2368 handwritten zip-code test set."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings 1992] IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1952587"
                        ],
                        "name": "J. Keeler",
                        "slug": "J.-Keeler",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Keeler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Keeler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787377"
                        ],
                        "name": "W. Leow",
                        "slug": "W.-Leow",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Leow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Leow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "The input to the first module is the input pattern If the partial derivative of\nwith respect to is known, then the partial derivatives of with respect to and can be computed using the backward recurrence\n(4)\nwhere is the Jacobian of with respect to evaluated at the point and\nis the Jacobian of with\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 894091,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "847d6ece37d22430a0d9e061b5dc1d1b8c679055",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural network algorithms have proven useful for recognition of individual, segmented characters. However, their recognition accuracy has been limited by the accuracy of the underlying segmentation algorithm. Conventional, rule-based segmentation algorithms encounter difficulty if the characters are touching, broken, or noisy. The problem in these situations is that often one cannot properly segment a character until it is recognized yet one cannot properly recognize a character until it is segmented. We present here a neural network algorithm that simultaneously segments and recognizes in an integrated system. This algorithm has several novel features: it uses a supervised learning algorithm (backpropagation), but is able to take position-independent information as targets and self-organize the activities of the units in a competitive fashion to infer the positional information. We demonstrate this ability with overlapping handprinted numerals."
            },
            "slug": "Integrated-Segmentation-and-Recognition-of-Numerals-Keeler-Rumelhart",
            "title": {
                "fragments": [],
                "text": "Integrated Segmentation and Recognition of Hand-Printed Numerals"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A neural network algorithm that simultaneously segments and recognizes in an integrated system that uses a supervised learning algorithm (backpropagation), but is able to take position-independent information as targets and self-organize the activities of the units in a competitive fashion to infer the positional information."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "Several authors have proposed such methods to train neural network/HMM speech recognizers at the word or sentence level [71], [72], [73], [74], [75], [76], [77], [78], [29], [67]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "This GTN is somewhat similar to Hidden Markov Models (HMM), which makes the approach reminiscent of the classical speech recognition [28], [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 172
                            }
                        ],
                        "text": "Similar algorithms have been applied to speech recognition systems that integrate neural networks with time alignment [71], [72], [76] or hybrid neural-network/HMM systems [29], [74], [75]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61058350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d82e058a5c40954b8f5db170a298a889a254c37",
            "isKey": false,
            "numCitedBy": 1409,
            "numCiting": 190,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nConnectionist Speech Recognition: A Hybrid Approach describes the theory and implementation of a method to incorporate neural network approaches into state-of-the-art continuous speech recognition systems based on Hidden Markov Models (HMMs) to improve their performance. In this framework, neural networks (and in particular, multilayer perceptrons or MLPs) have been restricted to well-defined subtasks of the whole system, i.e., HMM emission probability estimation and feature extraction. The book describes a successful five year international collaboration between the authors. The lessons learned form a case study that demonstrates how hybrid systems can be developed to combine neural networks with more traditional statistical approaches. The book illustrates both the advantages and limitations of neural networks in the framework of a statistical system. Using standard databases and comparing with some conventional approaches, it is shown that MLP probability estimation can improve recognition performance. Other approaches are discussed, though there is no such unequivocal experimental result for these methods. Connectionist Speech Recognition: A Hybrid Approach is of use to anyone intending to use neural networks for speech recognition or within the framework provided by an existing successful statistical approach. This includes research and development groups working in the field of speech recognition, both with standard and neural network approaches, as well as other pattern recognition and/or neural network researchers. This book is also suitable as a text for advanced courses on neural networks or speech processing."
            },
            "slug": "Connectionist-Speech-Recognition:-A-Hybrid-Approach-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "Connectionist Speech Recognition: A Hybrid Approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399006281"
                        ],
                        "name": "F. Fogelman-Souli\u00e9",
                        "slug": "F.-Fogelman-Souli\u00e9",
                        "structuredName": {
                            "firstName": "Fran\u00e7oise",
                            "lastName": "Fogelman-Souli\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fogelman-Souli\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072278622"
                        ],
                        "name": "P. Blanchet",
                        "slug": "P.-Blanchet",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Blanchet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Blanchet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145268518"
                        ],
                        "name": "J. Li\u00e9nard",
                        "slug": "J.-Li\u00e9nard",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Li\u00e9nard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Li\u00e9nard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41065888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "830a0c617b99a2cd39517f699fe376442c662816",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speaker-independent-isolated-digit-recognition:-vs.-Bottou-Fogelman-Souli\u00e9",
            "title": {
                "fragments": [],
                "text": "Speaker-independent isolated digit recognition: Multilayer perceptrons vs. Dynamic time warping"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050470845"
                        ],
                        "name": "H. Drucker",
                        "slug": "H.-Drucker",
                        "structuredName": {
                            "firstName": "Harris",
                            "lastName": "Drucker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Drucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2381438,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77b5185dafb9e5b884a677a32713e54c253a4e0b",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A boosting algorithm converts a learning machine with error rate less than 50% to one with an arbitrarily low error rate. However, the algorithm discussed here depends on having a large supply of independent training samples. We show how to circumvent this problem and generate an ensemble of learning machines whose performance in optical character recognition problems is dramatically improved over that of a single network. We report the effect of boosting on four databases (all handwritten) consisting of 12,000 digits from segmented ZIP codes from the United State Postal Service (USPS) and the following from the National Institute of Standards and Testing (NIST): 220,000 digits, 45,000 upper case alphas, and 45,000 lower case alphas. We use two performance measures: the raw error rate (no rejects) and the reject rate required to achieve a 1% error rate on the patterns not rejected. Boosting improved performance in some cases by a factor of three."
            },
            "slug": "Improving-Performance-in-Neural-Networks-Using-a-Drucker-Schapire",
            "title": {
                "fragments": [],
                "text": "Improving Performance in Neural Networks Using a Boosting Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The effect of boosting is reported on four databases consisting of 12,000 digits from segmented ZIP codes from the United State Postal Service and the following from the National Institute of Standards and Testing (NIST)."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3145585"
                        ],
                        "name": "O. Matan",
                        "slug": "O.-Matan",
                        "structuredName": {
                            "firstName": "Ofer",
                            "lastName": "Matan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Matan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120242409"
                        ],
                        "name": "J. Bromley",
                        "slug": "J.-Bromley",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Bromley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bromley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3208372"
                        ],
                        "name": "E. Pednault",
                        "slug": "E.-Pednault",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Pednault",
                            "middleNames": [
                                "P.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pednault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072066281"
                        ],
                        "name": "William Satterfield",
                        "slug": "William-Satterfield",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Satterfield",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Satterfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326170"
                        ],
                        "name": "C. E. Stenard",
                        "slug": "C.-E.-Stenard",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Stenard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. E. Stenard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145427586"
                        ],
                        "name": "Timothy J. Thompson",
                        "slug": "Timothy-J.-Thompson",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Thompson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy J. Thompson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206401851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52a3dca70cc21b540ad5d7b7b6e23744c20095f7",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural network algorithm-based system that reads handwritten ZIP codes appearing on real US mail is described. The system uses a recognition-based segmenter, that is a hybrid of connected-components analysis (CCA), vertical cuts, and a neural network recognizer. Connected components that are single digits are handled by CCA. CCs that are combined or dissected digits are handled by the vertical-cut segmenter. The four main stages of processing are preprocessing, in which noise is removed and the digits are deslanted, CCA segmentation and recognition, vertical-cut-point estimation and segmentation, and directly lookup. The system was trained and tested on approximately 10000 images, five- and nine-digit ZIP code fields taken from real mail.<<ETX>>"
            },
            "slug": "Reading-handwritten-digits:-a-ZIP-code-recognition-Matan-Baird",
            "title": {
                "fragments": [],
                "text": "Reading handwritten digits: a ZIP code recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A neural network algorithm-based system that reads handwritten ZIP codes appearing on real US mail is described, that is a hybrid of connected-components analysis (CCA), vertical cuts, and a neural network recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40396597"
                        ],
                        "name": "Toshiyuki Hanazawa",
                        "slug": "Toshiyuki-Hanazawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Hanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiyuki Hanazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "TDNNs have been used in phoneme recognition (without sub-sampling) [40], [41], spoken word recognition (with sub-sampling) [42], [43], on-line recognition of isolated handwritten characters [44], and signature veri cation [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9563026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd62c9976534a6a2096a38244f6cbb03635a127e",
            "isKey": false,
            "numCitedBy": 2786,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: (1) using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation; and (2) the time-delay arrangement enables the network to discover acoustic-phonetic features and the temporal relationships between them independently of position in time and therefore not blurred by temporal shifts in the input. As a recognition task, the speaker-dependent recognition of the phonemes B, D, and G in varying phonetic contexts was chosen. For comparison, several discrete hidden Markov models (HMM) were trained to perform the same task. Performance evaluation over 1946 testing tokens from three speakers showed that the TDNN achieves a recognition rate of 98.5% correct while the rate obtained by the best of the HMMs was only 93.7%. >"
            },
            "slug": "Phoneme-recognition-using-time-delay-neural-Waibel-Hanazawa",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition using time-delay neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2542741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86ab4cae682fbd49c5a5bedb630e5a40fa7529f6",
            "isKey": false,
            "numCitedBy": 2927,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service."
            },
            "slug": "Handwritten-Digit-Recognition-with-a-Network-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Handwritten Digit Recognition with a Back-Propagation Network"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task, and has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 206
                            }
                        ],
                        "text": "10 Tangent Distance Classi er (TDC) The Tangent Distance classi er (TDC) is a nearestneighbor method where the distance function is made insensitive to small distortions and translations of the input image [61]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11382731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8314dda1ec43ce57ff877f8f02ed89acb68ca035",
            "isKey": false,
            "numCitedBy": 581,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Memory-based classification algorithms such as radial basis functions or K-nearest neighbors typically rely on simple distances (Euclidean, dot product...), which are not particularly meaningful on pattern vectors. More complex, better suited distance measures are often expensive and rather ad-hoc (elastic matching, deformable templates). We propose a new distance measure which (a) can be made locally invariant to any set of transformations of the input and (b) can be computed efficiently. We tested the method on large handwritten character databases provided by the Post Office and the NIST. Using invariances with respect to translation, rotation, scaling, shearing and line thickness, the method consistently outperformed all other systems tested on the same databases."
            },
            "slug": "Efficient-Pattern-Recognition-Using-a-New-Distance-Simard-LeCun",
            "title": {
                "fragments": [],
                "text": "Efficient Pattern Recognition Using a New Transformation Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new distance measure which can be made locally invariant to any set of transformations of the input and can be computed efficiently is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771659"
                        ],
                        "name": "R. Freund",
                        "slug": "R.-Freund",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Freund",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Other authors have used Neural Networks, or other classi ers such as Support Vector Machines for face detection with great success [96], [97]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2845602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9008cdacbdcff8a218a6928e94fe7c6dfc237b24",
            "isKey": false,
            "numCitedBy": 2841,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points."
            },
            "slug": "Training-support-vector-machines:-an-application-to-Osuna-Freund",
            "title": {
                "fragments": [],
                "text": "Training support vector machines: an application to face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets is presented, and the feasibility of the approach on a face detection problem that involves a data set of 50,000 data points is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Following [82], we therefore prefer to postpone normalization as far as possible (in fact, until the final decision stage of the system)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "This local normalization of penalties may eliminate information that is important for locally rejecting all the classes [82], e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14958176,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a759fa3fd36e1d78191d33cdb1fb454959553470",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We have constructed a system for recognizing multi-character images 1. This is a nontrivial extension of our previous work on single-character images. It is somewhat surprising that a very good single-character recognizer does not in general form a good basis for a multi-character recognizer. The correct solution depends on three key ideas: 1) A method for normalizing probabilities correctly, to preserve information on the quality of the segmentation; 2) A method for giving credit for multiple segmentations that assign the same interpretation to the image; and 3) A method that combines recognition and segmentation into a single adaptive process, trained to maximize the score of the right answer. We also discuss improved ways of analyzing recognizer performance. A major part of this technical report is devoted to giving our methods a good theoretical footing. In particular, we do not start by asserting that maximum likelihood is obviously the right thing to do. Instead, the problem is formalized in terms of a probability measure; the learning algorithm must then be arranged to make this probability conform to the customer\u2019s needs. This formulation can be applied to other segmentation problems such as speech recognition. Our recognizer using these principles works noticeably better than the previous state of the art. This work also appeared, with the same title and authors, in The Mathematics of Generalization: Proceedings of the SFI/CNLS Workshop on Formal Approaches to Supervised Learning, Addison"
            },
            "slug": "Image-Segmentation-and-Recognition-Denker-Burges",
            "title": {
                "fragments": [],
                "text": "Image Segmentation and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A system for recognizing multi-character images and a recognizer using these principles works noticeably better than the previous state of the art, and can be applied to other segmentation problems such as speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41312633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
            "isKey": false,
            "numCitedBy": 7828,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification."
            },
            "slug": "Backpropagation-Applied-to-Handwritten-Zip-Code-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Backpropagation Applied to Handwritten Zip Code Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper demonstrates how constraints from the task domain can be integrated into a backpropagation network through the architecture of the network, successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2443457"
                        ],
                        "name": "M. Schenkel",
                        "slug": "M.-Schenkel",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Schenkel",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schenkel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073469360"
                        ],
                        "name": "H. Weissman",
                        "slug": "H.-Weissman",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Weissman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Weissman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2975061"
                        ],
                        "name": "C. Nohl",
                        "slug": "C.-Nohl",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Nohl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nohl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "Globally trained, variablesize TDNN/HMM hybrids have been used for speech recognition and online handwriting recognition [67], [77], [89], [90]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14432769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4d2207b9b9ee71da7b24c7172e5107492dd421d",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports on the performance of two methods for recognition-based segmentation of strings of on-line handprinted capital Latin characters. The input strings consist of a time-ordered sequence of X-Y coordinates, punctuated by pen-lifts. The methods were designed to work in \"run-on mode\" where there is no constraint on the spacing between characters. While both methods use a neural network recognition engine and a graph-algorithmic post-processor, their approaches to segmentation are quite different. The first method, which we call INSEG (for input segmentation), uses a combination of heuristics to identify particular penlifts as tentative segmentation points. The second method, which we call OUTSEG (for output segmentation), relies on the empirically trained recognition engine for both recognizing characters and identifying relevant segmentation points."
            },
            "slug": "Recognition-Based-Segmentation-of-On-Line-Words-Schenkel-Weissman",
            "title": {
                "fragments": [],
                "text": "Recognition-Based Segmentation of On-Line Hand-Printed Words"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper reports on the performance of two methods for recognition-based segmentation of strings of on-line handprinted capital Latin characters, using a neural network recognition engine and a graph-algorithmic post-processor."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144144572"
                        ],
                        "name": "G. Martin",
                        "slug": "G.-Martin",
                        "structuredName": {
                            "firstName": "Gale",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Martin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 207744862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfb28df0e6a807cabdecc8ab5ca9c9ed006be7c0",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual object recognition is often conceived of as a final step in a visual processing system, First, physical information in the raw image is used to isolate and enhance to-be-recognized clumps and then each of the resulting preprocessed representations is fed into the recognizer. This general conception fails when there are no reliable physical cues for isolating the objects, such as when objects overlap. This paper describes an approach, called centered object integrated segmentation and recognition (COISR), for integrating object segmentation and recognition within a single neural network. The application is handprinted character recognition. The approach uses a backpropagation network that scans a field of characters and is trained to recognize whether it is centered over a single character or between characters. When it is centered over a character, the net classifies the character. The approach is tested on a dataset of handprinted digits and high accuracy rates are reported."
            },
            "slug": "Centered-Object-Integrated-Segmentation-and-of-Martin",
            "title": {
                "fragments": [],
                "text": "Centered-Object Integrated Segmentation and Recognition of Overlapping Handprinted Characters"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The approach uses a backpropagation network that scans a field of characters and is trained to recognize whether it is centered over a single character or between characters, which classifies the character."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145334214"
                        ],
                        "name": "M. Rahim",
                        "slug": "M.-Rahim",
                        "structuredName": {
                            "firstName": "Mazin",
                            "lastName": "Rahim",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rahim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16898930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a5c494c9ac68c8915d9df880a3bf6fe48a696a8",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "AUTOMATIC SPEECH RECOGNITION Mazin Rahim, Yoshua Bengio and Yann LeCun AT&T Labs Research, 600 Mountain Avenue, Murray Hill, New Jersey 07974, USA ABSTRACT A system for discriminative feature and model design is presented for automatic speech recognition. Training based on minimum classi cation error with a single objective function is applied for designing a set of parallel networks performing feature transformation and a set of hidden Markov models performing speech recognition. This paper compares the use of linear and non-linear functional transformations when applied to conventional recognition features, such as spectrum or cepstrum. It also provides a framework for integrated feature and model training when using class-speci c transformations. Experimental results on telephone-based connected digit recognition are presented."
            },
            "slug": "Discriminative-feature-and-model-design-for-speech-Rahim-Bengio",
            "title": {
                "fragments": [],
                "text": "Discriminative feature and model design for automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper compares the use of linear and non-linear functional transformations when applied to conventional recognition features, such as spectrum or cepstrum and provides a framework for integrated feature and model training when using class-speci c transformations."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59636530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f462943c8d0af69c12a09058251848324135e5a",
            "isKey": false,
            "numCitedBy": 1100,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We are concerned with feed-forward non-linear networks (multi-layer perceptrons, or MLPs) with multiple outputs. We wish to treat the outputs of the network as probabilities of alternatives (e.g. pattern classes), conditioned on the inputs. We look for appropriate output non-linearities and for appropriate criteria for adaptation of the parameters of the network (e.g. weights). We explain two modifications: probability scoring, which is an alternative to squared error minimisation, and a normalised exponential (softmax) multi-input generalisation of the logistic non-linearity. The two modifications together result in quite simple arithmetic, and hardware implementation is not difficult either. The use of radial units (squared distance instead of dot product) immediately before the softmax output stage produces a network which computes posterior distributions over class labels based on an assumption of Gaussian within-class distributions. However the training, which uses cross-class information, can result in better performance at class discrimination than the usual within-class training method, unless the within-class distribution assumptions are actually correct."
            },
            "slug": "Probabilistic-Interpretation-of-Feedforward-Network-Bridle",
            "title": {
                "fragments": [],
                "text": "Probabilistic Interpretation of Feedforward Classification Network Outputs, with Relationships to Statistical Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Two modifications are explained: probability scoring, which is an alternative to squared error minimisation, and a normalised exponential (softmax) multi-input generalisation of the logistic non- linearity of feed-forward non-linear networks with multiple outputs."
            },
            "venue": {
                "fragments": [],
                "text": "NATO Neurocomputing"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2779846"
                        ],
                        "name": "H. Sakoe",
                        "slug": "H.-Sakoe",
                        "structuredName": {
                            "firstName": "Hiroaki",
                            "lastName": "Sakoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sakoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2216243"
                        ],
                        "name": "R. Isotani",
                        "slug": "R.-Isotani",
                        "structuredName": {
                            "firstName": "Ryosuke",
                            "lastName": "Isotani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Isotani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2293165"
                        ],
                        "name": "Kazunaga Yoshida",
                        "slug": "Kazunaga-Yoshida",
                        "structuredName": {
                            "firstName": "Kazunaga",
                            "lastName": "Yoshida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazunaga Yoshida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861227"
                        ],
                        "name": "K. Iso",
                        "slug": "K.-Iso",
                        "structuredName": {
                            "firstName": "Ken-ichi",
                            "lastName": "Iso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Iso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110691850"
                        ],
                        "name": "Takao Watanabe",
                        "slug": "Takao-Watanabe",
                        "structuredName": {
                            "firstName": "Takao",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takao Watanabe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61946039,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b62a2f2c2cdf561bab99b2cb66477a3a7ad9ca90",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A description is given of speaker-independent word recognition based on a new neural network model called the dynamic programming neural network (DNN), which can treat time-sequence patterns. DNN is based on the integration of a multilayer neural network and dynamic-programming-based matching. Speaker-independent isolated Japanese digit recognition experiments were carried out using data uttered by 107 speakers (50 speakers for training and 57 speakers for testing). The recognition accuracy was 99.3%, suggesting that the model can be effective for speech recognition.<<ETX>>"
            },
            "slug": "Speaker-independent-word-recognition-using-dynamic-Sakoe-Isotani",
            "title": {
                "fragments": [],
                "text": "Speaker-independent word recognition using dynamic programming neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Speaker-independent isolated Japanese digit recognition experiments were carried out using data uttered by 107 speakers, suggesting that the dynamic programming neural network model can be effective for speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113981914"
                        ],
                        "name": "P. Albrecht",
                        "slug": "P.-Albrecht",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Albrecht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Albrecht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 116
                            }
                        ],
                        "text": "Fixed-size convolutional networks that share weights along a single temporal dimension are known as time-delay NN\u2019s (TDNN\u2019s)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "The recognition may then be performed using curve matching [110], or other classi cation techniques such as TDNNs [44], [111]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "TDNN\u2019s have been used in phoneme recognition (without subsampling) [40], [41], spoken word recognition (with subsampling) [42], [43], online recognition of isolated handwritten characters [44], and signature verification [45]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "TDNNs have been used in phoneme recognition (without sub-sampling) [40], [41], spoken word recognition (with sub-sampling) [42], [43], on-line recognition of isolated handwritten characters [44], and signature veri cation [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "The recognition of handwritten characters from a pen trajectory on a digitizing surface is often done in the time domain [110], [44], [111]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37435941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "adf724f637afdb300426df8d2ff4c4342f1e7528",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Design-of-a-neural-network-character-recognizer-for-Guyon-Albrecht",
            "title": {
                "fragments": [],
                "text": "Design of a neural network character recognizer for a touch terminal"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2975061"
                        ],
                        "name": "C. Nohl",
                        "slug": "C.-Nohl",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Nohl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nohl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Fixed-size convolutional networks have been applied to many applications, among other handwriting recognition [35], [36], machine-printed character recognition [37], online handwriting recognition [38], and face recognition [39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3179635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a4192fd6efb5661eca197cce24289776a4fbcc2",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new approach for on-line recognition of handwritten words written in unconstrained mixed style. The preprocessor performs a word-level normalization by fitting a model of the word structure using the EM algorithm. Words are then coded into low resolution \"annotated images\" where each pixel contains information about trajectory direction and curvature. The recognizer is a convolution network that can be spatially replicated. From the network output, a hidden Markov model produces word scores. The entire system is globally trained to minimize word-level errors."
            },
            "slug": "LeRec:-A-NN/HMM-Hybrid-for-On-Line-Handwriting-Bengio-LeCun",
            "title": {
                "fragments": [],
                "text": "LeRec: A NN/HMM Hybrid for On-Line Handwriting Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new approach for on-line recognition of handwritten words written in unconstrained mixed style by fitting a model of the word structure using the EM algorithm to minimize word-level errors."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32703822"
                        ],
                        "name": "C. Dugast",
                        "slug": "C.-Dugast",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Dugast",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dugast"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713369"
                        ],
                        "name": "L. Devillers",
                        "slug": "L.-Devillers",
                        "structuredName": {
                            "firstName": "Laurence",
                            "lastName": "Devillers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Devillers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122690"
                        ],
                        "name": "X. Aubert",
                        "slug": "X.-Aubert",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Aubert",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Aubert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "Globally trained, variablesize TDNN/HMM hybrids have been used for speech recognition and online handwriting recognition [67], [77], [89], [90]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9923325,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b06fd351d10eccb830b75deb6061ffa3382f4166",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents a hybrid continuous-speech recognition system that leads to improved results on the speaker dependent DARPA Resource Management task. This hybrid system, called the combined system, is based on a combination of normalized neural network output scores with hidden Markov model (HMM) emission probabilities. The neural network is trained under mean square error and the HMM is trained under maximum likelihood estimation. In theory, whatever criterion may be used, the same word error rate should be reached if enough training data is available. As this is never the case, the idea of combining two different criteria, each of them extracting complementary characteristics of the feature is interesting. A state-of-the-art HMM system will be combined with a time delay neural network (TDNN) integrated in a Viterbi framework. A hierarchical TDNN structure is described that splits training into subtasks corresponding to subsets of phonemes. This structure makes training of TDNNs on large-vocabulary tasks manageable on workstations. It will be shown that the combined system, despite the low accuracy of the hierarchical TDNN, achieves a word error rate reduction of 15% with respect to our state-of-the-art HMM system. This reduction is obtained with a 10% increase only in the number of parameters. >"
            },
            "slug": "Combining-TDNN-and-HMM-in-a-hybrid-system-for-Dugast-Devillers",
            "title": {
                "fragments": [],
                "text": "Combining TDNN and HMM in a hybrid system for improved continuous-speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A hybrid continuous-speech recognition system that leads to improved results on the speaker dependent DARPA Resource Management task is presented, based on a combination of normalized neural network output scores with hidden Markov model (HMM) emission probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122774836"
                        ],
                        "name": "A. Brunot",
                        "slug": "A.-Brunot",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Brunot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Brunot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152547641"
                        ],
                        "name": "Corinna Cortes",
                        "slug": "Corinna-Cortes",
                        "structuredName": {
                            "firstName": "Corinna",
                            "lastName": "Cortes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinna Cortes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050470845"
                        ],
                        "name": "H. Drucker",
                        "slug": "H.-Drucker",
                        "structuredName": {
                            "firstName": "Harris",
                            "lastName": "Drucker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Drucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145636949"
                        ],
                        "name": "Urs Muller",
                        "slug": "Urs-Muller",
                        "structuredName": {
                            "firstName": "Urs",
                            "lastName": "Muller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs Muller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97914531"
                        ],
                        "name": "E. Sackinger",
                        "slug": "E.-Sackinger",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Sackinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sackinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "The values of the global learning rate [see (21) in Appendix C for a definition] was decreased using the following schedule: 0.0005 for the first two passes; 0.0002 for the next three; 0.0001 for the next three; 0.000 05 for the next 4; and 0.000 01 thereafter."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11259076,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d50dce749321301f0104689f2dc582303a83be65",
            "isKey": false,
            "numCitedBy": 631,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "COMPARISON OF LEARNINGALGORITHMS FOR HANDWRITTEN DIGITRECOGNITIONY. LeCun, L. Jackel, L. Bottou, A. Brunot, C. Cortes,J. Denker, H. Drucker, I. Guyon, U. M \u007fuller,E. S\u007fackinger, P. Simard, and V. VapnikBell Lab oratories, Holmdel, NJ 07733, USAEmail: yann@research.att.comAbstractThis pap er compares the p erformance of several classi er algorithmson a standard database of handwritten digits. We consider not only rawaccuracy, but also rejection, training time, recognition time, and memoryrequirements.1"
            },
            "slug": "Comparison-of-learning-algorithms-for-handwritten-LeCun-Jackel",
            "title": {
                "fragments": [],
                "text": "Comparison of learning algorithms for handwritten digit recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This comparison of several learning algorithms for handwritten digits considers not only raw accuracy, but also rejection, training time, recognition time, and memory requirements."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "1% on the regular test set [63], with a computational cost of only 650 000 multiply\u2013adds per recognition, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "obtained by Burges and Sch \u00f6lkopf and reported in [63]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9434141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40e5a40ae66d44e6c00d562d068d35db6922715d",
            "isKey": false,
            "numCitedBy": 431,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Support Vector Learning Machines (SVM) are finding application in pattern recognition, regression estimation, and operator inversion for ill-posed problems. Against this very general backdrop, any methods for improving the generalization performance, or for improving the speed in test phase, of SVMs are of increasing interest. In this paper we combine two such techniques on a pattern recognition problem. The method for improving generalization performance (the \"virtual support vector\" method) does so by incorporating known invariances of the problem. This method achieves a drop in the error rate on 10,000 NIST test digit images of 1.4% to 1.0%. The method for improving the speed (the \"reduced set\" method) does so by approximating the support vector decision surface. We apply this method to achieve a factor of fifty speedup in test phase over the virtual support vector machine. The combined approach yields a machine which is both 22 times faster than the original machine, and which has better generalization performance, achieving 1.1 % error. The virtual support vector method is applicable to any SVM problem with known invariances. The reduced set method is applicable to any support vector machine."
            },
            "slug": "Improving-the-Accuracy-and-Speed-of-Support-Vector-Burges-Sch\u00f6lkopf",
            "title": {
                "fragments": [],
                "text": "Improving the Accuracy and Speed of Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper combines two techniques for improving generalization performance and speed on a pattern recognition problem by incorporating known invariances of the problem, and applies the reduced set method, applicable to any support vector machine."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207165665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2599131a4bc2fa957338732a37c744cfe3e17b24",
            "isKey": false,
            "numCitedBy": 10832,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms."
            },
            "slug": "A-training-algorithm-for-optimal-margin-classifiers-Boser-Guyon",
            "title": {
                "fragments": [],
                "text": "A training algorithm for optimal margin classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented, applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145334214"
                        ],
                        "name": "M. Rahim",
                        "slug": "M.-Rahim",
                        "structuredName": {
                            "firstName": "Mazin",
                            "lastName": "Rahim",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rahim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 267
                            }
                        ],
                        "text": "On the other hand, if the probabilistic assumptions in an HMM (or other probabilistic model) are not realistic, discriminative training, discussed in Section VII, can improve performance as this has been clearly shown for speech recognition systems [48], [49], [50], [107], [108]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7958947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97055a12a77fe988f8e46b01f2093a0806182239",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Utterance verification represents an important technology in the design of user-friendly speech recognition systems. It involves the recognition of keyword strings and the rejection of nonkeyword strings. This paper describes a hidden Markov model-based (HMM-based) utterance verification system using the framework of statistical hypothesis testing. The two major issues on how to design keyword and string scoring criteria are addressed. For keyword verification, different alternative hypotheses are proposed based on the scores of antikeyword models and a general acoustic filler model. For string verification, different measures are proposed with the objective of detecting nonvocabulary word strings and possibly erroneous strings (so-called putative errors). This paper also motivates the need for discriminative hypothesis testing in verification. One such approach based on minimum classification error training is investigated in detail. When the proposed verification technique was integrated into a state-of-the-art connected digit recognition system, the string error rate for valid digit strings was found to decrease by 57% when setting the rejection rate to 5%. Furthermore, the system was able to correctly reject over 99.9% of nonvocabulary word strings."
            },
            "slug": "Discriminative-utterance-verification-for-connected-Rahim-Lee",
            "title": {
                "fragments": [],
                "text": "Discriminative utterance verification for connected digits recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "When the proposed verification technique was integrated into a state-of-the-art connected digit recognition system, the string error rate for valid digit strings was found to decrease by 57% when setting the rejection rate to 5%, and the need for discriminative hypothesis testing in verification was motivated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3242194"
                        ],
                        "name": "Ghulum Bakiri",
                        "slug": "Ghulum-Bakiri",
                        "structuredName": {
                            "firstName": "Ghulum",
                            "lastName": "Bakiri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ghulum Bakiri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "While they could have been chosen at random with equal probabilities for -1 and +1, or even chosen to form an error correcting code as suggested by [47], they were instead designed to represent a stylized image of the corresponding character class drawn on a 7x12 bitmap (hence the number 84)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 47109072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d221bbcbd20c7157e4500f942de8ceec490f8936",
            "isKey": false,
            "numCitedBy": 2852,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k > 2 values (i.e., k \"classes\"). The definition is acquired by studying collections of training examples of the form (xi, f(xi)). Existing approaches to multiclass learning problems include direct application of multiclass algorithms such as the decision-tree algorithms C4.5 and CART, application of binary concept learning algorithms to learn individual binary functions for each of the k classes, and application of binary concept learning algorithms with distributed output representations. This paper compares these three approaches to a new technique in which error-correcting codes are employed as a distributed output representation. We show that these output representations improve the generalization performance of both C4.5 and backpropagation on a wide range of multiclass learning tasks. We also demonstrate that this approach is robust with respect to changes in the size of the training sample, the assignment of distributed representations to particular classes, and the application of overfitting avoidance techniques such as decision-tree pruning. Finally, we show that--like the other methods--the error-correcting code technique can provide reliable class probability estimates. Taken together, these results demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems."
            },
            "slug": "Solving-Multiclass-Learning-Problems-via-Output-Dietterich-Bakiri",
            "title": {
                "fragments": [],
                "text": "Solving Multiclass Learning Problems via Error-Correcting Output Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is demonstrated that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715709"
                        ],
                        "name": "S. Katagiri",
                        "slug": "S.-Katagiri",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Katagiri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Katagiri"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32924048,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e142635b24b57cfeb20e0e69bf7836dabe44aa7f",
            "isKey": false,
            "numCitedBy": 709,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A formulation is proposed for minimum-error classification, in which the misclassification probability is to be minimized based on a given set of training samples. A fundamental technique for designing a classifier that approaches the objective of minimum classification error in a more direct manner than traditional methods is given. The method is contrasted with several traditional classifier designs in typical experiments to demonstrate the superiority of the new learning formulation. The method can applied to other classifier structures as well. Experimental results pertaining to a speech recognition task are provided to show the effectiveness of the technique. >"
            },
            "slug": "Discriminative-learning-for-minimum-error-[pattern-Juang-Katagiri",
            "title": {
                "fragments": [],
                "text": "Discriminative learning for minimum error classification [pattern recognition]"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A fundamental technique for designing a classifier that approaches the objective of minimum classification error in a more direct manner than traditional methods is given and is contrasted with several traditional classifier designs in typical experiments to demonstrate the superiority of the new learning formulation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5768521"
                        ],
                        "name": "G. Barna",
                        "slug": "G.-Barna",
                        "structuredName": {
                            "firstName": "Gy\u00f6rgy",
                            "lastName": "Barna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Barna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693259"
                        ],
                        "name": "Ron Chrisley",
                        "slug": "Ron-Chrisley",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Chrisley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ron Chrisley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17154105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6666e8358eed45caf93ada4272f8d63bb1b6b705",
            "isKey": false,
            "numCitedBy": 512,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Three basic types of neural-like networks (backpropagation network, Boltzmann machine, and learning vector quantization), were applied to two representative artificial statistical pattern recognition tasks, each with varying dimensionality. The performance of each network's approach to solving the tasks was evaluated and compared, both to the performance of the other two networks and to the theoretical limit. The learning vector quantization was further benchmarked against the parametric Bayes classifier and the k-nearest-neighbor classifier using natural speech data. A novel learning vector quantization classifier called LVQ2 is introduced.<<ETX>>"
            },
            "slug": "Statistical-pattern-recognition-with-neural-studies-Kohonen-Barna",
            "title": {
                "fragments": [],
                "text": "Statistical pattern recognition with neural networks: benchmarking studies"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Three basic types of neural-like networks, backpropagation network, Boltzmann machine, and learning vector quantization, were applied to two representative artificial statistical pattern recognition tasks, each with varying dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE 1988 International Conference on Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065228513"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14700006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee50abb5aff3e5c43a38f24396b9552d593a9ae0",
            "isKey": false,
            "numCitedBy": 420,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The statistical use of a particular classic form of a connectionist system, the multilayer perceptron (MLP), is described in the context of the recognition of continuous speech. A discriminant hidden Markov model (HMM) is defined, and it is shown how a particular MLP with contextual and extra feedback input units can be considered as a general form of such a Markov model. A link between these discriminant HMMs, trained along the Viterbi algorithm, and any other approach based on least mean square minimization of an error function (LMSE) is established. It is shown theoretically and experimentally that the outputs of the MLP (when trained along the LMSE or the entropy criterion) approximate the probability distribution over output classes conditioned on the input, i.e. the maximum a posteriori probabilities. Results of a series of speech recognition experiments are reported. The possibility of embedding MLP into HMM is described. Relations with other recurrent networks are also explained. >"
            },
            "slug": "Links-Between-Markov-Models-and-Multilayer-Bourlard-Wellekens",
            "title": {
                "fragments": [],
                "text": "Links Between Markov Models and Multilayer Perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown theoretically and experimentally that the outputs of the MLP approximate the probability distribution over output classes conditioned on the input, i.e. the maximum a posteriori probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "For example, a document recognition system is composed of a field locator (which extracts regions of interest), a field segmenter (which cuts the input image into images of candidate characters), a recognizer (which classifies and scores each candidate character), and a contextual postprocessor,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62242703,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f238b648bd99c3b66251ba0fc46b0be38e86483",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The architecture of a reading machine designed to achieve a high rate of correct interpretation of text as well as high speed in performing the interpretation is described. The refinement of the architecture for a specialized reading machine, to find and interpret addresses on a stream of postal letters, is also described. The addresses can be either machine-printed or handwritten. The primary subtasks correspond to finding the block of text corresponding to the destination address, recognizing characters and words within the address, and interpreting the text using postal directories. The need for multiple algorithms and multiple scales for recognition (holistic and analytic) and for methods for combining results of multiple algorithms, the efficacy of artificial neural nets and fuzzy matching, and the feasibility of reading unconstrained handwritten words when there exist accompanying numeric fields that limit word choices are shown. >"
            },
            "slug": "High-Performance-Reading-Machines-Srihari",
            "title": {
                "fragments": [],
                "text": "High-Performance Reading Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "The architecture of a reading machine designed to achieve a high rate of correct interpretation of text as well as high speed in performing the interpretation is described and the need for multiple algorithms and multiple scales for recognition is described."
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition: Architectures, Algorithms and Applications"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47749181"
                        ],
                        "name": "M. Franzini",
                        "slug": "M.-Franzini",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Franzini",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Franzini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110051082"
                        ],
                        "name": "K. Lee",
                        "slug": "K.-Lee",
                        "structuredName": {
                            "firstName": "K.-F.",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 166
                            }
                        ],
                        "text": "Similar algorithms have been applied to speech recognition systems that integrate NN\u2019s with time alignment [71], [72], [76] or hybrid neuralnetwork/HMM systems [29], [74], [75]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12292955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f866ac085771f5676800db2d9b102975b2a1b2d7",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A hybrid method for continuous-speech recognition which combines hidden Markov models (HMMs) and a connectionist technique called connectionist Viterbi training (CVT) is presented. CVT can be run iteratively and can be applied to large-vocabulary recognition tasks. Successful completion of training the connectionist component of the system, despite the large network size and volume of training data, depends largely on several measures taken to reduce learning time. The system is trained and tested on the TI/NBS speaker-independent continuous-digits database. Performance on test data for unknown-length strings is 98.5% word accuracy and 95.0% string accuracy. Several improvements to the current system are expected to increase these accuracies significantly.<<ETX>>"
            },
            "slug": "Connectionist-Viterbi-training:-a-new-hybrid-method-Franzini-Lee",
            "title": {
                "fragments": [],
                "text": "Connectionist Viterbi training: a new hybrid method for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A hybrid method for continuous-speech recognition which combines hidden Markov models (HMMs) and a connectionist technique called connectionist Viterbi training (CVT) is presented and can be run iteratively and applied to large-vocabulary recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 102
                            }
                        ],
                        "text": "A di erent approach to graph-based trainable systems, called Input-Output HMM, was proposed in [104], [105]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 35
                            }
                        ],
                        "text": "The Input-Output HMM model (IOHMM) [105], [109], is strongly related to graph transformers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14298205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25bdc473f8377c1200adbd691fbb3cc77fa7bf70",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider problems of sequence processing and propose a solution based on a discrete-state model in order to represent past context. We introduce a recurrent connectionist architecture having a modular structure that associates a subnetwork to each state. The model has a statistical interpretation we call input-output hidden Markov model (IOHMM). It can be trained by the estimation-maximization (EM) or generalized EM (GEM) algorithms, considering state trajectories as missing data, which decouples temporal credit assignment and actual parameter estimation. The model presents similarities to hidden Markov models (HMMs), but allows us to map input sequences to output sequences, using the same processing style as recurrent neural networks. IOHMMs are trained using a more discriminant learning paradigm than HMMs, while potentially taking advantage of the EM algorithm. We demonstrate that IOHMMs are well suited for solving grammatical inference problems on a benchmark problem. Experimental results are presented for the seven Tomita grammars, showing that these adaptive models can attain excellent generalization."
            },
            "slug": "Input-output-HMMs-for-sequence-processing-Bengio-Frasconi",
            "title": {
                "fragments": [],
                "text": "Input-output HMMs for sequence processing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is demonstrated that IOHMMs are well suited for solving grammatical inference problems on a benchmark problem and able to map input sequences to output sequences, using the same processing style as recurrent neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145468098"
                        ],
                        "name": "M. M\u00f8ller",
                        "slug": "M.-M\u00f8ller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "M\u00f8ller",
                            "middleNames": [
                                "Fodslette"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. M\u00f8ller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 114
                            }
                        ],
                        "text": "Several authors have attempted to use conjugate gradient with small batches or batches of increasing sizes [119], [120], but those attempts have not yet been demonstrated to surpass a carefully tuned stochastic gradient."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58321217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d6f37bb4352b334cb3ff4b48f55879e248dd63a",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "Since the discovery of the back-propagation method, many modified and new algorithms have been proposed for training of feed-forward neural networks. The problem with slow convergence rate has, however, not been solved when the training is on large scale problems. There is still a need for more efficient algorithms. This Ph.D. thesis describes different approaches to improve convergence. The main results of the thesis is the development of the Scaled Conjugate Gradient Algorithm and the stochastic version of this algorithm. Other important results are the development of methods that can derive and use Hessian information in an efficient way. The main part of this thesis is the 5 papers presented in appendices A-E. Chapters 1-6 give an overview of learning in feed-forward neural networks, put these papers in perspective and present the most important results. The conclusion of this thesis is: * Conjugate gradient algorithms are very suitable for training of feed-forward networks. * Use of second order information by calculations on the Hessian matrix can be used to improve convergence."
            },
            "slug": "Efficient-Training-of-Feed-Forward-Neural-Networks-M\u00f8ller",
            "title": {
                "fragments": [],
                "text": "Efficient Training of Feed-Forward Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The conclusion of this thesis is: Conjugate gradient algorithms are very suitable for training of feed-forward networks and use of second order information by calculations on the Hessian matrix can be used to improve convergence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "Other authors have used Neural Networks, or other classi ers such as Support Vector Machines for face detection with great success [96], [97]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3885c13438132b516e5ffc8b640d20b4e41a7a4",
            "isKey": false,
            "numCitedBy": 4155,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural network-based face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9326933"
                        ],
                        "name": "Y. L. Cun",
                        "slug": "Y.-L.-Cun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Cun",
                            "middleNames": [
                                "le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. L. Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141651709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44f2679f8169e7f6449c52e058ebe6a45838b3c0",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Threshold functions and related operators are widely used as basic elements of adaptive and associative networks [Nakano 72, Amari 72, Hopfield 82]. There exist numerous learning rules for finding a set of weights to achieve a particular correspondence between input-output pairs. But early works in the field have shown that the number of threshold functions (or linearly separable functions) in N binary variables is small compared to the number of all possible boolean mappings in N variables, especially if N is large. This problem is one of the main limitations of most neural networks models where the state is fully specified by the environment during learning: they can only learn linearly separable functions of their inputs. Moreover, a learning procedure which requires the outside world to specify the state of every neuron during the learning session can hardly be considered as a general learning rule because in real-world conditions, only a partial information on the \u201cideal\u201d network state for each task is available from the environment. It is possible to use a set of so-called \u201chidden units\u201d [Hinton,Sejnowski,Ackley. 84], without direct interaction with the environment, which can compute intermediate predicates. Unfortunately, the global response depends on the output of a particular hidden unit in a highly non-linear way, moreover the nature of this dependence is influenced by the states of the other cells."
            },
            "slug": "Learning-Process-in-an-Asymmetric-Threshold-Network-Cun",
            "title": {
                "fragments": [],
                "text": "Learning Process in an Asymmetric Threshold Network"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A learning procedure which requires the outside world to specify the state of every neuron during the learning session can hardly be considered as a general learning rule because in real-world conditions, only a partial information on the \u201cideal\u201d network state for each task is available from the environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 69
                            }
                        ],
                        "text": "This seems to be an almost perfect, if fortuitous, implementation of Vapnik\u2019s \u201cstructural risk minimization\u201d principle [6]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 11
                            }
                        ],
                        "text": "Cortes and Vapnik had reported an error rate of 1.1% with SVM on the same data using a slightly different technique."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 169
                            }
                        ],
                        "text": "In a series of experiments, we replaced the last layer of LeNet4 with a Euclidean nearest-neighbor classifier, and with the \u201clocal learning\u201d method of Bottou and Vapnik [58], in which a local linear classifier is retrained each time a new test pattern is shown."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7035291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ca97e1668e305fb719845f84a05a62dfb946a5d",
            "isKey": false,
            "numCitedBy": 578,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Very rarely are training data evenly distributed in the input space. Local learning algorithms attempt to locally adjust the capacity of the training system to the properties of the training set in each area of the input space. The family of local learning algorithms contains known methods, like the k-nearest neighbors method (kNN) or the radial basis function networks (RBF), as well as new algorithms. A single analysis models some aspects of these algorithms. In particular, it suggests that neither kNN or RBF, nor nonlocal classifiers, achieve the best compromise between locality and capacity. A careful control of these parameters in a simple local learning algorithm has provided a performance breakthrough for an optical character recognition problem. Both the error rate and the rejection performance have been significantly improved."
            },
            "slug": "Local-Learning-Algorithms-Bottou-Vapnik",
            "title": {
                "fragments": [],
                "text": "Local Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A single analysis suggests that neither kNN or RBF, nor nonlocal classifiers, achieve the best compromise between locality and capacity."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120460"
                        ],
                        "name": "L. Niles",
                        "slug": "L.-Niles",
                        "structuredName": {
                            "firstName": "Les",
                            "lastName": "Niles",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Niles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748100"
                        ],
                        "name": "H. Silverman",
                        "slug": "H.-Silverman",
                        "structuredName": {
                            "firstName": "Harvey",
                            "lastName": "Silverman",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Silverman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61486012,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a3397b9feb4869a27ff9f4c95c888e90d04e0bd",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "An architecture for a neural network that implements a hidden Markov model (HMM) is presented. This HMM net suggests integrating signal preprocessing (such as vector quantization) with the classifier. A minimum mean-squared-error training criterion for the HMM/neural net is presented and compared to maximum-likelihood and maximum-mutual-information criteria. The HMM forward-backward algorithm is shown to be the same as the neural net backpropagation algorithm. The implications of probability constraints on the HMM parameters are discussed. Relaxing these constraints allows negative probabilities, equivalent to inhibitory connections. A probabilistic interpretation is given for a network with negative, and even complex-valued, parameters.<<ETX>>"
            },
            "slug": "Combining-hidden-Markov-model-and-neural-network-Niles-Silverman",
            "title": {
                "fragments": [],
                "text": "Combining hidden Markov model and neural network classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "An architecture for a neural network that implements a hidden Markov model (HMM) that suggests integrating signal preprocessing (such as vector quantization) with the classifier and a probabilistic interpretation is given for a network with negative, and even complex-valued, parameters."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97914531"
                        ],
                        "name": "E. Sackinger",
                        "slug": "E.-Sackinger",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Sackinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sackinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120242409"
                        ],
                        "name": "J. Bromley",
                        "slug": "J.-Bromley",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Bromley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bromley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9326933"
                        ],
                        "name": "Y. L. Cun",
                        "slug": "Y.-L.-Cun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Cun",
                            "middleNames": [
                                "le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. L. Cun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "Specialized analog/digital chips have been designed and used in character recognition, and in image preprocessing applications [88]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18194430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82795cf04f5631e82413b1952625a5a6f21b68ea",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The architecture, implementation, and applications of a special-purpose neural network processor are described. The chip performs over 2000 multiplications and additions simultaneously. Its data path is particularly suitable for the convolutional topologies that are typical in classification networks, but can also be configured for fully connected or feedback topologies. Resources can be multiplexed to permit implementation of networks with several hundreds of thousands of connections on a single chip. Computations are performed with 6 b accuracy for the weights and 3 b for the neuron states. Analog processing is used internally for reduced power dissipation and higher density, but all input/output is digital to simplify system integration. The practicality of the chip is demonstrated with an implementation of a neural network for optical character recognition. This network contains over 130000 connections and was evaluated in 1 ms. >"
            },
            "slug": "An-analog-neural-network-processor-with-topology-Boser-Sackinger",
            "title": {
                "fragments": [],
                "text": "An analog neural network processor with programmable topology"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The architecture, implementation, and applications of a special-purpose neural network processor are described and the practicality of the chip is demonstrated with an implementation of a neural network for optical character recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60753901,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c41868f69d265783b7540094946ee902571c5cd",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The acoustic-modelling problem in automatic speech recognition is examined from an information theoretic point of view. This problem is to design a speech-recognition system which can extract from the speech waveform as much information as possible about the corresponding word sequence. The information extraction process is factored into two steps: a signal-processing step which converts a speech waveform into a sequence of informative acoustic feature vectors, and a step which models such a sequence. The authors are primarily concerned with the use of hidden Markov models to model sequences of feature vectors which lie in a continuous space. They explore the trade-off between packing information into such sequences and being able to model them accurately. The difficulty of developing accurate models of continuous-parameter sequences is addressed by investigating a method of parameter estimation which is designed to cope with inaccurate modeling assumptions.<<ETX>>"
            },
            "slug": "Speech-recognition-with-continuous-parameter-hidden-Bahl-Brown",
            "title": {
                "fragments": [],
                "text": "Speech recognition with continuous-parameter hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The authors explore the trade-off between packing information into sequences of feature vectors and being able to model them accurately and investigate a method of parameter estimation which is designed to cope with inaccurate modeling assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46949735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3c5f1e1edd0d63f2d1b30d308c2c88b06a829ef",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new approach to normalizing words written with an electronic stylus that applies to all styles of handwriting (upper case, lower case, printed, cursive, or mixed). A geometrical model of the word spatial structure is fitted to the pen trajectory using the expectation-maximisation algorithm. The fitting process maximizes the likelihood of the trajectory given the model and a set a priors on its parameters. The method was evaluated and integrated to a recognition system that combines neural networks and hidden Markov models."
            },
            "slug": "Word-normalization-for-online-handwritten-word-Bengio-LeCun",
            "title": {
                "fragments": [],
                "text": "Word normalization for online handwritten word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A geometrical model of the word spatial structure is fitted to the pen trajectory using the expectation-maximisation algorithm, which maximizes the likelihood of the trajectory given the model and a set a priors on its parameters."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 12th IAPR International Conference on Pattern Recognition, Vol. 3 - Conference C: Signal Processing (Cat. No.94CH3440-5)"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16655845,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b336597d72bef3b5b6964a88040129edcaf8dcd",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new approach to normalizing words written with an electronic stylus that applies to all styles of handwriting (upper case, lower case, printed, cursive, or mixed). A geometrical model of the word spatial structure is fitted to the pen trajectory using the EM algorithm. The fitting process maximizes the likelihood of the trajectory given the model and a set a priors on its parameters. The method was evaluated and integrated to a recognition system that combines neural networks and hidden Markov models."
            },
            "slug": "Word-normalization-for-on-line-handwritten-word-Bengio-LeCun",
            "title": {
                "fragments": [],
                "text": "Word normalization for on-line handwritten word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A geometrical model of the word spatial structure is fitted to the pen trajectory using the EM algorithm and the fitting process maximizes the likelihood of the trajectory given the model and a set a priors on its parameters."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120465549"
                        ],
                        "name": "J. Wang",
                        "slug": "J.-Wang",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2130202"
                        ],
                        "name": "J. Jean",
                        "slug": "J.-Jean",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Jean",
                            "middleNames": [
                                "S.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jean"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61843965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64e7adce9a36ffcace36a2e0a334a0415fbbfe75",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A multiresolution optical character recognition (OCR) using neural networks is proposed for omnifont character recognition. It is motivated by the human reading process in which a low resolution is used to effectively process the majority of clean and unambiguous text, while a more complicated recognition scheme is invoked only when a high resolution is needed. Compared with the method that utilizes single resolution, the multiresolution system not only speeds up recognition by up to 20 times, but also improves accuracy of isolated character recognition from 99.8% to 99.9%. The multiresolution approach captures the essence of better reading, and provides the building blocks for the next-generation OCR systems.<<ETX>>"
            },
            "slug": "Multiresolution-neural-networks-for-omnifont-Wang-Jean",
            "title": {
                "fragments": [],
                "text": "Multiresolution neural networks for omnifont character recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A multiresolution optical character recognition using neural networks is proposed for omnifont character recognition, which not only speeds up recognition by up to 20 times, but also improves accuracy of isolated character recognition from 99.8% to 99.9%."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714393"
                        ],
                        "name": "R. Mori",
                        "slug": "R.-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Mori",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2376916"
                        ],
                        "name": "G. Flammia",
                        "slug": "G.-Flammia",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Flammia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Flammia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688499"
                        ],
                        "name": "R. Kompe",
                        "slug": "R.-Kompe",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Kompe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kompe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "Several authors have proposed such methods to train neural network/HMM speech recognizers at the word or sentence level [71], [72], [73], [74], [75], [76], [77], [78], [29], [67]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "Globally trained, variable-size TDNN/HMM hybrids have been used for speech recognition and on-line handwriting recognition [77], [89], [90], [67]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "This con rms similar results obtained earlier in speech recognition [77]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 894840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c92ffacba4eaddcb86c8fde50d1b183ac995052",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "An original method for integrating artificial neural networks (ANN) with hidden Markov models (HMM) is proposed. ANNs are suitable for performing phonetic classification, whereas HMMs have been proven successful at modeling the temporal structure of the speech signal. In the approach described, the ANN outputs constitute the sequence of observation vectors for the HMM. An algorithm is proposed for global optimization of all the parameters. Results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported.<<ETX>>"
            },
            "slug": "Global-optimization-of-a-neural-network-hidden-Bengio-Mori",
            "title": {
                "fragments": [],
                "text": "Global optimization of a neural network-hidden Markov model hybrid"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "An original method for integrating artificial neural networks (ANN) with hidden Markov models (HMM) with results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN-91-Seattle International Joint Conference on Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "speech recognition systems, including Bridle and his -net model [73] and Ha ner and his -TDNN model [81], but these authors recommended discriminative training as described in the next section."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "Several authors have proposed such methods to train neural network/HMM speech recognizers at the word or sentence level [71], [72], [73], [74], [75], [76], [77], [78], [29], [67]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41994273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c91c2ac02e33caff601b2e4d62a6841b33ca3929",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Alpha-nets:-A-recurrent-'neural'-network-with-a-Bridle",
            "title": {
                "fragments": [],
                "text": "Alpha-nets: A recurrent 'neural' network architecture with a hidden Markov model interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "147984118"
                        ],
                        "name": "R. Vaillant",
                        "slug": "R.-Vaillant",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Vaillant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vaillant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3208918"
                        ],
                        "name": "C. Monrocq",
                        "slug": "C.-Monrocq",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Monrocq",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Monrocq"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9326933"
                        ],
                        "name": "Y. L. Cun",
                        "slug": "Y.-L.-Cun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Cun",
                            "middleNames": [
                                "le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. L. Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "To illustrate the method, we will consider the case of face detection in images as described in [93]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "The idea has been applied to face location [93], address block location on envelopes [94], and hand tracking in video [95]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 171
                            }
                        ],
                        "text": "A 2-D version of the global training method described in the previous section can be used to alleviate the need to manually locate faces when building the training sample [93]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16690291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc7fa2cf9d7d2b3aca4fa22271412831e9a61e22",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents an algorithm for the detection of faces in images using shared-weight replicated neural networks. A neural net forms rough hypotheses about the position of faces. These hypotheses are then verified using a second neural network. The algorithm applies to images where the size of the faces is unknown a priori. The computational time which is necessary for the complete processing of an image is reasonable. With a classical workstation an image of size 512*512 is treated in 50 seconds including smoothing and normalization of the image. This algorithm can be easily installed on a more specialized machine as the major part of the operation is based on convolutions with kernels of size 5*5 or 8*8. In this paper, the authors assume that the face are well oriented in the image. It is possible to eliminate this assumption by following an approach similar to the one used for the scale problem. A net is trained to be insensitive to the precise orientation of the face. This kind of segmentation algorithm can be applied to other problems where the objects to be detected cannot be characterized easily by its outline or by classical primitives in image processing."
            },
            "slug": "An-original-approach-for-the-localization-of-in-Vaillant-Monrocq",
            "title": {
                "fragments": [],
                "text": "An original approach for the localization of objects in images"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An algorithm for the detection of faces in images using shared-weight replicated neural networks, trained to be insensitive to the precise orientation of the face by following an approach similar to the one used for the scale problem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "78659204"
                        ],
                        "name": "M. Mohri",
                        "slug": "M.-Mohri",
                        "structuredName": {
                            "firstName": "Mehryar",
                            "lastName": "Mohri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mohri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428168"
                        ],
                        "name": "M. Riley",
                        "slug": "M.-Riley",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Riley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15367554,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c777b4a563220dcd73a1b020b80c1f24c0f772a",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Overview We describe the design principles and main algorithms for an object-oriented library for weighted nite-state transducers, which are nite automata in which each transition has an output and a weight as well as the more familiar input. The main goal of the library is to provide algorithms and representations for all the symbolic processing components (language models, dictionaries, acoustic realization rules, word lattices) in large-vocabulary speech recognition systems. This goal leads to several requirements: generality, to support the representation and use of the various information sources in speech recognition; modularity, to allow rapid experimentation with diierent representations of speech recognition tasks; and eeciency, to support competitive large-vocabulary recognition. Rational power series provide the theoretical foundation for the library by giving the semantics for the objects and operations in the library and by creating the opportunity for optimizations (on-demand composition, determinization and minimization) that are not available in more \\ad hoc\" speech recognition frameworks. The generality of the library has made it also valuable in other language-processing applications, such as word segmentation for Chinese text 25]. 1.1 Design Rationale Current speech-recognition systems rely on a variety of probabilistic nite-state models, for instance n-gram language models 21], multiple-pronunciation dictionaries 11], and context-dependent acoustic models 10]. However, most speech recognizers do not take advantage of the shared properties of the information sources they use. Instead, they rely on special-purpose algorithms for speciic representations. That means that the recognizer has to be rewritten if representations are changed for a new application or for increased accuracy or performance. Experiments with diierent representations are therefore diicult, as they require changing or even completely replacing fairly intricate recognition programs. This situation is not too diierent from that in programming-language parsing before lex and yacc 2]. Furthermore, specialized representations and algorithms preclude certain global optimizations based on the general properties of nite-state models. Again, the situation is similar to the lack of general"
            },
            "slug": "A-Rational-Design-for-a-Weighted-Finite-State-Mohri-Pereira",
            "title": {
                "fragments": [],
                "text": "A Rational Design for a Weighted Finite-State Transducer Library"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The design principles and main algorithms for an object-oriented library for weighted nite-state transducers, which are nite automata in which each transition has an output and a weight as well as the more familiar input, are described."
            },
            "venue": {
                "fragments": [],
                "text": "Workshop on Implementing Automata"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "Unfortunately, despite early enthusiasm, the training of RNNs with gradient-based techniques has proved very di cult in practice [79]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206457500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0be39ee052d246ae99c082a565aba25b811be2d",
            "isKey": false,
            "numCitedBy": 6141,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered."
            },
            "slug": "Learning-long-term-dependencies-with-gradient-is-Bengio-Simard",
            "title": {
                "fragments": [],
                "text": "Learning long-term dependencies with gradient descent is difficult"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases, and exposes a trade-off between efficient learning by gradient descent and latching on information for long periods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122946816"
                        ],
                        "name": "Schurmann",
                        "slug": "Schurmann",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Schurmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Schurmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11270671,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46b3764436e54ec10fdf14f31c544599456385d9",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the basic design principles of a multifont word recognition system developed for postal address reading. Of the three main subsystems, image preprocessing, single character recognition, and contextual postprocessing, the last two will be considered in detail. A multiple-channel/multiple-choice approach is taken in designing the overall system. The character images produced by the image preprocessing subsystem are fed into three parallel single character recognition (SCR) channels. Each channel classifies the raster image according to one of the three character types: capital letter, small letter, or numeral. A second degree polynomial classifier is required in order to satisfy the multifont requirements of address reading. Each SCR channel outputs a rank-ordered list of potential character meanings for the character type being processed and a channel-specific figure of confidence. This figure of confidence serves a twofold purpose. First, it is used to determine the number of alternatives in the rank-ordered list, and secondly, it is used by the subsequent contextual postprocessor in calculating a word-specific discriminant function designed to discriminate between four different kinds of words: numeric, all upper case, all lower case, and lower case with upper case initial. Based on this discriminant function for every character position, only one channel output is passed on to-the word recognition system. From the list of alternatives for each character position, a set of alternative words can be constructed which, with a high probability, contains the correct word."
            },
            "slug": "A-Multifont-Word-Recognition-System-for-Postal-Schurmann",
            "title": {
                "fragments": [],
                "text": "A Multifont Word Recognition System for Postal Address Reading"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "The basic design principles of a multifont word recognition system developed for postal address reading are described, with a multiple-channel/multiple-choice approach taken in designing the overall system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40221291"
                        ],
                        "name": "A. Kramer",
                        "slug": "A.-Kramer",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Kramer",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kramer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388394865"
                        ],
                        "name": "A. Sangiovanni-Vincentelli",
                        "slug": "A.-Sangiovanni-Vincentelli",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Sangiovanni-Vincentelli",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sangiovanni-Vincentelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8301037,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6733d4705a41de1a8f5a5eccd75479b448d5247",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Parallelizable optimization techniques are applied to the problem of learning in feedforward neural networks. In addition to having superior convergence properties, optimization techniques such as the Polak-Ribiere method are also significantly more efficient than the Backpropagation algorithm. These results are based on experiments performed on small boolean learning problems and the noisy real-valued learning problem of hand-written character recognition."
            },
            "slug": "Efficient-Parallel-Learning-Algorithms-for-Neural-Kramer-Sangiovanni-Vincentelli",
            "title": {
                "fragments": [],
                "text": "Efficient Parallel Learning Algorithms for Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Parallelizable optimization techniques such as the Polak-Ribiere method are significantly more efficient than the Backpropagation algorithm and the noisy real-valued learning problem of hand-written character recognition."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714393"
                        ],
                        "name": "R. Mori",
                        "slug": "R.-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Mori",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2376916"
                        ],
                        "name": "G. Flammia",
                        "slug": "G.-Flammia",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Flammia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Flammia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688499"
                        ],
                        "name": "R. Kompe",
                        "slug": "R.-Kompe",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Kompe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kompe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 241
                            }
                        ],
                        "text": "Numerous authors in speech recognition have used gradient-based learning methods that integrate graphbased statistical models (notably HMM\u2019s) with acoustic recognition modules, mainly Gaussian mixture models, but also NN\u2019s [67], [78], [98], [99]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9224966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a26b1e04cf5090a7026928bfb4e546cd45c6582",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The subject of this paper is the integration of multi-layered Artificial Neural Networks (ANN) with probability density functions such as Gaussian mixtures found in continuous density Hidden Markov Models (HMM). In the first part of this paper we present an ANN/HMM hybrid in which all the parameters of the system are simultaneously optimized with respect to a single criterion. In the second part of this paper, we study the relationship between the density of the inputs of the network and the density of the outputs of the networks. A few experiments are presented to explore how to perform density estimation with ANNs."
            },
            "slug": "Neural-Network-Gaussian-Mixture-Hybrid-for-Speech-Bengio-Mori",
            "title": {
                "fragments": [],
                "text": "Neural Network - Gaussian Mixture Hybrid for Speech Recognition or Density Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An ANN/HMM hybrid in which all the parameters of the system are simultaneously optimized with respect to a single criterion is presented and the relationship between the density of the inputs of the network and thedensity of the outputs of the networks is studied."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308302"
                        ],
                        "name": "D. Ackley",
                        "slug": "D.-Ackley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ackley",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ackley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "One of the most difficult problems in handwriting recognition, however, is not only to recognize individual characters, but also to separate out characters from their neighbors within the word or sentence, a process known as segmentation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12174018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657",
            "isKey": false,
            "numCitedBy": 3393,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Learning-Algorithm-for-Boltzmann-Machines-Ackley-Hinton",
            "title": {
                "fragments": [],
                "text": "A Learning Algorithm for Boltzmann Machines"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120242409"
                        ],
                        "name": "J. Bromley",
                        "slug": "J.-Bromley",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Bromley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bromley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058232056"
                        ],
                        "name": "James W. Bentz",
                        "slug": "James-W.-Bentz",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bentz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James W. Bentz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49015421"
                        ],
                        "name": "C. Moore",
                        "slug": "C.-Moore",
                        "structuredName": {
                            "firstName": "Cliff",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776424"
                        ],
                        "name": "Eduard S\u00e4ckinger",
                        "slug": "Eduard-S\u00e4ckinger",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "S\u00e4ckinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eduard S\u00e4ckinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105573840"
                        ],
                        "name": "Roopak Shah",
                        "slug": "Roopak-Shah",
                        "structuredName": {
                            "firstName": "Roopak",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roopak Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16394033,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "997dc5d9a058753f034422afe7bd0cc0b8ad808b",
            "isKey": false,
            "numCitedBy": 2613,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an algorithm for verification of signatures written on a pen-input tablet. The algorithm is based on a novel, artificial neural network, called a \"Siamese\" neural network. This network consists of two identical sub-networks joined at their outputs. During training the two sub-networks extract features from two signatures, while the joining neuron measures the distance between the two feature vectors. Verification consists of comparing an extracted feature vector with a stored feature vector for the signer. Signatures closer to this stored representation than a chosen threshold are accepted, all other signatures are rejected as forgeries."
            },
            "slug": "Signature-Verification-Using-A-\"Siamese\"-Time-Delay-Bromley-Bentz",
            "title": {
                "fragments": [],
                "text": "Signature Verification Using A \"Siamese\" Time Delay Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An algorithm for verification of signatures written on a pen-input tablet based on a novel, artificial neural network called a \"Siamese\" neural network, which consists of two identical sub-networks joined at their outputs."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729905"
                        ],
                        "name": "C. Tappert",
                        "slug": "C.-Tappert",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Tappert",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tappert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3069541"
                        ],
                        "name": "T. Wakahara",
                        "slug": "T.-Wakahara",
                        "structuredName": {
                            "firstName": "Toru",
                            "lastName": "Wakahara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wakahara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 42920826,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5b3ce16666f0d9a7ac1636370a58838a7843b0f",
            "isKey": false,
            "numCitedBy": 836,
            "numCiting": 157,
            "paperAbstract": {
                "fragments": [],
                "text": "This survey describes the state of the art of online handwriting recognition during a period of renewed activity in the field. It is based on an extensive review of the literature, including journal articles, conference proceedings, and patents. Online versus offline recognition, digitizer technology, and handwriting properties and recognition problems are discussed. Shape recognition algorithms, preprocessing and postprocessing techniques, experimental systems, and commercial products are examined. >"
            },
            "slug": "The-State-of-the-Art-in-Online-Handwriting-Tappert-Suen",
            "title": {
                "fragments": [],
                "text": "The State of the Art in Online Handwriting Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "The state of the art of online handwriting recognition during a period of renewed activity in the field is described, based on an extensive review of the literature, including journal articles, conference proceedings, and patents."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "The properties of such algorithms applied to learning have been studied theoretically since the 1960's [9], [10], [11], but practical successes for non-trivial tasks did not occur until the mid eighties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31220579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1339348aeef592802288d9d929a085cb3ae61c4b",
            "isKey": false,
            "numCitedBy": 451,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes error-correction adjustment procedures for determining the weight vector of linear pattern classifiers under general pattern distribution. It is mainly aimed at clarifying theoretically the performance of adaptive pattern classifiers. In the case where the loss depends on the distance between a pattern vector and a decision boundary and where the average risk function is unimodal, it is proved that, by the procedures proposed here, the weight vector converges to the optimal one even under nonseparable pattern distributions. The speed and the accuracy of convergence are analyzed, and it is shown that there is an important tradeoff between speed and accuracy of convergence. Dynamical behaviors, when the probability distributions of patterns are changing, are also shown. The theory is generalized and made applicable to the case with general discriminant functions, including piecewise-linear discriminant functions."
            },
            "slug": "A-Theory-of-Adaptive-Pattern-Classifiers-Amari",
            "title": {
                "fragments": [],
                "text": "A Theory of Adaptive Pattern Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "It is proved that, by the procedures proposed here, the weight vector converges to the optimal one even under nonseparable pattern distributions, and there is an important tradeoff between speed and accuracy of convergence."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Electron. Comput."
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15496295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "695c519820e791af974f190528baf42154655da7",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Alex Waibel Carnegie Mellon University Pittsburgh, PA 15213 ahw@cs.cmu.edu We present the \"Multi-State Time Delay Neural Network\" (MS-TDNN) as an extension of the TDNN to robust word recognition. Unlike most other hybrid methods. the MS-TDNN embeds an alignment search procedure into the connectionist architecture. and allows for word level supervision. The resulting system has the ability to manage the sequential order of subword units. while optimizing for the recognizer performance. In this paper we present extensive new evaluations of this approach over speaker-dependent and speaker-independent connected alphabet."
            },
            "slug": "Multi-State-Time-Delay-Neural-Networks-for-Speech-Haffner-Waibel",
            "title": {
                "fragments": [],
                "text": "Multi-State Time Delay Neural Networks for Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This paper presents the \"Multi-State Time Delay Neural Network\" (MS-TDNN) as an extension of the TDNN to robust word recognition and presents extensive new evaluations of this approach over speaker-dependent and speaker-independent connected alphabet."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 42
                            }
                        ],
                        "text": "The Input-Output HMM model (IOHMM) [105], [109], is strongly related to graph transformers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16693657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "730068cb367489f91aa8a99bc83fb43ef3b2466c",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In learning tasks in which input sequences are mapped to output sequences it is often the case that the input and output sequences are not synchronous For example in speech recognition acoustic sequences are longer than phoneme sequences Input Output Hidden Markov Models have already been proposed to represent the distribution of an output sequence given an input sequence of the same length We extend here this model to the case of asynchronous sequences and show an Expectation Maximization algorithm for training such models Introduction Supervised learning algorithms for sequential data minimize a training criterion that depends on pairs of input and output sequences It is often assumed that input and output sequences are synchronized i e that each input sequence has the same length as the corresponding output sequence For instance recurrent networks Rumelhart et al can be used to map input sequences to output sequences for example minimizing at each time step the squared di erence between the actual output and the desired output Another example is a recently proposed recurrent mixture of experts connectionist ar chitecture which has an interpretation as a probabilistic model called Input Output Hidden Markov Model IOHMM Bengio and Frasconi Bengio and Frasconi This model represents the distribution of an output sequence when given an input sequence of the same length using a hidden state variable and a Markovian independence assumption as in Hidden Markov Models HMMs Levinson et al Rabiner in order to simplify the distribution IOHMMs are a form of probabilistic transducers Pereira et al Singer with input and output variables which can be discrete as well as continuous valued However in many sequential problems where one tries to map an input sequence to an output sequence the length of the input and output sequences may not be equal Input and output sequences could behave at di erent time scales For example in a speech recognition problem where one wants to map an acoustic signal to a phoneme sequence each phoneme approximately corresponds to a subsequence of the acoustic signal therefore the input acoustic sequence is generally longer than the output phoneme sequence and the alignment between inputs and outputs is often not available In comparison with HMMs emission and transition probabilities in IOHMMs vary with time in function of an input sequence Unlike HMMs IOHMMs with discrete outputs are discriminant models Furthermore the transition probabilities and emission probabilities are generally better matched which reduces a problem observed in speech recognition HMMs because outputs are in a much higher dimensional space than transitions in HMMs the dynamic range of transition probabilities is much less than that of emission probabilities Therefore the choice between di erent paths during recognition is mostly in uenced by emission rather than transition probabilities In this paper we present an extension of IOHMMs to the asynchronous case We rst present the proba bilistic model then derive an exact Expectation Maximization EM algorithm for training asynchronous IOHMMs For complex distributions e g using arti cial neural networks to represent transition and emission distributions a Generalized EM algorithm or gradient ascent in likelihood can be used Finally a recognition algorithm similar to the Viterbi algorithm is presented to map given input sequences to likely output sequences The Model Let us note u for input sequences u u uT and similarly y S for output sequences y y yS In this paper we consider the case in which the output sequences are shorter than the input sequences The more general case is a straightforward extension of this model using empty transitions that do not take any time and will be discussed elsewhere As in HMMs and IOHMMs we introduce a discrete hidden state variable xt which will allow us to simplify the distribution P y ju T by using Markovian independence assumptions The state sequence x is taken to be synchronous with the input sequence u In order to produce output sequences shorter than input sequences we will have states that do not emit an output as well as states that do emit an output When at time t the system is in a non emitting state no output can be produced Therefore there exists many sequences of states corresponding to di erent shorter length output sequences When conceived as a generative model of the output given the input an asynchronous IOHMM works as follows At time t an initial state x is chosen according to the distribution P x and the length of the output sequence s is initialized to At other time steps t a state xt is rst picked according to the transition distribution P xtjxt ut using the state at the previous time step xt and the current input ut If xt is an emitting state then the length of the output sequence is increased from s to s and the sth output ys is sampled from the emission distribution P ysjxt ut The parameters of the model are thus the initial state probabilities i P x i and the parameters of the output and transition conditional distribution models P ysjxt ut and P xtjxt ut Since the input and output sequences are of di erent lengths we will introduce another hidden variable t speci cally to represent the alignment between inputs and outputs with t s meaning that s outputs have been emitted at time t Let us rst formalize the independence assumptions and the form of the conditional distribution rep resented by the model The conditional probability P y ju T can be written as a sum of terms P y x T T ju T over all possible state sequences x T such that the number of emitting states in each of these sequences is S the length of the output sequence P y ju T X x T S P y x T T ju T All S outputs must have been emitted by time T so T S The hidden state xt takes discrete values in a nite set Each of the terms P y x T T ju T corresponds to a particular sequence of states and a corresponding alignment this probability can be written as the initial state probabilities P x times a product of factors over all the time steps t if state xt i is an emitting state that factor is P xtjxt ut P ysjxt ut otherwise that factor is simply P xtjxt ut where s is the position in the output sequence of the output emitted at time t when an output is emitted at time t We summarize in table the notation we have introduced and de ne additional notation used in this paper Table Notation used in the paper S size of the output sequence T size of the input sequence N number of states in the IOHMM a i j t output of the module that computes P xt ijxt j ut b i s t output of the module that computes P ysjxt i ut i P x i initial probability of state i zi t if xt i zi t otherwise These indicator variables give the state sequence ms t if the system emits the s th output at time t ms t otherwise These indicator variables give the input output alignment ei is true if state i emits so P ei ei is false otherwise t s means that the rst s rst outputs have been emitted at time t t k if the t th input symbol is k t k otherwise s k if the s th output symbol is k s k otherwise pred i is the set of all the predecessors states of state i succ i is the set of all the successors states of state i The Markovian conditional independence assumptions in this model mean that the state variable xt summarizes su ciently the past of the sequence so P xtjx t u t P xtjxt ut and P ysjx t u t P ysjxt ut These assumptions are analogous to the Markovian independence assumptions used in HMMs and are the same as in synchronous IOHMMs Based on these two assumptions the conditional probability can be e ciently represented and computed recursively using an intermediate variable i s t def P xt i t s y s ju t The conditional probability of an output sequence can be expressed in terms of this variable L def P y ju T X"
            },
            "slug": "An-EM-Algorithm-for-Asynchronous-Input/Output-Bengio-Bengio",
            "title": {
                "fragments": [],
                "text": "An EM Algorithm for Asynchronous Input/Output Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper considers the case in which the output sequences are shorter than the input sequences, and presents an Expectation Maximization algorithm for training asynchronous IOHMMs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776424"
                        ],
                        "name": "Eduard S\u00e4ckinger",
                        "slug": "Eduard-S\u00e4ckinger",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "S\u00e4ckinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eduard S\u00e4ckinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120242409"
                        ],
                        "name": "J. Bromley",
                        "slug": "J.-Bromley",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Bromley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bromley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "excess of 1000 characters per second [64]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15574589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8bc656a1935f07e894833b608cc4671b9fa828f",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural network with 136000 connections for recognition of handwritten digits has been implemented using a mixed analog/digital neural network chip. The neural network chip is capable of processing 1000 characters/s. The recognition system has essentially the same rate (5%) as a simulation of the network with 32-b floating-point precision."
            },
            "slug": "Application-of-the-ANNA-neural-network-chip-to-S\u00e4ckinger-Boser",
            "title": {
                "fragments": [],
                "text": "Application of the ANNA neural network chip to high-speed character recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A neural network with 136000 connections for recognition of handwritten digits has been implemented using a mixed analog/digital neural network chip, capable of processing 1000 characters/s."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3106898"
                        ],
                        "name": "D. Guillevic",
                        "slug": "D.-Guillevic",
                        "structuredName": {
                            "firstName": "Didier",
                            "lastName": "Guillevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Guillevic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7249925,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f781aea31221172c64d9b9a6d45304d14f439c99",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for recognizing unconstrained handwritten words belonging to a small static lexicon is proposed. Our computational theory is based on a psychological model of the reading process of a fast reader. The method we propose is global in its nature and avoid the difficult segmentation stage of common word recognition techniques. Our computational theory has been applied to the processing of handwritten bank cheques, whose problem domain is that of unconstrained handwriting, unlimited writers in a small static lexicon. Current results seem comparable to those published in the literature and support our computational theory."
            },
            "slug": "Cursive-script-recognition-applied-to-the-of-bank-Guillevic-Suen",
            "title": {
                "fragments": [],
                "text": "Cursive script recognition applied to the processing of bank cheques"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A method for recognizing unconstrained handwritten words belonging to a small static lexicon is proposed, based on a psychological model of the reading process of a fast reader, to avoid the difficult segmentation stage of common word recognition techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Several authors have proposed such methods to train NN/HMM speech recognizers at the word or sentence level [29], [67], [71]\u2013[78]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In speech recognition, where the recognizer is at least one order of magnitude smaller, replicated convolutional networks are easier to implement, for instance in Haffner\u2019s multistate TDNN model [78], [85]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Numerous authors in speech recognition have used gradient-based learning methods that integrate graphbased statistical models (notably HMM\u2019s) with acoustic recognition modules, mainly Gaussian mixture models, but also NN\u2019s [67], [78], [98], [99]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46122561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "250e63438812c71b8d7287f05b6235dbae2123d6",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the \"Multi-State Time Delay Neural Network\" (MS-TDNN) as an extension of the TDNN to robust word recognition. Unlike most other hybrid methods, the MS-TDNN embeds an alignment search procedure into the connectionist architecture, and allows for word level supervision. The resulting system has the ability to manage the sequential order of subword units, while optimizing for the recognizer performance. In this paper we present extensive new evaluations of this approach over speaker-dependent and speaker-independent connected alphabet."
            },
            "slug": "Multi-State-Time-Delay-Networks-for-Continuous-Haffner-Waibel",
            "title": {
                "fragments": [],
                "text": "Multi-State Time Delay Networks for Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Detailed new evaluations of the MS-TDNN approach over speaker-dependent and speaker-independent connected alphabet are presented, showing the ability to manage the sequential order of subword units, while optimizing for the recognizer performance."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428168"
                        ],
                        "name": "M. Riley",
                        "slug": "M.-Riley",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Riley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5533356,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bf2c2ca87256956b3e51bec4845c4fa28d4de7b",
            "isKey": false,
            "numCitedBy": 247,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general framework based on weighted finite automata and weighted finite-state transducers for describing and implementing speech recognizers. The framework allows us to represent uniformly the information sources and data structures used in recognition, including context-dependent units, pronunciation dictionaries, language models and lattices. Furthermore, general but efficient algorithms can used for combining information sources in actual recognizers and for optimizing their application. In particular, a single composition algorithm is used both to combine in advance information sources such as language models and dictionaries, and to combine acoustic observations and information sources dynamically during recognition."
            },
            "slug": "Speech-Recognition-by-Composition-of-Weighted-Pereira-Riley",
            "title": {
                "fragments": [],
                "text": "Speech Recognition by Composition of Weighted Finite Automata"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A single composition algorithm is used both to combine in advance information sources such as language models and dictionaries, and to combine acoustic observations and information sources dynamically during recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802785"
                        ],
                        "name": "S. Nowlan",
                        "slug": "S.-Nowlan",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Nowlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "The idea has been applied to face location [93], address block location on envelopes [94], and hand tracking in video [95]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9066905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b234385356cb10d448908cef49584bece15d94b",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system that can track a hand in a sequence of video frames and recognize hand gestures in a user-independent manner. The system locates the hand in each video frame and determines if the hand is open or closed. The tracking system is able to track the hand to within \u00b110 pixels of its correct location in 99.7% of the frames from a test set containing video sequences from 18 different individuals captured in 18 different room environments. The gesture recognition network correctly determines if the hand being tracked is open or closed in 99.1% of the frames in this test set. The system has been designed to operate in real time with existing hardware."
            },
            "slug": "A-Convolutional-Neural-Network-Hand-Tracker-Nowlan-Platt",
            "title": {
                "fragments": [],
                "text": "A Convolutional Neural Network Hand Tracker"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A system that can track a hand in a sequence of video frames and recognize hand gestures in a user-independent manner and is designed to operate in real time with existing hardware is described."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700994"
                        ],
                        "name": "R. Battiti",
                        "slug": "R.-Battiti",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Battiti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Battiti"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 44
                            }
                        ],
                        "text": "The literature abounds with recommendations [118] for"
                    },
                    "intents": []
                }
            ],
            "corpusId": 27960650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbf6f07e699587c8d52faf829a289f8cbc7f11a5",
            "isKey": false,
            "numCitedBy": 1216,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "On-line first-order backpropagation is sufficiently fast and effective for many large-scale classification problems but for very high precision mappings, batch processing may be the method of choice. This paper reviews first- and second-order optimization methods for learning in feedforward neural networks. The viewpoint is that of optimization: many methods can be cast in the language of optimization techniques, allowing the transfer to neural nets of detailed results about computational complexity and safety procedures to ensure convergence and to avoid numerical problems. The review is not intended to deliver detailed prescriptions for the most appropriate methods in specific applications, but to illustrate the main characteristics of the different methods and their mutual relations."
            },
            "slug": "First-and-Second-Order-Methods-for-Learning:-and-Battiti",
            "title": {
                "fragments": [],
                "text": "First- and Second-Order Methods for Learning: Between Steepest Descent and Newton's Method"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "First- and second-order optimization methods for learning in feedforward neural networks are reviewed to illustrate the main characteristics of the different methods and their mutual relations."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061605234"
                        ],
                        "name": "Ralph Wolf",
                        "slug": "Ralph-Wolf",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ralph Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1199403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22a1f76ba46e620e5c3131869ee8b1acdca5890b",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the use of a convolutional neural network to perform address block location on machine-printed mail pieces. Locating the address block is a difficult object recognition problem because there is often a large amount of extraneous printing on a mail piece and because address blocks vary dramatically in size and shape. \n \nWe used a convolutional locator network with four outputs, each trained to find a different corner of the address block. A simple set of rules was used to generate ABL candidates from the network output. The system performs very well: when allowed five guesses, the network will tightly bound the address delivery information in 98.2% of the cases."
            },
            "slug": "Postal-Address-Block-Location-Using-a-Convolutional-Wolf-Platt",
            "title": {
                "fragments": [],
                "text": "Postal Address Block Location Using a Convolutional Locator Network"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The use of a convolutional neural network to perform address block location on machine-printed mail pieces and a simple set of rules was used to generate ABL candidates from the network output."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076815081"
                        ],
                        "name": "Seung",
                        "slug": "Seung",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Seung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30053069"
                        ],
                        "name": "Sompolinsky",
                        "slug": "Sompolinsky",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Sompolinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sompolinsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30093773"
                        ],
                        "name": "Tishby",
                        "slug": "Tishby",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tishby"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7394722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2498a4e1755f047accc06a6e0fab0b0eb1b37ae0",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "number of examples P used for training. The theory implies that, for a reduction in eg that remains finite in the large-N limit, P should generally scale as nN, where N is the number of independently adjustable weights in the network. We show that for smooth networks, i.e., those with continuously varying weights and smooth transfer functions, the generalization curve asymptotically obeys an inverse power law. In contrast, for nonsmooth networks other behaviors can appear, depending on the nature of the nonlinearities as well as the realizability of the rule. In particular, a discontinuous learning transition from a state of poor to a state of perfect generalization can occur in nonsmooth networks learning realizable rules. We illustrate both gradual and continuous learning with a detailed analytical and numerical study of several single-layer perceptron models. Comparing with the exact replica theory of perceptron learning, we find that for realizable rules the high-temperature and annealed theories provide very good approximations to the generalization performance. Assuming this to hold for multilayer networks as well, we propose a classification of possible asymptotic forms of learning curves in general realizable models. For unrealizable rules we find that the above approximations fail in general to predict correctly the shapes of the generalization curves. Another indication of the important role of quenched disorder for unrealizable rules is that the generalization error is not necessarily a monotonically increasing function of temperature. Also, unrealizable rules can possess genuine spin-glass phases indicative of degenerate minima separated by high barriers."
            },
            "slug": "Statistical-mechanics-of-learning-from-examples.-Seung-Sompolinsky",
            "title": {
                "fragments": [],
                "text": "Statistical mechanics of learning from examples."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that for smooth networks, i.e., those with continuously varying weights and smooth transfer functions, the generalization curve asymptotically obeys an inverse power law, while for nonsmooth networks other behaviors can appear, depending on the nature of the nonlinearities as well as the realizability of the rule."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review. A, Atomic, molecular, and optical physics"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428168"
                        ],
                        "name": "M. Riley",
                        "slug": "M.-Riley",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Riley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145421878"
                        ],
                        "name": "R. Sproat",
                        "slug": "R.-Sproat",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sproat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sproat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "have been using the transducer framework for stacking HMMs representing di erent levels of processing in automatic speech recognition [86])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 161
                            }
                        ],
                        "text": "The idea of transforming graphs into other graphs has received considerable interest in computer science, through the concept of weighted nite-state transducers [86]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "The second input graph to the transformer is a grammar transducer, more speci cally a nite-state transducer [86], that encodes the relationship between input strings of class labels and corresponding output strings of recognized characters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Standard Transduction In the established framework of nite-state transducers [86], discrete symbols are attached to arcs in the graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1320875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39e5fbed9b4928f4e88483e1f52c69d01396fb8a",
            "isKey": true,
            "numCitedBy": 107,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the concepts of weighted language, transduction and automaton from algebraic automata theory as a general framework for describing and implementing decoding cascades in speech and language processing. This generality allows us to represent uniformly such information sources as pronunciation dictionaries, language models and lattices, and to use uniform algorithms for building decoding stages and for optimizing and combining them. In particular, a single automata join algorithm can be used either to combine information sources such as a pronunciation dictionary and a context-dependency model during the construction of a decoder, or dynamically during the operation of the decoder. Applications to speech recognition and to Chinese text segmentation will be discussed."
            },
            "slug": "Weighted-Rational-Transductions-and-their-to-Human-Pereira-Riley",
            "title": {
                "fragments": [],
                "text": "Weighted Rational Transductions and their Application to Human Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "The concepts of weighted language, transduction and automaton from algebraic automata theory are presented as a general framework for describing and implementing decoding cascades in speech and language processing and applications to speech recognition and Chinese text segmentation are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115014"
                        ],
                        "name": "Corinna Cortes",
                        "slug": "Corinna-Cortes",
                        "structuredName": {
                            "firstName": "Corinna",
                            "lastName": "Cortes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinna Cortes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759839"
                        ],
                        "name": "S. Solla",
                        "slug": "S.-Solla",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Solla",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "More sophisticated procedures use variable or substitute it for a diagonal matrix, or substitute it for an estimate of the inverse Hessian matrix as in Newton or quasi-Newton methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1364116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be383aa25b79ba3cb2570f044433096100a062ec",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Training classifiers on large databases is computationally demanding. It is desirable to develop efficient procedures for a reliable prediction of a classifier's suitability for implementing a given task, so that resources can be assigned to the most promising candidates or freed for exploring new classifier candidates. We propose such a practical and principled predictive method. Practical because it avoids the costly procedure of training poor classifiers on the whole training set, and principled because of its theoretical foundation. The effectiveness of the proposed procedure is demonstrated for both single- and multi-layer networks."
            },
            "slug": "Learning-Curves:-Asymptotic-Values-and-Rate-of-Cortes-Jackel",
            "title": {
                "fragments": [],
                "text": "Learning Curves: Asymptotic Values and Rate of Convergence"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes a practical and principled predictive method that avoids the costly procedure of training poor classifiers on the whole training set, and it is demonstrated for both single- and multi-layer networks."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126340"
                        ],
                        "name": "S. Miyake",
                        "slug": "S.-Miyake",
                        "structuredName": {
                            "firstName": "Sei",
                            "lastName": "Miyake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Miyake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "This knowledge can be applied by forcing a set of units, whose receptive fields are located at different places on the image, to have identical weight vectors [15], [32], [34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "The convolution/subsampling combination, inspired by Hubel and Wiesel\u2019s notions of \u201csimple\u201d and \u201ccomplex\u201d cells, was implemented in Fukushima\u2019s Neocognitron [32],\nthough no globally supervised learning procedure such as back propagation was available then."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2357880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9aec973227713cd45f156090d82a3056cca8060f",
            "isKey": false,
            "numCitedBy": 697,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neocognitron:-A-new-algorithm-for-pattern-tolerant-Fukushima-Miyake",
            "title": {
                "fragments": [],
                "text": "Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144473519"
                        ],
                        "name": "M. Mozer",
                        "slug": "M.-Mozer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mozer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mozer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 5
                            }
                        ],
                        "text": "First, typical images are large, often with several hundred variables (pixels)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5125059,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1762498d7ef09cc706b551c54ce6894a7b2ee14d",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "\"The Perception of Multiple Objects \"describes a neurally inspired computational model of two-dimensional object recognition and spatial attention that can explain many characteristics of human visual perception. The model, called MORSEL (named for its ability to perform Multiple Object Recognition and attentional Selection), is unique in providing a broad and unified explanation for a wide range of experimental psychological data on visual perception and attention. Although it draws on existing theoretical perspectives from cognitive psychology, it is a fully mechanistic account, not just a functional-level theory.MORSEL has been trained to recognize letters and words in various positions on its \"retina.\" Following training, it can also recognize several items at once, subject to capacity limitations. The model makes predictions about what sorts of information the visual system can process in parallel and what sorts must be processed serially.Through simulation experiments, chiefly in letter and word perception, MORSEL has been shown to account for a variety of psychological phenomena, including perceptual errors that arise when several items appear simultaneously in the visual field, facilitatory effects of context and redundant information, attentional phenomena, visual search performance, and behaviors exhibited by neurological patients with acquired dyslexia."
            },
            "slug": "Perception-of-multiple-objects-a-connectionist-Mozer",
            "title": {
                "fragments": [],
                "text": "Perception of multiple objects - a connectionist approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The model, called MORSEL, is unique in providing a broad and unified explanation for a wide range of experimental psychological data on visual perception and attention, and draws on existing theoretical perspectives from cognitive psychology."
            },
            "venue": {
                "fragments": [],
                "text": "Neural network modeling and connectionism"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "78659204"
                        ],
                        "name": "M. Mohri",
                        "slug": "M.-Mohri",
                        "structuredName": {
                            "firstName": "Mehryar",
                            "lastName": "Mohri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mohri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 83
                            }
                        ],
                        "text": "Transducers have been applied to speech recognition [100] and language translation [101], and proposals have been made for handwriting recognition [102]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5548799,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4cc5563c694355ddcf746ff9a55ccdb22d86a98",
            "isKey": false,
            "numCitedBy": 1040,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Finite-machines have been used in various domains of natural language processing. We consider here the use of a type of transducer that supports very efficient programs: sequential transducers. We recall classical theorems and give new ones characterizing sequential string-to-string transducers. Transducers that outpur weights also play an important role in language and speech processing. We give a specific study of string-to-weight transducers, including algorithms for determinizing and minizizing these transducers very efficiently, and characterizations of the transducers admitting determinization and the corresponding algorithms. Some applications of these algorithms in speech recognition are described and illustrated."
            },
            "slug": "Finite-State-Transducers-in-Language-and-Speech-Mohri",
            "title": {
                "fragments": [],
                "text": "Finite-State Transducers in Language and Speech Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work recalls classical theorems and gives new ones characterizing sequential string-to-string transducers, including algorithms for determinizing and minizizing these transducers very efficiently, and characterizations of the transducers admitting determinization and the corresponding algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49128898"
                        ],
                        "name": "U. A. M\u00fcller",
                        "slug": "U.-A.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Urs",
                            "lastName": "M\u00fcller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. A. M\u00fcller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730723"
                        ],
                        "name": "A. Gunzinger",
                        "slug": "A.-Gunzinger",
                        "structuredName": {
                            "firstName": "Anton",
                            "lastName": "Gunzinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gunzinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3278726"
                        ],
                        "name": "W. Guggenb\u00fchl",
                        "slug": "W.-Guggenb\u00fchl",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Guggenb\u00fchl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Guggenb\u00fchl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206457807,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3bdb4893a1816f560e0baa82792e2bb40936d152",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the implementation of a fast neural net simulator on a novel parallel distributed-memory computer. A 60-processor system, named MUSIC (multiprocessor system with intelligent communication), is operational and runs the backpropagation algorithm at a speed of 330 million connection updates per second (continuous weight update) using 32-b floating-point precision. This is equal to 1.4 Gflops sustained performance. The complete system with 3.8 Gflops peak performance consumes less than 800 W of electrical power and fits into a 19-in rack. While reaching the speed of modern supercomputers, MUSIC still can be used as a personal desktop computer at a researcher's own disposal. In neural net simulation, this gives a computing performance to a single user which was unthinkable before. The system's real-time interfaces make it especially useful for embedded applications."
            },
            "slug": "Fast-neural-net-simulation-with-a-DSP-processor-M\u00fcller-Gunzinger",
            "title": {
                "fragments": [],
                "text": "Fast neural net simulation with a DSP processor array"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper describes the implementation of a fast neural net simulator on a novel parallel distributed-memory computer that gives a computing performance to a single user which was unthinkable before."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416462"
                        ],
                        "name": "G. Cybenko",
                        "slug": "G.-Cybenko",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Cybenko",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cybenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3958369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8da1dda34ecc96263102181448c94ec7d645d085",
            "isKey": false,
            "numCitedBy": 6368,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks."
            },
            "slug": "Approximation-by-superpositions-of-a-sigmoidal-Cybenko",
            "title": {
                "fragments": [],
                "text": "Approximation by superpositions of a sigmoidal function"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "It is demonstrated that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Control. Signals Syst."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087814893"
                        ],
                        "name": "Markus Voelter",
                        "slug": "Markus-Voelter",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Voelter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Voelter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2860566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3461eaf51016f9d6e85ea47173b27e019e801c4",
            "isKey": false,
            "numCitedBy": 4580,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "We are concerned with the inference (induction) of theories (hypotheses) from observations (data). This problem is common to philosophy (Aristotle 1988), statistical inference (Casella & Berger 2001) and machine learning (Mitchell 1997, Agluin & Smith 1983). We constrain ourselves only to the latter two frameworks. Within machine-learning, we further concentrate on its subfield called inductive logic programming (Nienhuys-Cheng & de Wolf 1997). Whereas in statistics we namely concentrate on evaluating hypotheses, in machine learning we study ways of constructing the theories. From the theoretical viewpoint, however, the construction is also viewed as a selection of a hypothesis from an a priori given set. Unlike in statistics, however, the range of considered hypotheses is usually large so that hypotheses cannot by inspected individually by a human. Such a set of hypotheses may be conveniently viewed as (equivalent to) a language L H generated by a certain formal grammar. Every hypothesis H \u2208 L H induces a mapping h : X \u2192 O where X is a predefined (usually countable) set of instances (which we also call the domain of L H) and O is a set usually assumed to be finite and its elements called classes. Very often, O has just two elements. The assigned mapping gives the hypothesis its meaning (semantics). The usual formalization of the concept learning task is then as follows. Let there be a hypothesis C \u2208 L H called the target concept and let n examples (x 1 , c(x 1)),(x 2 , c(x 2)),... ,(x n , c(x n))= S drawn from a predefined distribution D X on X be provided to the algorithm L called the learner (S is called a sample). We ask L to output an hypothesis H \u2208 L H such that a specified error function Err(H, C) is minimized with respect to D X. The error function may be defined as e.g. Err(H, C) = 0 if H \u2261 C (i.e. h(x) = c(x) \u2200x \u2208 X) and Err(H, C) = 1 otherwise, that is, irrespectively of the distribution D X. We would thus require the learner to exactly identify the target concept. This would be close to the theoretical framework of identification in the limit (Gold 1967), which, roughly said, demands that the learner converges to the correct hypothesis in the limit as n \u2192 \u221e. Such a requirement is however very rigid and does not comply to the \u2026"
            },
            "slug": "State-of-the-Art-Voelter",
            "title": {
                "fragments": [],
                "text": "State of the Art"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This work is concerned with the inference (induction) of theories (hypotheses) from observations ( data) and this problem is common to philosophy, statistical inference, machine learning and inductive logic programming."
            },
            "venue": {
                "fragments": [],
                "text": "Pediatric Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992604"
                        ],
                        "name": "E. Levin",
                        "slug": "E.-Levin",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "Much theoretical and experimental work [3], [4], [5] has shown that the gap between the expected error rate on the test set Etest and the error rate on the training set Etrain decreases with the number of training samples approximately as Etest Etrain = k(h=P ) (1) where P is the number of training samples, h is a measure of \\e ective capacity\" or complexity of the machine [6], [7], is a number between 0:5 and 1:0, and k is a constant."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207597853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "899defb6a100af509547b8d74bb626533ee87da4",
            "isKey": false,
            "numCitedBy": 351,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for measuring the capacity of learning machines is described. The method is based on fitting a theoretically derived function to empirical measurements of the maximal difference between the error rates on two separate data sets of varying sizes. Experimental measurements of the capacity of various types of linear classifiers are presented."
            },
            "slug": "Measuring-the-VC-Dimension-of-a-Learning-Machine-Vapnik-Levin",
            "title": {
                "fragments": [],
                "text": "Measuring the VC-Dimension of a Learning Machine"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A method for measuring the capacity of learning machines is described, based on fitting a theoretically derived function to empirical measurements of the maximal difference between the error rates on two separate data sets of varying sizes."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35046585"
                        ],
                        "name": "B. Flannery",
                        "slug": "B.-Flannery",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Flannery",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flannery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48590121"
                        ],
                        "name": "S. Teukolsky",
                        "slug": "S.-Teukolsky",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Teukolsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teukolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608024"
                        ],
                        "name": "W. Vetterling",
                        "slug": "W.-Vetterling",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vetterling",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vetterling"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 195707510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11b9a11e73ce3f648960e900c3f27bd98dda5ea2",
            "isKey": false,
            "numCitedBy": 10808,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis is the revised and greatly expanded Second Edition of the hugely popular Numerical Recipes: The Art of Scientific Computing. The product of a unique collaboration among four leading scientists in academic research and industry, Numerical Recipes is a complete text and reference book on scientific computing. In a self-contained manner it proceeds from mathematical and theoretical considerations to actual practical computer routines. With over 100 new routines (now well over 300 in all), plus upgraded versions of many of the original routines, this book is more than ever the most practical, comprehensive handbook of scientific computing available today. The book retains the informal, easy-to-read style that made the first edition so popular, with many new topics presented at the same accessible level. In addition, some sections of more advanced material have been introduced, set off in small type from the main body of the text. Numerical Recipes is an ideal textbook for scientists and engineers and an indispensable reference for anyone who works in scientific computing. Highlights of the new material include a new chapter on integral equations and inverse methods; multigrid methods for solving partial differential equations; improved random number routines; wavelet transforms; the statistical bootstrap method; a new chapter on \"less-numerical\" algorithms including compression coding and arbitrary precision arithmetic; band diagonal linear systems; linear algebra on sparse matrices; Cholesky and QR decomposition; calculation of numerical derivatives; Pade approximants, and rational Chebyshev approximation; new special functions; Monte Carlo integration in high-dimensional spaces; globally convergent methods for sets of nonlinear equations; an expanded chapter on fast Fourier methods; spectral analysis on unevenly sampled data; Savitzky-Golay smoothing filters; and two-dimensional Kolmogorov-Smirnoff tests. All this is in addition to material on such basic top"
            },
            "slug": "Numerical-Recipes-in-C:-The-Art-of-Sci-entific-Press-Flannery",
            "title": {
                "fragments": [],
                "text": "Numerical Recipes in C: The Art of Sci-entific Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This is the revised and greatly expanded Second Edition of the hugely popular Numerical Recipes, with over 100 new routines (now well over 300 in all), plus upgraded versions of many of the original routines."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081464302"
                        ],
                        "name": "Cun",
                        "slug": "Cun",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Cun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104372862"
                        ],
                        "name": "Kanter",
                        "slug": "Kanter",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Kanter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kanter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30006126"
                        ],
                        "name": "Solla",
                        "slug": "Solla",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Solla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Solla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This makes the mean input roughly zero and the variance roughly one, which accelerates learning [46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41596547,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fe5f4a0e774d3124b2a0e6591636acd0cdc7fc27",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The learing time of a simple neural-network model is obtained through an analytic computation of the eigenvalue spectrum for the Hessian matrix, which describes the second-order properties of the objective function in the space of coupling coefficients. The results are generic for symmetric matrices obtained by summing outer products of random vectors. The form of the eigenvalue distribution suggests new techniques for accelerating the learning process, and provides a theoretical justification for the choice of centered versus biased state variables."
            },
            "slug": "Eigenvalues-of-covariance-matrices:-Application-to-Cun-Kanter",
            "title": {
                "fragments": [],
                "text": "Eigenvalues of covariance matrices: Application to neural-network learning."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The learing time of a simple neural-network model is obtained through an analytic computation of the eigenvalue spectrum for the Hessian matrix, which describes the second-order properties of the objective function in the space of coupling coefficients."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review letters"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 141
                            }
                        ],
                        "text": "Gradient Back-Propagation Gradient-Based Learning procedures have been used since the late 1950's, but were mostly limited to linear systems [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "SUBMITTED TO PROCEEDINGS OF THE IEEE, 1998 2 used by the classi ers were limited to low-dimensional spaces with easily separable classes [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "The de ciencies of the linear classi er are well documented [1] and it is included here simply to form a basis of comparison for more sophisticated classi ers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": true,
            "numCitedBy": 16925,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256718"
                        ],
                        "name": "W. Press",
                        "slug": "W.-Press",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Press",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Press"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35046585"
                        ],
                        "name": "B. Flannery",
                        "slug": "B.-Flannery",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Flannery",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Flannery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48590121"
                        ],
                        "name": "S. Teukolsky",
                        "slug": "S.-Teukolsky",
                        "structuredName": {
                            "firstName": "Saul",
                            "lastName": "Teukolsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Teukolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608024"
                        ],
                        "name": "W. Vetterling",
                        "slug": "W.-Vetterling",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Vetterling",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Vetterling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46995895"
                        ],
                        "name": "P. B. Kramer",
                        "slug": "P.-B.-Kramer",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Kramer",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. B. Kramer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 147
                            }
                        ],
                        "text": "large when the second derivative is small, very much like the \u201cmodel-trust\u201d methods, and the Levenberg\u2013Marquardt methods in nonlinear optimization [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "The conjugate gradient method [8] can also be"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61629172,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "ae8a8f9f26683d6d462b4eaf5a4e0212e113de0d",
            "isKey": false,
            "numCitedBy": 1841,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Numerical-Recipes:-The-Art-of-Scientific-Computing-Press-Flannery",
            "title": {
                "fragments": [],
                "text": "Numerical Recipes: The Art of Scientific Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334226"
                        ],
                        "name": "D. Hubel",
                        "slug": "D.-Hubel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hubel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hubel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2629471"
                        ],
                        "name": "T. Wiesel",
                        "slug": "T.-Wiesel",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Wiesel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wiesel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "selective neurons in the cat\u2019s visual system [30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17055992,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "6b4fe4aa4d66fecc7b2869569002714d91d0b3f7",
            "isKey": false,
            "numCitedBy": 12429,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "What chiefly distinguishes cerebral cortex from other parts of the central nervous system is the great diversity of its cell types and interconnexions. It would be astonishing if such a structure did not profoundly modify the response patterns of fibres coming into it. In the cat's visual cortex, the receptive field arrangements of single cells suggest that there is indeed a degree of complexity far exceeding anything yet seen at lower levels in the visual system. In a previous paper we described receptive fields of single cortical cells, observing responses to spots of light shone on one or both retinas (Hubel & Wiesel, 1959). In the present work this method is used to examine receptive fields of a more complex type (Part I) and to make additional observations on binocular interaction (Part II). This approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours. In the past, the technique of recording evoked slow waves has been used with great success in studies of functional anatomy. It was employed by Talbot & Marshall (1941) and by Thompson, Woolsey & Talbot (1950) for mapping out the visual cortex in the rabbit, cat, and monkey. Daniel & Whitteiidge (1959) have recently extended this work in the primate. Most of our present knowledge of retinotopic projections, binocular overlap, and the second visual area is based on these investigations. Yet the method of evoked potentials is valuable mainly for detecting behaviour common to large populations of neighbouring cells; it cannot differentiate functionally between areas of cortex smaller than about 1 mm2. To overcome this difficulty a method has in recent years been developed for studying cells separately or in small groups during long micro-electrode penetrations through nervous tissue. Responses are correlated with cell location by reconstructing the electrode tracks from histological material. These techniques have been applied to"
            },
            "slug": "Receptive-fields,-binocular-interaction-and-in-the-Hubel-Wiesel",
            "title": {
                "fragments": [],
                "text": "Receptive fields, binocular interaction and functional architecture in the cat's visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This method is used to examine receptive fields of a more complex type and to make additional observations on binocular interaction and this approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of physiology"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 96
                            }
                        ],
                        "text": "A different approach to graph-based trainable systems, called input\u2013output HMM, was proposed in [104] and [105]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29085cdffb3277c1c8fd10ac09e0d89452c8db83",
            "isKey": false,
            "numCitedBy": 357,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a recurrent architecture having a modular structure and we formulate a training procedure based on the EM algorithm. The resulting model has similarities to hidden Markov models, but supports recurrent networks processing style and allows to exploit the supervised learning paradigm while using maximum likelihood estimation."
            },
            "slug": "An-Input-Output-HMM-Architecture-Bengio-Frasconi",
            "title": {
                "fragments": [],
                "text": "An Input Output HMM Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A recurrent architecture having a modular structure that has similarities to hidden Markov models, but supports recurrent networks processing style and allows to exploit the supervised learning paradigm while using maximum likelihood estimation is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47953439"
                        ],
                        "name": "R\u00e9gis Vaillant",
                        "slug": "R\u00e9gis-Vaillant",
                        "structuredName": {
                            "firstName": "R\u00e9gis",
                            "lastName": "Vaillant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9gis Vaillant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3208918"
                        ],
                        "name": "C. Monrocq",
                        "slug": "C.-Monrocq",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Monrocq",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Monrocq"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9326933"
                        ],
                        "name": "Y. L. Cun",
                        "slug": "Y.-L.-Cun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Cun",
                            "middleNames": [
                                "le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. L. Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To illustrate the method, we will consider the case of face detection in images as described in [93]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The idea has been applied to face location [93], address block location on envelopes [94], and hand tracking in video [95]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A 2-D version of the global training method described in the previous section can be used to alleviate the need to manually locate faces when building the training sample [93]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62763570,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "09ebd9ad4fa21c0d56433ac57a4cd69e94c72281",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An original approach is presented for the localisation of objects in an image which approach is neuronal and has two steps. In the first step, a rough localisation is performed by presenting each pixel with its neighbourhood to a neural net which is able to indicate whether this pixel and its neighbourhood are the image of the search object. This first filter does not discriminate for position. From its result, areas which might contain an image of the object can be selected. In the second step, these areas are presented to another neural net which can determine the exact position of the object in each area. This algorithm is applied to the problem of localising faces in images."
            },
            "slug": "Original-approach-for-the-localisation-of-objects-Vaillant-Monrocq",
            "title": {
                "fragments": [],
                "text": "Original approach for the localisation of objects in images"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "An original approach is presented for the localisation of objects in an image which approach is neuronal and has two steps and is applied to the problem of localising faces in images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144905110"
                        ],
                        "name": "L. Lam",
                        "slug": "L.-Lam",
                        "structuredName": {
                            "firstName": "Louisa",
                            "lastName": "Lam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3106898"
                        ],
                        "name": "D. Guillevic",
                        "slug": "D.-Guillevic",
                        "structuredName": {
                            "firstName": "Didier",
                            "lastName": "Guillevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Guillevic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820293"
                        ],
                        "name": "N. W. Strathy",
                        "slug": "N.-W.-Strathy",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Strathy",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. W. Strathy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145541445"
                        ],
                        "name": "M. Cheriet",
                        "slug": "M.-Cheriet",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Cheriet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cheriet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152352223"
                        ],
                        "name": "Ke Liu",
                        "slug": "Ke-Liu",
                        "structuredName": {
                            "firstName": "Ke",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ke Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911370"
                        ],
                        "name": "J. N. Said",
                        "slug": "J.-N.-Said",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Said",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. N. Said"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17954297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "683689ed058d0a5bea53129a09dc857d3bf04bc0",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In the business transactions of large corporations such as utility companies and banks, many cheques must be processed on a regular basis. In this paper, we describe algorithms currently under development to automatically process the information contained on them. These procedures are designed to preprocess the scanned image of a cheque, locate and extract different items of information from it, and produce recognition results for these items by classifiers developed for each function."
            },
            "slug": "Automatic-processing-of-information-on-cheques-Lam-Suen",
            "title": {
                "fragments": [],
                "text": "Automatic processing of information on cheques"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "These procedures are designed to preprocess the scanned image of a cheque, locate and extract different items of information from it, and produce recognition results for these items by classifiers developed for each function."
            },
            "venue": {
                "fragments": [],
                "text": "1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500689"
                        ],
                        "name": "A. Viterbi",
                        "slug": "A.-Viterbi",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Viterbi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Viterbi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "The Viterbi transformer owes its name to the famous Viterbi algorithm [70], an application of the principle of dynamic programming to find the shortest path in a graph efficiently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15843983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "145c0b53514b02bdc3dadfb2e1cea124f2abd99b",
            "isKey": false,
            "numCitedBy": 5206,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates above R_{0} , the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "slug": "Error-bounds-for-convolutional-codes-and-an-optimum-Viterbi",
            "title": {
                "fragments": [],
                "text": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2506116"
                        ],
                        "name": "D. Saad",
                        "slug": "D.-Saad",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Saad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Saad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759839"
                        ],
                        "name": "S. Solla",
                        "slug": "S.-Solla",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Solla",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12538968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d85aa0711038278b4e1717aec9f7a52ff8836f7",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of on-line gradient descent learning for general two-layer neural networks. An analytic solution is presented and used to investigate the role of the learning rate in controlling the evolution and convergence of the learning process."
            },
            "slug": "Dynamics-of-On-Line-Gradient-Descent-Learning-for-Saad-Solla",
            "title": {
                "fragments": [],
                "text": "Dynamics of On-Line Gradient Descent Learning for Multilayer Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This work considers the problem of on-line gradient descent learning for general two-layer neural networks and presents an analytic solution and uses the role of the learning rate in controlling the evolution and convergence of thelearning process."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 384,
                                "start": 381
                            }
                        ],
                        "text": "Much theoretical and experimental work [3], [4], [5] has shown that the gap between the expected error rate on the test set Etest and the error rate on the training set Etrain decreases with the number of training samples approximately as Etest Etrain = k(h=P ) (1) where P is the number of training samples, h is a measure of \\e ective capacity\" or complexity of the machine [6], [7], is a number between 0:5 and 1:0, and k is a constant."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "SUBMITTED TO PROCEEDINGS OF THE IEEE, 1998 3 structural risk minimization [6], [7], and is based on de ning a sequence of learning machines of increasing capacity, corresponding to a sequence of subsets of the parameter space such that each subset is a superset of the previous subset."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "Theoretical arguments [6], [7] suggest that estimating input densities when the real goal is to obtain a discriminant function for classi cation is a suboptimal strategy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": false,
            "numCitedBy": 26320,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56128297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5f09ce0dd760857e0d0e4879f6e2543f04c5d33",
            "isKey": false,
            "numCitedBy": 926,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for estimating the parameters of hidden Markov models of speech is described. Parameter values are chosen to maximize the mutual information between an acoustic observation sequence and the corresponding word sequence. Recognition results are presented comparing this method with maximum likelihood estimation."
            },
            "slug": "Maximum-mutual-information-estimation-of-hidden-for-Bahl-Brown",
            "title": {
                "fragments": [],
                "text": "Maximum mutual information estimation of hidden Markov model parameters for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method for estimating the parameters of hidden Markov models of speech is described and recognition results are presented comparing this method with maximum likelihood estimation."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 43
                            }
                        ],
                        "text": "The second event was the popularization by Rumelhartet al. [15] and others of a simple and efficient procedure to compute the gradient in a nonlinear system composed\n2280 PROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nof several layers of processing, i.e., the back-propagation algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58779360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8592e46a5435d18bba70557846f47290b34c1aa5",
            "isKey": false,
            "numCitedBy": 1338,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Relaxation Searches, Easy and Hard Learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, An Example of the Effects of Damage, Conclusion, Acknowledgments, Appendix: Derivation of the Learning Algorithm, References"
            },
            "slug": "Learning-and-relearning-in-Boltzmann-machines-Hinton-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Learning and relearning in Boltzmann machines"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This chapter contains sections titled: Relaxation Searches, Easy and Hard learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, and an Example of the Effects of Damage."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741426"
                        ],
                        "name": "P. Gallinari",
                        "slug": "P.-Gallinari",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Gallinari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gallinari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "The best way to justify it theoretically is through the use of Lagrange functions [21], [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 207
                            }
                        ],
                        "text": "If this is the case, a simple generalization of the well-known back-propagation procedure can be used to e ciently compute the gradients of the loss function with respect to all the parameters in the system [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 258
                            }
                        ],
                        "text": "The Lagrange formalism used in the control theory literature provides perhaps the best rigorous method for deriving back-propagation [20], and for deriving generalizations of back-propagation to recurrent networks [21], and networks of heterogeneous modules [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "A completely rigorous derivation in more general cases can be done using Lagrange functions [20], [21], [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 628165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3fa4c1ebd90bf14c55d253806fdf9e69defd729",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a framework for training architectures composed of several modules. This framework, which uses a statistical formulation of learning systems, provides a unique formalism for describing many classical connectionist algorithms as well as complex systems where several algorithms interact. It allows to design hybrid systems which combine the advantages of connectionist algorithms as well as other learning algorithms."
            },
            "slug": "A-Framework-for-the-Cooperation-of-Learning-Bottou-Gallinari",
            "title": {
                "fragments": [],
                "text": "A Framework for the Cooperation of Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This framework, which uses a statistical formulation of learning systems, provides a unique formalism for describing many classical connectionist algorithms as well as complex systems where several algorithms interact."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24802,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786606"
                        ],
                        "name": "R. Brodersen",
                        "slug": "R.-Brodersen",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Brodersen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brodersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48963764"
                        ],
                        "name": "C. Hewes",
                        "slug": "C.-Hewes",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Hewes",
                            "middleNames": [
                                "Robert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Hewes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1563805,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "f7760fb2a41c9ba811ede43ea4709e07413192fd",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The present capabilities of speech recognition algorithms will be surveyed. The application of IC technology to the implementation of these algorithms will be explored and potential future directions will be determined."
            },
            "slug": "Speech-recognition-Brodersen-Hewes",
            "title": {
                "fragments": [],
                "text": "Speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The present capabilities of speech recognition algorithms will be surveyed and the application of IC technology to the implementation of these algorithm will be explored and potential future directions will be determined."
            },
            "venue": {
                "fragments": [],
                "text": "1983 IEEE International Solid-State Circuits Conference. Digest of Technical Papers"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145884505"
                        ],
                        "name": "V. Cherkassky",
                        "slug": "V.-Cherkassky",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Cherkassky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cherkassky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "SUBMITTED TO PROCEEDINGS OF THE IEEE, 1998 3 structural risk minimization [6], [7], and is based on de ning a sequence of learning machines of increasing capacity, corresponding to a sequence of subsets of the parameter space such that each subset is a superset of the previous subset."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 119
                            }
                        ],
                        "text": "This seems to be an almost perfect, if fortuitous, implementation of Vapnik's \\Structural Risk Minimization\" principle [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 379,
                                "start": 376
                            }
                        ],
                        "text": "Much theoretical and experimental work [3], [4], [5] has shown that the gap between the expected error rate on the test set Etest and the error rate on the training set Etrain decreases with the number of training samples approximately as Etest Etrain = k(h=P ) (1) where P is the number of training samples, h is a measure of \\e ective capacity\" or complexity of the machine [6], [7], is a number between 0:5 and 1:0, and k is a constant."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "Theoretical arguments [6], [7] suggest that estimating input densities when the real goal is to obtain a discriminant function for classi cation is a suboptimal strategy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 176
                            }
                        ],
                        "text": "The Support Vector technique is an extremely economical way of representing complex surfaces in high-dimensional spaces, including polynomials and many other types of surfaces [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206755547,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "e64fecbaf4d75e0dd6711f8f335c8a53da9fd360",
            "isKey": true,
            "numCitedBy": 3182,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "If you really want to be smarter, reading can be one of the lots ways to evoke and realize. Many people who like reading will have more knowledge and experiences. Reading can be a way to gain information from economics, politics, science, fiction, literature, religion, and many others. As one of the part of book categories, the nature of statistical learning theory always becomes the most wanted book. Many people are absolutely searching for this book. It means that many love to read this kind of book."
            },
            "slug": "The-Nature-Of-Statistical-Learning-Theory-Cherkassky",
            "title": {
                "fragments": [],
                "text": "The Nature Of Statistical Learning Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "As one of the part of book categories, the nature of statistical learning theory always becomes the most wanted book."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69425235"
                        ],
                        "name": "I\ufe20a\ufe21. Z. T\ufe20S\ufe21ypkin",
                        "slug": "I\ufe20a\ufe21.-Z.-T\ufe20S\ufe21ypkin",
                        "structuredName": {
                            "firstName": "I\ufe20a\ufe21.",
                            "lastName": "T\ufe20S\ufe21ypkin",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I\ufe20a\ufe21. Z. T\ufe20S\ufe21ypkin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60871581,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "ded14685a23df94d93e8662578d4132c9f4aa1c7",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Foundations-of-the-theory-of-learning-systems-T\ufe20S\ufe21ypkin",
            "title": {
                "fragments": [],
                "text": "Foundations of the theory of learning systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19355,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 163
                            }
                        ],
                        "text": "However, Appendix B shows that despite many claims to the contrary in the literature, the usefulness of these second-order methods to large learning machines is very limited."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 219
                            }
                        ],
                        "text": "\u2026this procedure the parameter vector fluctuates around an average trajectory, but usually it converges considerably faster than regular gradient descent and second-order methods on large training sets with redundant samples (such as those encountered in speech or character recognition)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15516143"
                        ],
                        "name": "A. Lucier",
                        "slug": "A.-Lucier",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Lucier",
                            "middleNames": [
                                "Alfred"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lucier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103882335"
                        ],
                        "name": "S. Haines",
                        "slug": "S.-Haines",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Haines",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haines"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 127263026,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "bdf2081749ff30ec219006afa139f48e1edb9592",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Acidification of forest ecosystems is a complex process controlled by numerous hydrologic, geochemical, and biological factors. In the context of soil genesis, acidification is a normal consequence of mineral weathering, biological activity, and base cation leaching in humid environments (precipitation exceeds evapotranspiration). Relevant time scales are decades to millenia. In the context of ecology and environmental science, acidification may result from biomass harvest, land use conversions, natural changes in vegetation, and intentional or unintentional inputs of acidifying compounds, especially those of sulfur and nitrogen. Relevant time scales range from days to centuries."
            },
            "slug": "Overview-and-Synthesis-Lucier-Haines",
            "title": {
                "fragments": [],
                "text": "Overview and Synthesis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105353"
                        ],
                        "name": "K. Narendra",
                        "slug": "K.-Narendra",
                        "structuredName": {
                            "firstName": "Kumpati",
                            "lastName": "Narendra",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Narendra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62742604,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "624d7d56f98f29e96c36493b2a9e1820ec53725d",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Concrete"
            },
            "slug": "Adaptation-and-learning-in-automatic-systems-Narendra",
            "title": {
                "fragments": [],
                "text": "Adaptation and learning in automatic systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145778742"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Juang",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "This GTN is somewhat similar to Hidden Markov Models (HMM), which makes the approach reminiscent of the classical speech recognition [28], [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "Viterbi training, though formulated di erently, is often use in HMM-based speech recognition systems [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "Training methods for graph-based sequence recognition systems such as HMMs have been extensively studied in the context of speech recognition [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "Given an interpretation, there is a well known method, called the forward algorithm for computing the above quantity e ciently [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "The recent history of automatic speech recognition [28], [67] is here to remind us that training a recognizer by optimizing a global criterion (at the word or sentence level) is much preferable to merely training it on hand-segmented phonemes or other units."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "The forward algorithm gets its name from the forward pass of the wellknown Baum-Welsh algorithm for training Hidden Markov Models [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60838227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81d734347d5d6732be09493180387bd640d3490f",
            "isKey": true,
            "numCitedBy": 625,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-tutorial-on-Hidden-Markov-Models-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "A tutorial on Hidden Markov Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 141
                            }
                        ],
                        "text": "Gradient Back-Propagation Gradient-Based Learning procedures have been used since the late 1950's, but were mostly limited to linear systems [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "SUBMITTED TO PROCEEDINGS OF THE IEEE, 1998 2 used by the classi ers were limited to low-dimensional spaces with easily separable classes [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "The de ciencies of the linear classi er are well documented [1] and it is included here simply to form a basis of comparison for more sophisticated classi ers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 186248191,
            "fieldsOfStudy": [],
            "id": "f7725ec3cbf99605ec4f6e5a8d2ebf11eb407933",
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern Classi cation and Scene Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 149
                            }
                        ],
                        "text": "In a series of experiments, we replaced the last layer of LeNet4 with a Euclidean nearest-neighbor classifier, and with the \u201clocal learning\u201d method of Bottou and Vapnik [58], in which a local linear classifier is retrained each time a new test pattern is shown."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Another approach would consists of directly minimizing an approximation of the number of misclassifications [83], [76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "Similar algorithms have been applied to speech recognition systems that integrate NN\u2019s with time alignment [71], [72], [76] or hybrid neuralnetwork/HMM systems [29], [74], [75]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 13
                            }
                        ],
                        "text": "Y. LeCun, L. Bottou, and P. Haffner are with the Speech and Image\nProcessing Services Research Laboratory, AT&T Labs-Research, Red Bank, NJ 07701 USA."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Driancourt and Bottou [76] used a version of it where the loss function is saturated to a fixed value."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MLP, LVQ and DP: Comparison & cooperation"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Joint Conf. Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "For our simulations, we use A = 1:7159 and S = 2 3 (see [20], [34])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "This knowledge can be applied by forcing a set of units, whose receptive elds are located at di erent places on the image, to have identical weight vectors [32], [15], [34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "Local connections have been used many times in neural models of visual learning [31], [32], [18], [33], [34], [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 209
                            }
                        ],
                        "text": "The weight sharing technique has the interesting side e ect of reducing the number of free parameters, thereby reducing the \\capacity\" of the machine and reducing the gap between test error and training error [34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalization and network design"
            },
            "venue": {
                "fragments": [],
                "text": "Connectionism in Perspective,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 149
                            }
                        ],
                        "text": "In a series of experiments, we replaced the last layer of LeNet4 with a Euclidean nearest-neighbor classifier, and with the \u201clocal learning\u201d method of Bottou and Vapnik [58], in which a local linear classifier is retrained each time a new test pattern is shown."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "Similar algorithms have been applied to speech recognition systems that integrate neural networks with time alignment [71], [72], [76] or hybrid neural-network/HMM systems [29], [74], [75]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Driancourt and Bottou [76] used a version of it where the loss function is saturated to a xed value."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "Several authors have proposed such methods to train neural network/HMM speech recognizers at the word or sentence level [71], [72], [73], [74], [75], [76], [77], [78], [29], [67]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Another approach would consists of directly minimizing an approximation of the number of misclassi cations [83] [76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 13
                            }
                        ],
                        "text": "Y. LeCun, L. Bottou, and P. Haffner are with the Speech and Image\nProcessing Services Research Laboratory, AT&T Labs-Research, Red Bank, NJ 07701 USA."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Driancourt and Bottou [76] used a version of it where the loss function is saturated to a fixed value."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MLP, LVQ and DP: Compari-  son & cooperation,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Joint  Conference on Neural Networks, Seattle,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 16
                            }
                        ],
                        "text": "4) RBF Network: Following [55], an RBF network was constructed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "3 Principal Component Analysis and Polynomial Classi er Following [53], [54], a preprocessing stage was constructed which computes the projection of the input pattern on the 40 principal components of the set of training vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 19
                            }
                        ],
                        "text": "9) Boosted LeNet-4:Following theoretical work by Schapire [59], Druckeret al. [60] developed the \u201cboosting\u201d method for combining multiple classifiers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 108
                            }
                        ],
                        "text": "LECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION 2289\n3) PCA and Polynomial Classifier:Following [53] and [54], a preprocessing stage was constructed which computes the projection of the input pattern on the 40 principal components of the set of training vectors."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "construction of quadratic polynomial classi ers,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of International Conference on Pattern Recognition"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775043"
                        ],
                        "name": "H. Graf",
                        "slug": "H.-Graf",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Graf",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Graf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Isolated handwritten character recognition has been extensively studied in the literature (see [23] and [24] for reviews), and it was one of the early successful applications of NN\u2019s [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215808962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cdefacc5f4e4292936ea9bd542e0a46c6c49905c",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Handwritten-Digit-Recognition:-Applications-of-Net-LeCun-Jackel",
            "title": {
                "fragments": [],
                "text": "Handwritten Digit Recognition: Applications of Neural Net Chips and Automatic Learning"
            },
            "venue": {
                "fragments": [],
                "text": "NATO Neurocomputing"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067137798"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 151887454,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6f8fbd0873eb98519d7047c13251aef32e769dfe",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "PhD-thesis:-Modeles-connexionnistes-de-learning-LeCun",
            "title": {
                "fragments": [],
                "text": "PhD thesis: Modeles connexionnistes de l'apprentissage (connectionist learning models)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 183
                            }
                        ],
                        "text": "Interestingly, the early derivations of back-propagation in the context of neural network learning did not use gradients, but \\virtual targets\" for units in intermediate layers [17], [18], or minimal disturbance arguments [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "Local connections have been used many times in neural models of visual learning [31], [32], [18], [33], [34], [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 64582816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56b771c4c3a54910dc3e7ff838940de89ed282db",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-processes-in-an-asymmetric-threshold-LeCun",
            "title": {
                "fragments": [],
                "text": "Learning processes in an asymmetric threshold network"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63077747,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d007ed936c51a700d8c65d1bbfae7acc83783c31",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Une-procedure-d'apprentissage-pour-reseau-a-seuil-LeCun",
            "title": {
                "fragments": [],
                "text": "Une procedure d'apprentissage pour reseau a seuil asymmetrique (A learning scheme for asymmetric threshold networks)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059901706"
                        ],
                        "name": "J. Glynn",
                        "slug": "J.-Glynn",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Glynn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Glynn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "This idea was described in the control theory literature of the early 1960\u2019s [16], but its application to machine learning was not generally realized then."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61275972,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "16b4fd36ff5ca603fed13a326054cd0373ea442c",
            "isKey": false,
            "numCitedBy": 5880,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Numerical-Recipes:-The-Art-of-Scientific-Computing-Glynn",
            "title": {
                "fragments": [],
                "text": "Numerical Recipes: The Art of Scientific Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62589537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d34e23ec879c3a69b55e16dc7bdc2ad112a2dfa2",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speech-recognition-with-continuous-parameter-hidden-Bahl-Brown",
            "title": {
                "fragments": [],
                "text": "Speech recognition with continuous-parameter hidden Markov models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 65
                            }
                        ],
                        "text": "A simple derivation for generic multilayer systems is given in Section I-E."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60745007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73ccd50a3fc04e2eb3628305902f7754b123430e",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-theoretical-framework-for-back-propagation-LeCun",
            "title": {
                "fragments": [],
                "text": "A theoretical framework for back-propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61002534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f19ca2336b8a7cc9344ffef5dbe3d3ff17954ab4",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-time-delay-neural-network-architecture-for-speech-Lang",
            "title": {
                "fragments": [],
                "text": "A time delay neural network architecture for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59861896,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01b6affe3ea4eae1978aec54e87087feb76d9215",
            "isKey": false,
            "numCitedBy": 862,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generalization-and-network-design-strategies-LeCun",
            "title": {
                "fragments": [],
                "text": "Generalization and network design strategies"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "108011249"
                        ],
                        "name": "Markus Schenke",
                        "slug": "Markus-Schenke",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Schenke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Schenke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Transducers have been applied to speech recognition [100] and language translation [101], and proposals have been made for handwriting recognition [102]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59841867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6cd1f4ff52485e4bc154033e7b139b640ca9e12",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "OVERVIEW-AND-SYNTHESIS-OF-ON-LINE-CURSIVE-Guyon-Schenke",
            "title": {
                "fragments": [],
                "text": "OVERVIEW AND SYNTHESIS OF ON-LINE CURSIVE HANDWRITING RECOGNITION TECHNIQUES"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "68983984"
                        ],
                        "name": "A. Weisbuch",
                        "slug": "A.-Weisbuch",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Weisbuch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Weisbuch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073469360"
                        ],
                        "name": "H. Weissman",
                        "slug": "H.-Weissman",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Weissman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Weissman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 180
                            }
                        ],
                        "text": "The cause of this problem is that in weight space the origin is a xed point of the learning dynamics, and, although it is a saddle point, it is attractive in almost all directions [116]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59641335,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c8a4f5358bde28333ab94076c935bc49c3ff26ea",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-line-handwriting-recognition-with-neural-Spatial-LeCun-Bengio",
            "title": {
                "fragments": [],
                "text": "On-line handwriting recognition with neural networks: Spatial representation versus temporal representation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50333420"
                        ],
                        "name": "S. Becker",
                        "slug": "S.-Becker",
                        "structuredName": {
                            "firstName": "Suzanna",
                            "lastName": "Becker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Becker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59695337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "589d377b23e2bdae7ad161b36a5d6613bcfccdde",
            "isKey": false,
            "numCitedBy": 411,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Improving-the-convergence-of-back-propagation-with-Becker-LeCun",
            "title": {
                "fragments": [],
                "text": "Improving the convergence of back-propagation learning with second-order methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689675"
                        ],
                        "name": "J. Meditch",
                        "slug": "J.-Meditch",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Meditch",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Meditch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 51664181,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "ec0ed6c4fba767af67e7e156faffe7ddc990a264",
            "isKey": false,
            "numCitedBy": 1241,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Applied-optimal-control-Meditch",
            "title": {
                "fragments": [],
                "text": "Applied optimal control"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Automatic Control"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10952304,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21bb294a68926e80ba58aa05a376d7c8840bdf92",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Time-delay-neural-networks-embedding-time-a-Haffner-Waibel",
            "title": {
                "fragments": [],
                "text": "Time-delay neural networks embedding time alignment: a performance analysis"
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45991146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5aee00262285c4a26ec77af355ab86cd2d92b403",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Connectionist-speech-recognition-with-a-global-MMI-Haffner",
            "title": {
                "fragments": [],
                "text": "Connectionist speech recognition with a global MMI algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729905"
                        ],
                        "name": "C. Tappert",
                        "slug": "C.-Tappert",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Tappert",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tappert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "78990360"
                        ],
                        "name": "Ching",
                        "slug": "Ching",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Ching",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ching"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2098563087"
                        ],
                        "name": "Suen",
                        "slug": "Suen",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Suen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3069541"
                        ],
                        "name": "T. Wakahara",
                        "slug": "T.-Wakahara",
                        "structuredName": {
                            "firstName": "Toru",
                            "lastName": "Wakahara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wakahara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14320206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "061b28bd6c5df228a87aaafaa6dc11915eb89510",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 287,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-State-of-the-Art-in-On-Line-Handwriting-Tappert-Ching",
            "title": {
                "fragments": [],
                "text": "The State of the Art in On-Line Handwriting Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9326933"
                        ],
                        "name": "Y. L. Cun",
                        "slug": "Y.-L.-Cun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Cun",
                            "middleNames": [
                                "le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. L. Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "Unfortunately, not only is this an extremely tedious and costly task, it is also difficult to do the labeling consistently."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16775098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d1f4d800a3a3bd0bf10839f9869f533e0d41c23",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Theoretical-Framework-for-Back-Propagation-Cun",
            "title": {
                "fragments": [],
                "text": "A Theoretical Framework for Back-Propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "This idea was described in the control theory literature of the early 1960\u2019s [16], but its application to machine learning was not generally realized then."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ho,Applied Optimal Control"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "Although the idea of SDNN is quite old, and very attractive by its simplicity, it has not generated wide interest until recently because as stated above it puts enormous demands on the recognizer [26], [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 189
                            }
                        ],
                        "text": "its ability to correctly recognize a well-centered character in its input eld, even in the presence of other characters besides it, while rejecting images containing no centered characters [26], [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Integrated seg-  mentation and recognition of hand-printed numerals,\" in Neu-  ral Information Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "Fixed-size Convolutional Networks have been applied to many applications, among other handwriting recognition [35], [36], machine-printed character recognition [37], on-line handwriting recognition [38], and face recognition [39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 162
                            }
                        ],
                        "text": "The LeNet1 architecture was developed using our own version of the USPS (US Postal Service zip codes) database and its size was tuned to match the available data [35]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handwritten digit recognition  with a back-propagation network,\" in Advances in Neural In-  formation Processing Systems 2 (NIPS*89)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eigenvalues of covariance matrices"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 95
                            }
                        ],
                        "text": "A di erent approach to graph-based trainable systems, called Input-Output HMM, was proposed in [104], [105]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An input/output HMM architec-  ture,\" in Advances in Neural Information Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving performance in neural"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vapnik, \\Comparison of learning algorithms for handwritten digit recognition"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Artiicial Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An EM algorithm for asynchronous"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 258
                            }
                        ],
                        "text": "Previous Work Numerous authors in speech recognition have used Gradient-Based Learning methods that integrate graphbased statistical models (notably HMM) with acoustic recognition modules, mainly Gaussian mixture models, but also neural networks [98], [78], [99], [67]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neu-  ral network - gaussian mixture hybrid for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information  Processing Systems 4,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural-net classiiers useful for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE First International Conference on Neural Networks"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Aubert, \\Combining TDNN and HMM in a hybrid system for improved continuous-speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Speech and Audio Processing"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Measuring the vc-dimension"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 59
                            }
                        ],
                        "text": "The transduction operation can be performed very e ciently [Mohri et al., 1997], but presents complex book-keeping problems concerning the handling of all combinations of null and non null symbols."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Weighted determinization and minimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 59
                            }
                        ],
                        "text": "The transduction operation can be performed very e ciently [106], but presents complex book-keeping problems concerning the handling of all combinations of null and non null symbols."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A rational design  for a weighted nite-state transducer library, Lecture Notes in  Computer Science"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Measuring the vc-dimension"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 261
                            }
                        ],
                        "text": "On the other hand, if the probabilistic assumptions in an HMM (or other probabilistic model) are not realistic, discriminative training, discussed in Section VII, can improve performance as this has been clearly shown for speech recognition systems [48], [49], [50], [107], [108]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 224
                            }
                        ],
                        "text": "Such a competition can be obtained by using a more discriminative training criterion, dubbed the MAP (maximum a posteriori) criterion, similar to Maximum Mutual Information criterion sometimes used to train HMMs [48], [49], [50]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminative learning for min-  imum error classi cation,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Acoustics, Speech,  and Signal Processing,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[60] developed the \\boosting\" method for combining multiple classi ers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving perfor-  mance in neural networks using a boosting"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Information Processing Systems 5,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 113
                            }
                        ],
                        "text": "In the case of character recognition, a network could be fed with almost raw inputs (e.g., size-normalized images)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Receptive elds, binocular interaction, and functional architecture in the cat's visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Physiology"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "In speech recognition, where the recognizer is at least one order of magnitude smaller, replicated convolutional networks are easier to implement, for instance in Ha ner's Multi-State TDNN model [78], [85]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist ar-  chitectural learning for high performance character and speech  recognition,"
            },
            "venue": {
                "fragments": [],
                "text": "in International Conference on Acoustics, Speech,  and Signal Processing, Minneapolis,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bridle, \\Alphanets: a recurrentrecurrent`neural' network architecture with a hidden markov model interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Communication"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "Several authors have proposed such methods to train NN/HMM speech recognizers at the word or sentence level [29], [67], [71]\u2013[78]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "Similar algorithms have been applied to speech recognition systems that integrate NN\u2019s with time alignment [71], [72], [76] or hybrid neuralnetwork/HMM systems [29], [74], [75]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural-net classifiers useful for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE 1st Int. Conf. Neural Networks"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lerec: A NN/HMM hybrid"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 73
                            }
                        ],
                        "text": "This line of work has been mainly focused on efficient search algorithms [103] and on the algebraic aspects of combining transducers and graphs (called acceptors in this context), but very little effort has been devoted to building globally trainable systems out of transducers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Weighted determinization and minimization for large vocabulary recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Eurospeech '97"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 73
                            }
                        ],
                        "text": "This line of work has been mainly focused on efficient search algorithms [103] and on the algebraic aspects of combining transducers and graphs (called acceptors in this context), but very little effort has been devoted to building globally trainable systems out of transducers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Weighted determinization and minimization for large vocabulary recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Eurospeech '97"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Said, \\Automatic processing of information on checks"
            },
            "venue": {
                "fragments": [],
                "text": "Int. Conf. on Systems"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "They show that NN\u2019s trained with gradient-based learning perform better than all other methods tested here on the same data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning in random nets"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 4th London Symp. Information Theory"
            },
            "year": 1961
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "4) RBF Network: Following [55], an RBF network was constructed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handwritten digit recognition using k-nearest neighbor , radial-basis functions, and backpropagation neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "Globally trained, variable-size TDNN/HMM hybrids have been used for speech recognition and on-line handwriting recognition [77], [89], [90], [67]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hender-  son, \\Recognition-based segmentation of on-line hand-printed  words,\" in Advances in Neural Information Processing Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combining TDNN and HMM"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "Another approach would consists of directly minimizing an approximation of the number of misclassi cations [83] [76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Une Approche th  eorique de l'Apprentissage Connex-  ionniste: Applications a la Reconnaissance de la Parole"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D.  thesis, Universit  e de Paris XI,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "Other authors have used NN\u2019s or other classifiers such as SVM\u2019s for face detection with great success [96], [97]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural network-based 2322  PROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998  face detection"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE CVPR\u201996, pp. 203\u2013208."
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Authors Biographies Yann LeCun"
            },
            "venue": {
                "fragments": [],
                "text": "Authors Biographies Yann LeCun"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving the convergence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Authors Biographies Yann LeCun"
            },
            "venue": {
                "fragments": [],
                "text": "Authors Biographies Yann LeCun"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "OO line recognition of handwritten postal words using neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "689. Special Issue on Applications of Neural Networks to Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Training support vector machines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "speech recognition systems, including Bridle and his -net model [73] and Ha ner and his -TDNN model [81], but these authors recommended discriminative training as described in the next section."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ner, \\Connectionist speech recognition with a global  MMI algorithm,\" in EUROSPEECH'93, 3rd European Confer-  ence on Speech Communication and Technology, Berlin, Sept"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "First- and second-order methods for learning: Be-  tween steepest descent and newton's method.,"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Com-  putation,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handwritten digit recognition: Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Srihari, \\High-performance reading machines"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE, Special issue on Optical Character Recognition"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Following [82], we therefore prefer to postpone normalization as far as possible (in fact, until the nal decision stage of the system)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "This local normalization of penalties may eliminate information that is important for locally rejecting all the classes [82], e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image segmentation and recog-  nition,\" in The Mathematics of Induction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Output HMMs for sequence processing"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A connectionist recognizer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A connectionist recognizer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Une Approche th\u00e9orique de l'Apprentissage Connexionniste: ApplicationsApplications`Applications\u00e0 la Reconnaissance de la Parole"
            },
            "venue": {
                "fragments": [],
                "text": "Une Approche th\u00e9orique de l'Apprentissage Connexionniste: ApplicationsApplications`Applications\u00e0 la Reconnaissance de la Parole"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "For our simulations, we use A = 1:7159 and S = 2 3 (see [20], [34])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "The Lagrange formalism used in the control theory literature provides perhaps the best rigorous method for deriving back-propagation [20], and for deriving generalizations of back-propagation to recurrent networks [21], and networks of heterogeneous modules [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "A completely rigorous derivation in more general cases can be done using Lagrange functions [20], [21], [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mod  eles connexionnistes de l'apprentissage (con-  nectionist learning models)"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. thesis, Universit  e P. et M.  Curie (Paris"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A learning algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "construction of quadratic polynomial classiiers"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of International Conference on Pattern Recognition"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminative feature and model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Time-delay neural networks embedding"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Neural-net classiiers useful for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE First International Conference on Neural Networks"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "4 Radial Basis Function Network Following [55], an RBF network was constructed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handwritten digit recognition using k-nearest neigh-  bor, radial-basis functions, and backpropagation neural net-  works,"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 58
                            }
                        ],
                        "text": "One of the most important ones is called \\hit and de ect\" [115]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "O line recognition of handwritten postal words using  neural networks,\" Int"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Pattern Recognition and Ar-  ti cial Intelligence,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 204
                            }
                        ],
                        "text": "Because the origin of weight space is a saddle point that is attractive in almost every direction, the weights invariably shrink during the rst few epochs (recent theoretical analysis seem to con rm this [56])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamics of on-line gradient de-  scent learning for multilayer neural networks,\" in Advances"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Information Processing Systems,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "Segmentation Graph A now-classical method for word segmentation and recognition is called Heuristic Over-Segmentation [68], [69]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A system for the o -line recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 253
                            }
                        ],
                        "text": "The idea of connecting units to local receptive elds on the input goes back to the Perceptron in the early 60s, and was almost simultaneous with Hubel and Wiesel's discovery of locally-sensitive, orientation-selective neurons in the cat's visual system [30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Receptive elds, binocular  interaction, and functional architecture in the cat's visual cor-  tex,"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Physiology (London),"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Neural networkbased face detection"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of CVPR'96"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mod eles connexionnistes de l'apprentissage (connectionist learning models)"
            },
            "venue": {
                "fragments": [],
                "text": "Mod eles connexionnistes de l'apprentissage (connectionist learning models)"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminative learning for minimum"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "Much theoretical and experimental work [3], [4], [5] has shown that the gap between the expected error rate on the test set Etest and the error rate on the training set Etrain decreases with the number of training samples approximately as Etest Etrain = k(h=P ) (1) where P is the number of training samples, h is a measure of \\e ective capacity\" or complexity of the machine [6], [7], is a number between 0:5 and 1:0, and k is a constant."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical mechan-  ics of learning from examples,"
            },
            "venue": {
                "fragments": [],
                "text": "Physical Review A,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Une Approche th eorique de l'Apprentissage Connexionniste: Applications a la Reconnaissance de la Parole"
            },
            "venue": {
                "fragments": [],
                "text": "Une Approche th eorique de l'Apprentissage Connexionniste: Applications a la Reconnaissance de la Parole"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 71
                            }
                        ],
                        "text": "This line of work has been mainly focused on e cient search algorithms [103] and on the algebraic aspects of combining transducers and graphs (called acceptors in this context), but very little e ort has been devoted to building globally trainable systems out of transducers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Weighted determinization and min-  imization for large vocabulary recognition,\" in Proceedings of  Eurospeech"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wiesel, \\Receptive elds, binocular interaction, and functional architecture in the cat's visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Physiology"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vapnik, \\Local learning algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "Other modules include convolutional layers, sub-sampling layers, RBF layers, and \\softmax\" layers [65]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic interpretation of feedforward classi -  cation networks outputs, with relationship to statistical pattern  recognition,\" in Neurocomputing, Algorithms, Architectures  and Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 113
                            }
                        ],
                        "text": "As a consequence, there is a very high interest in automating the process as much as possible (see, for example, [112]\u2013[114])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition of cursive script amounts on postal checks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Europ. Conf. Postal Technol"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 134
                            }
                        ],
                        "text": "The recognition of handwritten characters from a pen trajectory on a digitizing surface is often done in the time domain [110], [44], [111]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 120
                            }
                        ],
                        "text": "The recognition may then be performed using curve matching [110], or other classi cation techniques such as TDNNs [44], [111]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bodenhausen, \\A connectionist recognizer for  on-line cursive handwriting recognition,\" in International Con-  ference on Acoustics, Speech, and Signal Processing, Adelaide"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "Modules in a GTN communicate their states and gradients in the form of directed graphs whose arcs carry numerical information (scalars or vectors) [66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reading checks with  graph transformer networks,\" in International Conference on  Acoustics"
            },
            "venue": {
                "fragments": [],
                "text": "Speech, and Signal Processing,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "Experiments in speech recognition with hybrids of NN\u2019s and HMM\u2019s also showed marked improvements brought by global training [29], [67], [77], [84]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Disriminative feature and model design for automatic speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Eurospeech"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "Another approach would consists of directly minimizing an approximation of the number of misclassifications [83], [76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approche th \u0301 eorique de l\u2019Apprentissage Connexionniste: Applications `  a la Reconnaissance de la Parole"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. dissertation, Univ. Paris XI, France,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 213
                            }
                        ],
                        "text": "Such a competition can be obtained by using a more discriminative training criterion, dubbed the maximuma posteriori(MAP) criterion, similar to maximum mutual information criterion sometimes used to train HMM\u2019s [48]\u2013[50]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum mutual information of hidden Markov model parameters for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Conf. Acoustics, Speech, Signal Processing"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Input/Output HMMs for sequence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Alphanets: a recurrentrecurrent`neural' network architecture with a hidden markov model interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "J. S. Speech Communication"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "During his time at the Universit\u00e9 Pierre et Marie Curie, he proposed an early version of the back-propagation learning algorithm for neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Yann LeCun (Member, IEEE) received the Dipl\u00f4me d'Ing\u00e9nieur degree from the Ecole 1983 and the Ph.D. degree in computer science from the Universit\u00e9 Pierre et Marie Curie 1988, he joined the Adaptive Systems Research Department at AT&T Bell Laboratories, Holmdel, NJ, where he worked on neural networks"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A multi-font word recognition system for postal address"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Convolutional networks force the extraction of local features by restricting the receptive fields of hidden units to be local."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Signature veriication using a siamese time delay neural network"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Pattern Recognition and Artiicial Intelligence"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neocognitron: A new algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural network-based face"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 177
                            }
                        ],
                        "text": "Interestingly, the early derivations of back-propagation in the context of neural network learning did not use gradients, but \\virtual targets\" for units in intermediate layers [17], [18], or minimal disturbance arguments [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A learning scheme for asymmetric threshold net-  works,"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Cognitiva"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "Learning in Real Handwriting Recognition Systems Isolated handwritten character recognition has been extensively studied in the literature (see [23], [24] for reviews), and was one of the early successful applications of neural"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "High-performance reading machines,\" Proceed-  ings of the IEEE"
            },
            "venue": {
                "fragments": [],
                "text": "Special issue on Optical Character Recogni-  tion,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Weighted rational transductions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "LeCun, \\Discriminative feature and model design for automatic speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Eurospeech '97"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 111
                            }
                        ],
                        "text": "As a consequence, there is a very high interest in automating the process as much as possible (see for example [112], [113], [114])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition of cursive script  amounts on postal checks,\" in European Conference dedicated  to Postal Technologies"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "43 handwritten zip code recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Jackel, \\Backpropagation applied to SUBMITTED TO PROCEEDINGS OF THE IEEE Neural Computation"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Waibel, \\Multi-state time-delay neural networks for continuous speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cursive script recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "EEcient Training of Feed-Forward Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "EEcient Training of Feed-Forward Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "Several authors have proposed such methods to train neural network/HMM speech recognizers at the word or sentence level [71], [72], [73], [74], [75], [76], [77], [78], [29], [67]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "Similar algorithms have been applied to speech recognition systems that integrate neural networks with time alignment [71], [72], [76] or hybrid neural-network/HMM systems [29], [74], [75]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Watan-  abe, \\Speaker-independent word recognition using dynamic  programming neural networks,\" in International Conference  on Acoustics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 29
                            }
                        ],
                        "text": "The input\u2013output HMM (IOHMM) [105], [109] is strongly related to GT\u2019s."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 106
                            }
                        ],
                        "text": "A different approach to graph-based trainable systems, called input\u2013output HMM, was proposed in [104] and [105]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Input/output HMM's for sequence processing"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 222
                            }
                        ],
                        "text": "TDNNs have been used in phoneme recognition (without sub-sampling) [40], [41], spoken word recognition (with sub-sampling) [42], [43], on-line recognition of isolated handwritten characters [44], and signature veri cation [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Signature veri ca-  tion using a siamese time delay neural network,"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Pattern Recognition and Arti cial Intelligence,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast neural net simulation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Waibel, \\Connectionist viterbi training: a new hybrid method for continuous speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "3) PCA and Polynomial Classifier:Following [53] and [54], a preprocessing stage was constructed which computes the projection of the input pattern on the 40 principal components of the set of training vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 78
                            }
                        ],
                        "text": "LECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION 2289\n3) PCA and Polynomial Classifier:Following [53] and [54], a preprocessing stage was constructed which computes the projection of the input pattern on the 40 principal components of the set of training vectors."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Construction of quadratic polynomial classifiers"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Int. Conf. Pattern Recognition"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Solla, \\Dynamics of on-line gradient descent learning for multilayer neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discriminative utterance veri "
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural network-based 2322 NOVEMBER 1998 face detection"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE CVPR'96"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A framework for the cooperation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "This can be seen as a generalization of the Learning Vector Quantization 2 (LVQ-2) loss function [80]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical pattern recognition with neural network: Benchmarking studies"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE 2nd Int. Conf. Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural-net classi ers useful for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Integrated segmentation and"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "Modules in a GTN communicate their states and gradients in the form of directed graphs whose arcs carry numerical information (scalars or vectors) [66]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reading checks with graph transformer networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Int. Conf. Acoustics , Speech, Signal Processing"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "A simple improvement of the basic linear classi er was tested [52]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparing di erent neural net architectures for  classifying handwritten digits,\" in Proc. of IJCNN, Washing-  ton DC"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Burges, \\Image segmentation and recognition"
            },
            "venue": {
                "fragments": [],
                "text": "The Mathematics of Induction"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E cient par-  allel learning algorithms for neural networks,\" in Advances"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Information Processing Systems,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Measuring the vcdimension of a learning machine"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sch urmann, \\A multi-font word recognition system for postal address reading"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Yoshua Bengio"
            },
            "venue": {
                "fragments": [],
                "text": "Yoshua Bengio"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "He received the Ph.D degree in speech and signal processing from ENST in 1994"
            },
            "venue": {
                "fragments": [],
                "text": "Patrick Haffner graduated from Ecole Polytechnique 1987 and from Ecole Nationale Sup\u00e9rieure des T\u00e9l\u00e9communications (ENST) he worked on the design of the TDNN and the MS-TDNN architectures at ATR (Japan) and Carnegie Mellon University"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition of cursive script amounts"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "Fixed-size Convolutional Networks have been applied to many applications, among other handwriting recognition [35], [36], machine-printed character recognition [37], on-line handwriting recognition [38], and face recognition [39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multi-resolution neural networks for om-  nifont character"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International  Conference on Neural Networks,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "Several authors have proposed such methods to train neural network/HMM speech recognizers at the word or sentence level [71], [72], [73], [74], [75], [76], [77], [78], [29], [67]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 184
                            }
                        ],
                        "text": "Similar algorithms have been applied to speech recognition systems that integrate neural networks with time alignment [71], [72], [76] or hybrid neural-network/HMM systems [29], [74], [75]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combining hidden markov  models and neural network classi ers,\" in International Con-  ference on Acoustics, Speech, and Signal Processing, Albu"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 147
                            }
                        ],
                        "text": "Transducers have been applied to speech recognition [100] and language translation [101], and proposals have been made for handwriting recognition [102]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Overview and syn-  thesis of on-line cursive handwriting recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Handbook on Optical Character Recognition and Document  Image Analysis,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "An early subset of these results was presented in [51]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparison of learning al-  gorithms for handwritten digit recognition,"
            },
            "venue": {
                "fragments": [],
                "text": "in International  Conference on Arti cial Neural Networks,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reading checks with graph"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "3 Principal Component Analysis and Polynomial Classi er Following [53], [54], a preprocessing stage was constructed which computes the projection of the input pattern on the 40 principal components of the set of training vectors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "urmann, \\A multi-font word recognition system for postal  address reading,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions,"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Solving multiclass learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Juang, \\Discriminative utterance veriication for connected digits recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Speech & Audio Proc"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speech recognition by composition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Schapire, \\The strength of weak learnability"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 52
                            }
                        ],
                        "text": "Transducers have been applied to speech recognition [100] and language translation [101], and proposals have been made for handwriting recognition [102]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speech recognition by compo-  sition of weighted nite automata,\" in Finite-State Devices for  Natural Langue Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combining hidden markov models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Training of Feed-Forward Neural Net-  works, Ph.D"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "Local connections have been used many times in neural models of visual learning [31], [32], [18], [33], [34], [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The perception of multiple objects: A connec-  tionist approach, MIT Press-Bradford Books"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 75,
            "methodology": 70,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 250,
        "totalPages": 25
    },
    "page_url": "https://www.semanticscholar.org/paper/Gradient-based-learning-applied-to-document-LeCun-Bottou/162d958ff885f1462aeda91cd72582323fd6a1f4?sort=total-citations"
}