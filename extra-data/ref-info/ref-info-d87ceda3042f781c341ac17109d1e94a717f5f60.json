{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746656"
                        ],
                        "name": "E. Voorhees",
                        "slug": "E.-Voorhees",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Voorhees",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Voorhees"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 350665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59407446503d49a8cf5f5643b17502835b62f139",
            "isKey": false,
            "numCitedBy": 582,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an automatic indexing procedure that uses the \u201cIS-A\u201d relations contained within WordNet and the set of nouns contained in a text to select a sense for each plysemous noun in the text. The result of the indexing procedure is a vector in which some of the terms represent word senses instead of word stems. Retrieval experiments comparing the effectivenss of these sense-based vectors vs. stem-based vectors show the stem-based vectors to be superior overall, although the sense-based vectors do improve the performance of some queries. The overall degradation is due in large part to the difficulty of disambiguating senses in short query statements. An analysis of these results suggests two conclusions: the IS-A links define a generalization/specialization hierarchy that is not sufficient to reliably select the correct sense of a noun from the set of fine sense distinctions in WordNet; and missing correct matches because of incorrect sense resolution has a much more deleterious effect on retrieval performance than does making spurious matches."
            },
            "slug": "Using-WordNet-to-disambiguate-word-senses-for-text-Voorhees",
            "title": {
                "fragments": [],
                "text": "Using WordNet to disambiguate word senses for text retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The IS-A links define a generalization/specialization hierarchy that is not sufficient to reliably select the correct sense of a noun from the set of fine sense distinctions in WordNet; and missing correct matches because of incorrect sense resolution has a much more deleterious effect on retrieval performance than does making spurious matches."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118077301"
                        ],
                        "name": "Jane Morris",
                        "slug": "Jane-Morris",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Morris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jane Morris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145036961"
                        ],
                        "name": "Graeme Hirst",
                        "slug": "Graeme-Hirst",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Hirst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graeme Hirst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 54
                            }
                        ],
                        "text": "The basic idea in this chapter is the same as that of Morris and Hirst (1991), which used Roget's Thesaurus instead of WordNet."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10970495,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "ca40dc1300ab085406455894dd42fd02f9cc36f8",
            "isKey": false,
            "numCitedBy": 1091,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In text, lexical cohesion is the result of chains of related words that contribute to the continuity of lexical meaning. These lexical chains are a direct result of units of text being \"about the same thing,\" and finding text structure involves finding units of text that are about the same thing. Hence, computing the chains is useful, since they will have a correspondence to the structure of the text. Determining the structure of text is an essential step in determining the deep meaning of the text. In this paper, a thesaurus is used as the major knowledge base for computing lexical chains. Correspondences between lexical chains and structural elements are shown to exist. Since the lexical chains are computable, and exist in non-domain-specific text, they provide a valuable indicator of text structure. The lexical chains also provide a semantic context for interpreting words, concepts, and sentences."
            },
            "slug": "Lexical-Cohesion-Computed-by-Thesaural-Relations-as-Morris-Hirst",
            "title": {
                "fragments": [],
                "text": "Lexical Cohesion Computed by Thesaural Relations as an Indicator of the Structure of Text"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Since the lexical chains are computable, and exist in non-domain-specific text, they provide a valuable indicator of text structure, and provide a semantic context for interpreting words, concepts, and sentences."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66511259"
                        ],
                        "name": "R. Beckwith",
                        "slug": "R.-Beckwith",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Beckwith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Beckwith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145386345"
                        ],
                        "name": "Derek Gross",
                        "slug": "Derek-Gross",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113623689"
                        ],
                        "name": "K. Miller",
                        "slug": "K.-Miller",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Miller",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2146137,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4bd970a37c59c97804ff93cbb2c108e081de3a37",
            "isKey": false,
            "numCitedBy": 5333,
            "numCiting": 133,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list. Unfortunately, there is no obvious alternative, no other simple way for lexicographers to keep track of what has been done or for readers to find the word they are looking for. But a frequent objection to this solution is that finding things on an alphabetical list can be tedious and time-consuming. Many people who would like to refer to a dictionary decide not to bother with it because finding the information would interrupt their work and break their train of thought."
            },
            "slug": "Introduction-to-WordNet:-An-On-line-Lexical-Miller-Beckwith",
            "title": {
                "fragments": [],
                "text": "Introduction to WordNet: An On-line Lexical Database"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 124142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7b27f149f4a946a7c04fb208c7d8dbf7fa8f34b",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe here the theory behind the language comprehension program Wimp. Wimp understands by first finding paths between the open-class words in a sentence using a marker passing, or spreading-activation, technique. This paper is primarily concerned with the \"meaning\" (or interpretation) of such paths. We argue that they are best thought of as backbones of proofs that the terms (words) at either end of the paths exist in the story and show how viewing paths in this way naturally leads to the kinds of inferences which are normally thought to characterize \"understanding.\" In a companion paper we show how this interpretation also accomplishes much of the work normally expected in the parsing of language (noun-phrase reference, word-sense disambiguation, etc) so we only briefly touch on this topic here. Wimp has been implemented and works on all of the examples herein."
            },
            "slug": "A-Neat-Theory-of-Marker-Passing-Charniak",
            "title": {
                "fragments": [],
                "text": "A Neat Theory of Marker Passing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued that paths found between open-class words in a sentence are best thought of as backbones of proofs that the terms at either end of the paths exist in the story and shown how viewing paths in this way naturally leads to the kinds of inferences which are normally thought to characterize \"understanding\"."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784519"
                        ],
                        "name": "Peter Norvig",
                        "slug": "Peter-Norvig",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Norvig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Norvig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 66
                            }
                        ],
                        "text": "A marker-passing algorithm similar to that of Charniak (1986) and Norvig (1989) was employed to make \"text inferences.\""
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16210282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71f6f2fb5fa836e99da7998bd9ea78fa2201a945",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of deciding what is implied by a written text, of \u201creading between the lines\u201d is the problem of text inference. To extract proper inferences from a text requires a great deal of general knowledge on the part of the reader. Past approaches have often used a \u201cstrong method\u201d tuned to process a particular kind of knowledge structure (such as a script, or a plan). The alternative is a \u201cweak method\u201d which is applicable to a variety of knowledge structures. Just such a method is proposed here, one which recognizes six very general classes of inference. These classes are not dependent on individual knowledge structures, but instead rely on patterns of connectivity between concepts. Patterns are discovered, and inferences are suggested, by a process of marker passing between concepts."
            },
            "slug": "Marker-Passing-as-a-Weak-Method-for-Text-Norvig",
            "title": {
                "fragments": [],
                "text": "Marker Passing as a Weak Method for Text Inferencing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A method is proposed here, one which recognizes six very general classes of inference, which are not dependent on individual knowledge structures, but instead rely on patterns of connectivity between concepts."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 108
                            }
                        ],
                        "text": "As a description of the software, however, papers in Part I are not as systematic and organized as those of Miller (1990) (which are included in the WordNet software distribution at http://www.cogsci.princeton.edu/~wn/)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 91
                            }
                        ],
                        "text": "The description of the information contained in WordNet, however, is not as detailed as in Miller (1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 68
                            }
                        ],
                        "text": "These chapters are essentially updated versions of four papers from Miller (1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "WordNet: An on-line lexical database. Special issue of"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Lexicography"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70055855"
                        ],
                        "name": "Barbara B. Levin",
                        "slug": "Barbara-B.-Levin",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Levin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barbara B. Levin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59862914,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "1b4f35e5298fc199eeb54b64dd5ee71565eb4d0d",
            "isKey": false,
            "numCitedBy": 961,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "English-verb-classes-and-alternations-Levin",
            "title": {
                "fragments": [],
                "text": "English verb classes and alternations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "His research interests include principle-based broad-coverage parsing, information extraction, word sense disambiguation, and learning from parsed corpora. Lin's address is"
            },
            "venue": {
                "fragments": [],
                "text": "His research interests include principle-based broad-coverage parsing, information extraction, word sense disambiguation, and learning from parsed corpora. Lin's address is"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 8,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/WordNet-:-an-electronic-lexical-database-Fellbaum/d87ceda3042f781c341ac17109d1e94a717f5f60?sort=total-citations"
}