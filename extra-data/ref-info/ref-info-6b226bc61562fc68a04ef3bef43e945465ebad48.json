{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1988453"
                        ],
                        "name": "R. Bekkerman",
                        "slug": "R.-Bekkerman",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Bekkerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bekkerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219900"
                        ],
                        "name": "Gary B. Huang",
                        "slug": "Gary-B.-Huang",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Huang",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gary B. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8536512,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e0e053244d642896ba2efda1c350d74625f6a52",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Office workers everywhere are drowning in email\u2014not only spam, but also large quantities of legitimate email to be read and organized for browsing. Although there have been extensive investigations of automatic document categorization, email gives rise to a number of unique challenges, and there has been relatively little study of classifying email into folders. This paper presents an extensive benchmark study of email foldering using two large corpora of real-world email messages and foldering schemes: one from former Enron employees, another from participants in an SRI research project. We discuss the challenges that arise from differences between email foldering and traditional document classification. We show experimental results from an array of automated classification methods and evaluation methodologies, including a new evaluation method of foldering results based on the email timeline, and including enhancements to the exponential gradient method Winnow, providing top-tier accuracy with a fraction the training time of alternative methods. We also establish that classification accuracy in many cases is relatively low, confirming the challenges of email data, and pointing toward email foldering as an important area for further research."
            },
            "slug": "Automatic-Categorization-of-Email-into-Folders:-on-Bekkerman-McCallum",
            "title": {
                "fragments": [],
                "text": "Automatic Categorization of Email into Folders: Benchmark Experiments on Enron and SRI Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An extensive benchmark study of email foldering using two large corpora of real-world email messages and foldering schemes: one from former Enron employees, another from participants in an SRI research project."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9440777"
                        ],
                        "name": "Dotan Di Castro",
                        "slug": "Dotan-Di-Castro",
                        "structuredName": {
                            "firstName": "Dotan",
                            "lastName": "Castro",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dotan Di Castro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3386660"
                        ],
                        "name": "Zohar S. Karnin",
                        "slug": "Zohar-S.-Karnin",
                        "structuredName": {
                            "firstName": "Zohar",
                            "lastName": "Karnin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zohar S. Karnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402943721"
                        ],
                        "name": "L. Lewin-Eytan",
                        "slug": "L.-Lewin-Eytan",
                        "structuredName": {
                            "firstName": "Liane",
                            "lastName": "Lewin-Eytan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lewin-Eytan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781257"
                        ],
                        "name": "Y. Maarek",
                        "slug": "Y.-Maarek",
                        "structuredName": {
                            "firstName": "Yoelle",
                            "lastName": "Maarek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Maarek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "This includes foldering [19], automatic prioritization [15], and even information extraction [2, 14, 41]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1518997,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b65ba3f48199a938926816c124912b01bc7cee54",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "With email traffic increasing, leading Web mail services have started to offer features that assist users in reading and processing their inboxes. One approach is to identify \"important\" messages, while a complementary one is to bundle messages, especially machine-generated ones, in pre-defined categories. We rather propose here to go back to the task at hand and consider what actions the users might conduct on received messages. We thoroughly studied, in a privacy-preserving manner, the actions of a large number of users in Yahoo mail, and found out that the most frequent actions are typically read, reply, delete and a sub-type of delete, delete-without-read. We devised a learning framework for predicting these four actions, for users with various levels of activity per action. Our framework leverages both vertical learning for personalization and horizontal learning for regularization purposes. In order to verify the quality of our predictions, we conducted a large-scale experiment involving users who had previously agreed to participate in such research studies. Our results show that, for recall values of 90%, we can predict important actions such as read or reply at precision levels up to 40% for active users, which we consider pretty encouraging for an assistance task. For less active users, we show that our regularization achieves an increase in AUC of close to 50%. To the best of our knowledge, our work is the first to provide a unified framework of this scale for predicting multiple actions on Web email, which hopefully provides a new ground for inventing new user experiences to help users process their inboxes."
            },
            "slug": "You've-got-Mail,-and-Here-is-What-you-Could-do-With-Castro-Karnin",
            "title": {
                "fragments": [],
                "text": "You've got Mail, and Here is What you Could do With It!: Analyzing and Predicting Actions on Email Messages"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work is the first to provide a unified framework of this scale for predicting multiple actions on Web email, which hopefully provides a new ground for inventing new user experiences to help users process their inboxes."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2709906"
                        ],
                        "name": "Mihajlo Grbovic",
                        "slug": "Mihajlo-Grbovic",
                        "structuredName": {
                            "firstName": "Mihajlo",
                            "lastName": "Grbovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mihajlo Grbovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2906220"
                        ],
                        "name": "Guy Halawi",
                        "slug": "Guy-Halawi",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Halawi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guy Halawi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3386660"
                        ],
                        "name": "Zohar S. Karnin",
                        "slug": "Zohar-S.-Karnin",
                        "structuredName": {
                            "firstName": "Zohar",
                            "lastName": "Karnin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zohar S. Karnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781257"
                        ],
                        "name": "Y. Maarek",
                        "slug": "Y.-Maarek",
                        "structuredName": {
                            "firstName": "Yoelle",
                            "lastName": "Maarek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Maarek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 89
                            }
                        ],
                        "text": "extraction, email classifiers are useful for other applications like automatic foldering [6, 19], spam classification [13], and message priority ranking [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "This includes foldering [19], automatic prioritization [15], and even information extraction [2, 14, 41]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 53245098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de3ea6e706e56309b4b85942b52ed0002cacb870",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Email classification is still a mostly manual task. Consequently, most Web mail users never define a single folder. Recently however, automatic classification offering the same categories to all users has started to appear in some Web mail clients, such as AOL or Gmail. We adopt this approach, rather than previous (unsuccessful) personalized approaches because of the change in the nature of consumer email traffic, which is now dominated by (non-spam) machine-generated email. We propose here a novel approach for (1) automatically distinguishing between personal and machine-generated email and (2) classifying messages into latent categories, without requiring users to have defined any folder. We report how we have discovered that a set of 6 \"latent\" categories (one for human- and the others for machine-generated messages) can explain a significant portion of email traffic. We describe in details the steps involved in building a Web-scale email categorization system, from the collection of ground-truth labels, the selection of features to the training of models. Experimental evaluation was performed on more than 500 billion messages received during a period of six months by users of Yahoo mail service, who elected to be part of such research studies. Our system achieved precision and recall rates close to 90% and the latent categories we discovered were shown to cover 70% of both email traffic and email search queries. We believe that these results pave the way for a change of approach in the Web mail industry, and could support the invention of new large-scale email discovery paradigms that had not been possible before."
            },
            "slug": "How-Many-Folders-Do-You-Really-Need:-Classifying-a-Grbovic-Halawi",
            "title": {
                "fragments": [],
                "text": "How Many Folders Do You Really Need?: Classifying Email into a Handful of Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes here a novel approach for automatically distinguishing between personal and machine-generated email and classifying messages into latent categories, without requiring users to have defined any folder, and believes that these results pave the way for a change of approach in the Web mail industry."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9440777"
                        ],
                        "name": "Dotan Di Castro",
                        "slug": "Dotan-Di-Castro",
                        "structuredName": {
                            "firstName": "Dotan",
                            "lastName": "Castro",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dotan Di Castro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703978"
                        ],
                        "name": "Iftah Gamzu",
                        "slug": "Iftah-Gamzu",
                        "structuredName": {
                            "firstName": "Iftah",
                            "lastName": "Gamzu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iftah Gamzu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405652973"
                        ],
                        "name": "Irena Grabovitch-Zuyev",
                        "slug": "Irena-Grabovitch-Zuyev",
                        "structuredName": {
                            "firstName": "Irena",
                            "lastName": "Grabovitch-Zuyev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irena Grabovitch-Zuyev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402943721"
                        ],
                        "name": "L. Lewin-Eytan",
                        "slug": "L.-Lewin-Eytan",
                        "structuredName": {
                            "firstName": "Liane",
                            "lastName": "Lewin-Eytan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lewin-Eytan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1414140637"
                        ],
                        "name": "Abhinav Pundir",
                        "slug": "Abhinav-Pundir",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Pundir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhinav Pundir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135787639"
                        ],
                        "name": "Nil Ratan Sahoo",
                        "slug": "Nil-Ratan-Sahoo",
                        "structuredName": {
                            "firstName": "Nil",
                            "lastName": "Sahoo",
                            "middleNames": [
                                "Ratan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nil Ratan Sahoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2101186"
                        ],
                        "name": "Michael Viderman",
                        "slug": "Michael-Viderman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Viderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Viderman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 94
                            }
                        ],
                        "text": "Learning good email representations has been an area of interest for multiple research groups [2, 14, 41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 93
                            }
                        ],
                        "text": "This includes foldering [19], automatic prioritization [15], and even information extraction [2, 14, 41]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 46
                            }
                        ],
                        "text": "used to power several intelligent experiences [14, 41]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13812725,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87da7a07bb1542f3bd32f5b803976ce396c96cb1",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Mail extraction is a critical task whose objective is to extract valuable data from the content of mail messages. This task is key for many types of applications including re-targeting, mail search, and mail summarization, which utilize the important personal data pieces in mail messages to achieve their objectives. We focus on machine generated traffic, which comprises most of the Web mail traffic today, and use its structured and large-scale repetitive nature to devise a fully automated extraction method. Our solution builds on an advanced structural clustering technique previously presented by some of the authors of this work. The heart of our solution is an offline process that leverages the structural mail-specific characteristics of the clustering, and automatically creates extraction rules that are later applied online for each new arriving message. We provide of a full description of our process, which has been productized in Yahoo mail backend. We complete our work with large-scale experiments carried over real Yahoo mail traffic, and evaluate the performance of our automatic extraction method."
            },
            "slug": "Automated-Extractions-for-Machine-Generated-Mail-Castro-Gamzu",
            "title": {
                "fragments": [],
                "text": "Automated Extractions for Machine Generated Mail"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The heart of the solution is an offline process that leverages the structural mail-specific characteristics of the clustering, and automatically creates extraction rules that are later applied online for each new arriving message."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405623777"
                        ],
                        "name": "Noa Avigdor-Elgrabli",
                        "slug": "Noa-Avigdor-Elgrabli",
                        "structuredName": {
                            "firstName": "Noa",
                            "lastName": "Avigdor-Elgrabli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noa Avigdor-Elgrabli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1413949481"
                        ],
                        "name": "Mark Cwalinski",
                        "slug": "Mark-Cwalinski",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Cwalinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Cwalinski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9440777"
                        ],
                        "name": "Dotan Di Castro",
                        "slug": "Dotan-Di-Castro",
                        "structuredName": {
                            "firstName": "Dotan",
                            "lastName": "Castro",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dotan Di Castro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703978"
                        ],
                        "name": "Iftah Gamzu",
                        "slug": "Iftah-Gamzu",
                        "structuredName": {
                            "firstName": "Iftah",
                            "lastName": "Gamzu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iftah Gamzu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405652973"
                        ],
                        "name": "Irena Grabovitch-Zuyev",
                        "slug": "Irena-Grabovitch-Zuyev",
                        "structuredName": {
                            "firstName": "Irena",
                            "lastName": "Grabovitch-Zuyev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irena Grabovitch-Zuyev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402943721"
                        ],
                        "name": "L. Lewin-Eytan",
                        "slug": "L.-Lewin-Eytan",
                        "structuredName": {
                            "firstName": "Liane",
                            "lastName": "Lewin-Eytan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lewin-Eytan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781257"
                        ],
                        "name": "Y. Maarek",
                        "slug": "Y.-Maarek",
                        "structuredName": {
                            "firstName": "Yoelle",
                            "lastName": "Maarek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Maarek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18673157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1747f88aaa66a85a2aedd8df511ad39c836c0970",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Several recent studies have presented different approaches for clustering and classifying machine-generated mail based on email headers. We propose to expand these approaches by considering email message bodies. We argue that our approach can help increase coverage and precision in several tasks, and is especially critical for mail extraction. We remind that mail extraction supports a variety of mail mining applications such as ad re-targeting, mail search, and mail summarization. We introduce new structural clustering methods that leverage the HTML structure that is common to messages generated by a same mass-sender script. We discuss how such structural clustering can be conducted at different levels of granularity, using either strict or flexible matching constraints, depending on the use cases. We present large scale experiments carried over real Yahoo mail traffic. For our first use case of automatic mail extraction, we describe novel flexible-matching clustering methods that meet the key requirements of high intra-cluster similarity, adequate clusters size, and relatively small overall number of clusters. We identify the precise level of flexibility that is needed in order to achieve extremely high extraction precision (close to 100%), while producing relatively small number of clusters. For our second use case, namely, mail classification, we show that strict structural matching is more adequate, achieving precision and recall rates between 85%-90%, while converging to a stable classification after a short learning cycle. This represents an increase of 10%-20% compared to the sender-based method described in previous work, when run over the same period length. Our work has been deployed in production in Yahoo mail backend."
            },
            "slug": "Structural-Clustering-of-Machine-Generated-Mail-Avigdor-Elgrabli-Cwalinski",
            "title": {
                "fragments": [],
                "text": "Structural Clustering of Machine-Generated Mail"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work describes novel flexible-matching clustering methods that meet the key requirements of high intra-cluster similarity, adequate clusters size, and relatively small overall number of clusters for automatic mail extraction, and shows that strict structural matching is more adequate."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24590005"
                        ],
                        "name": "Alex Perelygin",
                        "slug": "Alex-Perelygin",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Perelygin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Perelygin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110402830"
                        ],
                        "name": "Jean Wu",
                        "slug": "Jean-Wu",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964541"
                        ],
                        "name": "Jason Chuang",
                        "slug": "Jason-Chuang",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Chuang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Chuang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922861"
                        ],
                        "name": "Christopher Potts",
                        "slug": "Christopher-Potts",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Potts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Potts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Identifying the sentiment in text documents [43], detecting spam in email [12] and the web [36], and fake news detection [42] are well-known applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 990233,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "687bac2d3320083eb4530bf18bb8f8f721477600",
            "isKey": false,
            "numCitedBy": 5367,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases."
            },
            "slug": "Recursive-Deep-Models-for-Semantic-Compositionality-Socher-Perelygin",
            "title": {
                "fragments": [],
                "text": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A Sentiment Treebank that includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality, and introduces the Recursive Neural Tensor Network."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053802028"
                        ],
                        "name": "Ying Sheng",
                        "slug": "Ying-Sheng",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Sheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Sheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2519906"
                        ],
                        "name": "Sandeep Tata",
                        "slug": "Sandeep-Tata",
                        "structuredName": {
                            "firstName": "Sandeep",
                            "lastName": "Tata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sandeep Tata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796372"
                        ],
                        "name": "James Bradley Wendt",
                        "slug": "James-Bradley-Wendt",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wendt",
                            "middleNames": [
                                "Bradley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Bradley Wendt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144945348"
                        ],
                        "name": "Jing Xie",
                        "slug": "Jing-Xie",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110560772"
                        ],
                        "name": "Qi Zhao",
                        "slug": "Qi-Zhao",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763978"
                        ],
                        "name": "Marc Najork",
                        "slug": "Marc-Najork",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Najork",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Najork"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 46
                            }
                        ],
                        "text": "used to power several intelligent experiences [14, 41]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 94
                            }
                        ],
                        "text": "Learning good email representations has been an area of interest for multiple research groups [2, 14, 41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[41] for more detailed discussion on these annotators."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 93
                            }
                        ],
                        "text": "This includes foldering [19], automatic prioritization [15], and even information extraction [2, 14, 41]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "In this work, we use structural clustering techniques based on a locality sensitive hash of the email body similar to the technique described in [41]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 50767110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e765fa28e79e2157cb2ec926ccfeac6bbea027d5",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Extracting structured data from emails can enable several assistive experiences, such as reminding the user when a bill payment is due, answering queries about the departure time of a booked flight, or proactively surfacing an emailed discount coupon while the user is at that store. This paper presents Juicer, a system for extracting information from email that is serving over a billion Gmail users daily. We describe how the design of the system was informed by three key principles: scaling to a planet-wide email service, isolating the complexity to provide a simple experience for the developer, and safeguarding the privacy of users (our team and the developers we support are not allowed to view any single email). We describe the design tradeoffs made in building this system, the challenges faced and the approaches used to tackle them. We present case studies of three extraction tasks implemented on this platform---bill reminders, commercial offers, and hotel reservations---to illustrate the effectiveness of the platform despite challenges unique to each task. Finally, we outline several areas of ongoing research in large-scale machine-learned information extraction from email."
            },
            "slug": "Anatomy-of-a-Privacy-Safe-Large-Scale-Information-Sheng-Tata",
            "title": {
                "fragments": [],
                "text": "Anatomy of a Privacy-Safe Large-Scale Information Extraction System Over Email"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "How the design of the Juicer system was informed by three key principles: scaling to a planet-wide email service, isolating the complexity to provide a simple experience for the developer, and safeguarding the privacy of users is described."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39798499"
                        ],
                        "name": "Yang Liu",
                        "slug": "Yang-Liu",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "Recent studies in the literature have shown that attention-based LSTM models [29, 48] are excellent for modeling text documents and achieve state-of-the-art performance in document classification tasks by outperforming linear models, SVMs, and feed-forward neural networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 208
                            }
                        ],
                        "text": "In addition to the hierarchical structure, discourse structure [32] in the text, which represents the linguistic organization of a text as a tree, has also been studied in recent document representation work [8, 22, 29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39871772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29219d826ead654f2b863de6eceb69811850b7d4",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we focus on learning structure-aware document representations from data without recourse to a discourse parser or additional annotations. Drawing inspiration from recent efforts to empower neural networks with a structural bias (Cheng et al., 2016; Kim et al., 2017), we propose a model that can encode a document while automatically inducing rich structural dependencies. Specifically, we embed a differentiable non-projective parsing algorithm into a neural model and use attention mechanisms to incorporate the structural biases. Experimental evaluations across different tasks and datasets show that the proposed model achieves state-of-the-art results on document modeling tasks while inducing intermediate structures which are both interpretable and meaningful."
            },
            "slug": "Learning-Structured-Text-Representations-Liu-Lapata",
            "title": {
                "fragments": [],
                "text": "Learning Structured Text Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A model that can encode a document while automatically inducing rich structural dependencies is proposed that embeds a differentiable non-projective parsing algorithm into a neural model and uses attention mechanisms to incorporate the structural biases."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 197
                            }
                        ],
                        "text": "The success of these approaches are later combined with the power of recurrent neural networks (RNNs) which led others to learn distributed representations of a larger piece of text like sentences [26], paragraphs [28], and documents [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2407601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f527bcfb09f32e6a4a8afc0b37504941c1ba2cee",
            "isKey": false,
            "numCitedBy": 7044,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, \"powerful,\" \"strong\" and \"Paris\" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks."
            },
            "slug": "Distributed-Representations-of-Sentences-and-Le-Mikolov",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Sentences and Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Paragraph Vector is an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents, and its construction gives the algorithm the potential to overcome the weaknesses of bag-of-words models."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144766615"
                        ],
                        "name": "Sen Wu",
                        "slug": "Sen-Wu",
                        "structuredName": {
                            "firstName": "Sen",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sen Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065637845"
                        ],
                        "name": "Luke Hsiao",
                        "slug": "Luke-Hsiao",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Hsiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Hsiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149478197"
                        ],
                        "name": "Xiao Cheng",
                        "slug": "Xiao-Cheng",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34302368"
                        ],
                        "name": "Braden Hancock",
                        "slug": "Braden-Hancock",
                        "structuredName": {
                            "firstName": "Braden",
                            "lastName": "Hancock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Braden Hancock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145071799"
                        ],
                        "name": "Theodoros Rekatsinas",
                        "slug": "Theodoros-Rekatsinas",
                        "structuredName": {
                            "firstName": "Theodoros",
                            "lastName": "Rekatsinas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Theodoros Rekatsinas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721681"
                        ],
                        "name": "P. Levis",
                        "slug": "P.-Levis",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Levis",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Levis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114485554"
                        ],
                        "name": "C. R\u00e9",
                        "slug": "C.-R\u00e9",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "R\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. R\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "Lastly, systems like Fonduer [46] tackle richly formatted documents for the task of Knowledge Base Construction (KBC)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 39
                            }
                        ],
                        "text": "Our results agree with the findings in Fonduer \u2013 formatting information does indeed help us learn a better representation for an email."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Fonduer shows that augmenting textual features with structural and visual features produced by a library that parses the HTML markup and providing it to a strong baseline like a bi-directional LSTM with attention can indeed provide a significant improvement over just\nusing the text features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 87
                            }
                        ],
                        "text": "In contrast to the approach of engineering a set of structural features (examples from Fonduer include HTML tag of the term, HTML tag of the parent, tabular features like row number, column number, n-grams from all the cells in the same row) our approach simply relies on learning an encoding using the sequence of HTML tags that appear in the path from the root to the node containing the term."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 96
                            }
                        ],
                        "text": "While we do not implement the nearly 40 structural, tabular, and visual features implemented in Fonduer, an interesting piece of future work is to study if XPath encodings as learned by our model can be as effective as the sophisticated features manually engineered in Fonduer."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3627801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9946251c58094e193c68e01e9261cdb61af9f26e",
            "isKey": true,
            "numCitedBy": 74,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We focus on knowledge base construction (KBC) from richly formatted data. In contrast to KBC from text or tabular data, KBC from richly formatted data aims to extract relations conveyed jointly via textual, structural, tabular, and visual expressions. We introduce Fonduer, a machine-learning-based KBC system for richly formatted data. Fonduer presents a new data model that accounts for three challenging characteristics of richly formatted data: (1) prevalent document-level relations, (2) multimodality, and (3) data variety. Fonduer uses a new deep-learning model to automatically capture the representation (i.e., features) needed to learn how to extract relations from richly formatted data. Finally, Fonduer provides a new programming model that enables users to convert domain expertise, based on multiple modalities of information, to meaningful signals of supervision for training a KBC system. Fonduer-based KBC systems are in production for a range of use cases, including at a major online retailer. We compare Fonduer against state-of-the-art KBC approaches in four different domains. We show that Fonduer achieves an average improvement of 41 F1 points on the quality of the output knowledge base---and in some cases produces up to 1.87x the number of correct entries---compared to expert-curated public knowledge bases. We also conduct a user study to assess the usability of Fonduer's new programming model. We show that after using Fonduer for only 30 minutes, non-domain experts are able to design KBC systems that achieve on average 23 F1 points higher quality than traditional machine-learning-based KBC approaches."
            },
            "slug": "Fonduer:-Knowledge-Base-Construction-from-Richly-Wu-Hsiao",
            "title": {
                "fragments": [],
                "text": "Fonduer: Knowledge Base Construction from Richly Formatted Data"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Fonduer provides a new programming model that enables users to convert domain expertise, based on multiple modalities of information, to meaningful signals of supervision for training a KBC system, and presents a new data model that accounts for three challenging characteristics of richly formatted data."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693332"
                        ],
                        "name": "M. Agarwal",
                        "slug": "M.-Agarwal",
                        "structuredName": {
                            "firstName": "Manoj",
                            "lastName": "Agarwal",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153278724"
                        ],
                        "name": "J. Singh",
                        "slug": "J.-Singh",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Singh",
                            "middleNames": [
                                "Nath"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Singh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 94
                            }
                        ],
                        "text": "Learning good email representations has been an area of interest for multiple research groups [2, 14, 41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 93
                            }
                        ],
                        "text": "This includes foldering [19], automatic prioritization [15], and even information extraction [2, 14, 41]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 130
                            }
                        ],
                        "text": "These techniques range from clustering on the sender and subject of an email [3] to clustering on the structure of the email body [2, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52047682,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24353ad46a939a2a24a13b15ec7cfdf74eee8cf2",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Many machine generated emails carry important information which must be acted upon at scheduled time by the recipient. Thus, it becomes a natural goal to automatically extract such actionable information from these emails and communicate to the users. These emails are generated for many different domains, providing different types of services. However, such emails carry personal information, therefore, it becomes difficult to get access to large corpus of labeled data for supervised information extraction methods."
            },
            "slug": "Template-Trees:-Extracting-Actionable-Information-Agarwal-Singh",
            "title": {
                "fragments": [],
                "text": "Template Trees: Extracting Actionable Information from Machine Generated Emails"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper aims to get access to large corpus of labeled data for supervised information extraction methods from machine generated emails, which carry personal information, and find ways to automatically extract such actionable information."
            },
            "venue": {
                "fragments": [],
                "text": "DEXA"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38431523"
                        ],
                        "name": "Siwei Lai",
                        "slug": "Siwei-Lai",
                        "structuredName": {
                            "firstName": "Siwei",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siwei Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8540973"
                        ],
                        "name": "Liheng Xu",
                        "slug": "Liheng-Xu",
                        "structuredName": {
                            "firstName": "Liheng",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liheng Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2200096"
                        ],
                        "name": "Kang Liu",
                        "slug": "Kang-Liu",
                        "structuredName": {
                            "firstName": "Kang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390572170"
                        ],
                        "name": "Jun Zhao",
                        "slug": "Jun-Zhao",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 234
                            }
                        ],
                        "text": "The success of these approaches are later combined with the power of recurrent neural networks (RNNs) which led others to learn distributed representations of a larger piece of text like sentences [26], paragraphs [28], and documents [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16756501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eba36ac75bf22edf9a1bfd33244d459c75b98305",
            "isKey": false,
            "numCitedBy": 1576,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Text classification is a foundational task in many NLP applications. Traditional text classifiers often rely on many human-designed features, such as dictionaries, knowledge bases and special tree kernels. In contrast to traditional methods, we introduce a recurrent convolutional neural network for text classification without human-designed features. In our model, we apply a recurrent structure to capture contextual information as far as possible when learning word representations, which may introduce considerably less noise compared to traditional window-based neural networks. We also employ a max-pooling layer that automatically judges which words play key roles in text classification to capture the key components in texts. We conduct experiments on four commonly used datasets. The experimental results show that the proposed method outperforms the state-of-the-art methods on several datasets, particularly on document-level datasets.\n \n"
            },
            "slug": "Recurrent-Convolutional-Neural-Networks-for-Text-Lai-Xu",
            "title": {
                "fragments": [],
                "text": "Recurrent Convolutional Neural Networks for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A recurrent convolutional neural network is introduced for text classification without human-designed features to capture contextual information as far as possible when learning word representations, which may introduce considerably less noise compared to traditional window-based neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 16
                            }
                        ],
                        "text": "Techniques like Word2Vec [34] and Glove [38] have produced pre-trained embeddings for words that can be combined with more complex neural approaches."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "One can also use pre-trained word embeddings such as Word2Vec [35], Glove [38], or fastText [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16447573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "isKey": false,
            "numCitedBy": 26054,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. \n \nAn inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."
            },
            "slug": "Distributed-Representations-of-Words-and-Phrases-Mikolov-Sutskever",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Words and Phrases and their Compositionality"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a simple method for finding phrases in text, and shows that learning good vector representations for millions of phrases is possible and describes a simple alternative to the hierarchical softmax called negative sampling."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781257"
                        ],
                        "name": "Y. Maarek",
                        "slug": "Y.-Maarek",
                        "structuredName": {
                            "firstName": "Yoelle",
                            "lastName": "Maarek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Maarek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 198
                            }
                        ],
                        "text": "We focus on business-to-consumer (B2C) emails, the vast majority of which are machine-generated instantiations of predefined templates, accounting for up to 90% of all email traffic on the internet [30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41295988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8395795c48069dea9c6437b74163e2dd1a66731b",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The nature of Web mail traffic has significantly evolved in the last two decades, and consequently the behavior of Web mail users has also changed. For instance a recent study conducted by Yahoo Labs showed that today 90% of Web mail traffic is machine-generated. This partly explains why email traffic continues to grow even if a significant amount of personal communications has moved towards social media. Most users today are receiving in their inbox important invoices, receipts, and travel itineraries, together with non-malicious junk mail such as hotel newsletters or shopping promotions that could safely ignore. This is one of the reasons that a majority of messages remain unread, and many are deleted without being read. In that sense, Web mail has become quite similar to traditional snail mail. In spite of this drastic change in nature, many mail features remain unchanged. While 70% of mail users do not define even a single folder, folders are still predominant in the left trail of many Web mail clients. Mail search results are still mostly ranked by date, which makes the retrieving of older messages extremely challenging. This is even more painful to users, as unlike in Web search, they will know when a relevant previously read message has not been returned. In this talk, I present the results of multiple large-scale studies that have been conducted at Yahoo Labs in the last few years. I highlight the inherent challenges associated with such studies, especially around privacy concerns. I will discuss the new nature of consumer Web mail, which is dominated by machine-generated messages of highly heterogeneous forms and value. I will show how the change has not been fully recognized yet by my most email clients. As an example, why should there still be a reply option associated with a message coming from a \"do-not-reply@\" address?. I will introduce some approaches for large-scale mail mining specifically tailored to machine-generated email. I will conclude by discussing possible applications and research directions."
            },
            "slug": "Is-Mail-The-Next-Frontier-In-Search-And-Data-Mining-Maarek",
            "title": {
                "fragments": [],
                "text": "Is Mail The Next Frontier In Search And Data Mining?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This talk presents the results of multiple large-scale studies that have been conducted at Yahoo Labs in the last few years, and introduces some approaches for large- scale mail mining specifically tailored to machine-generated email."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49298465"
                        ],
                        "name": "Jiwei Li",
                        "slug": "Jiwei-Li",
                        "structuredName": {
                            "firstName": "Jiwei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiwei Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707242"
                        ],
                        "name": "Minh-Thang Luong",
                        "slug": "Minh-Thang-Luong",
                        "structuredName": {
                            "firstName": "Minh-Thang",
                            "lastName": "Luong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minh-Thang Luong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 214
                            }
                        ],
                        "text": "The success of these approaches are later combined with the power of recurrent neural networks (RNNs) which led others to learn distributed representations of a larger piece of text like sentences [26], paragraphs [28], and documents [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b21c78a62fbb945a19ae9a8935933711647e7d70",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language generation of coherent long texts like paragraphs or longer documents is a challenging problem for recurrent networks models. In this paper, we explore an important step toward this generation task: training an LSTM (Longshort term memory) auto-encoder to preserve and reconstruct multi-sentence paragraphs. We introduce an LSTM model that hierarchically builds an embedding for a paragraph from embeddings for sentences and words, then decodes this embedding to reconstruct the original paragraph. We evaluate the reconstructed paragraph using standard metrics like ROUGE and Entity Grid, showing that neural models are able to encode texts in a way that preserve syntactic, semantic, and discourse coherence. While only a first step toward generating coherent text units from neural models, our work has the potential to significantly impact natural language generation and summarization1."
            },
            "slug": "A-Hierarchical-Neural-Autoencoder-for-Paragraphs-Li-Luong",
            "title": {
                "fragments": [],
                "text": "A Hierarchical Neural Autoencoder for Paragraphs and Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces an LSTM model that hierarchically builds an embedding for a paragraph from embeddings for sentences and words, then decodes this embedding to reconstruct the original paragraph and evaluates the reconstructed paragraph using standard metrics to show that neural models are able to encode texts in a way that preserve syntactic, semantic, and discourse coherence."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143845796"
                        ],
                        "name": "Jeffrey Pennington",
                        "slug": "Jeffrey-Pennington",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pennington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "Techniques like Word2Vec [34] and Glove [38] have produced pre-trained embeddings for words that can be combined with more complex neural approaches."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "One can also use pre-trained word embeddings such as Word2Vec [35], Glove [38], or fastText [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1957433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "isKey": false,
            "numCitedBy": 22537,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition."
            },
            "slug": "GloVe:-Global-Vectors-for-Word-Representation-Pennington-Socher",
            "title": {
                "fragments": [],
                "text": "GloVe: Global Vectors for Word Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods and produces a vector space with meaningful substructure."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8421815"
                        ],
                        "name": "Kai Sheng Tai",
                        "slug": "Kai-Sheng-Tai",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Tai",
                            "middleNames": [
                                "Sheng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Sheng Tai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "Several variants of RNNs like convolutional-gated RNN [45], tree-LSTM [44] and Quasi-RNN [10] are proposed as alternative architectures."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3033526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32de44f01a96d4473d21099d15e25bc2b9f08e2f",
            "isKey": false,
            "numCitedBy": 2501,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank)."
            },
            "slug": "Improved-Semantic-Representations-From-Long-Memory-Tai-Socher",
            "title": {
                "fragments": [],
                "text": "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Tree-LSTM is introduced, a generalization of LSTMs to tree-structured network topologies that outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences and sentiment classification."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2048494"
                        ],
                        "name": "Nir Ailon",
                        "slug": "Nir-Ailon",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Ailon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nir Ailon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3386660"
                        ],
                        "name": "Zohar S. Karnin",
                        "slug": "Zohar-S.-Karnin",
                        "structuredName": {
                            "firstName": "Zohar",
                            "lastName": "Karnin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zohar S. Karnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2941680"
                        ],
                        "name": "Edo Liberty",
                        "slug": "Edo-Liberty",
                        "structuredName": {
                            "firstName": "Edo",
                            "lastName": "Liberty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edo Liberty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781257"
                        ],
                        "name": "Y. Maarek",
                        "slug": "Y.-Maarek",
                        "structuredName": {
                            "firstName": "Yoelle",
                            "lastName": "Maarek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Maarek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "These techniques range from clustering on the sender and subject of an email [3] to clustering on the structure of the email body [2, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15813440,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d95afb84683f524e5ab5878ab12eacc154736b6",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Viewing email messages as parts of a sequence or a thread is a convenient way to quickly understand their context. Current threading techniques rely on purely syntactic methods, matching sender information, subject line, and reply/forward prefixes. As such, they are mostly limited to personal conversations. In contrast, machine-generated email, which amount, as per our experiments, to more than 60% of the overall email traffic, requires a different kind of threading that should reflect how a sequence of emails is caused by a few related user actions. For example, purchasing goods from an online store will result in a receipt or a confirmation message, which may be followed, possibly after a few days, by a shipment notification message from an express shipping service. In today's mail systems, they will not be a part of the same thread, while we believe they should. In this paper, we focus on this type of threading that we coin \"causal threading\". We demonstrate that, by analyzing recurring patterns over hundreds of millions of mail users, we can infer a causality relation between these two individual messages. In addition, by observing multiple causal relations over common messages, we can generate \"causal threads\" over a sequence of messages. The four key stages of our approach consist of: (1) identifying messages that are instances of the same email type or \"template\" (generated by the same machine process on the sender side) (2) building a causal graph, in which nodes correspond to email templates and edges indicate potential causal relations (3) learning a causal relation prediction function, and (4) automatically \"threading\" the incoming email stream. We present detailed experimental results obtained by analyzing the inboxes of 12.5 million Yahoo! Mail users, who voluntarily opted-in for such research. Supervised editorial judgments show that we can identify more than 70% (recall rate) of all \"causal threads\" at a precision level of 90%. In addition, for a search scenario we show that we achieve a precision close to 80% at 90% recall. We believe that supporting causal threads in email clients opens new grounds for improving both email search and browsing experiences."
            },
            "slug": "Threading-machine-generated-email-Ailon-Karnin",
            "title": {
                "fragments": [],
                "text": "Threading machine generated email"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is demonstrated that, by analyzing recurring patterns over hundreds of millions of mail users, they can infer a causality relation between these two individual messages and it is believed that supporting causal threads in email clients opens new grounds for improving both email search and browsing experiences."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM '13"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3114123"
                        ],
                        "name": "G. Cormack",
                        "slug": "G.-Cormack",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Cormack",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cormack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "extraction, email classifiers are useful for other applications like automatic foldering [6, 19], spam classification [13], and message priority ranking [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62574043,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7be97249e88516058f34ad3836c16096413bd02b",
            "isKey": false,
            "numCitedBy": 280,
            "numCiting": 179,
            "paperAbstract": {
                "fragments": [],
                "text": "Spam is information crafted to be delivered to a large number of recipients, in spite of their wishes. A spam filter is an automated tool to recognize spam so as to prevent its delivery. The purposes of spam and spam filters are diametrically opposed: spam is effective if it evades filters, while a filter is effective if it recognizes spam. The circular nature of these definitions, along with their appeal to the intent of sender and recipient make them difficult to formalize. A typical email user has a working definition no more formal than \"I know it when I see it.\" Yet, current spam filters are remarkably effective, more effective than might be expected given the level of uncertainty and debate over a formal definition of spam, more effective than might be expected given the state-of-the-art information retrieval and machine learning methods for seemingly similar problems. But are they effective enough? Which are better? How might they be improved? Will their effectiveness be compromised by more cleverly crafted spam? \n \nWe survey current and proposed spam filtering techniques with particular emphasis on how well they work. Our primary focus is spam filtering in email; Similarities and differences with spam filtering in other communication and storage media \u2014 such as instant messaging and the Web \u2014 are addressed peripherally. In doing so we examine the definition of spam, the user's information requirements and the role of the spam filter as one component of a large and complex information universe. Well-known methods are detailed sufficiently to make the exposition self-contained, however, the focus is on considerations unique to spam. Comparisons, wherever possible, use common evaluation measures, and control for differences in experimental setup. Such comparisons are not easy, as benchmarks, measures, and methods for evaluating spam filters are still evolving. We survey these efforts, their results and their limitations. In spite of recent advances in evaluation methodology, many uncertainties (including widely held but unsubstantiated beliefs) remain as to the effectiveness of spam filtering techniques and as to the validity of spam filter evaluation methods. We outline several uncertainties and propose experimental methods to address them."
            },
            "slug": "Email-Spam-Filtering:-A-Systematic-Review-Cormack",
            "title": {
                "fragments": [],
                "text": "Email Spam Filtering: A Systematic Review"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work examines the definition of spam, the user's information requirements and the role of the spam filter as one component of a large and complex information universe, and outlines several uncertainties and proposes experimental methods to address them."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Inf. Retr."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329288"
                        ],
                        "name": "Piotr Bojanowski",
                        "slug": "Piotr-Bojanowski",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Bojanowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Bojanowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3024698"
                        ],
                        "name": "Edouard Grave",
                        "slug": "Edouard-Grave",
                        "structuredName": {
                            "firstName": "Edouard",
                            "lastName": "Grave",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edouard Grave"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319608"
                        ],
                        "name": "Armand Joulin",
                        "slug": "Armand-Joulin",
                        "structuredName": {
                            "firstName": "Armand",
                            "lastName": "Joulin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Armand Joulin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "One can also use pre-trained word embeddings such as Word2Vec [35], Glove [38], or fastText [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207556454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2dba792360873aef125572812f3673b1a85d850",
            "isKey": false,
            "numCitedBy": 6591,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks."
            },
            "slug": "Enriching-Word-Vectors-with-Subword-Information-Bojanowski-Grave",
            "title": {
                "fragments": [],
                "text": "Enriching Word Vectors with Subword Information"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new approach based on the skipgram model, where each word is represented as a bag of character n-grams, with words being represented as the sum of these representations, which achieves state-of-the-art performance on word similarity and analogy tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Transactions of the Association for Computational Linguistics"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781257"
                        ],
                        "name": "Y. Maarek",
                        "slug": "Y.-Maarek",
                        "structuredName": {
                            "firstName": "Yoelle",
                            "lastName": "Maarek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Maarek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Recent studies [31] have shown that most email is richly formatted and machine-generated rather than plaintext sent by humans."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32425979,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89466abc721b81eeed96999673bec10769e42eb8",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Many have noticed that personal communications have slowly moved from mail to social media and instant messaging platforms, especially with younger generation [6]. Yet Web Mail traffic continues to steadily grow. A paradox? Not really. We have observed at Yahoo Research that the nature of email traffic has significantly changed in the last two decades, and it is now dominated by machine-generated messages. These messages include hotel newsletters, from which users forgot to unsubscribe, repeated, and often annoying, notifications from a social media site, or critical information such as a flight e-ticket, a purchase invoice, or a telephone bill. In this talk, I first share some elements of this journey that led us to this critical finding that 90% of today's Web Mail is sent by automatic scripts [1]. I then discuss the challenges and opportunities this drastic change offers. First the key challenge: namely, the need for Web mail services to revisit their usage assumptions and their traditional features in light of this change. An obvious example is the \"reply\" button being displayed by default below messages sent from a \"no-reply@\" sender. Another feature is mail classification, which has finally experienced some changes in the last few years, [4]. I then discuss the opportunities in this era of big data. One first insight is that messages that have been generated by a same script, share some semantic commonality. Being able to automatically cluster such messages, and map such clusters into \"templates\" brings great value for discovering meaning, for generalizing findings and predicting behaviors [5]. A second insight is that within this commonality, the differences bring even more value, which allows highlighting what makes individuals unique within a crowd. In particular we discuss extraction techniques that automatically identify these unique elements [2]. Yet, they also present a clear risk in terms of privacy and I describe the absolute need for guaranteeing k-anonymity in our mining techniques, [3]. I conclude by encouraging the research community to explore this new domain of Web mail search and data mining."
            },
            "slug": "Web-Mail-is-not-Dead!:-It's-Just-Not-Human-Anymore-Maarek",
            "title": {
                "fragments": [],
                "text": "Web Mail is not Dead!: It's Just Not Human Anymore"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This talk shares some elements of this journey that led to this critical finding that 90% of today's Web Mail is sent by automatic scripts and discusses extraction techniques that automatically identify unique elements in messages, and describes the absolute need for guaranteeing k-anonymity in mining techniques."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8387085"
                        ],
                        "name": "Zichao Yang",
                        "slug": "Zichao-Yang",
                        "structuredName": {
                            "firstName": "Zichao",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zichao Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022168"
                        ],
                        "name": "Diyi Yang",
                        "slug": "Diyi-Yang",
                        "structuredName": {
                            "firstName": "Diyi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diyi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "Hence, we apply an attention mechanism [48] over the outputs of the LSTM layer in order to (1) extract such informative tags from long sequences and reward their contributions to the XPath representation, and (2) simultaneously reduce the impact of highly repetitive tags."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Recently, authors in [48] have argued that the hierarchical structure of documents helps to learn better representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "for assuming that documents are hierarchically organized [48] into sentences and paragraphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "shown that for relatively short documents, a recurrent neural network with an attention mechanism [48] is a very strong baseline for learning good representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "In this work, we use an LSTM encoder with an additional attention mechanism [48] to represent the sequential elements (HTML tags), however, one is free to choose any standard sequence encoder to model the sequential input."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "Recent studies in the literature have shown that attention-based LSTM models [29, 48] are excellent for modeling text documents and achieve state-of-the-art performance in document classification tasks by outperforming linear models, SVMs, and feed-forward neural networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 169
                            }
                        ],
                        "text": "With [w1,w2, \u00b7 \u00b7 \u00b7 ,wL] we can now compute an email representation vector by using another LSTM layer to encode the sequence and apply an additional attention mechanism [48] over that layer:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6857205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "455afd748e8834ef521e4b67c7c056d3c33429e2",
            "isKey": true,
            "numCitedBy": 3226,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a hierarchical attention network for document classification. Our model has two distinctive characteristics: (i) it has a hierarchical structure that mirrors the hierarchical structure of documents; (ii) it has two levels of attention mechanisms applied at the wordand sentence-level, enabling it to attend differentially to more and less important content when constructing the document representation. Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin. Visualization of the attention layers illustrates that the model selects qualitatively informative words and sentences."
            },
            "slug": "Hierarchical-Attention-Networks-for-Document-Yang-Yang",
            "title": {
                "fragments": [],
                "text": "Hierarchical Attention Networks for Document Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763978"
                        ],
                        "name": "Marc Najork",
                        "slug": "Marc-Najork",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Najork",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Najork"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Identifying the sentiment in text documents [43], detecting spam in email [12] and the web [36], and fake news detection [42] are well-known applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30964960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6d335565e00d707ea6482769c2f3014a8f0a2f2",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Definition Web spam refers to a host of techniques to subvert the ranking algorithms of web search engines and cause them to rank search results higher than they would otherwise. Examples of such techniques include content spam (populating web pages with popular and often highly monetizable search terms), link spam (creating links to a page in order to increase its linkbased score), and cloaking (serving different versions of a page to search engine crawlers than to human users). Web spam is annoying to search engine users and disruptive to search engines; therefore, most commercial search engines try to combat web spam. Combating web spam consists of identifying spam content with high probability and \u2013 depending on policy \u2013 downgrading it during ranking, eliminating it from the index, no longer crawling it, and tainting affiliated content. The first step \u2013 identifying likely spam pages \u2013 is a classification problem amenable to machine learning techniques. Spam classifiers take a large set of diverse features as input, including contentbased features, link-based features, DNS and domainregistration features, and implicit user feedback. Commercial search engines treat their precise set of spam-prediction features as extremely proprietary, and features (as well as spamming techniques) evolve continuously as search engines and web spammers are engaged in a continuing \u201carms race.\u201d"
            },
            "slug": "Web-Spam-Detection-Najork",
            "title": {
                "fragments": [],
                "text": "Web Spam Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Combating web spam consists of identifying spam content with high probability and \u2013 depending on policy \u2013 downgrading it during ranking, eliminating it from the index, no longer crawling it, and tainting affiliated content."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Database Systems"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 55
                            }
                        ],
                        "text": "There is a rich history of work in text representation [33, 47] for various tasks like sentiment classification [37] (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7311285,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04ce064505b1635583fa0d9cc07cac7e9ea993cc",
            "isKey": false,
            "numCitedBy": 3832,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in text classification has used two different first-order probabilistic models for classification, both of which make the naive Bayes assumption. Some use a multi-variate Bernoulli model, that is, a Bayesian Network with no dependencies between words and binary word features (e.g. Larkey and Croft 1996; Koller and Sahami 1997). Others use a multinomial model, that is, a uni-gram language model with integer word counts (e.g. Lewis and Gale 1994; Mitchell 1997). This paper aims to clarify the confusion by describing the differences and details of these two models, and by empirically comparing their classification performance on five text corpora. We find that the multi-variate Bernoulli performs well with small vocabulary sizes, but that the multinomial performs usually performs even better at larger vocabulary sizes--providing on average a 27% reduction in error over the multi-variate Bernoulli model at any vocabulary size."
            },
            "slug": "A-comparison-of-event-models-for-naive-bayes-text-McCallum-Nigam",
            "title": {
                "fragments": [],
                "text": "A comparison of event models for naive bayes text classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is found that the multi-variate Bernoulli performs well with small vocabulary sizes, but that the multinomial performs usually performs even better at larger vocabulary sizes--providing on average a 27% reduction in error over the multi -variateBernoulli model at any vocabulary size."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 1998"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "Techniques like Word2Vec [34] and Glove [38] have produced pre-trained embeddings for words that can be combined with more complex neural approaches."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 53
                            }
                        ],
                        "text": "One can also use pre-trained word embeddings such as Word2Vec [35], Glove [38], or fastText [9]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5959482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "330da625c15427c6e42ccfa3b747fb29e5835bf0",
            "isKey": false,
            "numCitedBy": 21886,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose two novel model architectures for computing continuous vector\nrepresentations of words from very large data sets. The quality of these\nrepresentations is measured in a word similarity task, and the results are\ncompared to the previously best performing techniques based on different types\nof neural networks. We observe large improvements in accuracy at much lower\ncomputational cost, i.e. it takes less than a day to learn high quality word\nvectors from a 1.6 billion words data set. Furthermore, we show that these\nvectors provide state-of-the-art performance on our test set for measuring\nsyntactic and semantic word similarities."
            },
            "slug": "Efficient-Estimation-of-Word-Representations-in-Mikolov-Chen",
            "title": {
                "fragments": [],
                "text": "Efficient Estimation of Word Representations in Vector Space"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Two novel model architectures for computing continuous vector representations of words from very large data sets are proposed and it is shown that these vectors provide state-of-the-art performance on the authors' test set for measuring syntactic and semantic word similarities."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145800151"
                        ],
                        "name": "Kai Shu",
                        "slug": "Kai-Shu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Shu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Shu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2880010"
                        ],
                        "name": "A. Sliva",
                        "slug": "A.-Sliva",
                        "structuredName": {
                            "firstName": "Amy",
                            "lastName": "Sliva",
                            "middleNames": [
                                "Lynn"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2893721"
                        ],
                        "name": "Suhang Wang",
                        "slug": "Suhang-Wang",
                        "structuredName": {
                            "firstName": "Suhang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suhang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736632"
                        ],
                        "name": "Jiliang Tang",
                        "slug": "Jiliang-Tang",
                        "structuredName": {
                            "firstName": "Jiliang",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiliang Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145896397"
                        ],
                        "name": "Huan Liu",
                        "slug": "Huan-Liu",
                        "structuredName": {
                            "firstName": "Huan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huan Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "Identifying the sentiment in text documents [43], detecting spam in email [12] and the web [36], and fake news detection [42] are well-known applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207718082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb40a5e6d4fc0290452345791bb91040aed76961",
            "isKey": false,
            "numCitedBy": 1502,
            "numCiting": 114,
            "paperAbstract": {
                "fragments": [],
                "text": "Social media for news consumption is a double-edged sword. On the one hand, its low cost, easy access, and rapid dissemination of information lead people to seek out and consume news from social media. On the other hand, it enables the wide spread of \\fake news\", i.e., low quality news with intentionally false information. The extensive spread of fake news has the potential for extremely negative impacts on individuals and society. Therefore, fake news detection on social media has recently become an emerging research that is attracting tremendous attention. Fake news detection on social media presents unique characteristics and challenges that make existing detection algorithms from traditional news media ine ective or not applicable. First, fake news is intentionally written to mislead readers to believe false information, which makes it difficult and nontrivial to detect based on news content; therefore, we need to include auxiliary information, such as user social engagements on social media, to help make a determination. Second, exploiting this auxiliary information is challenging in and of itself as users' social engagements with fake news produce data that is big, incomplete, unstructured, and noisy. Because the issue of fake news detection on social media is both challenging and relevant, we conducted this survey to further facilitate research on the problem. In this survey, we present a comprehensive review of detecting fake news on social media, including fake news characterizations on psychology and social theories, existing algorithms from a data mining perspective, evaluation metrics and representative datasets. We also discuss related research areas, open problems, and future research directions for fake news detection on social media."
            },
            "slug": "Fake-News-Detection-on-Social-Media:-A-Data-Mining-Shu-Sliva",
            "title": {
                "fragments": [],
                "text": "Fake News Detection on Social Media: A Data Mining Perspective"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This survey presents a comprehensive review of detecting fake news on social media, including fake news characterizations on psychology and social theories, existing algorithms from a data mining perspective, evaluation metrics and representative datasets, and future research directions for fake news detection on socialMedia."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 51693,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39483833"
                        ],
                        "name": "Duyu Tang",
                        "slug": "Duyu-Tang",
                        "structuredName": {
                            "firstName": "Duyu",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Duyu Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152277111"
                        ],
                        "name": "Bing Qin",
                        "slug": "Bing-Qin",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Qin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing Qin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40282288"
                        ],
                        "name": "Ting Liu",
                        "slug": "Ting-Liu",
                        "structuredName": {
                            "firstName": "Ting",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ting Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "The success of these approaches are later combined with the power of recurrent neural networks (RNNs) which led others to learn distributed representations of a larger piece of text like sentences [26], paragraphs [28], and documents [25]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Several variants of RNNs like convolutional-gated RNN [45], tree-LSTM [44] and Quasi-RNN [10] are proposed as alternative architectures."
                    },
                    "intents": []
                }
            ],
            "corpusId": 784094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecb5336bf7b54a62109f325e7152bb74c4c7f527",
            "isKey": false,
            "numCitedBy": 1172,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Document level sentiment classification remains a challenge: encoding the intrinsic relations between sentences in the semantic meaning of a document. To address this, we introduce a neural network model to learn vector-based document representation in a unified, bottom-up fashion. The model first learns sentence representation with convolutional neural network or long short-term memory. Afterwards, semantics of sentences and their relations are adaptively encoded in document representation with gated recurrent neural network. We conduct document level sentiment classification on four large-scale review datasets from IMDB and Yelp Dataset Challenge. Experimental results show that: (1) our neural model shows superior performances over several state-of-the-art algorithms; (2) gated recurrent neural network dramatically outperforms standard recurrent neural network in document modeling for sentiment classification. 1"
            },
            "slug": "Document-Modeling-with-Gated-Recurrent-Neural-for-Tang-Qin",
            "title": {
                "fragments": [],
                "text": "Document Modeling with Gated Recurrent Neural Network for Sentiment Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A neural network model is introduced to learn vector-based document representation in a unified, bottom-up fashion and dramatically outperforms standard recurrent neural network in document modeling for sentiment classification."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 123
                            }
                        ],
                        "text": "Acknowledging that the importance of words or sentences may vary depending on the context, they use an attention mechanism [5] while hierarchically encoding words into sentences and sentences into documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11212020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "isKey": false,
            "numCitedBy": 19342,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition."
            },
            "slug": "Neural-Machine-Translation-by-Jointly-Learning-to-Bahdanau-Cho",
            "title": {
                "fragments": [],
                "text": "Neural Machine Translation by Jointly Learning to Align and Translate"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and it is proposed to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50339091"
                        ],
                        "name": "Parminder Bhatia",
                        "slug": "Parminder-Bhatia",
                        "structuredName": {
                            "firstName": "Parminder",
                            "lastName": "Bhatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Parminder Bhatia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40608686"
                        ],
                        "name": "Yangfeng Ji",
                        "slug": "Yangfeng-Ji",
                        "structuredName": {
                            "firstName": "Yangfeng",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangfeng Ji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144154709"
                        ],
                        "name": "Jacob Eisenstein",
                        "slug": "Jacob-Eisenstein",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Eisenstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Eisenstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 208
                            }
                        ],
                        "text": "In addition to the hierarchical structure, discourse structure [32] in the text, which represents the linguistic organization of a text as a tree, has also been studied in recent document representation work [8, 22, 29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12252194,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93547ca277f93ae8cde856f66bf54166d64b4dcf",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Discourse structure is the hidden link between surface features and document-level properties, such as sentiment polarity. We show that the discourse analyses produced by Rhetorical Structure Theory (RST) parsers can improve document-level sentiment analysis, via composition of local information up the discourse tree. First, we show that reweighting discourse units according to their position in a dependency representation of the rhetorical structure can yield substantial improvements on lexicon-based sentiment analysis. Next, we present a recursive neural network over the RST structure, which offers significant improvements over classificationbased methods."
            },
            "slug": "Better-Document-level-Sentiment-Analysis-from-RST-Bhatia-Ji",
            "title": {
                "fragments": [],
                "text": "Better Document-level Sentiment Analysis from RST Discourse Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work shows that the discourse analyses produced by Rhetorical Structure Theory parsers can improve document-level sentiment analysis, via composition of local information up the discourse tree and presents a recursive neural network over the RST structure, which offers significant improvements over classificationbased methods."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46447747"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7818229"
                        ],
                        "name": "J. Zhao",
                        "slug": "J.-Zhao",
                        "structuredName": {
                            "firstName": "Junbo",
                            "lastName": "Zhao",
                            "middleNames": [
                                "Jake"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 79
                            }
                        ],
                        "text": "Apart from recurrent neural networks, methods employing convolutional networks [23, 49] have also produced compelling results for text classification tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 368182,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51a55df1f023571a7e07e338ee45a3e3d66ef73e",
            "isKey": false,
            "numCitedBy": 3477,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This article offers an empirical exploration on the use of character-level convolutional networks (ConvNets) for text classification. We constructed several large-scale datasets to show that character-level convolutional networks could achieve state-of-the-art or competitive results. Comparisons are offered against traditional models such as bag of words, n-grams and their TFIDF variants, and deep learning models such as word-based ConvNets and recurrent neural networks."
            },
            "slug": "Character-level-Convolutional-Networks-for-Text-Zhang-Zhao",
            "title": {
                "fragments": [],
                "text": "Character-level Convolutional Networks for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This article constructed several large-scale datasets to show that character-level convolutional networks could achieve state-of-the-art or competitive results in text classification."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3334758"
                        ],
                        "name": "Godwin Caruana",
                        "slug": "Godwin-Caruana",
                        "structuredName": {
                            "firstName": "Godwin",
                            "lastName": "Caruana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Godwin Caruana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716059"
                        ],
                        "name": "Maozhen Li",
                        "slug": "Maozhen-Li",
                        "structuredName": {
                            "firstName": "Maozhen",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maozhen Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "Identifying the sentiment in text documents [43], detecting spam in email [12] and the web [36], and fake news detection [42] are well-known applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16759,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e52af37793a56d8f5a19e4f57ee0df70dd7d4bc8",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 144,
            "paperAbstract": {
                "fragments": [],
                "text": "From just an annoying characteristic of the electronic mail epoch, spam has evolved into an expensive resource and time-consuming problem. In this survey, we focus on emerging approaches to spam filtering built on recent developments in computing technologies. These include peer-to-peer computing, grid computing, semantic Web, and social networks. We also address a number of perspectives related to personalization and privacy in spam filtering. We conclude that, while important advancements have been made in spam filtering in recent years, high performance approaches remain to be explored due to the large scale of the problem."
            },
            "slug": "A-survey-of-emerging-approaches-to-spam-filtering-Caruana-Li",
            "title": {
                "fragments": [],
                "text": "A survey of emerging approaches to spam filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This survey focuses on emerging approaches to spam filtering built on recent developments in computing technologies, which include peer-to-peer computing, grid computing, semantic Web, and social networks."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "For the Adam optimizer, we use the default settings suggested by the authors (\u03b21 = 0.9, \u03b22 = 0.999, \u03f5 = 10\u22128)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "5}), and the optimizer type (AdaGrad [16] and Adam [24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 343
                            }
                        ],
                        "text": "For all four variants, we perform grid search over the word embedding dimension ({50, 100, 200}), the word encoder LSTM output (hidden state) dimension ({64, 128, 256}), the initial learning rate ({0.01, 0.001, 0.0001}), the batch size ({50, 100, 200}), the word encoder dropout rate ({0, 0.25, 0.5}), and the optimizer type (AdaGrad [16] and Adam [24])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": true,
            "numCitedBy": 90076,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38367242"
                        ],
                        "name": "Yoon Kim",
                        "slug": "Yoon-Kim",
                        "structuredName": {
                            "firstName": "Yoon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoon Kim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 79
                            }
                        ],
                        "text": "Apart from recurrent neural networks, methods employing convolutional networks [23, 49] have also produced compelling results for text classification tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9672033,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba",
            "isKey": false,
            "numCitedBy": 10065,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task-specific and static vectors. The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification."
            },
            "slug": "Convolutional-Neural-Networks-for-Sentence-Kim",
            "title": {
                "fragments": [],
                "text": "Convolutional Neural Networks for Sentence Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The CNN models discussed herein improve upon the state of the art on 4 out of 7 tasks, which include sentiment analysis and question classification, and are proposed to allow for the use of both task-specific and static vectors."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120100599"
                        ],
                        "name": "Xin Liu",
                        "slug": "Xin-Liu",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 55
                            }
                        ],
                        "text": "There is a rich history of work in text representation [33, 47] for various tasks like sentiment classification [37] (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6465383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43015e9790c812bdc25bf0539b2ee4055a1882a7",
            "isKey": false,
            "numCitedBy": 2969,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports a controlled study with statistical signi cance tests on ve text categorization methods: the Support Vector Machines (SVM), a k-Nearest Neighbor (kNN) classi er, a neural network (NNet) approach, the Linear Leastsquares Fit (LLSF) mapping and a Naive Bayes (NB) classier. We focus on the robustness of these methods in dealing with a skewed category distribution, and their performance as function of the training-set category frequency. Our results show that SVM, kNN and LLSF signi cantly outperform NNet and NB when the number of positive training instances per category are small (less than ten), and that all the methods perform comparably when the categories are su ciently common (over 300 instances)."
            },
            "slug": "A-re-examination-of-text-categorization-methods-Yang-Liu",
            "title": {
                "fragments": [],
                "text": "A re-examination of text categorization methods"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The results show that SVM, kNN and LLSF signi cantly outperform NNet and NB when the number of positive training instances per category are small, and that all the methods perform comparably when the categories are over 300 instances."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144865353"
                        ],
                        "name": "B. Pang",
                        "slug": "B.-Pang",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Pang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Pang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066721"
                        ],
                        "name": "Shivakumar Vaithyanathan",
                        "slug": "Shivakumar-Vaithyanathan",
                        "structuredName": {
                            "firstName": "Shivakumar",
                            "lastName": "Vaithyanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shivakumar Vaithyanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "There is a rich history of work in text representation [33, 47] for various tasks like sentiment classification [37] (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7105713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12d0353ce8b41b7e5409e5a4a611110aee33c7bc",
            "isKey": false,
            "numCitedBy": 8511,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging."
            },
            "slug": "Thumbs-up-Sentiment-Classification-using-Machine-Pang-Lee",
            "title": {
                "fragments": [],
                "text": "Thumbs up? Sentiment Classification using Machine Learning Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work considers the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative, and concludes by examining factors that make the sentiment classification problem more challenging."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40518045"
                        ],
                        "name": "James Bradbury",
                        "slug": "James-Bradbury",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bradbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Bradbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3375440"
                        ],
                        "name": "Stephen Merity",
                        "slug": "Stephen-Merity",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Merity",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Merity"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228109"
                        ],
                        "name": "Caiming Xiong",
                        "slug": "Caiming-Xiong",
                        "structuredName": {
                            "firstName": "Caiming",
                            "lastName": "Xiong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Caiming Xiong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 51559,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d876ed1dd2c58058d7197b734a8e4d349b8f231",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural networks are a powerful tool for modeling sequential data, but the dependence of each timestep's computation on the previous timestep's output limits parallelism and makes RNNs unwieldy for very long sequences. We introduce quasi-recurrent neural networks (QRNNs), an approach to neural sequence modeling that alternates convolutional layers, which apply in parallel across timesteps, and a minimalist recurrent pooling function that applies in parallel across channels. Despite lacking trainable recurrent layers, stacked QRNNs have better predictive accuracy than stacked LSTMs of the same hidden size. Due to their increased parallelism, they are up to 16 times faster at train and test time. Experiments on language modeling, sentiment classification, and character-level neural machine translation demonstrate these advantages and underline the viability of QRNNs as a basic building block for a variety of sequence tasks."
            },
            "slug": "Quasi-Recurrent-Neural-Networks-Bradbury-Merity",
            "title": {
                "fragments": [],
                "text": "Quasi-Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Quasi-recurrent neural networks (QRNNs), an approach to neural sequence modeling that alternates convolutional layers, which apply in parallel across timesteps, and a minimalist recurrent pooling function that applies inallel across channels are introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724421"
                        ],
                        "name": "Deng Cai",
                        "slug": "Deng-Cai",
                        "structuredName": {
                            "firstName": "Deng",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deng Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1911562"
                        ],
                        "name": "Shipeng Yu",
                        "slug": "Shipeng-Yu",
                        "structuredName": {
                            "firstName": "Shipeng",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shipeng Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259699"
                        ],
                        "name": "Ji-Rong Wen",
                        "slug": "Ji-Rong-Wen",
                        "structuredName": {
                            "firstName": "Ji-Rong",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji-Rong Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712167"
                        ],
                        "name": "Wei-Ying Ma",
                        "slug": "Wei-Ying-Ma",
                        "structuredName": {
                            "firstName": "Wei-Ying",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Ying Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Another possible representation is to use a visual blocks structure using external parsers [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13007604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84372852886ddcb49e9adf9c5facf53e1bde9696",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A new web content structure based on visual representation is proposed in this paper. Many web applications such as information retrieval, information extraction and automatic page adaptation can benefit from this structure. This paper presents an automatic top-down, tag-tree independent approach to detect web content structure. It simulates how a user understands web layout structure based on his visual perception. Comparing to other existing techniques, our approach is independent to underlying documentation representation such as HTML and works well even when the HTML structure is far different from layout structure. Experiments show satisfactory results."
            },
            "slug": "Extracting-Content-Structure-for-Web-Pages-Based-on-Cai-Yu",
            "title": {
                "fragments": [],
                "text": "Extracting Content Structure for Web Pages Based on Visual Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents an automatic top-down, tag-tree independent approach to detect web content structure that simulates how a user understands web layout structure based on his visual perception."
            },
            "venue": {
                "fragments": [],
                "text": "APWeb"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40608686"
                        ],
                        "name": "Yangfeng Ji",
                        "slug": "Yangfeng-Ji",
                        "structuredName": {
                            "firstName": "Yangfeng",
                            "lastName": "Ji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangfeng Ji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144365875"
                        ],
                        "name": "Noah A. Smith",
                        "slug": "Noah-A.-Smith",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 208
                            }
                        ],
                        "text": "In addition to the hierarchical structure, discourse structure [32] in the text, which represents the linguistic organization of a text as a tree, has also been studied in recent document representation work [8, 22, 29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5914002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe3bd7c7b36cc563c1bd54189b963e3244b74580",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that discourse structure, as defined by Rhetorical Structure Theory and provided by an existing discourse parser, benefits text categorization. Our approach uses a recursive neural network and a newly proposed attention mechanism to compute a representation of the text that focuses on salient content, from the perspective of both RST and the task. Experiments consider variants of the approach and illustrate its strengths and weaknesses."
            },
            "slug": "Neural-Discourse-Structure-for-Text-Categorization-Ji-Smith",
            "title": {
                "fragments": [],
                "text": "Neural Discourse Structure for Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work uses a recursive neural network and a newly proposed attention mechanism to compute a representation of the text that focuses on salient content, from the perspective of both RST and the task."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145615125"
                        ],
                        "name": "R. Guha",
                        "slug": "R.-Guha",
                        "structuredName": {
                            "firstName": "Ramanathan",
                            "lastName": "Guha",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Guha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2458864"
                        ],
                        "name": "D. Brickley",
                        "slug": "D.-Brickley",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Brickley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Brickley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066981400"
                        ],
                        "name": "Steve Macbeth",
                        "slug": "Steve-Macbeth",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Macbeth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve Macbeth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "Microdata is a standard that enables senders to explicitly label and mark up their outgoing emails with structured information."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "Ground truth labels for this dataset are derived from three sources: Microdata [20], manually defined parsers, and rulebased extractors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 6
                            }
                        ],
                        "text": "While Microdata markup is precise, it is not widely\nadopted by all email senders, so the volume of annotations tends to be low."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 97
                            }
                        ],
                        "text": "Manually defined parsers are designed to extract category-specific fields from emails in lieu of Microdata."
                    },
                    "intents": []
                }
            ],
            "corpusId": 27038003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f58262626aeaab0b78750a7433f3f8017908c87",
            "isKey": true,
            "numCitedBy": 227,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Separation between content and presentation has always been one of the important design aspects of the Web. Historically, however, even though most Web sites were driven off structured databases, they published their content purely in HTML. Services such as Web search, price comparison, reservation engines, etc. that operated on this content had access only to HTML. Applications requiring access to the structured data underlying these Web pages had to build custom extractors to convert plain HTML into structured data. These efforts were often laborious and the scrapers were fragile and error-prone, breaking every time a site changed its layout."
            },
            "slug": "Schema.org:-Evolution-of-Structured-Data-on-the-Web-Guha-Brickley",
            "title": {
                "fragments": [],
                "text": "Schema.org: Evolution of Structured Data on the Web"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Historically, even though most Web sites were driven off structured databases, they published their content purely in HTML, and applications requiring access to the structured data underlying these Web pages had to build custom extractors to convert plain HTML into structured data."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Queue"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6919261"
                        ],
                        "name": "Xiaoguang Qi",
                        "slug": "Xiaoguang-Qi",
                        "structuredName": {
                            "firstName": "Xiaoguang",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoguang Qi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800527"
                        ],
                        "name": "Brian D. Davison",
                        "slug": "Brian-D.-Davison",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Davison",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian D. Davison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "For instance, web pages have rich HTML structure; classifying them [39] is useful for several applications like focused crawling, faceted search, and even as a signal for web page search ranking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3344003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e06cb621e796e749e12b1ad47f9d25456b42d476",
            "isKey": false,
            "numCitedBy": 506,
            "numCiting": 184,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification of Web page content is essential to many tasks in Web information retrieval such as maintaining Web directories and focused crawling. The uncontrolled nature of Web content presents additional challenges to Web page classification as compared to traditional text classification, but the interconnected nature of hypertext also provides features that can assist the process.\n As we review work in Web page classification, we note the importance of these Web-specific features and algorithms, describe state-of-the-art practices, and track the underlying assumptions behind the use of information from neighboring pages."
            },
            "slug": "Web-page-classification:-Features-and-algorithms-Qi-Davison",
            "title": {
                "fragments": [],
                "text": "Web page classification: Features and algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "As work in Web page classification is reviewed, the importance of these Web-specific features and algorithms are noted, state-of-the-art practices are described, and the underlying assumptions behind the use of information from neighboring pages are tracked."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734693"
                        ],
                        "name": "John C. Duchi",
                        "slug": "John-C.-Duchi",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Duchi",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Duchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34840427"
                        ],
                        "name": "Elad Hazan",
                        "slug": "Elad-Hazan",
                        "structuredName": {
                            "firstName": "Elad",
                            "lastName": "Hazan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elad Hazan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "5}), and the optimizer type (AdaGrad [16] and Adam [24])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 538820,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "413c1142de9d91804d6d11c67ff3fed59c9fc279",
            "isKey": false,
            "numCitedBy": 8025,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms."
            },
            "slug": "Adaptive-Subgradient-Methods-for-Online-Learning-Duchi-Hazan",
            "title": {
                "fragments": [],
                "text": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal functions that can be chosen in hindsight."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145973657"
                        ],
                        "name": "D. Golovin",
                        "slug": "D.-Golovin",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Golovin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Golovin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22695907"
                        ],
                        "name": "Benjamin Solnik",
                        "slug": "Benjamin-Solnik",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Solnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Solnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3316330"
                        ],
                        "name": "Subhodeep Moitra",
                        "slug": "Subhodeep-Moitra",
                        "structuredName": {
                            "firstName": "Subhodeep",
                            "lastName": "Moitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subhodeep Moitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2942286"
                        ],
                        "name": "G. Kochanski",
                        "slug": "G.-Kochanski",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Kochanski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kochanski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056044"
                        ],
                        "name": "J. Karro",
                        "slug": "J.-Karro",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Karro",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Karro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733143"
                        ],
                        "name": "D. Sculley",
                        "slug": "D.-Sculley",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Sculley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sculley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "For each model, we use the Vizier [17] platform to select the best combination of hyper-parameters based on AUC-PR after a maximum of 1M training steps."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19971112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "938f6ef7eed095919e6a482c7f1836a01d62db4b",
            "isKey": false,
            "numCitedBy": 517,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Any sufficiently complex system acts as a black box when it becomes easier to experiment with than to understand. Hence, black-box optimization has become increasingly important as systems have become more complex. In this paper we describe Google Vizier, a Google-internal service for performing black-box optimization that has become the de facto parameter tuning engine at Google. Google Vizier is used to optimize many of our machine learning models and other systems, and also provides core capabilities to Google's Cloud Machine Learning HyperTune subsystem. We discuss our requirements, infrastructure design, underlying algorithms, and advanced features such as transfer learning and automated early stopping that the service provides."
            },
            "slug": "Google-Vizier:-A-Service-for-Black-Box-Optimization-Golovin-Solnik",
            "title": {
                "fragments": [],
                "text": "Google Vizier: A Service for Black-Box Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Google Vizier is described, a Google-internal service for performing black-box optimization that has become the de facto parameter tuning engine at Google and is used to optimize many of the authors' machine learning models and other systems."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847871"
                        ],
                        "name": "W. Mann",
                        "slug": "W.-Mann",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Mann",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Mann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20082155"
                        ],
                        "name": "S. Thompson",
                        "slug": "S.-Thompson",
                        "structuredName": {
                            "firstName": "Sandra",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "In addition to the hierarchical structure, discourse structure [32] in the text, which represents the linguistic organization of a text as a tree, has also been studied in recent document representation work [8, 22, 29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60514661,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "af5100605a3b6bfd0adf9a30e69a47d1b98340ba",
            "isKey": false,
            "numCitedBy": 3752,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Rhetorical Structure Theory is a descriptive theory of a major aspect of the organization of natural text. It is a linguistically useful methodfor describing natural texts, characterizing their Structure primarily in terms of relations that hold between parts of the text. This paper establishes a new definitional foundation for RST. The paper also examines three Claims ofRST: the predominance of nucleus/satellite structural pattems, the functional basis of hierarchy, and the communicative role oftext Structure."
            },
            "slug": "Rhetorical-Structure-Theory:-Toward-a-functional-of-Mann-Thompson",
            "title": {
                "fragments": [],
                "text": "Rhetorical Structure Theory: Toward a functional theory of text organization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper establishes a new definitional foundation for RST and examines three Claims of RST: the predominance of nucleus/satellite structural pattems, the functional basis of hierarchy, and the communicative role oftext Structure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042818"
                        ],
                        "name": "D. Aberdeen",
                        "slug": "D.-Aberdeen",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Aberdeen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Aberdeen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66420429"
                        ],
                        "name": "Ondrey Pacovsky",
                        "slug": "Ondrey-Pacovsky",
                        "structuredName": {
                            "firstName": "Ondrey",
                            "lastName": "Pacovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ondrey Pacovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064024167"
                        ],
                        "name": "Andrew Slater",
                        "slug": "Andrew-Slater",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Slater",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Slater"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 153
                            }
                        ],
                        "text": "extraction, email classifiers are useful for other applications like automatic foldering [6, 19], spam classification [13], and message priority ranking [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59593475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5882cc9ac2380f13016c5aa6c81422de9e47b311",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Learning-Behind-Gmail-Priority-Inbox-Aberdeen-Pacovsky",
            "title": {
                "fragments": [],
                "text": "The Learning Behind Gmail Priority Inbox"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "At a high level, the XPath encoder models an email\u2019s DOM structure by encoding the tags along the XPath to a leaf node using an LSTM layer [21] while the word encoder combines word embeddings with the corresponding XPath encodings and additional features to learn an enhanced representation of the email."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Long short-termmemory"
            },
            "venue": {
                "fragments": [],
                "text": "Neural computation 9,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analyzing Entities"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Abhinav Pundir, Nil Ratan Sahoo, and Michael Viderman"
            },
            "venue": {
                "fragments": [],
                "text": "Companion Proceedings of the The Web Conference"
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 130
                            }
                        ],
                        "text": "These techniques range from clustering on the sender and subject of an email [3] to clustering on the structure of the email body [2, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Structural clustering ofmachine-generatedmail"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the 25th ACM International on Conference on Information and Knowledge Management (CIKM)"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "This structure introduces a complex hierarchy which can be represented by a Document Object Model (DOM) tree [27], such as the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Document Object Model (DOM). http://www.w3.org/DOM"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 28,
            "methodology": 15
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 50,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/RiSER:-Learning-Better-Representations-for-Richly-Kocayusufoglu-Sheng/6b226bc61562fc68a04ef3bef43e945465ebad48?sort=total-citations"
}