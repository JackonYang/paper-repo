{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125776"
                        ],
                        "name": "Chris Brockett",
                        "slug": "Chris-Brockett",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Brockett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Brockett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7861626,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23f8fa0b4a2db78a7a8dcc78494df8385b670f60",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The lack of readily-available large corpora of aligned monolingual sentence pairs is a major obstacle to the development of Statistical Machine Translation-based paraphrase models. In this paper, we describe the use of annotated datasets and Support Vector Machines to induce larger monolingual paraphrase corpora from a comparable corpus of news clusters found on the World Wide Web. Features include: morphological variants; WordNet synonyms and hypernyms; loglikelihood-based word pairings dynamically obtained from baseline sentence alignments; and formal string features such as word-based edit distance. Use of this technique dramatically reduces the Alignment Error Rate of the extracted corpora over heuristic methods based on position of the sentences in the text."
            },
            "slug": "Support-Vector-Machines-for-Paraphrase-and-Corpus-Brockett-Dolan",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines for Paraphrase Identification and Corpus Construction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The use of annotated datasets and Support Vector Machines are described to induce larger monolingual paraphrase corpora from a comparable corpus of news clusters found on the World Wide Web, which dramatically reduces the Alignment Error Rate of the extracted corpora."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNLP"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2596310"
                        ],
                        "name": "Chris Quirk",
                        "slug": "Chris-Quirk",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Quirk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Quirk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125776"
                        ],
                        "name": "Chris Brockett",
                        "slug": "Chris-Brockett",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Brockett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Brockett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10181753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7acfdc905f734abf966aed58abb983bc015ff7fe",
            "isKey": false,
            "numCitedBy": 794,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate unsupervised techniques for acquiring monolingual sentence-level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web-based news sources. Two techniques are employed: (1) simple string edit distance, and (2) a heuristic strategy that pairs initial (presumably summary) sentences from different news stories in the same cluster. We evaluate both datasets using a word alignment algorithm and a metric borrowed from machine translation. Results show that edit distance data is cleaner and more easily-aligned than the heuristic data, with an overall alignment error rate (AER) of 11.58% on a similarly-extracted test set. On test data extracted by the heuristic strategy, however, performance of the two training sets is similar, with AERs of 13.2% and 14.7% respectively. Analysis of 100 pairs of sentences from each set reveals that the edit distance data lacks many of the complex lexical and syntactic alternations that characterize monolingual paraphrase. The summary sentences, while less readily alignable, retain more of the non-trivial alternations that are of greatest interest learning paraphrase relationships."
            },
            "slug": "Unsupervised-Construction-of-Large-Paraphrase-News-Dolan-Quirk",
            "title": {
                "fragments": [],
                "text": "Unsupervised Construction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "Investigation of unsupervised techniques for acquiring monolingual sentence-level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web-based news sources shows that edit distance data is cleaner and more easily-aligned than the heuristic data."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9842595,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "8d7a692d8763a38283db54e19f1dcc694a34e706",
            "isKey": false,
            "numCitedBy": 538,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "While paraphrasing is critical both for interpretation and generation of natural language, current systems use manual or semi-automatic methods to collect paraphrases. We present an unsupervised learning algorithm for identification of paraphrases from a corpus of multiple English translations of the same source text. Our approach yields phrasal and single word lexical paraphrases as well as syntactic paraphrases."
            },
            "slug": "Extracting-Paraphrases-from-a-Parallel-Corpus-Barzilay-McKeown",
            "title": {
                "fragments": [],
                "text": "Extracting Paraphrases from a Parallel Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents an unsupervised learning algorithm for identification of paraphrases from a corpus of multiple English translations of the same source text that yields phrasal and single word lexical paraphrasing as well as syntactic paraphrase."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34981957"
                        ],
                        "name": "S. Shirai",
                        "slug": "S.-Shirai",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Shirai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shirai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1576796848"
                        ],
                        "name": "Kazuhide Yamamoto",
                        "slug": "Kazuhide-Yamamoto",
                        "structuredName": {
                            "firstName": "Kazuhide",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhide Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145440721"
                        ],
                        "name": "Francis Bond",
                        "slug": "Francis-Bond",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francis Bond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2911717"
                        ],
                        "name": "Hozumi Tanaka",
                        "slug": "Hozumi-Tanaka",
                        "structuredName": {
                            "firstName": "Hozumi",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hozumi Tanaka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15384300,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa56b221697e83e495da7486d90217624f40c300",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a thesaurus of predicates that can help to resolve pre-editing and/or post-editing problems in machine translation environments. It differs from earlier approaches such as conventional dictionaries in that we are aiming to link a wide range of near-synonyms and paraphrases. We are compiling such similar examples through both introspection and the use of translation data, giving us a large collection of monolingual and bilingual equivalences. This thesaurus enables the following machine translation techniques. (a) Unification of synonymous expressions in the source language (source language paraphrasing). (b) Conversion of homonymous expressions to more easily translated ones (source language rewriting). (c) Development of expressions appearing in the target language into various expressions (target language paraphrasing)."
            },
            "slug": "Towards-a-Thesaurus-of-Predicates-Shirai-Yamamoto",
            "title": {
                "fragments": [],
                "text": "Towards a Thesaurus of Predicates"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A thesaurus of predicates that can help to resolve pre-edited and/or post-editing problems in machine translation environments, aiming to link a wide range of near-synonyms and paraphrases."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 214
                            }
                        ],
                        "text": "The success of Statistical Machine Translation (SMT) has sparked a successful line of investigation that treats paraphrase acquisition and generation essentially as a monolingual machine translation problem (e.g., Barzilay & Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Finch et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 38
                            }
                        ],
                        "text": "Likewise, the data made available by (Barzilay & Lee, 2003: http://www.cs.cornell.edu/ Info/Projects/NLP/statpar.html), while invaluable in understanding and evaluating their results, is too limited in size and domain coverage to serve as either training or test data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6387310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10b8f21e57b3392ce623c374c2c039f811ce5f69",
            "isKey": false,
            "numCitedBy": 523,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the text-to-text generation problem of sentence-level paraphrasing --- a phenomenon distinct from and more difficult than word- or phrase-level paraphrasing. Our approach applies multiple-sequence alignment to sentences gathered from unannotated comparable corpora: it learns a set of paraphrasing patterns represented by word lattice pairs and automatically determines how to apply these patterns to rewrite new sentences. The results of our evaluation experiments show that the system derives accurate paraphrases, outperforming baseline systems."
            },
            "slug": "Learning-to-Paraphrase:-An-Unsupervised-Approach-Barzilay-Lee",
            "title": {
                "fragments": [],
                "text": "Learning to Paraphrase: An Unsupervised Approach Using Multiple-Sequence Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work applies multiple-sequence alignment to sentences gathered from unannotated comparable corpora: it learns a set of paraphrasing patterns represented by word lattice pairs and automatically determines how to apply these patterns to rewrite new sentences."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 771,
                                "start": 22
                            }
                        ],
                        "text": "In these respects, as Wu (2005) points out, the corpus is far from distributionally neutral. This is a matter that we hope to remedy in the future, since in many ways this excluded set of pairs is the most interesting of all. The above limitations, together with its relatively small size, perhaps make the MRSP inappropriate for direct use as a training corpus. We show separately that the results of training a classifier on the present corpus may be inferior to other training sets, though better than crude string or text-based heuristics (Brockett & Dolan, 2005). We expect that the utility of the corpus will stem primarily from its use as a tool for evaluating paraphrase recognition algorithms. It has already been applied in this way by Corley & Mihalcea (2005) and Wu (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 22
                            }
                        ],
                        "text": "In these respects, as Wu (2005) points out, the corpus is far from distributionally neutral."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 72
                            }
                        ],
                        "text": "It has already been applied in this way by Corley & Mihalcea (2005) and Wu (2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4955511,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "17ae5fa96cf3ad5427d9654b17a2f937aae242c0",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We present first results using paraphrase as well as textual entailment data to test the language universal constraint posited by Wu's (1995, 1997) Inversion Transduction Grammar (ITG) hypothesis. In machine translation and alignment, the ITG Hypothesis provides a strong inductive bias, and has been shown empirically across numerous language pairs and corpora to yield both efficiency and accuracy gains for various language acquisition tasks. Monolingual paraphrase and textual entailment recognition datasets, however, potentially facilitate closer tests of certain aspects of the hypothesis than bilingual parallel corpora, which simultaneously exhibit many irrelevant dimensions of cross-lingual variation. We investigate this using simple generic Bracketing ITGs containing no language-specific linguistic knowledge. Experimental results on the MSR Paraphrase Corpus show that, even in the absence of any thesaurus to accommodate lexical variation between the paraphrases, an uninterpolated average precision of at least 76% is obtainable from the Bracketing ITG's structure matching bias alone. This is consistent with experimental results on the Pascal Recognising Textual Entailment Challenge Corpus, which show surpisingly strong results for a number of the task subsets."
            },
            "slug": "Recognizing-Paraphrases-and-Textual-Entailment-Wu",
            "title": {
                "fragments": [],
                "text": "Recognizing Paraphrases and Textual Entailment Using Inversion Transduction Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experimental results on the MSR Paraphrase Corpus show that, even in the absence of any thesaurus to accommodate lexical variation between the paraphrases, an uninterpolated average precision of at least 76% is obtainable from the Bracketing ITG's structure matching bias alone."
            },
            "venue": {
                "fragments": [],
                "text": "EMSEE@ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2596310"
                        ],
                        "name": "Chris Quirk",
                        "slug": "Chris-Quirk",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Quirk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Quirk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125776"
                        ],
                        "name": "Chris Brockett",
                        "slug": "Chris-Brockett",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Brockett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Brockett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 305
                            }
                        ],
                        "text": "The Microsoft Research Paraphrase Corpus (MSRP) is distilled from a database of 13,127,938 sentence pairs, extracted from 9,516,684 sentences in 32,408 news clusters collected from the World Wide Web over a 2year period, The methods and assumptions used in building this initial data set are discussed in Quirk et al. (2004) and Dolan et al. (2004). Two heuristics based on shared lexical properties and sentence position in the document were employed to construct the initial database: Word-based Levenshtein edit distance"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 325,
                                "start": 305
                            }
                        ],
                        "text": "The Microsoft Research Paraphrase Corpus (MSRP) is distilled from a database of 13,127,938 sentence pairs, extracted from 9,516,684 sentences in 32,408 news clusters collected from the World Wide Web over a 2year period, The methods and assumptions used in building this initial data set are discussed in Quirk et al. (2004) and Dolan et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 247
                            }
                        ],
                        "text": "\u2026from a database of 13,127,938 sentence pairs, extracted from 9,516,684 sentences in 32,408 news clusters collected from the World Wide Web over a 2- year period, The methods and assumptions used in building this initial data set are discussed in Quirk et al. (2004) and Dolan et al. (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 207
                            }
                        ],
                        "text": "The success of Statistical Machine Translation (SMT) has sparked a successful line of investigation that treats paraphrase acquisition and generation essentially as a monolingual machine translation problem (e.g., Barzilay & Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Finch et al. , 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 255
                            }
                        ],
                        "text": "The success of Statistical Machine Translation (SMT) has sparked a successful line of investigation that treats paraphrase acquisition and generation essentially as a monolingual machine translation problem (e.g., Barzilay & Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Finch et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13043395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a5a179a70e98ee1c4b4b8b54f6c8aba629c02e4",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply statistical machine translation (SMT) tools to generate novel paraphrases of input sentences in the same language. The system is trained on large volumes of sentence pairs automatically extracted from clustered news articles available on the World Wide Web. Alignment Error Rate (AER) is measured to gauge the quality of the resulting corpus. A monotone phrasal decoder generates contextual replacements. Human evaluation shows that this system outperforms baseline paraphrase generation techniques and, in a departure from previous work, offers better coverage and scalability than the current best-of-breed paraphrasing approaches."
            },
            "slug": "Monolingual-Machine-Translation-for-Paraphrase-Quirk-Brockett",
            "title": {
                "fragments": [],
                "text": "Monolingual Machine Translation for Paraphrase Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Human evaluation shows that this SMT system outperforms baseline paraphrase generation techniques and, in a departure from previous work, offers better coverage and scalability than the current best-of-breed paraphrasing approaches."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5416402"
                        ],
                        "name": "J. Burger",
                        "slug": "J.-Burger",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Burger",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36405930"
                        ],
                        "name": "L. Ferro",
                        "slug": "L.-Ferro",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Ferro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ferro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2941806,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0724231630ccbc6e7b15740e49c42044507e6f39",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe our efforts to generate a large (100,000 instance) corpus of textual entailment pairs from the lead paragraph and headline of news articles. We manually inspected a small set of news stories in order to locate the most productive source of entailments, then built an annotation interface for rapid manual evaluation of further exemplars. With this training data we built an SVM-based document classifier, which we used for corpus refinement purposes---we believe that roughly three-quarters of the resulting corpus are genuine entailment pairs. We also discuss the difficulties inherent in manual entailment judgment, and suggest ways to ameliorate some of these."
            },
            "slug": "Generating-an-Entailment-Corpus-from-News-Headlines-Burger-Ferro",
            "title": {
                "fragments": [],
                "text": "Generating an Entailment Corpus from News Headlines"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work manually inspected a small set of news stories in order to locate the most productive source of entailments, then built an annotation interface for rapid manual evaluation of further exemplars, and built an SVM-based document classifier for corpus refinement purposes."
            },
            "venue": {
                "fragments": [],
                "text": "EMSEE@ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108257896"
                        ],
                        "name": "Yujie Zhang",
                        "slug": "Yujie-Zhang",
                        "structuredName": {
                            "firstName": "Yujie",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yujie Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1576796848"
                        ],
                        "name": "Kazuhide Yamamoto",
                        "slug": "Kazuhide-Yamamoto",
                        "structuredName": {
                            "firstName": "Kazuhide",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhide Yamamoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 145
                            }
                        ],
                        "text": "\u2026tend to be rather restricted in their domain (e.g. the ATR English-Chinese paraphrase corpus, which con-\nsists of translations of travel phrases (Zhang & Yamamoto, 2002)), are limited to short handcrafted predicates (e.g. the ATR JapaneseEnglish corpus (Shirai, et al., 2002)), or exhibit\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13393486,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "8f76788d60ebd4f3503551b5c56c036541a8883f",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the key issues in spoken language translation is how to deal with unrestricted expressions in spontaneous utterances. This research is centered on the development of a Chinese paraphraser that automatically paraphrases utterances prior to transfer in Chinese-Japanese spoken language translation. In this paper, a pattern-based approach to paraphrasing is proposed for which only morphological analysis is required. In addition, a pattern construction method is described through which paraphrasing patterns can be efficiently learned from a paraphrase corpus and human experience. Using the implemented paraphraser and the obtained patterns, a paraphrasing experiment was conducted and the results were evaluated."
            },
            "slug": "Paraphrasing-of-Chinese-Utterances-Zhang-Yamamoto",
            "title": {
                "fragments": [],
                "text": "Paraphrasing of Chinese Utterances"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In this paper, a pattern-based approach to paraphrase is proposed for which only morphological analysis is required and a pattern construction method is described through which paraphrasing patterns can be efficiently learned from a paraphrase corpus and human experience."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144865353"
                        ],
                        "name": "B. Pang",
                        "slug": "B.-Pang",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Pang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Pang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 236
                            }
                        ],
                        "text": "The success of Statistical Machine Translation (SMT) has sparked a successful line of investigation that treats paraphrase acquisition and generation essentially as a monolingual machine translation problem (e.g., Barzilay & Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Finch et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 207
                            }
                        ],
                        "text": "The success of Statistical Machine Translation (SMT) has sparked a successful line of investigation that treats paraphrase acquisition and generation essentially as a monolingual machine translation problem (e.g., Barzilay & Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Finch et al. , 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11728052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b48af24cd360d6b0a3dd25424550c28bf97bc1ce",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a syntax-based algorithm that automatically builds Finite State Automata (word lattices) from semantically equivalent translation sets. These FSAs are good representations of paraphrases. They can be used to extract lexical and syntactic paraphrase pairs and to generate new, unseen sentences that express the same meaning as the sentences in the input sets. Our FSAs can also predict the correctness of alternative semantic renderings, which may be used to evaluate the quality of translations."
            },
            "slug": "Syntax-based-Alignment-of-Multiple-Translations:-Pang-Knight",
            "title": {
                "fragments": [],
                "text": "Syntax-based Alignment of Multiple Translations: Extracting Paraphrases and Generating New Sentences"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A syntax-based algorithm that automatically builds Finite State Automata (word lattices) from semantically equivalent translation sets that are good representations of paraphrases and can predict the correctness of alternative semantic renderings, which may be used to evaluate the quality of translations."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683412"
                        ],
                        "name": "Pascale Fung",
                        "slug": "Pascale-Fung",
                        "structuredName": {
                            "firstName": "Pascale",
                            "lastName": "Fung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascale Fung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31473834"
                        ],
                        "name": "P. Cheung",
                        "slug": "P.-Cheung",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Cheung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cheung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6568389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bc960477fe06e20c6672ff734d0ebfcc329860c",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a completely unsupervised method for mining parallel sentences from quasi-comparable bilingual texts which have very different sizes, and which include both in-topic and off-topic documents. We discuss and analyze different bilingual corpora with various levels of comparability. We propose that while better document matching leads to better parallel sentence extraction, better sentence matching also leads to better document matching. Based on this, we use multi-level bootstrapping to improve the alignments between documents, sentences, and bilingual word pairs, iteratively. Our method is the first method that does not rely on any supervised training data, such as a sentence-aligned corpus, or temporal information, such as the publishing date of a news article. It is validated by experimental results that show a 23% improvement over a method without multilevel bootstrapping."
            },
            "slug": "Multi-level-Bootstrapping-For-Extracting-Parallel-a-Fung-Cheung",
            "title": {
                "fragments": [],
                "text": "Multi-level Bootstrapping For Extracting Parallel Sentences From a Quasi-Comparable Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This work proposes a completely unsupervised method for mining parallel sentences from quasi-comparable bilingual texts which have very different sizes, and which include both in-topic and off-topic documents, and uses multi-level bootstrapping to improve the alignments between documents, sentences, and bilingual word pairs."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11468390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d1e736b2bf090470b5d7e7b94f944c83ada59c5",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Current research in automatic single-document summarization is dominated by two effective, yet nave approaches: summarization by sentence extraction and headline generation via bagof-words models. While successful in some tasks, neither of these models is able to adequately capture the large set of linguistic devices utilized by humans when they produce summaries. One possible explanation for the widespread use of these models is that good techniques have been developed to extract appropriate training data for them from existing document/abstract and document/ headline corpora. We believe that future progress in automatic summarization will be driven both by the development of more sophisticated, linguistically informed models, as well as a more effective leveraging of document/abstract corpora. In order to open the doors to simultaneously achieving both of these goals, we have developed techniques for automatically producing word-to-word and phrase-to-phrase alignments between documents and their human-written abstracts. These alignments make explicit the correspondences that exist in such document/abstract pairs and create a potentially rich data source from which complex summarization algorithms may learn. This paper describes experiments we have carried out to analyze the ability of humans to perform such alignments, and based on these analyses, we describe experiments for creating them automatically. Our model for the alignment task is based on an extension of the standard hidden Markov model and learns to create alignments in a completely unsupervised fashion. We describe our model in detail and present experimental results that show that our model is able to learn to reliably identify word- and phrase-level alignments in a corpus of (document, abstract) pairs."
            },
            "slug": "Induction-of-Word-and-Phrase-Alignments-for-Daum\u00e9-Marcu",
            "title": {
                "fragments": [],
                "text": "Induction of Word and Phrase Alignments for Automatic Document Summarization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The model for the alignment task is based on an extension of the standard hidden Markov model and learns to create alignments in a completely unsupervised fashion, and experimental results show that the model is able to learn to reliably identify word- and phrase-level alignings in a corpus of (document, abstract) pairs."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987548"
                        ],
                        "name": "A. Finch",
                        "slug": "A.-Finch",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Finch",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Finch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110694221"
                        ],
                        "name": "Taro Watanabe",
                        "slug": "Taro-Watanabe",
                        "structuredName": {
                            "firstName": "Taro",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taro Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697510"
                        ],
                        "name": "Y. Akiba",
                        "slug": "Y.-Akiba",
                        "structuredName": {
                            "firstName": "Yasuhiro",
                            "lastName": "Akiba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Akiba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698363"
                        ],
                        "name": "E. Sumita",
                        "slug": "E.-Sumita",
                        "structuredName": {
                            "firstName": "Eiichiro",
                            "lastName": "Sumita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sumita"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 275
                            }
                        ],
                        "text": "The success of Statistical Machine Translation (SMT) has sparked a successful line of investigation that treats paraphrase acquisition and generation essentially as a monolingual machine translation problem (e.g., Barzilay & Lee, 2003; Pang et al., 2003; Quirk et al., 2004; Finch et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60082508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7f6bcedcd3d3ef0af17e33a063f6ffd8bfb3e56",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents two statistically-based methods of automatically generating paraphrases for sentences; one based on direct statistical machine translation, the other based on data-oriented techniques. These paraphrasers are evaluated by human judges, and compared to both human paraphrases and those generated by a simple baseline model. The data-oriented approach proved to be the most successful in this evaluation and a second experiment was conducted to determine the usefulness of machine-generated paraphrases when used to expand the reference set used for machine translation evaluation. Varying numbers of synthetic paraphrases were mixed with varying numbers of real references to determine the circumstances under which the addition of synthetic paraphrases might be useful. Nine different machine translation systems were evaluated in this study using scores from nine human judges. Three machine translation evaluation schemes were used to perform the machine translation evaluation: BLEU, NIST and mWER. The results show that the usefulness of the synthetic paraphrases depends on which of the machine translation evaluation methods is used. The paraphrases degraded the NIST performance, but improved the evaluation performance of both BLEU and mWER."
            },
            "slug": "Paraphrasing-as-Machine-Translation-Finch-Watanabe",
            "title": {
                "fragments": [],
                "text": "Paraphrasing as Machine Translation (\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u7279\u96c6\u53f7\u300c\u8a00\u3044\u63db\u3048\u300d)"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Two statistically-based methods of automatically generating paraphrases for sentences are presented; one based on direct statistical machine translation, the other based on data-oriented techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125776"
                        ],
                        "name": "Chris Brockett",
                        "slug": "Chris-Brockett",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Brockett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Brockett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 94
                            }
                        ],
                        "text": "Some initial efforts using game formats for elicitation are presented in Chklovski (2005) and Brockett & Dolan (2005)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 29
                            }
                        ],
                        "text": "More details can be found in Brockett and Dolan (2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 181
                            }
                        ],
                        "text": "We show separately that the results of training a classifier on the present corpus may be inferior to other training sets, though better than crude string or text-based heuristics (Brockett & Dolan, 2005)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16350920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2de9a14513cb66d11cbe4d6e40c517824444b342",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of semantic equivalence, or paraphrase, is a fundamental one for applications that \u201cunderstand\u201d natural language. Learned approaches to this problem face a lack of colloquial training data with which to build models. This paper describes, Echo Chamber, a game aimed at collecting sentential paraphrases from web users. Much of our current focus is designing a framework that makes this potentially burdensome task engaging and challenging. The game draws on elements of enduring pen-and-paper games such as Battleship and Hangman, and incorporates a time component to impart a sense of urgency. In the final version, it is intended that automated validation of input will ensure that the game is scalable and can collect high quality data without editorial intervention. In this paper, we discuss design considerations and issues emerging from the prototype of this game."
            },
            "slug": "Echo-Chamber:-A-Game-for-Eliciting-a-Colloquial-Brockett-Dolan",
            "title": {
                "fragments": [],
                "text": "Echo Chamber: A Game for Eliciting a Colloquial Paraphrase Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Echo Chamber is a game aimed at collecting sentential paraphrases from web users, and it is intended that automated validation of input will ensure that the game is scalable and can collect high quality data without editorial intervention."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI Spring Symposium: Knowledge Collection from Volunteer Contributors"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2218418"
                        ],
                        "name": "Timothy Chklovski",
                        "slug": "Timothy-Chklovski",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Chklovski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy Chklovski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 73
                            }
                        ],
                        "text": "Some initial efforts using game formats for elicitation are presented in Chklovski (2005) and Brockett & Dolan (2005)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6010814,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4732eed8e47416284b647daa20fc7f76a1dd12c2",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A variety of applications can benefit from broad and detailed repositories of linguistic and world knowledge. An emerging approach to acquiring such repositories is to collect them from volunteer contributors. To increase the volume of contributions, some deployed systems for collecting volunteer-contributed knowledge offer recognition or prizes to those who provide the highest volume of contributions. However, rewarding for volume alone can encourage irresponsible contributions by unscrupulous participants. In this paper, we present an approach to collection from volunteers which incents responsible contributions. Rather than asking contributors to simply enter knowledge, our approach is to collect additional answers by asking contributors to guess partially obfuscated answers. To test the approach, we have implemented an online game, 1001 Paraphrases (http://aigames.org/paraphrase.html), and deployed it to collect 20,944 entries paraphrasing 400 statements. We present preliminary observations and lessons learned on the success of the approach."
            },
            "slug": "1001-Paraphrases:-Incenting-Responsible-in-from-Chklovski",
            "title": {
                "fragments": [],
                "text": "1001 Paraphrases: Incenting Responsible Contributions in Collecting Paraphrases from Volunteers"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper presents an approach to collection from volunteers which incents responsible contributions by asking contributors to guess partially obfuscated answers in an online game, 1001 Paraphrases."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI Spring Symposium: Knowledge Collection from Volunteer Contributors"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": false,
            "numCitedBy": 13574,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 115
                            }
                        ],
                        "text": "(Vapnik, 1995), in this case an implementation of the Sequential Minimal Optimization (SMO) algorithm described in Platt (1999), 2 which has been shown to be useful in text classification tasks (Dumais 1998; Dumais et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5219389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de2df29b0a0312de7270c3f5a0af6af5645cf91a",
            "isKey": false,
            "numCitedBy": 4470,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present and compare various methods for computing word alignments using statistical or heuristic models. We consider the five alignment models presented in Brown, Della Pietra, Della Pietra, and Mercer (1993), the hidden Markov alignment model, smoothing techniques, and refinements. These statistical models are compared with two heuristic models based on the Dice coefficient. We present different methods for combining word alignments to perform a symmetrization of directed statistical alignment models. As evaluation criterion, we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment. We evaluate the models on the German-English Verbmobil task and the French-English Hansards task. We perform a detailed analysis of various design decisions of our statistical alignment system and evaluate these on training corpora of various sizes. An important result is that refined alignment models with a first-order dependence and a fertility model yield significantly better results than simple heuristic models. In the Appendix, we present an efficient training algorithm for the alignment models presented."
            },
            "slug": "A-Systematic-Comparison-of-Various-Statistical-Och-Ney",
            "title": {
                "fragments": [],
                "text": "A Systematic Comparison of Various Statistical Alignment Models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An important result is that refined alignment models with a first-order dependence and a fertility model yield significantly better results than simple heuristic models."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1947728"
                        ],
                        "name": "C. Corley",
                        "slug": "C.-Corley",
                        "structuredName": {
                            "firstName": "Courtney",
                            "lastName": "Corley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Corley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145557251"
                        ],
                        "name": "Rada Mihalcea",
                        "slug": "Rada-Mihalcea",
                        "structuredName": {
                            "firstName": "Rada",
                            "lastName": "Mihalcea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rada Mihalcea"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4948322,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "6fc4a08abd9f52013ad1c598aadc7ef60aa0d7d2",
            "isKey": false,
            "numCitedBy": 358,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a knowledge-based method for measuring the semantic-similarity of texts. While there is a large body of previous work focused on finding the semantic similarity of concepts and words, the application of these word-oriented methods to text similarity has not been yet explored. In this paper, we introduce a method that combines word-to-word similarity metrics into a text-to-text metric, and we show that this method outperforms the traditional text similarity metrics based on lexical matching."
            },
            "slug": "Measuring-the-Semantic-Similarity-of-Texts-Corley-Mihalcea",
            "title": {
                "fragments": [],
                "text": "Measuring the Semantic Similarity of Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method that combines word- to-word similarity metrics into a text-to-text metric is introduced, and it is shown that this method outperforms the traditional text similarity metrics based on lexical matching."
            },
            "venue": {
                "fragments": [],
                "text": "EMSEE@ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002316"
                        ],
                        "name": "F. Och",
                        "slug": "F.-Och",
                        "structuredName": {
                            "firstName": "Franz",
                            "lastName": "Och",
                            "middleNames": [
                                "Josef"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Och"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5284722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9214ebe91454e6369720136ab7dd990d52a07d4",
            "isKey": false,
            "numCitedBy": 1192,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present and compare various single-word based alignment models for statistical machine translation. We discuss the five IBM alignment models, the Hidden-Markov alignment model, smoothing techniques and various modifications. We present different methods to combine alignments. As evaluation criterion we use the quality of the resulting Viterbi alignment compared to a manually produced reference alignment. We show that models with a first-order dependence and a fertility model lead to significantly better results than the simple models IBM-1 or IBM-2, which are not able to go beyond zero-order dependencies."
            },
            "slug": "Improved-Statistical-Alignment-Models-Och-Ney",
            "title": {
                "fragments": [],
                "text": "Improved Statistical Alignment Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that models with a first-order dependence and a fertility model lead to significantly better results than the simple models IBM-1 or IBM-2, which are not able to go beyond zero-order dependencies."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 91
                            }
                        ],
                        "text": "It has been observed that the mean lexical overlap in the corpus is a relatively high 0.7 (Weeds et al, 2005), suggesting that more lexically divergent examples will be needed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Distributional Similarity of Subparses"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1099857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4de39c94e340a108fff01a90a67b0c17c86fb981",
            "isKey": false,
            "numCitedBy": 5910,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter describes a new algorithm for training Support Vector Machines: Sequential Minimal Optimization, or SMO. Training a Support Vector Machine (SVM) requires the solution of a very large quadratic programming (QP) optimization problem. SMO breaks this large QP problem into a series of smallest possible QP problems. These small QP problems are solved analytically, which avoids using a time-consuming numerical QP optimization as an inner loop. The amount of memory required for SMO is linear in the training set size, which allows SMO to handle very large training sets. Because large matrix computation is avoided, SMO scales somewhere between linear and quadratic in the training set size for various test problems, while a standard projected conjugate gradient (PCG) chunking algorithm scales somewhere between linear and cubic in the training set size. SMO's computation time is dominated by SVM evaluation, hence SMO is fastest for linear SVMs and sparse data sets. For the MNIST database, SMO is as fast as PCG chunking; while for the UCI Adult database and linear SVMs, SMO can be more than 1000 times faster than the PCG chunking algorithm."
            },
            "slug": "Fast-training-of-support-vector-machines-using-in-Platt",
            "title": {
                "fragments": [],
                "text": "Fast training of support vector machines using sequential minimal optimization, advances in kernel methods"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "SMO breaks this large quadratic programming problem into a series of smallest possible QP problems, which avoids using a time-consuming numerical QP optimization as an inner loop and hence SMO is fastest for linear SVMs and sparse data sets."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60502900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c4da62e9e89e65ac78ee271e424e8b498053e8c",
            "isKey": false,
            "numCitedBy": 5544,
            "numCiting": 260,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction to support vector learning roadmap. Part 1 Theory: three remarks on the support vector method of function estimation, Vladimir Vapnik generalization performance of support vector machines and other pattern classifiers, Peter Bartlett and John Shawe-Taylor Bayesian voting schemes and large margin classifiers, Nello Cristianini and John Shawe-Taylor support vector machines, reproducing kernel Hilbert spaces, and randomized GACV, Grace Wahba geometry and invariance in kernel based methods, Christopher J.C. Burges on the annealed VC entropy for margin classifiers - a statistical mechanics study, Manfred Opper entropy numbers, operators and support vector kernels, Robert C. Williamson et al. Part 2 Implementations: solving the quadratic programming problem arising in support vector classification, Linda Kaufman making large-scale support vector machine learning practical, Thorsten Joachims fast training of support vector machines using sequential minimal optimization, John C. Platt. Part 3 Applications: support vector machines for dynamic reconstruction of a chaotic system, Davide Mattera and Simon Haykin using support vector machines for time series prediction, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel. Part 4 Extensions of the algorithm: reducing the run-time complexity in support vector machines, Edgar E. Osuna and Federico Girosi support vector regression with ANOVA decomposition kernels, Mark O. Stitson et al support vector density estimation, Jason Weston et al combining support vector and mathematical programming methods for classification, Bernhard Scholkopf et al."
            },
            "slug": "Advances-in-kernel-methods:-support-vector-learning-Sch\u00f6lkopf-Burges",
            "title": {
                "fragments": [],
                "text": "Advances in kernel methods: support vector learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Support vector machines for dynamic reconstruction of a chaotic system, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 1
                            }
                        ],
                        "text": "(Vapnik, 1995), in this case an implementation of the Sequential Minimal Optimization (SMO) algorithm described in Platt (1999),2 which has been shown to be useful in text classification tasks (Dumais 1998; Dumais et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(Vapnik, 1995), in this case an implementation of the Sequential Minimal Optimization (SMO) algorithm described in Platt (1999), which has been shown to be useful in text classification tasks (Dumais 1998; Dumais et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 91
                            }
                        ],
                        "text": "It has been observed that the mean lexical overlap in the corpus is a relatively high 0.7 (Weeds et al, 2005), suggesting that more lexically divergent examples will be needed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Distributional Similarity of Subparses"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073956273"
                        ],
                        "name": "Shi Bing",
                        "slug": "Shi-Bing",
                        "structuredName": {
                            "firstName": "Shi",
                            "lastName": "Bing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shi Bing"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 194
                            }
                        ],
                        "text": "(Vapnik, 1995), in this case an implementation of the Sequential Minimal Optimization (SMO) algorithm described in Platt (1999), 2 which has been shown to be useful in text classification tasks (Dumais 1998; Dumais et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 207
                            }
                        ],
                        "text": "(Vapnik, 1995), in this case an implementation of the Sequential Minimal Optimization (SMO) algorithm described in Platt (1999),2 which has been shown to be useful in text classification tasks (Dumais 1998; Dumais et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62932125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a923a81a8f5069d50f827c22abe4546385603b4",
            "isKey": false,
            "numCitedBy": 463,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Text categorization-assignment of natural language texts to one or more predefined categories based on their content-is an important component in many information organization and management tasks.Different automatic learning algorithms for text categori-zation have different classification accuracy.Very accurate text classifiers can be learned automatically from training examples."
            },
            "slug": "Inductive-learning-algorithms-and-representations-Bing",
            "title": {
                "fragments": [],
                "text": "Inductive learning algorithms and representations for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Text categorization-assignment of natural language texts to one or more predefined categories based on their content-is an important component in many information organization and management tasks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154179"
                        ],
                        "name": "V. Levenshtein",
                        "slug": "V.-Levenshtein",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Levenshtein",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Levenshtein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60827152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2f8876482c97e804bb50a5e2433881ae31d0cdd",
            "isKey": false,
            "numCitedBy": 10969,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Binary-codes-capable-of-correcting-deletions,-and-Levenshtein",
            "title": {
                "fragments": [],
                "text": "Binary codes capable of correcting deletions, insertions, and reversals"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090910179"
                        ],
                        "name": "Treebank Penn",
                        "slug": "Treebank-Penn",
                        "structuredName": {
                            "firstName": "Treebank",
                            "lastName": "Penn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Treebank Penn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 67371551,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3fa4a8191e37b601877716858e6b1026e66e3c5c",
            "isKey": false,
            "numCitedBy": 1127,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Linguistic-Data-Consortium-Penn",
            "title": {
                "fragments": [],
                "text": "Linguistic Data Consortium"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714577"
                        ],
                        "name": "S. D. Pietra",
                        "slug": "S.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pietra",
                            "middleNames": [
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13259913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab7b5917515c460b90451e67852171a531671ab8",
            "isKey": false,
            "numCitedBy": 4744,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations of one another. We define a concept of word-by-word alignment between such pairs of sentences. For any given pair of such sentences each of our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable of these alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair of sentences. We have a great deal of data in French and English from the proceedings of the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we feel that because our algorithms have minimal linguistic content they would work well on other pairs of languages. We also feel, again because of the minimal linguistic content of our algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus."
            },
            "slug": "The-Mathematics-of-Statistical-Machine-Translation:-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "The Mathematics of Statistical Machine Translation: Parameter Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus, given a set of pairs of sentences that are translations of one another."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2500077"
                        ],
                        "name": "Julie Weeds",
                        "slug": "Julie-Weeds",
                        "structuredName": {
                            "firstName": "Julie",
                            "lastName": "Weeds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julie Weeds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35258592"
                        ],
                        "name": "David J. Weir",
                        "slug": "David-J.-Weir",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Weir",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Weir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39877126"
                        ],
                        "name": "B. Keller",
                        "slug": "B.-Keller",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Keller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Keller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4903419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89c990323733e02999578d06ffd0e1c0cb0edba2",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This work explores computing distributional similarity between sub-parses, i. e., fragments of a parse tree, as an extension to general lexical distributional similarity techniques. In the same way that lexical distributional similarity is used to estimate lexical semantic similarity, we propose using distributional similarity between subparses to estimate the semantic similarity of phrases. Such a technique will allow us to identify paraphrases where the component words are not semantically similar. We demonstrate the potential of the method by applying it to a small number of examples and showing that the paraphrases are more similar than the non-paraphrases."
            },
            "slug": "The-Distributional-Similarity-of-Sub-Parses-Weeds-Weir",
            "title": {
                "fragments": [],
                "text": "The Distributional Similarity of Sub-Parses"
            },
            "venue": {
                "fragments": [],
                "text": "EMSEE@ACL"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 498,
                                "start": 436
                            }
                        ],
                        "text": "These, however, tend to be rather restricted in their domain (e.g. the ATR English-Chinese paraphrase corpus, which con-\nsists of translations of travel phrases (Zhang & Yamamoto, 2002)), are limited to short handcrafted predicates (e.g. the ATR JapaneseEnglish corpus (Shirai, et al., 2002)), or exhibit quality problems stemming from insufficient command of the target language by the translators of the documents in question, e.g. the Linguistic Data Consortium\u2019s Multiple-Translation Chinese Corpus (Huang et al., 2002)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 270
                            }
                        ],
                        "text": "\u2026(e.g. the ATR JapaneseEnglish corpus (Shirai, et al., 2002)), or exhibit quality problems stemming from insufficient command of the target language by the translators of the documents in question, e.g. the Linguistic Data Consortium\u2019s Multiple-Translation Chinese Corpus (Huang et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiple-Translation Chinese Corpus. Linguistic Data Consortium"
            },
            "venue": {
                "fragments": [],
                "text": "Multiple-Translation Chinese Corpus. Linguistic Data Consortium"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 58
                            }
                        ],
                        "text": "2 The pseudocode for SMO may be found in the appendi x of Platt (1999) Encarta Thesaurus: 125,054 word synonym pairs were extracted from the Encarta Thesaurus (Rooney, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 57
                            }
                        ],
                        "text": "2 The pseudocode for SMO may be found in the appendix of Platt (1999)\nEncarta Thesaurus: 125,054 word synonym pairs were extracted from the Encarta Thesaurus (Rooney, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 115
                            }
                        ],
                        "text": "(Vapnik, 1995), in this case an implementation of the Sequential Minimal Optimization (SMO) algorithm described in Platt (1999),2 which has been shown to be useful in text classification tasks (Dumais 1998; Dumais et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast Training of Support Vecto"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiple-Translation Chinese Corpus"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 227
                            }
                        ],
                        "text": "\u2026available for download at http://research.microsoft.com/research/nlp/msr_ paraphrase.htm, consists of 5801 pairs of sentences, each accompanied by a binary judgment indicating whether human raters considered the pair of sentences to be similar enough in meaning to be considered close paraphrases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Yasuhiro Akiba and Eiichiro Sumita Paraphrasing as Machine Translation"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Natural Language Processing"
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 33,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Automatically-Constructing-a-Corpus-of-Sentential-Dolan-Brockett/475354f10798f110d34792b6d88f31d6d5cb099e?sort=total-citations"
}