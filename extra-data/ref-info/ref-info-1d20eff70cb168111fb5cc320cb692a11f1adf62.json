{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34900218"
                        ],
                        "name": "E. Posner",
                        "slug": "E.-Posner",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Posner",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Posner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3250540"
                        ],
                        "name": "E. Rodemich",
                        "slug": "E.-Rodemich",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Rodemich",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rodemich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144694846"
                        ],
                        "name": "S. Venkatesh",
                        "slug": "S.-Venkatesh",
                        "structuredName": {
                            "firstName": "Santosh",
                            "lastName": "Venkatesh",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Venkatesh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 30
                            }
                        ],
                        "text": "It has previously been shown (McEliece et al., 1987), however, that the extension from binary to real valued weights only changes the capacity of the Hopfield Model by a factor of r/2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 19
                            }
                        ],
                        "text": "(See, for example, McEliece et al. (1987) or Abu-Mostafa and St. Jacques (1985)) Recently Baum et al. (1986) have constructed feedforward nets with considerably better capacity and retrieval capabilities than known feedback designs for associative memory."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14340808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5db1cc4a5ea1fcf017ceac7f07496292f37a9a2",
            "isKey": false,
            "numCitedBy": 897,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Techniques from coding theory are applied to study rigorously the capacity of the Hopfield associative memory. Such a memory stores n -tuple of \\pm 1 's. The components change depending on a hard-limited version of linear functions of all other components. With symmetric connections between components, a stable state is ultimately reached. By building up the connection matrix as a sum-of-outer products of m fundamental memories, one hopes to be able to recover a certain one of the m memories by using an initial n -tuple probe vector less than a Hamming distance n/2 away from the fundamental memory. If m fundamental memories are chosen at random, the maximum asympotic value of m in order that most of the m original memories are exactly recoverable is n/(2 \\log n) . With the added restriction that every one of the m fundamental memories be recoverable exactly, m can be no more than n/(4 \\log n) asymptotically as n approaches infinity. Extensions are also considered, in particular to capacity under quantization of the outer-product connection matrix. This quantized memory capacity problem is closely related to the capacity of the quantized Gaussian channel."
            },
            "slug": "The-capacity-of-the-Hopfield-associative-memory-McEliece-Posner",
            "title": {
                "fragments": [],
                "text": "The capacity of the Hopfield associative memory"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Techniques from coding theory are applied to study rigorously the capacity of the Hopfield associative memory, in particular to capacity under quantization of the outer-product connection matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Cover (1965) gave a count of the number of dichotomies implementable by a single threshold unit."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 1
                            }
                        ],
                        "text": "(Cover, 1965)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 112
                            }
                        ],
                        "text": "I will extend this counting argument to the case of real valued weights by using a function counting theorem of Cover (1965), and will find that in this case Nc 2 Nellogz(N)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "Indeed, by applying a function counting theorem of Cover (1965), it was"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 162
                            }
                        ],
                        "text": "The input to such threshold units was frequently taken to be either s itself, or some vector 4(s) whose components 4i are polynomials of the components Si (e.g., Cover, 1965; Nilsson, 1965)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 69
                            }
                        ],
                        "text": "The literature on feedforward threshold logic includes, for example, Cover (1965), Nilsson (1965), Minsky and Papert (1969), Dertouzas (1965), Muroga (1979), Lewis and Coates (1967), and Hu (1965)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18251470,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "445ad69010658097fc317f7b83f1198179eebae8",
            "isKey": true,
            "numCitedBy": 1840,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops the separating capacities of families of nonlinear decision surfaces by a direct application of a theorem in classical combinatorial geometry. It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes. Applying these ideas to the vertices of a binary n-cube yields bounds on the number of spherically, quadratically, and, in general, nonlinearly separable Boolean functions of n variables. It is shown that the set of all surfaces which separate a dichotomy of an infinite, random, separable set of pattern vectors can be characterized, on the average, by a subset of only 2d extreme pattern vectors. In addition, the problem of generalizing the classifications on a labeled set of pattern points to the classification of a new point is defined, and it is found that the probability of ambiguous generalization is large unless the number of training patterns exceeds the capacity of the set of separating surfaces."
            },
            "slug": "Geometrical-and-Statistical-Properties-of-Systems-Cover",
            "title": {
                "fragments": [],
                "text": "Geometrical and Statistical Properties of Systems of Linear Inequalities with Applications in Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Electron. Comput."
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145020250"
                        ],
                        "name": "R. P. Gorman",
                        "slug": "R.-P.-Gorman",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Gorman",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. P. Gorman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8859486,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e631e48fabecf45c1898bc452e5b9494419fc59",
            "isKey": false,
            "numCitedBy": 268,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Massively parallel learning networks are applied to the classification of sonar returns from two undersea targets and the ability of networks to correctly classify both training and testing examples is studied. Networks with an intermediate layer of hidden processing units achieved a classification accuracy as high as 100% on a training set of 104 returns. These networks correctly classified a test set of 104 returns not contained in the training set with an accuracy of up to 90.4%. Networks without an intermediate layer of processing units achieved only 73.1% correct on the same test set. Performance improved and the variability due to the initial conditions for training decreased with the number of hidden units. The effect of training set design on test set performance was also examined. The performance of a three-layered network was better than trained human listeners and the network generalized better than a nearest-neighbor classifier. >"
            },
            "slug": "Learned-classification-of-sonar-targets-using-a-Gorman-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Learned classification of sonar targets using a massively parallel network"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The performance of a three-layered network was better than trained human listeners and the network generalized better than a nearest-neighbor classifier."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 156
                            }
                        ],
                        "text": "Recent intense interest in the storage capacity of threshold nets with feedback was stimulated by Hopfield\u2019s construction of a model for associative memory (Hopfield, 1982)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 97
                            }
                        ],
                        "text": "SUMMARY\nThe Boltzman machine (Ackley et al., 1985) and the Hopfield model of associative memory (Hopfield, 1982) have stimulated a resurgence in interest in circuits of threshold units."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 784288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98b4d4e24aab57ab4e1124ff8106909050645cfa",
            "isKey": false,
            "numCitedBy": 16694,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices."
            },
            "slug": "Neural-networks-and-physical-systems-with-emergent-Hopfield",
            "title": {
                "fragments": [],
                "text": "Neural networks and physical systems with emergent collective computational abilities."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A model of a system having a large number of simple equivalent components, based on aspects of neurobiology but readily adapted to integrated circuits, produces a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2647026"
                        ],
                        "name": "A. Blumer",
                        "slug": "A.-Blumer",
                        "structuredName": {
                            "firstName": "Anselm",
                            "lastName": "Blumer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blumer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683946"
                        ],
                        "name": "A. Ehrenfeucht",
                        "slug": "A.-Ehrenfeucht",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Ehrenfeucht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ehrenfeucht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794034"
                        ],
                        "name": "Manfred K. Warmuth",
                        "slug": "Manfred-K.-Warmuth",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Warmuth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred K. Warmuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 140
                            }
                        ],
                        "text": "\u2026dimension of F is defined as the smallest N such that no set S of size N + 1\nCAPABILITIES OF MULTILAYER PERCEPTRONS 211\nis shattered by F. Blumer et al. (1986) have proved remarkable theorems which classify learnable concepts with the Vapnik-Chernovenkis (V-C) dimension and rigorize\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5225434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29b6251c84def0cbd35397c71fada0d22cd9409c",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend Valiant's learnability model to learning classes of concepts defined by regions in Euclidean space E\". Our methods lead to a unified treatment of some of Valiant's results, along with previous results of Pearl and Devroye and Wagner on distribution-free convergence of certain pattern recognition algorithms. We show that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned. Using this parameter, we analyze the complexity and closure properties of learnable classes. Authors A. Blumer and D. Haussler gratefully acknowledge the support of NSF grant IST-8317918, author A. Ehrenfeucht the support of NSF grant MCS-8305245, and author M. Warmuth the support of the Faculty Research Committee of the University of California at Santa Cruz. Part of this work was done while A. Blumer was visiting the University of California at Santa Cruz and M. Warmuth the Univer-"
            },
            "slug": "Classifying-learnable-geometric-concepts-with-the-Blumer-Ehrenfeucht",
            "title": {
                "fragments": [],
                "text": "Classifying learnable geometric concepts with the Vapnik-Chervonenkis dimension"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the essential condition for distribution-free learnability is finiteness of the Vapnik-Chervonenkis dimension, a simple combinatorial parameter of the class of concepts to be learned."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '86"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 45617668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7649b11f66787cdd09ff146f3203198961e512c",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Random-problems-Abu-Mostafa",
            "title": {
                "fragments": [],
                "text": "Random problems"
            },
            "venue": {
                "fragments": [],
                "text": "J. Complex."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2020074"
                        ],
                        "name": "A. Lapedes",
                        "slug": "A.-Lapedes",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Lapedes",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lapedes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542113"
                        ],
                        "name": "R. Farber",
                        "slug": "R.-Farber",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Farber",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Farber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 10
                            }
                        ],
                        "text": "See also (Lapedes and Farber, 1987)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60720876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d981c7637fc39335cf53cfa792a0f8d5b66ec6e",
            "isKey": false,
            "numCitedBy": 626,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The backpropagation learning algorithm for neural networks is developed into a formalism for nonlinear signal processing. We illustrate the method by selecting two common topics in signal processing, prediction and system modelling, and show that nonlinear applications can be handled extremely well by using neural networks. The formalism is a natural, nonlinear extension of the linear Least Mean Squares algorithm commonly used in adaptive signal processing. Simulations are presented that document the additional performance achieved by using nonlinear neural networks. First, we demonstrate that the formalism may be used to predict points in a highly chaotic time series with orders of magnitude increase in accuracy over conventional methods including the Linear Predictive Method and the Gabor-Volterra-Weiner Polynomial Method. Deterministic chaos is thought to be involved in many physical situations including the onset of turbulence in fluids, chemical reactions and plasma physics. Secondly, we demonstrate the use of the formalism in nonlinear system modelling by providing a graphic example in which it is clear that the neural network has accurately modelled the nonlinear transfer function. It is interesting to note that the formalism provides explicit, analytic, global, approximations to the nonlinear maps underlying the various time series. Furthermore, the neural net more\u00a0\u00bb seems to be extremely parsimonious in its requirements for data points from the time series. We show that the neural net is able to perform well because it globally approximates the relevant maps by performing a kind of generalized mode decomposition of the maps. 24 refs., 13 figs. \u00ab\u00a0less"
            },
            "slug": "Nonlinear-signal-processing-using-neural-networks:-Lapedes-Farber",
            "title": {
                "fragments": [],
                "text": "Nonlinear signal processing using neural networks: Prediction and system modelling"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is demonstrated that the backpropagation learning algorithm for neural networks may be used to predict points in a highly chaotic time series with orders of magnitude increase in accuracy over conventional methods including the Linear Predictive Method and the Gabor-Volterra-Weiner Polynomial Method."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145773547"
                        ],
                        "name": "J. Jacques",
                        "slug": "J.-Jacques",
                        "structuredName": {
                            "firstName": "Jeannine-Marie",
                            "lastName": "Jacques",
                            "middleNames": [
                                "St."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jacques"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14068666,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad1698c1f463a396c25e18520ff73a30f8b5cb2c",
            "isKey": false,
            "numCitedBy": 260,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The information capacity of general forms of memory is formalized. The number of bits of information that can be stored in the Hopfield model of associative memory is estimated. It is found that the asymptotic information capacity of a Hopfield network of N neurons is of the order N^{3} b. The number of arbitrary state vectors that can be made stable in a Hopfield network of N neurons is proved to be bounded above by N ."
            },
            "slug": "Information-capacity-of-the-Hopfield-model-Abu-Mostafa-Jacques",
            "title": {
                "fragments": [],
                "text": "Information capacity of the Hopfield model"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The information capacity of general forms of memory is formalized and the number of bits of information that can be stored in the Hopfield model of associative memory is estimated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34870156"
                        ],
                        "name": "D. Hampel",
                        "slug": "D.-Hampel",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Hampel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hampel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2662980"
                        ],
                        "name": "R. Winder",
                        "slug": "R.-Winder",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Winder",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Winder"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 51652246,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87b618246c0f2ec41bbd79503cf0b051b102e504",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A threshold gate has binary inputs and outputs just like any other logic gate. The difference, however, is that in the threshold gate the inputs may be weighted and, eventually, a binary decision made as to whether the total weight is more or less than some reference. This principle of weighting and summing the inputs rather than simply noting the presence of all inputs as high (as in an AND gate) or one input high (as in an OR gate) is the reason that a threshold gate can tell more about the state of the inputs, thus providing greater ``logic power.'' This article gives some examples of the applicability of threshold logic, as well as an integrated-circuit approach for building arrays of versatile threshold gates. In addition, some logic designs are described and compared with conventional ECL implementations."
            },
            "slug": "Threshold-logic-Hampel-Winder",
            "title": {
                "fragments": [],
                "text": "Threshold logic"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article gives some examples of the applicability of threshold logic, as well as an integrated-circuit approach for building arrays of versatile threshold gates."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Spectrum"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140752"
                        ],
                        "name": "Charles R. Rosenberg",
                        "slug": "Charles-R.-Rosenberg",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Rosenberg",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles R. Rosenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 236
                            }
                        ],
                        "text": "They have been tested on a variety of highly structured, toy problems such as recognizing symmetries (Rumelhart et al., 1986) as well as on some (perhaps relatively simple) real world problems (Sejnowski and Rosenberg, 1987; Gorman and Sejnowski, 1987; Werbos and Titus, 1978)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12926318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de996c32045df6f7b404dda2a753b6a9becf3c08",
            "isKey": false,
            "numCitedBy": 1885,
            "numCiting": 229,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes NETtalk, a class of massively-parallel network systems that learn to convert English text to speech. The memory representations for pronunciations are learned by practice and are shared among many processing units. The performance of NETtalk has some similarities with observed human performance. (i) The learning follows a power law. (ii) The more words the network learns, the better it is at generalizing and correctly pronouncing new words, (iii) The performance of the network degrades very slowly as connections in the network are damaged: no single link or processing unit is essential. (iv) Relearning after damage is much faster than learning during the original training. (v) Distributed or spaced practice is more effective for long-term retention than massed practice. Network models can be constructed that have the same performance and learning characteristics on a particular task, but differ completely at the levels of synaptic strengths and single-unit responses. However, hierarchical clustering techniques applied to NETtalk reveal that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units. This suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations."
            },
            "slug": "Parallel-Networks-that-Learn-to-Pronounce-English-Sejnowski-Rosenberg",
            "title": {
                "fragments": [],
                "text": "Parallel Networks that Learn to Pronounce English Text"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "H hierarchical clustering techniques applied to NETtalk reveal that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units, which suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations."
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756533"
                        ],
                        "name": "G. Chaitin",
                        "slug": "G.-Chaitin",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Chaitin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Chaitin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 136
                            }
                        ],
                        "text": "The question of whether a given algorithm is the shortest representing a given function is in principle undecidable (Kholmogorov, 1965; Chaitin, 1974), so that one typically chooses some heuristic for finding a relatively terse algorithmic description."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206731887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a4f05562a59842ce2107e2e858c8c8a7302329c",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper attempts to describe, in nontechnical language, some of the concepts and methods of one school of thought regarding computational complexity. It applies the viewpoint of information theory to computers. This will first lead us to a definition of the degree of randomness of individual binary strings, and then to an information-theoretic version of Godel's theorem on the limitations of the axiomatic method. Finally, we will examine in the light of these ideas the scientific method and yon Neumann's views on the basic conceptual problems of biology."
            },
            "slug": "Information-theoretic-computation-complexity-Chaitin",
            "title": {
                "fragments": [],
                "text": "Information-theoretic computation complexity"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A definition of the degree of randomness of individual binary strings is led to and an information-theoretic version of Godel's theorem on the limitations of the axiomatic method is examined."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1847175"
                        ],
                        "name": "M. Minsky",
                        "slug": "M.-Minsky",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Minsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Minsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2434678"
                        ],
                        "name": "S. Papert",
                        "slug": "S.-Papert",
                        "structuredName": {
                            "firstName": "Seymour",
                            "lastName": "Papert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Papert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 81
                            }
                        ],
                        "text": "Interest declined when the limitations of single layers nets were made explicit (Minsky and Papert, 1969), but was revived by the discovery of the Boltzman machine (Ackley et al., 1985) and back propagation (Werbos, 1974; Parker, 1985; LeCun, 1985; Rumelhart et al., 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 99
                            }
                        ],
                        "text": "The literature on feedforward threshold logic includes, for example, Cover (1965), Nilsson (1965), Minsky and Papert (1969), Dertouzas (1965), Muroga (1979), Lewis and Coates (1967), and Hu (1965)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5400596,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f74ded11f72099d16591a1191d72262ae6b5f14a",
            "isKey": false,
            "numCitedBy": 3040,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Cambridge, Mass.: MIT Press, 1972. 2nd. ed. The book's aim is to seek general results from the close study of abstract version of devices known as perceptrons"
            },
            "slug": "Perceptrons-an-introduction-to-computational-Minsky-Papert",
            "title": {
                "fragments": [],
                "text": "Perceptrons - an introduction to computational geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The aim of this book is to seek general results from the close study of abstract version of devices known as perceptrons."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94013203"
                        ],
                        "name": "A. Gamba",
                        "slug": "A.-Gamba",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Gamba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gamba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699447"
                        ],
                        "name": "L. Gamberini",
                        "slug": "L.-Gamberini",
                        "structuredName": {
                            "firstName": "Luciano",
                            "lastName": "Gamberini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gamberini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064789637"
                        ],
                        "name": "G. Palmieri",
                        "slug": "G.-Palmieri",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Palmieri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Palmieri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089934192"
                        ],
                        "name": "R. Sanna",
                        "slug": "R.-Sanna",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Sanna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sanna"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 97
                            }
                        ],
                        "text": "Gamba and collaborators experimented with feedforward networks having two layers of perceptrons (Gamba et al., 1961; Borsellino and Gamba, 1961)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121274808,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "c3a20b9aa86033cec29f08e69f4bc81e8b329ae2",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The P A P A m a c h i n e , b u i l t in our I n s t i t u t e , has been d e s c r i b e d e l sewhere , a n d i t s a b i l i t y to recognize s imple g e o m e t r i c a l p a t t e r n s has been d e m o n s t r a t e d (1). I n t h e e x p e r i m e n t s r e p o r t e d here we w a n t e d to t e s t t he a b i l i t y of P A P A in r ecogn iz ing m o r e s o p h i s t i c a t e d (( c u l t u r a l ~) p a t t e r n s . B y th is t e r m we m e a n p a t t e r n s whose s igni f icance is g i v e n b y (( h i d d e n ru les ~) wh ich a re n o t o b v i o u s l y a p p a r e n t to a super f ic ia l obse rver . F o r e x a m p l e , in e x p e r i m e n t No. 1 (Sect i on 1 be low) we p r e s e n t e d a c h e c k e r b o a r d in w h i c h holes c o n n e c t e d b y r o o k m o v e s a n d k n i g h t m o v e s r e s p e c t i v e l y were g i v e n to t h e m a c h i n e fo r recogn i t i o n ; in e x p e r i m e n t No. 2 (Sect ion 2 be low) we c o d e d a few no te s f r o m B a c h ' s chora l s a n d f rom (~ f ake ~ mus ic m a d e b y one of us (L. GA~BERINI) a n d we a s k e d t h e m a c h i n e to l e a r n t hese two classes of p a t t e r n s . The r e su l t s t u r n e d ou t to be e x c e e d i n g l y e n c o u r a g i n g a n d we t h i n k t h a t th i s p r o v e s t h e (~ in t e l l i gence ~ of our m a c h i n e . G i v e n t h e a p p r o p r i a t e deve l o p m e n t b y i nc r ea s ing t h e n u m b e r of a s soc i a t i on un i t s , P A P A can be a dec is ion m a k i n g m a c h i n e t h a t , for i n s t ance , b y l ook ing a t a n e l e c t r i c a l w i r i ng d i a g r a m can dec ide w h e t h e r i t is a (~ good )~ one or no t , g i v e n t h e p e r t i n e n t i n s t r u c t i o n by examples. Or i t can b e c o m e a w e a t h e r f o r e c a s t i n g m a c h i n e w h e n shown e x a m p l e s of (~ g o o d )~ a n d (( b a d )~ f o r e c a s t i n g f r o m ~ c o l l e e t i sn of p h y s i c a l d a t a . I n o t h e r words , P A P A wil l beh~ve (( as if ~ i t h a d gue s se d t h e rules ."
            },
            "slug": "Further-experiments-with-PAPA-Gamba-Gamberini",
            "title": {
                "fragments": [],
                "text": "Further experiments with PAPA"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140752"
                        ],
                        "name": "Charles R. Rosenberg",
                        "slug": "Charles-R.-Rosenberg",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Rosenberg",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles R. Rosenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 194
                            }
                        ],
                        "text": "They have been tested on a variety of highly structured, toy problems such as recognizing symmetries (Rumelhart et al., 1986) as well as on some (perhaps relatively simple) real world problems (Sejnowski and Rosenberg, 1987; Gorman and Sejnowski, 1987; Werbos and Titus, 1978)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13921532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "406033f22b6a671b94bcbdfaf63070b7ce6f3e48",
            "isKey": false,
            "numCitedBy": 761,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Unrestricted English text can be converted to speech by applying phonological rules and handling exceptions with a look-up table. However, this approach is highly labor intensive since each entry and rule must be hand-crafted. NETtalk is an alternative approach that is based on an automated learning procedure for a parallel network of deterministic processing units. ~ f t e r ' training on a corpus of informal continuous speech, it achieves good performance and generalizes to novel words. The distributed internal representations of the phonological regularities discovered by the network are damage resistant."
            },
            "slug": "NETtalk:-a-parallel-network-that-learns-to-read-Sejnowski-Rosenberg",
            "title": {
                "fragments": [],
                "text": "NETtalk: a parallel network that learns to read aloud"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "NETtalk is an alternative approach that is based on an automated learning procedure for a parallel network of deterministic processing units that achieves good performance and generalizes to novel words."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319833"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064905984"
                        ],
                        "name": "Jim Titus",
                        "slug": "Jim-Titus",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Titus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Titus"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 264
                            }
                        ],
                        "text": "They have been tested on a variety of highly structured, toy problems such as recognizing symmetries (Rumelhart et al., 1986) as well as on some (perhaps relatively simple) real world problems (Sejnowski and Rosenberg, 1987; Gorman and Sejnowski, 1987; Werbos and Titus, 1978)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24278842,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "9c790c8e2d3bc565d59a91600dac0d8b4d1eedc4",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The \"compromise\" method is a new computer-based forecasting tool, available within the conversational CS package on the MIT Multics. Like regression (least squares) or new forms of Box-Jenkins methods, it estimates the parameters of a multivariate dynamic model and may be used for causal analysis or policy impact analysis. Unlike those maximum-likelihood methods, it does not assume that errors are \"white noise,\" random and normal. It follows the newer robust philosophy of trying to minimize estimation errors on the assumption that noise will be inextricably dirty. In the case of \"strong\" dynamic models\u00bfmodels which predict that changes in present variable values lead to comparable changes in future variable values it may reduce parameter errors by an order of magnitude. Forecasting errors will also be reduced, although the degree of reduction depends on how much randomness exists in the process. When we used the compromise method according to the new \"bias\" procedure, in order to reestimate the J-5 model (a nonlinear multiequation model used by the Department of Defense in long-range forecasting), forecasting errors were reduced by between 0 and 45 percent (with a median of about 20 percent) across different variables, as compared with regression. With simultaneous-equation econometric models, it has reduced them by 50 percent. The procedure has been documented for use by nonprogrammers [1]; it incorporates a new quasi-Newtonian method which can handle many parameters."
            },
            "slug": "An-Empirical-Test-of-New-Forecasting-Methods-from-a-Werbos-Titus",
            "title": {
                "fragments": [],
                "text": "An Empirical Test of New Forecasting Methods Derived from a Theory of Intelligence: The Prediction of Conflict in Latin America"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "The compromise method is a new computer-based forecasting tool, available within the conversational CS package on the MIT Multics, and incorporates a new quasi-Newtonian method which can handle many parameters."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7991309"
                        ],
                        "name": "A. Samuel",
                        "slug": "A.-Samuel",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Samuel",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Samuel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 170
                            }
                        ],
                        "text": "It is also perhaps worth remembering that an important feature of Samuel\u2019s celebrated checker program was its unstructured data blank of previously encountered positions (Samuel, 1959, 1967)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2126705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9e6bb5f2a04ae30d8ecc9287f8b702eedd7b772",
            "isKey": false,
            "numCitedBy": 3043,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A new signature-table technique is described together with an improved book-learning procedure which is thought to be much superior to the linear polynomial method. Full use is made of the so-called \u201calpha-beta\u201d pruning and several forms of forward pruning to restrict the spread of the move tree and to permit the program to look ahead to a much greater depth than it otherwise could do. While still unable to outplay checker masters, the program's playing ability has been greatly improved.tplay checker masters, the"
            },
            "slug": "Some-Studies-in-Machine-Learning-Using-the-Game-of-Samuel",
            "title": {
                "fragments": [],
                "text": "Some Studies in Machine Learning Using the Game of Checkers"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A new signature-table technique is described together with an improved book-learning procedure which is thought to be much superior to the linear polynomial method and to permit the program to look ahead to a much greater depth than it otherwise could do."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 87
                            }
                        ],
                        "text": "In constructing multilayer networks that solve problems many authors, and particularly Hinton and Sejnowski (1986), have stressed the importance of finding good internal representations of the data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58779360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8592e46a5435d18bba70557846f47290b34c1aa5",
            "isKey": false,
            "numCitedBy": 1336,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Relaxation Searches, Easy and Hard Learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, An Example of the Effects of Damage, Conclusion, Acknowledgments, Appendix: Derivation of the Learning Algorithm, References"
            },
            "slug": "Learning-and-relearning-in-Boltzmann-machines-Hinton-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Learning and relearning in Boltzmann machines"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This chapter contains sections titled: Relaxation Searches, Easy and Hard learning, The Boltzmann Machine Learning Algorithm, An Example of Hard Learning, Achieving Reliable Computation with Unreliable Hardware, and an Example of the Effects of Damage."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760676"
                        ],
                        "name": "S. Muroga",
                        "slug": "S.-Muroga",
                        "structuredName": {
                            "firstName": "Saburo",
                            "lastName": "Muroga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muroga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 143
                            }
                        ],
                        "text": "The literature on feedforward threshold logic includes, for example, Cover (1965), Nilsson (1965), Minsky and Papert (1969), Dertouzas (1965), Muroga (1979), Lewis and Coates (1967), and Hu (1965)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60879522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a27141912e401ef3039cbdcbd077b9a9c7150179",
            "isKey": false,
            "numCitedBy": 213,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Scalable energy-efficient magnetoelectric spin\u2013orbit logic Performing optical logic operations by a diffractive Logic gate WikipediaBi-Directional Logic Level converter using MOSFETCST203 LOGIC SYSTEM DESIGN | S3 CSE 2019 SCHEME | STUDY Logic synthesis WikipediaFoundation Of Switching Theory And Logic Design: (as Per Digital Logic circuits types, application, advantage and Courses Department of Computer Science IIT DelhiDigital Logic Design (DLD) Pdf Notes Free Download | SWElectromechanical Relay Logic Worksheet Digital CircuitsLow power vlsi design ppt SlideShareComputational Complexity Theory (Stanford Encyclopedia of Transistor Transistor Logic : History, Types, Working Multi Protocol Label Switching (MPLS) GeeksforGeeksLecture 1: Introduction to Digital Logic DesignIntroduction to Pass-Transistor Logic Technical ArticlesCourse Modules: Logic Circuits & Switching TheoryDigital Logic Design | Subject Wise \u2013 AcademyEraLogic AND Function Digital Logic GatesUser mode and Kernel mode Switching GeeksforGeeksSWITCHING THEORY AND LOGIC DESIGN COURSEFILEDigital Logic (DL) Syllabus CSITDigital Logic Design Books & Lecture Notes Pdf Download Basic Logic Gates with Truth Tables Digital Logic CircuitsHigh Voltage Switchgear | Electrical4U"
            },
            "slug": "Logic-design-and-switching-theory-Muroga",
            "title": {
                "fragments": [],
                "text": "Logic design and switching theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 90
                            }
                        ],
                        "text": "The back propagation learning algorithm uses nets very similar to multilayer perceptrons (Rumelhart et al., 1986; Werbos, 1974; LeCun, 1985; Parker, 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 97
                            }
                        ],
                        "text": "More recently, however, the back propagation algorithm (Werbos, 1974; Parker, 1985; LeCun, 1985; Rumelhart et al., 1986), which uses a circuit much like a layered perceptron, has aroused more interest than the Boltzman machine and feedforward networks have been proposed (Baum et al., 1986) which\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 102
                            }
                        ],
                        "text": "They have been tested on a variety of highly structured, toy problems such as recognizing symmetries (Rumelhart et al., 1986) as well as on some (perhaps relatively simple) real world problems (Sejnowski and Rosenberg, 1987; Gorman and Sejnowski, 1987; Werbos and Titus, 1978)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 249
                            }
                        ],
                        "text": "Interest declined when the limitations of single layers nets were made explicit (Minsky and Papert, 1969), but was revived by the discovery of the Boltzman machine (Ackley et al., 1985) and back propagation (Werbos, 1974; Parker, 1985; LeCun, 1985; Rumelhart et al., 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 127
                            }
                        ],
                        "text": "Many studies of learning algorithms, on the other hand, have emphasized highly structured problems which allow generalization (Rumelhart et al., 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": true,
            "numCitedBy": 19356,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784553"
                        ],
                        "name": "D. Psaltis",
                        "slug": "D.-Psaltis",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Psaltis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Psaltis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 214
                            }
                        ],
                        "text": "Abu-Mostafa has recently remarked that the problem of pattern recognition and other problems typically solved far better by people than by machines may be of a very unstructured nature4 (Abu-Mostafa, 1987a, 1987b; Abu-Mostafa and Psaltis, 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 119353923,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "23a9c0f4bb4be98fd3a861e1013bcff927665d89",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Reference EPFL-ARTICLE-158542doi:10.1038/scientificamerican0387-88View record in Web of Science Record created on 2010-11-25, modified on 2017-05-10"
            },
            "slug": "Optical-neural-computers-Abu-Mostafa-Psaltis",
            "title": {
                "fragments": [],
                "text": "Optical neural computers"
            },
            "tldr": {
                "abstractSimilarityScore": 32,
                "text": "This poster presents a probabilistic procedure to characterize the response of the immune system to repeated exposure to EPFL\u2019s Tournaisian\u2013Seiden\u2013Bouchut\u2013Boyaval virus."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49637194"
                        ],
                        "name": "A. Mullin",
                        "slug": "A.-Mullin",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Mullin",
                            "middleNames": [
                                "A."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mullin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51083130"
                        ],
                        "name": "F. Rosenblatt",
                        "slug": "F.-Rosenblatt",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Rosenblatt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rosenblatt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Rosenblatt (1962) and other early investigators also favored randomly chosen input feature detectors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 203
                            }
                        ],
                        "text": "Q.E.D.\nNote that this net can be learned by first constructing the first layer as outlined in the proof and then learning the second layer of synapses by the perceptron learning algorithm (Papert, 1961; Rosenblatt , 1962)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 119
                            }
                        ],
                        "text": "The proof that the perceptron learning algorithm was able to learn any linear separation from examples (Paper-t, 1961; Rosenblatt, 1962) generated considerable excite-\n193 0885-064x/88 $3.00\nCopyright 0 1988 by Academic Press, Inc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61566132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cccc0a4817fd5f6d8758c66b4065a23897d49f1d",
            "isKey": true,
            "numCitedBy": 2369,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Principles-of-neurodynamics-Mullin-Rosenblatt",
            "title": {
                "fragments": [],
                "text": "Principles of neurodynamics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643617125"
                        ],
                        "name": "A. Lewis",
                        "slug": "A.-Lewis",
                        "structuredName": {
                            "firstName": "A",
                            "lastName": "Lewis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 202956936,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "9e2c8125fd545546de5120b4d98f6c8708550d20",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Threshold-Logic-Lewis",
            "title": {
                "fragments": [],
                "text": "Threshold Logic"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756533"
                        ],
                        "name": "G. Chaitin",
                        "slug": "G.-Chaitin",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Chaitin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Chaitin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 136
                            }
                        ],
                        "text": "The question of whether a given algorithm is the shortest representing a given function is in principle undecidable (Kholmogorov, 1965; Chaitin, 1974), so that one typically chooses some heuristic for finding a relatively terse algorithmic description."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121888173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4925b1e8b4904b6d3b0d6fe8975c33ed5aa42ec",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-Theoretic-Computational-Complexity-Chaitin",
            "title": {
                "fragments": [],
                "text": "Information-Theoretic Computational Complexity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5529673"
                        ],
                        "name": "A. Borsellino",
                        "slug": "A.-Borsellino",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Borsellino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Borsellino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94013203"
                        ],
                        "name": "A. Gamba",
                        "slug": "A.-Gamba",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Gamba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gamba"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122160372,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fa9bbbf384b8b4e8be7be6d7484f9b94dd3f0d58",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-outline-of-a-mathematical-theory-of-PAPA-Borsellino-Gamba",
            "title": {
                "fragments": [],
                "text": "An outline of a mathematical theory of PAPA"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49637194"
                        ],
                        "name": "A. Mullin",
                        "slug": "A.-Mullin",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Mullin",
                            "middleNames": [
                                "A."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mullin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 125
                            }
                        ],
                        "text": "The literature on feedforward threshold logic includes, for example, Cover (1965), Nilsson (1965), Minsky and Papert (1969), Dertouzas (1965), Muroga (1979), Lewis and Coates (1967), and Hu (1965)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120817804,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9b6a8661c3e750464ba495c2390d44eda73d1406",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Threshold-Logic:-A-Synthesis-Approach-(Michael-L.-Mullin",
            "title": {
                "fragments": [],
                "text": "Threshold Logic: A Synthesis Approach (Michael L. Dertouzos)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319833"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 208
                            }
                        ],
                        "text": "Interest declined when the limitations of single layers nets were made explicit (Minsky and Papert, 1969), but was revived by the discovery of the Boltzman machine (Ackley et al., 1985) and back propagation (Werbos, 1974; Parker, 1985; LeCun, 1985; Rumelhart et al., 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 114
                            }
                        ],
                        "text": "The back propagation learning algorithm uses nets very similar to multilayer perceptrons (Rumelhart et al., 1986; Werbos, 1974; LeCun, 1985; Parker, 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 56
                            }
                        ],
                        "text": "More recently, however, the back propagation algorithm (Werbos, 1974; Parker, 1985; LeCun, 1985; Rumelhart et al., 1986), which uses a circuit much like a layered perceptron, has aroused more interest than the Boltzman machine and feedforward networks have been proposed (Baum et al., 1986) which\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207975157,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "56623a496727d5c71491850e04512ddf4152b487",
            "isKey": false,
            "numCitedBy": 4468,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Beyond-Regression-:-\"New-Tools-for-Prediction-and-Werbos",
            "title": {
                "fragments": [],
                "text": "Beyond Regression : \"New Tools for Prediction and Analysis in the Behavioral Sciences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A learning procedure for asymmetric threshold networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . Cogniriva"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 102
                            }
                        ],
                        "text": "I have previously remarked on the utility of using periodic activation functions in back propagation (Baum, 1986)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalizing back propagation to computation, in \u201cNeural Networks for Computing"
            },
            "venue": {
                "fragments": [],
                "text": "(J. Denker, Ed.),"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 209
                            }
                        ],
                        "text": "\u20261974; Parker, 1985; LeCun, 1985; Rumelhart et al., 1986), which uses a circuit much like a layered perceptron, has aroused more interest than the Boltzman machine and feedforward networks have been proposed (Baum et al., 1986) which seem superior to known feedback networks for associative memory."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 49
                            }
                        ],
                        "text": "I remark on this because in a previous preprint (Baum et al., 1986) we heuristically hypothesized that random feature detectors of this type might be able to increase the capacities of associative memories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 90
                            }
                        ],
                        "text": "(See, for example, McEliece et al. (1987) or Abu-Mostafa and St. Jacques (1985)) Recently Baum et al. (1986) have constructed feedforward nets with considerably better capacity and retrieval capabilities than known feedback designs for associative memory."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Internal representations for associative memory, preprint NSF-ITP-86-138; Biol"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random problems , J . Complexity , in press"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 26
                            }
                        ],
                        "text": "Since the seminal work of McCulloch and Pitts (1943), many researchers have studied the computational power and learning abilities of feedforward \u201cneural\u201d networks of linear threshold units."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A logical calculus of the ideas immanent in neural nets"
            },
            "venue": {
                "fragments": [],
                "text": "Bull. Math. Biophys"
            },
            "year": 1943
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A learning procedure for asymmetric threshold"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 187
                            }
                        ],
                        "text": "Abu-Mostafa has recently remarked that the problem of pattern recognition and other problems typically solved far better by people than by machines may be of a very unstructured nature4 (Abu-Mostafa, 1987a, 1987b; Abu-Mostafa and Psaltis, 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Abu-Mostafa (1987a, 1987b) has further emphasized that neural networks may be particularly effective for computing and learning random problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1987a), Number of synapses per neuron, in \u201cAnalog VLSI and Neural Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 117
                            }
                        ],
                        "text": "The question of whether a given algorithm is the shortest representing a given function is in principle undecidable (Kholmogorov, 1965; Chaitin, 1974), so that one typically chooses some heuristic for finding a relatively terse algorithmic description."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Three approaches for defining the concept of information quantity"
            },
            "venue": {
                "fragments": [],
                "text": "Znf. Transmission"
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Number of synapses per neuron , in \u201c Analog VLSI and Neural Systems \u201d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 189
                            }
                        ],
                        "text": "Q.E.D.\nNote that this net can be learned by first constructing the first layer as outlined in the proof and then learning the second layer of synapses by the perceptron learning algorithm (Papert, 1961; Rosenblatt , 1962)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Some mathematical models of learning, in \u201cProceedings"
            },
            "venue": {
                "fragments": [],
                "text": "4th London Symp. on Information Theory\u201d (C"
            },
            "year": 1961
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 36,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/On-the-capabilities-of-multilayer-perceptrons-Baum/1d20eff70cb168111fb5cc320cb692a11f1adf62?sort=total-citations"
}