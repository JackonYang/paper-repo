{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "In an earlier paper [5] we considered movement recognition as a classi cation problem and we used a Dynamic Time Warping method to match a test sequence with several reference sequences representing prototypical activities."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17525960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e88ca837b122a9c9e546db5395b451f27ea01f19",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe our work on 3-D model-based tracking and recognition of human movement from real images. Our system has two major components. The rst component takes real image sequences acquired from multiple views and recovers the 3-D body pose at each time instant. The pose-recovery problem is formulated as a search problem and entails nding the pose parameters of a graphical human model for which its synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. Currently, we use a best-rst search technique and chamfer matching as a fast similarity measure between synthesized and real edge images. The second component of our system deals with the representation and recognition of human movement patterns. The recognition of human movement patterns is considered as a classiication problem involving the matching of a test sequence with several reference sequences representing prototypical activities. A variation of dynamic time-warping is used to match movement patterns using 3-D joint angles as features. We illustrate our approach on real data acquired simultaneously from three views and data derived from stereo Moving Light Displays with diierent types of hand-gestures."
            },
            "slug": "Towards-3-D-model-based-tracking-and-recognition-of-Gavrila-Davis",
            "title": {
                "fragments": [],
                "text": "Towards 3-D model-based tracking and recognition of human movement: a multi-view approach"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "3-D model-based tracking and recognition of human movement from real images, and a variation of dynamic time-warping is used to match movement patterns using 3-D joint angles as features."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706204"
                        ],
                        "name": "I. Kakadiaris",
                        "slug": "I.-Kakadiaris",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Kakadiaris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kakadiaris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "We assume 2-D segmentation in the two orthogonal views; a way to obtain such a segmentation is proposed in [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15850434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3108574e200023a5eda434dd0f7057f4bad8212a",
            "isKey": false,
            "numCitedBy": 224,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel motion-based approach for the part determination and shape estimation of a human's body parts. The novelty of the technique is that neither a prior model of the human body is employed nor prior body part segmentation is assumed. We present a human body part identification strategy (HBPIS) that recovers all the body parts of a moving human based on the spatiotemporal analysis of its deforming silhouette. We formalize the process of simultaneous part determination and 2D shape estimation by employing the supervisory control theory of discrete event systems. In addition, in order to acquire the 3D shape of the body parts, we present a new algorithm which selectively integrates the (segmented by the HBPIS) apparent contours, from three mutually orthogonal views. The effectiveness of the approach is demonstrated through a series of experiments, where a subject performs a set of movements according to a protocol that reveals the structure of the human body.<<ETX>>"
            },
            "slug": "3D-human-body-model-acquisition-from-multiple-views-Kakadiaris-Metaxas",
            "title": {
                "fragments": [],
                "text": "3D human body model acquisition from multiple views"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A human body part identification strategy (HBPIS) that recovers all the body parts of a moving human based on the spatiotemporal analysis of its deforming silhouette and a new algorithm which selectively integrates the apparent contours from three mutually orthogonal views."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "Regarding shape, we felt that simple cylindrical primitives (possibly with elliptic XY-cross-sections) [4] [8] [18] would not represent body parts such as the head and torso accurately enough."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 162
                            }
                        ],
                        "text": "In our approach the similarity measure between model view and actual scene is based on arbitrary edge contours rather than on straight line approximations (as in [18], for example); we use a robust variant of chamfer matching [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122238372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92ab4fc76e2f085dde81626794b79b5e9d1d00e0",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The interpretation of the movements of articulated bodies in image sequences is one of the most challenging problems in computer vision. In this contribution, we introduce a model-based approach for the recognition of pedestrians. We represent the human body by a 3D-model consisting of cylinders, whereas for modelling the movement of walking we use data from medical motion studies. The estimation of model parameters in consecutive images is done by applying a Kalman filter. Experimental results are shown for synthetic as well as for real image data."
            },
            "slug": "Towards-model-based-recognition-of-human-movements-Rohr",
            "title": {
                "fragments": [],
                "text": "Towards model-based recognition of human movements in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model-based approach for the recognition of pedestrians is introduced and the human body is represented by a 3D-model consisting of cylinders, whereas for modelling the movement of walking the authors use data from medical motion studies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47265099"
                        ],
                        "name": "F. Perales",
                        "slug": "F.-Perales",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Perales",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perales"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075317523"
                        ],
                        "name": "J. Torres",
                        "slug": "J.-Torres",
                        "structuredName": {
                            "firstName": "Jesse",
                            "lastName": "Torres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Torres"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "So far, existing systems which work on real images using this strategy have had limitations: Perales and Torres [15] describe a system which involves input from a human operator."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61493162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bbe276e98cceec07e9363ea23f8074259b6274b",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for analysis and synthesis of human motion is presented. The system consists of an analysis part and a synthesis part. The analysis part can be used automatically or interactively. The automatic analysis part includes the pre-processing, modeling, matching and interpretation phases. The interactive analysis part includes the same phases but with the possibility of user supervision. We present a global overview of the whole system. The user can define a biomechanic graphical model to represent the human body in a 3D space, and use tools to perform an automatic or interactive supervised matching between the animated model and the real images to recover the motion. The synthesis part uses the results of matching process to show the motion of the human body that is shown in the real images, from any viewpoint. We use specific criteria to match walking persons from different views. Some results and images are presented.<<ETX>>"
            },
            "slug": "A-system-for-human-motion-matching-between-and-real-Perales-Torres",
            "title": {
                "fragments": [],
                "text": "A system for human motion matching between synthetic and real images based on a biomechanic graphical model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The system uses specific criteria to match walking persons from different views and uses the results of matching process to show the motion of the human body that is shown in the real images, from any viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890438"
                        ],
                        "name": "M. Leung",
                        "slug": "M.-Leung",
                        "structuredName": {
                            "firstName": "Maylor",
                            "lastName": "Leung",
                            "middleNames": [
                                "Karhang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35964920"
                        ],
                        "name": "Yee-Hong Yang",
                        "slug": "Yee-Hong-Yang",
                        "structuredName": {
                            "firstName": "Yee-Hong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Hong Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "2-D labeling and tracking under more general conditions is attempted by [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "ing some form of 2-D model [7] [11] or not [3] [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12328952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2582dd37d3011cf50dac8c2c400eda06a651900e",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "First Sight, a vision system in labeling the outline of a moving human body, is proposed in this paper. The emphasis of First Sight is on the analysis of motion information gathered solely from the outline of a moving human object. Two main processes are implemented in First Sight. The first process uses a novel technique to extract the outline of a moving human body from an image sequence. The second process, which employs a new human body model, interprets the outline and produces a labeled two-dimensional human body stick figure for each frame of the image sequence. Extensive knowledge of the structure, shape, and posture of the human body is used in the model. The experimental results of applying the technique on unedited image sequences with self-occlusions and missing boundary lines are encouraging. >"
            },
            "slug": "First-Sight:-A-Human-Body-Outline-Labeling-System-Leung-Yang",
            "title": {
                "fragments": [],
                "text": "First Sight: A Human Body Outline Labeling System"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "First Sight, a vision system in labeling the outline of a moving human body, is proposed in this paper and the experimental results of applying the technique on unedited image sequences with self-occlusions and missing boundary lines are encouraging."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798094"
                        ],
                        "name": "A. Downton",
                        "slug": "A.-Downton",
                        "structuredName": {
                            "firstName": "Andy",
                            "lastName": "Downton",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Downton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084976155"
                        ],
                        "name": "H. Drouet",
                        "slug": "H.-Drouet",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Drouet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Drouet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "Regarding shape, we felt that simple cylindrical primitives (possibly with elliptic XY-cross-sections) [4] [8] [18] would not represent body parts such as the head and torso accurately enough."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Downton and Drouet [4] attempt to track unconstrained upper-body motion, but must conclude that the tracking gets lost due to propagation of errors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60614552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b0134c456a71f20dfd2033a720254fd8e39cf2c",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research on model-based image coding for videotelephone and videoconferencing applications has mostly been concerned with head motion tracking and typically represents the human head as a 3D wire-frame model with texture-mapped surface features. However, the movements of the arms and hands are also important, particularly in sign language communication, and therefore should be included in the overall model. The paper describes a system which uses an articulated generalised cylindrical human model to track limb movements in a sequence of images. It outlines the closed-loop strategy developed to recognise and track human body motion and presents initial results for a complete implementation of the system."
            },
            "slug": "Model-based-image-analysis-for-unconstrained-human-Downton-Drouet",
            "title": {
                "fragments": [],
                "text": "Model-based image analysis for unconstrained human upper-body motion"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A system which uses an articulated generalised cylindrical human model to track limb movements in a sequence of images to recognise and track human body motion is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2652428"
                        ],
                        "name": "R. Polana",
                        "slug": "R.-Polana",
                        "structuredName": {
                            "firstName": "Ramprasad",
                            "lastName": "Polana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Polana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113399896"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randall",
                            "lastName": "Nelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "ing some form of 2-D model [7] [11] or not [3] [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "For constrained types of human movement (such as walking parallel to the image plane, involving periodic motion), many of these features have been successfully used for classi cation, as in [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6353138,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1ee01bf96b5dbd441eabda533fa89da3fa4d916a",
            "isKey": false,
            "numCitedBy": 371,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The recognition of human movements such as walking, running or climbing has been approached previously by tracking a number of feature points and either classifying the trajectories directly or matching them with a high-level model of the movement. A major difficulty with these methods is acquiring and trading the requisite feature points, which are generally specific joints such as knees or angles. This requires previous recognition and/or part segmentation of the actor. We show that the recognition of walking or any repetitive motion activity can be accomplished on the basis of bottom up processing, which does not require the prior identification of specific parts, or classification of the actor. In particular, we demonstrate that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatiotemporal template of motion features. We have implemented a real-time system that can recognize and classify repetitive motion activities in normal gray-scale image sequences.<<ETX>>"
            },
            "slug": "Low-level-recognition-of-human-motion-(or-how-to-Polana-Nelson",
            "title": {
                "fragments": [],
                "text": "Low level recognition of human motion (or how to get your man without finding his body parts)"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is demonstrated that repetitive motion is such a strong cue, that the moving actor can be segmented, normalized spatially and temporally, and recognized by matching against a spatiotemporal template of motion features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772763"
                        ],
                        "name": "E. Bernardo",
                        "slug": "E.-Bernardo",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Bernardo",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bernardo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149680415"
                        ],
                        "name": "L. Goncalves",
                        "slug": "L.-Goncalves",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Goncalves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Goncalves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46614172"
                        ],
                        "name": "Enrico Ursella",
                        "slug": "Enrico-Ursella",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Ursella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enrico Ursella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "We note that other measures could (and) have been used to evaluate a hypothesized model pose, which work directly on the scene image: correlation (see [6] and [17]) and average contrast value along"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6] use a Kalman- ltering approach to track arm movement from single-view images where the shoulder remains xed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19164875,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "7d91d26d47289d5633693cb6e91cb23b26195486",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of estimating the position and motion of a human arm in 3D without any constraints on its behavior and without the use of special markers. We model the arm as two truncated right-circular cones connected with spherical joints. We propose to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image. The system is demonstrated and tested on a real image sequence.<<ETX>>"
            },
            "slug": "Monocular-tracking-of-the-human-arm-in-3D-Bernardo-Goncalves",
            "title": {
                "fragments": [],
                "text": "Monocular tracking of the human arm in 3D"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "Regarding shape, we felt that simple cylindrical primitives (possibly with elliptic XY-cross-sections) [4] [8] [18] would not represent body parts such as the head and torso accurately enough."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34873540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92f98b189cec1220d479e3079b942e71b244aa65",
            "isKey": false,
            "numCitedBy": 597,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Model-based-vision:-a-program-to-see-a-walking-Hogg",
            "title": {
                "fragments": [],
                "text": "Model-based vision: a program to see a walking person"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052391642"
                        ],
                        "name": "J. O'Rourke",
                        "slug": "J.-O'Rourke",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "O'Rourke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Rourke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699200"
                        ],
                        "name": "N. Badler",
                        "slug": "N.-Badler",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Badler",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Badler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "The general framework for our tracking component is inspired by the early work of O'Rourke and Badler [19] and is illustrated in Figure 1a."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15680007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9df0428c30b8aab4f7e6f367e70126efdfb8fc45",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "A system capable of analyzing image sequences of human motion is described. The system is structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level. The domain of human motion lends itself to a model-driven analysis, and the system includes a detailed model of the human body. All information extracted from the image is interpreted through a constraint network based on the structure of the human model. A constraint propagation operator is defined and its theoretical properties outlined. An implementation of this operator is described, and results of the analysis system for short image sequences are presented."
            },
            "slug": "Model-based-image-analysis-of-human-motion-using-O'Rourke-Badler",
            "title": {
                "fragments": [],
                "text": "Model-based image analysis of human motion using constraint propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A system capable of analyzing image sequences of human motion is described, structured as a feedback loop between high and low levels: predictions are made at the semantic level and verifications are sought at the image level."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750924"
                        ],
                        "name": "Demetri Terzopoulos",
                        "slug": "Demetri-Terzopoulos",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Terzopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Demetri Terzopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "lows deformations of the shape primitives [12] [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Therefore, we employ the class of tapered super-quadrics [12]; these include such diverse shapes as cylinders, spheres, ellipsoids and hyper-rectangles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 31199185,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "6628820be220d48c567095f3aa8ac06516b730be",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A physics-based framework for 3-D shape and nonrigid motion estimation for real-time computer vision systems is presented. The framework features dynamic models that incorporate the mechanical principles of rigid and nonrigid bodies into conventional geometric primitives. Through the efficient numerical simulation of Lagrange equations of motion, the models can synthesize physically correct behaviors in response to applied forces and imposed constraints. Applying continuous Kalman filtering theory, a recursive shape and motion estimator that employs the Lagrange equations as a system model is developed. The system model continually synthesizes nonrigid motion in response to generalized forces that arise from the inconsistency between the incoming observations and the estimated model state. The observation forces also account formally for instantaneous uncertainties and incomplete information. A Riccati procedure updates a covariance matrix that transforms the forces in accordance with the system dynamics and prior observation history. Experiments involving model fitting and tracking of articulated and flexible objects from noisy 3-D data are described. >"
            },
            "slug": "Shape-and-Nonrigid-Motion-Estimation-Through-Metaxas-Terzopoulos",
            "title": {
                "fragments": [],
                "text": "Shape and Nonrigid Motion Estimation Through Physics-Based Synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A physics-based framework for 3-D shape and nonrigid motion estimation for real-time computer vision systems is presented and a recursive shape and motion estimator that employs the Lagrange equations as a system model is developed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738740"
                        ],
                        "name": "S. B. Kang",
                        "slug": "S.-B.-Kang",
                        "structuredName": {
                            "firstName": "Sing",
                            "lastName": "Kang",
                            "middleNames": [
                                "Bing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. B. Kang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "The cameras were calibrated using an iterative, non-linear least squares method developed by Szeliski and Kang [20] and kindly made available to us."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9709913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45d909a6f65878823735b5d36c1f7c33e1dfd2a7",
            "isKey": false,
            "numCitedBy": 330,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A shape and motion estimation algorithm based on nonlinear least squares applied to the tracks of features through time is presented. While the authors' approach requires iteration, it quickly converges to the desired solution, even in the absence of a priori knowledge about the shape or motion. Important features of the algorithm include its ability to handle partial point tracks and true perspective, its ability to use line segment matches and point matches simultaneously, and its use of an object-centered representation for faster and more accurate structure and motion recovery.<<ETX>>"
            },
            "slug": "Recovering-3D-shape-and-motion-from-image-streams-Szeliski-Kang",
            "title": {
                "fragments": [],
                "text": "Recovering 3D Shape and Motion from Image Streams Using Nonlinear Least Squares"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A shape and motion estimation algorithm based on nonlinear least squares applied to the tracks of features through time is presented, using an object-centered representation for faster and more accurate structure and motion recovery."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "We note that other measures could (and) have been used to evaluate a hypothesized model pose, which work directly on the scene image: correlation (see [6] and [17]) and average contrast value along"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "Finally, work by Rehg and Kanade [17] is geared towards nger tracking."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17009967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3740a2ab2936c2d87f6a3d8b742841a383ba502",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer sensing of hand and limb motion is an important problem for applications in human computer interaction and computer graphics. We describe a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another. Our approach uses a kinematic model to predict occlusions and windowed templates to track partially occluded objects. We present offline 3D tracking results for hand motion with significant self occlusion.<<ETX>>"
            },
            "slug": "Model-based-tracking-of-self-occluding-articulated-Rehg-Kanade",
            "title": {
                "fragments": [],
                "text": "Model-based tracking of self-occluding articulated objects"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work describes a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another, using a kinematic model to predict occlusions and windowed templates to track partially occluded objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "ing some form of 2-D model [7] [11] or not [3] [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5344867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1807058512ae2934b2be0b43f395d8583ef67303",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented. Objects are represented using sets of view models, rather than single templates. Stereotypical space-time patterns, i.e., gestures, are then matched to stored gesture patterns using dynamic time warping. Real-time performance is achieved by using special purpose correlation hardware and view prediction to prune as much of the search space as possible. Both view models and view predictions are learned from examples. Results showing tracking and recognition of human hand gestures at over 10 Hz are presented.<<ETX>>"
            },
            "slug": "Space-time-gestures-Darrell-Pentland",
            "title": {
                "fragments": [],
                "text": "Space-time gestures"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented and results showing tracking and recognition of human hand gestures at over 10 Hz are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708785"
                        ],
                        "name": "J. Ohya",
                        "slug": "J.-Ohya",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289052"
                        ],
                        "name": "F. Kishino",
                        "slug": "F.-Kishino",
                        "structuredName": {
                            "firstName": "Fumio",
                            "lastName": "Kishino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kishino"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "Search techniques are used to prune the high dimensional pose parameter space (see also [13])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46946327,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1cc06cf0e8c342903d585a1c22377ce6dbf4af8c",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for estimating human postures at a time instant from multiple images using a genetic algorithm is proposed. The posture parameters to be estimated are assigned to the genes of individuals in the population. For each individual, its fitness evaluates to what extent the multiple human images synthesized by deforming a 3D human model according to the values of the genes are registered to the real multiple human images. Genetic operations such as natural selection, crossover and mutation are performed, and individuals in the next generation are generated. After a certain number of repetitions for these processes, the estimated parameter values are obtained from the individual with the best fitness. Experiments using synthesized human multiple images show promising results."
            },
            "slug": "Human-posture-estimation-from-multiple-images-using-Ohya-Kishino",
            "title": {
                "fragments": [],
                "text": "Human posture estimation from multiple images using genetic algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A new method for estimating human postures at a time instant from multiple images using a genetic algorithm is proposed, and experiments using synthesized human multiple images show promising results."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 12th International Conference on Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710918"
                        ],
                        "name": "J. Yamato",
                        "slug": "J.-Yamato",
                        "structuredName": {
                            "firstName": "Junji",
                            "lastName": "Yamato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yamato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708785"
                        ],
                        "name": "J. Ohya",
                        "slug": "J.-Ohya",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Ohya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ohya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072192824"
                        ],
                        "name": "K. Ishii",
                        "slug": "K.-Ishii",
                        "structuredName": {
                            "firstName": "Kenichiro",
                            "lastName": "Ishii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ishii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 28489640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45336e96c04ea005b203ff3fc84aa4f4159e8cb0",
            "isKey": false,
            "numCitedBy": 1527,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A human action recognition method based on a hidden Markov model (HMM) is proposed. It is a feature-based bottom-up approach that is characterized by its learning capability and time-scale invariability. To apply HMMs, one set of time-sequential images is transformed into an image feature vector sequence, and the sequence is converted into a symbol sequence by vector quantization. In learning human action categories, the parameters of the HMMs, one per category, are optimized so as to best describe the training sequences from the category. To recognize an observed sequence, the HMM which best matches the sequence is chosen. Experimental results for real time-sequential images of sports scenes show recognition rates higher than 90%. The recognition rate is improved by increasing the number of people used to generate the training data, indicating the possibility of establishing a person-independent action recognizer.<<ETX>>"
            },
            "slug": "Recognizing-human-action-in-time-sequential-images-Yamato-Ohya",
            "title": {
                "fragments": [],
                "text": "Recognizing human action in time-sequential images using hidden Markov model"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The recognition rate is improved by increasing the number of people used to generate the training data, indicating the possibility of establishing a person-independent action recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696931"
                        ],
                        "name": "H. Barrow",
                        "slug": "H.-Barrow",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Barrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144592244"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11843441"
                        ],
                        "name": "H. C. Wolf",
                        "slug": "H.-C.-Wolf",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Wolf",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. C. Wolf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "It would be e cient if we could use only DD(M;S) during pose search (as done in [2]), where M and S are the projected model edges and scene edges, respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 226
                            }
                        ],
                        "text": "In our approach the similarity measure between model view and actual scene is based on arbitrary edge contours rather than on straight line approximations (as in [18], for example); we use a robust variant of chamfer matching [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1621080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "358a97112cc60d6bfefb352b863fec8a86a39e28",
            "isKey": false,
            "numCitedBy": 872,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Parametric correspondence is a technique for matching images to a three dimensional symbolic reference map. An analytic camera model is used to predict the location and appearance of landmarks in the image, generating a projection for an assumed viewpoint. Correspondence is achieved by adjusting the parameters of the camera model until the appearances of the landmarks optimally match a symbolic description extracted from the image. \n \nThe matching of image and map features is performed rapidly by a new technique, called \"chamfer matching\", that compares the shapes of two collections of shape fragments, at a cost proportional to linear dimension, rather than area. These two techniques permit the matching of spatially extensive features on the basis of shape, which reduces the risk of ambiguous matches and the dependence on viewing conditions inherent in conventional image based correlation matching."
            },
            "slug": "Parametric-Correspondence-and-Chamfer-Matching:-Two-Barrow-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "Parametric Correspondence and Chamfer Matching: Two New Techniques for Image Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The matching of image and map features is performed rapidly by a new technique, called \"chamfer matching\", that compares the shapes of two collections of shape fragments, at a cost proportional to linear dimension, rather than area."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155598311"
                        ],
                        "name": "Yan Guo",
                        "slug": "Yan-Guo",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110690761"
                        ],
                        "name": "Gang Xu",
                        "slug": "Gang-Xu",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143873014"
                        ],
                        "name": "S. Tsuji",
                        "slug": "S.-Tsuji",
                        "structuredName": {
                            "firstName": "Saburo",
                            "lastName": "Tsuji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tsuji"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46947080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25ba7cc4fed70ddf865870013557db1a1da4e451",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the recognition of human motion patterns. We represent the human body structure in the silhouette by a stick figure model. The human motion, thus, can be recorded as a sequence of the stick figure parameters, which can be used as input of a motion pattern analyzer. The recognition of human motion pattern is divided into two stages. In the first stage, a model-driven approach is used to track human motions. This is, in fact, finding the stick figure model which represents the human silhouette in each frame. In the second stage, a BP neural network classifies motions of the stick figures into three categories: walking, running and other motions. We transform the time sequence of stick figure parameters into Fourier domain by DFT, and use only the first four Fourier components as the input of the neural network."
            },
            "slug": "Understanding-human-motion-patterns-Guo-Xu",
            "title": {
                "fragments": [],
                "text": "Understanding human motion patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The human motion can be recorded as a sequence of the stick figure parameters, which can be used as input of a motion pattern analyzer, when recognition of human motion patterns is addressed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 12th IAPR International Conference on Pattern Recognition, Vol. 3 - Conference C: Signal Processing (Cat. No.94CH3440-5)"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861837498"
                        ],
                        "name": "G. G. Stokes",
                        "slug": "G.-G.-Stokes",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Stokes",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. G. Stokes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 221060727,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "90006064cafcb0a9ad8a30cffeb56efe7e14129b",
            "isKey": false,
            "numCitedBy": 672630,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "however (for it was the literal soul of the life of the Redeemer, John xv. io), is the peculiar token of fellowship with the Redeemer. That love to God (what is meant here is not God\u2019s love to men) is described in such a case as a perfect love (love that has been perfected), involves no difficulty, for the simple reason that the proposition is purely hypothetical. We must, of course, also take the &dquo;keeping&dquo; in all its stringency. John knows right well that the case supposed here ncver becomes full reality. &dquo; Hereb)\u2019,&dquo; i.e. from the actual realization of love to God. &dquo; TIli7i 7e)e are ill Hinz &dquo;"
            },
            "slug": "\"J.\"-Stokes",
            "title": {
                "fragments": [],
                "text": "\"J.\""
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1890
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "lows deformations of the shape primitives [12] [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33688980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8c817191c4143a71e396ea52ad359acb398af0a",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Extraction-Of-Deformable-Part-Models-Pentland",
            "title": {
                "fragments": [],
                "text": "Extraction Of Deformable Part Models"
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": "An alternative approach is to work directly with 2-D features derived from the images, using some form of 2-D model [7] [11] or not [3] [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Space-Time Ges-  tures,"
            },
            "venue": {
                "fragments": [],
                "text": "Looking at people, Proc. IJCAI, Cham-  bery, France,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "So far, existing systems which work on real images using this strategy have had limitations: Perales and Torres [15] describe a system which involves input from a human operator."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "System for Hu-  man Motion Matching between Synthetic and  Real Images,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Work. on Motion of Non-  Rig. and Art"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "Many highly accurate surface models have been used in the eld of graphics [1] to model the human body, often containing thousands of polygons obtained from actual body scans."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "See [1] for more sophisticated modeling."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Webber,  \\Simulating Humans,"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 183
                            }
                        ],
                        "text": "- Similarity measure In our approach the similarity measure between model view and actual scene is based on arbitrary edge contours rather than on straight line approximations (as in [18], for example); we use a robust variant of chamfer matching [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "Regarding shape, we felt that simple cylindrical primitives (possibly with elliptic XY-cross-sections) [4] [8] [18] would not represent body parts such as the head and torso accurately enough."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Hogg [8] and Rohr [18] deal with the restricted movement of walking parallel to image plane, for which the search space is essentially one-dimensional."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards Model-Based Recognition  of Human Movements in Image Sequences,\"  CVGIP: Image Understanding, Vol.59"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "- Search Search techniques are used to prune the high dimensional pose parameter space (see also [13])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Human Posture Es-  timation from Multiple Images Using Genetic  Algorithm,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ICPR,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "An alternative approach is to work directly with 2-D features derived from the images, using some form of 2-D model [7] [11] or not [3] [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "For constrained types of human movement (such as walking parallel to the image plane, involving periodic motion), many of these features have been successfully used for classi cation, as in [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Low Level Recog-  nition of Human Motion,\" IEEE Workshop on  Motion of Non-Rigid and Articulated Objects"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "So far, we have obtained satisfactory modeling results with these primitives alone (see experiments); a more general approach also allows deformations of the shape primitives [12] [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic Extraction of De-  formable Models,"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Computer Vision,  vol.4,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "Many highly accurate surface models have been used in the eld of graphics [1] to model the human body, often containing thousands of polygons obtained from actual body scans."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "See [1] for more sophisticated modeling."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Simulating Humans,"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "ing some form of 2-D model [7] [11] or not [3] [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "G"
            },
            "venue": {
                "fragments": [],
                "text": "Xu and S. Tsuji, \\Understanding Human Motion Patterns,\" Proc. ICPR"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "In an earlier paper [5] we considered movement recognition as a classi cation problem and we used a Dynamic Time Warping method to match a test sequence with several reference sequences representing prototypical activities."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards 3-D  Model-based Tracking and Recognition of Hu-  man Movement,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Work. on Face and  Gesture Recognition,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. ICPR"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ICPR"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 247
                            }
                        ],
                        "text": "- Similarity measure In our approach the similarity measure between model view and actual scene is based on arbitrary edge contours rather than on straight line approximations (as in [18], for example); we use a robust variant of chamfer matching [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "It would be e cient if we could use only DD(M;S) during pose search (as done in [2]), where M and S are the projected model edges and scene edges, respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parametric Correspon-  dence and Chamfer Matching: Two New Tech-  niques For Image Matching,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IJCAI,  vol.2,"
            },
            "year": 1977
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 20
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 32,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/3-D-model-based-tracking-of-humans-in-action:-a-Gavrila-Davis/cc9b263c1af95ea803c4f5c8888ef8e37f0cef80?sort=total-citations"
}