{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8551365"
                        ],
                        "name": "N. Kushmerick",
                        "slug": "N.-Kushmerick",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Kushmerick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kushmerick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913159"
                        ],
                        "name": "Robert B. Doorenbos",
                        "slug": "Robert-B.-Doorenbos",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Doorenbos",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Doorenbos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[15, 14] and the xpathbased method from Dalvi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "[15, 14, 10] considers documents as a sequence of characters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "For instance, as we show in Section 5, both the Wien system [15] that generates wrapper rules in terms of prefixes and suffixes, and the XPath system [6] that generates xpath rules, have a natural representation as a feature-based inductor."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 121
                            }
                        ],
                        "text": "Such a rule is called a wrapper, and the problem of inducing wrappers from labeled examples has been extensively studied [15, 13, 11, 19, 18, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "As we show in Section 5, the Wien system [15] that generates wrapper rules in terms of prefixes and suffixes, and the XPath system [6] that generates xpath rules, are both well-behaved."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 21
                            }
                        ],
                        "text": ", prefixsuffix pairs [15, 14], finite-state automaton [17] and xpaths [6, 1, 18], and various algorithms designed for learning wrappers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 24
                            }
                        ],
                        "text": "The second line of work [14, 15, 6] uses rule induction to learn wrappers from a small number of labeled examples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5119155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e7402ad740b73cc0bb64178f86df3478c3aaf5",
            "isKey": true,
            "numCitedBy": 1283,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "Many Internet information resources present relational data|telephone directories, product catalogs, etc. Because these sites are formatted for people, mechanically extracting their content is di cult. Systems using such resources typically use hand-coded wrappers, procedures to extract data from information resources. We introduce wrapper induction, a method for automatically constructing wrappers, and identify hlrt, a wrapper class that is e ciently learnable, yet expressive enough to handle 48% of a recently surveyed sample of Internet resources. We use PAC analysis to bound the problem's sample complexity, and show that the system degrades gracefully with imperfect labeling knowledge."
            },
            "slug": "Wrapper-Induction-for-Information-Extraction-Kushmerick-Weld",
            "title": {
                "fragments": [],
                "text": "Wrapper Induction for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work introduces wrapper induction, a method for automatically constructing wrappers, and identifies hlrt, a wrapper class that is e ciently learnable, yet expressive enough to handle 48% of a recently surveyed sample of Internet resources."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734682"
                        ],
                        "name": "P. Senellart",
                        "slug": "P.-Senellart",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Senellart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Senellart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323099"
                        ],
                        "name": "Avin Mittal",
                        "slug": "Avin-Mittal",
                        "structuredName": {
                            "firstName": "Avin",
                            "lastName": "Mittal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Avin Mittal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3116283"
                        ],
                        "name": "D. Muschick",
                        "slug": "D.-Muschick",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Muschick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Muschick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741371"
                        ],
                        "name": "R\u00e9mi Gilleron",
                        "slug": "R\u00e9mi-Gilleron",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Gilleron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9mi Gilleron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144640325"
                        ],
                        "name": "M. Tommasi",
                        "slug": "M.-Tommasi",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Tommasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tommasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7896529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e70cf29922d7f23a3e22b7655d37811464e2f29a",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an original approach to the automatic induction of wrappers for sources of the hidden Web that does not need any human supervision. Our approach only needs domain knowledge expressed as a set of concept names and concept instances. There are two parts in extracting valuable data from hidden-Web sources: understanding the structure of a given HTML form and relating its fields to concepts of the domain, and understanding how resulting records are represented in an HTML result page. For the former problem, we use a combination of heuristics and of probing with domain instances; for the latter, we use a supervised machine learning technique adapted to tree-like information on an automatic, imperfect, and imprecise, annotation using the domain knowledge. We show experiments that demonstrate the validity and potential of the approach."
            },
            "slug": "Automatic-wrapper-induction-from-hidden-web-sources-Senellart-Mittal",
            "title": {
                "fragments": [],
                "text": "Automatic wrapper induction from hidden-web sources with domain knowledge"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An original approach to the automatic induction of wrappers for sources of the hidden Web that does not need any human supervision and only needs domain knowledge expressed as a set of concept names and concept instances."
            },
            "venue": {
                "fragments": [],
                "text": "WIDM '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8551365"
                        ],
                        "name": "N. Kushmerick",
                        "slug": "N.-Kushmerick",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Kushmerick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kushmerick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "[15, 14, 10] considers documents as a sequence of characters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17531530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce2347d8fbeb3689a989ee13e7e0b4da50a6994a",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in machine learning for information extraction has focused on two distinct sub-problems: the conventional problem of filling template slots from natural language text, and the problem of wrapper induction, learning simple extraction procedures (\u201cwrappers\u201d) for highly structured text such as Web pages produced by CGI scripts. For suitably regular domains, existing wrapper induction algorithms can efficiently learn wrappers that are simple and highly accurate, but the regularity bias of these algorithms makes them unsuitable for most conventional information extraction tasks. Boosting is a technique for improving the performance of a simple machine learning algorithm by repeatedly applying it to the training set with different example weightings. We describe an algorithm that learns simple, low-coverage wrapper-like extraction patterns, which we then apply to conventional information extraction problems using boosting. The result is BWI, a trainable information extraction system with a strong precision bias and F1 performance better than state-of-the-art techniques in many domains."
            },
            "slug": "Boosted-Wrapper-Induction-Freitag-Kushmerick",
            "title": {
                "fragments": [],
                "text": "Boosted Wrapper Induction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work describes an algorithm that learns simple, low-coverage wrapper-like extraction patterns, which it then applies to conventional information extraction problems using boosting, resulting in BWI, a trainable information extraction system with a strong precision bias and F1 performance better than state-of-the-art techniques in many domains."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791339"
                        ],
                        "name": "Valter Crescenzi",
                        "slug": "Valter-Crescenzi",
                        "structuredName": {
                            "firstName": "Valter",
                            "lastName": "Crescenzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Valter Crescenzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785690"
                        ],
                        "name": "G. Mecca",
                        "slug": "G.-Mecca",
                        "structuredName": {
                            "firstName": "Giansalvatore",
                            "lastName": "Mecca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mecca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796590"
                        ],
                        "name": "P. Merialdo",
                        "slug": "P.-Merialdo",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Merialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Merialdo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 62
                            }
                        ],
                        "text": "There are several work that model the web publication process [2, 5], and try to infer the grammar that generated the given set of webpages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 46
                            }
                        ],
                        "text": "The first line of work is on grammar learning [2, 5], which focus on the web publication process, and try to infer the grammar that generated the given set of webpages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15075203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3dd1f9f7795b31493d98d9f260d37aad07550f6e",
            "isKey": false,
            "numCitedBy": 1157,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper investigates techniques for extracting data from HTML sites through the use of automatically generated wrappers. To automate the wrapper generation and the data extraction process, the paper develops a novel technique to compare HTML pages and generate a wrapper based on their similarities and dierences. Experimental results on real-life data-intensive Web sites confirm the feasibility of the approach."
            },
            "slug": "RoadRunner:-Towards-Automatic-Data-Extraction-from-Crescenzi-Mecca",
            "title": {
                "fragments": [],
                "text": "RoadRunner: Towards Automatic Data Extraction from Large Web Sites"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel technique to compare HTML pages and generate a wrapper based on their similarities and dierences is developed, which confirms the feasibility of the approach on real-life data-intensive Web sites."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3276863"
                        ],
                        "name": "Ion Muslea",
                        "slug": "Ion-Muslea",
                        "structuredName": {
                            "firstName": "Ion",
                            "lastName": "Muslea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ion Muslea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69388632"
                        ],
                        "name": "S. Minton",
                        "slug": "S.-Minton",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Minton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Minton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745117"
                        ],
                        "name": "Craig A. Knoblock",
                        "slug": "Craig-A.-Knoblock",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Knoblock",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig A. Knoblock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": ", prefixsuffix pairs [15, 14], finite-state automaton [17] and xpaths [6, 1, 18], and various algorithms designed for learning wrappers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16845836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8d0bbb9cfaf417baf33daaa94f2980df1cd7e4b",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Information mediators are systems capable of providing a unified view of several information sources. Central to any mediator that accesses Web-based sources is a set of wrappers that can extract relevant information from Web pages. In this paper, we present a wrapper-induction algorithm that generates extraction rules for Web-based information sources. We introduce landmark automata, a formalism that describes classes of extraction rules. Our wrapper induction algorithm, STALKER, generates extraction rules that are expressed as simple landmark grammars, which are a class of landmark automata that is more expressive than the existing extraction languages. Based on just a few training examples STALKER learns extraction rules for documents with multiple levels of embedding. The experimental results show that our approach successfully wraps classes of documents that can not be wrapped by existing techniques."
            },
            "slug": "STALKER:-Learning-Extraction-Rules-for-Web-based-*-Muslea-Minton",
            "title": {
                "fragments": [],
                "text": "STALKER: Learning Extraction Rules for Semistructured, Web-based Information Sources *"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A wrapper-induction algorithm that generates extraction rules for Web-based information sources that are expressed as simple landmark grammars, which are a class of landmark automata that is more expressive than the existing extraction languages."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8551365"
                        ],
                        "name": "N. Kushmerick",
                        "slug": "N.-Kushmerick",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Kushmerick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kushmerick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[15, 14] and the xpathbased method from Dalvi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "[15, 14, 10] considers documents as a sequence of characters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 21
                            }
                        ],
                        "text": ", prefixsuffix pairs [15, 14], finite-state automaton [17] and xpaths [6, 1, 18], and various algorithms designed for learning wrappers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 24
                            }
                        ],
                        "text": "The second line of work [14, 15, 6] uses rule induction to learn wrappers from a small number of labeled examples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11075952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f052f40a3307de1e45e11a3007a7552b36ebfc8",
            "isKey": true,
            "numCitedBy": 641,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Wrapper-induction:-Efficiency-and-expressiveness-Kushmerick",
            "title": {
                "fragments": [],
                "text": "Wrapper induction: Efficiency and expressiveness"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145612610"
                        ],
                        "name": "Doug Downey",
                        "slug": "Doug-Downey",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Downey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Doug Downey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3447955"
                        ],
                        "name": "Stanley Kok",
                        "slug": "Stanley-Kok",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Kok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stanley Kok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36445704"
                        ],
                        "name": "Ana-Maria Popescu",
                        "slug": "Ana-Maria-Popescu",
                        "structuredName": {
                            "firstName": "Ana-Maria",
                            "lastName": "Popescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ana-Maria Popescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3296031"
                        ],
                        "name": "Tal Shaked",
                        "slug": "Tal-Shaked",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Shaked",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tal Shaked"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295318"
                        ],
                        "name": "S. Soderland",
                        "slug": "S.-Soderland",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Soderland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soderland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780531"
                        ],
                        "name": "Daniel S. Weld",
                        "slug": "Daniel-S.-Weld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Weld",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel S. Weld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3321874"
                        ],
                        "name": "A. Yates",
                        "slug": "A.-Yates",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Yates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yates"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6755965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ef07373873cc0f0b940512dcdde4e7b54b0cfb0",
            "isKey": false,
            "numCitedBy": 892,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Manually querying search engines in order to accumulate a large bodyof factual information is a tedious, error-prone process of piecemealsearch. Search engines retrieve and rank potentially relevantdocuments for human perusal, but do not extract facts, assessconfidence, or fuse information from multiple documents. This paperintroduces KnowItAll, a system that aims to automate the tedious process ofextracting large collections of facts from the web in an autonomous,domain-independent, and scalable manner.The paper describes preliminary experiments in which an instance of KnowItAll, running for four days on a single machine, was able to automatically extract 54,753 facts. KnowItAll associates a probability with each fact enabling it to trade off precision and recall. The paper analyzes KnowItAll's architecture and reports on lessons learned for the design of large-scale information extraction systems."
            },
            "slug": "Web-scale-information-extraction-in-knowitall:-Etzioni-Cafarella",
            "title": {
                "fragments": [],
                "text": "Web-scale information extraction in knowitall: (preliminary results)"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "KnowItAll, a system that aims to automate the tedious process of extracting large collections of facts from the web in an autonomous, domain-independent, and scalable manner, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34607455"
                        ],
                        "name": "Chun-Nan Hsu",
                        "slug": "Chun-Nan-Hsu",
                        "structuredName": {
                            "firstName": "Chun-Nan",
                            "lastName": "Hsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chun-Nan Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094164369"
                        ],
                        "name": "Ming-Tzung Dung",
                        "slug": "Ming-Tzung-Dung",
                        "structuredName": {
                            "firstName": "Ming-Tzung",
                            "lastName": "Dung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Tzung Dung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 121
                            }
                        ],
                        "text": "Such a rule is called a wrapper, and the problem of inducing wrappers from labeled examples has been extensively studied [15, 13, 11, 19, 18, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17895561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9478265afd280486299a5b8f1dbaaf6769422de",
            "isKey": false,
            "numCitedBy": 507,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generating-Finite-State-Transducers-for-Data-from-Hsu-Dung",
            "title": {
                "fragments": [],
                "text": "Generating Finite-State Transducers for Semi-Structured Data Extraction from the Web"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Syst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114924634"
                        ],
                        "name": "Wei Han",
                        "slug": "Wei-Han",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690267"
                        ],
                        "name": "David J. Buttler",
                        "slug": "David-J.-Buttler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Buttler",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Buttler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145932397"
                        ],
                        "name": "C. Pu",
                        "slug": "C.-Pu",
                        "structuredName": {
                            "firstName": "Calton",
                            "lastName": "Pu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Pu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 121
                            }
                        ],
                        "text": "Such a rule is called a wrapper, and the problem of inducing wrappers from labeled examples has been extensively studied [15, 13, 11, 19, 18, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8223846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "516134942d62e3318cb3b94862cf303c454f4065",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The vast majority of online information is part of the World Wide Web. In order to use this information for more than human browsing, web pages in HTML must be converted into a format meaningful to software programs. Wrappers have been a useful technique to convert HTML documents into semantically meaningful XML files. However, developing wrappers is slow and labor-intensive. Further, frequent changes on the HTML documents typically require frequent changes in the wrappers. This paper describes XWRAP Elite, a tool to automatically generate robust wrappers. XWRAP breaks down the conversion process into three steps. First, discover where the data is located in an HTML page and separating the data into individual objects. Second, decompose objects into data elements. Third, mark objects and elements in an output format. XWRAP Elite automates the first two steps and minimizes human involvement in marking output data. Our experience shows that XWRAP is able to create useful wrapper software for a wide variety of real world HTML documents."
            },
            "slug": "Wrapping-web-data-into-XML-Han-Buttler",
            "title": {
                "fragments": [],
                "text": "Wrapping web data into XML"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "XWRAP Elite is described, a tool to automatically generate robust wrappers for real world HTML documents that automates the first two steps and minimizes human involvement in marking output data."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890500"
                        ],
                        "name": "Hazem Elmeleegy",
                        "slug": "Hazem-Elmeleegy",
                        "structuredName": {
                            "firstName": "Hazem",
                            "lastName": "Elmeleegy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hazem Elmeleegy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2224716"
                        ],
                        "name": "J. Madhavan",
                        "slug": "J.-Madhavan",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Madhavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 908261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50fd068ad5cb83265d6ad89f002277e88980d3c7",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A large number of web pages contain data structured in the form of \u201clists\u201d. Many such lists can be further split into multi-column tables, which can then be used in more semantically meaningful tasks. However, harvesting relational tables from such lists can be a challenging task. The lists are manually generated and hence need not have well-defined templates\u2014they have inconsistent delimiters (if any) and often have missing information. We propose a novel technique for extracting tables from lists. The technique is domain independent and operates in a fully unsupervised manner. We first use multiple sources of information to split individual lines into multiple fields and then, compare the splits across multiple lines to identify and fix incorrect splits and bad alignments. In particular, we exploit a corpus of HTML tables, also extracted from the web, to identify likely fields and good alignments. For each extracted table, we compute an extraction score that reflects our confidence in the table\u2019s quality. We conducted an extensive experimental study using both real web lists and lists derived from tables on the web. The experiments demonstrate the ability of our technique to extract tables with high accuracy. In addition, we applied our technique on a large sample of about 100,000 lists crawled from the web. The analysis of the extracted tables has led us to believe that there are likely to be tens of millions of useful and query-able relational tables extractable from lists on the web."
            },
            "slug": "Harvesting-relational-tables-from-lists-on-the-web-Elmeleegy-Madhavan",
            "title": {
                "fragments": [],
                "text": "Harvesting relational tables from lists on the web"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes a novel technique for extracting tables from lists that is domain independent and operates in a fully unsupervised manner, and believes that there are likely to be tens of millions of useful and query-able relational tables extractable from lists on the web."
            },
            "venue": {
                "fragments": [],
                "text": "The VLDB Journal"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2915438"
                        ],
                        "name": "T. Anton",
                        "slug": "T.-Anton",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Anton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Anton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "//div[@class = content]/table[1]/tr/td[2]/text(), (3)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 70
                            }
                        ],
                        "text": ", prefixsuffix pairs [15, 14], finite-state automaton [17] and xpaths [6, 1, 18], and various algorithms designed for learning wrappers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 121
                            }
                        ],
                        "text": "Such a rule is called a wrapper, and the problem of inducing wrappers from labeled examples has been extensively studied [15, 13, 11, 19, 18, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "It has td[2] at position 1, tr at position 2, table[1] at position 3 and so on."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9336145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76eb7007bc4aad2f861acbef93ae4c4ce3b1621d",
            "isKey": true,
            "numCitedBy": 45,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a wrapper induction algorithm for extracting information from tree-structured documents like HTML or XML. It derives XPath-compatible extraction rules from a set of annotated example documents. The approach builds a minimally generalized tree traversal pattern, and augments it with conditions. Another variant selects a subset of conditions so that (a) the pattern is consistent with the training data, (b) the pat-tern's document coverage is minimized, and (c) conditions that match structures preceding the target nodes are preferred. We discuss the ro-bustness of rules induced by this selection strategy and we illustrate how these rules exhibit knowledge of the target concept."
            },
            "slug": "XPath-Wrapper-Induction-by-generating-tree-patterns-Anton",
            "title": {
                "fragments": [],
                "text": "XPath-Wrapper Induction by generating tree traversal patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A wrapper induction algorithm for extracting information from tree-structured documents like HTML or XML derives XPath-compatible extraction rules from a set of annotated example documents and discusses the ro-bustness of rules induced by this selection strategy."
            },
            "venue": {
                "fragments": [],
                "text": "LWA"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612119"
                        ],
                        "name": "J. Myllymaki",
                        "slug": "J.-Myllymaki",
                        "structuredName": {
                            "firstName": "Jussi",
                            "lastName": "Myllymaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Myllymaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2876361"
                        ],
                        "name": "Jared Jackson",
                        "slug": "Jared-Jackson",
                        "structuredName": {
                            "firstName": "Jared",
                            "lastName": "Jackson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jared Jackson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 70
                            }
                        ],
                        "text": ", prefixsuffix pairs [15, 14], finite-state automaton [17] and xpaths [6, 1, 18], and various algorithms designed for learning wrappers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 121
                            }
                        ],
                        "text": "Such a rule is called a wrapper, and the problem of inducing wrappers from labeled examples has been extensively studied [15, 13, 11, 19, 18, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10997495,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5908690c8b0b86db7812654f828a0c77d917861",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Automated extraction of structured Web data has attracted considerable interest in both the academia and industry. A particularly promising approach is to employ XML technologies to translate semi-structured HTML documents to \u201cpure\u201d XML documents. In this approach, HTML documents are first normalized into XHMTL and then mapped to the desired XML application format by using XML path expressions and regular expressions. In this paper we describe a methodology for creating XML path (XPath) expressions that are capable of extracting data from virtually any HTML page, while placing an emphasis on the persistent integrity of these expressions. This robustness is critical given the vulnerability of extraction technologies to the continually changing content, structure, and formatting of pages on the Web. We define categories of extraction rules in terms of their dependence on content, structural, or formatting features, and provide practical tips on how to create dependable data extraction patterns for the Web."
            },
            "slug": "Robust-Web-Data-Extraction-with-XML-Path-Myllymaki-Jackson",
            "title": {
                "fragments": [],
                "text": "Robust Web Data Extraction with XML Path Expressions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes a methodology for creating XML path (XPath) expressions that are capable of extracting data from virtually any HTML page, while placing an emphasis on the persistent integrity of these expressions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923209"
                        ],
                        "name": "Nilesh N. Dalvi",
                        "slug": "Nilesh-N.-Dalvi",
                        "structuredName": {
                            "firstName": "Nilesh",
                            "lastName": "Dalvi",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nilesh N. Dalvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730124"
                        ],
                        "name": "P. Bohannon",
                        "slug": "P.-Bohannon",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Bohannon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bohannon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145757665"
                        ],
                        "name": "Fei Sha",
                        "slug": "Fei-Sha",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Sha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Sha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 41
                            }
                        ],
                        "text": "Figure 2(b) shows the same graph for the XPATH wrappers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "While XPATH [6] focuses on robustness of wrappers w."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 28
                            }
                        ],
                        "text": "Again, while not intuitive, XPATH can in fact be expressed as a feature-based inductor as follows."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "XPATH is a well-behaved wrapper inductor."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 43
                            }
                        ],
                        "text": "Since LR wrappers are less expressive than XPATH wrappers, the over-generalization due to the noise is more severe, leading to a really low precision of the naive method."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 36
                            }
                        ],
                        "text": "We take the DEALERS dataset and the XPATH wrappers, and study the accuracy (F1 measure) of our techniques as a function of precision/recall of annotators."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 72
                            }
                        ],
                        "text": "This is again due to the fact that LR wrappers are not as expressive as XPATH wrappers and for some of the websites, a perfect LR wrapper does not exist."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 4
                            }
                        ],
                        "text": "For XPATH wrappers, simply using the labeling errors almost takes us all the way to the maximum accuracy, while for LR, labeling errors by themselves do not help much."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 92
                            }
                        ],
                        "text": "The algorithm we describe here is from Dalvi et al. [6], which we refer to in this paper as XPATH 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "For instance, as we show in Section 5, both the Wien system [15] that generates wrapper rules in terms of prefixes and suffixes, and the XPath system [6] that generates xpath rules, have a natural representation as a feature-based inductor."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 4
                            }
                        ],
                        "text": "The XPATH wrapper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 7
                            }
                        ],
                        "text": "2While XPATH [6] focuses on robustness of wrappers w.r.t changes in website, this aspect is orthogonal to our setting, and we are only concerned here with their wrapper induction algorithm as described in Section 5 in their paper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 110
                            }
                        ],
                        "text": "Secondly, we see that the accuracy of the noise-tolerant framework, while quite high, is still only 90% while XPATH performs close to 100% on the same dataset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 65
                            }
                        ],
                        "text": "We experimented with two different wrapper induction algorithms, XPATH and LR, as defined in Section 5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 131
                            }
                        ],
                        "text": "As we show in Section 5, the Wien system [15] that generates wrapper rules in terms of prefixes and suffixes, and the XPath system [6] that generates xpath rules, are both well-behaved."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 71
                            }
                        ],
                        "text": "Figure 2(c) shows the physical running times of the two algorithms for XPATH wrapper."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "XPATH considers a simple fragment of the xpath language, consisting of child edges (/), descendant edges (//), attribute filters ([@fontsize=2]) and child number filters (td[2])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 70
                            }
                        ],
                        "text": ", prefixsuffix pairs [15, 14], finite-state automaton [17] and xpaths [6, 1, 18], and various algorithms designed for learning wrappers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 100
                            }
                        ],
                        "text": "Furthermore, we observe that the individual contribution of the components differ significantly for XPATH and LR wrappers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 47
                            }
                        ],
                        "text": "The above representation enables us to express XPATH as a feature-based wrapper using a small number of features, and TopDown algorithm can be used to enumerate the wrapper space for XPATH."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 24
                            }
                        ],
                        "text": "The second line of work [14, 15, 6] uses rule induction to learn wrappers from a small number of labeled examples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 163
                            }
                        ],
                        "text": "Figure 2(d) shows the precision, recall, and the f1-measure, which is the harmonic mean of the precision and recall, for the naive algorithm and our methods using XPATH wrappers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6], which we refer to in this paper as XPATH (2)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10711472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b47e5640376b1a3858e1f8119b8588d1e7517f6c",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "On script-generated web sites, many documents share common HTML tree structure, allowing wrappers to effectively extract information of interest. Of course, the scripts and thus the tree structure evolve over time, causing wrappers to break repeatedly, and resulting in a high cost of maintaining wrappers. In this paper, we explore a novel approach: we use temporal snapshots of web pages to develop a tree-edit model of HTML, and use this model to improve wrapper construction. We view the changes to the tree structure as suppositions of a series of edit operations: deleting nodes, inserting nodes and substituting labels of nodes. The tree structures evolve by choosing these edit operations stochastically. Our model is attractive in that the probability that a source tree has evolved into a target tree can be estimated efficiently--in quadratic time in the size of the trees--making it a potentially useful tool for a variety of tree-evolution problems. We give an algorithm to learn the probabilistic model from training examples consisting of pairs of trees, and apply this algorithm to collections of web-page snapshots to derive HTML-specific tree edit models. Finally, we describe a novel wrapper-construction framework that takes the tree-edit model into account, and compare the quality of resulting wrappers to that of traditional wrappers on synthetic and real HTML document examples."
            },
            "slug": "Robust-web-extraction:-an-approach-based-on-a-model-Dalvi-Bohannon",
            "title": {
                "fragments": [],
                "text": "Robust web extraction: an approach based on a probabilistic tree-edit model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper uses temporal snapshots of web pages to develop a tree-edit model of HTML, and uses this model to improve wrapper construction, and gives an algorithm to learn the probabilistic model from training examples consisting of pairs of trees."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16677640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29c99d263b5e05aae6bb96f004f025dcc9b5caae",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Information extraction IE is the problem of lling out pre de ned structured sum maries from text documents We are in terested in performing IE in non traditional domains where much of the text is often ungrammatical such as electronic bulletin board posts and Web pages We suggest that the best approach is one that takes into ac count many di erent kinds of information and argue for the suitability of a multistrat egy approach We describe learners for IE drawn from three separate machine learning paradigms rote memorization term space text classi cation and relational rule induc tion By building regression models mapping from learner con dence to probability of cor rectness and combining probabilities appro priately it is possible to improve extraction accuracy over that achieved by any individ ual learner We describe three di erent mul tistrategy approaches Experiments on two IE domains a collection of electronic seminar announcements from a university computer science department and a set of newswire ar ticles describing corporate acquisitions from the Reuters collection demonstrate the e ec tiveness of all three approaches"
            },
            "slug": "Multistrategy-Learning-for-Information-Extraction-Freitag",
            "title": {
                "fragments": [],
                "text": "Multistrategy Learning for Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is possible to improve extraction accuracy over that achieved by any individ ual learner by building regression models mapping from learner con dence to probability of cor rectness and combining probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1883948"
                        ],
                        "name": "A. Sahuguet",
                        "slug": "A.-Sahuguet",
                        "structuredName": {
                            "firstName": "Arnaud",
                            "lastName": "Sahuguet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sahuguet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3181471"
                        ],
                        "name": "Fabien Azavant",
                        "slug": "Fabien-Azavant",
                        "structuredName": {
                            "firstName": "Fabien",
                            "lastName": "Azavant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabien Azavant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 121
                            }
                        ],
                        "text": "Such a rule is called a wrapper, and the problem of inducing wrappers from labeled examples has been extensively studied [15, 13, 11, 19, 18, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7252520,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba1b6020d376dd28d4b1d3598c16e9477f379113",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The Web has become a major conduit to information repositories of all kinds. Today, more than 80% of information published on the Web is generated by underlying databases (however access is granted through a Web gateway using forms as a query language and HTML as a display vehicle) and this proportion keeps increasing. But Web data sources also consist of standalone HTML pages hand-coded by individuals, that provide very useful information such as reviews, digests, links, etc. As for the information that also exists in underlying databases, the HTML interface is often the only one available for many would-be clients."
            },
            "slug": "Building-Light-Weight-Wrappers-for-Legacy-Web-Using-Sahuguet-Azavant",
            "title": {
                "fragments": [],
                "text": "Building Light-Weight Wrappers for Legacy Web Data-Sources Using W4F"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The Web has become a major conduit to information repositories of all kinds, but Web data sources also consist of standalone HTML pages hand-coded by individuals, that provide very useful information such as reviews, digests, links, etc."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725561"
                        ],
                        "name": "Michael J. Cafarella",
                        "slug": "Michael-J.-Cafarella",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cafarella",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Cafarella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111220343"
                        ],
                        "name": "D. Wang",
                        "slug": "D.-Wang",
                        "structuredName": {
                            "firstName": "Daisy",
                            "lastName": "Wang",
                            "middleNames": [
                                "Zhe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48144872"
                        ],
                        "name": "Eugene Wu",
                        "slug": "Eugene-Wu",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145955157"
                        ],
                        "name": "Yang Zhang",
                        "slug": "Yang-Zhang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15642206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b5077161a6f55a0d18cdfa3abbb612663d08d69",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The World-Wide Web consists of a huge number of unstructured documents, but it also contains structured data in the form of HTML tables. We extracted 14.1 billion HTML tables from Google's general-purpose web crawl, and used statistical classification techniques to find the estimated 154M that contain high-quality relational data. Because each relational table has its own \"schema\" of labeled and typed columns, each such table can be considered a small structured database. The resulting corpus of databases is larger than any other corpus we are aware of, by at least five orders of magnitude. \n \nWe describe the WEBTABLES system to explore two fundamental questions about this collection of databases. First, what are effective techniques for searching for structured data at search-engine scales? Second, what additional power can be derived by analyzing such a huge corpus? \n \nFirst, we develop new techniques for keyword search over a corpus of tables, and show that they can achieve substantially higher relevance than solutions based on a traditional search engine. Second, we introduce a new object derived from the database corpus: the attribute correlation statistics database (AcsDB) that records corpus-wide statistics on co-occurrences of schema elements. In addition to improving search relevance, the AcsDB makes possible several novel applications: schema auto-complete, which helps a database designer to choose schema elements; attribute synonym finding, which automatically computes attribute synonym pairs for schema matching; and join-graph traversal, which allows a user to navigate between extracted schemas using automatically-generated join links."
            },
            "slug": "WebTables:-exploring-the-power-of-tables-on-the-web-Cafarella-Halevy",
            "title": {
                "fragments": [],
                "text": "WebTables: exploring the power of tables on the web"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The WEBTABLES system develops new techniques for keyword search over a corpus of tables, and shows that they can achieve substantially higher relevance than solutions based on a traditional search engine."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48183592"
                        ],
                        "name": "Bin He",
                        "slug": "Bin-He",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bin He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143922493"
                        ],
                        "name": "K. Chang",
                        "slug": "K.-Chang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Chang",
                            "middleNames": [
                                "Chen-Chuan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6980873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42a188a17cc48160457624b790d188b18682a938",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The Web has been rapidly \"deepened\" by myriad searchable databases online, where data are hidden behind query interfaces. As an essential task toward integrating these massive \"deep Web\" sources, large scale schema matching (i.e., discovering semantic correspondences of attributes across many query interfaces) has been actively studied recently. In particular, many works have emerged to address this problem by \"holistically\" matching many schemas at the same time and thus pursuing \"mining\" approaches in nature. However, while holistic schema matching has built its promise upon the large quantity of input schemas, it also suffers the robustness problem caused by noisy data quality. Such noises often inevitably arise in the automatic extraction of schema data, which is mandatory in large scale integration. For holistic matching to be viable, it is thus essential to make it robust against noisy schemas. To tackle this challenge, we propose a data-ensemble framework with sampling and voting techniques, which is inspired by bagging predictors. Specifically, our approach creates an ensemble of matchers, by randomizing input schema data into many independently downsampled trials, executing the same matcher on each trial and then aggregating their ranked results by taking majority voting. As a principled basis, we provide analytic justification of the effectiveness of this data-ensemble framework. Further, empirically, our experiments on real Web data show that the \"ensemblization\" indeed significantly boosts the matching accuracy under noisy schema input, and thus maintains the desired robustness of a holistic matcher."
            },
            "slug": "Making-holistic-schema-matching-robust:-an-ensemble-He-Chang",
            "title": {
                "fragments": [],
                "text": "Making holistic schema matching robust: an ensemble approach"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experiments on real Web data show that the \"ensemblization\" indeed significantly boosts the matching accuracy under noisy schema input, and thus maintains the desired robustness of a holistic matcher, and a principled basis is provided for analytic justification of the effectiveness of this data-ensemble framework."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8250918"
                        ],
                        "name": "Guizhen Yang",
                        "slug": "Guizhen-Yang",
                        "structuredName": {
                            "firstName": "Guizhen",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guizhen Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145761288"
                        ],
                        "name": "I. Ramakrishnan",
                        "slug": "I.-Ramakrishnan",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Ramakrishnan",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Ramakrishnan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1989587"
                        ],
                        "name": "M. Kifer",
                        "slug": "M.-Kifer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kifer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kifer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14636840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29192504d69fe67be5113204749c415b402b96a6",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "An increasingly large number of Web pages are machine-generated by filling in templates with data stored in backend databases. These templates can be viewed as the implicit schemas of those Web pages. The ability to infer the implicit schema from a collection of Web pages is important for scalable data extraction, since the inferred schema can be used to automatically identify schema attributes that are \"encoded\" in Web pages.However, the task of inferring a \"good\" schema is complicated due to the existence of nullable (missing) data attributes. Usually if an attribute contains a null value, then it will be omitted in the generated Web page, giving rise to different variations and permutations of layout structures in Web pages that are generated from the same template.In this paper we investigate the complexity of schema inference from Web pages in the presence of nullable data attributes. We introduce the notion of unambiguity as a quality measure for inferred schemas and prove that the problem of inferring \"good\" (unambiguous) schemas is NP-complete. Our complexity results imply that ambiguity resolution is one of the root causes of the computational difficulty underlying schema inference from Web pages."
            },
            "slug": "On-the-complexity-of-schema-inference-from-web-in-Yang-Ramakrishnan",
            "title": {
                "fragments": [],
                "text": "On the complexity of schema inference from web pages in the presence of nullable data attributes"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper investigates the complexity of schema inference from Web pages in the presence of nullable data attributes and introduces the notion of unambiguity as a quality measure for inferred schemas and proves that the problem of inferring \"good\" (unambiguous) schemas is NP-complete."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2224716"
                        ],
                        "name": "J. Madhavan",
                        "slug": "J.-Madhavan",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Madhavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143701664"
                        ],
                        "name": "L. Afanasiev",
                        "slug": "L.-Afanasiev",
                        "structuredName": {
                            "firstName": "Loredana",
                            "lastName": "Afanasiev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Afanasiev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3013198"
                        ],
                        "name": "Lyublena Antova",
                        "slug": "Lyublena-Antova",
                        "structuredName": {
                            "firstName": "Lyublena",
                            "lastName": "Antova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lyublena Antova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770962"
                        ],
                        "name": "A. Halevy",
                        "slug": "A.-Halevy",
                        "structuredName": {
                            "firstName": "Alon",
                            "lastName": "Halevy",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Halevy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": ") For each store locator page, we can use automatic form-filling techniques [16] to easily generate a large collection of HTML pages, each corresponding to store listing in a particular location."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 499698,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb0c56ef70a998c633b43bc4e470ee1983a7c0b8",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The Deep Web refers to content hidden behind HTML forms. In order to get to such content, a user has to perform a form submission with valid input values. The name Deep Web arises from the fact that such content was thought to be beyond the reach of search engines. The Deep Web is also believed to be the biggest source of structured data on the Web and hence accessing its contents has been a long standing challenge in the data management community [1, 8, 9, 13, 14, 18, 19]. Over the past few years, we have built a system that exposed content from the Deep Web to web-search users of Google.com. The results of our surfacing are now shown in over 1000 web-search queries per-second, and the content surfaced is in over 45 languages and in hundreds of domains. The algorithms underlying our system are described in [12]. In this paper we report some of our key observations in building our system and outline the main challenges we see in the further exploration and use of deep-web content. To understand the different efforts on providing access to deep-web content, we first present the rapidly changing landscape of different kinds of structured data that exist on the web and the relationships between them (Section 2). In fact, there appears to be some confusion about the term Deep Web \u2013 it has often been incorrectly used synonymously with structured data on the Web. The Deep Web is one (significant) source of data, much of which is structured, but not the only one. We describe the different types of structured data in the context of the varying search tasks that we can strive to support over them. Second, we discuss our choice of underlying approach in exposing deep-web content in a search engine. Most prior works on the Deep Web have espoused one of two main approaches. The first, known as virtual integration, follows the data integration paradigm. Here, we consider each deepweb site as a source in a data integration system. Users pose queries over a mediated schema that is exposed to them as a web form, and queries are routed to the relevant sites. The second, known as surfacing, attempts to"
            },
            "slug": "Harnessing-the-Deep-Web:-Present-and-Future-Madhavan-Afanasiev",
            "title": {
                "fragments": [],
                "text": "Harnessing the Deep Web: Present and Future"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper reports some of the key observations in building the system that exposed content from the Deep Web to web-search users of Google.com and discusses the choice of underlying approach in exposing deep-web content in a search engine."
            },
            "venue": {
                "fragments": [],
                "text": "CIDR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 47328136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1ee87290fa827f1217b8fa2bccb3485da1a300e",
            "isKey": false,
            "numCitedBy": 15183,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy."
            },
            "slug": "Bagging-predictors-Breiman",
            "title": {
                "fragments": [],
                "text": "Bagging predictors"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72500530"
                        ],
                        "name": "\u8463\u96f7",
                        "slug": "\u8463\u96f7",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\u8463\u96f7",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u8463\u96f7"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "149386911"
                        ],
                        "name": "\u9976\u4ead",
                        "slug": "\u9976\u4ead",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\u9976\u4ead",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u9976\u4ead"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 190333964,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9f0533e39818c0f12622ddf2b3df37670219b817",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "\u201dShe Walksin Beauty\u201d\u662f19\u4e16\u7eaa\u521d\u8457\u540d\u7684\u82f1\u56fd\u6d6a\u6f2b\u4e3b\u4e49\u8bd7\u4eba\u62dc\u4f26\u7684\u503e\u5fc3\u4e4b\u4f5c\uff1a\u672c\u6587\u8bd5\u4ece\u8bd7\u4eba\u7684\u6280\u6cd5\u4ee5\u53ca\u8bd7\u5185\u5916\u6240\u4f53\u73b0\u7684\u7f8e\u4e4b\u7eaf\u7cb9\u6765\u5bf9\u8be5\u8bd7\u8fdb\u884c\u8d4f\u6790\uff0c\u5e76\u7ed3\u5408\u4ee5\u5f80\u7ffb\u8bd1\u5bb6\u5bf9\u8be5\u8bd7\u7684\u7406\u89e3\u6765\u8ba9\u66f4\u591a\u7684\u4e2d\u56fd\u8bfb\u8005\u5bf9\u6b64\u8bd7\u6709\u66f4\u8d34\u5207\u548c\u66f4\u6df1\u5165\u7684\u6b23\u8d4f\u3002"
            },
            "slug": "\u8d4f\u6790\u62dc\u4f26\u7684\u201cShe-Walks-in-Beauty\u201d-\u8463\u96f7-\u9976\u4ead",
            "title": {
                "fragments": [],
                "text": "\u8d4f\u6790\u62dc\u4f26\u7684\u201cShe Walks in Beauty\u201d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079828"
                        ],
                        "name": "Tobias D\u00f6nz",
                        "slug": "Tobias-D\u00f6nz",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "D\u00f6nz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias D\u00f6nz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "//div[@class = content]/table[1]/tr/td[2]/text(), (3)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 46
                            }
                        ],
                        "text": "The first line of work is on grammar learning [2, 5], which focus on the web publication process, and try to infer the grammar that generated the given set of webpages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 62
                            }
                        ],
                        "text": "There are several work that model the web publication process [2, 5], and try to infer the grammar that generated the given set of webpages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "XPATH considers a simple fragment of the xpath language, consisting of child edges (/), descendant edges (//), attribute filters ([@fontsize=2]) and child number filters (td[2])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "It has td[2] at position 1, tr at position 2, table[1] at position 3 and so on."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13550720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb16e487560e82aacc9cea9cb662c9eb324aa80",
            "isKey": true,
            "numCitedBy": 417,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Extracting-Structured-Data-from-Web-Pages-D\u00f6nz",
            "title": {
                "fragments": [],
                "text": "Extracting Structured Data from Web Pages"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117253379"
                        ],
                        "name": "G. Jampolsky",
                        "slug": "G.-Jampolsky",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Jampolsky",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jampolsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152582090"
                        ],
                        "name": "Diane V. Cirincione",
                        "slug": "Diane-V.-Cirincione",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Cirincione",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diane V. Cirincione"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 150154343,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "4a23e9f1e9a317869ec0ec8e387234844c60385e",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Love-Is-the-Answer-Jampolsky-Cirincione",
            "title": {
                "fragments": [],
                "text": "Love Is the Answer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Kushmerick . Wrapper induction : Efficiency and expressiveness"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "If It Rains on Tuesday"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wrapping web data into XML. SIGMOD Record"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Automatic-Wrappers-for-Large-Scale-Web-Extraction-Dalvi-Kumar/65ec5824f6a997df0322827285ee691510b4527a?sort=total-citations"
}