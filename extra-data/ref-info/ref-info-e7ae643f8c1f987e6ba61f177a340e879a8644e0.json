{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143775793"
                        ],
                        "name": "J. Kumar",
                        "slug": "J.-Kumar",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144449660"
                        ],
                        "name": "Peng Ye",
                        "slug": "Peng-Ye",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In Kumar et al. (2012), we proposed a recursive horizontal-vertical partitioning scheme to learn spatial relationships in document images based on the observation that document objects have a horizontal and vertical bias."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In Kumar et al. (2012), we explored an unsupervised feature learning method, using raw-image patches, to construct a codebook representation of basic structural elements in document images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 37
                            }
                        ],
                        "text": "RIP based features were presented in Kumar et al. (2012), and were shown to be very effective for document classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 151
                            }
                        ],
                        "text": "In the third, the objective is to demonstrate the advantage of SURF codewords, so we compare our spatial features with raw-image-patch based features (Kumar et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 64
                            }
                        ],
                        "text": "Although raw image-patch based features are fast and effective (Kumar et al., 2012), they are not invariant to scale or robust to noise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 155
                            }
                        ],
                        "text": "Recent work has focused on developing general methods capable of handling less constrained handwritten documents and datasets with highly variable layout (Kumar et al., 2011, 2012; Jain and Doermann, 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 210
                            }
                        ],
                        "text": "Subsequently, there has been focus on selecting the optimal feature combination strategy and efficient ways to learn these local statistics, and a number of methods have been proposed (Yang et al., 2009, 2011; Kumar et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 391056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31da8cace27a08e6339145f95f190a77197f01b2",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a method for the retrieval of document images with chosen layout characteristics. The proposed method is based on statistics of patch-codewords over different regions of image. We begin with a set of wanted and a random set of unwanted images representative of a large heterogeneous collection. We then use raw-image patches extracted from the unlabeled images to learn a codebook. To model the spatial relationships between patches, the image is recursively partitioned horizontally and vertically, and a histogram of patch-codewords is computed in each partition. The resulting set of features give a high precision and recall for the retrieval of hand-drawn and machine-print table-documents, and unconstrained mixed form-type documents, when trained using a random forest classifier. We compare our method to the spatial-pyramid method, and show that the proposed approach for learning layout characteristics is competitive for document images."
            },
            "slug": "Learning-document-structure-for-retrieval-and-Kumar-Ye",
            "title": {
                "fragments": [],
                "text": "Learning document structure for retrieval and classification"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The proposed method is based on statistics of patch-codewords over different regions of image, which gives a high precision and recall for the retrieval of hand-drawn and machine-print table-documents, and unconstrained mixed form-type documents, when trained using a random forest classifier."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144338164"
                        ],
                        "name": "Siyuan Chen",
                        "slug": "Siyuan-Chen",
                        "structuredName": {
                            "firstName": "Siyuan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siyuan Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119287726"
                        ],
                        "name": "Yuan He",
                        "slug": "Yuan-He",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144291081"
                        ],
                        "name": "Jun Sun",
                        "slug": "Jun-Sun",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753831"
                        ],
                        "name": "S. Naoi",
                        "slug": "S.-Naoi",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Naoi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Naoi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 165
                            }
                        ],
                        "text": "A large number of retrieval techniques have been developed using a query by example paradigm (Zhu and Doermann, 2009; Marinai et al., 2011; Jain and Doermann, 2012; Chen et al., 2012a), where features are extracted and indexed from document images off-line."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 156
                            }
                        ],
                        "text": "Previous work have reported similar high accuracies on this dataset but they used a much larger training set in their experiments (Shin and Doermann, 2006; Chen et al., 2012b)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 12462738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "887e5ebacf16eebe47a187ff1b1e45bc0d96e464",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Following the recent trend in using low level image features in classifying document images, in this paper we present a novel approach for structured document classification by matching the salient feature points between the query image and the reference images. Our method is robust to diverse training data size, image formats and qualities. Through matching the feature points, image registration is available for the query image as well. Although we aimed for the large domain of the structured document images, our method already achieved zero error rates in the tests on the benchmark NIST tax form databases."
            },
            "slug": "Structured-document-classification-by-matching-Chen-He",
            "title": {
                "fragments": [],
                "text": "Structured document classification by matching local salient features"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper presents a novel approach for structured document classification by matching the salient feature points between the query image and the reference images, which is robust to diverse training data size, image formats and qualities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1941286"
                        ],
                        "name": "Christian K. Shin",
                        "slug": "Christian-K.-Shin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Shin",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian K. Shin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 256
                            }
                        ],
                        "text": "\u2026support and general document image search which depend on efficient and effective methods for computing similarity, previous approaches have focused on content-specific features or layout-specific structures (Collins-Thompson and Nickolov, 2002; Shin and Doermann, 2006; Zhu et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 140
                            }
                        ],
                        "text": "Previous work have reported similar high accuracies on this dataset but they used a much larger training set in their experiments (Shin and Doermann, 2006; Chen et al., 2012b)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 9
                            }
                        ],
                        "text": "Shin and Doermann (2006) defined visual similarity of layout structures and applied supervised classification for each specific type."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 138
                            }
                        ],
                        "text": "One effective way to define layout similarity for matching is based on structural features (Collins-Thompson and Nickolov, 2002; Shin and Doermann, 2006; Joutel et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 131
                            }
                        ],
                        "text": "Finding structurally similar images in large heterogenous document image collections has been of interest for many years (Shin and Doermann, 2006; Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8015543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d67d64b16537107ccb81af1915b7b0b40b147300",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe issues related to the measurement of structural similarity between document images. We define structural similarity, and discuss the benefits of using it as a complement to content similarity for querying document image databases. We present an approach to computing a geometrically invariant structural similarity, and use this measure to search document image databases. Our approach supports both full image matching using query by example (QBE) and sub-image matching using query by sketch (QBS). The similarity measure considers spatial and layout structure, and is computed by aggregating content area overlap measures with respect to their underlying column structures. These techniques are tested within the Intelligent Document Image Retrieval (IDIR) System, and results demonstrating effectiveness and efficiency of structure queries with respect to human relevance judgments are presented."
            },
            "slug": "Document-Image-Retrieval-Based-on-Layout-Structural-Shin-Doermann",
            "title": {
                "fragments": [],
                "text": "Document Image Retrieval Based on Layout Structural Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An approach to computing a geometrically invariant structural similarity, and use this measure to search document image databases, and results demonstrating effectiveness and efficiency of structure queries with respect to human relevance judgments are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IPCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285734"
                        ],
                        "name": "S. Marinai",
                        "slug": "S.-Marinai",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Marinai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marinai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40429927"
                        ],
                        "name": "E. Marino",
                        "slug": "E.-Marino",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Marino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Marino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 212
                            }
                        ],
                        "text": "Furthermore, as previously mentioned, a majority of the work published on defining and applying structural similarity is specific to a particular document type, such as business letters (Dengel and Dubiel, 1995; Marinai et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14686135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae245c4cdc4b2a669d39d0f361c1e87d191d83fa",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system for the retrieval on the basis of layout similarity of document images belonging to collections stored in digital libraries. Layout regions are extracted and represented with the XY tree. The proposed indexing method combines a new tree clustering algorithm (based on self organizing maps) with principal component analysis. The combination of these techniques allows us to retrieve the most similar pages from large collections without the need for a direct comparison of the query page with each indexed document"
            },
            "slug": "Tree-clustering-for-layout-based-document-image-Marinai-Marino",
            "title": {
                "fragments": [],
                "text": "Tree clustering for layout-based document image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The proposed indexing method combines a new tree clustering algorithm (based on self organizing maps) with principal component analysis that allows us to retrieve the most similar pages from large collections without the need for a direct comparison of the query page with each indexed document."
            },
            "venue": {
                "fragments": [],
                "text": "Second International Conference on Document Image Analysis for Libraries (DIAL'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114036784"
                        ],
                        "name": "Guangyu Zhu",
                        "slug": "Guangyu-Zhu",
                        "structuredName": {
                            "firstName": "Guangyu",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guangyu Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 138
                            }
                        ],
                        "text": "Documents which result in a number of 108 matches above a certain threshold are considered relevant and can be ge109 ometrically verified (Zhu and Doermann, 2009; Jain and Doermann, 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 101
                            }
                        ],
                        "text": "102 A large number of retrieval techniques have been developed using a 103 query by example paradigm (Zhu and Doermann, 2009; Marinai et al., 2011; 104 Jain and Doermann, 2012; Chen et al., 2012a), where features are extracted 105 and indexed from document images off-line."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 94
                            }
                        ],
                        "text": "A large number of retrieval techniques have been developed using a query by example paradigm (Zhu and Doermann, 2009; Marinai et al., 2011; Jain and Doermann, 2012; Chen et al., 2012a), where features are extracted and indexed from document images off-line."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 131
                            }
                        ],
                        "text": "Documents which result in a number of matches above a certain threshold are considered relevant and can be geometrically verified (Zhu and Doermann, 2009; Jain and Doermann, 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7664277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7bc2f7644bd277221adbc44557c3b42b21334f4d",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphics detection and recognition are fundamental research problems in document image analysis and retrieval. As one of the most pervasive graphical elements in business and government documents, logos may enable immediate identification of organizational entities and serve extensively as a declaration of a document's source and ownership. In this work, we developed an automatic logo-based document image retrieval system that handles: 1) Logo detection and segmentation by boosting a cascade of classifiers across multiple image scales; and 2) Logo matching using translation, scale, and rotation invariant shape descriptors and matching algorithms. Our approach is segmentation free and layout independent and we address logo retrieval in an unconstrained setting of 2-D feature point matching. Finally, we quantitatively evaluate the effectiveness of our approach using large collections of real-world complex document images."
            },
            "slug": "Logo-Matching-for-Document-Image-Retrieval-Zhu-Doermann",
            "title": {
                "fragments": [],
                "text": "Logo Matching for Document Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work developed an automatic logo-based document image retrieval system that handles logo detection and segmentation by boosting a cascade of classifiers across multiple image scales; and logo matching using translation, scale, and rotation invariant shape descriptors and matching algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114036784"
                        ],
                        "name": "Guangyu Zhu",
                        "slug": "Guangyu-Zhu",
                        "structuredName": {
                            "firstName": "Guangyu",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guangyu Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110381386"
                        ],
                        "name": "Yefeng Zheng",
                        "slug": "Yefeng-Zheng",
                        "structuredName": {
                            "firstName": "Yefeng",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yefeng Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144230620"
                        ],
                        "name": "Stefan Jaeger",
                        "slug": "Stefan-Jaeger",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Jaeger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Jaeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5288845,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d9fcf95d13b19a19227e845d92faa072f62ea15",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "As one of the most pervasive methods of individual identification and document authentication, signatures present convincing evidence and provide an important form of indexing for effective document image processing and retrieval in a broad range of applications. However, detection and segmentation of free-form objects such as signatures from clustered background is currently an open document analysis problem. In this paper, we focus on two fundamental problems in signature-based document image retrieval. First, we propose a novel multiscale approach to jointly detecting and segmenting signatures from document images. Rather than focusing on local features that typically have large variations, our approach captures the structural saliency using a signature production model and computes the dynamic curvature of 2D contour fragments over multiple scales. This detection framework is general and computationally tractable. Second, we treat the problem of signature retrieval in the unconstrained setting of translation, scale, and rotation invariant nonrigid shape matching. We propose two novel measures of shape dissimilarity based on anisotropic scaling and registration residual error and present a supervised learning framework for combining complementary shape information from different dissimilarity metrics using LDA. We quantitatively study state-of-the-art shape representations, shape matching algorithms, measures of dissimilarity, and the use of multiple instances as query in document image retrieval. We further demonstrate our matching techniques in offline signature verification. Extensive experiments using large real-world collections of English and Arabic machine-printed and handwritten documents demonstrate the excellent performance of our approaches."
            },
            "slug": "Signature-Detection-and-Matching-for-Document-Image-Zhu-Zheng",
            "title": {
                "fragments": [],
                "text": "Signature Detection and Matching for Document Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a novel multiscale approach to jointly detecting and segmenting signatures from document images, and quantitatively studies state-of-the-art shape representations, shape matching algorithms, measures of dissimilarity, and the use of multiple instances as query in document image retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39878379"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 140
                            }
                        ],
                        "text": "A large number of retrieval techniques have been developed using a query by example paradigm (Zhu and Doermann, 2009; Marinai et al., 2011; Jain and Doermann, 2012; Chen et al., 2012a), where features are extracted and indexed from document images off-line."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 155
                            }
                        ],
                        "text": "Documents which result in a number of matches above a certain threshold are considered relevant and can be geometrically verified (Zhu and Doermann, 2009; Jain and Doermann, 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 181
                            }
                        ],
                        "text": "Recent work has focused on developing general methods capable of handling less constrained handwritten documents and datasets with highly variable layout (Kumar et al., 2011, 2012; Jain and Doermann, 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8228374,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ad1b24d20128f998a29f06a8d59058955709bbe",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a scalable algorithm for segmentation free logo retrieval in document images. The contributions include the use of the SURF feature for logo retrieval, a novel indexing algorithm for efficient retrieval and a method to filter results using the orientation of local features and geometric constraints. Results demonstrate that logo retrieval can be performed with high accuracy and efficiently scaled to a large datasets."
            },
            "slug": "Logo-Retrieval-in-Document-Images-Jain-Doermann",
            "title": {
                "fragments": [],
                "text": "Logo Retrieval in Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A scalable algorithm for segmentation free logo retrieval in document images using the use of the SURF feature for logo retrieval, a novel indexing algorithm for efficient retrieval and a method to filter results using the orientation of local features and geometric constraints."
            },
            "venue": {
                "fragments": [],
                "text": "2012 10th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285734"
                        ],
                        "name": "S. Marinai",
                        "slug": "S.-Marinai",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Marinai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marinai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48997215"
                        ],
                        "name": "Beatrice Miotti",
                        "slug": "Beatrice-Miotti",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Miotti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Miotti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15591541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d0cf0addff9cb7a74a14338064d771f4ac37ebc",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 101,
            "paperAbstract": {
                "fragments": [],
                "text": "Nowadays, Digital Libraries have become a widely used service to store and share both digital born documents and digital versions of works stored by traditional libraries. Document images are intrinsically non-structured and the structure and semantic of the digitized documents is in most part lost during the conversion. Several techniques related to the Document Image Analysis research area have been proposed in the past to deal with document image retrieval applications. In this chapter a survey about the more recent techniques applied in the field of recognition and retrieval of text and graphical documents is presented. In particular we describe techniques related to recognition-free approaches."
            },
            "slug": "Digital-Libraries-and-Document-Image-Retrieval-A-Marinai-Miotti",
            "title": {
                "fragments": [],
                "text": "Digital Libraries and Document Image Retrieval Techniques: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In this chapter a survey about the more recent techniques applied in the field of recognition and retrieval of text and graphical documents is presented and techniques related to recognition-free approaches are described."
            },
            "venue": {
                "fragments": [],
                "text": "Learning Structure and Schemas from Documents"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403434962"
                        ],
                        "name": "K. Collins-Thompson",
                        "slug": "K.-Collins-Thompson",
                        "structuredName": {
                            "firstName": "Kevyn",
                            "lastName": "Collins-Thompson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Collins-Thompson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 210
                            }
                        ],
                        "text": "\u2026support and general document image search which depend on efficient and effective methods for computing similarity, previous approaches have focused on content-specific features or layout-specific structures (Collins-Thompson and Nickolov, 2002; Shin and Doermann, 2006; Zhu et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 92
                            }
                        ],
                        "text": "One effective way to define layout similarity for matching is based on structural features (Collins-Thompson and Nickolov, 2002; Shin and Doermann, 2006; Joutel et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 0
                            }
                        ],
                        "text": "Collins-Thompson and Nickolov (2002) proposed a model for estimating the inter-page similarity in ordered collections of document images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 359,
                                "start": 279
                            }
                        ],
                        "text": "While there are numerous applications in office automation, litigation support and general document image search which depend on efficient and effective methods for computing similarity, previous approaches have focused on content-specific features or layout-specific structures (Collins-Thompson and Nickolov, 2002; Shin and Doermann, 2006; Zhu et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1366361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29febec8e0415fb3ac4b64a269d2c3016f6d9b65",
            "isKey": true,
            "numCitedBy": 32,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "For text, audio, video, and still images, a number of projects have addressed the problem of estimating inter-object similarity and the related problem of finding transition, or \u2018segmentation\u2019 points in a stream of objects of the same media type. There has been relatively little work in this area for document images, which are typically text-intensive and contain a mixture of layout, text-based, and image features. Beyond simple partitioning, the problem of clustering related page images is also important, especially for information retrieval problems such as document image searching and browsing. Motivated by this, we describe a model for estimating inter-page similarity in ordered collections of document images, based on a combination of text and layout features. The features are used as input to a discriminative classifier, whose output is used in a constrained clustering criterion. We do a task-based evaluation of our method by applying it the problem of automatic document separation during batch scanning. Using layout and page numbering features, our algorithm achieved a separation accuracy of 95.6% on the test collection."
            },
            "slug": "A-Clustering-Based-Algorithm-for-Automatic-Document-Collins-Thompson",
            "title": {
                "fragments": [],
                "text": "A Clustering-Based Algorithm for Automatic Document Separation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model for estimating inter-page similarity in ordered collections of document images, based on a combination of text and layout features is described, which achieves a separation accuracy of 95.6% on the test collection."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 3
                            }
                        ],
                        "text": "In Lazebnik et al. (2006), features at coarser level were given less weights compared to features extracted from fine-regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 107
                            }
                        ],
                        "text": "In our experiments, we report accuracies for SP-LSVM and SP-RSVM using feature weighting scheme similar to Lazebnik et al. (2006), and for RF based approaches we used uniform weights."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 57
                            }
                        ],
                        "text": "We compare our approach with the spatial-pyramid method (Lazebnik et al., 2006) and show that the proposed method gives superior performance on many document retrieval and classification tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 197
                            }
                        ],
                        "text": "One of the early methods proposes the creation of spatial-pyramid features by partitioning the image into increasingly finer grids and computing the weighted histogram based kernel in each region (Lazebnik et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 86
                            }
                        ],
                        "text": "Spatial-pyramid with Support vector machine: Spatial-pyramid matching was proposed by Lazebnik et al. (2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": true,
            "numCitedBy": 8328,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060000798"
                        ],
                        "name": "E. Barbu",
                        "slug": "E.-Barbu",
                        "structuredName": {
                            "firstName": "Eugen",
                            "lastName": "Barbu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Barbu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1826457"
                        ],
                        "name": "P. H\u00e9roux",
                        "slug": "P.-H\u00e9roux",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "H\u00e9roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. H\u00e9roux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143680806"
                        ],
                        "name": "S\u00e9bastien Adam",
                        "slug": "S\u00e9bastien-Adam",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35863204"
                        ],
                        "name": "\u00c9. Trupin",
                        "slug": "\u00c9.-Trupin",
                        "structuredName": {
                            "firstName": "\u00c9ric",
                            "lastName": "Trupin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. Trupin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 43
                            }
                        ],
                        "text": ", 2005), and document image categorization (Barbu et al., 2006; Kumar et al., 2011)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 239
                            }
                        ],
                        "text": "Approaches based on bag-of-words (BOW) models have shown promising results on many computer vision tasks such as image classification (Wallraven et al., 2003), scene understanding (Quelhas et al., 2005), and document image categorization (Barbu et al., 2006; Kumar et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10662134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf83c2268d4cad01700c9869f34d1d8b275f8616",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A database is only usefull if it is associated a set of procedures allowing to retrieve relevant elements for the users\u2019 needs. A lot of IR techniques have been developed for automatic indexing and retrieval in document databases. Most of these use indexes depending on the textual content of documents, and very few are able to handle graphical or image content without human annotation. \n \nThis paper describes an approach similar to the bag of words technique for automatic indexing of graphical document image databases and different ways to consequently query these databases. In an unsupervised manner, this approach proposes a set of automatically discovered symbols that can be combined with logical operators to build queries."
            },
            "slug": "Using-Bags-of-Symbols-for-Automatic-Indexing-of-Barbu-H\u00e9roux",
            "title": {
                "fragments": [],
                "text": "Using Bags of Symbols for Automatic Indexing of Graphical Document Image Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes an approach similar to the bag of words technique for automatic indexing of graphical document image databases and different ways to consequently query these databases using a set of automatically discovered symbols that can be combined with logical operators to build queries."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3351018"
                        ],
                        "name": "Pedro Quelhas",
                        "slug": "Pedro-Quelhas",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Quelhas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro Quelhas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1824057"
                        ],
                        "name": "Florent Monay",
                        "slug": "Florent-Monay",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Monay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florent Monay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719610"
                        ],
                        "name": "J. Odobez",
                        "slug": "J.-Odobez",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Odobez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odobez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403029865"
                        ],
                        "name": "D. G\u00e1tica-P\u00e9rez",
                        "slug": "D.-G\u00e1tica-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "G\u00e1tica-P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G\u00e1tica-P\u00e9rez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14100761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba6417baed41a8f0fd4cab342aa214704389dcf9",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach to model visual scenes in image collections, based on local invariant features and probabilistic latent space models. Our formulation provides answers to three open questions:(l) whether the invariant local features are suitable for scene (rather than object) classification; (2) whether unsupennsed latent space models can be used for feature extraction in the classification task; and (3) whether the latent space formulation can discover visual co-occurrence patterns, motivating novel approaches for image organization and segmentation. Using a 9500-image dataset, our approach is validated on each of these issues. First, we show with extensive experiments on binary and multi-class scene classification tasks, that a bag-of-visterm representation, derived from local invariant descriptors, consistently outperforms state-of-the-art approaches. Second, we show that probabilistic latent semantic analysis (PLSA) generates a compact scene representation, discriminative for accurate classification, and significantly more robust when less training data are available. Third, we have exploited the ability of PLSA to automatically extract visually meaningful aspects, to propose new algorithms for aspect-based image ranking and context-sensitive image segmentation."
            },
            "slug": "Modeling-scenes-with-local-descriptors-and-latent-Quelhas-Monay",
            "title": {
                "fragments": [],
                "text": "Modeling scenes with local descriptors and latent aspects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Probabilistic latent semantic analysis generates a compact scene representation, discriminative for accurate classification, and significantly more robust when less training data are available, and the ability of PLSA to automatically extract visually meaningful aspects is exploited to propose new algorithms for aspect-based image ranking and context-sensitive image segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069634816"
                        ],
                        "name": "J. Kumar",
                        "slug": "J.-Kumar",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36073757"
                        ],
                        "name": "R. Prasad",
                        "slug": "R.-Prasad",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Prasad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Prasad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39784761"
                        ],
                        "name": "Huaigu Cao",
                        "slug": "Huaigu-Cao",
                        "structuredName": {
                            "firstName": "Huaigu",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huaigu Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404588675"
                        ],
                        "name": "W. Abd-Almageed",
                        "slug": "W.-Abd-Almageed",
                        "structuredName": {
                            "firstName": "Wael",
                            "lastName": "Abd-Almageed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Abd-Almageed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145603129"
                        ],
                        "name": "P. Natarajan",
                        "slug": "P.-Natarajan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Natarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Natarajan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6294186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb819a736b808b76c2cbcd94f714792dbd3f01d",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel method for extracting handwritten and printed text zones from noisy document images with mixed content. We use Triple-Adjacent-Segment (TAS) based features which encode local shape characteristics of text in a consistent manner. We first construct two codebooks of the shape features extracted from a set of handwritten and printed text documents respectively. We then compute the normalized histogram of codewords for each segmented zone and use it to train a Support Vector Machine (SVM) classifier. The codebook based approach is robust to the background noise present in the image and TAS features are invariant to translation, scale and rotation of text. In experiments, we show that a pixel-weighted zone classification accuracy of 98% can be achieved for noisy Arabic documents. Further, we demonstrate the effectiveness of our method for document page classification and show that a high precision can be achieved for the detection of machine printed documents. The proposed method is robust to the size of zones, which may contain text content at line or paragraph level."
            },
            "slug": "Shape-codebook-based-handwritten-and-machine-text-Kumar-Prasad",
            "title": {
                "fragments": [],
                "text": "Shape codebook based handwritten and machine printed text zone extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A novel method for extracting handwritten and printed text zones from noisy document images with mixed content using Triple-Adjacent-Segment (TAS) based features which encode local shape characteristics of text in a consistent manner is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 15
                            }
                        ],
                        "text": "Jayant Kumar \u21d1, Peng Ye, David Doermann Language and Media Processing Laboratory, Institute of Advanced Computer Studies, University of Maryland, College Park, United States\na r t i c l e i n f o a b s t r a c t\nArticle history: Available online 12 November 2013\nCommunicated by Katsushi Ikeuchi\nKeywords: Structural similarity Retrieval Classification Random forest\nThis paper presents a novel approach to defining document image structural similarity for the applications of classification and retrieval."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 57
                            }
                        ],
                        "text": "Jayant Kumar \u21d1, Peng Ye, David Doermann Language and Media Processing Laboratory, Institute of Advanced Computer Studies, University of Maryland, College Park, United States\na r t i c l e i n f o a b s t r a c t\nArticle history: Available online 12 November 2013\nCommunicated by Katsushi\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11498408,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b76bbddf92d247705c839436b5836081ab0add8a",
            "isKey": false,
            "numCitedBy": 310,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "The economic feasibility of maintaining large data bases of document images has created a tremendous demand for robust ways to access and manipulate the information these images contain. In an attempt to move toward a paperless office, large quantities of printed documents are often scanned and archived as images, without adequate index information. One way to provide traditional data-base indexing and retrieval capabilities is to fully convert the document to an electronic representation which can be indexed automatically. Unfortunately, there are many factors which prohibit complete conversion including high cost, low document quality, and the fact that many nontext components cannot be adequately represented in a converted form. In such cases, it can be advantageous to maintain a copy of and use the document in image form. In this paper, we provide a survey of methods developed by researchers to access and manipulate document images without the need for complete and accurate conversion. We briefly discuss traditional text indexing techniques on imperfect data and the retrieval of partially converted documents. This is followed by a more comprehensive review of techniques for the direct characterization, manipulation, and retrieval, of images of documents containing text, graphics, and scene images."
            },
            "slug": "The-Indexing-and-Retrieval-of-Document-Images:-A-Doermann",
            "title": {
                "fragments": [],
                "text": "The Indexing and Retrieval of Document Images: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A survey of methods developed by researchers to access and manipulate document images without the need for complete and accurate conversion is provided."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143685864"
                        ],
                        "name": "Yi Yang",
                        "slug": "Yi-Yang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145211099"
                        ],
                        "name": "S. Newsam",
                        "slug": "S.-Newsam",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Newsam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Newsam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 231648,
            "fieldsOfStudy": [
                "Environmental Science",
                "Computer Science"
            ],
            "id": "93deda60276a7e5b378c41013af6604b45351588",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel image representation termed spatial pyramid co-occurrence which characterizes both the photometric and geometric aspects of an image. Specifically, the co-occurrences of visual words are computed with respect to spatial predicates over a hierarchical spatial partitioning of an image. The representation captures both the absolute and relative spatial arrangement of the words and, through the choice and combination of the predicates, can characterize a variety of spatial relationships. Our representation is motivated by the analysis of overhead imagery such as from satellites or aircraft. This imagery generally does not have an absolute reference frame and thus the relative spatial arrangement of the image elements often becomes the key discriminating feature. We validate this hypothesis using a challenging ground truth image dataset of 21 land-use classes manually extracted from high-resolution aerial imagery. Our approach is shown to result in higher classification rates than a non-spatial bagof- visual-words approach as well as a popular approach for characterizing the absolute spatial arrangement of visual words, the spatial pyramid representation of Lazebnik et al. [7]. While our primary objective is analyzing overhead imagery, we demonstrate that our approach achieves state-of-the-art performance on the Graz-01 object class dataset and performs competitively on the 15 Scene dataset."
            },
            "slug": "Spatial-pyramid-co-occurrence-for-image-Yang-Newsam",
            "title": {
                "fragments": [],
                "text": "Spatial pyramid co-occurrence for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A novel image representation termed spatial pyramid co-occurrence which characterizes both the photometric and geometric aspects of an image which achieves state-of-the-art performance on the Graz-01 object class dataset and performs competitively on the 15 Scene dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793750"
                        ],
                        "name": "C. Wallraven",
                        "slug": "C.-Wallraven",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Wallraven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wallraven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144813423"
                        ],
                        "name": "Arnulf B. A. Graf",
                        "slug": "Arnulf-B.-A.-Graf",
                        "structuredName": {
                            "firstName": "Arnulf",
                            "lastName": "Graf",
                            "middleNames": [
                                "B.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnulf B. A. Graf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 134
                            }
                        ],
                        "text": "Approaches based on bag-of-words (BOW) models have shown promising results on many computer vision tasks such as image classification (Wallraven et al., 2003), scene understanding (Quelhas et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 135
                            }
                        ],
                        "text": "Approaches based on bag-of-words (BOW) models have shown promising results on many computer vision tasks such as image classification (Wallraven et al., 2003), scene understanding (Quelhas et al., 2005), and document image categorization (Barbu et al., 2006; Kumar et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4573035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c393b31ca71e8c4dd7c8c5a11653b18447c90466",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in computer vision have shown that local features can provide efficient representations suitable for robust object recognition. Support vector machines have been established as powerful learning algorithms with good generalization capabilities. We combine these two approaches and propose a general kernel method for recognition with local features. We show that the proposed kernel satisfies the Mercer condition and that it is, suitable for many established local feature frameworks. Large-scale recognition results are presented on three different databases, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features. In addition, experiments on noisy and occluded images show that local feature representations significantly outperform global approaches."
            },
            "slug": "Recognition-with-local-features:-the-kernel-recipe-Wallraven-Caputo",
            "title": {
                "fragments": [],
                "text": "Recognition with local features: the kernel recipe"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Large-scale recognition results are presented, which demonstrate that SVMs with the proposed kernel perform better than standard matching techniques on local features and that local feature representations significantly outperform global approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706007"
                        ],
                        "name": "Jianchao Yang",
                        "slug": "Jianchao-Yang",
                        "structuredName": {
                            "firstName": "Jianchao",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianchao Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108863279"
                        ],
                        "name": "Thomas Huang",
                        "slug": "Thomas-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 185
                            }
                        ],
                        "text": "Subsequently, there has been focus on selecting the optimal feature combination strategy and efficient ways to learn these local statistics, and a number of methods have been proposed (Yang et al., 2009, 2011; Kumar et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 440212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c9633aedafe4ee8cf238fa06c40b84f47e17362",
            "isKey": false,
            "numCitedBy": 1469,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently SVMs using spatial pyramid matching (SPM) kernel have been highly successful in image classification. Despite its popularity, these nonlinear SVMs have a complexity O(n2 ~ n3) in training and O(n) in testing, where n is the training size, implying that it is nontrivial to scaleup the algorithms to handle more than thousands of training images. In this paper we develop an extension of the SPM method, by generalizing vector quantization to sparse coding followed by multi-scale spatial max pooling, and propose a linear SPM kernel based on SIFT sparse codes. This new approach remarkably reduces the complexity of SVMs to O(n) in training and a constant in testing. In a number of image categorization experiments, we find that, in terms of classification accuracy, the suggested linear SPM based on sparse coding of SIFT descriptors always significantly outperforms the linear SPM kernel on histograms, and is even better than the nonlinear SPM kernels, leading to state-of-the-art performance on several benchmarks by using a single type of descriptors."
            },
            "slug": "Linear-spatial-pyramid-matching-using-sparse-coding-Yang-Yu",
            "title": {
                "fragments": [],
                "text": "Linear spatial pyramid matching using sparse coding for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An extension of the SPM method is developed, by generalizing vector quantization to sparse coding followed by multi-scale spatial max pooling, and a linear SPM kernel based on SIFT sparse codes is proposed, leading to state-of-the-art performance on several benchmarks by using a single type of descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 18
                            }
                        ],
                        "text": "Compared to SIFT (Lowe, 1999), the SURF descriptors are several times faster and more robust to noise, which often occurs during binarization (Bay et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 21
                            }
                        ],
                        "text": "170 Compared to SIFT (Lowe, 1999), the SURF descriptors are several times 171 faster and more robust to noise, which often occurs during binarization (Bay 172 et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": false,
            "numCitedBy": 16257,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2989580"
                        ],
                        "name": "J. DeCurtins",
                        "slug": "J.-DeCurtins",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "DeCurtins",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. DeCurtins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113754155"
                        ],
                        "name": "Edward Chen",
                        "slug": "Edward-Chen",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 156
                            }
                        ],
                        "text": "For text-content based retrieval, scanned document images are typically converted to electronic (Unicode) text through optical character recognition (OCR) (Decurtins and Chen, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "There is however an emerging need for effective methods for unconstrained document images for which OCR cannot be performed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Since the text from OCR may contain errors, especially for handwritten documents, the approach is limited to well-structured printed documents."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 117
                            }
                        ],
                        "text": "Approaches based on content are highly dependent on, and sensitive to, the quality of optical character recognition (OCR), graphics recognition or component labeling."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Since the OCR for unconstrained handwritten documents is still a difficult problem, content based approaches are typically limited to more structured machine printed documents (Marinai et al., 2011)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 33990648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e527b5e9216a031c4fc1fce3ff58c27f01a83f4e",
            "isKey": true,
            "numCitedBy": 40,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "With the advent of on-line access to very large collections of document images, electronic classification into areas of interest has become possible. A first approach to classification might be the use of OCR on each document followed by analysis of the resulting ASCII text. But if the quality of a document is poor, the format unconstrained, or time is critical, complete OCR of each image is not appropriate. An alternative approach is the use of word shape recognition (as opposed to individual character recognition) and the subsequent classification of documents by the presence or absence of selected keywords. Use of word shape recognition not only provides a more robust collection of features but also eliminates the need for character segmentation (a leading cause of error in OCR). In this paper we describe a system we have developed for the detection of isolated words, word portions, as well as multi-word phrases in images of documents. It is designed to be used with large, changeable, keyword sets and very large document sets. The system provides for automated training of desired keywords and creation of indexing filters to speed matching."
            },
            "slug": "Keyword-spotting-via-word-shape-recognition-DeCurtins-Chen",
            "title": {
                "fragments": [],
                "text": "Keyword spotting via word shape recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes a system developed for the detection of isolated words, word portions, as well as multi-word phrases in images of documents and provides for automated training of desired keywords and creation of indexing filters to speed matching."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144449660"
                        ],
                        "name": "Peng Ye",
                        "slug": "Peng-Ye",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143775793"
                        ],
                        "name": "J. Kumar",
                        "slug": "J.-Kumar",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145714522"
                        ],
                        "name": "Le Kang",
                        "slug": "Le-Kang",
                        "structuredName": {
                            "firstName": "Le",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Le Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 78
                            }
                        ],
                        "text": "This result is in agreement with a previous work on image quality estimation (Ye et al., 2012) where a large codebook (order of thousands) was necessary with RIP features."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 8060934,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d374e1f18f94e49c39e447ae2220a159cd60b619",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an efficient general-purpose objective no-reference (NR) image quality assessment (IQA) framework based on unsupervised feature learning. The goal is to build a computational model to automatically predict human perceived image quality without a reference image and without knowing the distortion present in the image. Previous approaches for this problem typically rely on hand-crafted features which are carefully designed based on prior knowledge. In contrast, we use raw-image-patches extracted from a set of unlabeled images to learn a dictionary in an unsupervised manner. We use soft-assignment coding with max pooling to obtain effective image representations for quality estimation. The proposed algorithm is very computationally appealing, using raw image patches as local descriptors and using soft-assignment for encoding. Furthermore, unlike previous methods, our unsupervised feature learning strategy enables our method to adapt to different domains. CORNIA (Codebook Representation for No-Reference Image Assessment) is tested on LIVE database and shown to perform statistically better than the full-reference quality measure, structural similarity index (SSIM) and is shown to be comparable to state-of-the-art general purpose NR-IQA algorithms."
            },
            "slug": "Unsupervised-feature-learning-framework-for-image-Ye-Kumar",
            "title": {
                "fragments": [],
                "text": "Unsupervised feature learning framework for no-reference image quality assessment"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper uses raw image patches extracted from a set of unlabeled images to learn a dictionary in an unsupervised manner and uses soft-assignment coding with max pooling to obtain effective image representations for quality estimation."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084270570"
                        ],
                        "name": "Guillaume Joutel",
                        "slug": "Guillaume-Joutel",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Joutel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guillaume Joutel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721326"
                        ],
                        "name": "V. Eglin",
                        "slug": "V.-Eglin",
                        "structuredName": {
                            "firstName": "V\u00e9ronique",
                            "lastName": "Eglin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Eglin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784847"
                        ],
                        "name": "S. Bres",
                        "slug": "S.-Bres",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Bres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739381"
                        ],
                        "name": "H. Emptoz",
                        "slug": "H.-Emptoz",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Emptoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Emptoz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 154
                            }
                        ],
                        "text": "One effective way to define layout similarity for matching is based on structural features (Collins-Thompson and Nickolov, 2002; Shin and Doermann, 2006; Joutel et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Joutel et al. (2007) presented an approach for the retrieval of handwritten historical documents at page level based on the curvelet transform to compose a unique signature for each page."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 8
                            }
                        ],
                        "text": "Although raw image-patch based features are fast and effective (Kumar et al., 2012), they are not invariant to scale or robust to noise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16683602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "443adf054bbf093cd5c90900d7f5594ff3ebb15c",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new use of the curvelet transform as a multiscale method for indexing linear singularities and curved handwritten shapes in documents images. As it belongs to the wavelet family, this representation can be useful at several scales of details. The proposed scheme for handwritten shape characterization targets to detect oriented and curved fragments at different scales so as to compose an unique signature for each handwritten analyzed samples. In this way, curvelets coefficients are used as a representation tool for handwriting when searching in large manuscripts databases by finding similar handwritten samples. Current results of ancient manuscripts retrieval are very promising with very satisfying precisions and recalls."
            },
            "slug": "Curvelets-Based-Queries-for-CBIR-Application-in-Joutel-Eglin",
            "title": {
                "fragments": [],
                "text": "Curvelets Based Queries for CBIR Application in Handwriting Collections"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper presents a new use of the curvelet transform as a multiscale method for indexing linear singularities and curved handwritten shapes in documents images to compose an unique signature for each handwritten analyzed samples."
            },
            "venue": {
                "fragments": [],
                "text": "Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2642099"
                        ],
                        "name": "F. Dubiel",
                        "slug": "F.-Dubiel",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Dubiel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Dubiel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 187
                            }
                        ],
                        "text": "Furthermore, as previously mentioned, a majority of the work published on defining and applying structural similarity is specific to a particular document type, such as business letters (Dengel and Dubiel, 1995; Marinai et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19200855,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ea4167f9eb9ad893be32ba35147fe4539b6cdd4",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system which is capable of learning the presentation of document logical structures, exemplarily shown for business letters. Presenting a set of instances to the system, it clusters them into structural concepts and induces a concept hierarchy. This concept hierarchy is taken as a source for classifying future input. The paper introduces the different learning steps, describes how the resulting concept hierarchy is applied for logical labeling and reports on the results."
            },
            "slug": "Clustering-and-classification-of-document-machine-Dengel-Dubiel",
            "title": {
                "fragments": [],
                "text": "Clustering and classification of document structure-a machine learning approach"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A system capable of learning the presentation of document logical structures, exemplarily shown for business letters, is described, which clusters them into structural concepts and induces a concept hierarchy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2195306"
                        ],
                        "name": "H. Bay",
                        "slug": "H.-Bay",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Bay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 143
                            }
                        ],
                        "text": "Compared to SIFT (Lowe, 1999), the SURF descriptors are several times faster and more robust to noise, which often occurs during binarization (Bay et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 87
                            }
                        ],
                        "text": "In order to capture the local information of document objects we use SURF descriptors (Bay et al., 2006) extracted from key-point locations in the image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 461853,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "490020c0d4fa1eb85fe353add5713e49f08c628d",
            "isKey": false,
            "numCitedBy": 8515,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. \n \nThis is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (in casu, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper presents experimental results on a standard evaluation set, as well as on imagery obtained in the context of a real-life object recognition application. Both show SURF's strong performance."
            },
            "slug": "SURF:-Speeded-Up-Robust-Features-Bay-Tuytelaars",
            "title": {
                "fragments": [],
                "text": "SURF: Speeded Up Robust Features"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Robust Features), which approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144249397"
                        ],
                        "name": "V. Manohar",
                        "slug": "V.-Manohar",
                        "structuredName": {
                            "firstName": "Vasant",
                            "lastName": "Manohar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Manohar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3306372"
                        ],
                        "name": "S. Vitaladevuni",
                        "slug": "S.-Vitaladevuni",
                        "structuredName": {
                            "firstName": "Shiv",
                            "lastName": "Vitaladevuni",
                            "middleNames": [
                                "Naga",
                                "Prasad"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vitaladevuni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39784761"
                        ],
                        "name": "Huaigu Cao",
                        "slug": "Huaigu-Cao",
                        "structuredName": {
                            "firstName": "Huaigu",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huaigu Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36073757"
                        ],
                        "name": "R. Prasad",
                        "slug": "R.-Prasad",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Prasad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Prasad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145603129"
                        ],
                        "name": "P. Natarajan",
                        "slug": "P.-Natarajan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Natarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Natarajan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 140
                            }
                        ],
                        "text": "\u2026we use data from three collections: (1) a collection of Arabic document images collected in a field operation (Anfal) (Kumar et al., 2011; Manohar et al., 2011), (2) the Tobacco litigation dataset (Lewis et al., 2006), and (3) a collection of 5590 tax-form images obtained from National\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8461025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a2f31ba2a5063f4f8cca3ada697ff4b2fc19ebb",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Handwritten text line segmentation on real-world data presents significant challenges that cannot be overcome by any single technique. Given the diversity of approaches and the recent advances in ensemble-based combination for pattern recognition problems, it is possible to improve the segmentation performance by combining the outputs from different line finding methods. In this paper, we propose a novel graph clustering-based approach to combine the output of an ensemble of text line segmentation algorithms. A weighted undirected graph is constructed with nodes corresponding to connected components and edge connecting pairs of connected components. Text line segmentation is then posed as the problem of minimum cost partitioning of the nodes in the graph such that each cluster corresponds to a unique line in the document image. Experimental results on a challenging Arabic field dataset using the ensemble method shows a relative gain of 18% in the F1 score over the best individual method within the ensemble."
            },
            "slug": "Graph-Clustering-Based-Ensemble-Method-for-Text-Manohar-Vitaladevuni",
            "title": {
                "fragments": [],
                "text": "Graph Clustering-Based Ensemble Method for Handwritten Text Line Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A novel graph clustering-based approach to combine the output of an ensemble of text line segmentation algorithms that shows a relative gain in the F1 score over the best individual method within the ensemble."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35151749"
                        ],
                        "name": "G. Agam",
                        "slug": "G.-Agam",
                        "structuredName": {
                            "firstName": "Gady",
                            "lastName": "Agam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Agam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144628595"
                        ],
                        "name": "S. Argamon",
                        "slug": "S.-Argamon",
                        "structuredName": {
                            "firstName": "Shlomo",
                            "lastName": "Argamon",
                            "middleNames": [
                                "Engelson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Argamon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741208"
                        ],
                        "name": "O. Frieder",
                        "slug": "O.-Frieder",
                        "structuredName": {
                            "firstName": "Ophir",
                            "lastName": "Frieder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Frieder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693690"
                        ],
                        "name": "D. Grossman",
                        "slug": "D.-Grossman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grossman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Grossman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20833434"
                        ],
                        "name": "J. Heard",
                        "slug": "J.-Heard",
                        "structuredName": {
                            "firstName": "Jefferson",
                            "lastName": "Heard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Heard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 146
                            }
                        ],
                        "text": "\u2026of Arabic document images collected in a field operation (Anfal) (Kumar et al., 2011; Manohar et al., 2011), (2) the Tobacco litigation dataset (Lewis et al., 2006), and (3) a collection of 5590 tax-form images obtained from National Institute of Standards and Technology (Dimmick et al., 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 19516087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47c6d10fe8a29fcd1727e805a2b9f804c12e0d4d",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Research and development of information access technology for scanned paper documents has been hampered by the lack of public test collections of realistic scope and complexity. As part of a project to create a prototype system for search and mining of masses of document images, we are assembling a 1.5 terabyte dataset to support evaluation of both end-to-end complex document information processing (CDIP) tasks (e.g., text retrieval and data mining) as well as component technologies such as optical character recognition (OCR), document structure analysis, signature matching, and authorship attribution."
            },
            "slug": "Building-a-test-collection-for-complex-document-Lewis-Agam",
            "title": {
                "fragments": [],
                "text": "Building a test collection for complex document information processing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A 1.5 terabyte dataset is assembled to support evaluation of both end-to-end complex document information processing (CDIP) tasks (e.g., text retrieval and data mining) as well as component technologies such as optical character recognition (OCR), document structure analysis, signature matching, and authorship attribution."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114660236"
                        ],
                        "name": "H. Schneider",
                        "slug": "H.-Schneider",
                        "structuredName": {
                            "firstName": "Hans-Jochen",
                            "lastName": "Schneider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneider"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 146
                            }
                        ],
                        "text": "\u2026of Arabic document images collected in a field operation (Anfal) (Kumar et al., 2011; Manohar et al., 2011), (2) the Tobacco litigation dataset (Lewis et al., 2006), and (3) a collection of 5590 tax-form images obtained from National Institute of Standards and Technology (Dimmick et al., 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39944136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26f2e89f5585cf2ec4c0cdcd4ec4264d5726b07e",
            "isKey": false,
            "numCitedBy": 1414,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "research and development in information retrieval is available in our digital library an online access to it is set as public so you can get it instantly. Our books collection spans in multiple countries, allowing you to get the most less latency time to download any of our books like this one. Kindly say, the research and development in information retrieval is universally compatible with any devices to read."
            },
            "slug": "Research-and-Development-in-Information-Retrieval-Salton-Schneider",
            "title": {
                "fragments": [],
                "text": "Research and Development in Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The research and development in information retrieval is universally compatible with any devices to read, and can be downloaded instantly from the authors' digital library."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713121"
                        ],
                        "name": "Kenneth D. Forbus",
                        "slug": "Kenneth-D.-Forbus",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Forbus",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth D. Forbus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704065"
                        ],
                        "name": "D. Gentner",
                        "slug": "D.-Gentner",
                        "structuredName": {
                            "firstName": "Dedre",
                            "lastName": "Gentner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gentner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30867581"
                        ],
                        "name": "K. Law",
                        "slug": "K.-Law",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Law",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Law"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 149
                            }
                        ],
                        "text": "Structurally consistent match between two document images is a match that preserves the constraints of one-to-one mapping and parallel connectivity (Forbus et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5606121,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "a0fea0e9514f6d62ab91b522e94a1be46839c1d9",
            "isKey": false,
            "numCitedBy": 862,
            "numCiting": 185,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of similarity-based retrieval that attempts to capture three seemingly contradictory psychological phenomena: (a) structural commonalities are weighed more heavily than surface commonalities in similarity judgments for items in working memory; (b) in retrieval, superficial similarity is more important than structural similarity; and yet (c) purely structural (analogical) remindings e sometimes experienced. Our model, MAC/FAC, explains these phenomena in terms of a two-stage process. The first stage uses a computationally cheap, non-structural matcher to filter candidate long-term memory items. It uses content vectors, a redundant encoding of structured representations whose dot product estimates how well the corresponding structural representations will match. The second stage uses SME (structure-mapping engine) to compute structural matches on the handful of items found by the first stage. We show the utility of the MAC/FAC model through a series of computational experiments: (a) We demonstrate that MAC/FAC can model patterns of access found in psychological data; (b) we argue via sensitivity analyses that these simulation results rely on the theory; and (c) we compare the performance of MAC/FAC with ARCS, an alternate model of similarity-based retrieval, and demonstrate that MAC/FAC explains the data better than ARCS. Finally, we discuss limitations and possible extensions of the model, relationships with other recent retrieval models, and place MAC/FAC in the context of other recent work on the nature of similarity."
            },
            "slug": "MAC/FAC:-A-Model-of-Similarity-Based-Retrieval-Forbus-Gentner",
            "title": {
                "fragments": [],
                "text": "MAC/FAC: A Model of Similarity-Based Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A model of similarity-based retrieval that attempts to capture three seemingly contradictory psychological phenomena, showing that structural commonalities are weighed more heavily than surface commonalities in similarity judgments for items in working memory and that MAC/FAC can model patterns of access found in psychological data."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71532197"
                        ],
                        "name": "Song Han-tao",
                        "slug": "Song-Han-tao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han-tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han-tao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 100
                            }
                        ],
                        "text": "The problem is made even more difficult when the number of relevant images for training is limited (Zheng et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63641096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7d298d54f9110a04a63ea3ddc8576275503cec9",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper studies feature selection in text categorization learning. It focuses on dimensionality reduction. Because high dimensionality feature sets are not all important and available in categorization learning. In the end some categorization methods and characteristics were introduced."
            },
            "slug": "Feature-Selection-in-Text-Categorization-Han-tao",
            "title": {
                "fragments": [],
                "text": "Feature Selection in Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The paper studies feature selection in text categorization learning by focusing on dimensionality reduction and some categorization methods and characteristics were introduced."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749245"
                        ],
                        "name": "Zhaohui Zheng",
                        "slug": "Zhaohui-Zheng",
                        "structuredName": {
                            "firstName": "Zhaohui",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaohui Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143690397"
                        ],
                        "name": "Xiaoyun Wu",
                        "slug": "Xiaoyun-Wu",
                        "structuredName": {
                            "firstName": "Xiaoyun",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoyun Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7956405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebe5b9a24275793de12cb367802db19690751f41",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of feature selection metrics have been explored in text categorization, among which information gain (IG), chi-square (CHI), correlation coefficient (CC) and odds ratios (OR) are considered most effective. CC and OR are one-sided metrics while IG and CHI are two-sided. Feature selection using one-sided metrics selects the features most indicative of membership only, while feature selection using two-sided metrics implicitly combines the features most indicative of membership (e.g. positive features) and non-membership (e.g. negative features) by ignoring the signs of features. The former never consider the negative features, which are quite valuable, while the latter cannot ensure the optimal combination of the two kinds of features especially on imbalanced data. In this work, we investigate the usefulness of explicit control of that combination within a proposed feature selection framework. Using multinomial na\u00efve Bayes and regularized logistic regression as classifiers, our experiments show both great potential and actual merits of explicitly combining positive and negative features in a nearly optimal fashion according to the imbalanced data."
            },
            "slug": "Feature-selection-for-text-categorization-on-data-Zheng-Wu",
            "title": {
                "fragments": [],
                "text": "Feature selection for text categorization on imbalanced data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work investigates the usefulness of explicit control of that combination within a proposed feature selection framework and shows both great potential and actual merits of explicitly combining positive and negative features in a nearly optimal fashion according to the imbalanced data."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 89141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986",
            "isKey": false,
            "numCitedBy": 65207,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148\u2013156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression."
            },
            "slug": "Random-Forests-Breiman",
            "title": {
                "fragments": [],
                "text": "Random Forests"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the forest, and are also applicable to regression."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2587444"
                        ],
                        "name": "Andy Liaw",
                        "slug": "Andy-Liaw",
                        "structuredName": {
                            "firstName": "Andy",
                            "lastName": "Liaw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andy Liaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39707890"
                        ],
                        "name": "M. Wiener",
                        "slug": "M.-Wiener",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Wiener",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wiener"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 104
                            }
                        ],
                        "text": "In our experiments, we set mTry = ffiffiffiffi N p\n, where N is the number of features and nTree = 500 (Liaw and Wiener, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 103
                            }
                        ],
                        "text": "In our experiments, we set mTry = ffiffiffiffi N p , where N is the number of features and nTree = 500 (Liaw and Wiener, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3093707,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e633b41d93051375ef9135102d54fa097dc8cf8",
            "isKey": false,
            "numCitedBy": 13682,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently there has been a lot of interest in \u201censemble learning\u201d \u2014 methods that generate many classifiers and aggregate their results. Two well-known methods are boosting (see, e.g., Shapire et al., 1998) and bagging Breiman (1996) of classification trees. In boosting, successive trees give extra weight to points incorrectly predicted by earlier predictors. In the end, a weighted vote is taken for prediction. In bagging, successive trees do not depend on earlier trees \u2014 each is independently constructed using a bootstrap sample of the data set. In the end, a simple majority vote is taken for prediction. Breiman (2001) proposed random forests, which add an additional layer of randomness to bagging. In addition to constructing each tree using a different bootstrap sample of the data, random forests change how the classification or regression trees are constructed. In standard trees, each node is split using the best split among all variables. In a random forest, each node is split using the best among a subset of predictors randomly chosen at that node. This somewhat counterintuitive strategy turns out to perform very well compared to many other classifiers, including discriminant analysis, support vector machines and neural networks, and is robust against overfitting (Breiman, 2001). In addition, it is very user-friendly in the sense that it has only two parameters (the number of variables in the random subset at each node and the number of trees in the forest), and is usually not very sensitive to their values. The randomForest package provides an R interface to the Fortran programs by Breiman and Cutler (available at http://www.stat.berkeley.edu/ users/breiman/). This article provides a brief introduction to the usage and features of the R functions."
            },
            "slug": "Classification-and-Regression-by-randomForest-Liaw-Wiener",
            "title": {
                "fragments": [],
                "text": "Classification and Regression by randomForest"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "random forests are proposed, which add an additional layer of randomness to bagging and are robust against overfitting, and the randomForest package provides an R interface to the Fortran programs by Breiman and Cutler."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472298"
                        ],
                        "name": "Chih-Chung Chang",
                        "slug": "Chih-Chung-Chang",
                        "structuredName": {
                            "firstName": "Chih-Chung",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Chung Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711460"
                        ],
                        "name": "Chih-Jen Lin",
                        "slug": "Chih-Jen-Lin",
                        "structuredName": {
                            "firstName": "Chih-Jen",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Jen Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 961425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "273dfbcb68080251f5e9ff38b4413d7bd84b10a1",
            "isKey": false,
            "numCitedBy": 40077,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail."
            },
            "slug": "LIBSVM:-A-library-for-support-vector-machines-Chang-Lin",
            "title": {
                "fragments": [],
                "text": "LIBSVM: A library for support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail."
            },
            "venue": {
                "fragments": [],
                "text": "TIST"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 3
                            }
                        ],
                        "text": "In Lazebnik et al. (2006), features at coarser level were given less weights compared to features extracted from fine-regions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 107
                            }
                        ],
                        "text": "In our experiments, we report accuracies for SP-LSVM and SP-RSVM using feature weighting scheme similar to Lazebnik et al. (2006), and for RF based approaches we used uniform weights."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 58
                            }
                        ],
                        "text": "We compare our approach with the spatial85 pyramid method (Lazebnik et al., 2006) and show that the proposed method 86 gives superior performance on many document retrieval and classification 87 tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 57
                            }
                        ],
                        "text": "We compare our approach with the spatial-pyramid method (Lazebnik et al., 2006) and show that the proposed method gives superior performance on many document retrieval and classification tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 197
                            }
                        ],
                        "text": "One of the early methods proposes the creation of spatial-pyramid features by partitioning the image into increasingly finer grids and computing the weighted histogram based kernel in each region (Lazebnik et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 86
                            }
                        ],
                        "text": "Spatial-pyramid with Support vector machine: Spatial-pyramid matching was proposed by Lazebnik et al. (2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Beyond bags of features: Spatial"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 101
                            }
                        ],
                        "text": "102 A large number of retrieval techniques have been developed using a 103 query by example paradigm (Zhu and Doermann, 2009; Marinai et al., 2011; 104 Jain and Doermann, 2012; Chen et al., 2012a), where features are extracted 105 and indexed from document images off-line."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 185
                            }
                        ],
                        "text": "Since the OCR for un11 constrained handwritten documents is still a difficult problem, content based 12 approaches are typically limited to more structured machine printed docu13 ments (Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 224
                            }
                        ],
                        "text": "When considering layout, the representation of documents\nusing image-based features is often more intuitive and useful because it preserves the physical structure and access to non-text components such as embedded graphics (Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 234
                            }
                        ],
                        "text": "When considering layout, the representation of docu99 ments using image-based features is often more intuitive and useful because 100 it preserves the physical structure and access to non-text components such 101 as embedded graphics (Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 147
                            }
                        ],
                        "text": "Finding structurally similar images in large heterogenous document image collections has been of interest for many years (Shin and Doermann, 2006; Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 118
                            }
                        ],
                        "text": "A large number of retrieval techniques have been developed using a query by example paradigm (Zhu and Doermann, 2009; Marinai et al., 2011; Jain and Doermann, 2012; Chen et al., 2012a), where features are extracted and indexed from document images off-line."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 177
                            }
                        ],
                        "text": "Since the OCR for unconstrained handwritten documents is still a difficult problem, content based approaches are typically limited to more structured machine printed documents (Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Digital libraries and document"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 220
                            }
                        ],
                        "text": "Contents lists available at ScienceDirect\nPattern Recognition Letters\njournal homepage: www.elsevier .com/locate /patrec\nStructural similarity for document image classification and retrieval\n0167-8655/$ - see front matter 2013 Elsevier B.V."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 224
                            }
                        ],
                        "text": "When considering layout, the representation of documents\nusing image-based features is often more intuitive and useful because it preserves the physical structure and access to non-text components such as embedded graphics (Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 147
                            }
                        ],
                        "text": "Finding structurally similar images in large heterogenous document image collections has been of interest for many years (Shin and Doermann, 2006; Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 118
                            }
                        ],
                        "text": "A large number of retrieval techniques have been developed using a query by example paradigm (Zhu and Doermann, 2009; Marinai et al., 2011; Jain and Doermann, 2012; Chen et al., 2012a), where features are extracted and indexed from document images off-line."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 177
                            }
                        ],
                        "text": "Since the OCR for unconstrained handwritten documents is still a difficult problem, content based approaches are typically limited to more structured machine printed documents (Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Digital libraries and document im- 466 age retrieval techniques: A survey. Learning Structure and Schemas from 467 Documents"
            },
            "venue": {
                "fragments": [],
                "text": "Digital libraries and document im- 466 age retrieval techniques: A survey. Learning Structure and Schemas from 467 Documents"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 210
                            }
                        ],
                        "text": "\u2026support and general document image search which depend on efficient and effective methods for computing similarity, previous approaches have focused on content-specific features or layout-specific structures (Collins-Thompson and Nickolov, 2002; Shin and Doermann, 2006; Zhu et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 0
                            }
                        ],
                        "text": "Collins-Thompson and Nickolov (2002) proposed a model for estimating the inter-page similarity in ordered collections of document images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 97
                            }
                        ],
                        "text": "34 One effective way to define layout similarity for matching is based on 35 structural features (Collins-Thompson and Nickolov, 2002; Shin and Doer36 mann, 2006; Joutel et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 92
                            }
                        ],
                        "text": "One effective way to define layout similarity for matching is based on structural features (Collins-Thompson and Nickolov, 2002; Shin and Doermann, 2006; Joutel et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 385,
                                "start": 287
                            }
                        ],
                        "text": "While there are numerous applications in office 4 automation, litigation support and general document image search which 5 depend on efficient and effective methods for computing similarity, previous 6 approaches have focused on content-specific features or layout-specific struc7 tures (Doermann, 1998; Collins-Thompson and Nickolov, 2002; Shin and Do8 ermann, 2006; Zhu et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A clustering-based algorithm for"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In Kumar et al. (2012), we proposed a recursive horizontal-vertical partitioning scheme to learn spatial relationships in document images based on the observation that document objects have a horizontal and vertical bias."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In Kumar et al. (2012), we explored an unsupervised feature learning method, using raw-image patches, to construct a codebook representation of basic structural elements in document images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 37
                            }
                        ],
                        "text": "RIP based features were presented in Kumar et al. (2012), and were shown to be very effective for document classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 192
                            }
                        ],
                        "text": "Subsequently, there has been focus on selecting the optimal 154 feature combination strategy and efficient ways to learn these local statis155 tics, and a number of methods have been proposed (Yang et al., 2009; Yang 156 and Newsam, 2011; Kumar et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 151
                            }
                        ],
                        "text": "In the third, the objective is to demonstrate the advantage of SURF codewords, so we compare our spatial features with raw-image-patch based features (Kumar et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 67
                            }
                        ],
                        "text": "Although raw image-patch based features are fast and effective 169 (Kumar et al., 2012), they are not invariant to scale or robust to noise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 64
                            }
                        ],
                        "text": "Although raw image-patch based features are fast and effective (Kumar et al., 2012), they are not invariant to scale or robust to noise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 155
                            }
                        ],
                        "text": "Recent work has focused on developing general methods capable of handling less constrained handwritten documents and datasets with highly variable layout (Kumar et al., 2011, 2012; Jain and Doermann, 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 210
                            }
                        ],
                        "text": "Subsequently, there has been focus on selecting the optimal feature combination strategy and efficient ways to learn these local statistics, and a number of methods have been proposed (Yang et al., 2009, 2011; Kumar et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Document Structure"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 177
                            }
                        ],
                        "text": "Since the OCR for unconstrained handwritten documents is still a difficult problem, content based approaches are typically limited to more structured machine printed documents (Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 118
                            }
                        ],
                        "text": "A large number of retrieval techniques have been developed using a query by example paradigm (Zhu and Doermann, 2009; Marinai et al., 2011; Jain and Doermann, 2012; Chen et al., 2012a), where features are extracted and indexed from document images off-line."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 147
                            }
                        ],
                        "text": "Finding structurally similar images in large heterogenous document image collections has been of interest for many years (Shin and Doermann, 2006; Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 224
                            }
                        ],
                        "text": "When considering layout, the representation of documents\nusing image-based features is often more intuitive and useful because it preserves the physical structure and access to non-text components such as embedded graphics (Marinai et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Digital libraries and document image retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In Kumar et al. (2012), we proposed a recursive horizontal-vertical partitioning scheme to learn spatial relationships in document images based on the observation that document objects have a horizontal and vertical bias."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 3
                            }
                        ],
                        "text": "In Kumar et al. (2012), we explored an unsupervised feature learning method, using raw-image patches, to construct a codebook representation of basic structural elements in document images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 37
                            }
                        ],
                        "text": "RIP based features were presented in Kumar et al. (2012), and were shown to be very effective for document classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 151
                            }
                        ],
                        "text": "In the third, the objective is to demonstrate the advantage of SURF codewords, so we compare our spatial features with raw-image-patch based features (Kumar et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 64
                            }
                        ],
                        "text": "Although raw image-patch based features are fast and effective (Kumar et al., 2012), they are not invariant to scale or robust to noise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 155
                            }
                        ],
                        "text": "Recent work has focused on developing general methods capable of handling less constrained handwritten documents and datasets with highly variable layout (Kumar et al., 2011, 2012; Jain and Doermann, 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 210
                            }
                        ],
                        "text": "Subsequently, there has been focus on selecting the optimal feature combination strategy and efficient ways to learn these local statistics, and a number of methods have been proposed (Yang et al., 2009, 2011; Kumar et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Unsupervised feature 482 learning framework for noreference image quality assessment"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "chines. Intelligent Systems and Technology ACM Transactions on"
            },
            "venue": {
                "fragments": [],
                "text": "chines. Intelligent Systems and Technology ACM Transactions on"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 344,
                                "start": 320
                            }
                        ],
                        "text": "In our experiments, we use data from three collections: (1) a collection of Arabic document images collected in a field operation (Anfal) (Kumar et al., 2011; Manohar et al., 2011), (2) the Tobacco litigation dataset (Lewis et al., 2006), and (3) a collection of 5590 tax-form images obtained from National Institute of Standards and Technology (Dimmick et al., 1991)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 274
                            }
                        ],
                        "text": "\u2026of Arabic document images collected in a field operation (Anfal) (Kumar et al., 2011; Manohar et al., 2011), (2) the Tobacco litigation dataset (Lewis et al., 2006), and (3) a collection of 5590 tax-form images obtained from National Institute of Standards and Technology (Dimmick et al., 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NIST structured forms 429 reference set of binary images (sfrs). NIST Special Database 2"
            },
            "venue": {
                "fragments": [],
                "text": "NIST structured forms 429 reference set of binary images (sfrs). NIST Special Database 2"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 58
                            }
                        ],
                        "text": "Using the K-medoids method, a set of exemplary codewords which represent the basic structural elements in the document database is obtained."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 187
                            }
                        ],
                        "text": "Furthermore, as previously mentioned, a majority of the work published on defining and applying structural similarity is specific to a particular document type, such as business letters (Dengel and Dubiel, 1995; Marinai et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Clustering and classification of document 426 structure-a machine learning approach. In: Document Analysis and Recog- 427 nition"
            },
            "venue": {
                "fragments": [],
                "text": "Intl. Conf. on"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 78
                            }
                        ],
                        "text": "This result is in agreement with a previous work on image quality estimation (Ye et al., 2012) where a large codebook (order of thousands) was necessary with RIP features."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Unsupervised feature 482 learning framework for no-reference image quality assessment"
            },
            "venue": {
                "fragments": [],
                "text": "Com- 483 puter Vision and Pattern Recognition, IEEE Conf. on"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape Codebook based Handwritten and Machine Printed 442 Text Zone Extraction. In: Document Recognition and Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Shape Codebook based Handwritten and Machine Printed 442 Text Zone Extraction. In: Document Recognition and Retrieval"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 212
                            }
                        ],
                        "text": "Furthermore, as previously mentioned, a majority of the work published on defining and applying structural similarity is specific to a particular document type, such as business letters (Dengel and Dubiel, 1995; Marinai et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tree clustering for layoutbased 463 document image retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Document Image Analysis for Libraries"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer Vision, Intl. Conf. on"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision, Intl. Conf. on"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "for automatic indexing of graphical document image databases. Graphics 405 Recognition. Ten Years Review and Future Perspectives"
            },
            "venue": {
                "fragments": [],
                "text": "for automatic indexing of graphical document image databases. Graphics 405 Recognition. Ten Years Review and Future Perspectives"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 154
                            }
                        ],
                        "text": "One effective way to define layout similarity for matching is based on structural features (Collins-Thompson and Nickolov, 2002; Shin and Doermann, 2006; Joutel et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Joutel et al. (2007) presented an approach for the retrieval of handwritten historical documents at page level based on the curvelet transform to compose a unique signature for each page."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 97
                            }
                        ],
                        "text": "34 One effective way to define layout similarity for matching is based on 35 structural features (Collins-Thompson and Nickolov, 2002; Shin and Doer36 mann, 2006; Joutel et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Curvelets based queries"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 175
                            }
                        ],
                        "text": "The number of features (N) using our approach is:\nN \u00bc XH\nl\u00bc0\nX2l k\u00bc1 Cj j \u00fe XV l\u00bc0 X2l k\u00bc1 Cj j \u00f01\u00de\nwhere Cj j is the number of codewords, H and V represents the level of partition in the horizontal and vertical dimension respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 149
                            }
                        ],
                        "text": "Structurally consistent match between two document images is a match that preserves the constraints of one-to-one mapping and parallel connectivity (Forbus et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mac/fac: A model of similarity- 434 based retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Science"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 140
                            }
                        ],
                        "text": "\u2026we use data from three collections: (1) a collection of Arabic document images collected in a field operation (Anfal) (Kumar et al., 2011; Manohar et al., 2011), (2) the Tobacco litigation dataset (Lewis et al., 2006), and (3) a collection of 5590 tax-form images obtained from National\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "459 Graph clustering-based ensemble method for handwritten text line seg- 460 mentation"
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis and Recognition, Intl. Conf. on"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 140
                            }
                        ],
                        "text": "\u2026we use data from three collections: (1) a collection of Arabic document images collected in a field operation (Anfal) (Kumar et al., 2011; Manohar et al., 2011), (2) the Tobacco litigation dataset (Lewis et al., 2006), and (3) a collection of 5590 tax-form images obtained from National\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "459 Graph clustering-based ensemble method for handwritten text line seg- 460 mentation"
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis and Recognition, Intl. Conf. on"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 187
                            }
                        ],
                        "text": "Furthermore, as previously mentioned, a majority of the work published on defining and applying structural similarity is specific to a particular document type, such as business letters (Dengel and Dubiel, 1995; Marinai et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Clustering and classification of document"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 165
                            }
                        ],
                        "text": "A large number of retrieval techniques have been developed using a query by example paradigm (Zhu and Doermann, 2009; Marinai et al., 2011; Jain and Doermann, 2012; Chen et al., 2012a), where features are extracted and indexed from document images off-line."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 156
                            }
                        ],
                        "text": "Previous work have reported similar high accuracies on this dataset but they used a much larger training set in their experiments (Shin and Doermann, 2006; Chen et al., 2012b)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Structured document classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Signature detection"
            },
            "venue": {
                "fragments": [],
                "text": "Conf. on Document Analysis and Recognition,"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 47
                            }
                        ],
                        "text": ", 2005), and document 143 image categorization (Barbu et al., 2006; Kumar et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 239
                            }
                        ],
                        "text": "Approaches based on bag-of-words (BOW) models have shown promising results on many computer vision tasks such as image classification (Wallraven et al., 2003), scene understanding (Quelhas et al., 2005), and document image categorization (Barbu et al., 2006; Kumar et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using bags of symbols"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 344,
                                "start": 320
                            }
                        ],
                        "text": "In our experiments, we use data from three collections: (1) a collection of Arabic document images collected in a field operation (Anfal) (Kumar et al., 2011; Manohar et al., 2011), (2) the Tobacco litigation dataset (Lewis et al., 2006), and (3) a collection of 5590 tax-form images obtained from National Institute of Standards and Technology (Dimmick et al., 1991)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 274
                            }
                        ],
                        "text": "\u2026of Arabic document images collected in a field operation (Anfal) (Kumar et al., 2011; Manohar et al., 2011), (2) the Tobacco litigation dataset (Lewis et al., 2006), and (3) a collection of 5590 tax-form images obtained from National Institute of Standards and Technology (Dimmick et al., 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 115
                            }
                        ],
                        "text": ", 2006), and (3) a collection of 5590 tax-form images obtained from National Institute of Standards and Technology (Dimmick et al., 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NIST structured forms reference set of binary images (SFRS), NIST Special Database 2. <http://www.nist.gov/srd/ nistsd2.cfm>"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Spatial pyramid co-occurrence for image classi- 480 fication"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision, Intl. Conf. on"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 385,
                                "start": 287
                            }
                        ],
                        "text": "While there are numerous applications in office 4 automation, litigation support and general document image search which 5 depend on efficient and effective methods for computing similarity, previous 6 approaches have focused on content-specific features or layout-specific struc7 tures (Doermann, 1998; Collins-Thompson and Nickolov, 2002; Shin and Do8 ermann, 2006; Zhu et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 272
                            }
                        ],
                        "text": "\u2026support and general document image search which depend on efficient and effective methods for computing similarity, previous approaches have focused on content-specific features or layout-specific structures (Collins-Thompson and Nickolov, 2002; Shin and Doermann, 2006; Zhu et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Signature detection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 72
                            }
                        ],
                        "text": "ity is specific to a particular document type, such as business letters (Dengel 42 and Dubiel, 1995; Marinai et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 212
                            }
                        ],
                        "text": "Furthermore, as previously mentioned, a majority of the work published on defining and applying structural similarity is specific to a particular document type, such as business letters (Dengel and Dubiel, 1995; Marinai et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tree clustering for layout-based"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 154
                            }
                        ],
                        "text": "One effective way to define layout similarity for matching is based on structural features (Collins-Thompson and Nickolov, 2002; Shin and Doermann, 2006; Joutel et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Joutel et al. (2007) presented an approach for the retrieval of handwritten historical documents at page level based on the curvelet transform to compose a unique signature for each page."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Curvelets based queries for CBIR"
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems (DAS),"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ing using sparse coding for image classification In: Computer Vision and 478 Pattern Recognition, IEEE Conf"
            },
            "venue": {
                "fragments": [],
                "text": "ing using sparse coding for image classification In: Computer Vision and 478 Pattern Recognition, IEEE Conf"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "459 Graph clusteringbased ensemble method for handwritten text line seg460 mentation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 192
                            }
                        ],
                        "text": "Subsequently, there has been focus on selecting the optimal 154 feature combination strategy and efficient ways to learn these local statis155 tics, and a number of methods have been proposed (Yang et al., 2009; Yang 156 and Newsam, 2011; Kumar et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 185
                            }
                        ],
                        "text": "Subsequently, there has been focus on selecting the optimal feature combination strategy and efficient ways to learn these local statistics, and a number of methods have been proposed (Yang et al., 2009, 2011; Kumar et al., 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Linear spatial pyramid"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 35,
            "methodology": 27,
            "result": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 63,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Structural-similarity-for-document-image-and-Kumar-Ye/e7ae643f8c1f987e6ba61f177a340e879a8644e0?sort=total-citations"
}