{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189883"
                        ],
                        "name": "Alex Chen",
                        "slug": "Alex-Chen",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46772671"
                        ],
                        "name": "Xiangrong Chen",
                        "slug": "Xiangrong-Chen",
                        "structuredName": {
                            "firstName": "Xiangrong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangrong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 99
                            }
                        ],
                        "text": "One promising direction is to integrate discriminative (bottomup) and generative (top-down) models [16, 13, 8, 10, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17925738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d944ff789af84cecc0a913da964e017408687d62",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a general framework for parsing images into regions and objects. In this framework, the detection and recognition of objects proceed simultaneously with image segmentation in a competitive and cooperative manner. We illustrate our approach on natural images of complex city scenes where the objects of primary interest are faces and text. This method makes use of bottom-up proposals combined with top-down generative models using the Data Driven Markov Chain Monte Carlo (DDMCMC) algorithm which is guaranteed to converge to the optimal estimate asymptotically. More precisely, we define generative models for faces, text, and generic regions\u2013 e.g. shading, texture, and clutter. These models are activated by bottom-up proposals. The proposals for faces and text are learnt using a probabilistic version of AdaBoost. The DDMCMC combines reversible jump and diffusion dynamics to enable the generative models to explain the input images in a competitive and cooperative manner. Our experiments illustrate the advantages and importance of combining bottom-up and top-down models and of performing segmentation and object detection/recognition simultaneously."
            },
            "slug": "Image-Parsing:-Segmentation,-Detection,-and-Tu-Chen",
            "title": {
                "fragments": [],
                "text": "Image Parsing: Segmentation, Detection, and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This method makes use of bottom-up proposals combined with top-down generative models using the Data Driven Markov Chain Monte Carlo (DDMCMC) algorithm which is guaranteed to converge to the optimal estimate asymptotically."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1915667"
                        ],
                        "name": "Y. Gdalyahu",
                        "slug": "Y.-Gdalyahu",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Gdalyahu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Gdalyahu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789171"
                        ],
                        "name": "D. Weinshall",
                        "slug": "D.-Weinshall",
                        "structuredName": {
                            "firstName": "Daphna",
                            "lastName": "Weinshall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Weinshall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27379268"
                        ],
                        "name": "M. Werman",
                        "slug": "M.-Werman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Werman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Werman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 47
                            }
                        ],
                        "text": "This can be done by message update as shown in [15, 2, 11] The messages are computed by"
                    },
                    "intents": []
                }
            ],
            "corpusId": 1935462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dedb4db1790ee4ec5e753824aefc85276ccf1ebc",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a stochastic clustering algorithm which uses pairwise similarity of elements and show how it can be used to address various problems in computer vision, including the low-level image segmentation, mid-level perceptual grouping, and high-level image database organization. The clustering problem is viewed as a graph partitioning problem, where nodes represent data elements and the weights of the edges represent pairwise similarities. We generate samples of cuts in this graph, by using Karger's contraction algorithm (1996), and compute an \"average\" cut which provides the basis for our solution to the clustering problem. The stochastic nature of our method makes it robust against noise, including accidental edges and small spurious clusters. The complexity of our algorithm is very low: O(|E| log/sup 2/ N) for N objects, |E| similarity relations, and a fixed accuracy level. In addition, and without additional computational cost, our algorithm provides a hierarchy of nested partitions. We demonstrate the superiority of our method for image segmentation on a few synthetic and real images, both B&W and color. Our other examples include the concatenation of edges in a cluttered scene (perceptual grouping) and the organization of an image database for the purpose of multiview 3D object recognition."
            },
            "slug": "Self-Organization-in-Vision:-Stochastic-Clustering-Gdalyahu-Weinshall",
            "title": {
                "fragments": [],
                "text": "Self-Organization in Vision: Stochastic Clustering for Image Segmentation, Perceptual Grouping, and Image Database Organization"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A stochastic clustering algorithm which uses pairwise similarity of elements and shows how it can be used to address various problems in computer vision, including the low-level image segmentation, mid-level perceptual grouping, and high- level image database organization is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787804"
                        ],
                        "name": "N. Shental",
                        "slug": "N.-Shental",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Shental",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Shental"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084674"
                        ],
                        "name": "A. Zomet",
                        "slug": "A.-Zomet",
                        "structuredName": {
                            "firstName": "Assaf",
                            "lastName": "Zomet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zomet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774536"
                        ],
                        "name": "T. Hertz",
                        "slug": "T.-Hertz",
                        "structuredName": {
                            "firstName": "Tomer",
                            "lastName": "Hertz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hertz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 47
                            }
                        ],
                        "text": "This can be done by message update as shown in [15, 2, 11] The messages are computed by"
                    },
                    "intents": []
                }
            ],
            "corpusId": 8607599,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16b9ab297236cc229ec0d3086b1765153f9391f5",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Significant progress in image segmentation has been made by viewing the problem in the framework of graph partitioning. In particular, spectral clustering methods such as \"normalized cuts\" (ncuts) can efficiently calculate good segmentations using eigenvector calculations. However, spectral methods when applied to images with local connectivity often oversegment homogenous regions. More importantly, they lack a straightforward probabilistic interpretation which makes it difficult to automatically set parameters using training data. In this paper we revisit the typical cut criterion proposed by Blatt et al. (1997) and Gdalyahu et al (2001). We show that computing the typical cut is equivalent to performing inference in an undirected graphical model. This equivalence allows us to use the powerful machinery of graphical models for learning and inferring image segmentations. For inferring segmentations we show that the generalized belief propagation (GBP) algorithm can give excellent results with a runtime that is usually faster than the ncut eigensolver. For learning segmentations we derive a maximum likelihood learning algorithm to learn affinity matrices from labelled datasets. We illustrate both learning and inference on challenging real and synthetic images."
            },
            "slug": "Learning-and-inferring-image-segmentations-using-Shental-Zomet",
            "title": {
                "fragments": [],
                "text": "Learning and inferring image segmentations using the GBP typical cut algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The typical cut criterion is revisited and it is shown that computing the typical cut is equivalent to performing inference in an undirected graphical model, which allows us to use the powerful machinery of graphical models for learning and inferring image segmentations."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7606118,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6cf3ad740d1e7309e6782c2f8e2fd41ce538505b",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Natura scenes consist of a wide variety of stochastic patterns. While many patterns are represented well by statistical models in two dimensional regions as most image segmentation work assume, some other patterns are fundamentally one dimensional and thus cause major problems in segmentation. We call the former region processes and the latter curve processes. In this paper, we propose a stochastic algorithm for parsing an image into a number of region and curve processes. The paper makes the following contributions to the literature. Firstly, it presents a generative rope model for the curve processes in the form of Hidden Markov Model (HMM). The hidden layer is a Markov chain with each element being an image vase selected from an over-complete basis, such as Difference of Gaussians (DOG) or Difference of Offset Gaussians (DOOG) at various scales and orientations. The rope model accounts for the geometric smoothness and photometric coherence of the curve processes. Secondly, it integrates both 2D region models, such as textures, splines etc with 1D curve models uner the Bayes framework. Because both region and curve models are generative, they compete to explain input images in a layered representation. Thirdl, it achieves global optimization by effective Markov chain Monte Carlo methods in the sense of maximizing a posterior probability. The Markov chain consists of reversivle jumps and diffusions driven by bottom up information. The algorithm is applied to real images with satisfactory results. We verify the results through random synthesis and compare them against segmentations with region processes only."
            },
            "slug": "Parsing-Images-into-Region-and-Curve-Processes-Tu-Zhu",
            "title": {
                "fragments": [],
                "text": "Parsing Images into Region and Curve Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A stochastic algorithm for parsing an image into a number of region and curve processes that achieves global optimization by effective Markov chain Monte Carlo methods in the sense of maximizing a posterior probability."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 398989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9376d0b8dade6323c170f57f4aaef36a2d61bdd1",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an algorithm for parsing natural images into middle level vision representations\u2014regions, curves, and curve groups (parallel curves and trees). This algorithm is targeted for an integrated solution to image segmentation and curve grouping through Bayesian inference. The paper makes the following contributions. (1) It adopts a layered (or 2.1D-sketch) representation integrating both region and curve models which compete to explain an input image. The curve layer occludes the region layer and curves observe a partial order occlusion relation. (2) A Markov chain search scheme Metropolized Gibbs Samplers (MGS) is studied. It consists of several pairs of reversible jumps to traverse the complex solution space. An MGS proposes the next state within the jump scope of the current state according to a conditional probability like a Gibbs sampler and then accepts the proposal with a Metropolis-Hastings step. This paper discusses systematic design strategies of devising reversible jumps for a complex inference task. (3) The proposal probability ratios in jumps are factorized into ratios of discriminative probabilities. The latter are computed in a bottom-up process, and they drive the Markov chain dynamics in a data-driven Markov chain Monte Carlo framework. We demonstrate the performance of the algorithm in experiments with a number of natural images."
            },
            "slug": "Parsing-Images-into-Regions,-Curves,-and-Curve-Tu-Zhu",
            "title": {
                "fragments": [],
                "text": "Parsing Images into Regions, Curves, and Curve Groups"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "An algorithm for parsing natural images into middle level vision representations\u2014regions, curves, and curve groups (parallel curves and trees) is presented for an integrated solution to image segmentation and curve grouping through Bayesian inference."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3587688"
                        ],
                        "name": "Jason J. Corso",
                        "slug": "Jason-J.-Corso",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Corso",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason J. Corso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699926"
                        ],
                        "name": "A. Toga",
                        "slug": "A.-Toga",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Toga",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Toga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1663845,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e5143b2c0ba756466a2e775e84f5800a62dd815",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel algorithm called graph-shifts for performing image segmentation and labeling. This algorithm makes use of a dynamic hierarchical representation of the image. This representation allows each iteration of the algorithm to make both small and large changes in the segmentation, similar to PDE and split-and-merge methods, respectively. In particular, at each iteration we are able to rapidly compute and select the optimal change to be performed. We apply graph-shifts to the task of segmenting sub-cortical brain structures. First we formalize this task as energy function minimization where the energy terms are learned from a training set of labeled images. Then we apply the graphshifts algorithm. We show that the labeling results are comparable in quantitative accuracy to other approaches but are obtained considerably faster: by orders of magnitude (roughly one minute). We also quantitatively demonstrate robustness to initialization and avoidance of local minima in which conventional boundary PDE methods fall."
            },
            "slug": "Segmentation-of-Sub-cortical-Structures-by-the-Corso-Tu",
            "title": {
                "fragments": [],
                "text": "Segmentation of Sub-cortical Structures by the Graph-Shifts Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The graphshifts algorithm makes use of a dynamic hierarchical representation of the image that allows each iteration of the algorithm to make both small and large changes in the segmentation, similar to PDE and split-and-merge methods, respectively."
            },
            "venue": {
                "fragments": [],
                "text": "IPMI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "With a variational approach [18], regions are competing for the boundary pixels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Region competition [18] is a variational approach which diffuses the neighboring region boundaries in minimizing the energy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35561340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73bd5c30eb274671c30b8f7222b5e4b03a915a62",
            "isKey": false,
            "numCitedBy": 2286,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel statistical and variational approach to image segmentation based on a new algorithm, named region competition. This algorithm is derived by minimizing a generalized Bayes/minimum description length (MDL) criterion using the variational principle. The algorithm is guaranteed to converge to a local minimum and combines aspects of snakes/balloons and region growing. The classic snakes/balloons and region growing algorithms can be directly derived from our approach. We provide theoretical analysis of region competition including accuracy of boundary location, criteria for initial conditions, and the relationship to edge detection using filters. It is straightforward to generalize the algorithm to multiband segmentation and we demonstrate it on gray level images, color images and texture images. The novel color model allows us to eliminate intensity gradients and shadows, thereby obtaining segmentation based on the albedos of objects. It also helps detect highlight regions."
            },
            "slug": "Region-Competition:-Unifying-Snakes,-Region-and-for-Zhu-Yuille",
            "title": {
                "fragments": [],
                "text": "Region Competition: Unifying Snakes, Region Growing, and Bayes/MDL for Multiband Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A novel statistical and variational approach to image segmentation based on a new algorithm, named region competition, derived by minimizing a generalized Bayes/minimum description length (MDL) criterion using the variational principle is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1952010"
                        ],
                        "name": "E. Sharon",
                        "slug": "E.-Sharon",
                        "structuredName": {
                            "firstName": "Eitan",
                            "lastName": "Sharon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sharon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144880062"
                        ],
                        "name": "A. Brandt",
                        "slug": "A.-Brandt",
                        "structuredName": {
                            "firstName": "Achi",
                            "lastName": "Brandt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Brandt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 99
                            }
                        ],
                        "text": "One promising direction is to integrate discriminative (bottomup) and generative (top-down) models [16, 13, 8, 10, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2038782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9dc4476dcbe47d8b3685df2aec232e242e268554",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Image segmentation is difficult because objects may differ from their background by any of a variety of properties that can be observed in some, but often not all scales. A further complication is that coarse measurements, applied to the image for detecting these properties, often average over properties of neighboring segments, making it difficult to separate the segments and to reliably detect their boundaries. Below we present a method for segmentation that generates and combines multiscale measurements of intensity contrast, texture differences, and boundary integrity. The method is based on our former algorithm SWA, which efficiently detects segments that optimize a normalized-cut like measure by recursively coarsening a graph reflecting similarities between intensities of neighboring pixels. In this process aggregates of pixels of increasing size are gradually collected to form segments. We intervene in this process by computing properties of the aggregates and modifying the graph to reflect these coarse scale measurements. This allows us to detect regions that differ by fine as well as coarse properties, and to accurately locate their boundaries. Furthermore, by combining intensity differences with measures of boundary integrity across neighboring aggregates we can detect regions separated by weak, yet consistent edges."
            },
            "slug": "Segmentation-and-boundary-detection-using-intensity-Sharon-Brandt",
            "title": {
                "fragments": [],
                "text": "Segmentation and boundary detection using multiscale intensity measurements"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method for segmentation that generates and combines multiscale measurements of intensity contrast, texture differences, and boundary integrity that allows to detect regions that differ by fine as well as coarse properties, and to accurately locate their boundaries."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "For image segmentation, the prior and likelihood models are the same to those used in [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "(I) The DDMCMC [12] method is a computational paradigm which combines top-down and bottom-up information in searching for the optimal solution."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 27
                            }
                        ],
                        "text": "It is much faster than the DDMCMC algorithm and more robust than the original SWC algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 50
                            }
                        ],
                        "text": "This largely improves the speed over the original DDMCMC algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "We show that it is much faster than the DDMCMC approach [12] and more robust than the SWC method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 58
                            }
                        ],
                        "text": "This gives rise to a system which is much faster than the DDMCMC algorithm, more robust than the SW-cut, and makes moves of large scope when searching for the optimal solution."
                    },
                    "intents": []
                }
            ],
            "corpusId": 20918902,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c045011905caf139326bcbd944398053dbb33e21",
            "isKey": false,
            "numCitedBy": 371,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a computational paradigm called Data-Driven Markov Chain Monte Carlo (DDMCMC) for image segmentation in the Bayesian statistical framework. The paper contributes to image segmentation in four aspects. First, it designs efficient and well-balanced Markov Chain dynamics to explore the complex solution space and, thus, achieves a nearly global optimal solution independent of initial segmentations. Second, it presents a mathematical principle and a K-adventurers algorithm for computing multiple distinct solutions from the Markov chain sequence and, thus, it incorporates intrinsic ambiguities in image segmentation. Third, it utilizes data-driven (bottom-up) techniques, such as clustering and edge detection, to compute importance proposal probabilities, which drive the Markov chain dynamics and achieve tremendous speedup in comparison to the traditional jump-diffusion methods. Fourth, the DDMCMC paradigm provides a unifying framework in which the role of many existing segmentation algorithms, such as, edge detection, clustering, region growing, split-merge, snake/balloon, and region competition, are revealed as either realizing Markov chain dynamics or computing importance proposal probabilities. Thus, the DDMCMC paradigm combines and generalizes these segmentation methods in a principled way. The DDMCMC paradigm adopts seven parametric and nonparametric image models for intensity and color at various regions. We test the DDMCMC paradigm extensively on both color and gray-level images and some results are reported in this paper."
            },
            "slug": "Image-Segmentation-by-Data-Driven-Markov-Chain-Tu-Zhu",
            "title": {
                "fragments": [],
                "text": "Image Segmentation by Data-Driven Markov Chain Monte Carlo"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The DDMCMC paradigm provides a unifying framework in which the role of many existing segmentation algorithms are revealed as either realizing Markov chain dynamics or computing importance proposal probabilities and generalizes these segmentation methods in a principled way."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144719476"
                        ],
                        "name": "Adrian Barbu",
                        "slug": "Adrian-Barbu",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Barbu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian Barbu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "(d) is the segmentation result by SWC [1], (e) shows the result by the algorithm proposed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "(5d) shows a segmentation result by the SWC algorithm [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "We briefly discuss the 2-way SWC below, and details can be found in [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "In image segmentation, it generalizes the Swendsen-Wang cut algorithm [1] (SWC) to make both 2-way and m-way cuts, and includes topology change processes (graph repartitioning and boundary diffusion)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "The SWC algorithm [1], instead, works on atomic regions (pixel groups), and combines the split and merge dynamics into a single process."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12481669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e74855540d4bd87824182cb115aafbfb375a42a",
            "isKey": true,
            "numCitedBy": 128,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Vision tasks, such as segmentation, grouping, recognition, can be formulated as graph partition problems. The recent literature witnessed two popular graph cut algorithms: the Ncut using spectral graph analysis and the minimum-cut using the maximum flow algorithm. We present a third major approach by generalizing the Swendsen-Wang method - a well celebrated algorithm in statistical mechanics. Our algorithm simulates ergodic, reversible Markov chain jumps in the space of graph partitions to sample a posterior probability. At each step, the algorithm splits, merges, or regroups a sizable subgraph, and achieves fast mixing at low temperature enabling a fast annealing procedure. Experiments show it converges in 2-30 seconds on a PC for image segmentation. This is 400 times faster than the single-site update Gibbs sampler, and 20-40 times faster than the DDMCMC algorithm. The algorithm can optimize over the number of models and works for general forms of posterior probabilities, so it is more general than the existing graph cut approaches."
            },
            "slug": "Graph-partition-by-Swendsen-Wang-cuts-Barbu-Zhu",
            "title": {
                "fragments": [],
                "text": "Graph partition by Swendsen-Wang cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work presents a third major approach by generalizing the Swendsen-Wang method, which can optimize over the number of models and works for general forms of posterior probabilities, so it is more general than the existing graph cut approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064563493"
                        ],
                        "name": "Feng Han",
                        "slug": "Feng-Han",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17718282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3476eeeb7e80537e2ca3424bab0b1fa0f1a1911f",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a stochastic algorithm by effective Markov chain Monte Carlo (MCMC) for segmenting and reconstructing 3D scenes. The objective is to segment a range image and its associated reflectance map into a number of surfaces which fit to various 3D surface models and have homogeneous reflectance (material) properties. In comparison to previous work on range image segmentation, the paper makes the following contributions. Firstly, it is aimed at generic natural scenes, indoor and outdoor, which are often much complexer than most of the existing experiments in the \"polyhedra world\". Natural scenes require the algorithm to automatically deal with multiple types (families) of surface models which compete to explain the data. Secondly, it integrates the range image with the reflectance map. The latter provides material properties and is especially useful for surface of high specularity, such as glass, metal, ceramics. Thirdly, the algorithm is designed by reversible jump and diffusion Markov chain dynamics and thus achieves globally optimal solutions under the Bayesian statistical framework. Thus it realizes the cue integration and multiple model switching. Fourthly, it adopts two techniques to improve the speed of the Markov chain search: One is a coarse-to-fine strategy and the other are data driven techniques such as edge detection and clustering. The data driven methods provide important information for narrowing the search spaces in a probabilistic fashion. We apply the algorithm to two data sets and the experiments demonstrate robust and satisfactory results on both. Based on the segmentation results, we extend the reconstruction of surfaces behind occlusions to fill in the occluded parts."
            },
            "slug": "A-Stochastic-Algorithm-for-3D-Scene-Segmentation-Han-Tu",
            "title": {
                "fragments": [],
                "text": "A Stochastic Algorithm for 3D Scene Segmentation and Reconstruction"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A stochastic algorithm by effective Markov chain Monte Carlo for segmenting and reconstructing 3D scenes, aimed at generic natural scenes, indoor and outdoor, which are often much complexer than most of the existing experiments in the \"polyhedra world\"."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46772671"
                        ],
                        "name": "Xiangrong Chen",
                        "slug": "Xiangrong-Chen",
                        "structuredName": {
                            "firstName": "Xiangrong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangrong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1752880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cca9200d9da958b7f90eab901b2f30c04f1e0e9c",
            "isKey": false,
            "numCitedBy": 656,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a Bayesian framework for parsing images into their constituent visual patterns. The parsing algorithm optimizes the posterior probability and outputs a scene representation as a \u201cparsing graph\u201d, in a spirit similar to parsing sentences in speech and natural language. The algorithm constructs the parsing graph and re-configures it dynamically using a set of moves, which are mostly reversible Markov chain jumps. This computational framework integrates two popular inference approaches\u2014generative (top-down) methods and discriminative (bottom-up) methods. The former formulates the posterior probability in terms of generative models for images defined by likelihood functions and priors. The latter computes discriminative probabilities based on a sequence (cascade) of bottom-up tests/filters. In our Markov chain algorithm design, the posterior probability, defined by the generative models, is the invariant (target) probability for the Markov chain, and the discriminative probabilities are used to construct proposal probabilities to drive the Markov chain. Intuitively, the bottom-up discriminative probabilities activate top-down generative models. In this paper, we focus on two types of visual patterns\u2014generic visual patterns, such as texture and shading, and object patterns including human faces and text. These types of patterns compete and cooperate to explain the image and so image parsing unifies image segmentation, object detection, and recognition (if we use generic visual patterns only then image parsing will correspond to image segmentation (Tu and Zhu, 2002. IEEE Trans. PAMI, 24(5):657\u2013673). We illustrate our algorithm on natural images of complex city scenes and show examples where image segmentation can be improved by allowing object specific knowledge to disambiguate low-level segmentation cues, and conversely where object detection can be improved by using generic visual patterns to explain away shadows and occlusions."
            },
            "slug": "Image-Parsing:-Unifying-Segmentation,-Detection,-Tu-Chen",
            "title": {
                "fragments": [],
                "text": "Image Parsing: Unifying Segmentation, Detection, and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A Bayesian framework for parsing images into their constituent visual patterns that optimizes the posterior probability and outputs a scene representation as a \u201cparsing graph\u201d, in a spirit similar to parsing sentences in speech and natural language is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43643294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bae9b7a69fa30edaf910d89f559f14901974de93",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for shape matching and recognition based on a generative model for how one shape can be generated by the other. This generative model allows for a class of transformations, such as affine and non-rigid transformations, and induces a similarity measure between shapes. The matching process if formulated in the EM algorithm. To have a fast algorithm and avoid local minima, we show how the EM algorithm can be approximated by using informative features, which have two key properties-invariant and representative. They are also similar to the proposal probabilities used in DDMCMC [13]. The formulation allows us to know when and why approximations can be made and justifies the use of bottom-up features, which are used in a wide range of vision problems. This integrates generative models and feature-based approaches within the EM framework and helps clarifying the relationship between different algorithms for this problem such as shape context [3] and softassign [5]. We test the algorithm on a variety of data sets including MPEG7 CE-Shape-1, Kimia silhouettes, and real images of street scenes. We demonstrate very effective performance and compare our results with existing algorithms. Finally, we briefly illustrate how our approach can be generalized to a wider range of problems including object detection."
            },
            "slug": "Shape-Matching-and-Recognition-Using-Generative-and-Tu-Yuille",
            "title": {
                "fragments": [],
                "text": "Shape Matching and Recognition - Using Generative Models and Informative Features"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "An algorithm for shape matching and recognition based on a generative model for how one shape can be generated by the other and the use of bottom-up features, which are used in a wide range of vision problems is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6382669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be305b0684f1a6ec8407c107187d28502b48f993",
            "isKey": false,
            "numCitedBy": 464,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Edge detection is one of the most studied problems in computer vision, yet it remains a very challenging task. It is difficult since often the decision for an edge cannot be made purely based on low level cues such as gradient, instead we need to engage all levels of information, low, middle, and high, in order to decide where to put edges. In this paper we propose a novel supervised learning algorithm for edge and object boundary detection which we refer to as Boosted Edge Learning or BEL for short. A decision of an edge point is made independently at each location in the image; a very large aperture is used providing significant context for each decision. In the learning stage, the algorithm selects and combines a large number of features across different scales in order to learn a discriminative model using an extended version of the Probabilistic Boosting Tree classification algorithm. The learning based framework is highly adaptive and there are no parameters to tune. We show applications for edge detection in a number of specific image domains as well as on natural images. We test on various datasets including the Berkeley dataset and the results obtained are very good."
            },
            "slug": "Supervised-Learning-of-Edges-and-Object-Boundaries-Doll\u00e1r-Tu",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Edges and Object Boundaries"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes a novel supervised learning algorithm for edge and object boundary detection which it refers to as Boosted Edge Learning or BEL for short and shows applications for edge detection in a number of specific image domains as well as on natural images."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "The results are demonstrated on the Berkeley data set [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "Yet the results of existing methods are not matching human performance in terms of both speed and quality [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8165754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33a7a59f785ef46091c30c4c85ef88c6bdabab51",
            "isKey": false,
            "numCitedBy": 2381,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "slug": "Learning-to-detect-natural-image-boundaries-using-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Learning to detect natural image boundaries using local brightness, color, and texture cues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The two main results are that cue combination can be performed adequately with a simple linear model and that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30740383"
                        ],
                        "name": "Rongxing Li",
                        "slug": "Rongxing-Li",
                        "structuredName": {
                            "firstName": "Rongxing",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rongxing Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 130817699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8c805fd19c438f4bf5f21bb97c709b6995b3224",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Mobile mapping is a new technology for capturing georeferenced data. It is, however, still not practical to extract spatial and attribute information of objects such as infrastructure elements filly automatically. In this article, a new framework for 30 object recognition by hypothesis-and-test techniques is proposed and developed. An example of traffic-light recognition from mobile mapping images is given in detail. The hypothesis is generated according to the viewpoint dependent theory. We formulate the hypothesis test problem based on Bayesian inference and, in particular, the (Maximize A Posteriori Probability). This approach functions in two major steps: (1) generation of hot-spot maps by vanishing point detection and template matching, and (2) estimation of the parameters of 3D objects (traffic lights) by Markov Chain Monte Carlo (MCMC). The developed hot-spot map generation method is, in general, faster than general color image segmentation algorithms. For example, it can handle the recognition problem with a color image of 720 by 400 pixels within a couple of minutes rather than tens of minutes to even hours when using the segmentation algorithms. The parameter estimation method uses MCMC to simulate an ergodic stochastic process so that a robust and global optimal solution can be found. The approach shows great potential for automatic object recognition in image sequences acquired by mobile mapping systems. lntroductlon Automatic recognition of 3D objects from color images is a challenging, yet unsolved, problem. Furthermore, recognition of spatial features from images acquired in outdoor scenes, outside of a controlled laboratory environment, by a mobile mapping system (Li, 1997) poses an even more difficult research topic. The ways in which the data are acquired, for example using active or passive sensors, may affect the methods of object recognition. In this paper, we mainly discuss object recognition from color mobile mapping images and show how traffic lights, in particular, are recognized by the proposed system. The human stereo vision system is an extremely comprehensive and effective system that functions very fast and accurately to support human decision-making processing in an ever-changing environment. \"How are 3D objects represented in the human visual system?\" becomes the initial question we ask if we want to produce a similar visual system (Bulthoff et al., 1994). Different answers to this question yield different model representations, and thus lead to different approaches. ?tvo common answers to this question are viewpoint independent and viewpoint dependent approaches that are further"
            },
            "slug": "A-FRAMEWORK-FOR-AUTOMATIC-RECOGNITION-OF-SPATIAL-Tu-Li",
            "title": {
                "fragments": [],
                "text": "A FRAMEWORK FOR AUTOMATIC RECOGNITION OF SPATIAL FEATURES FROM MOBILE MAPPING IMAGERY"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "A new framework for object recognition by hypothesis-and-test techniques is proposed and developed and an example of traffic-light recognition from mobile mapping images is given in detail."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1855894"
                        ],
                        "name": "Yonggang Shi",
                        "slug": "Yonggang-Shi",
                        "structuredName": {
                            "firstName": "Yonggang",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yonggang Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7174732"
                        ],
                        "name": "A. Reiss",
                        "slug": "A.-Reiss",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Reiss",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Reiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2025290"
                        ],
                        "name": "R. Dutton",
                        "slug": "R.-Dutton",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Dutton",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944286"
                        ],
                        "name": "Agatha D. Lee",
                        "slug": "Agatha-D.-Lee",
                        "structuredName": {
                            "firstName": "Agatha",
                            "lastName": "Lee",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Agatha D. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1871314"
                        ],
                        "name": "A. Galaburda",
                        "slug": "A.-Galaburda",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Galaburda",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Galaburda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46833023"
                        ],
                        "name": "I. Dinov",
                        "slug": "I.-Dinov",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Dinov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Dinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145363225"
                        ],
                        "name": "P. Thompson",
                        "slug": "P.-Thompson",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Thompson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699926"
                        ],
                        "name": "A. Toga",
                        "slug": "A.-Toga",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Toga",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Toga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14087677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf7e88e329ce775405bcc9433b0aa9cdfb7c94e5",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose an automated approach for joint sulci detection on cortical surfaces by using graphical models and boosting techniques to incorporate shape priors of major sulci and their Markovian relations. For each sulcus, we represent it as a node in the graphical model and associate it with a sample space of candidate curves, which is generated automatically using the Hamilton-Jacobi skeleton of sulcal regions. To take into account individual as well as joint priors about the shape of major sulci, we learn the potential functions of the graphical model using AdaBoost algorithm to select and fuse information from a large set of features. This discriminative approach is especially powerful in capturing the neighboring relations between sulcal lines, which are otherwise hard to be captured by generative models. Using belief propagation, efficient inferencing is then performed on the graphical model to estimate each sulcus as the maximizer of its final belief. On a data set of 40 cortical surfaces, we demonstrate the advantage of joint detection on four major sulci: central, precentral, postcentral and the sylvian fissure."
            },
            "slug": "Joint-Sulci-Detection-Using-Graphical-Models-and-Shi-Tu",
            "title": {
                "fragments": [],
                "text": "Joint Sulci Detection Using Graphical Models and Boosted Priors"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "An automated approach for joint sulci detection on cortical surfaces by using graphical models and boosting techniques to incorporate shape priors of major sulci and their Markovian relations, which is especially powerful in capturing the neighboring relations between sulcal lines, which are otherwise hard to be captured by generative models."
            },
            "venue": {
                "fragments": [],
                "text": "IPMI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145492205"
                        ],
                        "name": "Hai Tao",
                        "slug": "Hai-Tao",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hai Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8961509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69deed411eeff65cc0cba9e7db94ac337322089b",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The efficiency and robustness of a vision system is often largely determined by the quality of the image features available to it. In data mining, one typically works with immense volumes of raw data, which demands effective algorithms to explore the data space. In analogy to data mining, the space of meaningful features for image analysis is also quite vast. Recently, the challenges associated with these problem areas have become more tractable through progress made in machine learning and concerted research effort in manual feature design by domain experts. In this paper, we propose a feature mining paradigm for image classification and examine several feature mining strategies. We also derive a principled approach for dealing with features with varying computational demands. Our goal is to alleviate the burden of manual feature design, which is a key problem in computer vision and machine learning. We include an in-depth empirical study on three typical data sets and offer theoretical explanations for the performance of various feature mining strategies. As a final confirmation of our ideas, we show results of a system, that utilizing feature mining strategies matches or outperforms the best reported results on pedestrian classification (where considerable effort has been devoted to expert feature design)."
            },
            "slug": "Feature-Mining-for-Image-Classification-Doll\u00e1r-Tu",
            "title": {
                "fragments": [],
                "text": "Feature Mining for Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A feature mining paradigm for image classification is proposed and several feature mining strategies are examined to alleviate the burden of manual feature design, which is a key problem in computer vision and machine learning."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145349582"
                        ],
                        "name": "Sanjiv Kumar",
                        "slug": "Sanjiv-Kumar",
                        "structuredName": {
                            "firstName": "Sanjiv",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjiv Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Kumar and Herbert [4] have developed a discriminative Markov random fields model on rectangular image patches to perform scene interpretation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10689850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e54f01884e1fba4a0bbd2f0989ad21a16ebb13e3",
            "isKey": false,
            "numCitedBy": 530,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we present discriminative random fields (DRFs), a discriminative framework for the classification of image regions by incorporating neighborhood interactions in the labels as well as the observed data. The discriminative random fields offer several advantages over the conventional Markov random field (MRF) framework. First, the DRFs allow to relax the strong assumption of conditional independence of the observed data generally used in the MRF framework for tractability. This assumption is too restrictive for a large number of applications in vision. Second, the DRFs derive their classification power by exploiting the probabilistic discriminative models instead of the generative models used in the MRF framework. Finally, all the parameters in the DRF model are estimated simultaneously from the training data unlike the MRF framework where likelihood parameters are usually learned separately from the field parameters. We illustrate the advantages of the DRFs over the MRF framework in an application of man-made structure detection in natural images taken from the Corel database."
            },
            "slug": "Discriminative-random-fields:-a-discriminative-for-Kumar-Hebert",
            "title": {
                "fragments": [],
                "text": "Discriminative random fields: a discriminative framework for contextual interaction in classification"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This work presents discriminative random fields (DRFs), a discrim inative framework for the classification of image regions by incorporating neighborhood interactions in the labels as well as the observed data that offers several advantages over the conventional Markov random field framework."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053403"
                        ],
                        "name": "Songfeng Zheng",
                        "slug": "Songfeng-Zheng",
                        "structuredName": {
                            "firstName": "Songfeng",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Songfeng Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7174732"
                        ],
                        "name": "A. Reiss",
                        "slug": "A.-Reiss",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Reiss",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Reiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2025290"
                        ],
                        "name": "R. Dutton",
                        "slug": "R.-Dutton",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Dutton",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944286"
                        ],
                        "name": "Agatha D. Lee",
                        "slug": "Agatha-D.-Lee",
                        "structuredName": {
                            "firstName": "Agatha",
                            "lastName": "Lee",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Agatha D. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1871314"
                        ],
                        "name": "A. Galaburda",
                        "slug": "A.-Galaburda",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Galaburda",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Galaburda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145363225"
                        ],
                        "name": "P. Thompson",
                        "slug": "P.-Thompson",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Thompson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46833023"
                        ],
                        "name": "I. Dinov",
                        "slug": "I.-Dinov",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Dinov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Dinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699926"
                        ],
                        "name": "A. Toga",
                        "slug": "A.-Toga",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Toga",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Toga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2310315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aab55f042c710fc71dc7354d822dfd3d79b1ee3a",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a learning based method for automatic extraction of the major cortical sulci from MRI volumes or extracted surfaces. Instead of using a few pre-defined rules such as the mean curvature properties, to detect the major sulci, the algorithm learns a discriminative model by selecting and combining features from a large pool of candidates. We used the Probabilistic Boosting Tree algorithm to learn the model, which implicitly discovers and combines rules based on manually annotated sulci traced by neuroanatomists. The algorithm almost has no parameters to tune and is fast because of the adoption of integral volume and 3D Haar filters. For a given approximately registered MRI volume, the algorithm computes the probability of how likely it is that each voxel lies on a major sulcus curve. Dynamic programming is then applied to extract the curve based on the probability map and a shape prior. Because the algorithm can be applied to MRI volumes directly, there is no need to perform preprocessing such as tissue segmentation or mapping to a canonical space. The learning aspect makes the approach flexible and it also works on extracted cortical surfaces."
            },
            "slug": "A-Learning-Based-Algorithm-for-Automatic-Extraction-Zheng-Tu",
            "title": {
                "fragments": [],
                "text": "A Learning Based Algorithm for Automatic Extraction of the Cortical Sulci"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A learning based method for automatic extraction of the major cortical sulci from MRI volumes or extracted surfaces using the Probabilistic Boosting Tree algorithm, which implicitly discovers and combines rules based on manually annotated sulci traced by neuroanatomists."
            },
            "venue": {
                "fragments": [],
                "text": "MICCAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108130121"
                        ],
                        "name": "Jiayong Zhang",
                        "slug": "Jiayong-Zhang",
                        "structuredName": {
                            "firstName": "Jiayong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiayong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143980462"
                        ],
                        "name": "R. Collins",
                        "slug": "R.-Collins",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Collins",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689241"
                        ],
                        "name": "Yanxi Liu",
                        "slug": "Yanxi-Liu",
                        "structuredName": {
                            "firstName": "Yanxi",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanxi Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 41
                            }
                        ],
                        "text": "Some recent work in this domain includes [6, 17, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 578602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68ff6f5a19f965e829ba71357fcc70380df2146f",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of localizing the articulated and deformable shape of a walking person in a single view. We represent the non-rigid 2D body contour by a Bayesian graphical model whose nodes correspond to point positions along the contour. The deformability of the model is constrained by learned priors corresponding to two basic mechanisms: local non-rigid deformation, and rotation motion of the joints. Four types of image cues are combined to relate the model configuration to the observed image, including edge gradient map, foreground/background mask, skin color mask, and appearance consistency constraints. The constructed Bayes network is sparse and chain-like, enabling efficient spatial inference through sequential Monte Carlo sampling methods. We evaluate the performance of the model on images taken in cluttered, outdoor scenes. The utility of each image cue is also empirically explored."
            },
            "slug": "Representation-and-matching-of-articulated-shapes-Zhang-Collins",
            "title": {
                "fragments": [],
                "text": "Representation and matching of articulated shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work considers the problem of localizing the articulated and deformable shape of a walking person in a single view by representing the non-rigid 2D body contour by a Bayesian graphical model whose nodes correspond to point positions along the contour."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 226145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23b80dc704e25cf52b5a14935002fc083ce9c317",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Generative model learning is one of the key problems in machine learning and computer vision. Currently the use of generative models is limited due to the difficulty in effectively learning them. A new learning framework is proposed in this paper which progressively learns a target generative distribution through discriminative approaches. This framework provides many interesting aspects to the literature. From the generative model side: (1) A reference distribution is used to assist the learning process, which removes the need for a sampling processes in the early stages. (2) The classification power of discriminative approaches, e.g. boosting, is directly utilized. (3) The ability to select/explore features from a large candidate pool allows us to make nearly no assumptions about the training data. From the discriminative model side: (1) This framework improves the modeling capability of discriminative models. (2) It can start with source training data only and gradually \"invent\" negative samples. (3) We show how sampling schemes can be introduced to discriminative models. (4) The learning procedure helps to tighten the decision boundaries for classification, and therefore, improves robustness. In this paper, we show a variety of applications including texture modeling and classification, non-photorealistic rendering, learning image statistics/denoising, and face modeling. The framework handles both homogeneous patterns, e.g. textures, and inhomogeneous patterns, e.g. faces, with nearly an identical parameter setting for all the tasks in the learning stage."
            },
            "slug": "Learning-Generative-Models-via-Discriminative-Tu",
            "title": {
                "fragments": [],
                "text": "Learning Generative Models via Discriminative Approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new learning framework is proposed in this paper which progressively learns a target generative distribution through discriminative approaches, which improves the modeling capability of discrim inative models and improves robustness."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053403"
                        ],
                        "name": "Songfeng Zheng",
                        "slug": "Songfeng-Zheng",
                        "structuredName": {
                            "firstName": "Songfeng",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Songfeng Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7174732"
                        ],
                        "name": "A. Reiss",
                        "slug": "A.-Reiss",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Reiss",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Reiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2025290"
                        ],
                        "name": "R. Dutton",
                        "slug": "R.-Dutton",
                        "structuredName": {
                            "firstName": "Rebecca",
                            "lastName": "Dutton",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944286"
                        ],
                        "name": "Agatha D. Lee",
                        "slug": "Agatha-D.-Lee",
                        "structuredName": {
                            "firstName": "Agatha",
                            "lastName": "Lee",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Agatha D. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1871314"
                        ],
                        "name": "A. Galaburda",
                        "slug": "A.-Galaburda",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Galaburda",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Galaburda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46833023"
                        ],
                        "name": "I. Dinov",
                        "slug": "I.-Dinov",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Dinov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Dinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145363225"
                        ],
                        "name": "P. Thompson",
                        "slug": "P.-Thompson",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Thompson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699926"
                        ],
                        "name": "A. Toga",
                        "slug": "A.-Toga",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Toga",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Toga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15404441,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f6ec5254d4ce5a8246806e7e0cf231999ef7d34",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "It is important to detect and extract the major cortical sulci from brain images, but manually annotating these sulci is a time-consuming task and requires the labeler to follow complex protocols , . This paper proposes a learning-based algorithm for automated extraction of the major cortical sulci from magnetic resonance imaging (MRI) volumes and cortical surfaces. Unlike alternative methods for detecting the major cortical sulci, which use a small number of predefined rules based on properties of the cortical surface such as the mean curvature, our approach learns a discriminative model using the probabilistic boosting tree algorithm (PBT) . PBT is a supervised learning approach which selects and combines hundreds of features at different scales, such as curvatures, gradients and shape index. Our method can be applied to either MRI volumes or cortical surfaces. It first outputs a probability map which indicates how likely each voxel lies on a major sulcal curve. Next, it applies dynamic programming to extract the best curve based on the probability map and a shape prior. The algorithm has almost no parameters to tune for extracting different major sulci. It is very fast (it runs in under 1 min per sulcus including the time to compute the discriminative models) due to efficient implementation of the features (e.g., using the integral volume to rapidly compute the responses of 3-D Haar filters). Because the algorithm can be applied to MRI volumes directly, there is no need to perform preprocessing such as tissue segmentation or mapping to a canonical space. The learning aspect of our approach makes the system very flexible and general. For illustration, we use volumes of the right hemisphere with several major cortical sulci manually labeled. The algorithm is tested on two groups of data, including some brains from patients with Williams Syndrome, and the results are very encouraging"
            },
            "slug": "Automated-Extraction-of-the-Cortical-Sulci-Based-on-Tu-Zheng",
            "title": {
                "fragments": [],
                "text": "Automated Extraction of the Cortical Sulci Based on a Supervised Learning Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A learning-based algorithm for automated extraction of the major cortical sulci from magnetic resonance imaging (MRI) volumes and cortical surfaces using the probabilistic boosting tree algorithm (PBT)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Medical Imaging"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 99
                            }
                        ],
                        "text": "One promising direction is to integrate discriminative (bottomup) and generative (top-down) models [16, 13, 8, 10, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16292278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b678353f8e71f2fb75c7ab49c90cfb523ea59011",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system that can build appearance models of animals automatically from a video sequence of the relevant animal with no explicit supervisory information. The video sequence need not have any form of special background. Animals are modeled as a 2D kinematic chain of rectangular segments, where the number of segments and the topology of the chain are unknown. The system detects possible segments, clusters segments whose appearance is coherent over time, and then builds a spatial model of such segment clusters. The resulting representation of the spatial configuration of the animal in each frame can be seen either as a track - in which case the system described should be viewed as a generalized tracker, that is capable of modeling objects while tracking them - or as the source of an appearance model which can be used to build detectors for the particular animal. This is because knowing a video sequence is temporally coherent - i.e. that a particular animal is present through the sequence - is a strong supervisory signal. The method is shown to be successful as a tracker on video sequences of real scenes showing three different animals. For the same reason it is successful as a tracker, the method results in detectors that can be used to find each animal fairly reliably within the Corel collection of images."
            },
            "slug": "Using-temporal-coherence-to-build-models-of-animals-Ramanan-Forsyth",
            "title": {
                "fragments": [],
                "text": "Using temporal coherence to build models of animals"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A system that can build appearance models of animals automatically from a video sequence of the relevant animal with no explicit supervisory information is described, which results in detectors that can be used to find each animal fairly reliably within the Corel collection of images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 41
                            }
                        ],
                        "text": "Some recent work in this domain includes [6, 17, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "Experiments We test the proposed algorithm on in images in [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9177303,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5d6d6f5d9caaba221d785f0b92d07ce2bfa3a48",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to detect a human figure image and localize his joints and limbs along with their associated pixel masks. In this work we attempt to tackle this problem in a general setting. The dataset we use is a collection of sports news photographs of baseball players, varying dramatically in pose and clothing. The approach that we take is to use segmentation to guide our recognition algorithm to salient bits of the image. We use this segmentation approach to build limb and torso detectors, the outputs of which are assembled into human figures. We present quantitative results on torso localization, in addition to shortlisted full body configurations."
            },
            "slug": "Recovering-human-body-configurations:-combining-and-Mori-Ren",
            "title": {
                "fragments": [],
                "text": "Recovering human body configurations: combining segmentation and recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work uses segmentation to build limb and torso detectors, the outputs of which are assembled into human figures, and presents quantitative results on torso localization, in addition to shortlisted full body configurations."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157770501"
                        ],
                        "name": "Ron Li",
                        "slug": "Ron-Li",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ron Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14144634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50be054e2840b49b670bb3663b31198806f4e1b0",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Information technology is increasingly used to support civil infrastructure systems that are large, complex heterogeneous, and distributed. These dynamic systems include communication systems, roads, bridges, traffic control facilities, and facilities for the distribution of water, gas and electricity. Mobile mapping is a new technology to capture georeferenced data. It is, however, still not practical to extract spatial and attribute information of infrastructure objects fully automatically. In this article, a framework for 3D-object recognition is proposed according to a viewpoint dependent theory. A novel system that generates hot-spot maps using color indexing and edge gradient indexing and recognizes traffic lights using MCMC (Markov Chain Monte Carlo) method is proposed. The hot-spot map generation method we developed is much faster than general color image segmentation and thus is practical to be applied in a recognition system. In this approach, both top-down and bottom-up methods are combined by the MCMC engine, which not only recognizes traffic lights but also tells us their poses. This system is robust for different degrees of illumination and rotation."
            },
            "slug": "AUTOMATIC-RECOGNITION-OF-CIVIL-INFRASTRUCTURE-IN-A-Tu-Li",
            "title": {
                "fragments": [],
                "text": "AUTOMATIC RECOGNITION OF CIVIL INFRASTRUCTURE OBJECTS IN MOBILE MAPPING IMAGERY USING A MARKOV RANDOM FIELD MODEL"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel system that generates hot-spot maps using colorindexing and edge gradient indexing and recognizes traffic lights using MCMC (Markov Chain Monte Carlo) method is proposed and is much faster than general color image segmentation and thus is practical to be applied in a recognition system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 99
                            }
                        ],
                        "text": "One promising direction is to integrate discriminative (bottomup) and generative (top-down) models [16, 13, 8, 10, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 419324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a4300efb6895695205dfc1b74e124f9fea6aff2",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard approaches to object detection focus on local patches of the image, and try to classify them as background or not. We propose to use the scene context (image as a whole) as an extra source of (global) information, to help resolve local ambiguities. We present a conditional random field for jointly solving the tasks of object detection and scene classification."
            },
            "slug": "Using-the-Forest-to-See-the-Trees:-A-Graphical-and-Murphy-Torralba",
            "title": {
                "fragments": [],
                "text": "Using the Forest to See the Trees: A Graphical Model Relating Features, Objects, and Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a conditional random field for jointly solving the tasks of object detection and scene classification, and proposes to use the scene context as an extra source of (global) information, to help resolve local ambiguities."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "In the first layer, a discriminative method, probabilistic boosting-tree [14] is adopted to learn and compute a multi-class pairwise affinity map for atomic regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "PBT combines these cues into a strong decision maker, and outputs a posterior probability."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "In the first layer, probabilistic boosting-tree [14] (PBT) is adopted to learn and compute pairwise multi-class affinity map for neighboring atomic regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "We use a new discriminative model learning framework, probabilistic boosting-tree (PBT) [14] , to learn pairwise relationships between neighboring atomic regions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "The details of how to learn and compute the model by PBT are discussed in [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8540654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e56ae29377bff8e04336c778cac011f2bcf2b88",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a new learning framework - probabilistic boosting-tree (PBT), is proposed for learning two-class and multi-class discriminative models. In the learning stage, the probabilistic boosting-tree automatically constructs a tree in which each node combines a number of weak classifiers (evidence, knowledge,) into a strong classifier (a conditional posterior probability). It approaches the target posterior distribution by data augmentation (tree expansion) through a divide-and-conquer strategy. In the testing stage, the conditional probability is computed at each tree node based on the learned classifier, which guides the probability propagation in its sub-trees. The top node of the tree therefore outputs the overall posterior probability by integrating the probabilities gathered from its sub-trees. Also, clustering is naturally embedded in the learning phase and each sub-tree represents a cluster of certain level. The proposed framework is very general and it has interesting connections to a number of existing methods such as the A* algorithm, decision tree algorithms, generative models, and cascade approaches. In this paper, we show the applications of PBT for classification, detection, and object recognition. We have also applied the framework in segmentation"
            },
            "slug": "Probabilistic-boosting-tree:-learning-models-for-Tu",
            "title": {
                "fragments": [],
                "text": "Probabilistic boosting-tree: learning discriminative models for classification, recognition, and clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The applications of PBT for classification, detection, and object recognition are shown and the framework has interesting connections to a number of existing methods such as the A* algorithm, decision tree algorithms, generative models, and cascade approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1855894"
                        ],
                        "name": "Yonggang Shi",
                        "slug": "Yonggang-Shi",
                        "structuredName": {
                            "firstName": "Yonggang",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yonggang Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145363225"
                        ],
                        "name": "P. Thompson",
                        "slug": "P.-Thompson",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Thompson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996669518"
                        ],
                        "name": "G. Zubicaray",
                        "slug": "G.-Zubicaray",
                        "structuredName": {
                            "firstName": "Greig de",
                            "lastName": "Zubicaray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zubicaray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766349"
                        ],
                        "name": "S. Rose",
                        "slug": "S.-Rose",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Rose",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rose"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46833023"
                        ],
                        "name": "I. Dinov",
                        "slug": "I.-Dinov",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Dinov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Dinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699926"
                        ],
                        "name": "A. Toga",
                        "slug": "A.-Toga",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Toga",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Toga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3379915,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "177577faa48f7d4d3f930eaa0efbd0e44a4deb0c",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Direct-mapping-of-hippocampal-surfaces-with-shape-Shi-Thompson",
            "title": {
                "fragments": [],
                "text": "Direct mapping of hippocampal surfaces with intrinsic shape context"
            },
            "venue": {
                "fragments": [],
                "text": "NeuroImage"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198578"
                        ],
                        "name": "J. Yedidia",
                        "slug": "J.-Yedidia",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Yedidia",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yedidia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52835993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8921b3462a3575b0b5de602a975bd608f6f6652",
            "isKey": false,
            "numCitedBy": 1611,
            "numCiting": 115,
            "paperAbstract": {
                "fragments": [],
                "text": "Important inference problems in statistical physics, computer vision, error-correcting coding theory, and artificial intelligence can all be reformulated as the computation of marginal probabilities on factor graphs. The belief propagation (BP) algorithm is an efficient way to solve these problems that is exact when the factor graph is a tree, but only approximate when the factor graph has cycles. We show that BP fixed points correspond to the stationary points of the Bethe approximation of the free energy for a factor graph. We explain how to obtain region-based free energy approximations that improve the Bethe approximation, and corresponding generalized belief propagation (GBP) algorithms. We emphasize the conditions a free energy approximation must satisfy in order to be a \"valid\" or \"maxent-normal\" approximation. We describe the relationship between four different methods that can be used to generate valid approximations: the \"Bethe method\", the \"junction graph method\", the \"cluster variation method\", and the \"region graph method\". Finally, we explain how to tell whether a region-based approximation, and its corresponding GBP algorithm, is likely to be accurate, and describe empirical results showing that GBP can significantly outperform BP."
            },
            "slug": "Constructing-free-energy-approximations-and-belief-Yedidia-Freeman",
            "title": {
                "fragments": [],
                "text": "Constructing free-energy approximations and generalized belief propagation algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work explains how to obtain region-based free energy approximations that improve the Bethe approximation, and corresponding generalized belief propagation (GBP) algorithms, and describes empirical results showing that GBP can significantly outperform BP."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198578"
                        ],
                        "name": "J. Yedidia",
                        "slug": "J.-Yedidia",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Yedidia",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yedidia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 47
                            }
                        ],
                        "text": "This can be done by message update as shown in [15, 2, 11] The messages are computed by"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "In perceptual grouping, it integrates discriminative model learning/computing, a belief propagation algorithm (BP) [15] , and SWC into a three-layer computing framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15300022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2799fd1254689eec52f86daf3668a5aac3ea943",
            "isKey": false,
            "numCitedBy": 1127,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief propagation (BP) was only supposed to work for treelike networks but works surprisingly well in many applications involving networks with loops, including turbo codes. However, there has been little understanding of the algorithm or the nature of the solutions it finds for general graphs. \n \nWe show that BP can only converge to a stationary point of an approximate free energy, known as the Bethe free energy in statistical physics. This result characterizes BP fixed-points and makes connections with variational approaches to approximate inference. \n \nMore importantly, our analysis lets us build on the progress made in statistical physics since Bethe's approximation was introduced in 1935. Kikuchi and others have shown how to construct more accurate free energy approximations, of which Bethe's approximation is the simplest. Exploiting the insights from our analysis, we derive generalized belief propagation (GBP) versions of these Kikuchi approximations. These new message passing algorithms can be significantly more accurate than ordinary BP, at an adjustable increase in complexity. We illustrate such a new GBP algorithm on a grid Markov network and show that it gives much more accurate marginal probabilities than those found using ordinary BP."
            },
            "slug": "Generalized-Belief-Propagation-Yedidia-Freeman",
            "title": {
                "fragments": [],
                "text": "Generalized Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that BP can only converge to a stationary point of an approximate free energy, known as the Bethe free energy in statistical physics, and generalized belief propagation (GBP) versions of these Kikuchi approximations are derived."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2649483"
                        ],
                        "name": "M. Lee",
                        "slug": "M.-Lee",
                        "structuredName": {
                            "firstName": "Mun",
                            "lastName": "Lee",
                            "middleNames": [
                                "Wai"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144422657"
                        ],
                        "name": "I. Cohen",
                        "slug": "I.-Cohen",
                        "structuredName": {
                            "firstName": "Isaac",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 41
                            }
                        ],
                        "text": "Some recent work in this domain includes [6, 17, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1888970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2203112e8323c52950df0503126adc3af18098ad",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of estimating human body pose in static images. This problem is challenging due to the high dimensional state space of body poses, the presence of pose ambiguity, and the need to segment the human body in an image. We use an image generative approach by modeling the human kinematics, the shape and the clothing probabilistically. These models are used for deriving a good likelihood measure to evaluate samples in the solution, space. We adopt a data-driven MCMC framework for searching the solution space efficiently. Our observation data include the face, head-shoulders contour, skin color blobs, and ridges; and they provide evidences on the positions of the head, shoulders and limbs. To translate these inferences into pose hypotheses, we introduce the use of 'proposal maps', which is an efficient way of consolidating the evidence and generating 3D pose candidates during the MCMC search. As experimental results show, the proposed technique estimates the human 3D pose accurately on various test images."
            },
            "slug": "Proposal-maps-driven-MCMC-for-estimating-human-body-Lee-Cohen",
            "title": {
                "fragments": [],
                "text": "Proposal maps driven MCMC for estimating human body pose in static images"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An image generative approach is used by modeling the human kinematics, the shape and the clothing probabilistically, used for deriving a good likelihood measure to evaluate samples in the solution, space and introduces the use of 'proposal maps', which is an efficient way of consolidating the evidence and generating 3D pose candidates during the MCMC search."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145392702"
                        ],
                        "name": "P. Green",
                        "slug": "P.-Green",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Green",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Green"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "Compared to the traditional MCMC algorithms [3], it is more efficient due to its use of bottom-up processes in guiding the search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "We use the Metropolis-Hasting [3] algorithm to perform sampling in the solution space which consists of the partition space and the parameter space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17132495,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "961e2156d523e3901c491cc2a1f65764c976fc44",
            "isKey": false,
            "numCitedBy": 5895,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Markov chain Monte Carlo methods for Bayesian computation have until recently been restricted to problems where the joint distribution of all variables has a density with respect to some fixed standard underlying measure. They have therefore not been available for application to Bayesian model determination, where the dimensionality of the parameter vector is typically not fixed. This paper proposes a new framework for the construction of reversible Markov chain samplers that jump between parameter subspaces of differing dimensionality, which is flexible and entirely constructive. It should therefore have wide applicability in model determination problems. The methodology is illustrated with applications to multiple change-point analysis in one and two dimensions, and to a Bayesian comparison of binomial experiments."
            },
            "slug": "Reversible-jump-Markov-chain-Monte-Carlo-and-model-Green",
            "title": {
                "fragments": [],
                "text": "Reversible jump Markov chain Monte Carlo computation and Bayesian model determination"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Learning Based Framework for 3D Segmentation and Its Application for Colon Detagging"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of European Conference on Computer Vision (ECCV)"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Tenth IEEE International Conference on Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Tenth IEEE International Conference on Computer Vision"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Stochastic Algorithm for Parsing and Reconstructing 3D Scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the 7th European Conference on Computer Vision (ECCV)"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to Perform Whole Brain Segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of 10 th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic 3D Polyp Detection: The Role of Data Alignment"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Computer Vision and Pattern Recognition"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "One promising direction is to integrate discriminative (bottomup) and generative (top-down) models [16, 13, 8, 10, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Parsing: Segmentation, Detection , and Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Image Parsing: Segmentation, Detection , and Object Recognition"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Refereed Major Conferences"
            },
            "venue": {
                "fragments": [],
                "text": "Refereed Major Conferences"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Integrating Top-down/Bottom-up for Object Recognition by Data Driven Markov Chain Monte Carlo"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of IEEE Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Integrated Framework for Image Segmentation and Perceptual Grouping"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 99
                            }
                        ],
                        "text": "One promising direction is to integrate discriminative (bottomup) and generative (top-down) models [16, 13, 8, 10, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Concurrent Object Segmentation and Recognition with Graph Partitioning"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 43,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/An-integrated-framework-for-image-segmentation-and-Tu/8e3c29a882e76d1d7f2e04e3ab9ac9af11885d33?sort=total-citations"
}