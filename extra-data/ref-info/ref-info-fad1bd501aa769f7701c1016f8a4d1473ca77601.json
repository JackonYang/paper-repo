{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700185"
                        ],
                        "name": "S. Weiss",
                        "slug": "S.-Weiss",
                        "structuredName": {
                            "firstName": "Sholom",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092055"
                        ],
                        "name": "I. Kapouleas",
                        "slug": "I.-Kapouleas",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Kapouleas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kapouleas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1059822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b7222ac076d211d7fcae7d012bebcc4ea71e952",
            "isKey": false,
            "numCitedBy": 524,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification methods from statistical pattern recognition, neural nets, and machine learning were applied to four real-world data sets. Each of these data sets has been previously analyzed and reported in the statistical, medical, or machine learning literature. The data sets are characterized by statisucal uncertainty; there is no completely accurate solution to these problems. Training and testing or resampling techniques are used to estimate the true error rates of the classification methods. Detailed attention is given to the analysis of performance of the neural nets using back propagation. For these problems, which have relatively few hypotheses and features, the machine learning procedures for rule induction or tree induction clearly performed best."
            },
            "slug": "An-Empirical-Comparison-of-Pattern-Recognition,-and-Weiss-Kapouleas",
            "title": {
                "fragments": [],
                "text": "An Empirical Comparison of Pattern Recognition, Neural Nets, and Machine Learning Classification Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "For these problems, which have relatively few hypotheses and features, the machine learning procedures for rule induction or tree induction clearly performed best."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49800308"
                        ],
                        "name": "B. Silverman",
                        "slug": "B.-Silverman",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Silverman",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Silverman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 115
                            }
                        ],
                        "text": "These can be used to derive plug-in estimates for \u009e\u00c3\u00c2 which are well-suited to the goal of density estimation, see Silverman (1986) for further details."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 67073029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "729cb7a620b4e81b63b281627474020cdfbadd39",
            "isKey": false,
            "numCitedBy": 7458,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction. Survey of Existing Methods. The Kernel Method for Univariate Data. The Kernel Method for Multivariate Data. Three Important Methods. Density Estimation in Action."
            },
            "slug": "Density-Estimation-for-Statistics-and-Data-Analysis-Silverman",
            "title": {
                "fragments": [],
                "text": "Density Estimation for Statistics and Data Analysis."
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The Kernel Method for Multivariate Data: Three Important Methods and Density Estimation in Action."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34915378"
                        ],
                        "name": "R. Rohwer",
                        "slug": "R.-Rohwer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rohwer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rohwer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11297923,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8ae7125165506e1de408b1a62546a78678b6cca",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of seven minimization algorithms are compared on five neural network problems. These include a variable-step-size algorithm, conjugate gradient, and several methods with explicit analytic or numerical approximations to the Hessian."
            },
            "slug": "Time-Trials-on-Second-Order-and-Algorithms-Rohwer",
            "title": {
                "fragments": [],
                "text": "Time Trials on Second-Order and Variable-Learning-Rate Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "The performance of seven minimization algorithms are compared on five neural network problems, including a variable-step-size algorithm, conjugate gradient, and several methods with explicit analytic or numerical approximations to the Hessian."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14942773"
                        ],
                        "name": "M. Stone",
                        "slug": "M.-Stone",
                        "structuredName": {
                            "firstName": "Mervyn",
                            "lastName": "Stone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 764,
                                "start": 0
                            }
                        ],
                        "text": "Tsaptsinos et al. (1990) also found that ID3 was more preferable on an engineering control problem than two neural network algorithms. However, on different tasks other researchers found that a higher order neural network (HONN) performed better than ID3 (Spivoska & Reid, 1990) and back-propagation did better than CART (Atlas et al., 1991). Gorman & Sejnowski (1988) reported that back-propagation outperformed nearest neighbour for classifying sonar targets, whereas some Bayes algorithms were shown to be better on other tasks (Shadmehr & D\u2019Argenio, 1990). More extensive comparisons have also been carried out between neural network and symbolic methods. However, the results of these studies were inconclusive. For example, whereas Weiss & Kulikowski (1991) and Weiss & Kapouleas (1989) reported that backpropagation performed worse than symbolic methods (i."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 369,
                                "start": 0
                            }
                        ],
                        "text": "Tsaptsinos et al. (1990) also found that ID3 was more preferable on an engineering control problem than two neural network algorithms. However, on different tasks other researchers found that a higher order neural network (HONN) performed better than ID3 (Spivoska & Reid, 1990) and back-propagation did better than CART (Atlas et al., 1991). Gorman & Sejnowski (1988) reported that back-propagation outperformed nearest neighbour for classifying sonar targets, whereas some Bayes algorithms were shown to be better on other tasks (Shadmehr & D\u2019Argenio, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Tsaptsinos et al. (1990) also found that ID3 was more preferable on an engineering control problem than two neural network algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Stone (1974) describes cross-validation methods for giving unbiased estimates of the error rate."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62698647,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "7b28610d2d681a11398eb614de0d70d7de41c20c",
            "isKey": true,
            "numCitedBy": 7503,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY A generalized form of the cross-validation criterion is applied to the choice and assessment of prediction using the data-analytic concept of a prescription. The examples used to illustrate the application are drawn from the problem areas of univariate estimation, linear regression and analysis of variance."
            },
            "slug": "Cross\u2010Validatory-Choice-and-Assessment-of-Stone",
            "title": {
                "fragments": [],
                "text": "Cross\u2010Validatory Choice and Assessment of Statistical Predictions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702517"
                        ],
                        "name": "I. Sethi",
                        "slug": "I.-Sethi",
                        "structuredName": {
                            "firstName": "Ishwar",
                            "lastName": "Sethi",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sethi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066410160"
                        ],
                        "name": "Mike Otten",
                        "slug": "Mike-Otten",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Otten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Otten"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36295099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a1ad82d22eda1f5b7353c0059e0cdc44eca95be",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A class of hierarchical feedforward layered neural networks, called entropy nets, has been proposed to overcome the difficulty of the credit assignment problem and to introduce the self-configurable capability in the design and training of artificial neural networks. These networks are based on mapping binary decision trees into a three-layer structure. The authors report the results of an experimental study comparing the classification performance of the decision tree and the entropy-net classifiers. In addition to the consistently better performance of the entropy net with respect to the decision-tree classifier, it is observed that the entropy net is able to achieve its highest performance level in far fewer iterations than commonly required in the nonhierarchical feedforward networks trained using backpropagation. The reason for this lies in the coarse learning achieved during the binary tree development"
            },
            "slug": "Comparison-between-entropy-net-and-decision-tree-Sethi-Otten",
            "title": {
                "fragments": [],
                "text": "Comparison between entropy net and decision tree classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is observed that the entropy net is able to achieve its highest performance level in far fewer iterations than commonly required in the nonhierarchical feedforward networks trained using backpropagation."
            },
            "venue": {
                "fragments": [],
                "text": "1990 IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878706"
                        ],
                        "name": "D. Michie",
                        "slug": "D.-Michie",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Michie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Michie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10622577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad22ad164048191f49a6e23572595b33b6c07546",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "In the last few decades the rise of computing and telecommunications has flooded the worlds of government, business, medicine and engineering with unprecedented volumes of stored data. These databases provide the raw material for information supply but have been largely impenetrable as potential sources of expert knowledge. Computer-oriented techniques can now be used, however, in integration with established methods from classical statistics to generate rulestructured classifiers which not only make a better job of classifying new data sampled from the same source but also possess the quality of clear explanatory structure. New developments in the computer induction of decision rules have contributed to two areas, multivariate data analysis and computer assisted software engineering. Practical connections between the two are thereby coming to light. This paper reviews some of the more significant of these developments."
            },
            "slug": "Methodologies-from-Machine-Learning-in-Data-and-Michie",
            "title": {
                "fragments": [],
                "text": "Methodologies from Machine Learning in Data Analysis and Software"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Computer-oriented techniques can now be used in integration with established methods from classical statistics to generate rulestructured classifiers which not only make a better job of classifying new data sampled from the same source but also possess the quality of clear explanatory structure."
            },
            "venue": {
                "fragments": [],
                "text": "Informatica"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734317"
                        ],
                        "name": "J. Shavlik",
                        "slug": "J.-Shavlik",
                        "structuredName": {
                            "firstName": "Jude",
                            "lastName": "Shavlik",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shavlik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804836"
                        ],
                        "name": "G. Towell",
                        "slug": "G.-Towell",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Towell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Towell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460058"
                        ],
                        "name": "Alan N. Gove",
                        "slug": "Alan-N.-Gove",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Gove",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan N. Gove"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 18
                            }
                        ],
                        "text": "In both measures, Mooney et al. (1989) and Shavlik et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 18
                            }
                        ],
                        "text": "In both measures, Mooney et al. (1989) and Shavlik et al. (1991) and Fisher et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 8
                            }
                        ],
                        "text": "Second, Mooney et al. (1989) and Shavlik et al. (1991) compared similar algorithms on a larger collection of data sets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1076,
                                "start": 8
                            }
                        ],
                        "text": "Second, Mooney et al. (1989) and Shavlik et al. (1991) compared similar algorithms on a larger collection of data sets. There were only three algorithms involved (i.e. ID3, perceptron and back-propagation). Although it is useful to compare the relative performance of a few algorithms, the symbolic learning and neural network fields are rapidly developing; there are many newer algorithms that can also solve classification tasks (for example, CN2 (Clark & Boswell, 1991), C4.5 (Quinlan, 1987b), and radial basis networks (Poggio & Girosi, 1990). Many of these can outperform the algorithms selected here. Thus, they should also be included in a broader evaluation. In both Fisher & McKusick (1989), Mooney et al. (1989) and Shavlik et al. (1991), data sets were separated into a collection of training and test sets. After each system processed a training set its performance, in terms of error rate and training time, was measured on the corresponding test set. The final error rate was the geometric means of separate tests. Mooney et al. (1989) and Shavlik et al. (1991) measured speed differently from Fisher et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 748,
                                "start": 8
                            }
                        ],
                        "text": "Second, Mooney et al. (1989) and Shavlik et al. (1991) compared similar algorithms on a larger collection of data sets. There were only three algorithms involved (i.e. ID3, perceptron and back-propagation). Although it is useful to compare the relative performance of a few algorithms, the symbolic learning and neural network fields are rapidly developing; there are many newer algorithms that can also solve classification tasks (for example, CN2 (Clark & Boswell, 1991), C4.5 (Quinlan, 1987b), and radial basis networks (Poggio & Girosi, 1990). Many of these can outperform the algorithms selected here. Thus, they should also be included in a broader evaluation. In both Fisher & McKusick (1989), Mooney et al. (1989) and Shavlik et al. (1991), data sets were separated into a collection of training and test sets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 18
                            }
                        ],
                        "text": "In both measures, Mooney et al. (1989) and Shavlik et al. (1991) and Fisher et al. (1990) found that back-propagation was significantly slower than ID3."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17368699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "370ff7574ef183203ef3afe05b64bf6bb1d89f37",
            "isKey": true,
            "numCitedBy": 178,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite the fact that many symbolic and connectionist (neural net) learning algorithms are addressing the same problem of learning from classified examples, very little Is known regarding their comparative strengths and weaknesses. This paper presents the results of experiments comparing the ID3 symbolic learning algorithm with the perceptron and back-propagation connectionist learning algorithms on several large real-world data sets. The results show that ID3 and perceptron run significantly faster than does backpropagation, both during learning and during classification of novel examples. However, the probability of correctly classifying new examples is about the same for the three systems. On noisy data sets there is some indication that backpropagation classifies more accurately."
            },
            "slug": "An-Experimental-Comparison-of-Symbolic-and-Learning-Mooney-Shavlik",
            "title": {
                "fragments": [],
                "text": "An Experimental Comparison of Symbolic and Connectionist Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The results show that ID3 and perceptron run significantly faster than does backpropagation, both during learning and during classification of novel examples, however, the probability of correctly classifying new examples is about the same for the three systems."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 73
                            }
                        ],
                        "text": "The calculation is conveniently organised as a back propagation of error (Rumelhart et al., 1986; Rohwer & Renals, 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19357,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3252362"
                        ],
                        "name": "R. Schalkoff",
                        "slug": "R.-Schalkoff",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schalkoff",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schalkoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 33656944,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cea28c8b2d211110b3e48b4c545420282ea68f67",
            "isKey": false,
            "numCitedBy": 1052,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "STATISTICAL PATTERN RECOGNITION (StatPR). Supervised Learning (Training) Using Parametric and Nonparametric Approaches. Linear Discriminant Functions and the Discrete and Binary Feature Cases. Unsupervised Learning and Clustering. SYNTACTIC PATTERN RECOGNITION (SyntPR). Overview. Syntactic Recognition via Parsing and Other Grammars. Graphical Approaches to SyntPR. Learning via Grammatical Inference. NEURAL PATTERN RECOGNITION (NeurPR). Introduction to Neural Networks. Introduction to Neural Pattern Associators and Matrix Approaches. Feedforward Networks and Training by Backpropagation. Content Addressable Memory Approaches and Unsupervised Learning in NeurPR. Appendices. References. Permission Source Notes. Index."
            },
            "slug": "Pattern-recognition-statistical,-structural-and-Schalkoff",
            "title": {
                "fragments": [],
                "text": "Pattern recognition - statistical, structural and neural approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This chapter discusses supervised learning using Parametric and Nonparametric Approaches and unsupervised Learning in NeurPR, and discusses feedforward Networks and Training by Backpropagation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9371603"
                        ],
                        "name": "Jihoon Yang",
                        "slug": "Jihoon-Yang",
                        "structuredName": {
                            "firstName": "Jihoon",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jihoon Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145513516"
                        ],
                        "name": "Vasant G Honavar",
                        "slug": "Vasant-G-Honavar",
                        "structuredName": {
                            "firstName": "Vasant",
                            "lastName": "Honavar",
                            "middleNames": [
                                "G"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vasant G Honavar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12707827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d835be83333f02d07fd207713947ccab864ee401",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A series of experiments with the cascade-correlation algorithm (CCA) and some of its variants on a number of real-world pattern classification tasks are described. Some of the experiments investigated the effect of different design parameters on the performance of the CCA. Parameter settings that consistently yield good performance on different data sets were identified. The performance of the CCA is compared with that of the backpropagation algorithm and the perceptron algorithm. Preliminary results obtained from some variants of CCA and some directions for future work with CCA-like neural network learning methods are discussed.<<ETX>>"
            },
            "slug": "Experiments-with-the-cascade-correlation-algorithm-Yang-Honavar",
            "title": {
                "fragments": [],
                "text": "Experiments with the cascade-correlation algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A series of experiments with the cascade-correlation algorithm (CCA) and some of its variants on a number of real-world pattern classification tasks are described and Parameter settings that consistently yield good performance on different data sets were identified."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] 1991 IEEE International Joint Conference on Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690163"
                        ],
                        "name": "G. McLachlan",
                        "slug": "G.-McLachlan",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "McLachlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. McLachlan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "McLachlan (1992) quotes several empirical studies in which the allocation performance of logistic regression was very similar to that of linear discriminants."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 74
                            }
                        ],
                        "text": "For a proof that they arrive at the same solution, we refer the reader to McLachlan (1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 59
                            }
                        ],
                        "text": "A thorough treatment of statistical procedures is given in McLachlan (1992), who also mentions the more important alternative approaches."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 59
                            }
                        ],
                        "text": "A thorough treatment of statistical procedures is given in McLachlan (1992), who also mentions the more important alternative approaches. A recent text dealing with pattern recognition from a variety of perspectives is Schalkoff (1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14159881,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "20ce95262aa2781c2c3127ca77f18afece3c8f69",
            "isKey": true,
            "numCitedBy": 2626,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a systematic account of the subject area, concentrating on the most recent advances in the field. While the focus is on practical considerations, both theoretical and practical issues are explored. Among the advances covered are: regularized discriminant analysis and bootstrap-based assessment of the performance of a sample-based discriminant rule and extensions of discriminant analysis motivated by problems in statistical image analysis. Includes over 1,200 references in the bibliography."
            },
            "slug": "Discriminant-Analysis-and-Statistical-Pattern-McLachlan",
            "title": {
                "fragments": [],
                "text": "Discriminant Analysis and Statistical Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145652961"
                        ],
                        "name": "L. Xu",
                        "slug": "L.-Xu",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9745969"
                        ],
                        "name": "A. Krzy\u017cak",
                        "slug": "A.-Krzy\u017cak",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Krzy\u017cak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krzy\u017cak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726997"
                        ],
                        "name": "E. Oja",
                        "slug": "E.-Oja",
                        "structuredName": {
                            "firstName": "Erkki",
                            "lastName": "Oja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Oja"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38814255,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e725e9a9d0a193e04be45f33f65f2c10d6b131ba",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A new modification of the subspace pattern recognition method, called the dual subspace pattern recognition (DSPR) method, is proposed, and neural network models combining both constrained Hebbian and anti-Hebbian learning rules are developed for implementing the DSPR method. An experimental comparison is made by using our model and a three-layer forward net with backpropagation learning. The results illustrate that our model can outperform the backpropagation model in suitable applications."
            },
            "slug": "Neural-Nets-for-Dual-Subspace-Pattern-Recognition-Xu-Krzy\u017cak",
            "title": {
                "fragments": [],
                "text": "Neural Nets for Dual Subspace Pattern Recognition Method"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Neural network models combining both constrained Hebbian and anti-Hebbian learning rules are developed for implementing the DSPR method, and it is illustrated that the model can outperform the backpropagation model in suitable applications."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Neural Syst."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119126691"
                        ],
                        "name": "Jack W. Smith",
                        "slug": "Jack-W.-Smith",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Smith",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jack W. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2305118"
                        ],
                        "name": "J. Everhart",
                        "slug": "J.-Everhart",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Everhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Everhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46673474"
                        ],
                        "name": "W. C. Dickson",
                        "slug": "W.-C.-Dickson",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dickson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. C. Dickson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6211003"
                        ],
                        "name": "W. Knowler",
                        "slug": "W.-Knowler",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Knowler",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Knowler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2138536"
                        ],
                        "name": "R. Johannes",
                        "slug": "R.-Johannes",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Johannes",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Johannes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 33
                            }
                        ],
                        "text": "This dataset has been studied by Smith et al. (1988) using the ADAP algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60837618,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8674223cb2a4ff09c7b8d82e3a6ad187cc9008b5",
            "isKey": false,
            "numCitedBy": 680,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract \nNeural networks or connectionist models for parallel processing are not new. However, a resurgence of interest in the past half decade has occurred. In part, this is related to a better understanding of what are now referred to as hidden nodes. These algorithms are considered to be of marked value in pattern recognition problems. Because of that, we tested the ability of an early neural network model, ADAP, to forecast the onset of diabetes mellitus in a high risk population of Pima Indians. The algorithm's performance was analyzed using standard measures for clinical tests: sensitivity, specificity, and a receiver operating characteristic curve. The crossover point for sensitivity and specificity is 0.76. We are currently further examining these methods by comparing the ADAP results with those obtained from logistic regression and linear perceptron models using precisely the same training and forecasting sets. A description of the algorithm is included."
            },
            "slug": "Using-the-ADAP-Learning-Algorithm-to-Forecast-the-Smith-Everhart",
            "title": {
                "fragments": [],
                "text": "Using the ADAP Learning Algorithm to Forecast the Onset of Diabetes Mellitus"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Testing the ability of an early neural network model, ADAP, to forecast the onset of diabetes mellitus in a high risk population of Pima Indians and comparing the results with those obtained from logistic regression and linear perceptron models using precisely the same training and forecasting sets."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47029368"
                        ],
                        "name": "J. Remme",
                        "slug": "J.-Remme",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Remme",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Remme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145217017"
                        ],
                        "name": "J. Habbema",
                        "slug": "J.-Habbema",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Habbema",
                            "middleNames": [
                                "Dik",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Habbema"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066522092"
                        ],
                        "name": "J. Hermans",
                        "slug": "J.-Hermans",
                        "structuredName": {
                            "firstName": "Jo",
                            "lastName": "Hermans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hermans"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123240526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4096fc194edc9dfadcfbce94676f9f114e15b876",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Three discriminant analysis models: linear discriminant analysis, quadratic discriminant analysis and a model using kernel estimation, are compared in a simulation study. Data are generated from multinormal, lognormal and mixtures of distributions. Some measures of performance that are based upon posterior probabilities are used for the comparison. The influence on performance of sample size, dimensionality and distance between populations is investigated. An algorithm to estimate the smoothness parameters for the kernel model is evaluated. Finally some remarks are made with respect to the so-called variable kernel model."
            },
            "slug": "A-simulative-comparison-of-linear,-quadratic-and-Remme-Habbema",
            "title": {
                "fragments": [],
                "text": "A simulative comparison of linear, quadratic and kernel discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Three discriminantAnalysis models: linear discriminant analysis, quadratic discriminant Analysis and a model using kernel estimation, are compared in a simulation study."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700185"
                        ],
                        "name": "S. Weiss",
                        "slug": "S.-Weiss",
                        "structuredName": {
                            "firstName": "Sholom",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285789"
                        ],
                        "name": "C. Kulikowski",
                        "slug": "C.-Kulikowski",
                        "structuredName": {
                            "firstName": "Casimir",
                            "lastName": "Kulikowski",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kulikowski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 190
                            }
                        ],
                        "text": "In the problem of learning graphical representations, it could be said that the statistical community has mainly worked in the direction of building undirected representations: chapter 8 of Whittaker (1990) provides a good survey on selection of undirected graphical representations up to 1990 from the statistical point of view."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12484204,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "664b701a39371c5356754dc72cea1349233c8506",
            "isKey": false,
            "numCitedBy": 1046,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1 Overview of Learning Systems 1.1 What is a Learning System? 1.2 Motivation for Building Learning Systems 1.3 Types of Practical Empirical Learning Systems 1.3.1 Common Theme: The Classification Model 1.3.2 Let the Data Speak 1.4 What's New in Learning Methods 1.4.1 The Impact of New Technology 1.5 Outline of the Book 1.6 Bibliographical and Historical Remarks 2 How to Estimate the True Performance of a Learning System 2.1 The Importance of Unbiased Error Rate Estimation 2.2. What is an Error? 2.2.1 Costs and Risks 2.3 Apparent Error Rate Estimates 2.4 Too Good to Be True: Overspecialization 2.5 True Error Rate Estimation 2.5.1 The Idealized Model for Unlimited Samples 2.5.2 Train-and Test Error Rate Estimation 2.5.3 Resampling Techniques 2.5.4 Finding the Right Complexity Fit 2.6 Getting the Most Out of the Data 2.7 Classifier Complexity and Feature Dimensionality 2.7.1 Expected Patterns of Classifier Behavior 2.8 What Can Go Wrong? 2.8.1 Poor Features, Data Errors, and Mislabeled Classes 2.8.2 Unrepresentative Samples 2.9 How Close to the Truth? 2.10 Common Mistakes in Performance Analysis 2.11 Bibliographical and Historical Remarks 3 Statistical Pattern Recognition 3.1 Introduction and Overview 3.2 A Few Sample Applications 3.3 Bayesian Classifiers 3.3.1 Direct Application of the Bayes Rule 3.4 Linear Discriminants 3.4.1 The Normality Assumption and Discriminant Functions 3.4.2 Logistic Regression 3.5 Nearest Neighbor Methods 3.6 Feature Selection 3.7 Error Rate Analysis 3.8 Bibliographical and Historical Remarks 4 Neural Nets 4.1 Introduction and Overview 4.2 Perceptrons 4.2.1 Least Mean Square Learning Systems 4.2.2 How Good Is a Linear Separation Network? 4.3 Multilayer Neural Networks 4.3.1 Back-Propagation 4.3.2 The Practical Application of Back-Propagation 4.4 Error Rate and Complexity Fit Estimation 4.5 Improving on Standard Back-Propagation 4.6 Bibliographical and Historical Remarks 5 Machine Learning: Easily Understood Decision Rules 5.1 Introduction and Overview 5.2 Decision Trees 5.2.1 Finding the Perfect Tree 5.2.2 The Incredible Shrinking Tree 5.2.3 Limitations of Tree Induction Methods 5.3 Rule Induction 5.3.1 Predictive Value Maximization 5.4 Bibliographical and Historical Remarks 6 Which Technique is Best? 6.1 What's Important in Choosing a Classifier? 6.1.1 Prediction Accuracy 6.1.2 Speed of Learning and Classification 6.1.3 Explanation and Insight 6.2 So, How Do I Choose a Learning System? 6.3 Variations on the Standard Problem 6.3.1 Missing Data 6.3.2 Incremental Learning 6.4 Future Prospects for Improved Learning Methods 6.5 Bibliographical and Historical Remarks 7 Expert Systems 7.1 Introduction and Overview 7.1.1 Why Build Expert Systems? New vs. Old Knowledge 7.2 Estimating Error Rates for Expert Systems 7.3 Complexity of Knowledge Bases 7.3.1 How Many Rules Are Too Many? 7.4 Knowledge Base Example 7.5 Empirical Analysis of Knowledge Bases 7.6 Future: Combined Learning and Expert Systems 7.7 Bibliographical and Historical Remarks References Author Index Subject Index"
            },
            "slug": "Computer-Systems-That-Learn:-Classification-and-and-Weiss-Kulikowski",
            "title": {
                "fragments": [],
                "text": "Computer Systems That Learn: Classification and Prediction Methods from Statistics, Neural Nets, Machine Learning and Expert Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This book discusses how to Estimate the True Performance of a Learning System, and the Importance of Unbiased Error Rate Estimation, and Machine Learning: Easily Understood Decision Rules."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40457765"
                        ],
                        "name": "A. \u00d6zt\u00fcrk",
                        "slug": "A.-\u00d6zt\u00fcrk",
                        "structuredName": {
                            "firstName": "Aydin",
                            "lastName": "\u00d6zt\u00fcrk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. \u00d6zt\u00fcrk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2012633"
                        ],
                        "name": "J. Romeu",
                        "slug": "J.-Romeu",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Romeu",
                            "middleNames": [
                                "Luis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Romeu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122076757,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "61f9e8699a4fe8a30338aa03772d48e5fedd7af2",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A new methodology for assessing distributional assumptions of multivariate data, with graphical applications, is developed. The underlying procedure is based on transforming the multivariate sample into a set of uncorrelated samples and representing the order statistics of each transformed sample by linked vectors in a two dimensional space. The multivariate normality tests are reviewed in detail, the proposed method is described and its properties are discussed."
            },
            "slug": "A-new-method-for-assessing-multivariate-normality-\u00d6zt\u00fcrk-Romeu",
            "title": {
                "fragments": [],
                "text": "A new method for assessing multivariate normality with graphical applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790264"
                        ],
                        "name": "Eduardo Sontag",
                        "slug": "Eduardo-Sontag",
                        "structuredName": {
                            "firstName": "Eduardo",
                            "lastName": "Sontag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eduardo Sontag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 114
                            }
                        ],
                        "text": "These problems are tackled in different ways, for example by using expert systems (Dvorak, 1987), neural networks (Miller et al., 1990; Hunt et al., 1992), fuzzy control (Lee, 1990) and genetic algorithms (Renders & Nordvik, 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 422,
                                "start": 115
                            }
                        ],
                        "text": "These problems are tackled in different ways, for example by using expert systems (Dvorak, 1987), neural networks (Miller et al., 1990; Hunt et al., 1992), fuzzy control (Lee, 1990) and genetic algorithms (Renders & Nordvik, 1992). However, in the absence of a complete review and comparative evaluations, the decision about how to solve a problem at hand remains a difficult task and is often taken ad hoc. Leitch (1992) has introduced a step towards a systematisation that could provide some guidelines."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 742,
                                "start": 115
                            }
                        ],
                        "text": "These problems are tackled in different ways, for example by using expert systems (Dvorak, 1987), neural networks (Miller et al., 1990; Hunt et al., 1992), fuzzy control (Lee, 1990) and genetic algorithms (Renders & Nordvik, 1992). However, in the absence of a complete review and comparative evaluations, the decision about how to solve a problem at hand remains a difficult task and is often taken ad hoc. Leitch (1992) has introduced a step towards a systematisation that could provide some guidelines. However, most of the approaches provide only partial fulfilment of the objectives stated above. Taking into account also increasing complexity of modern systems together with real-time requirements, one must agree with Schoppers (1991), that designing control means looking for a suitable compromise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12704725,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da22a85b3e859139ff4aa40f85597e69ba3ff76d",
            "isKey": true,
            "numCitedBy": 573,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper starts by placing neural net techniques in a general nonlinear control framework. After that, several basic theoretical results on networks are surveyed."
            },
            "slug": "Neural-Networks-for-Control-Sontag",
            "title": {
                "fragments": [],
                "text": "Neural Networks for Control"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This paper starts by placing neural net techniques in a general nonlinear control framework, and several basic theoretical results on networks are surveyed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118570"
                        ],
                        "name": "R. Glendinning",
                        "slug": "R.-Glendinning",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Glendinning",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Glendinning"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 947,
                                "start": 26
                            }
                        ],
                        "text": "The method, originated by Shapiro & Niblett (1982) (see also Shapiro, 1987) assigns the task of attribute-invention to the user, in a manner that partitions the problem into a hierarchy of smaller problems. For each smaller problem a solution tree is separately induced. Structured induction is closely related to the software discipline of \u201cstructured programming\u201d. For large problems the industrial stream of ML work will continue to flow along this human-computer channel. It may for some time remain exceptional for problem complexity to force users to look beyond rule-based ML and multivariate statistics. Because the StatLog ground-rules of comparative trials necessarily barred the user from substantive importation of domain-specific knowledge, structured induction does not figure in this book. But industrially oriented readers may find advantage in studying cases of the method\u2019s successful field use. One such account by Leech (1986) concerned process and quality control in uranium refining."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 26
                            }
                        ],
                        "text": "The method, originated by Shapiro & Niblett (1982) (see also Shapiro, 1987) assigns the task of attribute-invention to the user, in a manner that partitions the problem into a hierarchy of smaller problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 315,
                                "start": 44
                            }
                        ],
                        "text": "CART and PVM), Fisher & McKusick (1989) and Shavlik et al. (1989) indicated that back-propagation did as well or better than ID3. Since these are the most extensive comparisons to date, we describe their findings briefly and detail their limitations in the following two paragraphs. First, Fisher & McKusick (1989) compared the accuracy and learning speed (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 44
                            }
                        ],
                        "text": "CART and PVM), Fisher & McKusick (1989) and Shavlik et al. (1989) indicated that back-propagation did as well or better than ID3."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 108295844,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aae7c875fc7531233c2a3ebefa31a33f1a0d7f49",
            "isKey": true,
            "numCitedBy": 4389,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Representation and Geometry of Multivariate Data. Nonparametric Estimation Criteria. Histograms: Theory and Practice. Frequency Polygons. Averaged Shifted Histograms. Kernel Density Estimators. The Curse of Dimensionality and Dimension Reduction. Nonparametric Regression and Additive Models. Special Topics. Appendices. Indexes."
            },
            "slug": "Multivariate-Density-Estimation,-Theory,-Practice-Glendinning",
            "title": {
                "fragments": [],
                "text": "Multivariate Density Estimation, Theory, Practice and Visualization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421006"
                        ],
                        "name": "R. Michalski",
                        "slug": "R.-Michalski",
                        "structuredName": {
                            "firstName": "Ryszard",
                            "lastName": "Michalski",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Michalski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144657113"
                        ],
                        "name": "J. Larson",
                        "slug": "J.-Larson",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Larson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Larson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61469255,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7f9416444656572bce37a30bc2b2c1d240003fa6",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This work was supported in part by a National Science Foundation Grant NSF MCS 76-22940 and in part by a Senior Visiting Fellowship from British Science Research Council."
            },
            "slug": "Selection-of-Most-Representative-Training-Examples-Michalski-Larson",
            "title": {
                "fragments": [],
                "text": "Selection of Most Representative Training Examples and Incremental Generation of VL1 Hypotheses: The Underlying Methodology and the Description of Programs ESEL and AQ11"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This work was supported in part by a National Science Foundation Grant NSF MCS 76-22940 and by a Senior Visiting Fellowship from British Science Research Council."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421006"
                        ],
                        "name": "R. Michalski",
                        "slug": "R.-Michalski",
                        "structuredName": {
                            "firstName": "Ryszard",
                            "lastName": "Michalski",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Michalski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 72
                            }
                        ],
                        "text": "Interestingly, one of the popular early machine learning algorithms, Aq (Michalski, 1973), had its origins in switching theory."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2298655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20883c0004d6a5eae7fea33e9d4371d8346417b5",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents a set-theoretical definition of the classification problem, and then discusses and illustrates by examples the application of the variable-valued logic system VL. to the synthesis of minimal (or simplest) classification rules under cost (or simplicity) functionals designed by a user from available criteria."
            },
            "slug": "Discovering-Classification-Rules-Using-Logic-System-Michalski",
            "title": {
                "fragments": [],
                "text": "Discovering Classification Rules Using variable-Valued Logic System VL1"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The paper discusses and illustrates by examples the application of the variable-valued logic system VL."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144355808"
                        ],
                        "name": "P. Switzer",
                        "slug": "P.-Switzer",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Switzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Switzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 121818178,
            "fieldsOfStudy": [
                "Mathematics",
                "Environmental Science"
            ],
            "id": "4fbdb54d53564e7ab307b156a788ac13fb2fe2a2",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Linear discriminant analysis is a commonly used statistical tool for the classification of surface features using satellite surface reflectance data. Extensions of this basic tool promise substantial improvements. In particular, we examine the added effectiveness of the integration of spatial autocorrelation into the discriminant model, the resolution of nonhomogeneous pixels, and data based prior probability estimates of class membership."
            },
            "slug": "Extensions-of-linear-discriminant-analysis-for-of-Switzer",
            "title": {
                "fragments": [],
                "text": "Extensions of linear discriminant analysis for statistical classification of remotely sensed satellite imagery"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Extensions of this basic tool promise substantial improvements and this work examines the added effectiveness of the integration of spatial autocorrelation into the discriminant model, the resolution of nonhomogeneous pixels, and data based prior probability estimates of class membership."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34244678"
                        ],
                        "name": "H. Verbruggen",
                        "slug": "H.-Verbruggen",
                        "structuredName": {
                            "firstName": "Henk",
                            "lastName": "Verbruggen",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Verbruggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2746471"
                        ],
                        "name": "K. \u00c5str\u00f6m",
                        "slug": "K.-\u00c5str\u00f6m",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "\u00c5str\u00f6m",
                            "middleNames": [
                                "Johan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. \u00c5str\u00f6m"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 110
                            }
                        ],
                        "text": "The emphasis in controller design has shifted from the precision requirements towards the following objectives(Leitch & Francis, 1986; Enterline, 1988; Verbruggen and \u00c5str\u0151m, 1989; \u00c5str\u0151m, 1991; Sammut & Michie, 1991; AIRTC92, 1992): control without complete prior knowledge (to extend the range of automatic control applications), reliability, robustness and adaptivity (to provide successful performance in the realworld environment), transparency of solutions (to enable understanding and verification), generality (to facilitate the transfer of solutions to similar problems), realisation of specified characteristics of system response (to please customers)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62752718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9bfa5fa84c21da72066c6c963f929d6712390d9",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ARTIFICIAL-INTELLIGENCE-AND-FEEDBACK-CONTROL-Verbruggen-\u00c5str\u00f6m",
            "title": {
                "fragments": [],
                "text": "ARTIFICIAL INTELLIGENCE AND FEEDBACK CONTROL"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118180516"
                        ],
                        "name": "F. M. Silva",
                        "slug": "F.-M.-Silva",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Silva",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. M. Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068289963"
                        ],
                        "name": "L. B. Almeida",
                        "slug": "L.-B.-Almeida",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Almeida",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. B. Almeida"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30453139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a546f8798597fd2acbad81a9da358f1d11a0ad75",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Like other gradient descent techniques, backpropagation converges slowly, even for medium sized network problems. This fact results from the usually large dimension of the weight space and from the particular shape of the error surface in each iteration point. Oscillation between the sides of deep and narrow valleys, for example, is a well known case where gradient descent provides poor convergence rates."
            },
            "slug": "Acceleration-Techniques-for-the-Backpropagation-Silva-Almeida",
            "title": {
                "fragments": [],
                "text": "Acceleration Techniques for the Backpropagation Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Backpropagation converges slowly, even for medium sized network problems, because of the usually large dimension of the weight space and from the particular shape of the error surface in each iteration point."
            },
            "venue": {
                "fragments": [],
                "text": "EURASIP Workshop"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742419"
                        ],
                        "name": "D. Titterington",
                        "slug": "D.-Titterington",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Titterington",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Titterington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145615522"
                        ],
                        "name": "G. D. Murray",
                        "slug": "G.-D.-Murray",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Murray",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. D. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077428528"
                        ],
                        "name": "L. Murray",
                        "slug": "L.-Murray",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Murray",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144433605"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079543026"
                        ],
                        "name": "A. Skene",
                        "slug": "A.-Skene",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Skene",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Skene"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145217017"
                        ],
                        "name": "J. Habbema",
                        "slug": "J.-Habbema",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Habbema",
                            "middleNames": [
                                "Dik",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Habbema"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8302174"
                        ],
                        "name": "G. Gelpke",
                        "slug": "G.-Gelpke",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Gelpke",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gelpke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Titterington et al. (1981) compared several discrimination procedures on this data."
                    },
                    "intents": []
                }
            ],
            "corpusId": 86399946,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "d7b811758bf6de6923d9b8363f5afd155a26e8a1",
            "isKey": false,
            "numCitedBy": 304,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Several techniques for discriminant analysis are applied to a set of data from patients with severe head injuries, for the purpose of prognosis. The data are such that multidimensionality, continuous, binary and ordered categorical variables and missing data must be coped with. The various methods are compared using criteria of prognostic success and reliability. In general, performance varies more with choice of the set of predictor variables than with that of the discriminant rule."
            },
            "slug": "Comparison-of-Discrimination-Techniques-Applied-to-Titterington-Murray",
            "title": {
                "fragments": [],
                "text": "Comparison of Discrimination Techniques Applied to a Complex Data Set of Head Injured Patients"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "In this work, several techniques for discriminant analysis are applied to a set of data from patients with severe head injuries, for the purpose of prognosis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116274497"
                        ],
                        "name": "J. H. V. Stein",
                        "slug": "J.-H.-V.-Stein",
                        "structuredName": {
                            "firstName": "Johann",
                            "lastName": "Stein",
                            "middleNames": [
                                "Heinrich",
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. V. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058448969"
                        ],
                        "name": "Werner Ziegler",
                        "slug": "Werner-Ziegler",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Ziegler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Werner Ziegler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 153827790,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "d321a9907cb02b782098586c65d5098e76914d17",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-prognosis-and-surveillance-of-risks-from-credit-Stein-Ziegler",
            "title": {
                "fragments": [],
                "text": "The prognosis and surveillance of risks from commercial credit borrowers"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067083222"
                        ],
                        "name": "Sidney Marks",
                        "slug": "Sidney-Marks",
                        "structuredName": {
                            "firstName": "Sidney",
                            "lastName": "Marks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sidney Marks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102093452"
                        ],
                        "name": "O. J. Dunn",
                        "slug": "O.-J.-Dunn",
                        "structuredName": {
                            "firstName": "Olive",
                            "lastName": "Dunn",
                            "middleNames": [
                                "Jean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. J. Dunn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120962818,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7c73ac95a4c164165435d539d46e120c84d4152a",
            "isKey": false,
            "numCitedBy": 208,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract This study compares by Monte Carlo methods the performance of three discriminant functions in classifying individuals into two multivariate normally distributed populations when covariance matrices are unequal\u2014the quadratic, best linear and Fisher's linear discriminant function. The comparison is carried out both asymptotically and using samples. The expected value of the probabilities is used as the measure of performance. Parameters that are varied in the study include the distance between the populations, covariance matrices, number of dimensions, samples size and a priori probabilities of origin from the populations."
            },
            "slug": "Discriminant-Functions-When-Covariance-Matrices-are-Marks-Dunn",
            "title": {
                "fragments": [],
                "text": "Discriminant Functions When Covariance Matrices are Unequal"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109174810"
                        ],
                        "name": "Jian-Xiong Wu",
                        "slug": "Jian-Xiong-Wu",
                        "structuredName": {
                            "firstName": "Jian-Xiong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian-Xiong Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39497278"
                        ],
                        "name": "Chorkin Chan",
                        "slug": "Chorkin-Chan",
                        "structuredName": {
                            "firstName": "Chorkin",
                            "lastName": "Chan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chorkin Chan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35046431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc98e89829ee58ff40acaa17b36107090658e94e",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Based on the assumption that most probability densities in real life can be approximated by a mixture of Gaussian densities, we propose here a three-layer adaptive network with each neuron in the lower hidden layer representing a Gaussian basis function (covariance matrix equal to where I is a unit matrix) to estimate various probability densities and serve as a Bayes classifier. The width of the basis function may be the same for all neurons in this layer or it may vary from one neuron to another. This paper investigates the effectiveness of the network for both cases and presents a localized learning algorithm to adjust the network parameters. The network was trained with artificial data derived from known mixtures of memoryless Gaussian sources as well as exponential and Gamma densities. The performance of the network as a pattern density estimator was measured in terms of the relative difference between the target probability density function (p.d.f.) which generates the training and testing data and the network output representing the estimation. Samples from two mixtures corresponding to two classes were used to test the network capability as a classifier by comparing its error rate against that of a Bayes classifier. Both one- and two-dimensional cases were explored. The successfulness of the network depended on how well the target p.d.f.\u2019s were represented by the training samples, the number of hidden neurons employed in the network and how thoroughly the network was trained. It was also found that allowing each basis function to have an independent width had a predominant effect on the network performance."
            },
            "slug": "A-Three-Layer-Adaptive-Network-for-Pattern-Density-Wu-Chan",
            "title": {
                "fragments": [],
                "text": "A Three-Layer Adaptive Network for Pattern Density Estimation and Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A three-layer adaptive network with each neuron in the lower hidden layer representing a Gaussian basis function to estimate various probability densities and serve as a Bayes classifier is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Neural Syst."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 188
                            }
                        ],
                        "text": "A compromise is to use decision tree induction to build an initial tree and then derive rules from the tree thus transforming an efficient but opaque representation into a transparent one (Quinlan, 1987b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 2
                            }
                        ],
                        "text": "5 (Quinlan, 1987b), and radial basis networks (Poggio & Girosi, 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1280035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea4bdeb0ba42ed22c85290528372941678680755",
            "isKey": false,
            "numCitedBy": 579,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Many inductive knowledge acquisition algorithms generate classifiers in the form of decision trees. This paper describes a technique for transforming such trees to small sets of production rules, a common formalism for expressing knowledge in expert systems. The method makes use of the training set of cases from which the decision tree was generated, first to generalize and assess the reliability of individual rules extracted from the tree, and subsequently to refine the collection of rules as a whole. The final set of production rules is usually both simpler than the decision tree from which it was obtained, and more accurate when classifying unseen cases. Transformation to production rules also provides a way of combining different decision trees for the same classification domain."
            },
            "slug": "Generating-Production-Rules-from-Decision-Trees-Quinlan",
            "title": {
                "fragments": [],
                "text": "Generating Production Rules from Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper describes a technique for transforming such trees to small sets of production rules, a common formalism for expressing knowledge in expert systems, and provides a way of combining different decision trees for the same classification domain."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29272733"
                        ],
                        "name": "P. D. Wasserman",
                        "slug": "P.-D.-Wasserman",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Wasserman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Wasserman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 349,
                                "start": 10
                            }
                        ],
                        "text": "(1991) or Wasserman (1989). Linear discriminants were introduced by Fisher (1936), as a statistical procedure for classification. Here the space of attributes can be partitioned by a set of hyperplanes, each defined by a linear combination of the attribute variables. A similar model for logical processing was suggested by McCulloch & Pitts (1943) as a possible structure bearing similarities to neurons in the human brain, and they demonstrated that the model could be used to build any finite logical expression."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 10
                            }
                        ],
                        "text": "(1991) or Wasserman (1989). Linear discriminants were introduced by Fisher (1936), as a statistical procedure for classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5047843,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "c6de447f45d4e2340cca01321a280ba9784ae869",
            "isKey": false,
            "numCitedBy": 1846,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In what case do you like reading so much? What about the type of the neural computing theory and practice book? The needs to read? Well, everybody has their own reason why should read some books. Mostly, it will relate to their necessity to get knowledge from the book and want to read just to get entertainment. Novels, story book, and other entertaining books become so popular this day. Besides, the scientific books will also be the best reason to choose, especially for the students, teachers, doctors, businessman, and other professions who are fond of reading."
            },
            "slug": "Neural-computing-theory-and-practice-Wasserman",
            "title": {
                "fragments": [],
                "text": "Neural computing - theory and practice"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The neural computing theory and practice book will be the best reason to choose, especially for the students, teachers, doctors, businessman, and other professions who are fond of reading."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2236752"
                        ],
                        "name": "R. Todeschini",
                        "slug": "R.-Todeschini",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Todeschini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Todeschini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 93
                            }
                        ],
                        "text": "A study on the influence of data transformation and metrics on the k-NN rule can be found in Todeschini (1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122888424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab69e08d7dc235cbb3676622738de59a250005eb",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "k-nearest-neighbour-method:-The-influence-of-data-Todeschini",
            "title": {
                "fragments": [],
                "text": "k-nearest neighbour method: The influence of data transformations and metrics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145949276"
                        ],
                        "name": "V. Srinivasan",
                        "slug": "V.-Srinivasan",
                        "structuredName": {
                            "firstName": "Venkat",
                            "lastName": "Srinivasan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Srinivasan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108446999"
                        ],
                        "name": "Yong H. Kim",
                        "slug": "Yong-H.-Kim",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Kim",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong H. Kim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 35
                            }
                        ],
                        "text": "This was followed by Hunt, Marin & Stone\u2019s (1966) CLS."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 154912387,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "46613841f51168a1c989abaaa929779afc498307",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Financial classification issues, and particularly the financial distress problem, continue to be subject to vigorous investigation. The corporate credit granting process has not received as much attention in the literature. This paper examines the relative effectiveness of parametric, nonparametric and judgemental classification procedures on a sample of corporate credit data. The judgemental model is based on the Analytic Hierarchy Process. Evidence indicates that (nonparametric) recursive partitioning methods provide greater information than simultaneous partitioning procedures. The judgemental model is found to perform as well as statistical models. A complementary relationship is proposed between the statistical and the judgemental models as an effective paradigm for granting credit. THE CREDIT GRANTING process involves a tradeoff between the perceived default risk of the credit applicant and potential returns from granting requested credit. The main objective in credit granting is to determine the optimal amount of credit to grant. The amount of credit requested along with other financial and nonfinancial factors influences the assessment of default risk. While default risk assessment can be appropriately modeled using classificatory models, integration of such risk assessment with potential returns can be accomplished using a dynamic expected value framework.' Academic research on credit granting can be grouped into two basic categories:2 (i) attempts to apply classification procedures to customer attribute data and develop classification models to assign group membership in the future; and (ii) attempts to explicitly recognize the need to integrate such risk assessment with potential return as well as allow for differing degrees of credit investigation depending on the costs of such investigation. To our knowledge, this study represents the first attempt at examining the relative performance of classification procedures for corporate credit granting. Relative performance is measured in terms of how well the models replicate expert judgement. We examine four statistical models: multiple discriminant analysis (MDA), logistic regression * Northeastern University and University of Cincinnati, respectively. We are grateful to Robert Eisenbeis and Sangit Chatterjee for their insightful comments on an earlier draft. We also thank an anonymous Fortune 500 corporation as well as the Credit Research Foundation for their support. The usual disclaimer applies. 1 This paper is primarily concerned with the credit granting decision in an industrial (nonfinancial) setting. A more detailed version of this paper is available from the authors. Further, for a review of the various motives for corporations to extend credit, refer Emery [10]. 2 We do not make any attempts to present a comprehensive review of the literature. Interested readers are referred to an excellent review by Altman et al. [1]."
            },
            "slug": "Credit-Granting:-A-Comparative-Analysis-of-Srinivasan-Kim",
            "title": {
                "fragments": [],
                "text": "Credit Granting: A Comparative Analysis of Classification Procedures"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118148995"
                        ],
                        "name": "Patricia L. Smith",
                        "slug": "Patricia-L.-Smith",
                        "structuredName": {
                            "firstName": "Patricia",
                            "lastName": "Smith",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patricia L. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 121
                            }
                        ],
                        "text": "A simple and effective strategy for automatically selecting both the number and locations for the knots was described by Smith(1982), who suggested using the truncated power basis in a numerical minimisation of the least squares criterion \u00fc N ! ] Z\\ \u00e2 ! \u009d N A ] 4 A A _ N7 ] pM7M2 }L7 5 \u009d` ]^ (4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 142
                            }
                        ],
                        "text": "In such circumstances the credit-granting company may well adopt the default strategy for the sake of good customer relations \u2013see Lawrence & Smith (1992). However, most decision tree algorithms do worse than the default if they are allowed to train on the given data which is strongly biased towards bad credits (typically decision tree algorithms have an error rate of around 6% error rate)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 72
                            }
                        ],
                        "text": "It is also important to assess the determinants of the risk: Lawrence & Smith (1992) state that payment history is the overwhelming factor in predicting the likelihood of default in mobile home credit cases."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60333516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c91791a74e1cada48aa85e1c1aa0b05eb4df044a",
            "isKey": true,
            "numCitedBy": 54,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The successful application of statistical variable selection techniques to fit splines is demonstrated. Major emphasis is given to knot selection, but order determination is also discussed. Two FORTRAN backward elimination programs, using the B-spline basis, were developed. The program for knot elimination is compared in detail with two other spline-fitting methods and several statistical software packages. An example is also given for the two-variable case using a tensor product basis, with a theoretical discussion of the difficulties of their use."
            },
            "slug": "Curve-fitting-and-modeling-with-splines-using-Smith",
            "title": {
                "fragments": [],
                "text": "Curve fitting and modeling with splines using statistical variable selection techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The successful application of statistical variable selection techniques to fit splines to solve knot elimination problems and is compared in detail with two other spline-fitting methods and several statistical software packages."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32980796"
                        ],
                        "name": "Sreerama K. Murthy",
                        "slug": "Sreerama-K.-Murthy",
                        "structuredName": {
                            "firstName": "Sreerama",
                            "lastName": "Murthy",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sreerama K. Murthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689332"
                        ],
                        "name": "S. Kasif",
                        "slug": "S.-Kasif",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Kasif",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kasif"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744109"
                        ],
                        "name": "S. Salzberg",
                        "slug": "S.-Salzberg",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Salzberg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Salzberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 202
                            }
                        ],
                        "text": "\u2026suggest Polynomial Networks (Farlow, 1984; Elder & Brown, 1994), Multivariate Adaptive Regression Splines (MARS), Generalized Additive Models (Hastie & Tibshirani, 1990), multilinear trees (e.g., OC1; Murthy et al., 1994), and piecewise methods such as Constrained Topological Maps (Mulier, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 62
                            }
                        ],
                        "text": "To\n3 investigate the relation between algorithm performance and type of dataset, several dataset features were calculated."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 200
                            }
                        ],
                        "text": "I'd suggest Polynomial Networks (Farlow, 1984; Elder & Brown, 1994), Multivariate Adaptive Regression Splines (MARS), Generalized Additive Models (Hastie & Tibshirani, 1990), multilinear trees (e.g., OC1; Murthy et al., 1994), and piecewise methods such as Constrained Topological Maps (Mulier, 1994)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11407469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fad1ee8b6ed596f72b81f61f01def620a4ee997",
            "isKey": false,
            "numCitedBy": 923,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes a new system for induction of oblique decision trees. This system, OC1, combines deterministic hill-climbing with two forms of randomization to find a good oblique split (in the form of a hyperplane) at each node of a decision tree. Oblique decision tree methods are tuned especially for domains in which the attributes are numeric, although they can be adapted to symbolic or mixed symbolic/numeric attributes. We present extensive empirical studies, using both real and artificial data, that analyze OC1's ability to construct oblique trees that are smaller and more accurate than their axis-parallel counterparts. We also examine the benefits of randomization for the construction of oblique decision trees."
            },
            "slug": "A-System-for-Induction-of-Oblique-Decision-Trees-Murthy-Kasif",
            "title": {
                "fragments": [],
                "text": "A System for Induction of Oblique Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This system, OC1, combines deterministic hill-climbing with two forms of randomization to find a good oblique split (in the form of a hyperplane) at each node of a decision tree."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34915378"
                        ],
                        "name": "R. Rohwer",
                        "slug": "R.-Rohwer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rohwer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rohwer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721235"
                        ],
                        "name": "F. Murtagh",
                        "slug": "F.-Murtagh",
                        "structuredName": {
                            "firstName": "Fionn",
                            "lastName": "Murtagh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Murtagh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60202933,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74085b319b4fc3e62a1f2d65b33aded195c68151",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reviews some basic issues and methods involved in using neural networks to respond in a desired fashion to a temporally-varying environment. Some popular network models and training methods are introduced. A speech recognition example is then used to illustrate the central difficulty of temporal data processing: learning to notice and remember relevant contextual information. Feedforward network methods are applicable to cases where this problem is not severe. The application of these methods are explained and applications are discussed in the areas of pure mathematics, chemical and physical systems, and economic systems. A more powerful but less practical algorithm for temporal problems, the moving targets algorithm, is sketched and discussed. For completeness, a few remarks are made on reinforcement learning."
            },
            "slug": "Neural-networks-for-time-varying-data-Rohwer-Murtagh",
            "title": {
                "fragments": [],
                "text": "Neural networks for time-varying data"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper reviews some basic issues and methods involved in using neural networks to respond in a desired fashion to a temporally-varying environment and some popular network models and training methods are introduced."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14892653,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "089a76dbc62a06ad30ae1925530e8733e850268e",
            "isKey": false,
            "numCitedBy": 3701,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of the approximation of nonlinear mapping, (especially continuous mappings) is considered. Regularization theory and a theoretical framework for approximation (based on regularization techniques) that leads to a class of three-layer networks called regularization networks are discussed. Regularization networks are mathematically related to the radial basis functions, mainly used for strict interpolation tasks. Learning as approximation and learning as hypersurface reconstruction are discussed. Two extensions of the regularization approach are presented, along with the approach's corrections to splines, regularization, Bayes formulation, and clustering. The theory of regularization networks is generalized to a formulation that includes task-dependent clustering and dimensionality reduction. Applications of regularization networks are discussed. >"
            },
            "slug": "Networks-for-approximation-and-learning-Poggio-Girosi",
            "title": {
                "fragments": [],
                "text": "Networks for approximation and learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815804"
                        ],
                        "name": "F. Mulier",
                        "slug": "F.-Mulier",
                        "structuredName": {
                            "firstName": "Filip",
                            "lastName": "Mulier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Mulier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145884505"
                        ],
                        "name": "V. Cherkassky",
                        "slug": "V.-Cherkassky",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Cherkassky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cherkassky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 284
                            }
                        ],
                        "text": "\u2026suggest Polynomial Networks (Farlow, 1984; Elder & Brown, 1994), Multivariate Adaptive Regression Splines (MARS), Generalized Additive Models (Hastie & Tibshirani, 1990), multilinear trees (e.g., OC1; Murthy et al., 1994), and piecewise methods such as Constrained Topological Maps (Mulier, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 257
                            }
                        ],
                        "text": "I'd suggest Polynomial Networks (Farlow, 1984; Elder & Brown, 1994), Multivariate Adaptive Regression Splines (MARS), Generalized Additive Models (Hastie & Tibshirani, 1990), multilinear trees (e.g., OC1; Murthy et al., 1994), and piecewise methods such as Constrained Topological Maps (Mulier, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 21
                            }
                        ],
                        "text": "These ranged from simple counts of cases and attributes, to statistical measures, such as tests for homogeneity of covariances and collinearity of the class means, and also included \"yardstick\" results from the simplest statistical classification methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2469687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b0c40e2f3f6f894909efba85b82db9c923c7edb",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-analysis-of-self-organization-Mulier-Cherkassky",
            "title": {
                "fragments": [],
                "text": "Statistical analysis of self-organization"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1875265"
                        ],
                        "name": "Robert S. Scalero",
                        "slug": "Robert-S.-Scalero",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Scalero",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert S. Scalero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2770900"
                        ],
                        "name": "N. Tepedelenlioglu",
                        "slug": "N.-Tepedelenlioglu",
                        "structuredName": {
                            "firstName": "Nazif",
                            "lastName": "Tepedelenlioglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Tepedelenlioglu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 103
                            }
                        ],
                        "text": "One example of the application of neural networks to solving the credit scoring problem is reported in Schumann et al. (1992). Michie (1989) reports a case where the aim of the credit-granting procedure was to keep the bad debt rate among those granted credit down to 9%."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30625381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "296b1e2883c97d259bf92ed0765d4e2cdf9ddc4f",
            "isKey": false,
            "numCitedBy": 230,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A fast new algorithm is presented for training multilayer perceptrons as an alternative to the back-propagation algorithm. This new algorithm reduces the required training time considerably and overcomes many of the shortcomings presented by the conventional back-propagation algorithm. \nThe new algorithm shortens the training time by several orders of magnitude for the pattern recognition type considered. In some cases improvement ratios of the new algorithm over the back-propagation algorithm run higher than 10,000, and it is not unlikely that this number may be further increased by considering patterns with higher resolution (more pixels per pattern). \nThe new algorithm can also be implemented in a parallel architecture. One processor handles the network processing and the calculation of the modified back-propagation error signals, while the other processor handles the Kalman filter calculations. \nAside from the speed advantage, the new algorithm is also more predictable in its training. The algorithm makes steady progress toward improving the mean squared error. In contrast, the back-propagation algorithm tends to reach a certain mean squared error and remain there for many iterations making little or no progress. At some point, it either rapidly converges, or jumps to a new level where it would again make little or no progress for many iterations. \nThe convergence of the back-propagation algorithm depends heavily on the magnitude of the initial weights. If chosen incorrectly, the algorithm takes a long time to converge. The new algorithm on the other hand is much less sensitive to the initial weight setting. \nFurthermore, the adaptive nature of the Kalman gain makes the new algorithm much less likely to get caught in a state other than the global minimum. \nThe new algorithm is much faster and more reliable than the back-propagation algorithm. It is very consistent in its training and is much less sensitive to the initial weight settings than the back-propagation algorithm. In every aspect the new algorithm outperforms the back-propagation algorithm for training multilayer perceptrons. (Abstract shortened with permission of author.)"
            },
            "slug": "A-fast-new-algorithm-for-training-feedforward-Scalero-Tepedelenlioglu",
            "title": {
                "fragments": [],
                "text": "A fast new algorithm for training feedforward neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A fast new algorithm is presented for training multilayer perceptrons as an alternative to the back-propagation algorithm that reduces the required training time considerably and overcomes many of the shortcomings presented by the conventional back- Propagation algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403768028"
                        ],
                        "name": "IV JohnF.Elder",
                        "slug": "IV-JohnF.Elder",
                        "structuredName": {
                            "firstName": "IV",
                            "lastName": "JohnF.Elder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "IV JohnF.Elder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3027365"
                        ],
                        "name": "D. Pregibon",
                        "slug": "D.-Pregibon",
                        "structuredName": {
                            "firstName": "Daryl",
                            "lastName": "Pregibon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pregibon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 103
                            }
                        ],
                        "text": "The book grew out of the European StatLog project, in which a team of 6 University and 6 Industrial research groups performed a controlled evaluation of a score of procedures on as many example datasets \"to determine to what extent the various techniques met the needs of industry\" (p. 4)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3036588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50fcc55a731e3dd94dad5134294185e8b9825b3e",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "The quest to nd models usefully characterizing data is a process central to the scientiic method, and has been carried out on many fronts. Researchers from an expanding number of elds have designed algorithms to discover rules or equations that capture key relationships between variables in a database. The task of this chapter is to provide a perspective on statistical techniques applicable to KDD; accordingly, we review below some major advances in statistics in the last few decades. We next highlight some distinctives of what may be called a \\statistical viewpoint.\" Finally we overview some innuential classical and modern statistical methods for practical model induction. It would be unfortunate if the KDD community dismissed statistical methods on the basis of courses that they took on statistics several to many years ago. The following provides a rough chronology of \\recent\" signiicant contributions in statistics that are relevant to the KDD community. The noteworthy fact is that this time period coincides with the signiicant increases in computing horsepower and memory, powerful and expressive programming languages, and general accessibility to computing that has propelled us into"
            },
            "slug": "A-Statistical-Perspective-on-Knowledge-Discovery-in-JohnF.Elder-Pregibon",
            "title": {
                "fragments": [],
                "text": "A Statistical Perspective on Knowledge Discovery in Databases"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The task of this chapter is to provide a perspective on statistical techniques applicable to KDD, and below some major advances in statistics in the last few decades are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Knowledge Discovery and Data Mining"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2172770680"
                        ],
                        "name": "N. L. Johnson",
                        "slug": "N.-L.-Johnson",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Johnson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. L. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4206943,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "182f77976b08d832b5cdc7debdaeacc300c8e723",
            "isKey": false,
            "numCitedBy": 5733,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An Introduction to Multivariate Statistical AnalysisBy Prof. T. W. Anderson. (Wiley Publications in Mathematical Statistics.) Pp. xii + 374. (New York: John Wiley and Sons, Inc.; London: Chapman and Hall, Ltd., 1958.) 100s. net.Some Aspects of Multivariate AnalysisBy Prof. S. N. Roy. (Indian Statistical Series, No. 1.) Pp. viii + 214. (New York: John Wiley and Sons, Inc.; Calcutta: Indian Statistical Institute; London: Chapman and Hall, Ltd., 1957.) 64s. net.The Analysis of Multiple Time-SeriesBy M. H. Quenouille. (Griffin's Statistical Monographs and Courses, No. 1.) Pp. 105. (London: Charles Griffin and Co., Ltd., 1957.) 24s."
            },
            "slug": "Multivariate-Analysis-Johnson",
            "title": {
                "fragments": [],
                "text": "Multivariate Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804253"
                        ],
                        "name": "C. Sammut",
                        "slug": "C.-Sammut",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Sammut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sammut"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 42
                            }
                        ],
                        "text": "It is interesting to note the comments of Sammut et al. (1992) regarding the contents of the induced rules:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 47
                            }
                        ],
                        "text": "After some initial experiments we found, as in Sammut et al. (1992), that it was beneficial to use different trials performed by the same student, since it was practically impossible to find trials perfect in all aspects even among the successful cases."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Sammut et al. (1992) stated that it remains debatable what a really appropriate delay is between the state of the plane variables and control action invoked by that state:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26434801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcf7af8dd646e5519ae28f79133f786833bbf043",
            "isKey": true,
            "numCitedBy": 38,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Experimental-Results-from-an-Evaluation-of-that-to-Sammut",
            "title": {
                "fragments": [],
                "text": "Experimental Results from an Evaluation of Algorithms that Learn to Control Dynamic Systems"
            },
            "venue": {
                "fragments": [],
                "text": "ML"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6050918"
                        ],
                        "name": "J. Elder",
                        "slug": "J.-Elder",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Elder",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2171909383"
                        ],
                        "name": "D.E. Brown",
                        "slug": "D.E.-Brown",
                        "structuredName": {
                            "firstName": "D.E.",
                            "lastName": "Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D.E. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61651363,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2025098906962a267a76349dabc37cb2ed9a5b15",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 170,
            "paperAbstract": {
                "fragments": [],
                "text": "Induction plays a major role in a wide variety of application domains. Because of this broad range of applicability a variety of approaches have been suggested and employed to discover general models from data. A key goal in these approaches is to perform well on data not seen during the model construction process. This paper surveys the variety of techniques available for induction and categorizes them by their degree of automation. The authors then examine in more detail polynomial networks which are induction methods that grew out of cybernetics and early neural network research. The authors conclude the paper with suggested directions for continued work in polynomial networks."
            },
            "slug": "Induction-and-polynomial-networks-Elder-Brown",
            "title": {
                "fragments": [],
                "text": "Induction and polynomial networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper surveys the variety of techniques available for induction and categorizes them by their degree of automation and examines in more detail polynomial networks, which are induction methods that grew out of cybernetics and early neural network research."
            },
            "venue": {
                "fragments": [],
                "text": "1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34915378"
                        ],
                        "name": "R. Rohwer",
                        "slug": "R.-Rohwer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rohwer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rohwer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 80
                            }
                        ],
                        "text": "Reports on benchmark excercises are available for some of these MLP programs in Rohwer (1991c). The centres for the radial basis functions were selected randomly from the training data, except that centres were allocated to each class in proportion to the number of representatives of that class in the dataset, with at least one centre provided to each class in any case."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1709501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33fcc09d5b8fe77f7abe926ffb39e9687f361326",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of a radial basis functions network to a static speech pattern classification problem is described. The radial basis functions network offers training times two to three orders of magnitude faster than backpropagation, when training networks of similar power and generality. Recognition results compare well with those obtained using backpropagation and a vector-quantized hidden Markov model on the same problem. A computationally efficient method of exactly solving linear networks in a noniterative fashion is also described. The method was applied to classification of vowels into 20 classes using three different types of input analysis and varying numbers of radial basis functions. The three types of input vectors consisted of linear-prediction-coding cepstral coefficient; formant tracks with frequency, amplitude, and bandwidth information; and bark-scaled formant tracks. All input analyses were supplemented with duration information. The best test results were obtained using the cepstral coefficients and 170 or more radial basis functions.<<ETX>>"
            },
            "slug": "Phoneme-classification-experiments-using-radial-Renals-Rohwer",
            "title": {
                "fragments": [],
                "text": "Phoneme classification experiments using radial basis functions"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The application of a radial basis functions network to a static speech pattern classification problem is described and recognition results compare well with those obtained using backpropagation and a vector-quantized hidden Markov model on the same problem."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34915378"
                        ],
                        "name": "R. Rohwer",
                        "slug": "R.-Rohwer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rohwer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rohwer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 75
                            }
                        ],
                        "text": "Experimental comparisons between RAMnets and other methods can be found in Rohwer & Cressy (1989) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115232018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3a4e2575ad1ece356f52846a0e1cbd0d4458157",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Attractor properties of a popular discrete-time neural network model are illustrated through numerical simulations. The most complex dynamics is found to occur within particular ranges of parameters controlling the symmetry and magnitude of the weight matrix. A small network model is observed to produce fixed points, limit cycles, mode-locking, the Ruelle-Takens route to chaos, and the period-doubling route to chaos. Training algorithms for tuning this dynamical behaviour are discussed. Training can be an easy or difficult task, depending whether the problem requires the use of temporal information distributed over long time intervals. Such problems require training algorithms which can handle hidden nodes. The most prominent of these algorithms, back propagation through time, solves the temporal credit assignment problem in a way which can work only if the relevant information is distributed locally in time. The Moving Targets algorithm works for the more general case, but is computationally intensive, and prone to local minima."
            },
            "slug": "Description-and-training-of-neural-network-dynamics-Rohwer",
            "title": {
                "fragments": [],
                "text": "Description and training of neural network dynamics"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Attractor properties of a popular discrete-time neural network model are illustrated through numerical simulations, and the most complex dynamics is found to occur within particular ranges of parameters controlling the symmetry and magnitude of the weight matrix."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145468098"
                        ],
                        "name": "M. M\u00f8ller",
                        "slug": "M.-M\u00f8ller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "M\u00f8ller",
                            "middleNames": [
                                "Fodslette"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. M\u00f8ller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 50
                            }
                        ],
                        "text": "There is some work on finding a compromise method (M\u00f8ller, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8029054,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f4a097b2131784d7ac3fc3c47d1e9283e9ac207",
            "isKey": false,
            "numCitedBy": 3758,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-scaled-conjugate-gradient-algorithm-for-fast-M\u00f8ller",
            "title": {
                "fragments": [],
                "text": "A scaled conjugate gradient algorithm for fast supervised learning"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47719614"
                        ],
                        "name": "J. Piper",
                        "slug": "J.-Piper",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Piper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Piper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700008"
                        ],
                        "name": "E. Granum",
                        "slug": "E.-Granum",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Granum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Granum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 36593830,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "20e7b8b56b119e1e84041c9bee77e2251a73ab69",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Procedures for fully automatic location of chromosome axis and centromere in metaphase chromosomes are described for a practical interactive chromosome analysis system that omits the usual stages of interactive axis and centromere correction. Accuracy of centromere finding and consequential determination of a chromosome's polarity, i.e., which end is which, is measured experimentally. The saving in interaction by not correcting centromeres is compared to the increase in errors at the classification stage and the consequent increase in interaction needed to correct these errors. Some previously unreported features for banded chromosome classification are described, and in particular a set of global shape features is introduced. The discrimination capability of the feature measurements is evaluated by use of simple statistics and by reference to the performance of classifiers trained with various feature subsets. Class discrimination capability of the global shape feature set is shown to be comparable to that of centromere position, a widely used local shape feature. The variability of feature measurements that might occur in data from different laboratories on account of differing tissue, preparation methods, and digitiser hardware is assessed using three data bases of G-banded human metaphase cells. It is shown that the differences can be considerable and that appropriate feature selection and classifier training substantially improve classification performance."
            },
            "slug": "On-fully-automatic-feature-measurement-for-banded-Piper-Granum",
            "title": {
                "fragments": [],
                "text": "On fully automatic feature measurement for banded chromosome classification."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that the differences can be considerable and that appropriate feature selection and classifier training substantially improve classification performance, and in particular a set of global shape features is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Cytometry"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878706"
                        ],
                        "name": "D. Michie",
                        "slug": "D.-Michie",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Michie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Michie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054341955"
                        ],
                        "name": "R. Camacho",
                        "slug": "R.-Camacho",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Camacho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Camacho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14704249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c1e846241d8c83dda7a26dfa403aed70ec5dc51",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Building Symbolic Representations of Intuitive Real-time Skills from Performance Data D. Michie and R. Camacho The Turing Institute, Glasgow, UK Abstract Real-time control skills are ordinarily tacit | their possessors cannot explicitly communicate them. But given su cient sampling of a trained expert's input{output behaviour, machine learning programs have been found capable of constructing rules which, when run as programs, deliver behaviours similar to those"
            },
            "slug": "Building-symbolic-representations-of-intuitive-from-Michie-Camacho",
            "title": {
                "fragments": [],
                "text": "Building symbolic representations of intuitive real-time skills from performance data"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "Building Symbolic Representations of Intuitive Real-time Skills from Performance Data shows that machine learning programs have been found capable of constructing rules which, when run as programs, deliver behaviours similar to those of trained experts."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Intelligence 13"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48616434"
                        ],
                        "name": "D. Spiegelhalter",
                        "slug": "D.-Spiegelhalter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Spiegelhalter",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Spiegelhalter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144845491"
                        ],
                        "name": "A. Dawid",
                        "slug": "A.-Dawid",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Dawid",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dawid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050895"
                        ],
                        "name": "S. Lauritzen",
                        "slug": "S.-Lauritzen",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Lauritzen",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lauritzen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34631309"
                        ],
                        "name": "R. Cowell",
                        "slug": "R.-Cowell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Cowell",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cowell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 121
                            }
                        ],
                        "text": "Another context in which knowledge derived from humans and data is synthesised is in the area of Bayesian expert systems (Spiegelhalter et al., 1993), in which subjective judgments of model structure and conditional probabilities are formally combined with likelihoods derived from data by Bayes theorem: this provides a way for a system to smoothly adapt a model from being initially expert-based towards one derived from data."
                    },
                    "intents": []
                }
            ],
            "corpusId": 86367536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6acd45949c2b167928211c562c8d9c445651f1ef",
            "isKey": false,
            "numCitedBy": 777,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "We review recent developments in applying Bayesian probabilistic and statistical ideas to expert systems. Using a real, moderately complex, medical example we illustrate how qualitative and quantitative knowledge can be represented within a directed graphical model, generally known as a belief network in this context. Exact probabilistic inference on individual cases is possible using a general propagation procedure. When data on a series of cases are available, Bayesian statistical techniques can be used for updating the original subjective quantitative inputs, and we present a sets of diagnostics for identifying conflicts between the data and the prior specification. A model comparison procedure is explored, and a number of links made with mainstream statistical methods. Details are given on the use of Dirichlet prior distributions for learning about parameters and the process of transforming the original graphical model to a junction tree as the basis for efficient computation."
            },
            "slug": "Bayesian-analysis-in-expert-systems-Spiegelhalter-Dawid",
            "title": {
                "fragments": [],
                "text": "Bayesian analysis in expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Using a real, moderately complex, medical example, it is illustrated how qualitative and quantitative knowledge can be represented within a directed graphical model, generally known as a belief network in this context."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1931927"
                        ],
                        "name": "A. Varsek",
                        "slug": "A.-Varsek",
                        "structuredName": {
                            "firstName": "Alen",
                            "lastName": "Varsek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Varsek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2654837"
                        ],
                        "name": "T. Urbancic",
                        "slug": "T.-Urbancic",
                        "structuredName": {
                            "firstName": "Tanja",
                            "lastName": "Urbancic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Urbancic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691028"
                        ],
                        "name": "B. Filipi\u010d",
                        "slug": "B.-Filipi\u010d",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Filipi\u010d",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Filipi\u010d"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 116
                            }
                        ],
                        "text": "Here, two methods will be described in more detail: BOXES (Michie & Chambers, 1968) and genetic learning of control (Var\u0161ek et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 125
                            }
                        ],
                        "text": "Therefore, the latest attempts take advantage of the existing knowledge, being explicit and formulated at the symbolic level (for example Urban\u010di\u010d & Bratko, 1992; Bratko, 1993; Var\u0161ek et al., 1993), or implicit and observable just as operator\u2019s skill (Michie et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34528543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60a67687d892d39c6aeac3ca3e2758fb947c0791",
            "isKey": false,
            "numCitedBy": 238,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A three-phased framework for learning dynamic system control is presented. A genetic algorithm is employed to derive control rules encoded as decision tables. Next, the rules are automatically transformed into comprehensible form by means of inductive machine learning. Finally, a genetic algorithm is applied again to optimize the numerical parameters of the induced rules. The approach is experimentally verified on a benchmark problem of inverted pendulum control, with special emphasis on robustness and reliability. It is also shown that the proposed framework enables exploiting available domain knowledge. In this case, genetic algorithm makes qualitative control rules operational by providing interpretation of symbols in terms of numerical values. >"
            },
            "slug": "Genetic-algorithms-in-controller-design-and-tuning-Varsek-Urbancic",
            "title": {
                "fragments": [],
                "text": "Genetic algorithms in controller design and tuning"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A three-phased framework for learning dynamic system control is presented, with special emphasis on robustness and reliability, and it is shown that the proposed framework enables exploiting available domain knowledge."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34915378"
                        ],
                        "name": "R. Rohwer",
                        "slug": "R.-Rohwer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rohwer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rohwer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2639784"
                        ],
                        "name": "David C. Cressy",
                        "slug": "David-C.-Cressy",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cressy",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Cressy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29928852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec24f8befab8bebaba24c01b93899a6e15d4df63",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The most popular neural network models for use in speech recognition experiments are employ model neurons which apply a nonlinear function to a weighted sum of their inputs. These networks are trained by adjusting the weights in the weighted sums. There is another class of models called Boolean networks, in which the model neurons output logical functions of their inputs. The training process adjusts the truth-tables which specify the logical functions. Although less well-known than conventional models, Boolean networks have been studied since 1960's. They have been sufficiently successful to form the basis of a commercial product for classification of images. This is a report on the application of a Boolean network to phoneme classification."
            },
            "slug": "Phoneme-classification-by-boolean-networks-Rohwer-Cressy",
            "title": {
                "fragments": [],
                "text": "Phoneme classification by boolean networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This is a report on the application of a Boolean network to phoneme classification."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1999747"
                        ],
                        "name": "L. Spirkovska",
                        "slug": "L.-Spirkovska",
                        "structuredName": {
                            "firstName": "Lilly",
                            "lastName": "Spirkovska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Spirkovska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31575769"
                        ],
                        "name": "M. B. Reid",
                        "slug": "M.-B.-Reid",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Reid",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. B. Reid"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1976952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2dda46707e72017f9f18de666cadb58318201bf",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present results of experiments comparing the performance of the ID3 symbolic learning algorithm with a higher-order neural network (HONN) in the distortion invariant object recognition domain. In this domain, the classification algorithm needs to be able to distinguish between two objects regardless of their position in the input field, their in-plane rotation, or their scale. It is shown that HONNs are superior to ID3 with respect to recognition accuracy, whereas, on a sequential machine, ID3 classifies examples faster once trained. A further advantage of HONNs is the small training set required. HONNs can be trained on just one view of each object, whereas ID3 needs an exhaustive training set.<<ETX>>"
            },
            "slug": "An-empirical-comparison-of-ID3-and-HONNs-for-object-Spirkovska-Reid",
            "title": {
                "fragments": [],
                "text": "An empirical comparison of ID3 and HONNs for distortion invariant object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that HONNs are superior to ID3 with respect to recognition accuracy, whereas, on a sequential machine, ID3 classifies examples faster once trained."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings of the 2nd International IEEE Conference on Tools for Artificial Intelligence"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11058174"
                        ],
                        "name": "D. Pearce",
                        "slug": "D.-Pearce",
                        "structuredName": {
                            "firstName": "Danny",
                            "lastName": "Pearce",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pearce"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 70
                            }
                        ],
                        "text": "They can be found, for example, in trouble-shooting complex circuitry (Pearce, 1989), in inferring biological activity from specifications of macromolecular structure in the pharmaceutical industry (see last section of Chapter 12) and in many other large combinatorial domains."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42256481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45b5091166863a20ab053061821a3408d1be612f",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a methodology for the automatic construction of diagnostic expert systems, and its application for fault diagnosis of a satellite's electrical power subsystem. \n \nThe synthesised knowledge base is compared with an existing expert system for the same application built using a commercial expert system shell. Both systems have been tested using a real-time satellite simulator which has the capability to fail components. \n \nA traditional knowledge-engineering approach involves building a prototype which is refined until satisfactory results are obtained. This process is error-ridden, as even in small systems, rules can conflict, be irrelevant, or missing. It is never clear when a system is complete and validation is always difficult. \n \nAs an alternative, a fault diagnostic knowledge base can be automatically synthesised from a qualitative model of the device. This is achieved by systematically simulating all component failures. Individual failures are used as examples. A learning algorithm is applied to the examples to output a set of diagnostic rules. The resulting rules are complete and consistent with the qualitative model and diagnose component failures in the model 100% accurately. Validation becomes a higher level problem of ensuring that the qualitative simulation accurately models physical device behaviour."
            },
            "slug": "The-Induction-of-Fault-Diagnosis-Systems-from-Pearce",
            "title": {
                "fragments": [],
                "text": "The Induction of Fault Diagnosis Systems from Qualitative Models"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A fault diagnostic knowledge base can be automatically synthesised from a qualitative model of the device by systematically simulating all component failures, and its application for fault diagnosis of a satellite's electrical power subsystem is described."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057878288"
                        ],
                        "name": "A. Shapiro",
                        "slug": "A.-Shapiro",
                        "structuredName": {
                            "firstName": "Alen",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shapiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2353436"
                        ],
                        "name": "T. Niblett",
                        "slug": "T.-Niblett",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Niblett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Niblett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53911463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "715916de986050eb2f6c1f963750dd8a72d033cf",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "AUTOMATIC-INDUCTION-OF-CLASSIFICATION-RULES-FOR-A-Shapiro-Niblett",
            "title": {
                "fragments": [],
                "text": "AUTOMATIC INDUCTION OF CLASSIFICATION RULES FOR A CHESS ENDGAME"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696678"
                        ],
                        "name": "D. Wolpert",
                        "slug": "D.-Wolpert",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wolpert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wolpert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 98
                            }
                        ],
                        "text": "This method of setting regularisation parameters does not provide a guarantee against overfitting (Wolpert, 1992), but it helps."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16602772,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "dadf60c10e4bc99672064adf1d42f07a754d446b",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper first reviews the reasoning behind the Bayesian \"evidence\" procedure for setting parameters in the probability distributions involved in inductive inference. This paper then proves that the evidence procedure is incorrect. More precisely, this paper proves that the assumptions going into the evidence procedure do not, as claimed, \"let the data determine the distributions\". Instead, those assumptions simply amount to an implicit replacement of the original distributions, containing free parameters, with new distributions, none of whose parameters are free. For example, as used by MacKay [1991] in the context of neural nets, the evidence procedure is a means for using the training set to determine the free parameter ex in the distribution P(Iwil) oc exp(ro:: 1 Wi2), where the N Wi are the N weights in the network. As this paper proves, in actuality the assumptions going into MacKay's use of the evidence procedure do not result in a distribution P(lwil) oc exp(ro::1 w?) for some ex, but rather result in a parameter-less distribution, P(lwil) oc (L:1 w?r CN!2 + 1). This paper goes on to prove that ifone makes the assumption of an \"entropic prior\" with unknown parameter value, in addition to the assumptions used in the evidence procedure, then the prior is completely fixed, but in a form which can not be entropic. (This calls into question the self-consistency of the numerous arguments purporting to derive an entropic prior \"from first principles\".) Finally, this paper goes on to investigate the Bayesian first-principles \"proof' of Occam's razor involving Occam factors. This paper proves that that \"proof' is flawed."
            },
            "slug": "A-Rigorous-Investigation-of-\u201cEvidence\u201d-and-\u201cOccam-Wolpert",
            "title": {
                "fragments": [],
                "text": "A Rigorous Investigation of \u201cEvidence\u201d and \u201cOccam Factors\u201d in Bayesian Reasoning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2822140"
                        ],
                        "name": "J. Renders",
                        "slug": "J.-Renders",
                        "structuredName": {
                            "firstName": "Jean-Michel",
                            "lastName": "Renders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Renders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144685306"
                        ],
                        "name": "J. Nordvik",
                        "slug": "J.-Nordvik",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Nordvik",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nordvik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775694"
                        ],
                        "name": "H. Bersini",
                        "slug": "H.-Bersini",
                        "structuredName": {
                            "firstName": "Hugues",
                            "lastName": "Bersini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bersini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 107938307,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8be06c29d343e5adf378d5e00903e8e5f4a29edf",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "GENETIC-ALGORITHMS-FOR-PROCESS-CONTROL:-A-SURVEY-Renders-Nordvik",
            "title": {
                "fragments": [],
                "text": "GENETIC ALGORITHMS FOR PROCESS CONTROL: A SURVEY"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802785"
                        ],
                        "name": "S. Nowlan",
                        "slug": "S.-Nowlan",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Nowlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5597033,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de75e4e15e22d4376300e5c968e2db44be29ac9e",
            "isKey": false,
            "numCitedBy": 644,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "One way of simplifying neural networks so they generalize better is to add an extra term to the error function that will penalize complexity. Simple versions of this approach include penalizing the sum of the squares of the weights or penalizing the number of nonzero weights. We propose a more complicated penalty term in which the distribution of weight values is modeled as a mixture of multiple gaussians. A set of weights is simple if the weights have high probability density under the mixture model. This can be achieved by clustering the weights into subsets with the weights in each cluster having very similar values. Since we do not know the appropriate means or variances of the clusters in advance, we allow the parameters of the mixture model to adapt at the same time as the network learns. Simulations on two different problems demonstrate that this complexity term is more effective than previous complexity terms."
            },
            "slug": "Simplifying-Neural-Networks-by-Soft-Weight-Sharing-Nowlan-Hinton",
            "title": {
                "fragments": [],
                "text": "Simplifying Neural Networks by Soft Weight-Sharing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A more complicated penalty term is proposed in which the distribution of weight values is modeled as a mixture of multiple gaussians, which allows the parameters of the mixture model to adapt at the same time as the network learns."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 4
                            }
                        ],
                        "text": "See Pearl (1988) and Lauritzen & Spiegelhalter (1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 53
                            }
                        ],
                        "text": "The algorithm to direct the skeleton can be found in Pearl (1988). The program to estimate causal polytrees used in our trials is CASTLE, ( p usal \u0083 } ructures From Inductive \u00a5 5 arning). It has been developed at the University of Granada for the ESPRIT project StatLog (Acid et al. (1991a); Acid et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 53
                            }
                        ],
                        "text": "The algorithm to direct the skeleton can be found in Pearl (1988). The program to estimate causal polytrees used in our trials is CASTLE, ( p usal \u0083 } ructures From Inductive \u00a5 5 arning)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 312,
                                "start": 53
                            }
                        ],
                        "text": "The algorithm to direct the skeleton can be found in Pearl (1988). The program to estimate causal polytrees used in our trials is CASTLE, ( p usal \u0083 } ructures From Inductive \u00a5 5 arning). It has been developed at the University of Granada for the ESPRIT project StatLog (Acid et al. (1991a); Acid et al. (1991b))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 246
                            }
                        ],
                        "text": "Moreover, the network shows the variables in \u00c1 that directly have influence on , in fact the parents of , the children of and the other parents of the children of (the knowledge of these variables makes independent of the rest of variables in \u00c1 )(Pearl, 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 50
                            }
                        ],
                        "text": ", 1991) and the artificial intelligence community (Pearl, 1988; Herkovsits & Cooper, 1990; Cooper & Herkovsits , 1991 and Fung & Crawford, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": true,
            "numCitedBy": 18219,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34915378"
                        ],
                        "name": "R. Rohwer",
                        "slug": "R.-Rohwer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rohwer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rohwer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 108
                            }
                        ],
                        "text": "Among the former however, we may mention comparisons of symbolic (ML) procedures in Clark & Boswell (1991), Sammut (1988), Quinlan et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18076331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc877ff5ffee426a6ff25a80c35fd02ae1b4428d",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "States or state sequences in neural network models are made to represent concepts from applications. This paper motivates, introduces and discusses a formalism for denoting such representations; a representation for representations. The formalism is illustrated by using it to discuss the representation of variable binding and inference abstractly, and then to present four specific representations. One of these is an apparently novel hybrid of phasic and tensor-product representations which retains the desirable properties of each."
            },
            "slug": "A-representation-of-representation-applied-to-a-of-Rohwer",
            "title": {
                "fragments": [],
                "text": "A representation of representation applied to a discussion of variable binding"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A formalism for denoting representations of states or state sequences in neural network models is introduced and an apparently novel hybrid of phasic and tensor-product representations which retains the desirable properties of each is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878706"
                        ],
                        "name": "D. Michie",
                        "slug": "D.-Michie",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Michie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Michie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144041292"
                        ],
                        "name": "Michael Bain",
                        "slug": "Michael-Bain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Bain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403929847"
                        ],
                        "name": "Jean Hayes-Michie",
                        "slug": "Jean-Hayes-Michie",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Hayes-Michie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean Hayes-Michie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 61
                            }
                        ],
                        "text": ", 1993), or implicit and observable just as operator\u2019s skill (Michie et al., 1990; Sammut et al., 1992; Camacho & Michie, 1992; Michie & Camacho, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60575716,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d40aff59c9b0785e0d75765b0040430ffc377f2d",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter considers the acquisition of skill in dynamical control tasks for which the 'recognise-act' cycle is relatively fast, as in piloting a helicopter. Human pilots commonly receive their initial training on computer simulations. From such trial-and-error learning they acquire cognitive capabilities which they cannot articulate."
            },
            "slug": "Cognitive-models-from-subcognitive-skills-Michie-Bain",
            "title": {
                "fragments": [],
                "text": "Cognitive models from subcognitive skills"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter considers the acquisition of skill in dynamical control tasks for which the 'recognise-act' cycle is relatively fast, as in piloting a helicopter."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680968"
                        ],
                        "name": "R. Prager",
                        "slug": "R.-Prager",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Prager",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Prager"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1998157"
                        ],
                        "name": "F. Fallside",
                        "slug": "F.-Fallside",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Fallside",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fallside"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62770392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "756fd2782cca1e4114d2e83296078c6423a0eeb0",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-modified-Kanerva-model-for-automatic-speech-Prager-Fallside",
            "title": {
                "fragments": [],
                "text": "The modified Kanerva model for automatic speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2237914"
                        ],
                        "name": "M. D. Fraser",
                        "slug": "M.-D.-Fraser",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fraser",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. D. Fraser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60015805,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7413c6ee30949711a44db2cabe120c88deba9b7e",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This volume is concerned with state-of-the-art developments in modelling control and processing in distributed networks. Contributions from researchers and practitioners in universities, private industry, and government are included. The main themes addressed include: the models and methodologies for distributed control and parallel distributed processing networks; feedback and control, distributed control and self-organization; model performance evaluation; texting of models and simulations; learning and memory; internodal communications and network flow; and information transmission and processing."
            },
            "slug": "Advances-in-control-networks-and-large-scale-models-Fraser",
            "title": {
                "fragments": [],
                "text": "Advances in control networks and large-scale parallel distributed processing models"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This volume is concerned with state-of-the-art developments in modelling control and processing in distributed networks and the models and methodologies for distributed control and parallel distributed processing networks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2338183"
                        ],
                        "name": "M. M\u00e9zard",
                        "slug": "M.-M\u00e9zard",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "M\u00e9zard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. M\u00e9zard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187506"
                        ],
                        "name": "J. Nadal",
                        "slug": "J.-Nadal",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "Nadal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nadal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 44826720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8c9c463b17a63380f3dd0d62e034d9c76411de2",
            "isKey": false,
            "numCitedBy": 473,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors propose a new algorithm which builds a feedforward layered network in order to learn any Boolean function of N Boolean units. The number of layers and the number of hidden units in each layer are not prescribed in advance: they are outputs of the algorithm. It is an algorithm for growth of the network, which adds layers, and units inside a layer, at will until convergence. The convergence is guaranteed and numerical tests of this strategy look promising."
            },
            "slug": "Learning-in-feedforward-layered-networks:-the-M\u00e9zard-Nadal",
            "title": {
                "fragments": [],
                "text": "Learning in feedforward layered networks: the tiling algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new algorithm which builds a feedforward layered network in order to learn any Boolean function of N Boolean units, which is an algorithm for growth of the network, which adds layers, and units inside a layer, at will until convergence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057878288"
                        ],
                        "name": "A. Shapiro",
                        "slug": "A.-Shapiro",
                        "structuredName": {
                            "firstName": "Alen",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shapiro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10116897,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "467fe68e1f52e2baa442a08b338f93b46ceb9210",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Read more and get great! That's what the book enPDFd structured induction in expert systems will give for every reader to read this book. This is an on-line book provided in this website. Even this book becomes a choice of someone to read, many in the world also loves it so much. As what we talk, when you read more every page of this structured induction in expert systems, what you will obtain is something great."
            },
            "slug": "Structured-induction-in-expert-systems-Shapiro",
            "title": {
                "fragments": [],
                "text": "Structured induction in expert systems"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "When you read more every page of this structured induction in expert systems, what you will obtain is something great."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804253"
                        ],
                        "name": "C. Sammut",
                        "slug": "C.-Sammut",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Sammut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sammut"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 95
                            }
                        ],
                        "text": "Figures vary considerably from paper to paper and are between 84 (Geva & Sitte, 1993b) and 557 (Sammut, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 251
                            }
                        ],
                        "text": "Recently, the research concentrated on removing the deficiencies inherent to these methods, like the obscurity and unreliability of the learned control rules (Bain, 1990; Sammut & Michie, 1991; Sammut & Cribb, 1990) and time-consuming experimentation (Sammut, 1994) while still presuming no prior knowledge."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14668966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2e46948da746ae489c7640e95b6771bfd0d6daa",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The BOXES algorithm of Michie and Chambers (1968) has proved to be an effective and flexible method for learning to control dynamic systems. The algorithm, in its original form has been used a benchmark for many experiments in control tasks such as pole balancing. Recent work in our laboratory has shown that the BOXES algorithm can be improved to yield very good learning rates. We describe experiments on a variety of update functions and discuss their robustness. We also develop the notion of freezing of BOXES, suggested by Michie and implemented by Bain (1990). We have also been concerned with synthesising a readable account of the control strategy employed by a set of boxes. Some preliminary work has begun in combining decision tree learning algorithms with BOXES. Using this method, we regard BOXES as the acquirer of sub-cognitive skills and the decision tree induction as a means of introspecting on the learned strategy to generate understandable control rules."
            },
            "slug": "Recent-progress-with-BOXES-Sammut",
            "title": {
                "fragments": [],
                "text": "Recent progress with BOXES"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work regards BOXES as the acquirer of sub-cognitive skills and the decision tree induction as a means of introspecting on the learned strategy to generate understandable control rules."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Intelligence 13"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145147566"
                        ],
                        "name": "S. Muggleton",
                        "slug": "S.-Muggleton",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Muggleton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muggleton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Muggleton & Buntine (1998) took this approach a step further and realised that through the application of a few simple rules, they could invert resolution as Plotkin and Reynolds had wished."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 38
                            }
                        ],
                        "text": "The other was an ILP learner based on Muggleton & Feng\u2019s (1990) GOLEM, with \u201cClosed World Specialization\u201d enhancements (Bain, private communication)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1863367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67f3e9c5b7007fc2e9e84bc547e448fa067490de",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Turing's best known work is concerned with whether universal machines can decide the truth value of arbitrary logic formulae. However, in this paper it is shown that there is a direct evolution in Turing's ideas from his earlier investigations of computability to his later interests in machine intelligence and machine learning. Turing realised that machines which could learn would be able to avoid some of the consequences of Godes and his results on incompleteness and undecidability. Machines which learned could continuously add new axioms to their repertoire. Inspired by a radio talk given by Turing in 1951, Christopher Strachey went on to implement the world's first machine learning program. This particular first is usually attributed to A.L. Samuel. Strachey's program, which did rote learning in the game of Nim, preceded Samuel's checker playing program by four years. Neither Strachey's nor Samuel's system took up Turing's suggestion of learning logical formulae. Developments in this area were delayed until Gordon Plotkin's work in the early 1970's. Computer-based learning of logical formulae is the central theme of the research area of Inductive Logic Programming, which grew directly out of the earlier work of Plotkin and Shapiro. In the present paper the author describes the state of this new field and discusses areas for future development."
            },
            "slug": "Logic-and-Learning:-Turing's-legacy-Muggleton",
            "title": {
                "fragments": [],
                "text": "Logic and Learning: Turing's legacy"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The author describes the state of this new field of Inductive Logic Programming, which grew directly out of the earlier work of Plotkin and Shapiro, and discusses areas for future development."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Intelligence 13"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767485"
                        ],
                        "name": "M. Schoppers",
                        "slug": "M.-Schoppers",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Schoppers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schoppers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 17643570,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "231b91f14d782b17160120a5bd097803404edf21",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This special section is the outgrowth of a workshop on real-time knowledge-based control systems, held during the 1990 national conference of the American Association for Artificial Intelligence (AAAI). The workshop was motivated by the recognition that constructing robotic systems capable of autonomous, flexible, intelligent behavior is an inherently interdisciplinary task. In particular, professionals from the fields of artificial intelligence (AI), control theory, process control and real-time scheduling were invited. To facilitate communication among these fields, the workshop organizers decided to focus on software design principles for real-time systems, and so sought out those who had built working systems and could express their experiences in terms of techniques they had tested and/or refuted."
            },
            "slug": "Real-time-knowledge-based-control-systems-Schoppers",
            "title": {
                "fragments": [],
                "text": "Real-time knowledge-based control systems"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This special section is the outgrowth of a workshop on real-time knowledge-based control systems, held during the 1990 national conference of the American Association for Artificial Intelligence (AAAI), where professionals from the fields of artificial intelligence, control theory, process control and real- time scheduling were invited."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2510971"
                        ],
                        "name": "T. Tollenaere",
                        "slug": "T.-Tollenaere",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Tollenaere",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tollenaere"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 104
                            }
                        ],
                        "text": "This circumstance has given rise to a plethora of heuristics for adaptive variable step size algorithms (Toolenaere, 1990; Silva & Almeida, 1990; Jacobs, 1988) ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 115
                            }
                        ],
                        "text": "These methods offer the benefit of simplicity, but their performance depends sensitively on the parameters ~ and \u00e1 (Toolenaere, 1990)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 29674798,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa79c269b31af3834b6db801bb0ad9690e13631c",
            "isKey": false,
            "numCitedBy": 407,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SuperSAB:-Fast-adaptive-back-propagation-with-good-Tollenaere",
            "title": {
                "fragments": [],
                "text": "SuperSAB: Fast adaptive back propagation with good scaling properties"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4605464"
                        ],
                        "name": "W. McCulloch",
                        "slug": "W.-McCulloch",
                        "structuredName": {
                            "firstName": "Warren",
                            "lastName": "McCulloch",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. McCulloch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50314979"
                        ],
                        "name": "W. Pitts",
                        "slug": "W.-Pitts",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Pitts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pitts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15619658,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "090c5a5df345ab60c41d6de02b3e366e1a27cf43",
            "isKey": false,
            "numCitedBy": 6088,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Because of the \u201call-or-none\u201d character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed."
            },
            "slug": "A-logical-calculus-of-the-ideas-immanent-in-nervous-McCulloch-Pitts",
            "title": {
                "fragments": [],
                "text": "A logical calculus of the ideas immanent in nervous activity"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time."
            },
            "venue": {
                "fragments": [],
                "text": "The Philosophy of Artificial Intelligence"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145147566"
                        ],
                        "name": "S. Muggleton",
                        "slug": "S.-Muggleton",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Muggleton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muggleton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70219052"
                        ],
                        "name": "Wray L. Buntine",
                        "slug": "Wray-L.-Buntine",
                        "structuredName": {
                            "firstName": "Wray",
                            "lastName": "Buntine",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wray L. Buntine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6159430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e340a9b752f9b358cda4dc7a1c6e3c6280867158",
            "isKey": false,
            "numCitedBy": 599,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Machine-Invention-of-First-Order-Predicates-by-Muggleton-Buntine",
            "title": {
                "fragments": [],
                "text": "Machine Invention of First Order Predicates by Inverting Resolution"
            },
            "venue": {
                "fragments": [],
                "text": "ML"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804253"
                        ],
                        "name": "C. Sammut",
                        "slug": "C.-Sammut",
                        "structuredName": {
                            "firstName": "Claude",
                            "lastName": "Sammut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sammut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878706"
                        ],
                        "name": "D. Michie",
                        "slug": "D.-Michie",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Michie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Michie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1234414,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d5afa81cf718ca25c375659c998eea231ecacba0",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This article reports on experiments performed using a black-box simulation of a spacecraft. The goal of this research is to learn to control the attitude of an orbiting satellite. The space-craft must be able to operate with minimal human supervision. To this end, we are investigating the possibility of using adaptive controllers for such tasks. Laboratory tests have suggested that rule-based methods can be more robust than systems developed using traditional control theory. The BOXES learning system, which has already met with success in simulated laboratory tasks, is an effective design framework for this new exercise."
            },
            "slug": "Controlling-a-Black-Box-Simulation-of-a-Spacecraft-Sammut-Michie",
            "title": {
                "fragments": [],
                "text": "Controlling a Black-Box Simulation of a Spacecraft"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This research aims to learn to control the attitude of an orbiting satellite using the BOXES learning system, which has already met with success in simulated laboratory tasks, and is an effective design framework for this new exercise."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145147566"
                        ],
                        "name": "S. Muggleton",
                        "slug": "S.-Muggleton",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Muggleton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muggleton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117343701"
                        ],
                        "name": "C. Feng",
                        "slug": "C.-Feng",
                        "structuredName": {
                            "firstName": "Cao",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Feng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14992676,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a669636e0ada62a0fb444e95435e24fdbdf4dbd",
            "isKey": false,
            "numCitedBy": 848,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently there has been increasing interest in systems which induce rst order logic programs from examples. However, many diiculties need to be overcome. Well-known algorithms fail to discover correct logical descriptions for large classes of interesting predicates , due either to the intractability of search or overly strong limitations applied to the hypothesis space. In contrast, search is avoided within Plotkin's framework of relative least general generalisation (rlgg). It is replaced by the process of constructing a unique clause which covers a set of examples relative to given background knowledge. However, such a clause can in the worst case contain innnitely many literals, or at best grow exponentially with the number of examples involved. In this paper we introduce the concept of h-easy rlgg clauses and show that they have nite length. We also prove that the length of a certain class of \\determinate\" rlgg is bounded by a polynomial function of certain features of the background knowledge. This function is independent of the number of examples used to construct them. An existing implementation called GOLEM is shown to be capable of inducing many interesting logic programs which have not been demonstrated to be learnable using other algorithms."
            },
            "slug": "Efficient-Induction-of-Logic-Programs-Muggleton-Feng",
            "title": {
                "fragments": [],
                "text": "Efficient Induction of Logic Programs"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The concept of h-easy rlgg clauses is introduced and it is proved that the length of a certain class of \\determinate\" r lgg is bounded by a polynomial function of certain features of the background knowledge."
            },
            "venue": {
                "fragments": [],
                "text": "ALT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878706"
                        ],
                        "name": "D. Michie",
                        "slug": "D.-Michie",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Michie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Michie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 75
                            }
                        ],
                        "text": "Preference goes to that attribute contributing the greatest expected total (Michie, 1990; Michie & Al Attar, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123553195,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "054136fd4da4abaf43aeea56c341f0aa7a2de11d",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Personal-models-of-rationality-Michie",
            "title": {
                "fragments": [],
                "text": "Personal models of rationality"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145282631"
                        ],
                        "name": "J. A. Robinson",
                        "slug": "J.-A.-Robinson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Robinson",
                            "middleNames": [
                                "Alan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Robinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 11
                            }
                        ],
                        "text": "Resolution (Robinson, 1965) provides an efficient means of deriving a solution to a problem, giving a set of axioms which define the task environment."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14389185,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d2109eba4f160755f0b9a7497b6b691c2fa2d5d8",
            "isKey": false,
            "numCitedBy": 4367,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ":tb.~tract. Theorem-proving on the computer, using procedures based on the fund~mental theorem of Herbrand concerning the first-order predicate etdeulus, is examined with ~ view towards improving the efticieney and widening the range of practical applicability of these procedures. A elose analysis of the process of substitution (of terms for variables), and the process of t ruth-funct ional analysis of the results of such substitutions, reveals that both processes can be combined into a single new process (called resolution), i terating which is vastty more ef[ieient than the older cyclic procedures consisting of substitution stages alternating with truth-functional analysis stages. The theory of the resolution process is presented in the form of a system of first<~rder logic with .just one inference principle (the resolution principle). The completeness of the system is proved; the simplest proof-procedure based oil the system is then the direct implementation of the proof of completeness. Howew~r, this procedure is quite inefficient, ~nd the paper concludes with a discussion of several principles (called search principles) which are applicable to the design of efficient proof-procedures employing resolution as the basle logical process."
            },
            "slug": "A-Machine-Oriented-Logic-Based-on-the-Resolution-Robinson",
            "title": {
                "fragments": [],
                "text": "A Machine-Oriented Logic Based on the Resolution Principle"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The paper concludes with a discussion of several principles which are applicable to the design of efficient proof-procedures employing resolution as the basle logical process."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805236"
                        ],
                        "name": "J. McCarthy",
                        "slug": "J.-McCarthy",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "McCarthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. McCarthy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 19
                            }
                        ],
                        "text": "2 constitutes what McCarthy and Hayes (1969) termed an \u201cepistemologically adequate\u201d representation: it supplies whatever facts are in principle needed to obtain solutions. But for decision-tree learning, the representation is not \u201cheuristically adequate\u201d. Michie & Bain (1992) applied a state-of-the-art decision-tree learner (XpertRule) of roughly similar power to C4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 19
                            }
                        ],
                        "text": "2 constitutes what McCarthy and Hayes (1969) termed an \u201cepistemologically adequate\u201d representation: it supplies whatever facts are in principle needed to obtain solutions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2823033,
            "fieldsOfStudy": [
                "Philosophy",
                "Computer Science"
            ],
            "id": "76c880bd5bfa3c627a9497cd6f1ee0afa093e131",
            "isKey": false,
            "numCitedBy": 3747,
            "numCiting": 104,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SOME-PHILOSOPHICAL-PROBLEMS-FROM-THE-STANDPOINT-OF-McCarthy",
            "title": {
                "fragments": [],
                "text": "SOME PHILOSOPHICAL PROBLEMS FROM THE STANDPOINT OF ARTI CIAL INTELLIGENCE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48855558"
                        ],
                        "name": "D. Pomerleau",
                        "slug": "D.-Pomerleau",
                        "structuredName": {
                            "firstName": "Dean",
                            "lastName": "Pomerleau",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pomerleau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 13
                            }
                        ],
                        "text": "For example, Pomerleau (1989) accepts raw data from a camera mounted on a moving vehicle and selects portions of the image to process for input to a neural net that learns how to steer the vehicle."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18420840,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "7786bc6c25ba38ff0135f1bdad192f6b3c4ad0b3",
            "isKey": false,
            "numCitedBy": 1459,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "ALVINN (Autonomous Land Vehicle In a Neural Network) is a 3-layer back-propagation network designed for the task of road following. Currently ALVINN takes images from a camera and a laser range finder as input and produces as output the direction the vehicle should travel in order to follow the road. Training has been conducted using simulated road images. Successful tests on the Carnegie Mellon autonomous navigation test vehicle indicate that the network can effectively follow real roads under certain field conditions. The representation developed to perform the task differs dramatically when the network is trained under various conditions, suggesting the possibility of a novel adaptive autonomous navigation system capable of tailoring its processing to the conditions at hand."
            },
            "slug": "ALVINN:-An-Autonomous-Land-Vehicle-in-a-Neural-Pomerleau",
            "title": {
                "fragments": [],
                "text": "ALVINN: An Autonomous Land Vehicle in a Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "ALVINN (Autonomous Land Vehicle In a Neural Network) is a 3-layer back-propagation network designed for the task of road following that can effectively follow real roads under certain field conditions."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982689"
                        ],
                        "name": "J. Siebert",
                        "slug": "J.-Siebert",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Siebert",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Siebert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 323,
                                "start": 88
                            }
                        ],
                        "text": "(1984) describe CART, which is a partitioning algorithm developed by statisticians, and Silverman (1986) discusses density estimation methods. For neural net approaches, the book by Hertz et al. (1991) is probably the most comprehensive and reliable. Two excellent texts on pattern recognition are those of Fukunaga (1990) , who gives a thorough treatment of classification problems, and Devijver & Kittler (1982) who concentrate on the k-nearest neighbour approach."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 88
                            }
                        ],
                        "text": "(1984) describe CART, which is a partitioning algorithm developed by statisticians, and Silverman (1986) discusses density estimation methods."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 88
                            }
                        ],
                        "text": "(1984) describe CART, which is a partitioning algorithm developed by statisticians, and Silverman (1986) discusses density estimation methods. For neural net approaches, the book by Hertz et al. (1991) is probably the most comprehensive and reliable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 13
                            }
                        ],
                        "text": "The original Siebert (1987) paper showed machine learning performing better than k-NN, but there is not much support for this in our results."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 53782195,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79f058f5890760223f2298a6c512af63a2bc251b",
            "isKey": true,
            "numCitedBy": 97,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vehicle-Recognition-Using-Rule-Based-Methods-Siebert",
            "title": {
                "fragments": [],
                "text": "Vehicle Recognition Using Rule Based Methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421006"
                        ],
                        "name": "R. Michalski",
                        "slug": "R.-Michalski",
                        "structuredName": {
                            "firstName": "Ryszard",
                            "lastName": "Michalski",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Michalski"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 55
                            }
                        ],
                        "text": "We are here concerned with heading (b), exemplified by Michalski and Chilausky\u2019s (1980) landmark use of the AQ11 algorithm (Michalski & Larson, 1978) to generate automatically a rule-based classifier for crop farmers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1108,
                                "start": 90
                            }
                        ],
                        "text": "In common with CN2 and ITrule but in contrast to the specific-to-general earlier style of Michalski\u2019s AQ family of rule learning, decision-tree learning is general-to-specific. In illustrating with the vertebrate taxonomy example we will assume that the set of nine attributes are sufficient to classify without error all vertebrate species into one of MAMMAL, BIRD, AMPHIBIAN, REPTILE, FISH. Later we will consider elaborations necessary in underspecified or in inherently \u201cnoisy\u201d domains, where methods from statistical data analysis enter the picture. As shown in Figure 5.4, the starting point is a tree of only one node that allocates all cases in the training set to a single class. In the case that a mammal-recogniser is required, this default class could be NOT-MAMMAL. The presumption here is that in the population there are more of these than there are mammals. Unless all vertebrates in the training set are non-mammals, some of the training set of cases associated with this single node will be correctly classified and others incorrectly, \u2013 in the terminology of Breiman and colleagues (1984), such a node is \u201cimpure\u201d."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 4
                            }
                        ],
                        "text": "See Michalski & Larson (1978). AQ searches for rules which are completely consistent with the training data, whereas CN2 may prematurely halt specialisation of a rule when no further rules above a certain threshold of statistical significance can be generated via specialisation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1342,
                                "start": 200
                            }
                        ],
                        "text": "if skin-covering = hair or skin-covering = none, reproduction = viviparous then MAMMAL; and if skin-covering = hair or skin-covering = none, warm-blooded = y then MAMMAL; In rule induction, following Michalski,an attribute-test is called a selector, a conjunction of selectors is a complex, and a disjunction of complexes is called a cover. If a rule is true of an example we say that it covers the example. Rule learning systems in practical use qualify and elaborate the above simple scheme, including by assigning a prominent role to general-to-specific processes. In the StatLog experiment such algorithms are exemplified by CN2 (Clarke & Niblett, 1989) and ITrule. Both generate decision rules for each class in turn, for each class starting with a universal rule which assigns all examples to the current class. This rule ought to cover at least one of the examples belonging to that class. Specialisations are then repeatedly generated and explored until all rules consistent with the data are found. Each rule must correctly classify at least a prespecified percentage of the examples belonging to the current class. As few as possible negative examples, i.e. examples in other classes, should be covered. Specialisations are obtained by adding a condition to the left-hand side of the rule. CN2 is an extension of Michalski\u2019s (1969) algorithm AQ with several techniques to process noise in the data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 26
                            }
                        ],
                        "text": "Following the notation of Michalski (1983), the classes in Figure 12."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58427035,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e3b0fe4c409930f37c0a4be9222e0b21d6471ac7",
            "isKey": true,
            "numCitedBy": 288,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-Quasi-Minimal-Solution-of-the-General-Michalski",
            "title": {
                "fragments": [],
                "text": "On the Quasi-Minimal Solution of the General Covering Problem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72932272"
                        ],
                        "name": "A. Makarovic",
                        "slug": "A.-Makarovic",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Makarovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Makarovic"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 522,
                                "start": 3
                            }
                        ],
                        "text": "2: Makarovi\u010d\u2019s rule for pole balancing. A solution, distinguished by its simplicity, was derived by Makarovi\u010d (1988) (see Figure 13.2). Rules of the same tree structure, but with the state variables ordered in different ways, were experimentally studied by D\u017eeroski (1989). He showed that no less than seven permutations of state variables yielded successful control rules. We denote such rules as , where is a permutation of the variables, determining their top-down order. Another solution was inferred by Bratko (1991) from a very simple qualitative model of the inverted pendulum system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 3
                            }
                        ],
                        "text": "2: Makarovi\u010d\u2019s rule for pole balancing. A solution, distinguished by its simplicity, was derived by Makarovi\u010d (1988) (see Figure 13.2). Rules of the same tree structure, but with the state variables ordered in different ways, were experimentally studied by D\u017eeroski (1989). He showed that no less than seven permutations of state variables yielded successful control rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 45
                            }
                        ],
                        "text": "The obtained rules are very close in form to Makarovi\u010d\u2019s rule. From the rules shown by D\u017eeroski (1989) to successfully control the pole-cart system, rules * \u0006 * * \r , * * * \r , and * \u0006 * \r * were discovered automatically."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 62481317,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "f3773eb68707eb9aceb87782075a85dbb848719f",
            "isKey": true,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-qualitative-way-of-solving-the-pole-balancing-Makarovic",
            "title": {
                "fragments": [],
                "text": "A qualitative way of solving the pole balancing problem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122942"
                        ],
                        "name": "B. Ripley",
                        "slug": "B.-Ripley",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ripley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ripley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 11
                            }
                        ],
                        "text": "(1990) and Ripley (1993) The dataset used by Ripley was slightly different in that the attributes were normalised to be in the range [0,1] over the whole dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Ripley (1993) compared a diverse set of statistical methods, neural networks, and a decision tree classifier on the Tsetse fly data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 521,
                                "start": 0
                            }
                        ],
                        "text": "Ripley (1993) compared a diverse set of statistical methods, neural networks, and a decision tree classifier on the Tsetse fly data. This is a restricted comparison because it has only one data set and includes only one symbolic algorithm. However, some findings are nevertheless interesting. In accuracy, the results favoured nearest neighbour, the decision tree algorithm, back-propagation and projection pursuit. The decision tree algorithm rapidly produced most interpretable results. More importantly, Ripley (1993) also described the \u201cdegree of frustration\u201d in getting some algorithms to produce the eventual results (whereas others, for example, Fisher & McKusick (1989) and Shavlik et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Ripley (1993) also raises some important points on the use and claims of Neural Net methods."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 4
                            }
                        ],
                        "text": "See Ripley (1993) for the explicit connection between discrimination and regression."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 13
                            }
                        ],
                        "text": "Results from Ripley (1993) indicate that condensing does not greatly affect the classification performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1157,
                                "start": 0
                            }
                        ],
                        "text": "Ripley (1993) compared a diverse set of statistical methods, neural networks, and a decision tree classifier on the Tsetse fly data. This is a restricted comparison because it has only one data set and includes only one symbolic algorithm. However, some findings are nevertheless interesting. In accuracy, the results favoured nearest neighbour, the decision tree algorithm, back-propagation and projection pursuit. The decision tree algorithm rapidly produced most interpretable results. More importantly, Ripley (1993) also described the \u201cdegree of frustration\u201d in getting some algorithms to produce the eventual results (whereas others, for example, Fisher & McKusick (1989) and Shavlik et al. (1991) did not). The neural networks were bad in this respect: they were very sensitive to various system settings (for example, hidden units and the stopping criterion) and they generally converged to the final accuracies slowly. Of course, the inclusion of statistical algorithms does not, of itself, make the comparisons valid. For example, statisticians would be wary of applying a Bayes algorithm to the four problems involved in Weiss & Kapouleas (1989) because of the lack of basic information regarding the prior and posterior probabilities in the data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 56833645,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8c4869392e5a52c3511fb907bd719391d9b9726",
            "isKey": true,
            "numCitedBy": 516,
            "numCiting": 119,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-aspects-of-neural-networks-Ripley",
            "title": {
                "fragments": [],
                "text": "Statistical aspects of neural networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 66
                            }
                        ],
                        "text": "For a description of correspondence analysis, see Hill (1982) and Mardia et al. (1979) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 0
                            }
                        ],
                        "text": "Mardia et al. (1979) give multivariate measures of skewness and kurtosis that are invariant to affine transformations of the data: critical values of these statistics for small samples are given in Mardia (1974). These measures are difficult to compare across datasets with differing dimensionality."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 718,
                                "start": 0
                            }
                        ],
                        "text": "Mardia et al. (1979) give multivariate measures of skewness and kurtosis that are invariant to affine transformations of the data: critical values of these statistics for small samples are given in Mardia (1974). These measures are difficult to compare across datasets with differing dimensionality. They also have the disadvantage that they do not reduce to the usual univariate statistics when the attributes are independent. Our approach is to concentrate on the original coordinates by looking at their marginal distributions. Moreover, the emphasis here is on a measure of non-normality, rather than on a test that tells us how statistically significant is the departure from normality. See Ozturk & Romeu (1992) for a review of methods for testing multivariate normality."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Mardia et al. (1979) give multivariate measures of skewness and kurtosis that are invariant to affine transformations of the data: critical values of these statistics for small samples are given in Mardia (1974)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Applications of some measures of multivariate skewness and kurtosis in testing normality and robustness studies"
            },
            "venue": {
                "fragments": [],
                "text": "Sankhya B, 36:115\u2013128."
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 11
                            }
                        ],
                        "text": "(1992) and Michie & Sammut (1993) describe experiments in extracting, by Machine Learning, the pilot\u2019s subcognitive component of the skill of flying a plane."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Michie (1989) reports a case where the aim of the credit-granting procedure was to keep the bad debt rate among those granted credit down to 9%."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 60
                            }
                        ],
                        "text": "Quantitative measures of linearity are discussed by Arbab & Michie (1988), who present an algorithm, RG, for building trees biased towards linearity. They also compare RG with Bratko\u2019s (1983) AOCDL directed towards the same end."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 43
                            }
                        ],
                        "text": "In this idea, we are following the work of Michie et al. (1990), Sammut et al. (1992) and Michie & Camacho (1994) who confirmed the findings of Sammut et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 60
                            }
                        ],
                        "text": "Quantitative measures of linearity are discussed by Arbab & Michie (1988), who present an algorithm, RG, for building trees biased towards linearity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1022,
                                "start": 61
                            }
                        ],
                        "text": "Sammut (1994) describes some recent refinements of the basic Michie-Chambers learning scheme. The central mechanism of learning in BOXES is the decision rule based on the \u201cexperience\u201d of each box. The experience for each individual box is accumulated in the variables DED (left action lifetime), DIH (left action usage), FGD and F:H (same for the right action). The Michie-Chambers rule determines the decision between left and right action depending on these variables. The rule is designed so that it combines two, possibly conflicting interests: exploitation and exploration. The first is to perform the action that in the past produced the best results (that is maximum lifetime), and the second is to explore the alternatives. The alternatives may in the future turn out in fact to be superior to what appears to be best at present. The original Michie-Chambers formulas find a particular compromise between these two interests. The compromise can be adjusted by varying the parameters in the formulas. Sammut (1994) describes a series of modifications of the original Michie-Chambers rule."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 43
                            }
                        ],
                        "text": "In this idea, we are following the work of Michie et al. (1990), Sammut et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 46
                            }
                        ],
                        "text": "We have observed a \u2018clean-up\u2019 effect noted in Michie, Bain and Hayes-Michie (1990). The flight log of any trainer will contain many spurious actions due to human inconsistency and corrections required as a result of inattention."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 591,
                                "start": 71
                            }
                        ],
                        "text": "The following improvement of the Law & Sammut rule with respect to the Michie & Chambers rule was reported: on the average over 20 experiments, the original BOXES needed 557 trials to learn to control the system, whereas the Law & Sammut rule needed 75 trials (with T @po ). In trying to test the stability of the Law & Sammut rule, it was found that T was slightly, but not significantly, sensitive to small changes in the learning problem, such as changing the number of boxes from 162 to 225, or introducing asymmetry in the force (left push twice the right push). Geva and Sitte (1993a) carried out exhaustive experiments concerning the same topic."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 83
                            }
                        ],
                        "text": "This basic idea has been implemented in many different ways, for example in BOXES (Michie & Chambers, 1968), Adaptive Critic reinforcement method (Barto et al., 1983), CART (Connell & Utgoff, 1987), multilayer connectionist approach (Anderson, 1987) and many others. Geva and Sitte (1993a) provide an exhaustive review."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Problems of computer-aided concept formation"
            },
            "venue": {
                "fragments": [],
                "text": "Quinlan, J. R., editor, Applications of Expert Systems, volume 2, pages 310 \u2013 333. Addison-Wesley, London."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406409112"
                        ],
                        "name": "A. O'Hagan",
                        "slug": "A.-O'Hagan",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "O'Hagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. O'Hagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2322494"
                        ],
                        "name": "J. Ord",
                        "slug": "J.-Ord",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Ord",
                            "middleNames": [
                                "Keith"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40692782"
                        ],
                        "name": "M. Kendall",
                        "slug": "M.-Kendall",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Kendall",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kendall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2322494"
                        ],
                        "name": "J. Ord",
                        "slug": "J.-Ord",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Ord",
                            "middleNames": [
                                "Keith"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46918097"
                        ],
                        "name": "A. Stuart",
                        "slug": "A.-Stuart",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Stuart",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stuart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36674058"
                        ],
                        "name": "S. Arnold",
                        "slug": "S.-Arnold",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Arnold",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Arnold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124153255,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "45fc16072ffff14592cc24c5e1da120b4b496901",
            "isKey": false,
            "numCitedBy": 247,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Advanced-Theory-of-Statistics,-Vol.-1:-Theory-O'Hagan-Ord",
            "title": {
                "fragments": [],
                "text": "The Advanced Theory of Statistics, Vol. 1: Distribution Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 100
                            }
                        ],
                        "text": "In a similar way, other types of controllers can be tuned, for example the classical PID controller (Urban\u010di\u010d et al., 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 114735804,
            "fieldsOfStudy": [],
            "id": "3ef1a925a18fbbb2e391dd26b2c05a77fd536f11",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "AUTOMATED SYNTHESIS OF CONTROL FOR NONLINEAR DYNAMIC SYSTEMS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057878514"
                        ],
                        "name": "A. Shapiro",
                        "slug": "A.-Shapiro",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Shapiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shapiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878706"
                        ],
                        "name": "D. Michie",
                        "slug": "D.-Michie",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Michie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Michie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 109002266,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "e9db85cab124ad7f4ccd1a4b444bcf190d02e678",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-self-commenting-facility-for-inductively-endgame-Shapiro-Michie",
            "title": {
                "fragments": [],
                "text": "A self-commenting facility for inductively synthesised endgame expertise"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49637194"
                        ],
                        "name": "A. Mullin",
                        "slug": "A.-Mullin",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Mullin",
                            "middleNames": [
                                "A."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mullin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51083130"
                        ],
                        "name": "F. Rosenblatt",
                        "slug": "F.-Rosenblatt",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Rosenblatt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rosenblatt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 314,
                                "start": 296
                            }
                        ],
                        "text": "Rosenblatt studied the capabilities of groups of neurons in a single layer, and hence all acting on the same input vectors; this structure was termed the Perceptron (Rosenblatt, 1958), and Rosenblatt proposed the Perceptron Learning Rule for learning suitable weights for classification problems (Rosenblatt, 1962)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61566132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cccc0a4817fd5f6d8758c66b4065a23897d49f1d",
            "isKey": false,
            "numCitedBy": 2369,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Principles-of-neurodynamics-Mullin-Rosenblatt",
            "title": {
                "fragments": [],
                "text": "Principles of neurodynamics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145878706"
                        ],
                        "name": "D. Michie",
                        "slug": "D.-Michie",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Michie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Michie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40627186"
                        ],
                        "name": "A. A. Attar",
                        "slug": "A.-A.-Attar",
                        "structuredName": {
                            "firstName": "Amaar",
                            "lastName": "Attar",
                            "middleNames": [
                                "A"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. A. Attar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61861913,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c93dcb60255c67705400d00e6ca745a3d9763dc4",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Use-of-sequential-Bayes-with-class-probability-Michie-Attar",
            "title": {
                "fragments": [],
                "text": "Use of sequential Bayes with class probability trees"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61536073,
            "fieldsOfStudy": [],
            "id": "dd1d8628cb1dc1b1938aa12cf32fb2d4a85948df",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A theory and methodology of inductive learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123962567"
                        ],
                        "name": "M. C. Seiler",
                        "slug": "M.-C.-Seiler",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Seiler",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. C. Seiler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50678756"
                        ],
                        "name": "F. A. Seiler",
                        "slug": "F.-A.-Seiler",
                        "structuredName": {
                            "firstName": "Fritz",
                            "lastName": "Seiler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. A. Seiler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 671,
                                "start": 112
                            }
                        ],
                        "text": "Whereas ID3 cannot tolerate noise, several descendants of ID3 can tolerate noise more effectively (for example, Quinlan, 1987b), which would improve their performance on many noisy data sets. Furthermore, their measure of speed, which simply counted the number of example presentations until asymptotic accuracy was attained, unfairly favours ID3. Whereas the training examples need be given to ID3 only once, they were repeatedly presented to back-propagation to attain asymptotic accuracies. However, their measure ignored that back-propagation\u2019s cost per example presentation is much lower than ID3\u2019s. This measure of speed was later addressed in Fisher et al. (1989), where they defined speed as the product of total example presentations and the cost per presentation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 864,
                                "start": 112
                            }
                        ],
                        "text": "Whereas ID3 cannot tolerate noise, several descendants of ID3 can tolerate noise more effectively (for example, Quinlan, 1987b), which would improve their performance on many noisy data sets. Furthermore, their measure of speed, which simply counted the number of example presentations until asymptotic accuracy was attained, unfairly favours ID3. Whereas the training examples need be given to ID3 only once, they were repeatedly presented to back-propagation to attain asymptotic accuracies. However, their measure ignored that back-propagation\u2019s cost per example presentation is much lower than ID3\u2019s. This measure of speed was later addressed in Fisher et al. (1989), where they defined speed as the product of total example presentations and the cost per presentation. Finally, the only data set with industrial ramifications used in Fisher & McKusick (1989) is the Garvan Institute\u2019s thyroid disease data set."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62717952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e980fbf251ecb28ba85eb092fc66ce284bb63be",
            "isKey": false,
            "numCitedBy": 13115,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Numerical-Recipes-in-C:-The-Art-of-Scientific-Seiler-Seiler",
            "title": {
                "fragments": [],
                "text": "Numerical Recipes in C: The Art of Scientific Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319833"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 207975157,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "56623a496727d5c71491850e04512ddf4152b487",
            "isKey": false,
            "numCitedBy": 4468,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Beyond-Regression-:-\"New-Tools-for-Prediction-and-Werbos",
            "title": {
                "fragments": [],
                "text": "Beyond Regression : \"New Tools for Prediction and Analysis in the Behavioral Sciences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145608771"
                        ],
                        "name": "P. Compton",
                        "slug": "P.-Compton",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Compton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Compton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144664909"
                        ],
                        "name": "K. Horn",
                        "slug": "K.-Horn",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Horn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Horn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2435031"
                        ],
                        "name": "L. Lazarus",
                        "slug": "L.-Lazarus",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Lazarus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lazarus"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61043564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dca815956ad8d908167fff7bf8c85b2ec320f75b",
            "isKey": false,
            "numCitedBy": 243,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Inductive-knowledge-acquisition:-a-case-study-Quinlan-Compton",
            "title": {
                "fragments": [],
                "text": "Inductive knowledge acquisition: a case study"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820860"
                        ],
                        "name": "R. Neapolitan",
                        "slug": "R.-Neapolitan",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Neapolitan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Neapolitan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 27
                            }
                        ],
                        "text": "The proofs can be found in Neapolitan (1990). The first theorem establishes that if c&|2>\u00c1g\" \u00d6 \"L: 5 is a causal network, then :;2>\u00c1 5 can be written as :;2>\u00c1 5'& \u00a6 *2,3- :;2Qz < FK24zP5%5"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59866093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc8b13639c55b4d66693ff3ba3d7dad6548d8216",
            "isKey": false,
            "numCitedBy": 510,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-reasoning-in-expert-systems-Neapolitan",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in expert systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2758080"
                        ],
                        "name": "R. Scheines",
                        "slug": "R.-Scheines",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Scheines",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Scheines"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143648560"
                        ],
                        "name": "P. Spirtes",
                        "slug": "P.-Spirtes",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Spirtes",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Spirtes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3058012"
                        ],
                        "name": "C. Glymour",
                        "slug": "C.-Glymour",
                        "structuredName": {
                            "firstName": "Clark",
                            "lastName": "Glymour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Glymour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50004012"
                        ],
                        "name": "Christopher Meek",
                        "slug": "Christopher-Meek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Meek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Meek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59895207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c1e4840512da8055aab637e8f68f1473f411138",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "TETRAD-II:-Tools-for-Discovery-Scheines-Spirtes",
            "title": {
                "fragments": [],
                "text": "TETRAD II: Tools for Discovery"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66693357"
                        ],
                        "name": "Turing Am",
                        "slug": "Turing-Am",
                        "structuredName": {
                            "firstName": "Turing",
                            "lastName": "Am",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Turing Am"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59260125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ddb8dc30e9485f213ef2810e34ca6cc9adcf336a",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lecture-to-the-London-Mathematical-Society-on-20-Am",
            "title": {
                "fragments": [],
                "text": "Lecture to the London Mathematical Society on 20 February 1947. 1986."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "67012519"
                        ],
                        "name": "S. J. Farlow",
                        "slug": "S.-J.-Farlow",
                        "structuredName": {
                            "firstName": "Stanley",
                            "lastName": "Farlow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. J. Farlow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 12
                            }
                        ],
                        "text": "I'd suggest Polynomial Networks (Farlow, 1984; Elder & Brown, 1994), Multivariate Adaptive Regression Splines (MARS), Generalized Additive Models (Hastie & Tibshirani, 1990), multilinear trees (e.g., OC1; Murthy et al., 1994), and piecewise methods such as Constrained Topological Maps (Mulier, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 80
                            }
                        ],
                        "text": "Chapter 7 (18 pgs.) describes how the methods were compared, outlining the error estimation techniques of train-and-test, cross-validation, and the bootstrap (though the last was not used)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 33
                            }
                        ],
                        "text": "I'd suggest Polynomial Networks (Farlow, 1984; Elder & Brown, 1994), Multivariate Adaptive Regression Splines (MARS), Generalized Additive Models (Hastie & Tibshirani, 1990), multilinear trees (e.g., OC1; Murthy et al., 1994), and piecewise methods such as Constrained Topological Maps (Mulier,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58296089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5b36892f5f29bb318bf4420d5cfdba2d45d1e13",
            "isKey": false,
            "numCitedBy": 551,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Self-Organizing-Methods-in-Modeling:-Gmdh-Type-Farlow",
            "title": {
                "fragments": [],
                "text": "Self-Organizing Methods in Modeling: Gmdh Type Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145549030"
                        ],
                        "name": "J. Andel",
                        "slug": "J.-Andel",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Andel",
                            "middleNames": [
                                "A.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Andel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 182
                            }
                        ],
                        "text": "A related, but more direct, criterion applies Bayesian probability theory to the weighing of evidence (see Good, 1950, for the classical treatment) in a sequential testing framework (Wald, 1947)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 240615,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "18bfe4cd9232f58474eaf91906b46c09f27471a1",
            "isKey": false,
            "numCitedBy": 2282,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "[Sequential-analysis].-Andel",
            "title": {
                "fragments": [],
                "text": "[Sequential analysis]."
            },
            "venue": {
                "fragments": [],
                "text": "Ceskoslovenska fysiologie"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065449379"
                        ],
                        "name": "Christopher J. C. H. Watkins",
                        "slug": "Christopher-J.-C.-H.-Watkins",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Watkins",
                            "middleNames": [
                                "J.",
                                "C.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher J. C. H. Watkins"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 722184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09d53cc7db6f873bfade813183f02db0991aa454",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Combining-Cross-Validation-and-Search-Watkins",
            "title": {
                "fragments": [],
                "text": "Combining Cross-Validation and Search"
            },
            "venue": {
                "fragments": [],
                "text": "EWSL"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685991"
                        ],
                        "name": "M. Odetayo",
                        "slug": "M.-Odetayo",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Odetayo",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Odetayo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624039"
                        ],
                        "name": "D. McGregor",
                        "slug": "D.-McGregor",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "McGregor",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. McGregor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32542496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4561636f0f0702b8fbda253ea70b3c823c6b5727",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Genetic-Algorithm-for-Inducing-Control-Rules-for-a-Odetayo-McGregor",
            "title": {
                "fragments": [],
                "text": "Genetic Algorithm for Inducing Control Rules for a Dynamic System"
            },
            "venue": {
                "fragments": [],
                "text": "ICGA"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lernf\u00e4hige Klassifizierungssysteme"
            },
            "venue": {
                "fragments": [],
                "text": "Akademie-Verlag, Berlin."
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparison of machine learning paradigms in a classification task"
            },
            "venue": {
                "fragments": [],
                "text": "Rzevski, G., editor, Applications of artificial intelligence in engineering V: proceedings of the fifth international conference, Berlin. Springer-Verlag."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluation of an automatic container crane operation system based on predictive fuzzy control"
            },
            "venue": {
                "fragments": [],
                "text": "Control-Theory and Advanced Technology, 2(3):419\u2013432."
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Versuche zur Kreditwurdigkeitsprognose mit kunstlichen Neuronalen Netzen"
            },
            "venue": {
                "fragments": [],
                "text": "Universitat Gottingen."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Transformational systems and the algebraic structure of atomic formulas"
            },
            "venue": {
                "fragments": [],
                "text": "Meltzer, B. and Michie, D., editors, Machine Intelligence 5, pages 153\u2013 163. Edinburgh University Press."
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Is learning rate a good performance criterion of learning? In Proceedings of the Seventh International Machine Learning Conference, pages 170\u2013 178, Austin, Texas"
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 284
                            }
                        ],
                        "text": "\u2026suggest Polynomial Networks (Farlow, 1984; Elder & Brown, 1994), Multivariate Adaptive Regression Splines (MARS), Generalized Additive Models (Hastie & Tibshirani, 1990), multilinear trees (e.g., OC1; Murthy et al., 1994), and piecewise methods such as Constrained Topological Maps (Mulier, 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 257
                            }
                        ],
                        "text": "I'd suggest Polynomial Networks (Farlow, 1984; Elder & Brown, 1994), Multivariate Adaptive Regression Splines (MARS), Generalized Additive Models (Hastie & Tibshirani, 1990), multilinear trees (e.g., OC1; Murthy et al., 1994), and piecewise methods such as Constrained Topological Maps (Mulier, 1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 68
                            }
                        ],
                        "text": ", 1994), and piecewise methods such as Constrained Topological Maps (Mulier, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Analysis of Self-Organization,\" Ph.D. dissertation, Electrical Engineering Department, University of Minnesota"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Graphical models in applied multivariate analysis"
            },
            "venue": {
                "fragments": [],
                "text": "John Wiley, Chichester."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The monk\u2019s comparison of learning algorithms - introduction and survey"
            },
            "venue": {
                "fragments": [],
                "text": "Thrun, S., Bala, J., Bloedorn, E., and Bratko, I., editors, The MONK\u2019s problems - a performance comparison of different learning algorithms, pages 1\u20136. Carnegie Mellon University, Computer Science Department."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine acquisition of concepts from sample data"
            },
            "venue": {
                "fragments": [],
                "text": "Kopec, D. and Thompson, R. B., editors, Artificial Intelligence and Intelligent Tutoring Systems, pages 5 \u2013 23. Ellis Horwood Ltd., Chichester."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 53
                            }
                        ],
                        "text": "DIPOL92 has some similarity with the MADALINE-system (Widrow, 1962) which is also a piecewise linear classification procedure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalization and information in networks of adaline neurons"
            },
            "venue": {
                "fragments": [],
                "text": "Yovits, J. and Goldstein, editors, Self-Organizing Systems, Washington. Spartan Books."
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TETRADII, Tools for discovery"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Constructive learning by specialisation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Conference on Artificial Neural Networks, Helsinki, Finland."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 66
                            }
                        ],
                        "text": "The pole balancing experiments described above, were conducted by Odetayo (1988). This may not be the only way of encoding the problem for a genetic algorithm and so other solutions may be possible."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Balancing a pole-cart system using genetic algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Master\u2019s thesis, Department of Computer Science, University of Strathclyde."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Some spatial statistics for the interpretation of satellite data"
            },
            "venue": {
                "fragments": [],
                "text": "Bull. Int. Stat. Inst., 50:962\u2013971."
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 178
                            }
                        ],
                        "text": "However recurrent networks attract a great deal of research interest becauseof their potential to serve as a vehicle for bringing statistical methods to bear on algorithm design (Rohwer 1991a, 1991b, 1992; Rohwer et al., 1992; Shastri & Ajjanagadde 1993) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards a connectionist reasoning system"
            },
            "venue": {
                "fragments": [],
                "text": "British Telecom Technology Journal, 10:103\u2013109."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An experimental comparison of learning formalisms"
            },
            "venue": {
                "fragments": [],
                "text": "Sixth Internat. Workshop on Mach. Learning, pages 113 \u2013 118, San Mateo, CA. Morgan Kaufmann."
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine learning from real-time input-output behaviour"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the International Conference Design to Manufacture in Modern Industry, pages 363\u2013369."
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 43
                            }
                        ],
                        "text": "The pruned implementation of MARS in Splus (StatSci, 1991) also suffered in a similar way, but a standalone version which also does classification is expected shortly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "S-plus user\u2019s manual"
            },
            "venue": {
                "fragments": [],
                "text": "Technical report, StatSci Europe, Oxford. U.K."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Methods (7th edition)"
            },
            "venue": {
                "fragments": [],
                "text": "Iowa State University Press, Iowa, U.S.A."
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Methoden der automatischen Zeichenerkennung"
            },
            "venue": {
                "fragments": [],
                "text": "Akademie-Verlag, Berlin."
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Knowledge acquisition for dynamic system control"
            },
            "venue": {
                "fragments": [],
                "text": "Sou\u010dek, B., editor, Dynamic, Genetic, and Chaotic Programming, pages 65\u201383. Wiley & Sons."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimal control of container crane"
            },
            "venue": {
                "fragments": [],
                "text": "Automatica, 18(3):257\u2013266."
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A comparison of a neural network based estimator and two statistical estimators in a sparse and noisy environment"
            },
            "venue": {
                "fragments": [],
                "text": "In IJCNN-90: proceedings of the international joint conference on neural networks,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 71
                            }
                        ],
                        "text": "There is a detailed description of this dataset and related results in Wehenkel et al. (1993) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Decision tree based transient stability assessment - a case study"
            },
            "venue": {
                "fragments": [],
                "text": "volume Proceedings of IEEE/PES 1993 Winter Meeting, Columbus, OH, Jan/Feb. 5., pages Paper # 93 WM 235\u20132 PWRS."
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Simplifyingdecision trees"
            },
            "venue": {
                "fragments": [],
                "text": "Int J Man-Machine Studies, 27:221\u2013234."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 20
                            }
                        ],
                        "text": "For example, in the SAS manual (1985) it states that the memory required for nearest neighbour is \u00f1 \u0088 \u0084 \u0308\u00bb \u0082 \u00a4 \u00bb j \u00bb \u0082P\u00f1 n \u0082C1\u20444 j \u00a5\u00ac\u00bb \u0082 \u00f1 \u008c n , i."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Analysis System"
            },
            "venue": {
                "fragments": [],
                "text": "SAS Institute Inc., Cary, NC, version 5 edition."
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 36
                            }
                        ],
                        "text": ", 1989) and constructive algorithms (Wynne-Jones, 1991)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 50
                            }
                        ],
                        "text": "A full review of these techniques can be found in Wynne-Jones (1991)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Constructive algorithms and pruning: Improving the multi layer perceptron"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IMACS \u201991, the 13th World Congress on Computation and Applied Mathematics, Dublin, volume 2, pages 747\u2013750."
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 42,
            "methodology": 26,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 124,
        "totalPages": 13
    },
    "page_url": "https://www.semanticscholar.org/paper/Machine-Learning,-Neural-and-Statistical-Michie-Spiegelhalter/fad1bd501aa769f7701c1016f8a4d1473ca77601?sort=total-citations"
}