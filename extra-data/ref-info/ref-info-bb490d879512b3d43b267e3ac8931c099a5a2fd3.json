{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145328018"
                        ],
                        "name": "M. Oren",
                        "slug": "M.-Oren",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Oren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46597039"
                        ],
                        "name": "P. Sinha",
                        "slug": "P.-Sinha",
                        "structuredName": {
                            "firstName": "Pawan",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[12] much of the previous work on \\Looking at People\" [7] has involved a static camera; initial segmentation was possible by"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7967646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd0534a87e09b3d64b7e7462e2684c60c9aca1f5",
            "isKey": false,
            "numCitedBy": 837,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes. This problem poses several challenges. People are highly non-rigid objects with a high degree of variability in size, shape, color, and texture. Unlike previous approaches, this system learns from examples and does not rely on any a priori (hand-crafted) models or on motion. The detection technique is based on the novel idea of the wavelet template that defines the shape of an object in terms of a subset of the wavelet coefficients of the image. It is invariant to changes in color and texture and can be used to robustly define a rich and complex class of objects such as people. We show how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "slug": "Pedestrian-detection-using-wavelet-templates-Oren-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection using wavelet templates"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper presents a trainable object detection architecture that is applied to detecting people in static images of cluttered scenes and shows how the invariant properties and computational efficiency of the wavelet template make it an effective tool for object detection."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329435"
                        ],
                        "name": "G. Piccioli",
                        "slug": "G.-Piccioli",
                        "structuredName": {
                            "firstName": "Giulia",
                            "lastName": "Piccioli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Piccioli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7409396"
                        ],
                        "name": "E. D. Micheli",
                        "slug": "E.-D.-Micheli",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Micheli",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. D. Micheli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34741785"
                        ],
                        "name": "P. Parodi",
                        "slug": "P.-Parodi",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Parodi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Parodi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35074426"
                        ],
                        "name": "M. Campani",
                        "slug": "M.-Campani",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Campani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Campani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5372532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19aca01bafe52131ec95473dac105889aa6a4d33",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Robust-method-for-road-sign-detection-and-Piccioli-Micheli",
            "title": {
                "fragments": [],
                "text": "Robust method for road sign detection and recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698040"
                        ],
                        "name": "C. Olson",
                        "slug": "C.-Olson",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Olson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Olson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "Yet other extensions deal with multiple feature types [6] [11], consider salience measures [14], or use probabilistic frameworks [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 10
                            }
                        ],
                        "text": "[11] C.F. Olson and D.P. Huttenlocher."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 5
                            }
                        ],
                        "text": "Like Olson, we consider the more general case where we match multiple templates."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Work by Olson [11] discusses a way to avoid matching duplicate points across multiple templates."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 10
                            }
                        ],
                        "text": "[10] C.F. Olson."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "With the exception of [11], previous work on DTbased matching has dealt with the case of matching one template against an image, allowing certain geometrical transformations (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 217564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68acf850d8e73399155963865bf37eaf749f96da",
            "isKey": true,
            "numCitedBy": 401,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes techniques to perform efficient and accurate target recognition in difficult domains. In order to accurately model small, irregularly shaped targets, the target objects and images are represented by their edge maps, with a local orientation associated with each edge pixel. Three dimensional objects are modeled by a set of two-dimensional (2-D) views of the object. Translation, rotation, and scaling of the views are allowed to approximate full three-dimensional (3-D) motion of the object. A version of the Hausdorff measure that incorporates both location and orientation information is used to determine which positions of each object model are reported as possible target locations. These positions are determined efficiently through the examination of a hierarchical cell decomposition of the transformation space. This allows large volumes of the space to be pruned quickly. Additional techniques are used to decrease the computation time required by the method when matching is performed against a catalog of object models. The probability that this measure will yield a false alarm and efficient methods for estimating this probability at run time are considered in detail. This information can be used to maintain a low false alarm rate or to rank competing hypotheses based on their likelihood of being a false alarm. Finally, results of the system recognizing objects in infrared and intensity images are given."
            },
            "slug": "Automatic-target-recognition-by-matching-oriented-Olson-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "Automatic target recognition by matching oriented edge pixels"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This paper describes techniques to perform efficient and accurate target recognition in difficult domains using a version of the Hausdorff measure that incorporates both location and orientation information to determine which positions of each object model are reported as possible target locations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 123
                            }
                        ],
                        "text": "Similarly, 8 distance images were derived from the scene image, so that correlation took place between corresponding types [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Yet other extensions deal with multiple feature types [6] [11], consider salience measures [14], or use probabilistic frameworks [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7668815,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "926b6e939dd72f3d72bf270c4557558e09a66270",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a multi-feature hierarchical algorithm to efficiently match N objects (templates) with am image using distance transforms (DTs). The matching is under translation, but it can cover more general transformations by generating the various transformed templates explicitly. The novel part of the algorithm is that, in addition to a coarse-to-fine search over the translation parameters, the N templates are grouped off-line into a template hierarchy based on their similarity. This way, multiple templates can be matched simultaneously at the coarse levels of the search, resulting in various speed-up factors. Furthermore, in matching, features are distinguished by type and separate DTs are computed for each type (e.g. based on edge orientations). These concepts are illustrated in the application of traffic sign detection."
            },
            "slug": "Multi-feature-hierarchical-template-matching-using-Gavrila",
            "title": {
                "fragments": [],
                "text": "Multi-feature hierarchical template matching using distance transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A multi-feature hierarchical algorithm to efficiently match N objects (templates) with am image using distance transforms (DTs) so that multiple templates can be matched simultaneously at the coarse levels of the search, resulting in various speed-up factors."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698040"
                        ],
                        "name": "C. Olson",
                        "slug": "C.-Olson",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Olson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Olson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16237439,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "2aaca9d558536b1c48625494ff2c1fe43f08e513",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Matching images based on a Hausdorr measure has become popular for computer vision applications. However, no probabilistic model has been used in these applications. This limits the formal treatment of several issues, such as feature uncertainties and prior knowledge. In this paper, we develop a probabilis-tic formulation of image matching in terms of maximum likelihood estimation that generalizes a version of Hausdorr matching. This formulation yields several beneets with respect to previous Hausdorr matching formulations. In addition, we show that the optimal model position in a discretized pose space can be located eeciently in this formation and we apply these techniques to a mobile robot self-localization problem."
            },
            "slug": "A-Probabilistic-Formulation-for-Hausdorr-Matching-Olson",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Formulation for Hausdorr Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A probabilis-tic formulation of image matching in terms of maximum likelihood estimation that generalizes a version of Hausdorr matching and is applied to a mobile robot self-localization problem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733319"
                        ],
                        "name": "G. Borgefors",
                        "slug": "G.-Borgefors",
                        "structuredName": {
                            "firstName": "Gunilla",
                            "lastName": "Borgefors",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Borgefors"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "Some deal with hierarchical approaches to improve match e ciency and use multiple image resolutions [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39521929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "541f734dffb13e95a6b33681187ecd5c626137f5",
            "isKey": false,
            "numCitedBy": 1210,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The algorithm matches edges by minimizing a generalized distance between them. The matching is performed in a series of images depicting the same scene with different resolutions, i.e. in a resolution pyramid. Using this hierarchical structure reduces the computational load significantly. The algorithm is reasonably simple to implement and is insensitive to noise and other disturbances. The algorithm has been tested in several applications. Two of them are briefly presented. In the first application the outlines of common tools are matched to gray-level images of the same tools, with overlapping. In the second application lake edges from aerial photographs are matched to lake edges from a map, with translation, rotation, scale, and perspective changes. The hierarchical chamfer matching algorithm gives correct results using a reasonable amount of computational resources in all tested applications. >"
            },
            "slug": "Hierarchical-Chamfer-Matching:-A-Parametric-Edge-Borgefors",
            "title": {
                "fragments": [],
                "text": "Hierarchical Chamfer Matching: A Parametric Edge Matching Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The hierarchical chamfer matching algorithm matches edges by minimizing a generalized distance between them in a hierarchical structure, i.e. in a resolution pyramid, which reduces the computational load significantly."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696931"
                        ],
                        "name": "H. Barrow",
                        "slug": "H.-Barrow",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Barrow",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144592244"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11843441"
                        ],
                        "name": "H. C. Wolf",
                        "slug": "H.-C.-Wolf",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Wolf",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. C. Wolf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 196
                            }
                        ],
                        "text": "Here is pseudo-C-code for the original (sequential) implementation of the computationally-intensive chamfer transform (with x-y kernel, forward pass, image width W, image height H), adjusted from [1]:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1621080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "358a97112cc60d6bfefb352b863fec8a86a39e28",
            "isKey": false,
            "numCitedBy": 872,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Parametric correspondence is a technique for matching images to a three dimensional symbolic reference map. An analytic camera model is used to predict the location and appearance of landmarks in the image, generating a projection for an assumed viewpoint. Correspondence is achieved by adjusting the parameters of the camera model until the appearances of the landmarks optimally match a symbolic description extracted from the image. \n \nThe matching of image and map features is performed rapidly by a new technique, called \"chamfer matching\", that compares the shapes of two collections of shape fragments, at a cost proportional to linear dimension, rather than area. These two techniques permit the matching of spatially extensive features on the basis of shape, which reduces the risk of ambiguous matches and the dependence on viewing conditions inherent in conventional image based correlation matching."
            },
            "slug": "Parametric-Correspondence-and-Chamfer-Matching:-Two-Barrow-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "Parametric Correspondence and Chamfer Matching: Two New Techniques for Image Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The matching of image and map features is performed rapidly by a new technique, called \"chamfer matching\", that compares the shapes of two collections of shape fragments, at a cost proportional to linear dimension, rather than area."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116003"
                        ],
                        "name": "W. Rucklidge",
                        "slug": "W.-Rucklidge",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Rucklidge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Rucklidge"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "due to occlusion or segmentation errors) by using the average truncated distance or the f-th quantile value (the Hausdor distance) [8] [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "Others use a pruning [13] [8] or a coarse-to- ne approach [15] in the parameter space of relevant template transformations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 38024643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03d6b6cabebef4daafaf18e454087c96207273ce",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The Hausdorff distance is a measure defined between two point sets representing a model and an image. In the past, it has been used to search images for instances of a model that has been translated or translated and scaled by finding transformations that bring a large number of model features close to image features, and vice versa. The Hausdorff distance is reliable even when the image contains multiple objects, noise, spurious features, and occlusions. We apply it to the task of locating an affine transformation of a model in an image; this corresponds to determining the pose of a planar object that has undergone weak perspective projection. We develop a rasterised approach to the search and a number of techniques that allow us to quickly locate all transformations of the model that satisfy two quality criteria; we can also quickly locate only the best transformation. We discuss an implementation of this approach, and present some examples of its use.<<ETX>>"
            },
            "slug": "Locating-objects-using-the-Hausdorff-distance-Rucklidge",
            "title": {
                "fragments": [],
                "text": "Locating objects using the Hausdorff distance"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work develops a rasterised approach to the search and a number of techniques that allow it to quickly locate all transformations of the model that satisfy two quality criteria; it can also quickly locate only the best transformation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698040"
                        ],
                        "name": "C. Olson",
                        "slug": "C.-Olson",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Olson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Olson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "Yet other extensions deal with multiple feature types [6] [11], consider salience measures [14], or use probabilistic frameworks [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 212424568,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "df1dbcf22669f0801ab97f4f8f5960126f10019b",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Matching images based on a Hausdor measure has become popular for computer vision applications. However, no probabilistic model has been used in these applications. This limits the formal treatment of several issues, such as feature uncertainties and prior knowledge. In this paper, we develop a probabilistic formulation of image matching in terms of maximum likelihood estimation that generalizes a version of Hausdor matching. This formulation yields several bene ts with respect to previous Hausdor matching formulations. In addition, we show that the optimal model position in a discretized pose space can be located e ciently in this formation and we apply these techniques to a mobile robot self-localization problem."
            },
            "slug": "A-Probabilistic-Formulation-for-Hausdor-Matching-Olson",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Formulation for Hausdor Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A probabilistic formulation of image matching in terms of maximum likelihood estimation that generalizes a version of Hausdor matching and is applied to a mobile robot self-localization problem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770242"
                        ],
                        "name": "U. Handmann",
                        "slug": "U.-Handmann",
                        "structuredName": {
                            "firstName": "Uwe",
                            "lastName": "Handmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Handmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356391"
                        ],
                        "name": "T. Kalinke",
                        "slug": "T.-Kalinke",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kalinke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kalinke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2986690"
                        ],
                        "name": "C. Tzomakas",
                        "slug": "C.-Tzomakas",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Tzomakas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tzomakas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113434322"
                        ],
                        "name": "M. Werner",
                        "slug": "M.-Werner",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Werner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Werner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8019217"
                        ],
                        "name": "W. Seelen",
                        "slug": "W.-Seelen",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Seelen",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Seelen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6298283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ab5c4962f4ab1aa527f8f881d181f500b40afec",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-image-processing-system-for-driver-assistance-Handmann-Kalinke",
            "title": {
                "fragments": [],
                "text": "An image processing system for driver assistance"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698040"
                        ],
                        "name": "C. Olson",
                        "slug": "C.-Olson",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Olson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Olson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16933450,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "172694e0d249e6900a4389c8d745677840011d8e",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Matching images based on a Hausdorff measure has become popular for computer vision applications. However, no probabilistic model has been used in these applications. This limits the formal treatment of several issues, such as feature uncertainties and prior knowledge. In this paper, we develop a probabilistic formulation of image matching in terms of maximum likelihood estimation that generalizes a version of Hausdorff matching. This formulation yields several benefits with respect to previous Hausdorff matching formulations. In addition, we show that the optimal model position in a discretized pose space can be located efficiently in this formation and we apply these techniques to a mobile robot self-localization problem."
            },
            "slug": "A-probabilistic-formulation-for-Hausdorff-matching-Olson",
            "title": {
                "fragments": [],
                "text": "A probabilistic formulation for Hausdorff matching"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A probabilistic formulation of image matching in terms of maximum likelihood estimation that generalizes a version of Hausdorff matching and is applied to a mobile robot self-localization problem."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145582788"
                        ],
                        "name": "Uwe Franke",
                        "slug": "Uwe-Franke",
                        "structuredName": {
                            "firstName": "Uwe",
                            "lastName": "Franke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uwe Franke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2262044"
                        ],
                        "name": "S. G\u00f6rzig",
                        "slug": "S.-G\u00f6rzig",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "G\u00f6rzig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. G\u00f6rzig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145881356"
                        ],
                        "name": "F. Lindner",
                        "slug": "F.-Lindner",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Lindner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lindner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050256"
                        ],
                        "name": "F. Paetzold",
                        "slug": "F.-Paetzold",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Paetzold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Paetzold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696091"
                        ],
                        "name": "C. W\u00f6hler",
                        "slug": "C.-W\u00f6hler",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "W\u00f6hler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. W\u00f6hler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3132403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9aee6f7927d6ec8df47407a050629026cf67a149",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Most computer-vision systems for vehicle guidance are for highway scenarios. Developing autonomous or driver-assistance systems for complex urban traffic poses new algorithmic and system-architecture challenges. To address these issues, the authors introduce their intelligent Stop&Go system and discuss appropriate algorithms and approaches for vision-module control."
            },
            "slug": "Autonomous-Driving-Goes-Downtown-Franke-Gavrila",
            "title": {
                "fragments": [],
                "text": "Autonomous Driving Goes Downtown"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The authors introduce their intelligent Stop&Go system and discuss appropriate algorithms and approaches for vision-module control."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intell. Syst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679710"
                        ],
                        "name": "D. Paglieroni",
                        "slug": "D.-Paglieroni",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Paglieroni",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paglieroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1928962"
                        ],
                        "name": "G. Ford",
                        "slug": "G.-Ford",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Ford",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516062"
                        ],
                        "name": "Eric M. Tsujimoto",
                        "slug": "Eric-M.-Tsujimoto",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Tsujimoto",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric M. Tsujimoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Others use a pruning [13] [8] or a coarse-to- ne approach [15] in the parameter space of relevant template transformations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 44547602,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "bff57b81ce8c940c75d85ea5b000be62eaa11a90",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A new search method over (x,y,/spl theta/), called position-orientation masking is introduced. It is applied to vertices that are allowed to be separated into different bands of acuteness. Position-orientation masking yields exactly one /spl theta/ value for each (x,y) that it considers to be the location of a possible occurrence of an object. Detailed matching of edge segments is performed at only these candidate (x,y,/spl theta/) to determine if objects actually do occur there. Template matching is accelerated dramatically since the candidates comprise only a small fraction of all (x,y,/spl theta/). Position-orientation masking eliminates the need for exhaustive search when deriving the candidate (x,y,/spl theta/). Search is guided by correlations between template vertices and distance transforms of image vertices. When a poor correlation is encountered at a particular position and orientation, nearby positions at that orientation and nearby orientations at that position are masked out. Position and orientation traversal are by quadrant and binary decomposition. >"
            },
            "slug": "The-Position-Orientation-Masking-Approach-to-Search-Paglieroni-Ford",
            "title": {
                "fragments": [],
                "text": "The Position-Orientation Masking Approach to Parametric Search for Template Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A new search method over (x,y,/spl theta/), called position-orientation masking is introduced, which is applied to vertices that are allowed to be separated into different bands of acuteness."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 84
                            }
                        ],
                        "text": "Note that with a few exceptions (e.g. [12] much of the previous work on \\Looking at People\" [7] has involved a static camera; initial segmentation was possible by\nbackground subtraction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "[12] much of the previous work on \\Looking at People\" [7] has involved a static camera; initial segmentation was possible by"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7788290,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4e4b41b6010ac1e6c90791168f57bcd75b696ab",
            "isKey": false,
            "numCitedBy": 2210,
            "numCiting": 145,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to recognize humans and their activities by vision is key for a machine to interact intelligently and effortlessly with a human-inhabited environment. Because of many potentially important applications, \u201clooking at people\u201d is currently one of the most active application domains in computer vision. This survey identifies a number of promising applications and provides an overview of recent developments in this domain. The scope of this survey is limited to work on whole-body or hand motion; it does not include work on human faces. The emphasis is on discussing the various methodologies; they are grouped in 2-D approaches with or without explicit shape models and 3-D approaches. Where appropriate, systems are reviewed. We conclude with some thoughts about future directions."
            },
            "slug": "The-Visual-Analysis-of-Human-Movement:-A-Survey-Gavrila",
            "title": {
                "fragments": [],
                "text": "The Visual Analysis of Human Movement: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A number of promising applications are identified and an overview of recent developments in this domain is provided, including work on whole-body or hand motion and the various methodologies."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734823"
                        ],
                        "name": "Paul L. Rosin",
                        "slug": "Paul-L.-Rosin",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Rosin",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul L. Rosin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145227675"
                        ],
                        "name": "G. West",
                        "slug": "G.-West",
                        "structuredName": {
                            "firstName": "Geoff",
                            "lastName": "West",
                            "middleNames": [
                                "A.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. West"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Yet other extensions deal with multiple feature types [6] [11], consider salience measures [14], or use probabilistic frameworks [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9453886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7822f0f721e57ec8144cfb86f7046d0c3bcec533",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The distance transform has been used in computer vision for a number of applications such as matching and skeletonization. This paper proposes two things: (1) a multiscale distance transform to overcome the need to choose the appropriate scale and (2) the addition of various saliency factors such as edge strength, length, and curvature to the basic distance transform to eliminate the need for (e.g., edge magnitude) thresholds and to improve its effectiveness. Results are presented for applications of matching and snake fitting."
            },
            "slug": "Salience-Distance-Transforms-Rosin-West",
            "title": {
                "fragments": [],
                "text": "Salience Distance Transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A multiscale distance transform is proposed to overcome the need to choose the appropriate scale and the addition of various saliency factors such as edge strength, length, and curvature to the basic distance transform to eliminate the need for thresholds and to improve its effectiveness."
            },
            "venue": {
                "fragments": [],
                "text": "CVGIP Graph. Model. Image Process."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901136"
                        ],
                        "name": "G. Klanderman",
                        "slug": "G.-Klanderman",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Klanderman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Klanderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116003"
                        ],
                        "name": "W. Rucklidge",
                        "slug": "W.-Rucklidge",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Rucklidge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Rucklidge"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 131
                            }
                        ],
                        "text": "due to occlusion or segmentation errors) by using the average truncated distance or the f-th quantile value (the Hausdor distance) [8] [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "Other extensions involve the use of a un-directed (\"symmetric\") similarity measure between image and a template [8] (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Others use a pruning [13] [8] or a coarse-to- ne approach [15] in the parameter space of relevant template transformations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8027136,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "85efeeb25d8e363606d94c8fadaa922ba9b93a37",
            "isKey": false,
            "numCitedBy": 3912,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The Hausdorff distance measures the extent to which each point of a model set lies near some point of an image set and vice versa. Thus, this distance can be used to determine the degree of resemblance between two objects that are superimposed on one another. Efficient algorithms for computing the Hausdorff distance between all possible relative positions of a binary image and a model are presented. The focus is primarily on the case in which the model is only allowed to translate with respect to the image. The techniques are extended to rigid motion. The Hausdorff distance computation differs from many other shape comparison methods in that no correspondence between the model and the image is derived. The method is quite tolerant of small position errors such as those that occur with edge detectors and other feature extraction methods. It is shown that the method extends naturally to the problem of comparing a portion of a model against an image. >"
            },
            "slug": "Comparing-Images-Using-the-Hausdorff-Distance-Huttenlocher-Klanderman",
            "title": {
                "fragments": [],
                "text": "Comparing Images Using the Hausdorff Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Efficient algorithms for computing the Hausdorff distance between all possible relative positions of a binary image and a model are presented and it is shown that the method extends naturally to the problem of comparing a portion of a model against an image."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145847131"
                        ],
                        "name": "S. Kirkpatrick",
                        "slug": "S.-Kirkpatrick",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Kirkpatrick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kirkpatrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5882723"
                        ],
                        "name": "C. D. Gelatt",
                        "slug": "C.-D.-Gelatt",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Gelatt",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Gelatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88645967"
                        ],
                        "name": "M. Vecchi",
                        "slug": "M.-Vecchi",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Vecchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vecchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "We use simulated annealing [9] to perform the minimization of E."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 129
                            }
                        ],
                        "text": "where T is the temperature parameter which is adjusted according to a certain \\cooling\" schedule (we use an exponential schedule [9])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205939,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dd5061631a4d11fa394f4421700ebf7e78dcbc59",
            "isKey": false,
            "numCitedBy": 39636,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods."
            },
            "slug": "Optimization-by-Simulated-Annealing-Kirkpatrick-Gelatt",
            "title": {
                "fragments": [],
                "text": "Optimization by Simulated Annealing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An image processing system for driver assistance Autonomous driving goes downtown"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of Intelligent Vehicles Conference"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gelatt , and M . P . Vecchi . Optimization by simulated annealing"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Salience distance transforms . GMIP, 576:4833521, November 1995. 155 W. Rucklidge. Locating objects using the hausdorr distance"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimization by s i m ulated annealing"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. of the International Joint Conference o n A rtiicial Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the International Joint Conference o n A rtiicial Intelligence"
            },
            "year": 1977
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 8,
            "methodology": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 22,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Real-time-object-detection-for-\"smart\"-vehicles-Gavrila-Philomin/bb490d879512b3d43b267e3ac8931c099a5a2fd3?sort=total-citations"
}