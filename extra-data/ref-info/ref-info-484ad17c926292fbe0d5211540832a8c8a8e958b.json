{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144717963"
                        ],
                        "name": "Karol Gregor",
                        "slug": "Karol-Gregor",
                        "structuredName": {
                            "firstName": "Karol",
                            "lastName": "Gregor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karol Gregor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841008"
                        ],
                        "name": "Ivo Danihelka",
                        "slug": "Ivo-Danihelka",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Danihelka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivo Danihelka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714004"
                        ],
                        "name": "A. Mnih",
                        "slug": "A.-Mnih",
                        "structuredName": {
                            "firstName": "Andriy",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723876"
                        ],
                        "name": "C. Blundell",
                        "slug": "C.-Blundell",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Blundell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Blundell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 41
                            }
                        ],
                        "text": ", 1996) and deep autoregressive networks (Gregor et al., 2014), which use auto-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 107
                            }
                        ],
                        "text": "Other related models include sigmoid belief networks (Saul et al., 1996) and deep autoregressive networks (Gregor et al., 2014), which use auto-\nregressive Bernoulli distributions at each layer instead of Gaussian distributions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 52
                            }
                        ],
                        "text": "1996; Bartholomew & Knott, 1999; Uria et al., 2014; Gregor et al., 2014) can be easily sampled from, but in most cases, efficient inference algorithms have remained elusive."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14576846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "695a2c95eacdbccb7a73d2f1e90e7b35b4b3d864",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a deep, generative autoencoder capable of learning hierarchies of distributed representations from data. Successive deep stochastic hidden layers are equipped with autoregressive connections, which enable the model to be sampled from quickly and exactly via ancestral sampling. We derive an efficient approximate parameter estimation method based on the minimum description length (MDL) principle, which can be seen as maximising a variational lower bound on the log-likelihood, with a feedforward neural network implementing approximate inference. We demonstrate state-of-the-art generative performance on a number of classic data sets, including several UCI data sets, MNIST and Atari 2600 games."
            },
            "slug": "Deep-AutoRegressive-Networks-Gregor-Danihelka",
            "title": {
                "fragments": [],
                "text": "Deep AutoRegressive Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An efficient approximate parameter estimation method based on the minimum description length (MDL) principle is derived, which can be seen as maximising a variational lower bound on the log-likelihood, with a feedforward neural network implementing approximate inference."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 30
                            }
                        ],
                        "text": "Concurrently with this paper, Kingma & Welling (2014) present an alternative discussion of stochastic backpropagation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 216078090,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f5dc5b9a2ba710937e2c413b37b053cd673df02",
            "isKey": false,
            "numCitedBy": 16786,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract: How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results."
            },
            "slug": "Auto-Encoding-Variational-Bayes-Kingma-Welling",
            "title": {
                "fragments": [],
                "text": "Auto-Encoding Variational Bayes"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398746441"
                        ],
                        "name": "Eric Thibodeau-Laufer",
                        "slug": "Eric-Thibodeau-Laufer",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Thibodeau-Laufer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Thibodeau-Laufer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815021"
                        ],
                        "name": "Guillaume Alain",
                        "slug": "Guillaume-Alain",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Alain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guillaume Alain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2965424"
                        ],
                        "name": "J. Yosinski",
                        "slug": "J.-Yosinski",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Yosinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yosinski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 99
                            }
                        ],
                        "text": "DAEs can also be used as generative models by simulating from a Markov chain (Bengio et al., 2013; Bengio & Thibodeau-Laufer, 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9494295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ffa8bf1bf3e39227be28de4ff6915d3b21eb52d",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel training principle for probabilistic models that is an alternative to maximum likelihood. The proposed Generative Stochastic Networks (GSN) framework is based on learning the transition operator of a Markov chain whose stationary distribution estimates the data distribution. The transition distribution of the Markov chain is conditional on the previous state, generally involving a small move, so this conditional distribution has fewer dominant modes, being unimodal in the limit of small moves. Thus, it is easier to learn because it is easier to approximate its partition function, more like learning to perform supervised function approximation, with gradients that can be obtained by backprop. We provide theorems that generalize recent work on the probabilistic interpretation of denoising autoencoders and obtain along the way an interesting justification for dependency networks and generalized pseudolikelihood, along with a definition of an appropriate joint distribution and sampling mechanism even when the conditionals are not consistent. GSNs can be used with missing inputs and can be used to sample subsets of variables given the rest. We validate these theoretical results with experiments on two image datasets using an architecture that mimics the Deep Boltzmann Machine Gibbs sampler but allows training to proceed with simple backprop, without the need for layerwise pretraining."
            },
            "slug": "Deep-Generative-Stochastic-Networks-Trainable-by-Bengio-Thibodeau-Laufer",
            "title": {
                "fragments": [],
                "text": "Deep Generative Stochastic Networks Trainable by Backprop"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Theorems that generalize recent work on the probabilistic interpretation of denoising autoencoders are provided and obtain along the way an interesting justification for dependency networks and generalized pseudolikelihood."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28552618"
                        ],
                        "name": "M. Hoffman",
                        "slug": "M.-Hoffman",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108881999"
                        ],
                        "name": "Chong Wang",
                        "slug": "Chong-Wang",
                        "structuredName": {
                            "firstName": "Chong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143855009"
                        ],
                        "name": "J. Paisley",
                        "slug": "J.-Paisley",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Paisley",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Paisley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 268,
                                "start": 248
                            }
                        ],
                        "text": "A number of approaches are known and widely used, and include: mean-field variational EM (Beal, 2003); the wake-sleep algorithm (Dayan, 2000); and stochastic variational methods and related control-variate estimators (Wilson, 1984; Williams, 1992; Hoffman et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 344,
                                "start": 253
                            }
                        ],
                        "text": "One popular approach is the REINFORCE algorithm (Williams, 1992), since it is simple to implement and applicable to both discrete and continuous models, though control variate methods are becoming increasingly popular for variational inference problems (Hoffman et al., 2013; Blei et al., 2012; Ranganath et al., 2014; Salimans & Knowles, 2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 207
                            }
                        ],
                        "text": "\u2026(Williams, 1992), since it is simple to implement and applicable to both discrete and continuous models, though control variate methods are becoming increasingly popular for variational inference problems (Hoffman et al., 2013; Blei et al., 2012; Ranganath et al., 2014; Salimans & Knowles, 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5652538,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bccb2f99a9d1c105699f5d88c479569085e2c7ba",
            "isKey": false,
            "numCitedBy": 2014,
            "numCiting": 133,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets."
            },
            "slug": "Stochastic-variational-inference-Hoffman-Blei",
            "title": {
                "fragments": [],
                "text": "Stochastic variational inference"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Stochastic variational inference lets us apply complex Bayesian models to massive data sets, and it is shown that the Bayesian nonparametric topic model outperforms its parametric counterpart."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The computational complexity per training sample during training is also O(LK\u03042) \u2013 the same as that of matching auto-encoder."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2178983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aeed631d6a84100b5e9a021ec1914095c66de415",
            "isKey": false,
            "numCitedBy": 1701,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic gradient optimization algorithm we show that the iterates will converge to samples from the true posterior distribution as we anneal the stepsize. This seamless transition between optimization and Bayesian posterior sampling provides an inbuilt protection against overfitting. We also propose a practical method for Monte Carlo estimates of posterior statistics which monitors a \"sampling threshold\" and collects samples after it has been surpassed. We apply the method to three models: a mixture of Gaussians, logistic regression and ICA with natural gradients."
            },
            "slug": "Bayesian-Learning-via-Stochastic-Gradient-Langevin-Welling-Teh",
            "title": {
                "fragments": [],
                "text": "Bayesian Learning via Stochastic Gradient Langevin Dynamics"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper proposes a new framework for learning from large scale datasets based on iterative learning from small mini-batches by adding the right amount of noise to a standard stochastic gradient optimization algorithm and shows that the iterates will converge to samples from the true posterior distribution as the authors anneal the stepsize."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3106771"
                        ],
                        "name": "A. Damianou",
                        "slug": "A.-Damianou",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Damianou",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Damianou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145306271"
                        ],
                        "name": "Neil D. Lawrence",
                        "slug": "Neil-D.-Lawrence",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Lawrence",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neil D. Lawrence"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 88
                            }
                        ],
                        "text": "The Gaussian process latent variable model and deep Gaussian processes (Lawrence, 2005; Damianou & Lawrence, 2013) form the non-parametric analogue of our model and employ Gaussian process priors over the non-linear functions between each layer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5945613,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5f5ed292ce93404a0985754b2b531eca4e6cf50",
            "isKey": false,
            "numCitedBy": 766,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce deep Gaussian process (GP) models. Deep GPs are a deep belief network based on Gaussian process mappings. The data is modeled as the output of a multivariate GP. The inputs to that Gaussian process are then governed by another GP. A single layer model is equivalent to a standard GP or the GP latent variable model (GP-LVM). We perform inference in the model by approximate variational marginalization. This results in a strict lower bound on the marginal likelihood of the model which we use for model selection (number of layers and nodes per layer). Deep belief networks are typically applied to relatively large data sets using stochastic gradient descent for optimization. Our fully Bayesian treatment allows for the application of deep models even when data is scarce. Model selection by our variational bound shows that a five layer hierarchy is justified even when modelling a digit data set containing only 150 examples."
            },
            "slug": "Deep-Gaussian-Processes-Damianou-Lawrence",
            "title": {
                "fragments": [],
                "text": "Deep Gaussian Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Deep Gaussian process (GP) models are introduced and model selection by the variational bound shows that a five layer hierarchy is justified even when modelling a digit data set containing only 150 examples."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2825051"
                        ],
                        "name": "B. Uria",
                        "slug": "B.-Uria",
                        "structuredName": {
                            "firstName": "Benigno",
                            "lastName": "Uria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Uria"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145797336"
                        ],
                        "name": "Iain Murray",
                        "slug": "Iain-Murray",
                        "structuredName": {
                            "firstName": "Iain",
                            "lastName": "Murray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iain Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 80
                            }
                        ],
                        "text": "The neural auto-regressive density estimator (NADE) (Larochelle & Murray, 2011; Uria et al., 2014) uses function approximation to model conditional distributions within a directed acyclic graph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 36
                            }
                        ],
                        "text": "We used the binarised dataset as in Uria et al. (2014) and quote the log-likelihoods in the lower part of the table from this work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "NADE is amongst the most competitive generative models currently available, but has several limitations, such as the inability to allow for deep representations and difficulties in extending to locally-connected models (e.g., through the use of convolutional layers), preventing it from scaling easily to high-dimensional data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 33
                            }
                        ],
                        "text": "1996; Bartholomew & Knott, 1999; Uria et al., 2014; Gregor et al., 2014) can be easily sampled from, but in most cases, efficient inference algorithms have remained elusive."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13147238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "705fd4febe2fff810d2f72f48dcda20826eca77a",
            "isKey": true,
            "numCitedBy": 137,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The Neural Autoregressive Distribution Estimator (NADE) and its real-valued version RNADE are competitive density models of multidimensional data across a variety of domains. These models use a fixed, arbitrary ordering of the data dimensions. One can easily condition on variables at the beginning of the ordering, and marginalize out variables at the end of the ordering, however other inference tasks require approximate inference. In this work we introduce an efficient procedure to simultaneously train a NADE model for each possible ordering of the variables, by sharing parameters across all these models. We can thus use the most convenient model for each inference task at hand, and ensembles of such models with different orderings are immediately available. Moreover, unlike the original NADE, our training procedure scales to deep models. Empirically, ensembles of Deep NADE models obtain state of the art density estimation performance."
            },
            "slug": "A-Deep-and-Tractable-Density-Estimator-Uria-Murray",
            "title": {
                "fragments": [],
                "text": "A Deep and Tractable Density Estimator"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work introduces an efficient procedure to simultaneously train a NADE model for each possible ordering of the variables, by sharing parameters across all these models."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 153
                            }
                        ],
                        "text": "These identities have been recognised by Opper & Archambeau (2009) for variational inference in Gaussian process regression, and following this work, by Graves (2011) for parameter learning in large neural networks."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14885866,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a9ef216bf11f222438fff130c778267d39a9564",
            "isKey": false,
            "numCitedBy": 1074,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Variational methods have been previously explored as a tractable approximation to Bayesian inference for neural networks. However the approaches proposed so far have only been applicable to a few simple network architectures. This paper introduces an easy-to-implement stochastic variational method (or equivalently, minimum description length loss function) that can be applied to most neural networks. Along the way it revisits several common regularisers from a variational perspective. It also provides a simple pruning heuristic that can both drastically reduce the number of network weights and lead to improved generalisation. Experimental results are provided for a hierarchical multidimensional recurrent neural network applied to the TIMIT speech corpus."
            },
            "slug": "Practical-Variational-Inference-for-Neural-Networks-Graves",
            "title": {
                "fragments": [],
                "text": "Practical Variational Inference for Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces an easy-to-implement stochastic variational method (or equivalently, minimum description length loss function) that can be applied to most neural networks and revisits several common regularisers from a variational perspective."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143855009"
                        ],
                        "name": "J. Paisley",
                        "slug": "J.-Paisley",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Paisley",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Paisley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1758804,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ceb1dea15ac3df3d610fd0b3cc52b9a4e9141a3",
            "isKey": false,
            "numCitedBy": 385,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Mean-field variational inference is a method for approximate Bayesian posterior inference. It approximates a full posterior distribution with a factorized set of distributions by maximizing a lower bound on the marginal likelihood. This requires the ability to integrate a sum of terms in the log joint likelihood using this factorized distribution. Often not all integrals are in closed form, which is typically handled by using a lower bound. We present an alternative algorithm based on stochastic optimization that allows for direct optimization of the variational lower bound. This method uses control variates to reduce the variance of the stochastic search gradient, in which existing lower bounds can play an important role. We demonstrate the approach on two non-conjugate models: logistic regression and an approximation to the HDP."
            },
            "slug": "Variational-Bayesian-Inference-with-Stochastic-Paisley-Blei",
            "title": {
                "fragments": [],
                "text": "Variational Bayesian Inference with Stochastic Search"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents an alternative algorithm based on stochastic optimization that allows for direct optimization of the variational lower bound and demonstrates the approach on two non-conjugate models: logistic regression and an approximation to the HDP."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145766200"
                        ],
                        "name": "A. Honkela",
                        "slug": "A.-Honkela",
                        "structuredName": {
                            "firstName": "Antti",
                            "lastName": "Honkela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Honkela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2132516"
                        ],
                        "name": "H. Valpola",
                        "slug": "H.-Valpola",
                        "structuredName": {
                            "firstName": "Harri",
                            "lastName": "Valpola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Valpola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 99
                            }
                        ],
                        "text": "An important family of alternative estimators is based on quadrature and series expansion methods (Honkela & Valpola, 2004; Lappalainen & Honkela, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 802355,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ae2e4e974f7ee57f590a691aada75c27c4c5394",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a framework for using multi-layer perceptron (MLP) networks in nonlinear generative models trained by variational Bayesian learning. The nonlinearity is handled by linearizing it using a Gauss-Hermite quadrature at the hidden neurons. This yields an accurate approximation for cases of large posterior variance. The method can be used to derive nonlinear counterparts for linear algorithms such as factor analysis, independent component/factor analysis and state-space models. This is demonstrated with a nonlinear factor analysis experiment in which even 20 sources can be estimated from a real world speech data set."
            },
            "slug": "Unsupervised-Variational-Bayesian-Learning-of-Honkela-Valpola",
            "title": {
                "fragments": [],
                "text": "Unsupervised Variational Bayesian Learning of Nonlinear Models"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper presents a framework for using multi-layer perceptron (MLP) networks in nonlinear generative models trained by variational Bayesian learning using a Gauss-Hermite quadrature at the hidden neurons for accurate approximation for cases of large posterior variance."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773821"
                        ],
                        "name": "Matthew J. Beal",
                        "slug": "Matthew-J.-Beal",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Beal",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew J. Beal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 216
                            }
                        ],
                        "text": "\u2026for integrals; we provide the proofs for these identities in appendix B.\nEquations (7) and (8) are especially interesting since they allow for unbiased gradient estimates by using a small number of samples from q. Assume that both the mean \u00b5 and covariance matrix C depend on a parameter vector \u03b8."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11861569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00cf63a7926a826f7cf73c1d5edb117f98d70c2c",
            "isKey": false,
            "numCitedBy": 1836,
            "numCiting": 181,
            "paperAbstract": {
                "fragments": [],
                "text": "The Bayesian framework for machine learning allows for the incorporation of prior knowledge in a coherent way, avoids overfitting problems, and provides a principled basis for selecting between alternative models. Unfortunately the computations required are usually intractable. This thesis presents a unified variational Bayesian (VB) framework which approximates these computations in models with latent variables using a lower bound on the marginal likelihood. Chapter 1 presents background material on Bayesian inference, graphical models, and propagation algorithms. Chapter 2 forms the theoretical core of the thesis, generalising the expectationmaximisation (EM) algorithm for learning maximum likelihood parameters to the VB EM algorithm which integrates over model parameters. The algorithm is then specialised to the large family of conjugate-exponential (CE) graphical models, and several theorems are presented to pave the road for automated VB derivation procedures in both directed and undirected graphs (Bayesian and Markov networks, respectively). Chapters 3-5 derive and apply the VB EM algorithm to three commonly-used and important models: mixtures of factor analysers, linear dynamical systems, and hidden Markov models. It is shown how model selection tasks such as determining the dimensionality, cardinality, or number of variables are possible using VB approximations. Also explored are methods for combining sampling procedures with variational approximations, to estimate the tightness of VB bounds and to obtain more effective sampling algorithms. Chapter 6 applies VB learning to a long-standing problem of scoring discrete-variable directed acyclic graphs, and compares the performance to annealed importance sampling amongst other methods. Throughout, the VB approximation is compared to other methods including sampling, Cheeseman-Stutz, and asymptotic approximations such as BIC. The thesis concludes with a discussion of evolving directions for model selection including infinite models and alternative approximations to the marginal likelihood."
            },
            "slug": "Variational-algorithms-for-approximate-Bayesian-Beal",
            "title": {
                "fragments": [],
                "text": "Variational algorithms for approximate Bayesian inference"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A unified variational Bayesian (VB) framework which approximates computations in models with latent variables using a lower bound on the marginal likelihood and is compared to other methods including sampling, Cheeseman-Stutz, and asymptotic approximations such as BIC."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145797336"
                        ],
                        "name": "Iain Murray",
                        "slug": "Iain-Murray",
                        "structuredName": {
                            "firstName": "Iain",
                            "lastName": "Murray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iain Murray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 53
                            }
                        ],
                        "text": "The neural auto-regressive density estimator (NADE) (Larochelle & Murray, 2011; Uria et al., 2014) uses function approximation to model conditional distributions within a directed acyclic graph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "NADE is amongst the most competitive generative models currently available, but has several limitations, such as the inability to allow for deep representations and difficulties in extending to locally-connected models (e.g., through the use of convolutional layers), preventing it from scaling easily to high-dimensional data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 123
                            }
                        ],
                        "text": "We use sampling to evaluate the true posterior distribution for a number of MNIST digits using the binarised data set from Larochelle & Murray (2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13975441,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32f078a7478d1ec2169599500a4507aceaccdda7",
            "isKey": false,
            "numCitedBy": 469,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new approach for modeling the distribution of high-dimensional vectors of discrete variables. This model is inspired by the restricted Boltzmann machine (RBM), which has been shown to be a powerful model of such distributions. However, an RBM typically does not provide a tractable distribution estimator, since evaluating the probability it assigns to some given observation requires the computation of the so-called partition function, which itself is intractable for RBMs of even moderate size. Our model circumvents this diculty by decomposing the joint distribution of observations into tractable conditional distributions and modeling each conditional using a non-linear function similar to a conditional of an RBM. Our model can also be interpreted as an autoencoder wired such that its output can be used to assign valid probabilities to observations. We show that this new model outperforms other multivariate binary distribution estimators on several datasets and performs similarly to a large (but intractable) RBM."
            },
            "slug": "The-Neural-Autoregressive-Distribution-Estimator-Larochelle-Murray",
            "title": {
                "fragments": [],
                "text": "The Neural Autoregressive Distribution Estimator"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new approach for modeling the distribution of high-dimensional vectors of discrete variables inspired by the restricted Boltzmann machine, which outperforms other multivariate binary distribution estimators on several datasets and performs similarly to a large (but intractable) RBM."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764325"
                        ],
                        "name": "Radford M. Neal",
                        "slug": "Radford-M.-Neal",
                        "structuredName": {
                            "firstName": "Radford",
                            "lastName": "Neal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radford M. Neal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 56
                            }
                        ],
                        "text": "A very general alternative is the wake-sleep algorithm (Dayan et al., 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 76
                            }
                        ],
                        "text": "Directed models such as belief networks and similar latent variable models (Dayan et al., 1995; Frey, 1996; Saul et al.,\nProceedings of the 31 st International Conference on Machine Learning, Beijing, China, 2014."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1890561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "605402e235bd62437baf3c9ebefe77fb4d92ee95",
            "isKey": false,
            "numCitedBy": 1173,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Discovering the structure inherent in a set of patterns is a fundamental aim of statistical inference or learning. One fruitful approach is to build a parameterized stochastic generative model, independent draws from which are likely to produce the patterns. For all but the simplest generative models, each pattern can be generated in exponentially many ways. It is thus intractable to adjust the parameters to maximize the probability of the observed patterns. We describe a way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations. Our method can be viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways."
            },
            "slug": "The-Helmholtz-Machine-Dayan-Hinton",
            "title": {
                "fragments": [],
                "text": "The Helmholtz Machine"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations is described, viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2615814"
                        ],
                        "name": "R. Ranganath",
                        "slug": "R.-Ranganath",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Ranganath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ranganath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21007048"
                        ],
                        "name": "S. Gerrish",
                        "slug": "S.-Gerrish",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Gerrish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gerrish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 344,
                                "start": 253
                            }
                        ],
                        "text": "One popular approach is the REINFORCE algorithm (Williams, 1992), since it is simple to implement and applicable to both discrete and continuous models, though control variate methods are becoming increasingly popular for variational inference problems (Hoffman et al., 2013; Blei et al., 2012; Ranganath et al., 2014; Salimans & Knowles, 2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 248
                            }
                        ],
                        "text": "\u2026(Williams, 1992), since it is simple to implement and applicable to both discrete and continuous models, though control variate methods are becoming increasingly popular for variational inference problems (Hoffman et al., 2013; Blei et al., 2012; Ranganath et al., 2014; Salimans & Knowles, 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1580089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a667700100e228cb30a5d884258a0db921603fe",
            "isKey": false,
            "numCitedBy": 845,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Variational inference has become a widely used method to approximate posteriors in complex latent variables models. However, deriving a variational inference algorithm generally requires significant model-specific analysis, and these efforts can hinder and deter us from quickly developing and exploring a variety of models for a problem at hand. In this paper, we present a \"black box\" variational inference algorithm, one that can be quickly applied to many models with little additional derivation. Our method is based on a stochastic optimization of the variational objective where the noisy gradient is computed from Monte Carlo samples from the variational distribution. We develop a number of methods to reduce the variance of the gradient, always maintaining the criterion that we want to avoid difficult model-based derivations. We evaluate our method against the corresponding black box sampling based methods. We find that our method reaches better predictive likelihoods much faster than sampling methods. Finally, we demonstrate that Black Box Variational Inference lets us easily explore a wide space of models by quickly constructing and evaluating several models of longitudinal healthcare data."
            },
            "slug": "Black-Box-Variational-Inference-Ranganath-Gerrish",
            "title": {
                "fragments": [],
                "text": "Black Box Variational Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents a \"black box\" variational inference algorithm, one that can be quickly applied to many models with little additional derivation, based on a stochastic optimization of the variational objective where the noisy gradient is computed from Monte Carlo samples from the Variational distribution."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3103594"
                        ],
                        "name": "Sungjin Ahn",
                        "slug": "Sungjin-Ahn",
                        "structuredName": {
                            "firstName": "Sungjin",
                            "lastName": "Ahn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sungjin Ahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34786378"
                        ],
                        "name": "A. Balan",
                        "slug": "A.-Balan",
                        "structuredName": {
                            "firstName": "Anoop",
                            "lastName": "Balan",
                            "middleNames": [
                                "Korattikara"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Balan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In all cases, we train using minibatches, which requires the introduction of scaling terms in the free energy objective function (13) in order to maintain the correct scale between the prior over the parameters and the remaining terms (Ahn et al., 2012; Welling & Teh, 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 216077795,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "57f3faa06d215481d04238a3c6ee75828863d6e4",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the following question: \"Can we approximately sample from a Bayesian posterior distribution if we are only allowed to touch a small mini-batch of data-items for every sample we generate?\". An algorithm based on the Langevin equation with stochastic gradients (SGLD) was previously proposed to solve this, but its mixing rate was slow. By leveraging the Bayesian Central Limit Theorem, we extend the SGLD algorithm so that at high mixing rates it will sample from a normal approximation of the posterior, while for slow mixing rates it will mimic the behavior of SGLD with a pre-conditioner matrix. As a bonus, the proposed algorithm is reminiscent of Fisher scoring (with stochastic gradients) and as such an efficient optimizer during burn-in."
            },
            "slug": "Bayesian-Posterior-Sampling-via-Stochastic-Gradient-Ahn-Balan",
            "title": {
                "fragments": [],
                "text": "Bayesian Posterior Sampling via Stochastic Gradient Fisher Scoring"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "By leveraging the Bayesian Central Limit Theorem, the SGLD algorithm is extended so that at high mixing rates it will sample from a normal approximation of the posterior, while for slow mixing rate it will mimic the behavior of S GLD with a pre-conditioner matrix."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49430964"
                        ],
                        "name": "Ahn",
                        "slug": "Ahn",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Ahn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145134884"
                        ],
                        "name": "J. Pineau",
                        "slug": "J.-Pineau",
                        "structuredName": {
                            "firstName": "Jo\u00eblle",
                            "lastName": "Pineau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pineau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 73653161,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "3c58034bface3ca6b45aedff821ba049e8302c88",
            "isKey": false,
            "numCitedBy": 171,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the following question: \u201cCan we approximately sample from a Bayesian posterior distribution if we are only allowed to touch a small mini-batch of data-items for every sample we generate?\u201d . An algorithm based on the Langevin equation with stochastic gradients (SGLD) was previously proposed to solve this, but its mixing rate was slow. By leverag-ing the Bayesian Central Limit Theorem, we ex-tend the SGLD algorithm so that at high mixing rates it will sample from a normal approximation of the posterior, while for slow mixing rates it will mimic the behavior of SGLD with a pre-conditioner matrix. As a bonus, the proposed algorithm is reminiscent of Fisher scoring (with stochastic gradients) and as such an ef\ufb01cient optimizer during burn-in."
            },
            "slug": "Bayesian-posterior-sampling-via-stochastic-gradient-Ahn-Pineau",
            "title": {
                "fragments": [],
                "text": "Bayesian posterior sampling via stochastic gradient Fisher scoring Bayesian Posterior Sampling via Stochastic Gradient Fisher Scoring"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "By leverag-ing the Bayesian Central Limit Theorem, the SGLD algorithm is ex-tend so that at high mixing rates it will sample from a normal approximation of the posterior, while for slow mixing rates the algorithm will mimic the behavior of S GLD with a pre-conditioner matrix."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2887364"
                        ],
                        "name": "Tim Salimans",
                        "slug": "Tim-Salimans",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Salimans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Salimans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3250170"
                        ],
                        "name": "David A. Knowles",
                        "slug": "David-A.-Knowles",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Knowles",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Knowles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 272
                            }
                        ],
                        "text": "\u2026(Williams, 1992), since it is simple to implement and applicable to both discrete and continuous models, though control variate methods are becoming increasingly popular for variational inference problems (Hoffman et al., 2013; Blei et al., 2012; Ranganath et al., 2014; Salimans & Knowles, 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 88519529,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "98d764b59e26338aaeffaf40db303d079ffcd07c",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, we and several other authors have written about the possibilities of using stochastic approximation techniques for fitting variational approximations to intractable Bayesian posterior distributions. Naive implementations of stochastic approximation suffer from high variance in this setting. Several authors have therefore suggested using control variates to reduce this variance, while we have taken a different but analogous approach to reducing the variance which we call stochastic linear regression. In this note we take the former perspective and derive the ideal set of control variates for stochastic approximation variational Bayes under a certain set of assumptions. We then show that using these control variates is closely related to using the stochastic linear regression approximation technique we proposed earlier. A simple example shows that our method for constructing control variates leads to stochastic estimators with much lower variance compared to other approaches."
            },
            "slug": "On-Using-Control-Variates-with-Stochastic-for-Bayes-Salimans-Knowles",
            "title": {
                "fragments": [],
                "text": "On Using Control Variates with Stochastic Approximation for Variational Bayes and its Connection to Stochastic Linear Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This note derives the ideal set of control Variates for stochastic approximation variational Bayes under a certain set of assumptions and shows that using these control variates is closely related to using the stochastically linear regression approximation technique the authors proposed earlier."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2194841"
                        ],
                        "name": "H. Rue",
                        "slug": "H.-Rue",
                        "structuredName": {
                            "firstName": "H\u00e5vard",
                            "lastName": "Rue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116156469"
                        ],
                        "name": "S. Martino",
                        "slug": "S.-Martino",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Martino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Martino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2593810"
                        ],
                        "name": "N. Chopin",
                        "slug": "N.-Chopin",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Chopin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Chopin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1657669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "65bb01b985035307f7b1102e17b8a5c0f2dafff8",
            "isKey": false,
            "numCitedBy": 3380,
            "numCiting": 307,
            "paperAbstract": {
                "fragments": [],
                "text": "Summary.\u2002 Structured additive regression models are perhaps the most commonly used class of models in statistical applications. It includes, among others, (generalized) linear models, (generalized) additive models, smoothing spline models, state space models, semiparametric regression, spatial and spatiotemporal models, log\u2010Gaussian Cox processes and geostatistical and geoadditive models. We consider approximate Bayesian inference in a popular subset of structured additive regression models, latent Gaussian models, where the latent field is Gaussian, controlled by a few hyperparameters and with non\u2010Gaussian response variables. The posterior marginals are not available in closed form owing to the non\u2010Gaussian response variables. For such models, Markov chain Monte Carlo methods can be implemented, but they are not without problems, in terms of both convergence and computational time. In some practical applications, the extent of these problems is such that Markov chain Monte Carlo sampling is simply not an appropriate tool for routine analysis. We show that, by using an integrated nested Laplace approximation and its simplified version, we can directly compute very accurate approximations to the posterior marginals. The main benefit of these approximations is computational: where Markov chain Monte Carlo algorithms need hours or days to run, our approximations provide more precise estimates in seconds or minutes. Another advantage with our approach is its generality, which makes it possible to perform Bayesian analysis in an automatic, streamlined way, and to compute model comparison criteria and various predictive measures so that models can be compared and the model under study can be challenged."
            },
            "slug": "Approximate-Bayesian-inference-for-latent-Gaussian-Rue-Martino",
            "title": {
                "fragments": [],
                "text": "Approximate Bayesian inference for latent Gaussian models by using integrated nested Laplace approximations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work considers approximate Bayesian inference in a popular subset of structured additive regression models, latent Gaussian models, where the latent field is Gaussian, controlled by a few hyperparameters and with non\u2010Gaussian response variables and can directly compute very accurate approximations to the posterior marginals."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145095579"
                        ],
                        "name": "L. Yao",
                        "slug": "L.-Yao",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815021"
                        ],
                        "name": "Guillaume Alain",
                        "slug": "Guillaume-Alain",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Alain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guillaume Alain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467703"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 78
                            }
                        ],
                        "text": "DAEs can also be used as generative models by simulating from a Markov chain (Bengio et al., 2013; Bengio & Thibodeau-Laufer, 2013)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 194
                            }
                        ],
                        "text": "There is then a direct correspondence between the expression for the free energy (11) and the reconstruction error and regularization terms used in denoising auto-encoders (c.f. equation (4) of Bengio et al. (2013))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5554756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9704f8119d6ba748230b4f2ad59f0e8c64fdfb0",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has shown how denoising and contractive autoencoders implicitly capture the structure of the data-generating density, in the case where the corruption noise is Gaussian, the reconstruction error is the squared error, and the data is continuous-valued. This has led to various proposals for sampling from this implicitly learned density function, using Langevin and Metropolis-Hastings MCMC. However, it remained unclear how to connect the training procedure of regularized auto-encoders to the implicit estimation of the underlying data-generating distribution when the data are discrete, or using other forms of corruption process and reconstruction errors. Another issue is the mathematical justification which is only valid in the limit of small corruption noise. We propose here a different attack on the problem, which deals with all these issues: arbitrary (but noisy enough) corruption, arbitrary reconstruction loss (seen as a log-likelihood), handling both discrete and continuous-valued variables, and removing the bias due to non-infinitesimal corruption noise (or non-infinitesimal contractive penalty)."
            },
            "slug": "Generalized-Denoising-Auto-Encoders-as-Generative-Bengio-Yao",
            "title": {
                "fragments": [],
                "text": "Generalized Denoising Auto-Encoders as Generative Models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A different attack on the problem is proposed, which deals with arbitrary (but noisy enough) corruption, arbitrary reconstruction loss, handling both discrete and continuous-valued variables, and removing the bias due to non-infinitesimal corruption noise."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 203
                            }
                        ],
                        "text": "When the mappings are of the form Tl(h) = Alf(h) +bl, for simple element-wise non-linearities f such as the probit function or the rectified linearity, we recover the non-linear Gaussian belief network (Frey & Hinton, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For inference in DLGMs, we later introduce an unbiased though higher variance estimator that requires only quadratic complexity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 196
                            }
                        ],
                        "text": "DLGMs form a unified family of models that includes factor analysis (Bartholomew & Knott, 1999), non-linear factor analysis (Lappalainen & Honkela, 2000), and non-linear Gaussian belief networks (Frey & Hinton, 1999)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7707909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "763aa50583ed047528ba4ef471d72bfbe34471e6",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We view perceptual tasks such as vision and speech recognition as inference problems where the goal is to estimate the posterior distribution over latent variables (e.g., depth in stereo vision) given the sensory input. The recent flurry of research in independent component analysis exemplifies the importance of inferring the continuous-valued latent variables of input data. The latent variables found by this method are linearly related to the input, but perception requires nonlinear inferences such as classification and depth estimation. In this article, we present a unifying framework for stochastic neural networks with nonlinear latent variables. Nonlinear units are obtained by passing the outputs of linear gaussian units through various nonlinearities. We present a general variational method that maximizes a lower bound on the likelihood of a training set and give results on two visual feature extraction problems. We also show how the variational method can be used for pattern classification and compare the performance of these nonlinear networks with other methods on the problem of handwritten digit recognition."
            },
            "slug": "Variational-Learning-in-Nonlinear-Gaussian-Belief-Frey-Hinton",
            "title": {
                "fragments": [],
                "text": "Variational Learning in Nonlinear Gaussian Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This article presents a general variational method that maximizes a lower bound on the likelihood of a training set and gives results on two visual feature extraction problems."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2824663"
                        ],
                        "name": "C. Archambeau",
                        "slug": "C.-Archambeau",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Archambeau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Archambeau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 41
                            }
                        ],
                        "text": "These identities have been recognised by Opper & Archambeau (2009) for variational inference in Gaussian process regression, and following this work, by Graves (2011) for parameter learning in large neural networks."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10036331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e5eda285b30216bc5f5ca93d3a93728c15852f8",
            "isKey": false,
            "numCitedBy": 295,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The variational approximation of posterior distributions by multivariate gaussians has been much less popular in the machine learning community compared to the corresponding approximation by factorizing distributions. This is for a good reason: the gaussian approximation is in general plagued by an number of variational parameters to be optimized, N being the number of random variables. In this letter, we discuss the relationship between the Laplace and the variational approximation, and we show that for models with gaussian priors and factorizing likelihoods, the number of variational parameters is actually . The approach is applied to gaussian process regression with nongaussian likelihoods."
            },
            "slug": "The-Variational-Gaussian-Approximation-Revisited-Opper-Archambeau",
            "title": {
                "fragments": [],
                "text": "The Variational Gaussian Approximation Revisited"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The relationship between the Laplace and the variational approximation is discussed, and it is shown that for models with gaussian priors and factorizing likelihoods, the number of variational parameters is actually ."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764325"
                        ],
                        "name": "Radford M. Neal",
                        "slug": "Radford-M.-Neal",
                        "structuredName": {
                            "firstName": "Radford",
                            "lastName": "Neal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radford M. Neal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The computational complexity per training sample during training is also O(LK\u03042) \u2013 the same as that of matching auto-encoder."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9690330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ee392ad467b967c0a32d8ecb19fc20f7c1d62fe",
            "isKey": false,
            "numCitedBy": 1138,
            "numCiting": 324,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic inference is an attractive approach to uncertain reasoning and empirical learning in artificial intelligence. Computational difficulties arise, however, because probabilistic models with the necessary realism and flexibility lead to complex distributions over high-dimensional spaces. Related problems in other fields have been tackled using Monte Carlo methods based on sampling using Markov chains, providing a rich array of techniques that can be applied to problems in artificial intelligence. The \u201cMetropolis algorithm\u201d has been used to solve difficult problems in statistical physics for over forty years, and, in the last few years, the related method of \u201cGibbs sampling\u201d has been applied to problems of statistical inference. Concurrently, an alternative method for solving problems in statistical physics by means of dynamical simulation has been developed as well, and has recently been unified with the Metropolis algorithm to produce the \u201chybrid Monte Carlo\u201d method. In computer science, Markov chain sampling is the basis of the heuristic optimization technique of \u201csimulated annealing\u201d, and has recently been used in randomized algorithms for approximate counting of large sets. In this review, I outline the role of probabilistic inference in artificial intelligence, present the theory of Markov chains, and describe various Markov chain Monte Carlo algorithms, along with a number of supporting techniques. I try to present a comprehensive picture of the range of methods that have been developed, including techniques from the varied literature that have not yet seen wide application in artificial intelligence, but which appear relevant. As illustrative examples, I use the problems of probabilistic inference in expert systems, discovery of latent classes from data, and Bayesian learning for neural networks."
            },
            "slug": "Probabilistic-Inference-Using-Markov-Chain-Monte-Neal",
            "title": {
                "fragments": [],
                "text": "Probabilistic Inference Using Markov Chain Monte Carlo Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The role of probabilistic inference in artificial intelligence is outlined, the theory of Markov chains is presented, and various Markov chain Monte Carlo algorithms are described, along with a number of supporting techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8632802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf527ca11d7d81a15ff5b5603374a4e9d53b55b6",
            "isKey": false,
            "numCitedBy": 986,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the major obstacles to using Bayesian methods for pattern recognition has been its computational expense. This thesis presents an approximation technique that can perform Bayesian inference faster and more accurately than previously possible. This method, \u201cExpectation Propagation,\u201d unifies and generalizes two previous techniques: assumed-density filtering, an extension of the Kalman filter, and loopy belief propagation, an extension of belief propagation in Bayesian networks. The unification shows how both of these algorithms can be viewed as approximating the true posterior distribution with simpler distribution, which is close in the sense of KL-divergence. Expectation Propagation exploits the best of both algorithms: the generality of assumed-density filtering and the accuracy of loopy belief propagation. \nLoopy belief propagation, because it propagates exact belief states, is useful for limited types of belief networks, such as purely discrete networks. Expectation Propagation approximates the belief states with expectations, such as means and variances, giving it much wider scope. Expectation Propagation also extends belief propagation in the opposite direction\u2014propagating richer belief states which incorporate correlations between variables. \nThis framework is demonstrated in a variety of statistical models using synthetic and real-world data. On Gaussian mixture problems, Expectation Propagation is found, for the same amount of computation, to be convincingly better than rival approximation techniques: Monte Carlo, Laplace's method, and variational Bayes. For pattern recognition, Expectation Propagation provides an algorithm for training Bayes Point Machine classifiers that is faster and more accurate than any previously known. The resulting classifiers outperform Support Vector Machines on several standard datasets, in addition to having a comparable training time. Expectation Propagation can also be used to choose an appropriate feature set for classification, via Bayesian model selection. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)"
            },
            "slug": "A-family-of-algorithms-for-approximate-Bayesian-Minka",
            "title": {
                "fragments": [],
                "text": "A family of algorithms for approximate Bayesian inference"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This thesis presents an approximation technique that can perform Bayesian inference faster and more accurately than previously possible, and is found to be convincingly better than rival approximation techniques: Monte Carlo, Laplace's method, and variational Bayes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2243483"
                        ],
                        "name": "H. Lappalainen",
                        "slug": "H.-Lappalainen",
                        "structuredName": {
                            "firstName": "Harri",
                            "lastName": "Lappalainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lappalainen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145766200"
                        ],
                        "name": "A. Honkela",
                        "slug": "A.-Honkela",
                        "structuredName": {
                            "firstName": "Antti",
                            "lastName": "Honkela",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Honkela"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 196
                            }
                        ],
                        "text": "When we have only one layer of latent variables and use a linear mapping T (\u00b7), we recover factor analysis (Bartholomew & Knott, 1999) \u2013 more general mappings allow for a non-linear factor analysis (Lappalainen & Honkela, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 124
                            }
                        ],
                        "text": "An important family of alternative estimators is based on quadrature and series expansion methods (Honkela & Valpola, 2004; Lappalainen & Honkela, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 125
                            }
                        ],
                        "text": "DLGMs form a unified family of models that includes factor analysis (Bartholomew & Knott, 1999), non-linear factor analysis (Lappalainen & Honkela, 2000), and non-linear Gaussian belief networks (Frey & Hinton, 1999)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14089272,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ce2c5c3cf802a7f66c9e49ed00364313927c4e5",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Summary. In this chapter, a nonlinear extension to independent component analysis is developed. The nonlinear mapping from source signals to observations is modelled by a multi-layer perceptron network and the distributions of source signals are modelled by mixture-of-Gaussians. The observations are assumed to be corrupted by Gaussian noise and therefore the method is more adequately described as nonlinear independent factor analysis. The nonlinear mapping, the source distributions and the noise level are estimated from the data. Bayesian approach to learning avoids problems with overlearning which would otherwise be severe in unsupervised learning with flexible nonlinear models."
            },
            "slug": "Bayesian-Non-Linear-Independent-Component-Analysis-Lappalainen-Honkela",
            "title": {
                "fragments": [],
                "text": "Bayesian Non-Linear Independent Component Analysis by Multi-Layer Perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A nonlinear extension to independent component analysis is developed that avoids problems with overlearning which would otherwise be severe in unsupervised learning with flexible nonlinear models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 48
                            }
                        ],
                        "text": "One popular approach is the REINFORCE algorithm (Williams, 1992), since it is simple to implement and applicable to both discrete and continuous models, though control variate methods are becoming increasingly popular for variational inference problems (Hoffman et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 232
                            }
                        ],
                        "text": "A number of approaches are known and widely used, and include: mean-field variational EM (Beal, 2003); the wake-sleep algorithm (Dayan, 2000); and stochastic variational methods and related control-variate estimators (Wilson, 1984; Williams, 1992; Hoffman et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 49
                            }
                        ],
                        "text": "One popular approach is the REINFORCE algorithm (Williams, 1992), since it is simple to implement and applicable to both discrete and continuous models, though control variate methods are becoming increasingly popular for variational inference problems (Hoffman et al., 2013; Blei et al., 2012;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2332513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "isKey": false,
            "numCitedBy": 5181,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms."
            },
            "slug": "Simple-statistical-gradient-following-algorithms-Williams",
            "title": {
                "fragments": [],
                "text": "Simple statistical gradient-following algorithms for connectionist reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units that are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reInforcement tasks, and they do this without explicitly computing gradient estimates."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467703"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2453026"
                        ],
                        "name": "Isabelle Lajoie",
                        "slug": "Isabelle-Lajoie",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Lajoie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Isabelle Lajoie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798462"
                        ],
                        "name": "Pierre-Antoine Manzagol",
                        "slug": "Pierre-Antoine-Manzagol",
                        "structuredName": {
                            "firstName": "Pierre-Antoine",
                            "lastName": "Manzagol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre-Antoine Manzagol"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 30
                            }
                        ],
                        "text": "Denoising autoencoders (DAE) (Vincent et al., 2010) introduce a random corruption to the encoder network and attempt to minimize the expected reconstruction error under this corruption noise with additional regularisation terms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "DAEs can also be used as generative models by simulating from a Markov chain (Bengio et al., 2013; Bengio & Thibodeau-Laufer, 2013)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "In our variational approach, the recognition distribution q(\u03be|v) can be interpreted as a stochastic encoder in the DAE setting."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17804904,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd",
            "isKey": false,
            "numCitedBy": 5611,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations."
            },
            "slug": "Stacked-Denoising-Autoencoders:-Learning-Useful-in-Vincent-Larochelle",
            "title": {
                "fragments": [],
                "text": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724065"
                        ],
                        "name": "D. M. Chickering",
                        "slug": "D.-M.-Chickering",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chickering",
                            "middleNames": [
                                "Maxwell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Chickering"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14226732,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fb874a1c8106a5b2b2779ee8e1433149109ba00",
            "isKey": false,
            "numCitedBy": 1055,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for learning Bayesian networks from data have two components: a scoring metric and a search procedure. The scoring metric computes a score reflecting the goodness-of-fit of the structure to the data. The search procedure tries to identify network structures with high scores. Heckerman et al. (1995) introduce a Bayesian metric, called the BDe metric, that computes the relative posterior probability of a network structure given data. In this paper, we show that the search problem of identifying a Bayesian network\u2014among those where each node has at most K parents\u2014that has a relative posterior probability greater than a given constant is NP-complete, when the BDe metric is used."
            },
            "slug": "Learning-Bayesian-Networks-is-NP-Complete-Chickering",
            "title": {
                "fragments": [],
                "text": "Learning Bayesian Networks is NP-Complete"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that the search problem of identifying a Bayesian network\u2014among those where each node has at most K parents\u2014that has a relative posterior probability greater than a given constant is NP-complete, when the BDe metric is used."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1831199"
                        ],
                        "name": "S. Gershman",
                        "slug": "S.-Gershman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Gershman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gershman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144002017"
                        ],
                        "name": "Noah D. Goodman",
                        "slug": "Noah-D.-Goodman",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Goodman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah D. Goodman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 71
                            }
                        ],
                        "text": "A recognition model allows us introduce a form of amortised inference (Gershman & Goodman, 2014) for variational methods in which we share statistical strength by allowing for generalisation across the posterior estimates for all latent variables using a model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 924780,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93f5a28d16e04334fcb71cb62d0fd9b1c68883bb",
            "isKey": false,
            "numCitedBy": 245,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Amortized Inference in Probabilistic Reasoning Samuel J. Gershman 1 (sjgershm@mit.edu) and Noah D. Goodman 2 (ngoodman@stanford.edu) 1 Department of Brain and Cognitive Sciences, MIT of Psychology, Stanford University 2 Department Abstract similar or related queries. For example, as you view an im- age, your head and eyes are continuously moving, generating an infinitude of slightly different queries. For these queries, it may be inaccurate to reuse a stored inference without modifi- cation. This raises the problem of amortized inference: how to flexibly reuse inferences so as to answer a variety of re- lated queries. Recently, Stuhlm\u00a8uller et al. (2013) addressed this problem by using stored samples to estimate local condi- tional distributions, and then approximating answers to more complex queries by composing the local distributions. The work described in this paper seeks experimental evidence for a similar kind of flexible reuse in human reasoning. We presented subjects with a simple Bayesian network and asked them to answer a series of queries about it. One of these queries (the \u201ctarget\u201d) could be answered by reusing the answer to another query (the \u201csub-query\u201d). We hypothesized that the effects of reuse would be evident compared to an in- ference with the same structure but no re-usable sub-query. Further, we hypothesized that this effect would be present only if the target was presented after the sub-query. Accord- ingly, we manipulated (between subjects) whether the target came before or after the sub-query. This design allowed us to look for two key signatures of reuse: correlations between related inferences (Experiment 1) and faster responses for in- ferences that exploit reuse (Experiment 2). Recent studies of probabilistic reasoning have postulated general-purpose inference algorithms that can be used to an- swer arbitrary queries. These algorithms are memoryless, in the sense that each query is processed independently, without reuse of earlier computation. We argue that the brain oper- ates in the setting of amortized inference, where numerous related queries must be answered (e.g., recognizing a scene from multiple viewpoints); in this setting, memoryless algo- rithms can be computationally wasteful. We propose a simple form of flexible reuse, according to which shared inferences are cached and composed together to answer new queries. We present experimental evidence that humans exploit this form of reuse: the answer to a complex query can be systematically predicted from a person\u2019s response to a simpler query if the simpler query was presented first and entails a sub-inference (i.e., a sub-component of the more complex query). People are also faster at answering a complex query when it is preceded by a sub-inference. Our results suggest that the astonishing ef- ficiency of human probabilistic reasoning may be supported by interactions between inference and memory. Keywords: induction, Bayesian inference, memory \u201cCognition is recognition.\u201d \u2013 Hofstadter (1995) Introduction One view of probabilistic reasoning holds that our brains are equipped with general-purpose inference algorithms that can be used to answer arbitrary queries (Griffiths et al., 2012; Pouget et al., 2013). An under-appreciated property of such algorithms borrowed from computer science is that they are memoryless: each query is (at least in principle) processed independently of others. While this property guarantees that inferences will not interfere with one another, it can also lead to gross computational inefficiency, since inferences are never reused; memorylessness implies that answering the same query twice requires the same amount of computation as answer two unique queries. 1 Whatever inference algorithms the brain uses, they are un- likely to be memoryless. Consider, for example, the image in Figure 1 (Gregory, 1970). Upon viewing it for the first time, most observers find it extremely difficult to identify what the image depicts. 2 However, once the image has been deciphered, all subsequent views are instantly recognized. Clearly, the visual system is not running a computationally expensive inference algorithm upon each viewing; the infer- ence is simply reused. In reality, it is rare to be faced with the exact same query multiple times. Much more pervasive is the appearance of Figure 1: What does this image depict? Amortized inference in Bayesian networks 1 To be fair, inference algorithms for dynamical systems, like Kalman filtering, involve reuse in a certain sense. However, these algorithms are not designed to reuse inferences when applied to sev- eral independent time series (even if the time series are identical). 2 Answer: a dalmatian. In this paper, we will restrict our attention to amortized in- ference for Bayesian networks. Let p(x) denote a probability distribution on variables x = {x 1 , . . . , x M }. A Bayesian net- work G is a directed acyclic graph with nodes corresponding"
            },
            "slug": "Amortized-Inference-in-Probabilistic-Reasoning-Gershman-Goodman",
            "title": {
                "fragments": [],
                "text": "Amortized Inference in Probabilistic Reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is argued that the brain oper- ates in the setting of amortized inference, where numerous related queries must be answered (e.g., recognizing a scene from multiple viewpoints); in this setting, memoryless algo- rithms can be computationally wasteful."
            },
            "venue": {
                "fragments": [],
                "text": "CogSci"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145306271"
                        ],
                        "name": "Neil D. Lawrence",
                        "slug": "Neil-D.-Lawrence",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Lawrence",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neil D. Lawrence"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 72
                            }
                        ],
                        "text": "The Gaussian process latent variable model and deep Gaussian processes (Lawrence, 2005; Damianou & Lawrence, 2013) form the non-parametric analogue of our model and employ Gaussian process priors over the non-linear functions between each layer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1969477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d60f04d9677f1a5c439b6b1cef41606bd0ca646",
            "isKey": false,
            "numCitedBy": 997,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Summarising a high dimensional data set with a low dimensional embedding is a standard approach for exploring its structure. In this paper we provide an overview of some existing techniques for discovering such embeddings. We then introduce a novel probabilistic interpretation of principal component analysis (PCA) that we term dual probabilistic PCA (DPPCA). The DPPCA model has the additional advantage that the linear mappings from the embedded space can easily be non-linearised through Gaussian processes. We refer to this model as a Gaussian process latent variable model (GP-LVM). Through analysis of the GP-LVM objective function, we relate the model to popular spectral techniques such as kernel PCA and multidimensional scaling. We then review a practical algorithm for GP-LVMs in the context of large data sets and develop it to also handle discrete valued data and missing attributes. We demonstrate the model on a range of real-world and artificially generated data sets."
            },
            "slug": "Probabilistic-Non-linear-Principal-Component-with-Lawrence",
            "title": {
                "fragments": [],
                "text": "Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel probabilistic interpretation of principal component analysis (PCA) that is based on a Gaussian process latent variable model (GP-LVM), and related to popular spectral techniques such as kernel PCA and multidimensional scaling."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399249722"
                        ],
                        "name": "M. Magdon-Ismail",
                        "slug": "M.-Magdon-Ismail",
                        "structuredName": {
                            "firstName": "Malik",
                            "lastName": "Magdon-Ismail",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Magdon-Ismail"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38769302"
                        ],
                        "name": "Jonathan T. Purnell",
                        "slug": "Jonathan-T.-Purnell",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Purnell",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan T. Purnell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1350588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "adb4d64fc1b05a464f2915f27ccafdf73c6134af",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Covariance matrices capture correlations that are invaluable in modeling real-life datasets. Using all d2 elements of the covariance (in d dimensions) is costly and could result in over-fitting; and the simple diagonal approximation can be over-restrictive. In this work, we present a new model, the low-rank Gaussian mixture model (LRGMM), for modeling data which can be extended to identifying partitions or overlapping clusters. The curse of dimensionality that arises in calculating the covariance matrices of the GMM is countered by using low-rank perturbed diagonal matrices. The efficiency is comparable to the diagonal approximation, yet one can capture correlations among the dimensions. Our experiments reveal the LRGMM to be an efficient and highly applicable tool for working with large high-dimensional datasets."
            },
            "slug": "Approximating-the-covariance-matrix-of-GMMs-with-Magdon-Ismail-Purnell",
            "title": {
                "fragments": [],
                "text": "Approximating the covariance matrix of GMMs with low-rank perturbations"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The curse of dimensionality that arises in calculating the covariance matrices of the GMM is countered by using low-rank perturbed diagonal matrices, and the efficiency is comparable to the diagonal approximation, yet one can capture correlations among the dimensions."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Data Min. Model. Manag."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117036852,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7b2bffdf5b62305bec4c0f1ea7e3c1ba66fccb5",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A fundamental problem in learning and reasoning about a set of information is finding the right representation. The primary goal of an unsupervised learning procedure is to optimize the quality of a system's internal representation. In this thesis, we present a general framework for describing unsupervised learning procedures based on the Minimum Description Length (MDL) principle. The MDL principle states that the best model is one that minimizes the summed description length of the model and the data with respect to the model. Applying this approach to the unsupervised learning problem makes explicit a key trade off between the accuracy of a representation (i.e., how concise a description of the input may be generated from it) and its succinctness (i.e., how compactly the representation itself can be described). \nViewing existing unsupervised learning procedures in terms of the framework exposes their implicit assumptions about the type of structure assumed to underlie the data. While these existing algorithms typically minimize the data description using a fixed length representation, we use the framework to derive a class of objective functions for training self-supervised neural networks, where the goal is to minimize the description length of the representation simultaneously with that of the data. Formulating a description of the representation forces assumptions about the structure of the data to be made explicit, which in turn leads to a particular network configuration as well as an objective function that can be used to optimize the network parameters. We describe three new learning algorithms derived in this manner from the MDL framework. Each algorithm embodies a different scheme for describing the internal representation, and is therefore suited to a range of datasets based on the structure underlying the data. Simulations demonstrate the applicability of these algorithms on some simple computational vision tasks."
            },
            "slug": "A-minimum-description-length-framework-for-learning-Zemel",
            "title": {
                "fragments": [],
                "text": "A minimum description length framework for unsupervised learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This thesis presents a general framework for describing unsupervised learning procedures based on the Minimum Description Length (MDL) principle, and describes three new learning algorithms derived in this manner from the MDL framework."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796044"
                        ],
                        "name": "L. Saul",
                        "slug": "L.-Saul",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Saul",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Saul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 53
                            }
                        ],
                        "text": "Other related models include sigmoid belief networks (Saul et al., 1996) and deep autoregressive networks (Gregor et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 54
                            }
                        ],
                        "text": "Other related models include sigmoid belief networks (Saul et al., 1996) and deep autoregressive networks (Gregor et al., 2014), which use auto-\nregressive Bernoulli distributions at each layer instead of Gaussian distributions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7424318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a79433b5feacd9e8feeafa629dae5a85f362fef",
            "isKey": false,
            "numCitedBy": 438,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a mean field theory for sigmoid belief networks based on ideas from statistical mechanics. Our mean field theory provides a tractable approximation to the true probability distribution in these networks; it also yields a lower bound on the likelihood of evidence. We demonstrate the utility of this framework on a benchmark problem in statistical pattern recognition-the classification of handwritten digits."
            },
            "slug": "Mean-Field-Theory-for-Sigmoid-Belief-Networks-Saul-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Mean Field Theory for Sigmoid Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The utility of a mean field theory for sigmoid belief networks based on ideas from statistical mechanics is demonstrated on a benchmark problem in statistical pattern recognition-the classification of handwritten digits."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34180232"
                        ],
                        "name": "Yuval Netzer",
                        "slug": "Yuval-Netzer",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Netzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Netzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156632012"
                        ],
                        "name": "Tao Wang",
                        "slug": "Tao-Wang",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726358"
                        ],
                        "name": "A. Bissacco",
                        "slug": "A.-Bissacco",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bissacco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bissacco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144397975"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 115
                            }
                        ],
                        "text": "We demonstrate the ability of the model to impute missing data using the street view house numbers (SVHN) data set (Netzer et al., 2011), which consists of 73, 257 images of size 32 \u00d7 32 pixels, and the Frey faces and MNIST data sets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 116
                            }
                        ],
                        "text": "We demonstrate the ability of the model to impute missing data using the street view house numbers (SVHN) data set (Netzer et al., 2011), which consists of 73, 257 images of\nsize 32 \u00d7 32 pixels, and the Frey faces and MNIST data sets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16852518,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02227c94dd41fe0b439e050d377b0beb5d427cda",
            "isKey": false,
            "numCitedBy": 3898,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting and reading text from natural images is a hard computer vision task that is central to a variety of emerging applications. Related problems like document character recognition have been widely studied by computer vision and machine learning researchers and are virtually solved for practical applications like reading handwritten digits. Reliably recognizing characters in more complex scenes like photographs, however, is far more difficult: the best existing methods lag well behind human performance on the same tasks. In this paper we attack the problem of recognizing digits in a real application using unsupervised feature learning methods: reading house numbers from street level photos. To this end, we introduce a new benchmark dataset for research use containing over 600,000 labeled digits cropped from Street View images. We then demonstrate the difficulty of recognizing these digits when the problem is approached with hand-designed features. Finally, we employ variants of two recently proposed unsupervised feature learning methods and find that they are convincingly superior on our benchmarks."
            },
            "slug": "Reading-Digits-in-Natural-Images-with-Unsupervised-Netzer-Wang",
            "title": {
                "fragments": [],
                "text": "Reading Digits in Natural Images with Unsupervised Feature Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new benchmark dataset for research use is introduced containing over 600,000 labeled digits cropped from Street View images, and variants of two recently proposed unsupervised feature learning methods are employed, finding that they are convincingly superior on benchmarks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153149219"
                        ],
                        "name": "R. Price",
                        "slug": "R.-Price",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Price",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Price"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 64
                            }
                        ],
                        "text": "The gradient of the expectation with respect to R is then:\n\u2207REN(\u00b5,C) [f(\u03be)] = \u2207REN (0,I) [f(\u00b5 + R )] = EN (0,I) [ g> ] , (10)\nwhere g is the gradient of f evaluated at \u00b5 + R and provides a lower-cost alternative to Price\u2019s theorem (8)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 254
                            }
                        ],
                        "text": "\u2026q is a K-dimensional Gaussian N (\u03be|\u00b5,C) the required gradients can be computed using the Gaussian gradient identities:\n\u2207\u00b5iEN (\u00b5,C) [f(\u03be)] = EN (\u00b5,C) [\u2207\u03beif(\u03be)] , (7) \u2207CijEN (\u00b5,C) [f(\u03be)] = 12EN (\u00b5,C) [ \u22072\u03bei,\u03bejf(\u03be) ] , (8)\nwhich are due to the theorems by Bonnet (1964) and Price (1958), respectively."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13450229,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f20fd159bca2a955b0d3dab00d8ea9aabc63b82a",
            "isKey": false,
            "numCitedBy": 532,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "If and only if the inputs to a set of nonlinear, zero-memory devices are variates drawn from a Gaussian random process, a useful general relationship may be found between certain input and output statistics of the set. This relationship equates partial derivatives of the (high-order) output correlation coefficient taken with respect to the input correlation coefficients, to the output correlation coefficient of a new set of nonlinear devices bearing a simple derivative relation to the original set. Application is made to the interesting special cases of conventional cross-correlation and autocorrelation functions, and Bussgang's theorem is easily proved. As examples, the output autocorrelation functions are simply obtained for a hard limiter, linear detector, clipper, and smooth limiter."
            },
            "slug": "A-useful-theorem-for-nonlinear-devices-having-Price",
            "title": {
                "fragments": [],
                "text": "A useful theorem for nonlinear devices having Gaussian inputs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Application is made to the interesting special cases of conventional cross-correlation and autocorrelation functions, and Bussgang's theorem is easily proved."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145382036"
                        ],
                        "name": "R. Little",
                        "slug": "R.-Little",
                        "structuredName": {
                            "firstName": "Roderick",
                            "lastName": "Little",
                            "middleNames": [
                                "J.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Little"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 70
                            }
                        ],
                        "text": "We test the imputation ability under two different missingness types (Little & Rubin, 1987): Missing-at-Random (MAR), where we consider 60% and 80% of the pixels to be missing randomly, and Not Missing-at-Random (NMAR), where we consider a square region of the image to be missing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 125113713,
            "fieldsOfStudy": [
                "Medicine",
                "Mathematics",
                "Business",
                "Psychology"
            ],
            "id": "c5c95938c03caa0b73303bab1e5ceeacb1879177",
            "isKey": false,
            "numCitedBy": 3490,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface.PART I: OVERVIEW AND BASIC APPROACHES.Introduction.Missing Data in Experiments.Complete-Case and Available-Case Analysis, Including Weighting Methods.Single Imputation Methods.Estimation of Imputation Uncertainty.PART II: LIKELIHOOD-BASED APPROACHES TO THE ANALYSIS OF MISSING DATA.Theory of Inference Based on the Likelihood Function.Methods Based on Factoring the Likelihood, Ignoring the Missing-Data Mechanism.Maximum Likelihood for General Patterns of Missing Data: Introduction and Theory with Ignorable Nonresponse.Large-Sample Inference Based on Maximum Likelihood Estimates.Bayes and Multiple Imputation.PART III: LIKELIHOOD-BASED APPROACHES TO THE ANALYSIS OF MISSING DATA: APPLICATIONS TO SOME COMMON MODELS.Multivariate Normal Examples, Ignoring the Missing-Data Mechanism.Models for Robust Estimation.Models for Partially Classified Contingency Tables, Ignoring the Missing-Data Mechanism.Mixed Normal and Nonnormal Data with Missing Values, Ignoring the Missing-Data Mechanism.Nonignorable Missing-Data Models.References.Author Index.Subject Index."
            },
            "slug": "Statistical-Analysis-with-Missing-Data-Little-Rubin",
            "title": {
                "fragments": [],
                "text": "Statistical Analysis with Missing Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115380819"
                        ],
                        "name": "James R. Wilson",
                        "slug": "James-R.-Wilson",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wilson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Wilson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 218
                            }
                        ],
                        "text": "A number of approaches are known and widely used, and include: mean-field variational EM (Beal, 2003); the wake-sleep algorithm (Dayan, 2000); and stochastic variational methods and related control-variate estimators (Wilson, 1984; Williams, 1992; Hoffman et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 136
                            }
                        ],
                        "text": "Control variate methods are amongst the most general and effective techniques for variance reduction when Monte Carlo methods are used (Wilson, 1984)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122177694,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d11d994b4f875f962fcf9e6379d29383196a7b45",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "SYNOPTIC ABSTRACTIn the design and analysis of large-scale simulation experiments, It Is generally difficult to estimate model performance parameters with adequate precision at an acceptable sampling cost. This paper provides a state-of-the-art survey of the principal variance reduction techniques that can Improve the efficiency of such experiments."
            },
            "slug": "Variance-Reduction-Techniques-for-Digital-Wilson",
            "title": {
                "fragments": [],
                "text": "Variance Reduction Techniques for Digital Simulation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A state-of-the-art survey of the principal variance reduction techniques that can improve the efficiency of large-scale simulation experiments."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144932903"
                        ],
                        "name": "G. Bonnet",
                        "slug": "G.-Bonnet",
                        "structuredName": {
                            "firstName": "Georges",
                            "lastName": "Bonnet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bonnet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 46
                            }
                        ],
                        "text": "The gradient of the expectation with respect to R is then:\n\u2207REN(\u00b5,C) [f(\u03be)] = \u2207REN (0,I) [f(\u00b5 + R )] = EN (0,I) [ g> ] , (10)\nwhere g is the gradient of f evaluated at \u00b5 + R and provides a lower-cost alternative to Price\u2019s theorem (8)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 236
                            }
                        ],
                        "text": "\u2026q is a K-dimensional Gaussian N (\u03be|\u00b5,C) the required gradients can be computed using the Gaussian gradient identities:\n\u2207\u00b5iEN (\u00b5,C) [f(\u03be)] = EN (\u00b5,C) [\u2207\u03beif(\u03be)] , (7) \u2207CijEN (\u00b5,C) [f(\u03be)] = 12EN (\u00b5,C) [ \u22072\u03bei,\u03bejf(\u03be) ] , (8)\nwhich are due to the theorems by Bonnet (1964) and Price (1958), respectively."
                    },
                    "intents": []
                }
            ],
            "corpusId": 108215001,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5b9a3b410b37bb97fc0766f13c758dd146274dca",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "SommaireCet article constitute une mise au point critique des diff\u00e9rentes m\u00e9thodes permettant de calculer les propri\u00e9t\u00e9s statistiques de fonctions al\u00e9atoires soumises \u00e0 un certain type de transformation non lin\u00e9aire. Les r\u00e9sultats les plus r\u00e9cents dans ce domaine sont analys\u00e9s et discut\u00e9s. De nombreux exemples permettent d\u2019illustrer les diff\u00e9rents proc\u00e9d\u00e9s connus et de les comparer entre eux."
            },
            "slug": "Transformations-des-signaux-al\u00e9atoires-a-travers-Bonnet",
            "title": {
                "fragments": [],
                "text": "Transformations des signaux al\u00e9atoires a travers les syst\u00e8mes non lin\u00e9aires sans m\u00e9moire"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 208875690,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "8cf24826e5bbe8e9e3161bdb98c0523b3ace5443",
            "isKey": false,
            "numCitedBy": 25208,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "11. Brunck W: Die systematische untersuchung des sprachorgans bei angeborenen gaumendefekte. Diss Leipiz 1906 (from Meissner). 12. Commichau G, Oeken FW: Pneumatisationsverhaitnisse bel gaumenspaltentragem. HNO (Bed) 7:73-75, 1958 13. Compere WE, Jr: Tympanic cavity clearance studies. Trans AAOO 62:444-454, 1958 14. Compere WE, Jr: The radiologic evaluation of eustachian tube function. AMA Arch Otolaryngol 7 :386-389, 1960 15. Day KM: Management of deafness: Wherry Memorial Lecture. Trans AAOO 55: 22, 1950 16. Donaldson JA: The role of artificial Eustachian tube in cleft palate patients. Cleft Palate J 61-66, 1966 17. Drettner B: The nasal air way and hearing in patients with cleft palate. Acta Otolaryng 52: 131-142, 1960 18. Duncan RB: Positional otitis media. Arch Otolaryng 72:455-463, 1960"
            },
            "slug": "References",
            "title": {
                "fragments": [],
                "text": "References"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "11. Brunck W: Die systematische untersuchung des sprachorgans bei angeborenen gaumendefekte ist wirklich ein wirkliches Problem gegen \u00e2\u201a\u00ac\u201d Pneumatisationsverhaitnisse bel gaumenspaltentragem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 107
                            }
                        ],
                        "text": "When we have only one layer of latent variables and use a linear mapping T (\u00b7), we recover factor analysis (Bartholomew & Knott, 1999) \u2013 more general mappings allow for a non-linear factor analysis (Lappalainen & Honkela, 2000)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For inference in DLGMs, we later introduce an unbiased though higher variance estimator that requires only quadratic complexity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 6
                            }
                        ],
                        "text": "1996; Bartholomew & Knott, 1999; Uria et al., 2014; Gregor et al., 2014) can be easily sampled from, but in most cases, efficient inference algorithms have remained elusive."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 69
                            }
                        ],
                        "text": "DLGMs form a unified family of models that includes factor analysis (Bartholomew & Knott, 1999), non-linear factor analysis (Lappalainen & Honkela, 2000), and non-linear Gaussian belief networks (Frey & Hinton, 1999)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Latent variable models and factor analysis, volume 7 of Kendall\u2019s library of statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 70
                            }
                        ],
                        "text": "We test the imputation ability under two different missingness types (Little & Rubin, 1987): Missing-at-Random (MAR), where we consider 60% and 80% of the pixels to be missing randomly, and Not Missing-at-Random (NMAR), where we consider a square region of the image to be missing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 167798727,
            "fieldsOfStudy": [],
            "id": "c5c95938c03caa0b73303bab1e5ceeacb1879177",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Analysis with Missing Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 128
                            }
                        ],
                        "text": "A number of approaches are known and widely used, and include: mean-field variational EM (Beal, 2003); the wake-sleep algorithm (Dayan, 2000); and stochastic variational methods and related control-variate estimators (Wilson, 1984; Williams, 1992; Hoffman et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 129
                            }
                        ],
                        "text": "A number of approaches are known and widely used, and include: mean-field variational EM (Beal, 2003); the wake-sleep algorithm (Dayan, 2000); and stochastic variational methods and related control-variate estimators (Wilson, 1984; Williams, 1992; Hoffman et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16890943,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd8cda00ccb0af1594fbaa5d41ee639d053a9cb2",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Helmholtz-Machines-and-Wake-Sleep-Learning-Dayan",
            "title": {
                "fragments": [],
                "text": "Helmholtz Machines and Wake-Sleep Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian learning via"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic inference using Markov chain"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 70
                            }
                        ],
                        "text": "We test the imputation ability under two different missingness types (Little & Rubin, 1987): Missing-at-Random (MAR), where we consider 60% and 80% of the pixels to be missing randomly, and Not Missing-at-Random (NMAR), where we consider a square region of the image to be missing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical analysis with missing data, volume 539"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 21
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 44,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Stochastic-Backpropagation-and-Approximate-in-Deep-Rezende-Mohamed/484ad17c926292fbe0d5211540832a8c8a8e958b?sort=total-citations"
}