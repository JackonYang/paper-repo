{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35681810"
                        ],
                        "name": "Jo\u00e3o Carreira",
                        "slug": "Jo\u00e3o-Carreira",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Carreira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Carreira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "Computing min-cuts on the superpixels is significantly faster than the pixel-level graph used in [6] and loses little accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "Furthermore, when using color unary terms [6], unary capacities can change for all other nodes because a separate color prior is adopted for each seed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "Without supervision, systems such as [9, 6, 19, 34, 31] are able to generate a pool of overlapping segment proposals, where most foreground objects are captured by at least one segment from the pool."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 172
                            }
                        ],
                        "text": "State-of-the-art figure-ground segmentation methods perform parametric min-cut on multiple seed graphs created by enumerating foreground seeds at different image locations [6, 9, 19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 47
                            }
                        ],
                        "text": "Our segmentation algorithm, like other methods [9, 6], uses graph min-cuts from multiple seeds to compute segments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "1http://cpl.cc.gatech.edu/projects/RIGOR/\nMethod Mean Best Mean Best Run Number of Overlap Covering Time (s) Segments CPMC 70.67 82.24 34.01 624.1 Object Proposals 71.48 80.98 126.46 1544.1 Shape Sharing 67.82 82.71 410.31 1115.4\nR IG\nO R GB-25 68.04 79.83 4.62 808.7 SketchTokens-25 67.33 78.94 2.75 839.1 StructEdges-25 68.85 79.89 2.16 741.9 GB-64 72.83 82.55 6.99 1490.3 SketchTokens-64 72.62 82.05 4.84 1630.5 StructEdges-64 73.64 82.84 4.71 1462.8 GB-100 74.22 83.25 9.26 1781.9 SketchTokens-100 73.78 82.61 6.80 1995.7 StructEdges-100 75.19 83.52 6.84 1828.7\nTable 1: VOC performance and timing results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "GB is used for computing CPMC boundaries."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "Our algorithm is compared against CPMC [6], Object Proposals [9], and Shape Sharing [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "This led to multiple image segmentation approaches such as CPMC [6], object proposals [9] and contour completion [26] that produce objects of different sizes by enumerating multiple unary parameters related to object size."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Note that CPMC results are about 1% better if the GlobalPB [2] boundaries are used, as in the public version, however, GlobalPB takes much longer to compute and therefore for the timing comparison it puts CPMC in a worse position."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206764991,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb2115a6765e8484830865b8ad5e6cc5dd29b48d",
            "isKey": true,
            "numCitedBy": 628,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel framework to generate and rank plausible hypotheses for the spatial extent of objects in images using bottom-up computational processes and mid-level selection cues. The object hypotheses are represented as figure-ground segmentations, and are extracted automatically, without prior knowledge of the properties of individual object classes, by solving a sequence of Constrained Parametric Min-Cut problems (CPMC) on a regular image grid. In a subsequent step, we learn to rank the corresponding segments by training a continuous model to predict how likely they are to exhibit real-world regularities (expressed as putative overlap with ground truth) based on their mid-level region properties, then diversify the estimated overlap score using maximum marginal relevance measures. We show that this algorithm significantly outperforms the state of the art for low-level segmentation in the VOC 2009 and 2010 data sets. In our companion papers [1], [2], we show that the algorithm can be used, successfully, in a segmentation-based visual object category recognition pipeline. This architecture ranked first in the VOC2009 and VOC2010 image segmentation and labeling challenges."
            },
            "slug": "CPMC:-Automatic-Object-Segmentation-Using-Min-Cuts-Carreira-Sminchisescu",
            "title": {
                "fragments": [],
                "text": "CPMC: Automatic Object Segmentation Using Constrained Parametric Min-Cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A novel framework to generate and rank plausible hypotheses for the spatial extent of objects in images using bottom-up computational processes and mid-level selection cues and it is shown that the algorithm can be used, successfully, in a segmentation-based visual object category recognition pipeline."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37895334"
                        ],
                        "name": "S. Fidler",
                        "slug": "S.-Fidler",
                        "structuredName": {
                            "firstName": "Sanja",
                            "lastName": "Fidler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fidler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3012475"
                        ],
                        "name": "Roozbeh Mottaghi",
                        "slug": "Roozbeh-Mottaghi",
                        "structuredName": {
                            "firstName": "Roozbeh",
                            "lastName": "Mottaghi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roozbeh Mottaghi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2422559"
                        ],
                        "name": "R. Urtasun",
                        "slug": "R.-Urtasun",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Urtasun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Urtasun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "It has also been used to generate additional features for bounding box detectors [11] and in video segmentation [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 155
                            }
                        ],
                        "text": "Recognition pipelines based on these segment proposals have significantly advanced the state-of-the-art in both object detection and semantic segmentation [27, 1, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 501222,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06b2739f4daba0382870f7e34ab653fa444993c0",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we are interested in how semantic segmentation can help object detection. Towards this goal, we propose a novel deformable part-based model which exploits region-based segmentation algorithms that compute candidate object regions by bottom-up clustering followed by ranking of those regions. Our approach allows every detection hypothesis to select a segment (including void), and scores each box in the image using both the traditional HOG filters as well as a set of novel segmentation features. Thus our model ``blends'' between the detector and segmentation models. Since our features can be computed very efficiently given the segments, we maintain the same complexity as the original DPM. We demonstrate the effectiveness of our approach in PASCAL VOC 2010, and show that when employing only a root filter our approach outperforms Dalal & Triggs detector on all classes, achieving 13% higher average AP. When employing the parts, we outperform the original DPM in $19$ out of $20$ classes, achieving an improvement of 8% AP. Furthermore, we outperform the previous state-of-the-art on VOC 2010 test by 4%."
            },
            "slug": "Bottom-Up-Segmentation-for-Top-Down-Detection-Fidler-Mottaghi",
            "title": {
                "fragments": [],
                "text": "Bottom-Up Segmentation for Top-Down Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A novel deformable part-based model which exploits region-based segmentation algorithms that compute candidate object regions by bottom-up clustering followed by ranking of those regions that outperform the previous state-of-the-art on VOC 2010 test by 4%."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790580"
                        ],
                        "name": "Bharath Hariharan",
                        "slug": "Bharath-Hariharan",
                        "structuredName": {
                            "firstName": "Bharath",
                            "lastName": "Hariharan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bharath Hariharan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39599498"
                        ],
                        "name": "Chunhui Gu",
                        "slug": "Chunhui-Gu",
                        "structuredName": {
                            "firstName": "Chunhui",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chunhui Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144157872"
                        ],
                        "name": "Saurabh Gupta",
                        "slug": "Saurabh-Gupta",
                        "structuredName": {
                            "firstName": "Saurabh",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saurabh Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769383"
                        ],
                        "name": "Lubomir D. Bourdev",
                        "slug": "Lubomir-D.-Bourdev",
                        "structuredName": {
                            "firstName": "Lubomir",
                            "lastName": "Bourdev",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubomir D. Bourdev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 155
                            }
                        ],
                        "text": "Recognition pipelines based on these segment proposals have significantly advanced the state-of-the-art in both object detection and semantic segmentation [27, 1, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 118
                            }
                        ],
                        "text": "The resulting pool of multiple figure-ground segment proposals has been applied successfully in semantic segmentation [27, 1] as training/testing examples, leading to top scores in the PASCAL VOC segmentation challenge."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2278554,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1395f0561db13cad21a519e18be111cbe1e6d818",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of segmenting and recognizing objects in real world images, focusing on challenging articulated categories such as humans and other animals. For this purpose, we propose a novel design for region-based object detectors that integrates efficiently top-down information from scanning-windows part models and global appearance cues. Our detectors produce class-specific scores for bottom-up regions, and then aggregate the votes of multiple overlapping candidates through pixel classification. We evaluate our approach on the PASCAL segmentation challenge, and report competitive performance with respect to current leading techniques. On VOC2010, our method obtains the best results in 6/20 categories and the highest performance on articulated objects."
            },
            "slug": "Semantic-segmentation-using-regions-and-parts-Arbel\u00e1ez-Hariharan",
            "title": {
                "fragments": [],
                "text": "Semantic segmentation using regions and parts"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel design for region-based object detectors that integrates efficiently top-down information from scanning-windows part models and global appearance cues is proposed that produces class-specific scores for bottom-up regions, and then aggregate the votes of multiple overlapping candidates through pixel classification."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064379349"
                        ],
                        "name": "David J. Weiss",
                        "slug": "David-J.-Weiss",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Weiss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "Without supervision, systems such as [9, 6, 19, 34, 31] are able to generate a pool of overlapping segment proposals, where most foreground objects are captured by at least one segment from the pool."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 90
                            }
                        ],
                        "text": "Later, shape priors were introduced to improve the segmentation of objects of known shape [19, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8448043,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac3a851577a62e2ca908c8a8a48714b7d0fa3acd",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose SCALPEL, a flexible method for object segmentation that integrates rich region-merging cues with mid- and high-level information about object layout, class, and scale into the segmentation process. Unlike competing approaches, SCALPEL uses a cascade of bottom-up segmentation models that is capable of learning to ignore boundaries early on, yet use them as a stopping criterion once the object has been mostly segmented. Furthermore, we show how such cascades can be learned efficiently. When paired with a novel method that generates better localized shape priors than our competitors, our method leads to a concise, accurate set of segmentation proposals, these proposals are more accurate on the PASCAL VOC2010 dataset than state-of-the-art methods that use re-ranking to filter much larger bags of proposals. The code for our algorithm is available online."
            },
            "slug": "SCALPEL:-Segmentation-Cascades-with-Localized-and-Weiss-Taskar",
            "title": {
                "fragments": [],
                "text": "SCALPEL: Segmentation Cascades with Localized Priors and Efficient Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "SCALPEL is a flexible method for object segmentation that integrates rich region-merging cues with mid- and high-level information about object layout, class, and scale into the segmentation process and uses a cascade of bottom-up segmentation models that is capable of learning to ignore boundaries early on, yet use them as a stopping criterion once the object has been mostly segmented."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109202643"
                        ],
                        "name": "Jaechul Kim",
                        "slug": "Jaechul-Kim",
                        "structuredName": {
                            "firstName": "Jaechul",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaechul Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 90
                            }
                        ],
                        "text": "Later, shape priors were introduced to improve the segmentation of objects of known shape [19, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "Without supervision, systems such as [9, 6, 19, 34, 31] are able to generate a pool of overlapping segment proposals, where most foreground objects are captured by at least one segment from the pool."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 172
                            }
                        ],
                        "text": "State-of-the-art figure-ground segmentation methods perform parametric min-cut on multiple seed graphs created by enumerating foreground seeds at different image locations [6, 9, 19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 190
                            }
                        ],
                        "text": "1http://cpl.cc.gatech.edu/projects/RIGOR/\nMethod Mean Best Mean Best Run Number of Overlap Covering Time (s) Segments CPMC 70.67 82.24 34.01 624.1 Object Proposals 71.48 80.98 126.46 1544.1 Shape Sharing 67.82 82.71 410.31 1115.4\nR IG\nO R GB-25 68.04 79.83 4.62 808.7 SketchTokens-25 67.33 78.94 2.75 839.1 StructEdges-25 68.85 79.89 2.16 741.9 GB-64 72.83 82.55 6.99 1490.3 SketchTokens-64 72.62 82.05 4.84 1630.5 StructEdges-64 73.64 82.84 4.71 1462.8 GB-100 74.22 83.25 9.26 1781.9 SketchTokens-100 73.78 82.61 6.80 1995.7 StructEdges-100 75.19 83.52 6.84 1828.7\nTable 1: VOC performance and timing results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "Our algorithm is compared against CPMC [6], Object Proposals [9], and Shape Sharing [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18833642,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e8a94e91ed5e5c154021dfa917b8357746d20da",
            "isKey": true,
            "numCitedBy": 76,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a category-independent shape prior for object segmentation. Existing shape priors assume class-specific knowledge, and thus are restricted to cases where the object class is known in advance. The main insight of our approach is that shapes are often shared between objects of different categories. To exploit this \"shape sharing\" phenomenon, we develop a non-parametric prior that transfers object shapes from an exemplar database to a test image based on local shape matching. The transferred shape priors are then enforced in a graph-cut formulation to produce a pool of object segment hypotheses. Unlike previous multiple segmentation methods, our approach benefits from global shape cues; unlike previous top-down methods, it assumes no class-specific training and thus enhances segmentation even for unfamiliar categories. On the challenging PASCAL 2010 and Berkeley Segmentation datasets, we show it outperforms the state-of-the-art in bottom-up or category-independent segmentation."
            },
            "slug": "Shape-Sharing-for-Object-Segmentation-Kim-Grauman",
            "title": {
                "fragments": [],
                "text": "Shape Sharing for Object Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A non-parametric prior is developed that transfers object shapes from an exemplar database to a test image based on local shape matching and is enforced in a graph-cut formulation to produce a pool of object segment hypotheses."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3141988"
                        ],
                        "name": "Fuxin Li",
                        "slug": "Fuxin-Li",
                        "structuredName": {
                            "firstName": "Fuxin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fuxin Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35681810"
                        ],
                        "name": "Jo\u00e3o Carreira",
                        "slug": "Jo\u00e3o-Carreira",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Carreira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Carreira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 155
                            }
                        ],
                        "text": "Recognition pipelines based on these segment proposals have significantly advanced the state-of-the-art in both object detection and semantic segmentation [27, 1, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 118
                            }
                        ],
                        "text": "The resulting pool of multiple figure-ground segment proposals has been applied successfully in semantic segmentation [27, 1] as training/testing examples, leading to top scores in the PASCAL VOC segmentation challenge."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7625628,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ec1f8cbe8c9da709d519f99fc670604c268742f",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to visual object-class recognition and segmentation based on a pipeline that combines multiple, holistic figure-ground hypotheses generated in a bottom-up, object independent process. Decisions are performed based on continuous estimates of the spatial overlap between image segment hypotheses and each putative class. We differ from existing approaches not only in our seemingly unreasonable assumption that good object-level segments can be obtained in a feed-forward fashion, but also in framing recognition as a regression problem. Instead of focusing on a one-vs-all winning margin that can scramble ordering inside the non-maximum (non-winning) set, learning produces a globally consistent ranking with close ties to segment quality, hence to the extent entire object or part hypotheses spatially overlap with the ground truth. We demonstrate results beyond the current state of the art for image classification, object detection and semantic segmentation, in a number of challenging datasets including Caltech-101, ETHZ-Shape and PASCAL VOC 2009."
            },
            "slug": "Object-recognition-as-ranking-holistic-hypotheses-Li-Carreira",
            "title": {
                "fragments": [],
                "text": "Object recognition as ranking holistic figure-ground hypotheses"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Results are demonstrated beyond the current state of the art for image classification, object detection and semantic segmentation, in a number of challenging datasets including Caltech-101, ETHZ-Shape and PASCAL VOC 2009."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699161"
                        ],
                        "name": "C. L. Zitnick",
                        "slug": "C.-L.-Zitnick",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Zitnick",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Zitnick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 35
                            }
                        ],
                        "text": "Time (ms) [5] [20] [17] Ours RIGOR StructEdges-9 632.8 347.5 502.2 282.1 RIGOR StructEdges-25 1,363.8 825,4 813.5 688.5 RIGOR StructEdges-64 3,181.3 2,038.8 1,511.8 1,846.2\nTable 3: Max-flow/Min-cut timing comparison\n1 4 9 16 25 36 49 64 81 100 0.8x\n1x\n1.2x\n1.4x\n1.6x\n1.8x\n2x\n2.2x\n2.4x\nNumber of seeds\nS pe\ned up\nfa ct\nor\n(a) Comparison to BK [5]\n1 4 9 16 25 36 49 64 81 100 0.9x\n0.95x\n1x\n1.05x\n1.1x\n1.15x\n1.2x\n1.25x\nNumber of seeds\nS pe\ned up\nfa ct\nor\n(b) Comparison to Kohli & Torr [20]\n1 4 9 16 25 36 49 64 81 100 0.5x\n1x\n1.5x\n2x\n2.5x\n3x\n3.5x\n4x\nNumber of seeds\nS pe\ned up\nfa ct\nor\n(c) Comparison to PF [17]\n0\n1\n2\n3 3.2\nStr uc\ntEd ge s Pb Hie rar ch ica l\nSe gm\nen tat\nion\nSu pe\nrp ixe\nls\nCo m\npu ta\ntio n\nTi m\ne (s\n)\nRIGOR StructEdges-64 Object Proposals [9] - Total time 126.46s - Total time 4.71s\nOv erh\nea ds\nSe gm\nen t\nFil tra\ntio n\nPa ram\netr ic Mi n-C ut Un ari es Pa irw ise\n4.5s\n79.9s\n27.9s\n10.6s\n(d) Pipeline timing comparison to Object Proposals [9]\nFigure 5: Timing comparisons."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "We combine our algorithm with three recent approaches for fast boundary detection: GB [25], SketchTokens [28] and StructEdges [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 192
                            }
                        ],
                        "text": "0 20 40 60 80 100 35\n40\n45\n50\n55\n60\n65\n70\n75\n80\n85\nS c o re\n0\n200\n400\n600\n800\n1000\n1200\n1400\n1600\n1800\n2000\nNumber of seeds\nN u m\nb e r\no f S\ne g m\ne n ts\nMean Best Overlap\u2212GB Mean Best Overlap\u2212StructEdges Mean Best Covering\u2212GB Mean Best Covering\u2212StructEdges Number of Segments\u2212GB Number of Segments\u2212StructEdges\nFigure 4: The number of seeds and algorithm performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 318,
                                "start": 307
                            }
                        ],
                        "text": "1http://cpl.cc.gatech.edu/projects/RIGOR/\nMethod Mean Best Mean Best Run Number of Overlap Covering Time (s) Segments CPMC 70.67 82.24 34.01 624.1 Object Proposals 71.48 80.98 126.46 1544.1 Shape Sharing 67.82 82.71 410.31 1115.4\nR IG\nO R GB-25 68.04 79.83 4.62 808.7 SketchTokens-25 67.33 78.94 2.75 839.1 StructEdges-25 68.85 79.89 2.16 741.9 GB-64 72.83 82.55 6.99 1490.3 SketchTokens-64 72.62 82.05 4.84 1630.5 StructEdges-64 73.64 82.84 4.71 1462.8 GB-100 74.22 83.25 9.26 1781.9 SketchTokens-100 73.78 82.61 6.80 1995.7 StructEdges-100 75.19 83.52 6.84 1828.7\nTable 1: VOC performance and timing results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 53
                            }
                        ],
                        "text": "It can be seen that improvements are significant for StructEdges, which has higher recall but more false positives."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 19
                            }
                        ],
                        "text": "(d) compares RIGOR StructEdges-64 timing of each component in the pipeline to its counterpart in [9]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 44
                            }
                        ],
                        "text": "Method Mean Best Mean Best Overlap Covering\nStructEdges-Median 67.59 80.27 StructEdges-Mean 69.96 81.82 StructEdges-Learned 73.64 82.84 GB-Median 71.38 82.42 GB-Mean 72.67 82.39\nGB-Learned 72.83 82.55\nTable 2: Effects of learning pairwise potentials, on 64 seeds per image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 7
                            }
                        ],
                        "text": "GB and StructEdges perform similarly in covering, but StructEdges is slightly better in overlap, potentially due to better boundary recall than GB. Interestingly, even with only 9 seeds the algorithm already has a mean best overlap of about 60% and a covering more than 75%, finding most foreground objects in the scene."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 39
                            }
                        ],
                        "text": "The number after GB, SketchTokens, and StructEdges indicates the amount of seeds used."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10702897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e8ce202fb51cd11d2b926e7ad21e08a58a43903",
            "isKey": true,
            "numCitedBy": 869,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Edge detection is a critical component of many vision systems, including object detectors and image segmentation algorithms. Patches of edges exhibit well-known forms of local structure, such as straight lines or T-junctions. In this paper we take advantage of the structure present in local image patches to learn both an accurate and computationally efficient edge detector. We formulate the problem of predicting local edge masks in a structured learning framework applied to random decision forests. Our novel approach to learning decision trees robustly maps the structured labels to a discrete space on which standard information gain measures may be evaluated. The result is an approach that obtains real time performance that is orders of magnitude faster than many competing state-of-the-art approaches, while also achieving state-of-the-art edge detection results on the BSDS500 Segmentation dataset and NYU Depth dataset. Finally, we show the potential of our approach as a general purpose edge detector by showing our learned edge models generalize well across datasets."
            },
            "slug": "Structured-Forests-for-Fast-Edge-Detection-Doll\u00e1r-Zitnick",
            "title": {
                "fragments": [],
                "text": "Structured Forests for Fast Edge Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper forms the problem of predicting local edge masks in a structured learning framework applied to random decision forests and develops a novel approach to learning decision trees robustly maps the structured labels to a discrete space on which standard information gain measures may be evaluated."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Computer Vision"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144197071"
                        ],
                        "name": "M. Jolly",
                        "slug": "M.-Jolly",
                        "structuredName": {
                            "firstName": "Marie-Pierre",
                            "lastName": "Jolly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jolly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "Boykov and Jolly [4] proposed a scheme to reparameterize a graph when only a small amount of unary capacities change."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "2 Reparameterizations: Boykov and Jolly [4] demonstrated that if the capacity difference, cu = csu\u2212cut, remains unchanged in a new graph, the min-cut would be the same as in the original graph, and only the flow value would change."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 56
                            }
                        ],
                        "text": "We utilize the reparametrization technique described in [4, 20], which demonstrated that if only unaries change, one can reparameterize a graph so that the min-cut does not change and only the flow value changes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 53
                            }
                        ],
                        "text": "In addition, the graph reparameterization methods of [4, 20] are iterative approaches, where the max-flow for a graph needs to be computed before it can be utilized for another graph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 76
                            }
                        ],
                        "text": "These seed node unaries are reparameterized in the same way as explained in [20, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 27
                            }
                        ],
                        "text": "3.2.2 Reparameterizations: Boykov and Jolly [4] demonstrated that if the capacity difference, cu = csu\u2212cut, remains unchanged in a new graph, the min-cut would be the same as in the original graph, and only the flow value would change."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2245438,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d3b177e8d027d44c191e739a3a70ccacc2eac82",
            "isKey": true,
            "numCitedBy": 4175,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new technique for general purpose interactive segmentation of N-dimensional images. The user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation. Additional soft constraints incorporate both boundary and region information. Graph cuts are used to find the globally optimal segmentation of the N-dimensional image. The obtained solution gives the best balance of boundary and region properties among all segmentations satisfying the constraints. The topology of our segmentation is unrestricted and both \"object\" and \"background\" segments may consist of several isolated parts. Some experimental results are presented in the context of photo/video editing and medical image segmentation. We also demonstrate an interesting Gestalt example. A fast implementation of our segmentation method is possible via a new max-flow algorithm."
            },
            "slug": "Interactive-graph-cuts-for-optimal-boundary-&-of-in-Boykov-Jolly",
            "title": {
                "fragments": [],
                "text": "Interactive graph cuts for optimal boundary & region segmentation of objects in N-D images"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A new technique for general purpose interactive segmentation of N-dimensional images where the user marks certain pixels as \"object\" or \"background\" to provide hard constraints for segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967473"
                        ],
                        "name": "Pushmeet Kohli",
                        "slug": "Pushmeet-Kohli",
                        "structuredName": {
                            "firstName": "Pushmeet",
                            "lastName": "Kohli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushmeet Kohli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635540"
                        ],
                        "name": "Philip H. S. Torr",
                        "slug": "Philip-H.-S.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip H. S. Torr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "In order to reuse the S, T trees from BK, [20] runs an adoption like stage from BK to reflect the change to a new graph."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 483,
                                "start": 479
                            }
                        ],
                        "text": "Time (ms) [5] [20] [17] Ours RIGOR StructEdges-9 632.8 347.5 502.2 282.1 RIGOR StructEdges-25 1,363.8 825,4 813.5 688.5 RIGOR StructEdges-64 3,181.3 2,038.8 1,511.8 1,846.2\nTable 3: Max-flow/Min-cut timing comparison\n1 4 9 16 25 36 49 64 81 100 0.8x\n1x\n1.2x\n1.4x\n1.6x\n1.8x\n2x\n2.2x\n2.4x\nNumber of seeds\nS pe\ned up\nfa ct\nor\n(a) Comparison to BK [5]\n1 4 9 16 25 36 49 64 81 100 0.9x\n0.95x\n1x\n1.05x\n1.1x\n1.15x\n1.2x\n1.25x\nNumber of seeds\nS pe\ned up\nfa ct\nor\n(b) Comparison to Kohli & Torr [20]\n1 4 9 16 25 36 49 64 81 100 0.5x\n1x\n1.5x\n2x\n2.5x\n3x\n3.5x\n4x\nNumber of seeds\nS pe\ned up\nfa ct\nor\n(c) Comparison to PF [17]\n0\n1\n2\n3 3.2\nStr uc\ntEd ge s Pb Hie rar ch ica l\nSe gm\nen tat\nion\nSu pe\nrp ixe\nls\nCo m\npu ta\ntio n\nTi m\ne (s\n)\nRIGOR StructEdges-64 Object Proposals [9] - Total time 126.46s - Total time 4.71s\nOv erh\nea ds\nSe gm\nen t\nFil tra\ntio n\nPa ram\netr ic Mi n-C ut Un ari es Pa irw ise\n4.5s\n79.9s\n27.9s\n10.6s\n(d) Pipeline timing comparison to Object Proposals [9]\nFigure 5: Timing comparisons."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "Graph Cuts Over Multiple Seed Enumerations In order to reuse the S, T trees from BK, [20] runs an adoption like stage from BK to reflect the change to a new graph."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 56
                            }
                        ],
                        "text": "We utilize the reparametrization technique described in [4, 20], which demonstrated that if only unaries change, one can reparameterize a graph so that the min-cut does not change and only the flow value changes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "This is similar to the condition in BK, where an orphan node from S cannot be directly adopted by T , and vice versa."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "One can see two benefits of the precomputation graph: (1) reusing tree structure is faster than building new trees, as also demonstrated by [20]; and (2) some nodes are never revisited after precomputation (nodes 10, 13, 14 in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Motivated by [20], we propose a precomputation step which builds a tree from s for each foreground seed Si."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "(b) Comparison to Kohli & Torr [20] 1 4 9 16 25 36 49 64 81 100 0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 53
                            }
                        ],
                        "text": "In addition, the graph reparameterization methods of [4, 20] are iterative approaches, where the max-flow for a graph needs to be computed before it can be utilized for another graph."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Time (ms) [5] [20] [17] Ours RIGOR StructEdges-9 632."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 76
                            }
                        ],
                        "text": "These seed node unaries are reparameterized in the same way as explained in [20, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Kohli and Torr [20] identified how max-flow could be reused even when edge capacities change between graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Kohli and Torr [20]\u2019s implementation comes packaged with BK."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6967934,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7128f74f1d5ed0bf28629e1a6b0d6c39bb08cba3",
            "isKey": true,
            "numCitedBy": 251,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a fast new fully dynamic algorithm for the st-mincut/max-flow problem. We show how this algorithm can be used to efficiently compute MAP solutions for certain dynamically changing MRF models in computer vision such as image segmentation. Specifically, given the solution of the max-flow problem on a graph, the dynamic algorithm efficiently computes the maximum flow in a modified version of the graph. The time taken by it is roughly proportional to the total amount of change in the edge weights of the graph. Our experiments show that, when the number of changes in the graph is small, the dynamic algorithm is significantly faster than the best known static graph cut algorithm. We test the performance of our algorithm on one particular problem: the object-background segmentation problem for video. It should be noted that the application of our algorithm is not limited to the above problem, the algorithm is generic and can be used to yield similar improvements in many other cases that involve dynamic change."
            },
            "slug": "Dynamic-Graph-Cuts-for-Efficient-Inference-in-Kohli-Torr",
            "title": {
                "fragments": [],
                "text": "Dynamic Graph Cuts for Efficient Inference in Markov Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A fast new fully dynamic algorithm for the st-mincut/max-flow problem and how this algorithm can be used to efficiently compute MAP solutions for certain dynamically changing MRF models in computer vision such as image segmentation is shown."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144756076"
                        ],
                        "name": "Yong Jae Lee",
                        "slug": "Yong-Jae-Lee",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Lee",
                            "middleNames": [
                                "Jae"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Jae Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109202643"
                        ],
                        "name": "Jaechul Kim",
                        "slug": "Jaechul-Kim",
                        "structuredName": {
                            "firstName": "Jaechul",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaechul Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "It has also been used to generate additional features for bounding box detectors [11] and in video segmentation [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "This makes segmentation-based methods impractical for large-scale or real-time applications, such as video analysis [24], object tracking or robotics."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3185202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a213ec900a4e245f31413dc35c2c2e9ae2f09c88",
            "isKey": false,
            "numCitedBy": 485,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to discover and segment foreground object(s) in video. Given an unannotated video sequence, the method first identifies object-like regions in any frame according to both static and dynamic cues. We then compute a series of binary partitions among those candidate \u201ckey-segments\u201d to discover hypothesis groups with persistent appearance and motion. Finally, using each ranked hypothesis in turn, we estimate a pixel-level object labeling across all frames, where (a) the foreground likelihood depends on both the hypothesis's appearance as well as a novel localization prior based on partial shape matching, and (b) the background likelihood depends on cues pulled from the key-segments' (possibly diverse) surroundings observed across the sequence. Compared to existing methods, our approach automatically focuses on the persistent foreground regions of interest while resisting oversegmentation. We apply our method to challenging benchmark videos, and show competitive or better results than the state-of-the-art."
            },
            "slug": "Key-segments-for-video-object-segmentation-Lee-Kim",
            "title": {
                "fragments": [],
                "text": "Key-segments for video object segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The method first identifies object-like regions in any frame according to both static and dynamic cues and compute a series of binary partitions among candidate \u201ckey-segments\u201d to discover hypothesis groups with persistent appearance and motion."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758056"
                        ],
                        "name": "A. Stein",
                        "slug": "A.-Stein",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Stein",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1750601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55f9b470cb7eb91797ab1553cdf9d84a11006a80",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Occlusion reasoning, necessary for tasks such as navigation and object search, is an important aspect of everyday life and a fundamental problem in computer vision. We believe that the amazing ability of humans to reason about occlusions from one image is based on an intrinsically 3D interpretation. In this paper, our goal is to recover the occlusion boundaries and depth ordering of free-standing structures in the scene. Our approach is to learn to identify and label occlusion boundaries using the traditional edge and region cues together with 3D surface and depth cues. Since some of these cues require good spatial support (i.e., a segmentation), we gradually create larger regions and use them to improve inference over the boundaries. Our experiments demonstrate the power of a scene-based approach to occlusion reasoning."
            },
            "slug": "Recovering-Occlusion-Boundaries-from-a-Single-Image-Hoiem-Stein",
            "title": {
                "fragments": [],
                "text": "Recovering Occlusion Boundaries from a Single Image"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The goal is to recover the occlusion boundaries and depth ordering of free-standing structures in the scene using the traditional edge and region cues together with 3D surface and depth cues."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831988"
                        ],
                        "name": "Ian Endres",
                        "slug": "Ian-Endres",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Endres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Endres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 758,
                                "start": 742
                            }
                        ],
                        "text": "Time (ms) [5] [20] [17] Ours RIGOR StructEdges-9 632.8 347.5 502.2 282.1 RIGOR StructEdges-25 1,363.8 825,4 813.5 688.5 RIGOR StructEdges-64 3,181.3 2,038.8 1,511.8 1,846.2\nTable 3: Max-flow/Min-cut timing comparison\n1 4 9 16 25 36 49 64 81 100 0.8x\n1x\n1.2x\n1.4x\n1.6x\n1.8x\n2x\n2.2x\n2.4x\nNumber of seeds\nS pe\ned up\nfa ct\nor\n(a) Comparison to BK [5]\n1 4 9 16 25 36 49 64 81 100 0.9x\n0.95x\n1x\n1.05x\n1.1x\n1.15x\n1.2x\n1.25x\nNumber of seeds\nS pe\ned up\nfa ct\nor\n(b) Comparison to Kohli & Torr [20]\n1 4 9 16 25 36 49 64 81 100 0.5x\n1x\n1.5x\n2x\n2.5x\n3x\n3.5x\n4x\nNumber of seeds\nS pe\ned up\nfa ct\nor\n(c) Comparison to PF [17]\n0\n1\n2\n3 3.2\nStr uc\ntEd ge s Pb Hie rar ch ica l\nSe gm\nen tat\nion\nSu pe\nrp ixe\nls\nCo m\npu ta\ntio n\nTi m\ne (s\n)\nRIGOR StructEdges-64 Object Proposals [9] - Total time 126.46s - Total time 4.71s\nOv erh\nea ds\nSe gm\nen t\nFil tra\ntio n\nPa ram\netr ic Mi n-C ut Un ari es Pa irw ise\n4.5s\n79.9s\n27.9s\n10.6s\n(d) Pipeline timing comparison to Object Proposals [9]\nFigure 5: Timing comparisons."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "Without supervision, systems such as [9, 6, 19, 34, 31] are able to generate a pool of overlapping segment proposals, where most foreground objects are captured by at least one segment from the pool."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 172
                            }
                        ],
                        "text": "State-of-the-art figure-ground segmentation methods perform parametric min-cut on multiple seed graphs created by enumerating foreground seeds at different image locations [6, 9, 19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 47
                            }
                        ],
                        "text": "Our segmentation algorithm, like other methods [9, 6], uses graph min-cuts from multiple seeds to compute segments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 147
                            }
                        ],
                        "text": "1http://cpl.cc.gatech.edu/projects/RIGOR/\nMethod Mean Best Mean Best Run Number of Overlap Covering Time (s) Segments CPMC 70.67 82.24 34.01 624.1 Object Proposals 71.48 80.98 126.46 1544.1 Shape Sharing 67.82 82.71 410.31 1115.4\nR IG\nO R GB-25 68.04 79.83 4.62 808.7 SketchTokens-25 67.33 78.94 2.75 839.1 StructEdges-25 68.85 79.89 2.16 741.9 GB-64 72.83 82.55 6.99 1490.3 SketchTokens-64 72.62 82.05 4.84 1630.5 StructEdges-64 73.64 82.84 4.71 1462.8 GB-100 74.22 83.25 9.26 1781.9 SketchTokens-100 73.78 82.61 6.80 1995.7 StructEdges-100 75.19 83.52 6.84 1828.7\nTable 1: VOC performance and timing results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "We adopted the superpixel graph from [9], which is created by computing the watershed image from soft edge potentials before non-maximum suppression [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "Se gm en tat ion Su pe rp ixe ls Co m pu ta tio n Ti m e (s ) RIGOR StructEdges-64 Object Proposals [9] - Total time 126."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "Our algorithm is compared against CPMC [6], Object Proposals [9], and Shape Sharing [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "(d) compares RIGOR StructEdges-64 timing of each component in the pipeline to its counterpart in [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "(d) Pipeline timing comparison to Object Proposals [9]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "This led to multiple image segmentation approaches such as CPMC [6], object proposals [9] and contour completion [26] that produce objects of different sizes by enumerating multiple unary parameters related to object size."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 697224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0640da2565bad7037d969e9f07276c10102083d",
            "isKey": true,
            "numCitedBy": 495,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a category-independent method to produce a bag of regions and rank them, such that top-ranked regions are likely to be good segmentations of different objects. Our key objectives are completeness and diversity: every object should have at least one good proposed region, and a diverse set should be top-ranked. Our approach is to generate a set of segmentations by performing graph cuts based on a seed region and a learned affinity function. Then, the regions are ranked using structured learning based on various cues. Our experiments on BSDS and PASCAL VOC 2008 demonstrate our ability to find most objects within a small bag of proposed regions."
            },
            "slug": "Category-Independent-Object-Proposals-Endres-Hoiem",
            "title": {
                "fragments": [],
                "text": "Category Independent Object Proposals"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A category-independent method to produce a bag of regions and rank them, such that top-ranked regions are likely to be good segmentations of different objects, and the ability to find most objects within a small bag of proposed regions is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756036"
                        ],
                        "name": "C. Rother",
                        "slug": "C.-Rother",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Rother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[22, 21] characterized the submodular functions that can be optimized globally with graph cut, especially the parametric max-flow formulation [21] that produces cuts with multiple unary terms at the same time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7582545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce7dc3a992201ee7b6706c6a8f12b41496691ea2",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "The maximum flow algorithm for minimizing energy functions of binary variables has become a standard tool in computer vision. In many cases, unary costs of the energy depend linearly on parameter lambda. In this paper we study vision applications for which it is important to solve the maxflow problem for different lambda's. An example is a weighting between data and regularization terms in image segmentation or stereo: it is desirable to vary it both during training (to learn lambda from ground truth data) and testing (to select best lambda using high-knowledge constraints, e.g. user input). We review algorithmic aspects of this parametric maximum flow problem previously unknown in vision, such as the ability to compute all breakpoints of lambda and corresponding optimal configurations infinite time. These results allow, in particular, to minimize the ratio of some geometric functional, such as flux of a vector field over length (or area). Previously, such functional were tackled with shortest path techniques applicable only in 2D. We give theoretical improvements for \"PDE cuts\" [5]. We present experimental results for image segmentation, 3D reconstruction, and the cosegmentation problem."
            },
            "slug": "Applications-of-parametric-maxflow-in-computer-Kolmogorov-Boykov",
            "title": {
                "fragments": [],
                "text": "Applications of parametric maxflow in computer vision"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Algorithmic aspects of this parametric maximum flow problem previously unknown in vision, such as the ability to compute all breakpoints of lambda and corresponding optimal configurations infinite time are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329582"
                        ],
                        "name": "Alex Levinshtein",
                        "slug": "Alex-Levinshtein",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Levinshtein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Levinshtein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779136"
                        ],
                        "name": "S. Dickinson",
                        "slug": "S.-Dickinson",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Dickinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dickinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "This led to multiple image segmentation approaches such as CPMC [6], object proposals [9] and contour completion [26] that produce objects of different sizes by enumerating multiple unary parameters related to object size."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3165684,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "b461bbc3a5a5cc4a2e0550949eac77de3a346ac9",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting contour closure, i.e., finding a cycle of disconnected contour fragments that separates an object from its background, is an important problem in perceptual grouping. Searching the entire space of possible groupings is intractable, and previous approaches have adopted powerful perceptual grouping heuristics, such as proximity and co-curvilinearity, to manage the search. We introduce a new formulation of the problem, by transforming the problem of finding cycles of contour fragments to finding subsets of superpixels whose collective boundary has strong edge support in the image. Our cost function, a ratio of a novel learned boundary gap measure to area, promotes spatially coherent sets of superpixels. Moreover, its properties support a global optimization procedure using parametric maxflow. We evaluate our framework by comparing it to two leading contour closure approaches, and find that it yields improved performance."
            },
            "slug": "Optimal-Contour-Closure-by-Superpixel-Grouping-Levinshtein-Sminchisescu",
            "title": {
                "fragments": [],
                "text": "Optimal Contour Closure by Superpixel Grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The problem of finding cycles of contour fragments is transformed to finding subsets of superpixels whose collective boundary has strong edge support in the image, and the cost function, a ratio of a novel learned boundary gap measure to area, promotes spatially coherent sets ofsuperpixels."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98828088"
                        ],
                        "name": "Song Wang",
                        "slug": "Song-Wang",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737754"
                        ],
                        "name": "J. Siskind",
                        "slug": "J.-Siskind",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Siskind",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Siskind"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 147
                            }
                        ],
                        "text": "However, the original min-cut approaches either tend to find foreground regions with a very small size [35] or attempt to solve an NP-hard problem [30, 33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3077189,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e388fbe0f992cdf725b2950fa6cb36bfe9065305",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new cost function, cut ratio, for segmenting images using graph-based methods. The cut ratio is defined as the ratio of the corresponding sums of two different weights of edges along the cut boundary and models the mean affinity between the segments separated by the boundary per unit boundary length. This new cost function allows the image perimeter to be segmented, guarantees that the segments produced by bipartitioning are connected, and does not introduce a size, shape, smoothness, or boundary-length bias. The latter allows it to produce segmentations where boundaries are aligned with image edges. Furthermore, the cut-ratio cost function allows efficient iterated region-based segmentation as well as pixel-based segmentation. These properties may be useful for some image-segmentation applications. While the problem of finding a minimum ratio cut in an arbitrary graph is NP-hard, one can find a minimum ratio cut in the connected planar graphs that arise during image segmentation in polynomial time. While the cut ratio, alone, is not sufficient as a baseline method for image segmentation, it forms a good basis for an extended method of image segmentation when combined with a small number of standard techniques. We present an implemented algorithm for finding a minimum ratio cut, prove its correctness, discuss its application to image segmentation, and present the results of segmenting a number of medical and natural images using our techniques."
            },
            "slug": "Image-Segmentation-with-Ratio-Cut-Wang-Siskind",
            "title": {
                "fragments": [],
                "text": "Image Segmentation with Ratio Cut"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A new cost function, cut ratio, for segmenting images using graph-based methods that allows the image perimeter to be segmented, guarantees that the segments produced by bipartitioning are connected, and does not introduce a size, shape, smoothness, or boundary-length bias."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749627"
                        ],
                        "name": "M. Leordeanu",
                        "slug": "M.-Leordeanu",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Leordeanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leordeanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694199"
                        ],
                        "name": "R. Sukthankar",
                        "slug": "R.-Sukthankar",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Sukthankar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sukthankar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "We combine our algorithm with three recent approaches for fast boundary detection: GB [25], SketchTokens [28] and StructEdges [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1851952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78b071744be4db2d78e723bb24d978c8105b8f6f",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Boundary detection is essential for a variety of computer vision tasks such as segmentation and recognition. We propose a unified formulation for boundary detection, with closed-form solution, which is applicable to the localization of different types of boundaries, such as intensity edges and occlusion boundaries from video and RGB-D cameras. Our algorithm simultaneously combines low- and mid-level image representations, in a single eigenvalue problem, and we solve over an infinite set of putative boundary orientations. Moreover, our method achieves state of the art results at a significantly lower computational cost than current methods. We also propose a novel method for soft-segmentation that can be used in conjunction with our boundary detection algorithm and improve its accuracy at a negligible extra computational cost."
            },
            "slug": "Efficient-Closed-Form-Solution-to-Generalized-Leordeanu-Sukthankar",
            "title": {
                "fragments": [],
                "text": "Efficient Closed-Form Solution to Generalized Boundary Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A unified formulation for boundary detection, with closed-form solution, which is applicable to the localization of different types of boundaries, such as intensity edges and occlusion boundaries from video and RGB-D cameras is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109780936"
                        ],
                        "name": "Joseph J. Lim",
                        "slug": "Joseph-J.-Lim",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Lim",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph J. Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699161"
                        ],
                        "name": "C. L. Zitnick",
                        "slug": "C.-L.-Zitnick",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Zitnick",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Zitnick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 21
                            }
                        ],
                        "text": "The number after GB, SketchTokens, and StructEdges indicates the amount of seeds used."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 268
                            }
                        ],
                        "text": "1http://cpl.cc.gatech.edu/projects/RIGOR/\nMethod Mean Best Mean Best Run Number of Overlap Covering Time (s) Segments CPMC 70.67 82.24 34.01 624.1 Object Proposals 71.48 80.98 126.46 1544.1 Shape Sharing 67.82 82.71 410.31 1115.4\nR IG\nO R GB-25 68.04 79.83 4.62 808.7 SketchTokens-25 67.33 78.94 2.75 839.1 StructEdges-25 68.85 79.89 2.16 741.9 GB-64 72.83 82.55 6.99 1490.3 SketchTokens-64 72.62 82.05 4.84 1630.5 StructEdges-64 73.64 82.84 4.71 1462.8 GB-100 74.22 83.25 9.26 1781.9 SketchTokens-100 73.78 82.61 6.80 1995.7 StructEdges-100 75.19 83.52 6.84 1828.7\nTable 1: VOC performance and timing results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 10
                            }
                        ],
                        "text": "Note that SketchTokens results have not been included since they are consistently worse than the two other boundary detectors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "We combine our algorithm with three recent approaches for fast boundary detection: GB [25], SketchTokens [28] and StructEdges [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2792395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b71a01be65d5040809b409105b77f0da810d057",
            "isKey": true,
            "numCitedBy": 372,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach to both learning and detecting local contour-based representations for mid-level features. Our features, called sketch tokens, are learned using supervised mid-level information in the form of hand drawn contours in images. Patches of human generated contours are clustered to form sketch token classes and a random forest classifier is used for efficient detection in novel images. We demonstrate our approach on both top-down and bottom-up tasks. We show state-of-the-art results on the top-down task of contour detection while being over 200x faster than competing methods. We also achieve large improvements in detection accuracy for the bottom-up tasks of pedestrian and object detection as measured on INRIA and PASCAL, respectively. These gains are due to the complementary information provided by sketch tokens to low-level features such as gradient histograms."
            },
            "slug": "Sketch-Tokens:-A-Learned-Mid-level-Representation-Lim-Zitnick",
            "title": {
                "fragments": [],
                "text": "Sketch Tokens: A Learned Mid-level Representation for Contour and Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This work proposes a novel approach to both learning and detecting local contour-based representations for mid-level features called sketch tokens, which achieve large improvements in detection accuracy for the bottom-up tasks of pedestrian and object detection as measured on INRIA and PASCAL, respectively."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787591"
                        ],
                        "name": "Christoph H. Lampert",
                        "slug": "Christoph-H.-Lampert",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Lampert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoph H. Lampert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758219"
                        ],
                        "name": "Matthew B. Blaschko",
                        "slug": "Matthew-B.-Blaschko",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Blaschko",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew B. Blaschko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 115
                            }
                        ],
                        "text": "When enumerating bounding boxes and computing their features, tricks such as integral image and distance transform [10, 23] can help to speed-up the computation, even achieving real-time performance in certain tasks [3, 29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6131848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54b224478a63e33441c651175c522f3702062fc4",
            "isKey": false,
            "numCitedBy": 800,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Most successful object recognition systems rely on binary classification, deciding only if an object is present or not, but not providing information on the actual object location. To perform localization, one can take a sliding window approach, but this strongly increases the computational cost, because the classifier function has to be evaluated over a large set of candidate subwindows. In this paper, we propose a simple yet powerful branch-and-bound scheme that allows efficient maximization of a large class of classifier functions over all possible subimages. It converges to a globally optimal solution typically in sublinear time. We show how our method is applicable to different object detection and retrieval scenarios. The achieved speedup allows the use of classifiers for localization that formerly were considered too slow for this task, such as SVMs with a spatial pyramid kernel or nearest neighbor classifiers based on the chi2-distance. We demonstrate state-of-the-art performance of the resulting systems on the UIUC Cars dataset, the PASCAL VOC 2006 dataset and in the PASCAL VOC 2007 competition."
            },
            "slug": "Beyond-sliding-windows:-Object-localization-by-Lampert-Blaschko",
            "title": {
                "fragments": [],
                "text": "Beyond sliding windows: Object localization by efficient subwindow search"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A simple yet powerful branch-and-bound scheme that allows efficient maximization of a large class of classifier functions over all possible subimages and converges to a globally optimal solution typically in sublinear time is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9739979"
                        ],
                        "name": "P. Arbel\u00e1ez",
                        "slug": "P.-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Arbel\u00e1ez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1505240324"
                        ],
                        "name": "C. Fowlkes",
                        "slug": "C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charlotte",
                            "lastName": "Fowlkes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787589"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 149
                            }
                        ],
                        "text": "We adopted the superpixel graph from [9], which is created by computing the watershed image from soft edge potentials before non-maximum suppression [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "Note that CPMC results are about 1% better if the GlobalPB [2] boundaries are used, as in the public version, however, GlobalPB takes much longer to compute and therefore for the timing comparison it puts CPMC in a worse position."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206764694,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e5a262bf59b68ba8a7a1103d16fa33a9f5ffc28",
            "isKey": false,
            "numCitedBy": 4197,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates two fundamental problems in computer vision: contour detection and image segmentation. We present state-of-the-art algorithms for both of these tasks. Our contour detector combines multiple local cues into a globalization framework based on spectral clustering. Our segmentation algorithm consists of generic machinery for transforming the output of any contour detector into a hierarchical region tree. In this manner, we reduce the problem of image segmentation to that of contour detection. Extensive experimental evaluation demonstrates that both our contour detection and segmentation methods significantly outperform competing algorithms. The automatically generated hierarchical segmentations can be interactively refined by user-specified annotations. Computation at multiple image resolutions provides a means of coupling our system to recognition applications."
            },
            "slug": "Contour-Detection-and-Hierarchical-Image-Arbel\u00e1ez-Maire",
            "title": {
                "fragments": [],
                "text": "Contour Detection and Hierarchical Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper investigates two fundamental problems in computer vision: contour detection and image segmentation and presents state-of-the-art algorithms for both of these tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1823362"
                        ],
                        "name": "J. Uijlings",
                        "slug": "J.-Uijlings",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Uijlings",
                            "middleNames": [
                                "R.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Uijlings"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756979"
                        ],
                        "name": "K. V. D. Sande",
                        "slug": "K.-V.-D.-Sande",
                        "structuredName": {
                            "firstName": "Koen",
                            "lastName": "Sande",
                            "middleNames": [
                                "E.",
                                "A.",
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. V. D. Sande"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "Without supervision, systems such as [9, 6, 19, 34, 31] are able to generate a pool of overlapping segment proposals, where most foreground objects are captured by at least one segment from the pool."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 216077384,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38b6540ddd5beebffd05047c78183f7575559fb2",
            "isKey": false,
            "numCitedBy": 4753,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of generating possible object locations for use in object recognition. We introduce selective search which combines the strength of both an exhaustive search and segmentation. Like segmentation, we use the image structure to guide our sampling process. Like exhaustive search, we aim to capture all possible object locations. Instead of a single technique to generate possible object locations, we diversify our search and use a variety of complementary image partitionings to deal with as many image conditions as possible. Our selective search results in a small set of data-driven, class-independent, high quality locations, yielding 99\u00a0% recall and a Mean Average Best Overlap of 0.879 at 10,097 locations. The reduced number of locations compared to an exhaustive search enables the use of stronger machine learning techniques and stronger appearance models for object recognition. In this paper we show that our selective search enables the use of the powerful Bag-of-Words model for recognition. The selective search software is made publicly available (Software: http://disi.unitn.it/~uijlings/SelectiveSearch.html)."
            },
            "slug": "Selective-Search-for-Object-Recognition-Uijlings-Sande",
            "title": {
                "fragments": [],
                "text": "Selective Search for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This paper introduces selective search which combines the strength of both an exhaustive search and segmentation, and shows that its selective search enables the use of the powerful Bag-of-Words model for recognition."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066180438"
                        ],
                        "name": "Tanmay Verma",
                        "slug": "Tanmay-Verma",
                        "structuredName": {
                            "firstName": "Tanmay",
                            "lastName": "Verma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tanmay Verma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746610"
                        ],
                        "name": "Dhruv Batra",
                        "slug": "Dhruv-Batra",
                        "structuredName": {
                            "firstName": "Dhruv",
                            "lastName": "Batra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dhruv Batra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Verma and Batra [32] quantitatively tested different maxflow algorithms in vision applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6850537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a77bf5e284c1c85308ebc6a529fed535dd91c7d6",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for finding the maximum amount of flow possible in a network (or maxflow) play a central role in computer vision problems. We present an empirical comparison of different max-flow algorithms on modern problems. Our problem instances arise from energy minimization problems in Object Category Segmentation, Image Deconvolution, Super Resolution, Texture Restoration, Character Completion and 3D Segmentation. We compare 14 different implementations and find that the most popularly used implementation of Kolmogorov [5] is no longer the fastest algorithm available, especially for dense graphs."
            },
            "slug": "MaxFlow-Revisited:-An-Empirical-Comparison-of-for-Verma-Batra",
            "title": {
                "fragments": [],
                "text": "MaxFlow Revisited: An Empirical Comparison of Maxflow Algorithms for Dense Vision Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is found that the most popularly used implementation of Kolmogorov is no longer the fastest algorithm available, especially for dense graphs, and 14 different implementations are compared."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21160985"
                        ],
                        "name": "M. Sadeghi",
                        "slug": "M.-Sadeghi",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Sadeghi",
                            "middleNames": [
                                "Amin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sadeghi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6207389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29623191b1fa8c92027cc46e165c56a9eda0e8a4",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Applying linear templates is an integral part of many object detection systems and accounts for a significant portion of computation time. We describe a method that achieves a substantial end-to-end speedup over the best current methods, without loss of accuracy. Our method is a combination of approximating scores by vector quantizing feature windows and a number of speedup techniques including cascade. Our procedure allows speed and accuracy to be traded off in two ways: by choosing the number of Vector Quantization levels, and by choosing to rescore windows or not. Our method can be directly plugged into any recognition system that relies on linear templates. We demonstrate our method to speed up the original Exemplar SVM detector [1] by an order of magnitude and Deformable Part models [2] by two orders of magnitude with no loss of accuracy."
            },
            "slug": "Fast-Template-Evaluation-with-Vector-Quantization-Sadeghi-Forsyth",
            "title": {
                "fragments": [],
                "text": "Fast Template Evaluation with Vector Quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A method that achieves a substantial end-to-end speedup over the best current methods, without loss of accuracy, is described, a combination of approximating scores by vector quantizing feature windows and a number of speedup techniques including cascade."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692688"
                        ],
                        "name": "Yuri Boykov",
                        "slug": "Yuri-Boykov",
                        "structuredName": {
                            "firstName": "Yuri",
                            "lastName": "Boykov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuri Boykov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "(a), (b), and (c) give speedup factors for our parametric min-cut when compared to [5], [20], and [17], with increasing number of seeds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "We used the implementation provided by authors of BK [5] and PF [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "(a) Comparison to BK [5] 1 4 9 16 25 36 49 64 81 100 0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "Our choice of building on the Boykov-Kolmogorov algorithm (BK) [5] was partially motivated by their results, since BK tends perform equally or better than push-relabel [15] and Pseudoflow (PF) [17] in small density graphs like the ones we use."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 216
                            }
                        ],
                        "text": "Our reuse scheme first generates a precomputation graph which consists of one tree for each foreground seed plus a sink tree, as an extension to the source and sink trees used in the Boykov-Kolmogorov algorithm (BK) [5] (summarized in \u00a73."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Time (ms) [5] [20] [17] Ours RIGOR StructEdges-9 632."
                    },
                    "intents": []
                }
            ],
            "corpusId": 36955056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6116661b3ed8126bd983024c4158b70ae410f88b",
            "isKey": true,
            "numCitedBy": 2189,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "After [15], [31], [19], [8], [25], [5], minimum cut/maximum flow algorithms on graphs emerged as an increasingly useful tool for exact or approximate energy minimization in low-level vision. The combinatorial optimization literature provides many min-cut/max-flow algorithms with different polynomial time complexity. Their practical efficiency, however, has to date been studied mainly outside the scope of computer vision. The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/max flow algorithms for applications in vision. We compare the running times of several standard algorithms, as well as a new algorithm that we have recently developed. The algorithms we study include both Goldberg-Tarjan style \"push-relabel\" methods and algorithms based on Ford-Fulkerson style \"augmenting paths.\" We benchmark these algorithms on a number of typical graphs in the contexts of image restoration, stereo, and segmentation. In many cases, our new algorithm works several times faster than any of the other methods, making near real-time performance possible. An implementation of our max-flow/min-cut algorithm is available upon request for research purposes."
            },
            "slug": "An-experimental-comparison-of-min-cut/max-flow-for-Boykov-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper compares the running times of several standard algorithms, as well as a new algorithm that is recently developed that works several times faster than any of the other methods, making near real-time performance possible."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE transactions on pattern analysis and machine intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150358370"
                        ],
                        "name": "Zhenyu Wu",
                        "slug": "Zhenyu-Wu",
                        "structuredName": {
                            "firstName": "Zhenyu",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhenyu Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9274265"
                        ],
                        "name": "R. Leahy",
                        "slug": "R.-Leahy",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Leahy",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Leahy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "However, the original min-cut approaches either tend to find foreground regions with a very small size [35] or attempt to solve an NP-hard problem [30, 33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2595046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "250748b4494cec56abd55ae049bdd38f4d42e5c8",
            "isKey": false,
            "numCitedBy": 1265,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel graph theoretic approach for data clustering is presented and its application to the image segmentation problem is demonstrated. The data to be clustered are represented by an undirected adjacency graph G with arc capacities assigned to reflect the similarity between the linked vertices. Clustering is achieved by removing arcs of G to form mutually exclusive subgraphs such that the largest inter-subgraph maximum flow is minimized. For graphs of moderate size ( approximately 2000 vertices), the optimal solution is obtained through partitioning a flow and cut equivalent tree of G, which can be efficiently constructed using the Gomory-Hu algorithm (1961). However for larger graphs this approach is impractical. New theorems for subgraph condensation are derived and are then used to develop a fast algorithm which hierarchically constructs and partitions a partially equivalent tree of much reduced size. This algorithm results in an optimal solution equivalent to that obtained by partitioning the complete equivalent tree and is able to handle very large graphs with several hundred thousand vertices. The new clustering algorithm is applied to the image segmentation problem. The segmentation is achieved by effectively searching for closed contours of edge elements (equivalent to minimum cuts in G), which consist mostly of strong edges, while rejecting contours containing isolated strong edges. This method is able to accurately locate region boundaries and at the same time guarantees the formation of closed edge contours. >"
            },
            "slug": "An-Optimal-Graph-Theoretic-Approach-to-Data-Theory-Wu-Leahy",
            "title": {
                "fragments": [],
                "text": "An Optimal Graph Theoretic Approach to Data Clustering: Theory and Its Application to Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A novel graph theoretic approach for data clustering is presented and its application to the image segmentation problem is demonstrated, resulting in an optimal solution equivalent to that obtained by partitioning the complete equivalent tree and is able to handle very large graphs with several hundred thousand vertices."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 115
                            }
                        ],
                        "text": "When enumerating bounding boxes and computing their features, tricks such as integral image and distance transform [10, 23] can help to speed-up the computation, even achieving real-time performance in certain tasks [3, 29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14327585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "860a9d55d87663ca88e74b3ca357396cd51733d0",
            "isKey": false,
            "numCitedBy": 2616,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose."
            },
            "slug": "A-discriminatively-trained,-multiscale,-deformable-Felzenszwalb-McAllester",
            "title": {
                "fragments": [],
                "text": "A discriminatively trained, multiscale, deformable part model"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A discriminatively trained, multiscale, deformable part model for object detection, which achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge and outperforms the best results in the 2007 challenge in ten out of twenty categories."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143774737"
                        ],
                        "name": "J. Shotton",
                        "slug": "J.-Shotton",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Shotton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shotton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967473"
                        ],
                        "name": "Pushmeet Kohli",
                        "slug": "Pushmeet-Kohli",
                        "structuredName": {
                            "firstName": "Pushmeet",
                            "lastName": "Kohli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushmeet Kohli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "Previous research has shown that a boosted regressor with a few deep decision trees could achieve similar performance as one with many shallow trees while being faster to evaluate [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14001084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82fc3af52b53a92efb3d0489d89f7e022fb7c2c9",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach to general-activity human pose estimation from depth images, building on Hough forests. We extend existing techniques in several ways: real time prediction of multiple 3D joints, explicit learning of voting weights, vote compression to allow larger training sets, and a comparison of several decision-tree training objectives. Key aspects of our work include: regression directly from the raw depth image, without the use of an arbitrary intermediate representation; applicability to general motions (not constrained to particular activities) and the ability to localize occluded as well as visible body joints. Experimental results demonstrate that our method produces state of the art results on several data sets including the challenging MSRC-5000 pose estimation test set, at a speed of about 200 frames per second. Results on silhouettes suggest broader applicability to other imaging modalities."
            },
            "slug": "Efficient-regression-of-general-activity-human-from-Girshick-Shotton",
            "title": {
                "fragments": [],
                "text": "Efficient regression of general-activity human poses from depth images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Key aspects of this work include: regression directly from the raw depth image, without the use of an arbitrary intermediate representation; applicability to general motions (not constrained to particular activities) and the ability to localize occluded as well as visible body joints."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798000"
                        ],
                        "name": "Rodrigo Benenson",
                        "slug": "Rodrigo-Benenson",
                        "structuredName": {
                            "firstName": "Rodrigo",
                            "lastName": "Benenson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rodrigo Benenson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11983029"
                        ],
                        "name": "Markus Mathias",
                        "slug": "Markus-Mathias",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Mathias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Mathias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732855"
                        ],
                        "name": "R. Timofte",
                        "slug": "R.-Timofte",
                        "structuredName": {
                            "firstName": "Radu",
                            "lastName": "Timofte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Timofte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 216
                            }
                        ],
                        "text": "When enumerating bounding boxes and computing their features, tricks such as integral image and distance transform [10, 23] can help to speed-up the computation, even achieving real-time performance in certain tasks [3, 29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13510913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78cea77517dcc8e0f3a4c28ec4d4606ca5b20af5",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new pedestrian detector that improves both in speed and quality over state-of-the-art. By efficiently handling different scales and transferring computation from test time to training time, detection speed is improved. When processing monocular images, our system provides high quality detections at 50 fps. We also propose a new method for exploiting geometric context extracted from stereo images. On a single CPU+GPU desktop machine, we reach 135 fps, when processing street scenes, from rectified input to detections output."
            },
            "slug": "Pedestrian-detection-at-100-frames-per-second-Benenson-Mathias",
            "title": {
                "fragments": [],
                "text": "Pedestrian detection at 100 frames per second"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A new pedestrian detector that improves both in speed and quality over state-of-the-art by efficiently handling different scales and transferring computation from test time to training time, detection speed is improved."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2394251"
                        ],
                        "name": "A. Goldberg",
                        "slug": "A.-Goldberg",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Goldberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721050"
                        ],
                        "name": "R. Tarjan",
                        "slug": "R.-Tarjan",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tarjan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tarjan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14492800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8fb31bef2bf64bfbde869601cb624812a1d066e",
            "isKey": false,
            "numCitedBy": 1595,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "All previously known efftcient maximum-flow algorithms work by finding augmenting paths, either one path at a time (as in the original Ford and Fulkerson algorithm) or all shortest-length augmenting paths at once (using the layered network approach of Dinic). An alternative method based on the preflow concept of Karzanov is introduced. A preflow is like a flow, except that the total amount flowing into a vertex is allowed to exceed the total amount flowing out. The method maintains a preflow in the original network and pushes local flow excess toward the sink along what are estimated to be shortest paths. The algorithm and its analysis are simple and intuitive, yet the algorithm runs as fast as any other known method on dense. graphs, achieving an O(n)) time bound on an n-vertex graph. By incorporating the dynamic tree data structure of Sleator and Tarjan, we obtain a version of the algorithm running in O(nm log(n'/m)) time on an n-vertex, m-edge graph. This is as fast as any known method for any graph density and faster on graphs of moderate density. The algorithm also admits efticient distributed and parallel implementations. A parallel implementation running in O(n'log n) time using n processors and O(m) space is obtained. This time bound matches that of the Shiloach-Vishkin"
            },
            "slug": "A-new-approach-to-the-maximum-flow-problem-Goldberg-Tarjan",
            "title": {
                "fragments": [],
                "text": "A new approach to the maximum flow problem"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "By incorporating the dynamic tree data structure of Sleator and Tarjan, a version of the algorithm running in O(nm log(n'/m)) time on an n-vertex, m-edge graph is obtained, as fast as any known method for any graph density and faster on graphs of moderate density."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '86"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "For boosting a regressor, we used LAD-boosting [13] which is found empirically to be more robust than L2 or Huber loss functions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 39450643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1679beddda3a183714d380e944fe6bf586c083cd",
            "isKey": false,
            "numCitedBy": 13780,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent boosting paradigm is developed for additive expansions based on any fitting criterion. Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such TreeBoost models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed."
            },
            "slug": "Greedy-function-approximation:-A-gradient-boosting-Friedman",
            "title": {
                "fragments": [],
                "text": "Greedy function approximation: A gradient boosting machine."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A general gradient descent boosting paradigm is developed for additive expansions based on any fitting criterion, and specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717379"
                        ],
                        "name": "D. Hochbaum",
                        "slug": "D.-Hochbaum",
                        "structuredName": {
                            "firstName": "Dorit",
                            "lastName": "Hochbaum",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hochbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "(a), (b), and (c) give speedup factors for our parametric min-cut when compared to [5], [20], and [17], with increasing number of seeds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "We used the implementation provided by authors of BK [5] and PF [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 193
                            }
                        ],
                        "text": "Our choice of building on the Boykov-Kolmogorov algorithm (BK) [5] was partially motivated by their results, since BK tends perform equally or better than push-relabel [15] and Pseudoflow (PF) [17] in small density graphs like the ones we use."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Time (ms) [5] [20] [17] Ours RIGOR StructEdges-9 632."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8830581,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67e15c4b288590f206b55156affd97f17355915d",
            "isKey": true,
            "numCitedBy": 192,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the pseudoflow algorithm for the maximum-flow problem that employs only pseudoflows and does not generate flows explicitly. The algorithm solves directly a problem equivalent to the minimum-cut problem---the maximum blocking-cut problem. Once the maximum blocking-cut solution is available, the additional complexity required to find the respective maximum-flow is O(m log n). A variant of the algorithm is a new parametric maximum-flow algorithm generating all breakpoints in the same complexity required to solve the constant capacities maximum-flow problem. The pseudoflow algorithm has also a simplex variant, pseudoflow-simplex, that can be implemented to solve the maximum-flow problem. One feature of the pseudoflow algorithm is that it can initialize with any pseudoflow. This feature allows it to reach an optimal solution quickly when the initial pseudoflow is \u201cclose\u201d to an optimal solution. The complexities of the pseudoflow algorithm, the pseudoflow-simplex, and the parametric variants of pseudoflow and pseudoflow-simplex algorithms are all O(mn log n) on a graph with n nodes and m arcs. Therefore, the pseudoflow-simplex algorithm is the fastest simplex algorithm known for the parametric maximum-flow problem. The pseudoflow algorithm is also shown to solve the maximum-flow problem on s, t-tree networks in linear time, where s, t-tree networks are formed by joining a forest of capacitated arcs, with nodes s and t adjacent to any subset of the nodes."
            },
            "slug": "The-Pseudoflow-Algorithm:-A-New-Algorithm-for-the-Hochbaum",
            "title": {
                "fragments": [],
                "text": "The Pseudoflow Algorithm: A New Algorithm for the Maximum-Flow Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The pseudoflow algorithm is introduced, which is a simplex algorithm that employs only pseudoflows and does not generate flows explicitly, and is shown to solve the maximum-flow problem on s, t-tree networks in linear time."
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49026551"
                        ],
                        "name": "D. Greig",
                        "slug": "D.-Greig",
                        "structuredName": {
                            "firstName": "Darryl",
                            "lastName": "Greig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Greig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146294528"
                        ],
                        "name": "B. Porteous",
                        "slug": "B.-Porteous",
                        "structuredName": {
                            "firstName": "Baroness",
                            "lastName": "Porteous",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Porteous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1887111"
                        ],
                        "name": "A. Seheult",
                        "slug": "A.-Seheult",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Seheult",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Seheult"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 92
                            }
                        ],
                        "text": "Graph cuts have been a mainstream approach for image segmentation over the last two decades [16, 30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 115691220,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a717b20e99b76cb228b47694140ed3dce082b530",
            "isKey": false,
            "numCitedBy": 1257,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Exact-Maximum-A-Posteriori-Estimation-for-Binary-Greig-Porteous",
            "title": {
                "fragments": [],
                "text": "Exact Maximum A Posteriori Estimation for Binary Images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259589"
                        ],
                        "name": "E. A. Dinic",
                        "slug": "E.-A.-Dinic",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Dinic",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. A. Dinic"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "Unlike algorithms like blocking flow [7] which performs BFS afresh for exploring every new depth level, BK maintains two search trees, S (originating from s) and T (from t)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115824074,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "13e9613b5a06776c15f7adc562f6f8a385fc4f29",
            "isKey": false,
            "numCitedBy": 709,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithm-for-solution-of-a-problem-of-maximal-flow-Dinic",
            "title": {
                "fragments": [],
                "text": "Algorithm for solution of a problem of maximal flow in a network with power estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653004"
                        ],
                        "name": "V. Kolmogorov",
                        "slug": "V.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Kolmogorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kolmogorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104192849"
                        ],
                        "name": "R. Zabin",
                        "slug": "R.-Zabin",
                        "structuredName": {
                            "firstName": "Rawaa",
                            "lastName": "Zabin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[22, 21] characterized the submodular functions that can be optimized globally with graph cut, especially the parametric max-flow formulation [21] that produces cuts with multiple unary terms at the same time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 53303132,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6a1876f699838d79c184b7a2349f927c6f5ec99e",
            "isKey": false,
            "numCitedBy": 2088,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction. We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts. Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is possible and then follow our construction to create the appropriate graph. A software implementation is freely available."
            },
            "slug": "What-energy-functions-can-be-minimized-via-graph-Kolmogorov-Zabin",
            "title": {
                "fragments": [],
                "text": "What energy functions can be minimized via graph cuts"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work gives a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "//cpl.cc.gatech.edu/projects/RIGOR Ahmad Humayun Fuxin Li James M. Rehg Computer Vision and Pattern Recognition 2014 Columbus, Ohio Compared to Boykov Kolmogorov"
            },
            "venue": {
                "fragments": [],
                "text": "//cpl.cc.gatech.edu/projects/RIGOR Ahmad Humayun Fuxin Li James M. Rehg Computer Vision and Pattern Recognition 2014 Columbus, Ohio Compared to Boykov Kolmogorov"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "StructEdges [3] was used in all tests"
            },
            "venue": {
                "fragments": [],
                "text": "StructEdges [3] was used in all tests"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parametric max-flow/min-cut timing comparison using different methods"
            },
            "venue": {
                "fragments": [],
                "text": "Parametric max-flow/min-cut timing comparison using different methods"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 147
                            }
                        ],
                        "text": "However, the original min-cut approaches either tend to find foreground regions with a very small size [35] or attempt to solve an NP-hard problem [30, 33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 92
                            }
                        ],
                        "text": "Graph cuts have been a mainstream approach for image segmentation over the last two decades [16, 30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image"
            },
            "venue": {
                "fragments": [],
                "text": "segmentation. PAMI,"
            },
            "year": 2000
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 23,
            "methodology": 19
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 37,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/RIGOR:-Reusing-Inference-in-Graph-Cuts-for-Object-Humayun-Li/566b8bbdc8d039f24d38453e5f233febff406b1d?sort=total-citations"
}