{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "This conjecture is supported by experiments performed at an earlier stage of this research [19], where spin images achieved better results than rotation-invariant \u201cGabor-like\u201d linear filters [38] (note that this filter bank is similar in terms of performance and dimensionality to several others in popular use [42])."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 144
                            }
                        ],
                        "text": "We have eschewed the more popular filter-based features [1, 6, 37, 38, 42] because of growing evidence in favor of region-based representations [19, 30, 43], as will be discussed in detail at the end of this section."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "A preliminary version of this article has appeared in [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 256365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb342b4d65a79120c6ddc3782f330c829bffd000",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces a texture representation suitable for recognizing images of textured surfaces under a wide range of transformations, including viewpoint changes and nonrigid deformations. At the feature extraction stage, a sparse set of affine-invariant local patches is extracted from the image. This spatial selection process permits the computation of characteristic scale and neighborhood shape for every texture element. The proposed texture representation is evaluated in retrieval and classification tasks using the entire Brodatz database and a collection of photographs of textured surfaces taken from different viewpoints."
            },
            "slug": "A-sparse-texture-representation-using-regions-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "A sparse texture representation using affine-invariant regions"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The proposed texture representation is evaluated in retrieval and classification tasks using the entire Brodatz database and a collection of photographs of textured surfaces taken from different viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2964260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aac66ac5e90cc4c187a5aa063b522e5193ef8834",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and demonstrate a texture region descriptor which is invariant to affine geometric and photometric transformations, and insensitive to the shape of the texture region. It is applicable to texture patches which are locally planar and have stationary statistics. The novelty of the descriptor is that it is based on statistics aggregated over the region, resulting in richer and more stable descriptors than those computed at a point. Two texture matching applications of this descriptor are demonstrated: (1) it is used to automatically identify, regions of the same type of texture, but with varying surface pose, within a single image; (2) it is used to support wide baseline stereo, i.e. to enable the automatic computation of the epipolar geometry between two images acquired from quite separated viewpoints. Results are presented on several sets of real images."
            },
            "slug": "Viewpoint-invariant-texture-matching-and-wide-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Viewpoint invariant texture matching and wide baseline stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A texture region descriptor is described and demonstrated which is invariant to affine geometric and photometric transformations, and insensitive to the shape of the texture region, resulting in richer and more stable descriptors than those computed at a point."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2672681"
                        ],
                        "name": "G. O. Cula",
                        "slug": "G.-O.-Cula",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Cula",
                            "middleNames": [
                                "Oana"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. O. Cula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Image processing and computer vision, feature measurement, texture, pattern recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "Alternative region extraction schemes include the \u201centropy detector\u201d of Kadir and Brady [16], the difference-ofGaussians (or DoG) detector of Lowe [27], the \u201cmaximally stable extremal regions\u201d of Matas et al. [31], and the corner and intensity-based operators of Tuytelaars and Van Gool [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7356365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b45dc2f11ed201f192d9bec153fcca1ca95e460",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A bidirectional texture function (BTF) describes image texture as it varies with viewing and illumination direction. Many real world surfaces such as skin, fur, gravel, etc. exhibit fine-scale geometric surface detail. Accordingly, variations in appearance with viewing and illumination direction may be quite complex due to local foreshortening, masking and shadowing. Representations of surface texture that support robust recognition must account for these effects. We construct a representation which captures the underlying statistical distribution of features in the image texture as well as the variations in this distribution with viewing and illumination direction. The representation combines clustering to learn characteristic image features and principle components analysis to reduce the space of feature histograms. This representation is based on a core image set as determined by a quantitative evaluation of importance of individual images in the overall representation. The result is a compact representation and a recognition method where a single novel image of unknown viewing and illumination direction can be classified efficiently. The CUReT (Columbia-Utrecht reflectance and texture) database is used as a test set for evaluation of these methods."
            },
            "slug": "Compact-representation-of-bidirectional-texture-Cula-Dana",
            "title": {
                "fragments": [],
                "text": "Compact representation of bidirectional texture functions"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A representation is constructed which captures the underlying statistical distribution of features in the image texture as well as the variations in this distribution with viewing and illumination direction and is a compact representation and a recognition method where a single novel image of unknown viewing and illuminated direction can be classified efficiently."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "To date, we have conducted preliminary experiments in classification of individual texture regions using simple co-occurrence relations [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15208439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "400736e84b3b04ffa41542cf62b6546e57f590f7",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a framework for texture recognition based on local affine-invariant descriptors and their spatial layout. At modelling time, a generative model of local descriptors is learned from sample images using the EM algorithm. The EM framework allows the incorporation of unsegmented multitexture images into the training set. The second modelling step consists of gathering co-occurrence statistics of neighboring descriptors. At recognition time, initial probabilities computed from the generative model are refined using a relaxation step that incorporates co-occurrence statistics. Performance is evaluated on images of an indoor scene and pictures of wild animals."
            },
            "slug": "Affine-invariant-local-descriptors-and-neighborhood-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Affine-invariant local descriptors and neighborhood statistics for texture recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A framework for texture recognition based on local affine-invariant descriptors and their spatial layout is presented and initial probabilities computed from the generative model are refined using a relaxation step that incorporates co-occurrence statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 206
                            }
                        ],
                        "text": "The proposed approach is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5927402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db7159af39b66cde32cec502a17d48436b541d00",
            "isKey": false,
            "numCitedBy": 423,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new method for constructing models from a set of positive and negative sample images; the method requires no manual extraction of significant objects or features. Our model representation is based on two layers. The first one consists of \"generic\" descriptors which represent sets of similar rotational invariant feature vectors. Rotation invariance allows to group similar, but rotated patterns and makes the method robust to model deformations. The second layer is the joint probability on the frequencies of the \"generic\" descriptors over neighborhoods. This probability is multi-modal and is represented by a set of \"spatial-frequency\" clusters. It adds a statistical spatial constraint which is rotationally invariant. Our two-layer representation is novel; it allows to efficiently capture \"texture-like\" visual structure. The selection of distinctive structure determines characteristic model features (common to the positive and rare in the negative examples) and increases the performance of the model. Models are retrieved and localized using a probabilistic score. Experimental results for \"textured\" animals and faces show a very good performance for retrieval as well as localization."
            },
            "slug": "Constructing-models-for-content-based-image-Schmid",
            "title": {
                "fragments": [],
                "text": "Constructing models for content-based image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A new method for constructing models from a set of positive and negative sample images; the method requires no manual extraction of significant objects or features and allows to efficiently capture \"texture-like\" visual structure."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14915716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90d6e7f2202f754d8588f9536e3f5b4a24701f24",
            "isKey": false,
            "numCitedBy": 1713,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the recognition of surfaces made from different materials such as concrete, rug, marble, or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof. Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions.Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions. We also illustrate how the 3D texton model can be used to predict the appearance of materials under novel conditions."
            },
            "slug": "Representing-and-Recognizing-the-Visual-Appearance-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "Representing and Recognizing the Visual Appearance of Materials using Three-dimensional Textons"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A unified model to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions is provided."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726178"
                        ],
                        "name": "X. Llad\u00f3",
                        "slug": "X.-Llad\u00f3",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Llad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Llad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153913367"
                        ],
                        "name": "J. Mart\u00ed",
                        "slug": "J.-Mart\u00ed",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Mart\u00ed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mart\u00ed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144877016"
                        ],
                        "name": "M. Petrou",
                        "slug": "M.-Petrou",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Petrou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Petrou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 145656,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "249e5937b44f9e1c6b8a61d27ca361c43ca23f1a",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Changes in the angle of illumination incident upon a 3D surface texture can significantly alter its appearance, implying variations in the image texture. These texture variations produce displacements of class members in the feature space, increasing the failure rates of texture classifiers. To avoid this problem, a model-based texture recognition system which classifies textures seen from different distances and under different illumination directions is presented in this paper. The system works on the basis of a surface model obtained by means of 4-source colour photometric stereo, used to generate 2D image textures under different illumination directions. The recognition system combines coocurrence matrices for feature extraction with a Nearest Neighbour classifier. Moreover, the recognition allows one to guess the approximate direction of the illumination used to capture the test image."
            },
            "slug": "Classification-of-textures-seen-from-different-and-Llad\u00f3-Mart\u00ed",
            "title": {
                "fragments": [],
                "text": "Classification of textures seen from different distances and under varying illumination direction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A model-based texture recognition system which classifies textures seen from different distances and under different illumination directions is presented, working on the basis of a surface model obtained by means of 4-source colour photometric stereo."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 199
                            }
                        ],
                        "text": "Apart from being memory and computation-intensive, this dense approach produces redundant texton dictionaries that may include, for instance, many slightly shifted versions of the same basic element [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "A few recent representations [28], [42] have used"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17582380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34d4eb4666a20f7e3fad689d7862959bd128130b",
            "isKey": false,
            "numCitedBy": 1296,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture. Natural images contain both textured and untextured regions, so the cues of contour and texture differences are exploited simultaneously. Contours are treated in the intervening contour framework, while texture is analyzed using textons. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on the texturedness of the neighborhood at a pixel. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown."
            },
            "slug": "Contour-and-Texture-Analysis-for-Image-Segmentation-Malik-Belongie",
            "title": {
                "fragments": [],
                "text": "Contour and Texture Analysis for Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture, and introduces a gating operator based on the texturedness of the neighborhood at a pixel to facilitate cue combination."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Image processing and computer vision, feature measurement, texture, pattern recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2166325,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "191c3c15cc4c957ee3437fc27ba3178bae292e7f",
            "isKey": false,
            "numCitedBy": 257,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the recognition of surfaces made from different materials such as concrete, rug, marble or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons. Examples might be ridges, grooves, spots or stripes or combinations thereof Associated with each texton is an appearance vector, which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions. Given a large collection of images of different materials, a clustering approach is used to acquire a small (on the order of 100) 3D texton vocabulary. Given a few (1 to 4) images of any material, it can be characterized using these textons. We demonstrate the application of this representation for recognition of the material viewed under novel lighting and viewing conditions."
            },
            "slug": "Recognizing-surfaces-using-three-dimensional-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "Recognizing surfaces using three-dimensional textons"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A unified model to address both the reflectance and surface normal aspects of natural texture and to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties is provided."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2679389"
                        ],
                        "name": "A. Baumberg",
                        "slug": "A.-Baumberg",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Baumberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Baumberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15626261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67f693427d956c0dbc822e7f3452aee8ca36204b",
            "isKey": false,
            "numCitedBy": 767,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints. Unlike conventional stereo matching approaches we assume no prior knowledge about the relative camera positions and orientations. In fact in our application this is the information we wish to determine from the image feature matches. Features are detected in two or more images and characterised using affine texture invariants. The problem of window effects is explicitly addressed by our method-our feature characterisation is invariant to linear transformations of the image data including rotation, stretch and skew. The feature matching process is optimised for a structure-from-motion application where we wish to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "slug": "Reliable-feature-matching-across-widely-separated-Baumberg",
            "title": {
                "fragments": [],
                "text": "Reliable feature matching across widely separated views"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A robust method for automatically matching features in images corresponding to the same physical point on an object seen from two arbitrary viewpoints that is optimised for a structure-from-motion application where it wishes to ignore unreliable matches at the expense of reducing the number of feature matches."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46365515"
                        ],
                        "name": "Jiahua Wu",
                        "slug": "Jiahua-Wu",
                        "structuredName": {
                            "firstName": "Jiahua",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiahua Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712844"
                        ],
                        "name": "M. Chantler",
                        "slug": "M.-Chantler",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Chantler",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chantler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10190315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d10d57b032aa3e57f45283454b7a5a50faa5a3f",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new texture classification scheme which is invariant to surface-rotation. Many texture classification approaches have been presented in the past that are image-rotation invariant. However, image rotation is not necessarily the same as surface rotation. We have therefore developed a classifier that uses invariants that are derived from surface properties rather than image properties. Previously we developed a scheme that used surface gradient (normal) fields estimated using photometric stereo. In this paper we augment these data with albedo information and also employ an additional feature set: the radial spectrum. We used 30 real textures to test the new classifier. A classification accuracy of 91% was achieved when albedo and gradient 1D polar and radial features were combined. The best performance was also achieved by using 2D albedo and gradient spectra. The classification accuracy is 99%."
            },
            "slug": "Combining-gradient-and-albedo-data-for-rotation-of-Wu-Chantler",
            "title": {
                "fragments": [],
                "text": "Combining gradient and albedo data for rotation invariant classification of 3D surface texture"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This paper presents a new texture classification scheme which is invariant to surface-rotation, and uses invariants that are derived from surface properties rather than image properties, and employs the radial spectrum."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3260234"
                        ],
                        "name": "J. G\u00e5rding",
                        "slug": "J.-G\u00e5rding",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "G\u00e5rding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. G\u00e5rding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 159
                            }
                        ],
                        "text": "In this work, we use two types of detectors: The Harrisaffine detector of Mikolajczyk and Schmid [33] and the Laplacian blob detector of G\u00e5rding and Lindeberg [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Ga\u030arding and Lindeberg [9] have also shown how to design an affine blob detector using an affine adaptation process based on the second moment matrix."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "G\u00e5rding and Lindeberg [9] have also shown how to design an affine blob detector using an affine adaptation process based on the second moment matrix."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 137
                            }
                        ],
                        "text": "In this work, we use two types of detectors: The Harrisaffine detector of Mikolajczyk and Schmid [33] and the Laplacian blob detector of Ga\u030arding and Lindeberg [9].2 Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "Lindeberg [24] has extended this detector in the framework of automatic scale selection, where a \u201cblob\u201d is defined by a scale-space location where a\nnormalized Laplacian measure attains a local maximum."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "Note that we have implemented simplified versions of the algorithms given in [9], [33]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "The technical details of automatic scale selection and affine adaptation, described in [9], [24], [33], are beyond the scope of this paper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15548916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9e58a5b063d4252a15fd94c0613f83a4fdb780e",
            "isKey": true,
            "numCitedBy": 117,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of computing cues to the three-dimensional structure of surfaces in the world directly from the local structure of the brightness pattern of either a single monocular image or a binocular image pair.It is shown that starting from Gaussian derivatives of order up to two at a range of scales in scale-space, local estimates of (i) surface orientation from monocular texture foreshortening, (ii) surface orientation from monocular texture gradients, and (iii) surface orientation from the binocular disparity gradient can be computed without iteration or search, and by using essentially the same basic mechanism.The methodology is based on a multi-scale descriptor of image structure called the windowed second moment matrix, which is computed with adaptive selection of both scale levels and spatial positions. Notably, this descriptor comprises two scale parameters; a local scale parameter describing the amount of smoothing used in derivative computations, and an integration scale parameter determining over how large a region in space the statistics of regional descriptors is accumulated.Experimental results for both synthetic and natural images are presented, and the relation with models of biological vision is briefly discussed."
            },
            "slug": "Direct-computation-of-shape-cues-using-spatial-G\u00e5rding-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Direct computation of shape cues using scale-adapted spatial derivative operators"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of computing cues to the three-dimensional structure of surfaces in the world directly from the local structure of the brightness pattern of either a single monocular image or a binocular image pair using a multi-scale descriptor of image structure called the windowed second moment matrix."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170732251"
                        ],
                        "name": "Fang Liu",
                        "slug": "Fang-Liu",
                        "structuredName": {
                            "firstName": "Fang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "Following the same procedure as previous evaluations [25],"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "We use the standard procedure followed by several Brodatz database evaluations [25], [35], [50]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "For one, relatively few publications actually report results on the entire database (the only studies known to us are [10], [25], [35], [50])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "higher than the results reported in [25], [35], but below Xu"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2675336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0df54adafa6eb7743e75d5cf0d7d92c1c1eaa72",
            "isKey": true,
            "numCitedBy": 685,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the fundamental challenges in pattern recognition is choosing a set of features appropriate to a class of problems. In applications such as database retrieval, it is important that image features used in pattern comparison provide good measures of image perceptual similarities. We present an image model with a new set of features that address the challenge of perceptual similarity. The model is based on the 2D Wold decomposition of homogeneous random fields. The three resulting mutually orthogonal subfields have perceptual properties which can be described as \"periodicity,\" \"directionality,\" and \"randomness,\" approximating what are indicated to be the three most important dimensions of human texture perception. The method presented improves upon earlier Wold-based models in its tolerance to a variety of local inhomogeneities which arise in natural textures and its invariance under image transformation such as rotation. An image retrieval algorithm based on the new texture model is presented. Different types of image features are aggregated for similarity comparison by using a Bayesian probabilistic approach. The, effectiveness of the Wold model at retrieving perceptually similar natural textures is demonstrated in comparison to that of two other well-known pattern recognition methods. The Wold model appears to offer a perceptually more satisfying measure of pattern similarity while exceeding the performance of these other methods by traditional pattern recognition criteria. Examples of natural scene Wold texture modeling are also presented."
            },
            "slug": "Periodicity,-Directionality,-and-Randomness:-Wold-Liu-Picard",
            "title": {
                "fragments": [],
                "text": "Periodicity, Directionality, and Randomness: Wold Features for Image Modeling and Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The Wold model appears to offer a perceptually more satisfying measure of pattern similarity while exceeding the performance of these other methods by traditional pattern recognition criteria."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120763852"
                        ],
                        "name": "F. Cohen",
                        "slug": "F.-Cohen",
                        "structuredName": {
                            "firstName": "Fredric",
                            "lastName": "Cohen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47774603"
                        ],
                        "name": "Z. Fan",
                        "slug": "Z.-Fan",
                        "structuredName": {
                            "firstName": "Zhigang",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107308659"
                        ],
                        "name": "M. A. Patel",
                        "slug": "M.-A.-Patel",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Patel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Patel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Early research in this domain has concentrated on global 2D image transformations, such as rotation and scaling [ 5 , 30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206418967,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "92a552175e992afd0b9fe943a02ec5580b4aa6df",
            "isKey": false,
            "numCitedBy": 335,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Consideration is given to the problem of classifying a test textured image that is obtained from one of C possible parent texture classes, after possibly applying unknown rotation and scale changes to the parent texture. The training texture images (parent classes) are modeled by Gaussian Markov random fields (GMRFs). To classify a rotated and scaled test texture, the rotation and scale changes are incorporated in the texture model through an appropriate transformation of the power spectral density of the GMRF. For the rotated and scaled image, a bona fide likelihood function that shows the explicit dependence of the likelihood function on the GMRF parameters, as well as on the rotation and scale parameters, is derived. Although, in general, the scaled and/or rotated texture does not correspond to a finite-order GMRF, it is possible nonetheless to write down a likelihood function for the image data. The likelihood function of the discrete Fourier transform of the image data corresponds to that of a white nonstationary Gaussian random field, with the variance at each pixel (i,j) being a known function of the rotation, the scale, the GMRF model parameters, and (i,j). The variance is an explicit function of the appropriately sampled power spectral density of the GMRF. The estimation of the rotation and scale parameters is performed in the frequency domain by maximizing the likelihood function associated with the discrete Fourier transform of the image data. Cramer-Rao error bounds on the scale and rotation estimates are easily computed. A modified Bayes decision rule is used to classify a given test image into one of C possible texture classes. The classification power of the method is demonstrated through experimental results on natural textures from the Brodatz album. >"
            },
            "slug": "Classification-of-Rotated-and-Scaled-Textured-Using-Cohen-Fan",
            "title": {
                "fragments": [],
                "text": "Classification of Rotated and Scaled Textured Images Using Gaussian Markov Random Field Models"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A modified Bayes decision rule is used to classify a given test image into one of C possible texture classes and the classification power of the method is demonstrated through experimental results on natural textures from the Brodatz album."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829696"
                        ],
                        "name": "Y. Rubner",
                        "slug": "Y.-Rubner",
                        "structuredName": {
                            "firstName": "Yossi",
                            "lastName": "Rubner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rubner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "Before presenting the details of our approach (Section 3), let us briefly discuss a number of texture models aimed at achieving invariance under various geometric transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12427914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c82d70ca7bedf750707b92781d0a48b991f7156",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Image segmentation is not only hard and unnecessary for texture-based image retrieval, but can even be harmful. Images of either individual or multiple textures are best described by distributions of spatial frequency descriptors, rather than single descriptor vectors over presegmented regions. A retrieval method based on the earth movers distance with an appropriate ground distance is shown to handle both complete and partial multi-textured queries. As an illustration, different images of the same type of animal are easily retrieved together. At the same time, animals with subtly different coats, like cheetahs and leopards, are properly distinguished."
            },
            "slug": "Texture-based-image-retrieval-without-segmentation-Rubner-Tomasi",
            "title": {
                "fragments": [],
                "text": "Texture-based image retrieval without segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A retrieval method based on the earth movers distance with an appropriate ground distance is shown to handle both complete and partial multi-textured queries."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3214795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7417d7dcf6152736612e3f04ccc72731dc8d9505",
            "isKey": false,
            "numCitedBy": 418,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new approach to material classification under unknown viewpoint and illumination. Our texture model is based on the statistical distribution of clustered filter responses. However, unlike previous 3D texton representations, we use rotationally invariant filters and cluster in an extremely low dimensional space. Having built a texton dictionary, we present a novel method of classifying a single image without requiring any a priori knowledge about the viewing or illumination conditions under which it was photographed. We argue that using rotationally invariant filters while clustering in such a low dimensional space improves classification performance and demonstrate this claim with results on all 61 textures in the Columbia-Utrecht database. We then proceed to show how texture models can be further extended by compensating for viewpoint changes using weak isotropy.The new clustering and classification methods are compared to those of Leung and Malik (ICCV 1999), Schmid (CVPR 2001) and Cula and Dana (CVPR 2001), which are the current state-of-the-art approaches."
            },
            "slug": "Classifying-Images-of-Materials:-Achieving-and-Varma-Zisserman",
            "title": {
                "fragments": [],
                "text": "Classifying Images of Materials: Achieving Viewpoint and Illumination Independence"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper presents a novel method of classifying a single image without requiring any a priori knowledge about the viewing or illumination conditions under which it was photographed, and argues that using rotationally invariant filters while clustering in such a low dimensional space improves classification performance."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8038506"
                        ],
                        "name": "B. Ginneken",
                        "slug": "B.-Ginneken",
                        "structuredName": {
                            "firstName": "Bram",
                            "lastName": "Ginneken",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ginneken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 223
                            }
                        ],
                        "text": "Alternative region extraction schemes include the \u201centropy detector\u201d of Kadir and Brady [16], the difference-ofGaussians (or DoG) detector of Lowe [27], the \u201cmaximally stable extremal regions\u201d of Matas et al. [31], and the corner and intensity-based operators of Tuytelaars and Van Gool [45]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 622815,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "16ba88cb3c3a0438bd9e5ace9096f9655ddc63df",
            "isKey": false,
            "numCitedBy": 1074,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we investigate the visual appearance of real-world surfaces and the dependence of appearance on imaging conditions. We present a BRDF (bidirectional reflectance distribution function) database with reflectance measurements for over 60 different samples, each observed with over 200 different combinations of viewing and source directions. We fit the BRDF measurements to two recent models to obtain a BRDF parameter database. These BRDF parameters can be directly used for both image analysis and image synthesis. Finally, we present a BTF (bidirectional texture function) database with image textures from over 60 different samples, each observed with over 200 different combinations of viewing and source directions. Each of these unique databases has important implications for a variety of vision algorithms and each is made publicly available."
            },
            "slug": "Reflectance-and-texture-of-real-world-surfaces-Dana-Ginneken",
            "title": {
                "fragments": [],
                "text": "Reflectance and texture of real-world surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The visual appearance of real-world surfaces and the dependence of appearance on imaging conditions is investigated and a BRDF (bidirectional reflectance distribution function) database with reflectance measurements for over 60 different samples, each observed with over 200 different combinations of viewing and source directions is presented."
            },
            "venue": {
                "fragments": [],
                "text": "TOGS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "In this work, we use two types of detectors: The Harrisaffine detector of Mikolajczyk and Schmid [33] and the Laplacian blob detector of G\u00e5rding and Lindeberg [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "Intuitively, the two detectors provide complementary kinds of information about the image: The former responds to regions of \u201chigh information content\u201d [33], while the latter produces a perceptually plausible decomposition of the image into a set of blob-like primitives."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 172
                            }
                        ],
                        "text": "In some previous work, this ambiguity has been resolved by estimating a dominant gradient direction of the patch and aligning this direction with the positive x-axis [27], [33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 3
                            }
                        ],
                        "text": "C. Schmid is with INRIA Rho\u0302ne-Alpes, 665 Avenue de l\u2019Europe, 38330 Montbonnot, France."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 74
                            }
                        ],
                        "text": "In this work, we use two types of detectors: The Harrisaffine detector of Mikolajczyk and Schmid [33] and the Laplacian blob detector of Ga\u030arding and Lindeberg [9].2 Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "Note that we have implemented simplified versions of the algorithms given in [9], [33]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "This process forms an important part of the affine-invariant region detection frameworks of Baumberg [1] and Mikolajczyk and Schmid [33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 196
                            }
                        ],
                        "text": "Recent experimental data tends to support this intuition: SIFT descriptors have achieved better repeatability rates than filter banks and differential invariants in the comparative evaluations of Mikolajczyk and Schmid [34], while shape contexts have performed remarkably well for the application of handwritten digit recognition [2]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "The technical details of automatic scale selection and affine adaptation, described in [9], [24], [33], are beyond the scope of this paper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8571961,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c7a96155f10f152cae0866102c061cdf6da02e8",
            "isKey": false,
            "numCitedBy": 1683,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images."
            },
            "slug": "An-Affine-Invariant-Interest-Point-Detector-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "An Affine Invariant Interest Point Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel approach for detecting affine invariant interest points that can deal with significant affine transformations including large scale changes and shows an excellent performance in the presence of large perspective transformations including significant scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14457153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642e328cae81c5adb30069b680cf60ba6b475153",
            "isKey": false,
            "numCitedBy": 6760,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used. The result is that retrieved is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching in two full length feature films."
            },
            "slug": "Video-Google:-a-text-retrieval-approach-to-object-Sivic-Zisserman",
            "title": {
                "fragments": [],
                "text": "Video Google: a text retrieval approach to object matching in videos"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "An approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video, represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4723637"
                        ],
                        "name": "J. Mao",
                        "slug": "J.-Mao",
                        "structuredName": {
                            "firstName": "Jianchang",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "Each of these regions can be thought of as a texture element having a characteristic elliptic shape and a distinctive appearance pattern."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11686184,
            "fieldsOfStudy": [
                "Mathematics",
                "Environmental Science",
                "Computer Science"
            ],
            "id": "0b1c14ccf1aad87f215bfa5c6678d975d44ffb3a",
            "isKey": false,
            "numCitedBy": 795,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Texture-classification-and-segmentation-using-Mao-Jain",
            "title": {
                "fragments": [],
                "text": "Texture classification and segmentation using multiresolution simultaneous autoregressive models"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "The original SIFT has been noted for its superior performance in retrieval tasks [34]; however, we cannot use it directly in our work because it depends on finding the dominant orientation of the normalized patch."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 3
                            }
                        ],
                        "text": "C. Schmid is with INRIA Rho\u0302ne-Alpes, 665 Avenue de l\u2019Europe, 38330 Montbonnot, France."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 74
                            }
                        ],
                        "text": "In this work, we use two types of detectors: The Harrisaffine detector of Mikolajczyk and Schmid [33] and the Laplacian blob detector of Ga\u030arding and Lindeberg [9].2 Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 109
                            }
                        ],
                        "text": "This process forms an important part of the affine-invariant region detection frameworks of Baumberg [1] and Mikolajczyk and Schmid [33]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 219
                            }
                        ],
                        "text": "Recent experimental data tends to support this intuition: SIFT descriptors have achieved better repeatability rates than filter banks and differential invariants in the comparative evaluations of Mikolajczyk and Schmid [34], while shape contexts have performed remarkably well for the application of handwritten digit recognition [2]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 2572455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69401bfdafab7cde00bb8e5b2f6c28e9d72d8cfb",
            "isKey": false,
            "numCitedBy": 3666,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "slug": "A-performance-evaluation-of-local-descriptors-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "A performance evaluation of local descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is observed that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best and Moments and steerable filters show the best performance among the low dimensional descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829696"
                        ],
                        "name": "Y. Rubner",
                        "slug": "Y.-Rubner",
                        "structuredName": {
                            "firstName": "Yossi",
                            "lastName": "Rubner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rubner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "In addition, in several evaluations of color and texture-based image retrieval [36], [39], EMD has performed better than other methods for comparing distributions, including 2 distance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1060374,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7eb1ebe839501e2e7371ff4b2a8552941fa9c091",
            "isKey": false,
            "numCitedBy": 563,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper empirically compares nine image dissimilarity measures that are based on distributions of color and texture features summarizing over 1,000 CPU hours of computational experiments. Ground truth is collected via a novel random sampling scheme for color and via an image partitioning method for texture. Quantitative performance evaluations are given for classification, image retrieval, and segmentation tasks, and for a wide variety of dissimilarity measures. It is demonstrated how the selection of a measure, based on large scale evaluation, substantially improves the quality of classification, retrieval, and unsupervised segmentation of color and texture images."
            },
            "slug": "Empirical-evaluation-of-dissimilarity-measures-for-Puzicha-Rubner",
            "title": {
                "fragments": [],
                "text": "Empirical evaluation of dissimilarity measures for color and texture"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is demonstrated how the selection of a measure, based on large scale evaluation, substantially improves the quality of classification, retrieval, and unsupervised segmentation of color and texture images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3037691"
                        ],
                        "name": "A. Johnson",
                        "slug": "A.-Johnson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Edie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 211
                            }
                        ],
                        "text": "\u2026make restrictive assumptions about the nature of the input texture (e.g., stationarity) and they are not, in general, invariant with respect to 2D similarity and affine transformations, much less to 3D transformations such as viewpoint changes and nonrigid deformations of the textured surface."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1377132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df6c0c55864252090b4099237aa821a6c75b52c2",
            "isKey": false,
            "numCitedBy": 2634,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a 3D shape-based object recognition system for simultaneous recognition of multiple objects in scenes containing clutter and occlusion. Recognition is based on matching surfaces by matching points using the spin image representation. The spin image is a data level shape descriptor that is used to match surfaces represented as surface meshes. We present a compression scheme for spin images that results in efficient multiple object recognition which we verify with results showing the simultaneous recognition of multiple objects from a library of 20 models. Furthermore, we demonstrate the robust performance of recognition in the presence of clutter and occlusion through analysis of recognition trials on 100 scenes."
            },
            "slug": "Using-Spin-Images-for-Efficient-Object-Recognition-Johnson-Hebert",
            "title": {
                "fragments": [],
                "text": "Using Spin Images for Efficient Object Recognition in Cluttered 3D Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A compression scheme for spin images that results in efficient multiple object recognition which is verified with results showing the simultaneous recognition of multiple objects from a library of 20 models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081646576"
                        ],
                        "name": "Dorothea Blostein",
                        "slug": "Dorothea-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dorothea Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066986631"
                        ],
                        "name": "Narendra Ahuja",
                        "slug": "Narendra-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Narendra Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Blostein and Ahuja [3] were the first to introduce a multiscale blob detector based on maxima of the Laplacian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15572022,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "83cfed80f5cfc3d3d5fadb0790a681dd7dbee421",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-multiscale-region-detector-Blostein-Ahuja",
            "title": {
                "fragments": [],
                "text": "A multiscale region detector"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 200
                            }
                        ],
                        "text": "The proposed approach is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2326264,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6647f56413722e812cb084fbb3597ba18ceada36",
            "isKey": false,
            "numCitedBy": 759,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new method for detecting scale invariant interest points. The method is based on two recent results on scale space: (1) Interest points can be adapted to scale and give repeatable results (geometrically stable). (2) Local extrema over scale of normalized derivatives indicate the presence of characteristic local structures. Our method first computes a multi-scale representation for the Harris interest point detector. We then select points at which a local measure (the Laplacian) is maximal over scales. This allows a selection of distinctive points for which the characteristic scale is known. These points are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. For indexing, the image is characterized by a set of scale invariant points; the scale associated with each point allows the computation of a scale invariant descriptor. Our descriptors are, in addition, invariant to image rotation, of affine illumination changes and robust to small perspective deformations. Experimental results for indexing show an excellent performance up to a scale factor of 4 for a database with more than 5000 images."
            },
            "slug": "Indexing-based-on-scale-invariant-interest-points-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "Indexing Based on Scale Invariant Interest Points"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper presents a new method for detecting scale invariant interest points based on two recent results on scale space: 1) Interest points can be adapted to scale and give repeatable results (geometrically stable); 2) local extrema over scale of normalized derivatives indicate the presence of characteristic local structures."
            },
            "venue": {
                "fragments": [],
                "text": "ICCV"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687022"
                        ],
                        "name": "J. Crowley",
                        "slug": "J.-Crowley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crowley",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780629"
                        ],
                        "name": "A. Parker",
                        "slug": "A.-Parker",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Parker",
                            "middleNames": [
                                "Cline"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Parker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "features in natural images, where emphasis is placed on locating perceptually salient prim- itives such as blobs [ 6 , 48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14348919,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "252347ef2f962dde7f4c6c0467014e18bdc2cd4f",
            "isKey": false,
            "numCitedBy": 349,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper defines a multiple resolution representation for the two-dimensional gray-scale shapes in an image. This representation is constructed by detecting peaks and ridges in the difference of lowpass (DOLP) transform. Descriptions of shapes which are encoded in this representation may be matched efficiently despite changes in size, orientation, or position. Motivations for a multiple resolution representation are presented first, followed by the definition of the DOLP transform. Techniques are then presented for encoding a symbolic structural description of forms from the DOLP transform. This process involves detecting local peaks and ridges in each bandpass image and in the entire three-dimensional space defined by the DOLP transform. Linking adjacent peaks in different bandpass images gives a multiple resolution tree which describes shape. Peaks which are local maxima in this tree provide landmarks for aligning, manipulating, and matching shapes. Detecting and linking the ridges in each DOLP bandpass image provides a graph which links peaks within a shape in a bandpass image and describes the positions of the boundaries of the shape at multiple resolutions. Detecting and linking the ridges in the DOLP three-space describes elongated forms and links the largest peaks in the tree. The principles for determining the correspondence between symbols in pairs of such descriptions are then described. Such correspondence matching is shown to be simplified by using the correspondence at lower resolutions to constrain the possible correspondence at higher resolutions."
            },
            "slug": "A-Representation-for-Shape-Based-on-Peaks-and-in-of-Crowley-Parker",
            "title": {
                "fragments": [],
                "text": "A Representation for Shape Based on Peaks and Ridges in the Difference of Low-Pass Transform"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A multiple resolution representation for the two-dimensional gray-scale shapes in an image is defined by detecting peaks and ridges in the difference of lowpass (DOLP) transform and the principles for determining the correspondence between symbols in pairs of such descriptions are described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 456211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70284b4fe852f472d4576c30f97a6fddbfef2aee",
            "isKey": false,
            "numCitedBy": 532,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We question the role that large scale filter banks have traditionally played in texture classification. It is demonstrated that textures can be classified using the joint distribution of intensity values over extremely compact neighborhoods (starting from as small as 3 /spl times/ 3 pixels square), and that this outperforms classification using filter banks with large support. We develop a novel texton based representation, which is suited to modeling this joint neighborhood distribution for MRFs. The representation is learnt from training images, and then used to classify novel images (with unknown viewpoint and lighting) into texture classes. The power of the method is demonstrated by classifying over 2800 images of all 61 textures present in the Columbia-Utrecht database. The classification performance surpasses that of recent state-of-the-art filter bank based classifiers such as Leung & Malik, Cula & Dana, and Varma & Zisserman."
            },
            "slug": "Texture-classification:-are-filter-banks-necessary-Varma-Zisserman",
            "title": {
                "fragments": [],
                "text": "Texture classification: are filter banks necessary?"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A novel texton based representation is developed, which is suited to modeling this joint neighborhood distribution for MRFs, and it is demonstrated that textures can be classified using the joint distribution of intensity values over extremely compact neighborhoods."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2264779"
                        ],
                        "name": "T. Kadir",
                        "slug": "T.-Kadir",
                        "structuredName": {
                            "firstName": "Timor",
                            "lastName": "Kadir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kadir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144431498"
                        ],
                        "name": "M. Brady",
                        "slug": "M.-Brady",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brady",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brady"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 825395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "254be2055a84c4d80c4c8eb8e6090b3977cc6fb6",
            "isKey": false,
            "numCitedBy": 1255,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Many computer vision problems can be considered to consist of two main tasks: the extraction of image content descriptions and their subsequent matching. The appropriate choice of type and level of description is of course task dependent, yet it is generally accepted that the low-level or so called early vision layers in the Human Visual System are context independent.This paper concentrates on the use of low-level approaches for solving computer vision problems and discusses three inter-related aspects of this: saliency; scale selection and content description. In contrast to many previous approaches which separate these tasks, we argue that these three aspects are intrinsically related. Based on this observation, a multiscale algorithm for the selection of salient regions of an image is introduced and its application to matching type problems such as tracking, object recognition and image retrieval is demonstrated."
            },
            "slug": "Saliency,-Scale-and-Image-Description-Kadir-Brady",
            "title": {
                "fragments": [],
                "text": "Saliency, Scale and Image Description"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A multiscale algorithm for the selection of salient regions of an image is introduced and its application to matching type problems such as tracking, object recognition and image retrieval is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747498"
                        ],
                        "name": "B. Georgescu",
                        "slug": "B.-Georgescu",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Georgescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Georgescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782918"
                        ],
                        "name": "I. Shimshoni",
                        "slug": "I.-Shimshoni",
                        "structuredName": {
                            "firstName": "Ilan",
                            "lastName": "Shimshoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Shimshoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1833221,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c41bf09e692ae81b7f81e8c657303b30a4d807b5",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Feature space analysis is the main module in many computer vision tasks. The most popular technique, k-means clustering, however, has two inherent limitations: the clusters are constrained to be spherically symmetric and their number has to be known a priori. In nonparametric clustering methods, like the one based on mean shift, these limitations are eliminated but the amount of computation becomes prohibitively large as the dimension of the space increases. We exploit a recently proposed approximation technique, locality-sensitive hashing (LSH), to reduce the computational complexity of adaptive mean shift. In our implementation of LSH the optimal parameters of the data structure are determined by a pilot learning procedure, and the partitions are data driven. As an application, the performance of mode and k-means based textons are compared in a texture classification study."
            },
            "slug": "Mean-shift-based-clustering-in-high-dimensions:-a-Georgescu-Shimshoni",
            "title": {
                "fragments": [],
                "text": "Mean shift based clustering in high dimensions: a texture classification example"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work exploits a recently proposed approximation technique, locality-sensitive hashing (LSH), to reduce the computational complexity of adaptive mean shift and implements the implementation of LSH, where the optimal parameters of the data structure are determined by a pilot learning procedure, and the partitions are data driven."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1911372"
                        ],
                        "name": "T. Randen",
                        "slug": "T.-Randen",
                        "structuredName": {
                            "firstName": "Trygve",
                            "lastName": "Randen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Randen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31557075"
                        ],
                        "name": "J. H. Hus\u00f8y",
                        "slug": "J.-H.-Hus\u00f8y",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hus\u00f8y",
                            "middleNames": [
                                "H\u00e5kon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Hus\u00f8y"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Each of these regions can be thought of as a texture element having a characteristic elliptic shape and a distinctive appearance pattern."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17026785,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8c3ae83da4542257971c4033087bcd7eb33465a6",
            "isKey": false,
            "numCitedBy": 1620,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we review most major filtering approaches to texture feature extraction and perform a comparative study. Filtering approaches included are Laws masks (1980), ring/wedge filters, dyadic Gabor filter banks, wavelet transforms, wavelet packets and wavelet frames, quadrature mirror filters, discrete cosine transform, eigenfilters, optimized Gabor filters, linear predictors, and optimized finite impulse response filters. The features are computed as the local energy of the filter responses. The effect of the filtering is highlighted, keeping the local energy function and the classification algorithm identical for most approaches. For reference, comparisons with two classical nonfiltering approaches, co-occurrence (statistical) and autoregressive (model based) features, are given. We present a ranking of the tested approaches based on extensive experiments."
            },
            "slug": "Filtering-for-Texture-Classification:-A-Comparative-Randen-Hus\u00f8y",
            "title": {
                "fragments": [],
                "text": "Filtering for Texture Classification: A Comparative Study"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Most major filtering approaches to texture feature extraction are reviewed and a ranking of the tested approaches based on extensive experiments is presented, showing the effect of the filtering is highlighted, keeping the local energy function and the classification algorithm identical for most approaches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144968846"
                        ],
                        "name": "Kun Xu",
                        "slug": "Kun-Xu",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747498"
                        ],
                        "name": "B. Georgescu",
                        "slug": "B.-Georgescu",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Georgescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Georgescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "[35], [50], we form classes by partitioning each image into nine nonoverlapping fragments, for a total of 999 images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[50], who report 84 percent recall using the multi-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "For one, relatively few publications actually report results on the entire database (the only studies known to us are [10], [25], [35], [50])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 188
                            }
                        ],
                        "text": "In addition, while near-perfect overall results have been shown for the CUReT database [47], the best (to our knowledge) retrieval performance on the Brodatz database is around 84 percent [50]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "to those reported by a noninvariant method [50], one might"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "We use the standard procedure followed by several Brodatz database evaluations [25], [35], [50]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6870274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f0d2b460203c6085ca0722741eb5e7f0d941603",
            "isKey": true,
            "numCitedBy": 23,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The features employed in content-based retrieval are most often simple low-level representations, while a human observer judges similarity between images based on high-level semantic properties. Using textures as an example, we show that a more accurate description of the underlying distribution of low-level features does not improve the retrieval performance. We also introduce the simplified multiresolution symmetric autoregressive model for textures, and the Bhattacharyya distance based similarity measure. Experiments are performed with four texture representations and four similarity measures over the Brodatz and Vis Tex databases."
            },
            "slug": "Performance-analysis-in-content-based-retrieval-Xu-Georgescu",
            "title": {
                "fragments": [],
                "text": "Performance analysis in content-based retrieval with textures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work shows that a more accurate description of the underlying distribution of low-level features does not improve the retrieval performance, and introduces the simplified multiresolution symmetric autoregressive model for textures, and the Bhattacharyya distance based similarity measure."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 15th International Conference on Pattern Recognition. ICPR-2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7977369"
                        ],
                        "name": "A. Doorn",
                        "slug": "A.-Doorn",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Doorn",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doorn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 54
                            }
                        ],
                        "text": "The use of soft histograms has also been\nadvocated by Koenderink and Van Doorn [19] because it alleviates aliasing effects."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "advocated by Koenderink and Van Doorn [19] because it alleviates aliasing effects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16340445,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ad6190216bd1b1f589f131c7b96bde8b702547d4",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a representation of images in which a global, but not a local topology is defined. The topology is restricted to resolutions up to the extent of the local region of interest (ROI). Although the ROI's may contain many pixels, there is no spatial order on the pixels within the ROI, the only information preserved is the histogram of pixel values within the ROI's. This can be considered as an extreme case of a textel (texture element) image: The histogram is the limit of texture where the spatial order has been completely disregarded. We argue that locally orderless images are ubiquitous in perception and the visual arts. Formally, the orderless images are most aptly described by three mutually intertwined scale spaces. The scale parameters correspond to the pixellation (\u201cinner scale\u201d), the extent of the ROI's (\u201couter scale\u201d) and the resolution in the histogram (\u201ctonal scale\u201d). We describe how to construct locally orderless images, how to render them, and how to use them in a variety of local and global image processing operations."
            },
            "slug": "The-Structure-of-Locally-Orderless-Images-Koenderink-Doorn",
            "title": {
                "fragments": [],
                "text": "The Structure of Locally Orderless Images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is argued that locally orderless images are ubiquitous in perception and the visual arts and how to construct and use them in a variety of local and global image processing operations is described."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 151
                            }
                        ],
                        "text": "We will conclude this section by discussing the advantages of the proposed descriptors over the more traditional features like differential invariants [18, 43] and filter banks [1, 7, 41, 42, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 187
                            }
                        ],
                        "text": "Invariance to such transformations is highly desirable for many applications, including wide-baseline stereo matching [1, 40, 41, 45], indexing and retrieval in image and video databases [32, 42, 43, 44], and classification of images of materials [46, 47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700928"
                        ],
                        "name": "O. Chum",
                        "slug": "O.-Chum",
                        "structuredName": {
                            "firstName": "Ond\u0159ej",
                            "lastName": "Chum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067522034"
                        ],
                        "name": "Martin Urban",
                        "slug": "Martin-Urban",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Urban",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Urban"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758039"
                        ],
                        "name": "T. Pajdla",
                        "slug": "T.-Pajdla",
                        "structuredName": {
                            "firstName": "Tom\u00e1s",
                            "lastName": "Pajdla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pajdla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "Of the above, [16], [27] are scale-invariant, while [31], [45] are fully affine-invariant."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[31], and the corner and intensity-based operators of Tuytelaars and Van Gool [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2104851,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9d5ea177c7fcaf88ec6f56cbeb3e9b74c08e98a3",
            "isKey": false,
            "numCitedBy": 3922,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied. A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under 1. continuous (and thus projective) transformation of image coordinates and 2. monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely-invariant stable subset of extremal regions, the maximally stable extremal regions (MSER). A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences. The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5\u00d7), illumination conditions, out-of-plane rotation, occlusion , locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained."
            },
            "slug": "Robust-Wide-Baseline-Stereo-from-Maximally-Stable-Matas-Chum",
            "title": {
                "fragments": [],
                "text": "Robust Wide Baseline Stereo from Maximally Stable Extremal Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints, is studied and an efficient and practically fast detection algorithm is presented for an affinely-invariant stable subset of extremal regions, the maximally stable extremal region (MSER)."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13687267"
                        ],
                        "name": "Tanweer Kabir",
                        "slug": "Tanweer-Kabir",
                        "structuredName": {
                            "firstName": "Tanweer",
                            "lastName": "Kabir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tanweer Kabir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170732251"
                        ],
                        "name": "Fang Liu",
                        "slug": "Fang-Liu",
                        "structuredName": {
                            "firstName": "Fang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fang Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[35], [50], we form classes by partitioning each image into nine nonoverlapping fragments, for a total of 999 images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "We use the standard procedure followed by several Brodatz database evaluations [25], [35], [50]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "For one, relatively few publications actually report results on the entire database (the only studies known to us are [10], [25], [35], [50])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "higher than the results reported in [25], [35], but below Xu"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 6884754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2cdfb65cb9d565f831fe11d048c8958c2c5e40f4",
            "isKey": true,
            "numCitedBy": 149,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The Brodatz Album has become the de facto standard for evaluating texture algorithms, with hundreds of studies having been applied to small sets of its images. The authors compare two powerful recognition algorithms, principal components analysis and multiscale autoregressive models, by evaluating them on a 999-image database derived from the entire Brodatz Album. The variety of homogeneous and nonhomogeneous images studied is thus nearly an order of magnitude larger than has been compared before, giving one snapshot of the state of the art in real-time texture recognition.<<ETX>>"
            },
            "slug": "Real-time-recognition-with-the-entire-Brodatz-Picard-Kabir",
            "title": {
                "fragments": [],
                "text": "Real-time recognition with the entire Brodatz texture database"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The authors compare two powerful recognition algorithms, principal components analysis and multiscale autoregressive models, by evaluating them on a 999-image database derived from the entire Brodatz Album, giving one snapshot of the state of the art in real-time texture recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7977369"
                        ],
                        "name": "A. Doorn",
                        "slug": "A.-Doorn",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Doorn",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doorn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "features like differential invariants [18], [43] and filter"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24284500,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "00aa5220d49f3fcf357c1b64ac14f24cd8afb76d",
            "isKey": false,
            "numCitedBy": 626,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that a convolution with certain reasonable receptive field (RF) profiles yields the exact partial derivatives of the retinal illuminance blurred to a specified degree. Arbitrary concatenations of such RF profiles yield again similar ones of higher order and for a greater degree of blurring.By replacing the illuminance with its third order jet extension we obtain position dependent geometries. It is shown how such a representation can function as the substrate for \u201cpoint processors\u201d computing geometrical features such as edge curvature. We obtain a clear dichotomy between local and multilocal visual routines. The terms of the truncated Taylor series representing the jets are partial derivatives whose corresponding RF profiles closely mimic the well known units in the primary visual cortex. Hence this description provides a novel means to understand and classify these units.Taking the receptive field outputs as the basic input data one may devise visual routines that compute geometric features on the basis of standard differential geometry exploiting the equivalence with the local jets (partial derivatives with respect to the space coordinates)."
            },
            "slug": "Representation-of-local-geometry-in-the-visual-Koenderink-Doorn",
            "title": {
                "fragments": [],
                "text": "Representation of local geometry in the visual system"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "It is shown that a convolution with certain reasonable receptive field (RF) profiles yields the exact partial derivatives of the retinal illuminance blurred to a specified degree and how this representation can function as the substrate for \u201cpoint processors\u201d computing geometrical features such as edge curvature."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40309692"
                        ],
                        "name": "C. G. Harris",
                        "slug": "C.-G.-Harris",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40365651"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stephens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "Both of these methods rely on a multiscale version of the Harris operator [12] to localize interest points in space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1694378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6818668fb895d95861a2eb9673ddc3a41e27b3b3",
            "isKey": false,
            "numCitedBy": 14111,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed."
            },
            "slug": "A-Combined-Corner-and-Edge-Detector-Harris-Stephens",
            "title": {
                "fragments": [],
                "text": "A Combined Corner and Edge Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem the authors are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work."
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065554001"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "Each of these regions can be thought of as a texture element having a characteristic elliptic shape and a distinctive appearance pattern."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5601682,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "29cb9c230d999a2175c31969f0d90fcae3fb4efe",
            "isKey": false,
            "numCitedBy": 1083,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of human preattentive texture perception. This model consists of three stages: (1) convolution of the image with a bank of even-symmetric linear filters followed by half-wave rectification to give a set of responses modeling outputs of V1 simple cells, (2) inhibition, localized in space, within and among the neural-response profiles that results in the suppression of weak responses when there are strong responses at the same or nearby locations, and (3) texture-boundary detection by using wide odd-symmetric mechanisms. Our model can predict the salience of texture boundaries in any arbitrary gray-scale image. A computer implementation of this model has been tested on many of the classic stimuli from psychophysical literature. Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminability in human observers."
            },
            "slug": "Preattentive-texture-discrimination-with-early-Malik-Perona",
            "title": {
                "fragments": [],
                "text": "Preattentive texture discrimination with early vision mechanisms."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A model of human preattentive texture perception that can predict the salience of texture boundaries in any arbitrary gray-scale image and Quantitative predictions of the degree of discriminability of different texture pairs match well with experimental measurements of discriminateability in human observers."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics and image science"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829696"
                        ],
                        "name": "Y. Rubner",
                        "slug": "Y.-Rubner",
                        "structuredName": {
                            "firstName": "Yossi",
                            "lastName": "Rubner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rubner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "Before presenting the details of our approach (Section 3), let us briefly discuss a number of texture models aimed at achieving invariance under various geometric transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14106275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d13a04844e4a781e5180987118f732d93aa9f398",
            "isKey": false,
            "numCitedBy": 4139,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the properties of a metric between two distributions, the Earth Mover's Distance (EMD), for content-based image retrieval. The EMD is based on the minimal cost that must be paid to transform one distribution into the other, in a precise sense, and was first proposed for certain vision problems by Peleg, Werman, and Rom. For image retrieval, we combine this idea with a representation scheme for distributions that is based on vector quantization. This combination leads to an image comparison framework that often accounts for perceptual similarity better than other previously proposed methods. The EMD is based on a solution to the transportation problem from linear optimization, for which efficient algorithms are available, and also allows naturally for partial matching. It is more robust than histogram matching techniques, in that it can operate on variable-length representations of the distributions that avoid quantization and other binning problems typical of histograms. When used to compare distributions with the same overall mass, the EMD is a true metric. In this paper we focus on applications to color and texture, and we compare the retrieval performance of the EMD with that of other distances."
            },
            "slug": "The-Earth-Mover's-Distance-as-a-Metric-for-Image-Rubner-Tomasi",
            "title": {
                "fragments": [],
                "text": "The Earth Mover's Distance as a Metric for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper investigates the properties of a metric between two distributions, the Earth Mover's Distance (EMD), for content-based image retrieval, and compares the retrieval performance of the EMD with that of other distances."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 256
                            }
                        ],
                        "text": "\u2026make restrictive assumptions about the nature of the input texture (e.g., stationarity) and they are not, in general, invariant with respect to 2D similarity and affine transformations, much less to 3D transformations such as viewpoint changes and nonrigid deformations of the textured surface."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25503,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "The proposed approach is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1699616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e81996384b030b580a0e02c0dc367d59c0c15ba",
            "isKey": false,
            "numCitedBy": 697,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been considerable success in automated reconstruction for image sequences where small baseline algorithms can be used to establish matches across a number of images. In contrast in the case of widely separated views, methods have generally been restricted to two or three views.In this paper we investigate the problem of establishing relative viewpoints given a large number of images where no ordering information is provided. A typical application would be where images are obtained from different sources or at different times: both the viewpoint (position, orientation, scale) and lighting conditions may vary significantly over the data set.Such a problem is not fundamentally amenable to exhaustive pair wise and triplet wide baseline matching because this would be prohibitively expensive as the number of views increases. Instead, we investiate how a combination of image invariants, covariants, and multiple view relations can be used in concord to enable efficient multiple view matching. The result is a matching algorithm which is linear in the number of views.The methods are illustrated on several real image data sets. The output enables an image based technique for navigating in a 3D scene, moving from one image to whichever image is the next most appropriate."
            },
            "slug": "Multi-view-Matching-for-Unordered-Image-Sets,-or-Do-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Multi-view Matching for Unordered Image Sets, or \"How Do I Organize My Holiday Snaps?\""
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper invests how a combination of image invariants, covariants, and multiple view relations can be used in concord to enable efficient multiple view matching and produces a matching algorithm which is linear in the number of views."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Lindeberg [24] has extended this detector in the framework of automatic scale selection, where a \u201cblob\u201d is defined by a scale-space location where a normalized Laplacian measure attains a local maximum."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "The technical details of automatic scale selection and affine adaptation, described in [9], [24], [33], are beyond the scope of this paper."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 723210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b02f474196fb9bd61fa3d418a7ba8ac500e8d422",
            "isKey": false,
            "numCitedBy": 2940,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of \u03b3-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure.Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation.In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments."
            },
            "slug": "Feature-Detection-with-Automatic-Scale-Selection-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Feature Detection with Automatic Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation and how it can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326400"
                        ],
                        "name": "B. Julesz",
                        "slug": "B.-Julesz",
                        "structuredName": {
                            "firstName": "B\u00e9la",
                            "lastName": "Julesz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Julesz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "One commonly thinks of a texture image as being \u201cgenerated\u201d by a few basic primitives or textons [15], repeated many times and arranged in some regular or stochastic spatial pattern."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4327694,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "8999355e47248bc60f5768fc2168fd28295b5f27",
            "isKey": false,
            "numCitedBy": 1772,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Research with texture pairs having identical second-order statistics has revealed that the pre-attentive texture discrimination system cannot globally process third- and higher-order statistics, and that discrimination is the result of a few local conspicuous features, called textons. It seems that only the first-order statistics of these textons have perceptual significance, and the relative phase between textons cannot be perceived without detailed scrutiny by focal attention."
            },
            "slug": "Textons,-the-elements-of-texture-perception,-and-Julesz",
            "title": {
                "fragments": [],
                "text": "Textons, the elements of texture perception, and their interactions"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Research with texture pairs having identical second-order statistics has revealed that the pre-attentive texture discrimination system cannot globally process third- and higher- order statistics, and that discrimination is the result of a few local conspicuous features, called textons."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143808488"
                        ],
                        "name": "E. Levina",
                        "slug": "E.-Levina",
                        "structuredName": {
                            "firstName": "Elizaveta",
                            "lastName": "Levina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678771"
                        ],
                        "name": "P. Bickel",
                        "slug": "P.-Bickel",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bickel",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bickel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "The theoretical justification of this formula and the specifics of the optimization setup are beyond the scope of this paper; we refer the interested reader to [23], [39] for more details."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9682419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "554ed92c2af92d5a1456bed2ddc85fe59d5dae00",
            "isKey": false,
            "numCitedBy": 503,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The Earth Mover's distanc1e was first introduced as a purely empirical ways to measure texture and color similarities. We show that it has a rigorous probabilistic interpretation and is conceptually equivalent to the Mallows distance on probability distributions. The two distances are exactly the same when applied to probability distributions, but behave differently when applied to unnormalized distributions with different masses, called signatures. We discuss the advantages and disadvantages of both distances, and statistical issues involved in computing them from data. We also report some texture classification results for the Mallows distance applied to texture features and compare several ways of estimating feature distributions. In addition, we list some known probabilistic properties of this distance."
            },
            "slug": "The-Earth-Mover's-distance-is-the-Mallows-distance:-Levina-Bickel",
            "title": {
                "fragments": [],
                "text": "The Earth Mover's distance is the Mallows distance: some insights from statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The Earth Mover's distanc1e has a rigorous probabilistic interpretation and is conceptually equivalent to the Mallows distance on probability distributions, but behave differently when applied to unnormalized distributions with different masses, called signatures."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716904"
                        ],
                        "name": "J. Koenderink",
                        "slug": "J.-Koenderink",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koenderink",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koenderink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7977369"
                        ],
                        "name": "A. Doorn",
                        "slug": "A.-Doorn",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Doorn",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doorn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710772"
                        ],
                        "name": "Kristin J. Dana",
                        "slug": "Kristin-J.-Dana",
                        "structuredName": {
                            "firstName": "Kristin",
                            "lastName": "Dana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristin J. Dana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14489428,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "3abfd03c050f03e8bcd900340fab76c6c00f2d8f",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive the BRDF (Bidirectional Reflection Distribution Function) at the mega scale of opaque surfaces that are rough on the macro and micro scale. The roughness at the micro scale is modeled as a uniform, isotropically scattering, Lambertian surface. At the macro scale the roughness is modeled by way of a distribution of spherical concavities. These pits influence the BRDF via vignetting, cast shadow, interreflection and interposition, causing it to differ markedly from Lambertian. Pitted surfaces show strong backward scattering (so called \u201copposition effect\u201d). When we assume that the macro scale can be resolved, the radiance histogram and the spatial structure of the textons of the textured surface (at the mega scale) can be calculated. This is the main advantage of the model over previous ones: One can do exact (numerical) calculations for a surface geometry that is physically realizable."
            },
            "slug": "Bidirectional-Reflection-Distribution-Function-of-Koenderink-Doorn",
            "title": {
                "fragments": [],
                "text": "Bidirectional Reflection Distribution Function of Thoroughly Pitted Surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The BRDF (Bidirectional Reflection Distribution Function) at the mega scale of opaque surfaces that are rough on the macro and micro scale is derived, which means one can do exact calculations for a surface geometry that is physically realizable."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326400"
                        ],
                        "name": "B. Julesz",
                        "slug": "B.-Julesz",
                        "structuredName": {
                            "firstName": "B\u00e9la",
                            "lastName": "Julesz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Julesz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "At the feature extraction stage, a sparse set of affineHarris and Laplacian regions is found in the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29648250,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4754bfb45726057d98ad47499481e8c172233e20",
            "isKey": false,
            "numCitedBy": 895,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual discrimination experiments were conducted using unfamiliar displays generated by a digital computer. The displays contained two side-by-side fields with different statistical, topological or heuristic properties. Discrimination was defined as that spontaneous visual process which gives the immediate impression of two distinct fields. The condition for such discrimination was found to be based primarily on clusters or lines formed by proximate points of uniform brightness. A similar rule of connectivity with hue replacing brightness was obtained by using varicolored dots of equal subjective brightness. The limitations in discriminating complex line structures were also investigated."
            },
            "slug": "Visual-Pattern-Discrimination-Julesz",
            "title": {
                "fragments": [],
                "text": "Visual Pattern Discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The condition for discrimination was found to be based primarily on clusters or lines formed by proximate points of uniform brightness, and a similar rule of connectivity with hue replacing brightness was obtained by using varicolored dots of equal subjective brightness."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409513867"
                        ],
                        "name": "M.",
                        "slug": "M.",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "M.",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M."
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Each of these regions can be thought of as a texture element having a characteristic elliptic shape and a distinctive appearance pattern."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1990278,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f7625798c6e08daa9a603551c71bab68f9abe5dd",
            "isKey": false,
            "numCitedBy": 3671,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "A b m t-I n this survey we review the impge processing literature on the various approaches and models investigators have uaed for texture."
            },
            "slug": "Statistical-and-Structural-Approaches-to-Texture-M.",
            "title": {
                "fragments": [],
                "text": "Statistical and Structural Approaches to Texture"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102539957"
                        ],
                        "name": "Wei-Liem Loh",
                        "slug": "Wei-Liem-Loh",
                        "structuredName": {
                            "firstName": "Wei-Liem",
                            "lastName": "Loh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Liem Loh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2245494"
                        ],
                        "name": "T. Lam",
                        "slug": "T.-Lam",
                        "structuredName": {
                            "firstName": "Tao-Kai",
                            "lastName": "Lam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 118506641,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "55fdd2f19ba0f08705bd0f8713d24da1493dd948",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This article considers the estimation of structured correlation matrices in infinitely differentiable Gaussian random field models. The problem is essentially motivated by the stochastic modeling of smooth deterministic responses in computer experiments. In particular, the log-likelihood function is determined explicitly in closed-form and the sieve maximum likelihood estimators are shown to be strongly consistent under mild conditions."
            },
            "slug": "Estimating-structured-correlation-matrices-in-field-Loh-Lam",
            "title": {
                "fragments": [],
                "text": "Estimating structured correlation matrices in smooth Gaussian random field models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50718271"
                        ],
                        "name": "L. Kaufman",
                        "slug": "L.-Kaufman",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Kaufman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kaufman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2218687"
                        ],
                        "name": "P. Rousseeuw",
                        "slug": "P.-Rousseeuw",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Rousseeuw",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Rousseeuw"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "repeatedly merges clusters until the average intracluster distance exceeds a specified threshold [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60820748,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "965ea5946708f0b669403a377c48e78e9326be61",
            "isKey": false,
            "numCitedBy": 8264,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An electrical signal transmission system, applicable to the transmission of signals from trackside hot box detector equipment for railroad locomotives and rolling stock, wherein a basic pulse train is transmitted whereof the pulses are of a selected first amplitude and represent a train axle count, and a spike pulse of greater selected amplitude is transmitted, occurring immediately after the axle count pulse to which it relates, whenever an overheated axle box is detected. To enable the signal receiving equipment to determine on which side of a train the overheated box is located, the spike pulses are of two different amplitudes corresponding, respectively, to opposite sides of the train."
            },
            "slug": "Finding-Groups-in-Data:-An-Introduction-to-Cluster-Kaufman-Rousseeuw",
            "title": {
                "fragments": [],
                "text": "Finding Groups in Data: An Introduction to Cluster Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An electrical signal transmission system, applicable to the transmission of signals from trackside hot box detector equipment for railroad locomotives and rolling stock, wherein a basic pulse train is transmitted whereof the pulses are of a selected first amplitude and represent a train axle count."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5107897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2893662ec4001949b4afcba124492340216dfd7e",
            "isKey": false,
            "numCitedBy": 732,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\u2018Invariant regions\u2019 are self-adaptive image patches that automatically deform with changing viewpoint as to keep on covering identical physical parts of a scene. Such regions can be extracted directly from a single image. They are then described by a set of invariant features, which makes it relatively easy to match them between views, even under wide baseline conditions. In this contribution, two methods to extract invariant regions are presented. The first one starts from corners and uses the nearby edges, while the second one is purely intensity-based. As a matter of fact, the goal is to build an opportunistic system that exploits several types of invariant regions as it sees fit. This yields more correspondences and a system that can deal with a wider range of images. To increase the robustness of the system, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric). They allow to test the consistency of correspondences and hence to reject falsely matched regions. Experiments on images of real-world scenes taken from substantially different viewpoints demonstrate the feasibility of the approach."
            },
            "slug": "Matching-Widely-Separated-Views-Based-on-Affine-Tuytelaars-Gool",
            "title": {
                "fragments": [],
                "text": "Matching Widely Separated Views Based on Affine Invariant Regions"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "To increase the robustness of the system, two semi-local constraints on combinations of region correspondences are derived (one geometric, the other photometric) allow to test the consistency of correspondences and hence to reject falsely matched regions."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Her research interests include computer vision , object and pattern recognition, and machine learning. She is a student member of"
            },
            "venue": {
                "fragments": [],
                "text": "Her research interests include computer vision , object and pattern recognition, and machine learning. She is a student member of"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Zisserman . Multiview matching for unordered image sets , or \u201c How do I organize my holiday snaps ? \u201d"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . European Conf . Comp . Vision"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "Alternative region extraction schemes include the \u201centropy detector\u201d of Kadir and Brady [16], the difference-ofGaussians (or DoG) detector of Lowe [27], the \u201cmaximally stable extremal regions\u201d of Matas et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 70
                            }
                        ],
                        "text": "Alternative region extraction schemes include the \u201centropy detector\u201d of Kadir and Brady [16], the difference-ofGaussians (or DoG) detector of Lowe [27], the \u201cmaximally stable extremal regions\u201d of Matas et al. [31], and the corner and intensity-based operators of Tuytelaars and Van Gool [45]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Of the above, [16], [27] are scale-invariant, while [31], [45] are fully affine-invariant."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scale, Saliency and Image Description"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Blostein and Ahuja [3] were the first to introduce a multiscale blob detector based on maxima of the Laplacian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A multiscale region detector. Computer Vision, Graphics and Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": "A multiscale region detector. Computer Vision, Graphics and Image Processing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "The proposed approach is evaluated in retrieval and classification tasks using the entire Brodatz database and a publicly available collection of 1,000 photographs of textured surfaces taken from different viewpoints."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matching Widely Separated Views Based on Affinely Invariant Neighbourhoods"
            },
            "venue": {
                "fragments": [],
                "text": "Int'l J. Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "Alternative region extraction schemes include the \u201centropy detector\u201d of Kadir and Brady [16], the difference-of-Gaussians (or DoG) detector of Lowe [27], the \u201cmaximally stable extremal regions\u201d of Matas et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 14
                            }
                        ],
                        "text": "Of the above, [16, 27] are scale-invariant, while [31, 45] are fully affine-invariant."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 70
                            }
                        ],
                        "text": "Alternative region extraction schemes include the \u201centropy detector\u201d of Kadir and Brady [16], the difference-ofGaussians (or DoG) detector of Lowe [27], the \u201cmaximally stable extremal regions\u201d of Matas et al. [31], and the corner and intensity-based operators of Tuytelaars and Van Gool [45]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scale, saliency and image"
            },
            "venue": {
                "fragments": [],
                "text": "description. IJCV,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE"
            },
            "year": 1278
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "The use of soft histograms has also been advocated by Koenderink and Van Doorn [19] because it alleviates aliasing effects."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 54
                            }
                        ],
                        "text": "The use of soft histograms has also been\nadvocated by Koenderink and Van Doorn [19] because it alleviates aliasing effects."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The structure of locally orderless"
            },
            "venue": {
                "fragments": [],
                "text": "images. IJCV,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 205
                            }
                        ],
                        "text": "Conceptually, our approach may be traced back to early papers on the extraction of local features in natural images, where emphasis is placed on locating perceptually salient primitives such as blobs [6], [48]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detecting Textons and Texture Boundaries in Natural Images"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int'l Conf. Computer Vision"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "Each of these regions can be thought of as a texture element having a characteristic elliptic shape and a distinctive appearance pattern."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random Field Models Handbook of Image and Video Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Random Field Models Handbook of Image and Video Processing"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. IEEE Conf. Comp. Vision Patt. Recog"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. Comp. Vision Patt. Recog"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "Blostein and Ahuja [3] were the first to introduce a multiscale blob detector based on maxima of the Laplacian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Multiscale Region Detector,\u201dComputer"
            },
            "venue": {
                "fragments": [],
                "text": "Vision, Graphics, and Image Processing,"
            },
            "year": 1989
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 35,
            "methodology": 19,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 62,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/A-sparse-texture-representation-using-local-affine-Lazebnik-Schmid/72bf4b2ce534b95bc24118491dbc4f8d550734a2?sort=total-citations"
}