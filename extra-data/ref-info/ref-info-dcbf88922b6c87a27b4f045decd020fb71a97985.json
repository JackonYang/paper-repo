{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144404428"
                        ],
                        "name": "Yang Song",
                        "slug": "Yang-Song",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149680415"
                        ],
                        "name": "L. Goncalves",
                        "slug": "L.-Goncalves",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Goncalves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Goncalves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 6
                            }
                        ],
                        "text": "As in [10, 11], we assumed all the pdfs were Gaussian, and the parameters for the Gaussian distribution were estimated from the training set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "The detailed analysis and explanation of equation (12) to (13) can be found in [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "Another way to perform detection [11] is to first get the most likely labeling (the labeling with highest PLbody (Xbody) (1=S) M K L ), then compare the likelihood of such labeling to a threshold."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "3) and thresholding the likelihood of the most human like configuration (as in [11])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 97
                            }
                        ],
                        "text": "= argmax L2L PSbody (Xbody) (11) The above optimization can be done by dynamic programming as in [10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14427717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d52b2f12ca4b5b4db30943c7c29d91237aa4ec22",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of detecting and labeling a moving human body viewed monocularly in a cluttered scene is considered. The task is to decide whether or not one or more people are in the scene (detection), to count them, and to label their visible body parts (labeling). \n \nIt is assumed that a motion-tracking front end is supplied: a number of moving features, some belonging to the body and some to the background are tracked for two frames and their position and velocity is supplied (Johansson display). It is not guaranteed that all the body parts are visible, nor that the only motion present is the one of the body. \n \nThe algorithm is based on our previous work [12]; we learn a probabilistic model of the position and motion of body features, and calculate maximum-likelihood labels efficiently using dynamic programming on a triangulated approximation of the probabilistic model. We extend those results by allowing an arbitrary number of body parts to be undetected (e.g. because of occlusion) and by allowing an arbitrary number of noise features to be present. We train and test on walking and dancing sequences for a total of approximately 104 frames. The algorithm is demonstrated to be accurate and efficient."
            },
            "slug": "Monocuolar-Perception-of-Biological-Motion-Clutter-Song-Goncalves",
            "title": {
                "fragments": [],
                "text": "Monocuolar Perception of Biological Motion - Clutter and Partial Occlusion"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The problem of detecting and labeling a moving human body viewed monocularly in a cluttered scene is considered and a probabilistic model of the position and motion of body features is learned and maximum-likelihood labels are calculated efficiently using dynamic programming on a triangulated approximation of the probabilism model."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144404428"
                        ],
                        "name": "Yang Song",
                        "slug": "Yang-Song",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149680415"
                        ],
                        "name": "L. Goncalves",
                        "slug": "L.-Goncalves",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Goncalves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Goncalves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772763"
                        ],
                        "name": "E. Bernardo",
                        "slug": "E.-Bernardo",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Bernardo",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bernardo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 6
                            }
                        ],
                        "text": "As in [10, 11], we assumed all the pdfs were Gaussian, and the parameters for the Gaussian distribution were estimated from the training set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[10] have demonstrated that their system generalizes well to viewpoint changes and to different types of motion when using unoccluded Johansson stimuli and this gives reason to believe that our system would be equally robust."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[10] have focused on detection in the context of Johannson stimuli."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 97
                            }
                        ],
                        "text": "= argmax L2L PSbody (Xbody) (11) The above optimization can be done by dynamic programming as in [10, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 90
                            }
                        ],
                        "text": "The summation in equation (7) can be done by an algorithm similar to dynamic programming ([10, 1])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[10] provides a way to approximate the foreground probability density PSbody (Xbody) so that we can do the summation efficiently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 42
                            }
                        ],
                        "text": "The structure of the decomposable graph ( [1, 10]) allows us to do the summation as follows, X"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2185149,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1dfba037b2bd101f3ec172cac1589625edb539c3",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer perception of biological motion is key to developing convenient and powerful human-computer interfaces. Successful body tracking algorithms have been developed; however initialization is done by hand. We propose a method for detecting a moving human body and for labeling its parts automatically. It is based on maximizing the joint probability density function (PDF) of the position and velocity of the body parts. The PDF is estimated from training data. Dynamic programming is used for calculating efficiently the best global labeling on an approximation of the PDF. The computational cost is on the order of N/sup 4/ where N is the number of features detected. We explore the performance of our method with experiments carried on a variety of periodic and non-periodic body motions viewed monocularly for a total of approximately 30,000 frames. Point-markers were strapped to the joints of the subject for facilitating image analysis. We find an average of 2.3% labeling error; the experiments also suggest a high degree of viewpoint-invariance."
            },
            "slug": "Monocular-perception-of-biological-motion-detection-Song-Goncalves",
            "title": {
                "fragments": [],
                "text": "Monocular perception of biological motion-detection and labeling"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "A method for detecting a moving human body and for labeling its parts automatically based on maximizing the joint probability density function (PDF) of the position and velocity of the body parts."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 104
                            }
                        ],
                        "text": "Of the two, tracking has recently been object of much attention and considerable progress has been made [9, 8, 3, 4, 2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2751624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f6a3dea66b539d75c30fb24ecefe627bbb0c3a9",
            "isKey": false,
            "numCitedBy": 882,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences. We introduce the use of a novel mathematical technique, the product of exponential maps and twist motions, and its integration into a differential motion estimation. This results in solving simple linear systems, and enables us to recover robustly the kinematic degrees-of-freedom in noise and complex self occluded configurations. We demonstrate this on several image sequences of people doing articulated full body movements, and visualize the results in re-animating an artificial 3D human model. We are also able to recover and re-animate the famous movements of Eadweard Muybridge's motion studies from the last century. To the best of our knowledge, this is the first computer vision based system that is able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "slug": "Tracking-people-with-twists-and-exponential-maps-Bregler-Malik",
            "title": {
                "fragments": [],
                "text": "Tracking people with twists and exponential maps"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences, and is the first computer vision based system able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 104
                            }
                        ],
                        "text": "Of the two, tracking has recently been object of much attention and considerable progress has been made [9, 8, 3, 4, 2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15268662,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "86086a48021d34c1e36cc9e0d1fa532d3a3efb1e",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach that uses a volume model consisting of cylinders for model-based recognition of pedestrians in real-world images is presented. The human body is represented by a volume model, and medical motion data are used for simulating the movement of walking. This knowledge is exploited to determine the 3-D position, as well as the posture of an observed person. By applying a Kalman filter, the model parameters in consecutive images are incrementally estimated. The approach is tested on real image data.<<ETX>>"
            },
            "slug": "Incremental-recognition-of-pedestrians-from-image-Rohr",
            "title": {
                "fragments": [],
                "text": "Incremental recognition of pedestrians from image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "An approach that uses a volume model consisting of cylinders for model-based recognition of pedestrians in real-world images is presented, and medical motion data are used for simulating the movement of walking."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2798041"
                        ],
                        "name": "I. Haritaoglu",
                        "slug": "I.-Haritaoglu",
                        "structuredName": {
                            "firstName": "Ismail",
                            "lastName": "Haritaoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Haritaoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064469316"
                        ],
                        "name": "D. Harwood",
                        "slug": "D.-Harwood",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Harwood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harwood"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Of the two, tracking has recently been object of much attention and considerable progress has been made [9, 8, 3,  4 , 2]. Detection (given two frames: is there a human, where?), on the contrary, remains an open problem so that current trackers have either to be initialized by hand, or by ad-hoc heuristics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60733765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89d3cd1a3a189cfd8a712ae0015fe6d9d6435ffc",
            "isKey": false,
            "numCitedBy": 637,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "W/sup 4/ is a real time visual surveillance system for detecting and tracking people and monitoring their activities in an outdoor environment. It operates on monocular grayscale video imagery, or on video imagery from an infrared camera. Unlike many of the systems for tracking people, W/sup 4/ makes no use of color cues; instead, W/sup 4/ employs a combination of shape analysis and tracking to locate people and their parts (head, hands, feet, torso) and to create models of people's appearance so that they can be tracked through interactions such as occlusions. W/sup 4/ is capable of simultaneously tracking multiple people even with occlusion. It runs at 25 Hz for 320/spl times/240 resolution images on a dual pentium PC."
            },
            "slug": "W/sup-4/:-Who-When-Where-What-A-real-time-system-Haritaoglu-Harwood",
            "title": {
                "fragments": [],
                "text": "W/sup 4/: Who? When? Where? What? A real time system for detecting and tracking people"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "W/sup 4/ is a real time visual surveillance system for detecting and tracking people and monitoring their activities in an outdoor environment that employs a combination of shape analysis and tracking to locate people and their parts and to create models of people's appearance so that they can be tracked through interactions such as occlusion."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38388395"
                        ],
                        "name": "N. Howe",
                        "slug": "N.-Howe",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Howe",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Howe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1956966"
                        ],
                        "name": "M. Leventon",
                        "slug": "M.-Leventon",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Leventon",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leventon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 111
                            }
                        ],
                        "text": "The body moves in 3D which makes the estimation of these degrees of freedom a challenge in a monocular setting [3, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 81
                            }
                        ],
                        "text": "The localization results from our algorithm may be used to compute 3D pose as in [3, 5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1010343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71afe994133786f9f8865a68e6d4c065bc8101ed",
            "isKey": false,
            "numCitedBy": 329,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The three-dimensional motion of humans is underdetermined when the observation is limited to a single camera, due to the inherent 3D ambiguity of 2D video. We present a system that reconstructs the 3D motion of human subjects from single-camera video, relying on prior knowledge about human motion, learned from training data, to resolve those ambiguities. After initialization in 2D, the tracking and 3D reconstruction is automatic; we show results for several video sequences. The results show the power of treating 3D body tracking as an inference problem."
            },
            "slug": "Bayesian-Reconstruction-of-3D-Human-Motion-from-Howe-Leventon",
            "title": {
                "fragments": [],
                "text": "Bayesian Reconstruction of 3D Human Motion from Single-Camera Video"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A system that reconstructs the 3D motion of human subjects from single-camera video, relying on prior knowledge about human motion, learned from training data, to resolve those ambiguities."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053178525"
                        ],
                        "name": "G. Johansson",
                        "slug": "G.-Johansson",
                        "structuredName": {
                            "firstName": "Gunnar",
                            "lastName": "Johansson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Johansson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 123
                            }
                        ],
                        "text": "It is not so surprising after all that the human visual system has evolved to be so good at perceiving Johansson\u2019s stimuli [6, 7] where each joint of the body is shown as a moving dot."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54046837,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "58ea2fa0580b2117618be6e1cc9658a5c9531dba",
            "isKey": false,
            "numCitedBy": 4094,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports the first phase of a research program on visual perception of motion patterns characteristic of living organisms in locomotion. Such motion patterns in animals and men are termed here as biological motion. They are characterized by a far higher degree of complexity than the patterns of simple mechanical motions usually studied in our laboratories. In everyday perceptions, the visual information from biological motion and from the corresponding figurative contour patterns (the shape of the body) are intermingled. A method for studying information from the motion pattern per se without interference with the form aspect was devised. In short, the motion of the living body was represented by a few bright spots describing the motions of the main joints. It is found that 10\u201312 such elements in adequate motion combinations in proximal stimulus evoke a compelling impression of human walking, running, dancing, etc. The kinetic-geometric model for visual vector analysis originally developed in the study of perception of motion combinations of the mechanical type was applied to these biological motion patterns. The validity of this model in the present context was experimentally tested and the results turned out to be highly positive."
            },
            "slug": "Visual-perception-of-biological-motion-and-a-model-Johansson",
            "title": {
                "fragments": [],
                "text": "Visual perception of biological motion and a model for its analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The kinetic-geometric model for visual vector analysis originally developed in the study of perception of motion combinations of the mechanical type was applied to biological motion patterns and the results turned out to be highly positive."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34702104"
                        ],
                        "name": "P. Neri",
                        "slug": "P.-Neri",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Neri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Neri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087960"
                        ],
                        "name": "M. Morrone",
                        "slug": "M.-Morrone",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Morrone",
                            "middleNames": [
                                "Concetta"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Morrone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299127"
                        ],
                        "name": "D. Burr",
                        "slug": "D.-Burr",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Burr",
                            "middleNames": [
                                "Charles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4312844,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "582f32f1c26d7df019121b2a2f570f55f7e4c91b",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the more stunning examples of the resourcefulness of human vision is the ability to see \u2018biological motion\u2019, which was first shown with an adaptation of earlier cinematic work: illumination of only the joints of a walking person is enough to convey a vivid, compelling impression of human animation, although the percept collapses to a jumble of meaningless lights when the walker stands still. The information is sufficient to discriminate the sex and other details of the walker,, and can be interpreted by young infants. Here we measure the ability of the visual system to integrate this type of motion information over space and time, and compare this capacity with that for viewing simple translational motion. Sensitivity to biological motion increases rapidly with the number of illuminated joints, far more rapidly than for simple motion. Furthermore, this information is summed over extended temporal intervals of up to 3 seconds (eight times longer than for simple motion). The steepness of the summation curves indicates that the mechanisms that analyse biological motion do not integrate linearly over space and time with constant efficiency, as may occur for other forms of complex motion, but instead adapt to the nature of the stimulus."
            },
            "slug": "Seeing-biological-motion-Neri-Morrone",
            "title": {
                "fragments": [],
                "text": "Seeing biological motion"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The steepness of the summation curves indicates that the mechanisms that analyse biological motion do not integrate linearly over space and time with constant efficiency, as may occur for other forms of complex motion, but instead adapt to the nature of the stimulus."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772763"
                        ],
                        "name": "E. Bernardo",
                        "slug": "E.-Bernardo",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Bernardo",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bernardo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149680415"
                        ],
                        "name": "L. Goncalves",
                        "slug": "L.-Goncalves",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Goncalves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Goncalves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46614172"
                        ],
                        "name": "Enrico Ursella",
                        "slug": "Enrico-Ursella",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Ursella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enrico Ursella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 111
                            }
                        ],
                        "text": "The body moves in 3D which makes the estimation of these degrees of freedom a challenge in a monocular setting [3, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 104
                            }
                        ],
                        "text": "Of the two, tracking has recently been object of much attention and considerable progress has been made [9, 8, 3, 4, 2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 81
                            }
                        ],
                        "text": "The localization results from our algorithm may be used to compute 3D pose as in [3, 5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19164875,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "7d91d26d47289d5633693cb6e91cb23b26195486",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of estimating the position and motion of a human arm in 3D without any constraints on its behavior and without the use of special markers. We model the arm as two truncated right-circular cones connected with spherical joints. We propose to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image. The system is demonstrated and tested on a real image sequence.<<ETX>>"
            },
            "slug": "Monocular-tracking-of-the-human-arm-in-3D-Bernardo-Goncalves",
            "title": {
                "fragments": [],
                "text": "Monocular tracking of the human arm in 3D"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 104
                            }
                        ],
                        "text": "Of the two, tracking has recently been object of much attention and considerable progress has been made [9, 8, 3, 4, 2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16357559,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db4e821c2b09ff8774ee6f616e4dec202c9a419e",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer sensing of hand and limb motion is an important problem for applications in human-computer interaction (HCI), virtual reality, and athletic performance measurement. Commercially available sensors are invasive, and require the user to wear gloves or targets. We have developed a noninvasive vision-based hand tracking system, called DigitEyes. Employing a kinematic hand model, the DigitEyes system has demonstrated tracking performance at speeds of up to 10 Hz, using line and point features extracted from gray scale images of unadorned, unmarked hands. We describe an application of our sensor to a 3D mouse user-interface problem.<<ETX>>"
            },
            "slug": "DigitEyes:-vision-based-hand-tracking-for-Rehg-Kanade",
            "title": {
                "fragments": [],
                "text": "DigitEyes: vision-based hand tracking for human-computer interaction"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The DigitEyes system has demonstrated tracking performance at speeds of up to 10 Hz, using line and point features extracted from gray scale images of unadorned, unmarked hands, and an application of the sensor to a 3D mouse user-interface problem is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 IEEE Workshop on Motion of Non-rigid and Articulated Objects"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49504816"
                        ],
                        "name": "A. Kong",
                        "slug": "A.-Kong",
                        "structuredName": {
                            "firstName": "Augustine",
                            "lastName": "Kong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 42
                            }
                        ],
                        "text": "The structure of the decomposable graph ( [1, 10]) allows us to do the summation as follows, X"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 90
                            }
                        ],
                        "text": "The summation in equation (7) can be done by an algorithm similar to dynamic programming ([10, 1])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8425651,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c67b37fcacc4581248cb79c918f692a2af933f95",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of model registration is proposed using graphical templates. A graph of landmarks is chosen in the template image. All possible candidates for these landmarks are found in the data image using local operators. A dynamic programming algorithm on decomposable subgraphs of the template graph finds the optimal match to a subset of the candidate points in polynomial time. This combination of local operators to describe points of interest/landmarks and a graph to describe their geometric orientation in the plane, yields fast and precise matches of the model to the data, with no initialization required."
            },
            "slug": "Graphical-Templates-for-Model-Registration-Amit-Kong",
            "title": {
                "fragments": [],
                "text": "Graphical Templates for Model Registration"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This combination of local operators to describe points of interest/landmarks and a graph to describe their geometric orientation in the plane, yields fast and precise matches of the model to the data, with no initialization required."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 42
                            }
                        ],
                        "text": "The structure of the decomposable graph ( [1, 10]) allows us to do the summation as follows, X L2LPSbody (Xbody) = X L2LYT 1 t=1 Pt(XAt jXBt ; XCt)PT (XAT ; XBT ; XCT ) = X XAT ;XBT ;XCT PT (XAT ; XBT ; XCT ) X XAT 1 X XA2 P2(XA2 jXB2 ; XC2)X XA1 P1(XA1 jXB1 ; XC1) (7)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 90
                            }
                        ],
                        "text": "The summation in equation (7) can be done by an algorithm similar to dynamic programming ([10, 1])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Graphical templates for model registration.IEEE"
            },
            "venue": {
                "fragments": [],
                "text": "Transactions on Pattern Analysis and Machine Intelligence,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "Then the features are tracked automatically to the next frame using the Lucas-Tomasi-Kanade tracking algorithm ( [12]) and their velocities between the two frames are computed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detection and tracking of point features"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Rep. CMU-CS-91-132,Carnegie Mellon University,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "Then the features are tracked automatically to the next frame using the Lucas-Tomasi-Kanade tracking algorithm ( [12]) and their velocities between the two frames are computed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Detection and tracking of point features.Tech"
            },
            "venue": {
                "fragments": [],
                "text": "Rep. CMU-CS-91-132,Carnegie Mellon University,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[7] used similar assumption when conducting their psychophysical investigation of biological motion perception in the human visual system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 123
                            }
                        ],
                        "text": "It is not so surprising after all that the human visual system has evolved to be so good at perceiving Johansson\u2019s stimuli [6, 7] where each joint of the body is shown as a moving dot."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "M.C.Morrone, and D.C.Burr"
            },
            "venue": {
                "fragments": [],
                "text": "Seeing biological motion. Nature,"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Towards-detection-of-human-motion-Song-Feng/dcbf88922b6c87a27b4f045decd020fb71a97985?sort=total-citations"
}