{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3154722"
                        ],
                        "name": "Mark A. Ruzon",
                        "slug": "Mark-A.-Ruzon",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Ruzon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark A. Ruzon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "A first family of methods aims at quantifying the presence of a boundary at a given image location through local measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62357971,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37e27e86515ef410fffbff5b702139191b93ea27",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "For over 30 years (1970-2000) researchers in computer vision have been proposing new methods for performing low-level vision tasks such as detecting edges and corners. One key element shared by most methods is that they represent local image neighborhoods as constant in color or intensity with deviations modeled as noise. Due to computational considerations that encourage the use of small neighborhoods where this assumption holds, these methods remain popular. The research presented models a neighborhood as a distribution of colors. The goal is to show that the increase in accuracy of this representation translates into higher-quality results for low-level vision tasks on difficult, natural images, especially as neighborhood size increases. We emphasize large neighborhoods because small ones often do not contain enough information. We emphasize color because it subsumes gray scale as an image range and because it is the dominant form of human perception. We discuss distributions in the context of detecting edges, corners, and junctions, and we show results for each."
            },
            "slug": "Edge,-Junction,-and-Corner-Detection-Using-Color-Ruzon-Tomasi",
            "title": {
                "fragments": [],
                "text": "Edge, Junction, and Corner Detection Using Color Distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The goal is to show that the increase in accuracy of this representation translates into higher-quality results for low-level vision tasks on difficult, natural images, especially as neighborhood size increases."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 182
                            }
                        ],
                        "text": "\u2026a single multiscale oriented signal:\nmPb(x, y, \u03b8) =\n9 \u2211\ni=1\n\u03b1i \u00b7 Gi(x, y, \u03b8) (2)\nIn order to introduce global information, we consider the first k + 1 generalized eigenvectors of the system (1), noted {v0, ...,vk}, where the corresponding eigenvalues {\u03bb0, ..., \u03bbk} are such that 0 = \u03bb0 \u2264 ... \u2264 \u03bbk ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rather, we choose the support of the neighborhood large enough with respect to the support of the boundary operator so that our algorithm may recover from errors in contour detection near a junction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "Figure 2 presents the evaluation of our boundary detection results using the BSDS benchmark [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8165754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33a7a59f785ef46091c30c4c85ef88c6bdabab51",
            "isKey": false,
            "numCitedBy": 2381,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "slug": "Learning-to-detect-natural-image-boundaries-using-Martin-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Learning to detect natural image boundaries using local brightness, color, and texture cues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The two main results are that cue combination can be performed adequately with a simple linear model and that a proper, explicit treatment of texture is required to detect boundaries in natural images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2324658"
                        ],
                        "name": "Josh H. McDermott",
                        "slug": "Josh-H.-McDermott",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "McDermott",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josh H. McDermott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": "For the purposes of this paper, we consider two main approaches to this task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16339187,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "45e394ca6bd6485a0cd69ca01e4a6724d4a24aac",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Junctions, formed at the intersection of image contours, are thought to play an important and early role in vision. The interest in junctions can be attributed in part to the notion that they are local image features that are easy to detect but that nonetheless provide valuable information about important events in the world, such as occlusion and transparency. Here I test the notion that there are locally defined junctions in real images that might be detected with simple, early visual mechanisms. Human observers were used as a tool to measure the visual information available in local regions of real images. One set of observers was made to label all the points in a set of real images where one edge occluded another. A second set of observers was presented with variable-size circular subregions of these images, and was asked to judge whether the regions were centered on an occlusion point. This task is easy if junctions are visible, but I found performance to be poor for small regions, not approaching ceiling levels until observers were given fairly large (approximately 50 pixels in diameter) regions over which to make the judgment. Control experiments ruled out the possibility that the effects are just due to junctions at multiple scales. Experiments reported here suggest that, although some junctions in real images are locally defined and can be detected with simple mechanisms, a substantial fraction necessitate the use of more complex and global processes. This raises the possibility that junctions in such cases may not be detected prior to scene interpretation."
            },
            "slug": "Psychophysics-with-junctions-in-real-images.-McDermott",
            "title": {
                "fragments": [],
                "text": "Psychophysics with junctions in real images."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments reported here suggest that, although some junctions in real images are locally defined and can be detected with simple mechanisms, a substantial fraction necessitate the use of more complex and global processes, and raises the possibility that junications in such cases may not be detected prior to scene interpretation."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "We then combine linearly the local cues, denoted {Gi}, in a single multiscale oriented signal:\nmPb(x, y, \u03b8) =\n9 \u2211\ni=1\n\u03b1i \u00b7 Gi(x, y, \u03b8) (2)\nIn order to introduce global information, we consider the first k + 1 generalized eigenvectors of the system (1), noted {v0, ...,vk}, where the corresponding\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5315394,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "83f3321b8f57c11d30252b3a86e35b8ca94eb358",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The projection of depth or orientation discontinuities in a physical scene results in image intensity edges which are not ideal step edges but are more typically a combination of step, peak and roof profiles. Most edge detection schemes ignore the composite nature of these edges, resulting in systematic errors in detection and localization. The problem of detecting and localizing these edges is addressed, along with the problem of false responses in smoothly shaded regions with constant gradient of the image brightness. A class of nonlinear filters, known as quadratic filters, is appropriate for this task, while linear filters are not. Performance criteria are derived for characterizing the SNR, localization and multiple responses of these filters in a manner analogous to Canny's criteria for linear filters. A two-dimensional version of the approach is developed which has the property of being able to represent multiple edges at the same location and determine the orientation of each to any desired precision. This permits junctions to be localized without rounding. Experimental results are presented.<<ETX>>"
            },
            "slug": "Detecting-and-localizing-edges-composed-of-steps,-Perona-Malik",
            "title": {
                "fragments": [],
                "text": "Detecting and localizing edges composed of steps, peaks and roofs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A two-dimensional version of the approach is developed which has the property of being able to represent multiple edges at the same location and determine the orientation of each to any desired precision, which permits junctions to be localized without rounding."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1814318"
                        ],
                        "name": "S. Mahamud",
                        "slug": "S.-Mahamud",
                        "structuredName": {
                            "firstName": "Shyjan",
                            "lastName": "Mahamud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mahamud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2955375"
                        ],
                        "name": "L. Williams",
                        "slug": "L.-Williams",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Williams",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31373813"
                        ],
                        "name": "K. Thornber",
                        "slug": "K.-Thornber",
                        "structuredName": {
                            "firstName": "Karvel",
                            "lastName": "Thornber",
                            "middleNames": [
                                "K."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Thornber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2421148"
                        ],
                        "name": "Kanglin Xu",
                        "slug": "Kanglin-Xu",
                        "structuredName": {
                            "firstName": "Kanglin",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kanglin Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "A thinned, real-valued contour image can be obtained from gPb by considering the maximal response over orientations at each location and applying non-maximum suppression [3, 12]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15205495,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c07958ce81bc3295c8a56e57b6dec5421214921f",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Using a saliency measure based on the global property of contour closure, we have developed a segmentation method which identifies smooth closed contours bounding objects of unknown shape in real images. The saliency measure incorporates the Gestalt principles of proximity and good continuity that previous methods have also exploited. Unlike previous methods, we incorporate contour closure by finding the eigenvector with the largest positive real eigenvalue of a transition matrix for a Markov process where edges from the image serve as states. Element (i, j) of the transition matrix is the conditional probability that a contour which contains edge j will also contain edge i. We show how the saliency measure, defined for individual edges, can be used to derive a saliency relation, defined for pairs of edges, and further show that strongly-connected components of the graph representing the saliency relation correspond to smooth closed contours in the image. Finally, we report for the first time, results on large real images for which segmentation takes an average of about 10 seconds per object on a general-purpose workstation."
            },
            "slug": "Segmentation-of-Multiple-Salient-Closed-Contours-Mahamud-Williams",
            "title": {
                "fragments": [],
                "text": "Segmentation of Multiple Salient Closed Contours from Real Images"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A segmentation method which identifies smooth closed contours bounding objects of unknown shape in real images by incorporating contour closure by finding the eigenvector with the largest positive real eigenvalue of a transition matrix for a Markov process where edges from the image serve as states."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A thinned, real-valued contour image can be obtained from gPb by considering the maximal response over orientations at each location and applying non-maximum suppression [3, 12]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rather, we choose the support of the neighborhood large enough with respect to the support of the boundary operator so that our algorithm may recover from errors in contour detection near a junction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5839283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8392ada55a60ba7814aaf4ad32d1a014d1acbeae",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of curvilinear grouping using piece-wise linear representations of contours and a conditional random field to capture continuity and the frequency of different junction types. Potential completions are generated by building a constrained Delaunay triangulation (CDT) over the set of contours found by a local edge detector. Maximum likelihood parameters for the model are learned from human labeled ground truth. Using held out test data, we measure how the model, by incorporating continuity structure, improves boundary detection over the local edge detector. We also compare performance with a baseline local classifier that operates on pairs of edgels. Both algorithms consistently dominate the low-level boundary detector at all thresholds. To our knowledge, this is the first time that curvilinear continuity has been shown quantitatively useful for a large variety of natural images. Better boundary detection has immediate application in the problem of object detection and recognition"
            },
            "slug": "Scale-invariant-contour-completion-using-random-Ren-Fowlkes",
            "title": {
                "fragments": [],
                "text": "Scale-invariant contour completion using conditional random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This is the first time that curvilinear continuity has been shown quantitatively useful for a large variety of natural images and better boundary detection has immediate application in the problem of object detection and recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 1611614,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "0217380908642d79a05d8db92a775081c94f684a",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop an approach to image segmentation for natural scenes containing image texture. One general methodology which shows promise for solving this problem is to characterize textured regions via their responses to a set of filters. However, this approach brings with it many open questions, including how to combine texture and intensity information into a common descriptor and how to deal with the fact that filter responses inside textured regions are generally spatially inhomogeneous. Our goal in this paper is to introduce two new ideas which address these open questions and to demonstrate the application of these ideas to the segmentation of natural images. The first idea consists of a novel means of describing points in natural images and an associated distance function for comparing these descriptors. This distance function is aided in textured regions by the use of the second idea, a new process introduced here which we have termed area completion. Experimental segmentation results which incorporate our proposed approach into the Normalized Cut framework of Shi and Malik are provided for a variety of natural images."
            },
            "slug": "Finding-Boundaries-in-Natural-Images:-A-New-Method-Belongie-Malik",
            "title": {
                "fragments": [],
                "text": "Finding Boundaries in Natural Images: A New Method Using Point Descriptors and Area Completion"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "An approach to image segmentation for natural scenes containing image texture is developed which consists of a novel means of describing points in natural images and an associated distance function for comparing these descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729041"
                        ],
                        "name": "J. Canny",
                        "slug": "J.-Canny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Canny",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Canny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "In our experiments, we sample \u03b8 at 8 orientations in the interval [0, \u03c0)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rather, we choose the support of the neighborhood large enough with respect to the support of the boundary operator so that our algorithm may recover from errors in contour detection near a junction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13284142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcf9fc4e23b45345c2404ce7d6cb0fc9dea2c9ec",
            "isKey": false,
            "numCitedBy": 27661,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge."
            },
            "slug": "A-Computational-Approach-to-Edge-Detection-Canny",
            "title": {
                "fragments": [],
                "text": "A Computational Approach to Edge Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "There is a natural uncertainty principle between detection and localization performance, which are the two main goals, and with this principle a single operator shape is derived which is optimal at any scale."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800213"
                        ],
                        "name": "Charless C. Fowlkes",
                        "slug": "Charless-C.-Fowlkes",
                        "structuredName": {
                            "firstName": "Charless",
                            "lastName": "Fowlkes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charless C. Fowlkes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "Note that, by extracting an oriented contour signal from the eigenvectors instead of producing hard segmentations, we eliminate the problem of large uniform regions sometimes being broken up by the Normalized Cuts algorithm."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1854189,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a69bb8b10479df8300dfafe489e015de084cf6cf",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper quantifies the information gained in integrating local measurements using spectral graph partitioning. We employ a large dataset of manually segmented images in order to learn an optimal affinity function between nearby pairs of pixels. Region cues are computed as the similarity in brightness, color, and texture between image patches. Boundary cues are incorporated by looking for the presence of an \u201cintervening contour\u201d, a large gradient along a straight line connecting two pixels. We then use spectral clustering to find an approximate minimizer of the normalized cut, partitioning the image into coherent segments. We evaluate the power of local measurements and global segmentations in predicting the location of image boundaries by computing the precision and recall with respect to the human groundtruth data. The results show that spectral clustering is successful in suppressing noise and boosting weak signals over a wide variety of natural images."
            },
            "slug": "How-Much-Does-Globalization-Help-Segmentation-Fowlkes-Malik",
            "title": {
                "fragments": [],
                "text": "How Much Does Globalization Help Segmentation ?"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper quantifies the information gained in integrating local measurements using spectral graph partitioning by computing the precision and recall with respect to the human groundtruth data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702017"
                        ],
                        "name": "R. Deriche",
                        "slug": "R.-Deriche",
                        "structuredName": {
                            "firstName": "Rachid",
                            "lastName": "Deriche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Deriche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3105050"
                        ],
                        "name": "G. Giraudon",
                        "slug": "G.-Giraudon",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Giraudon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Giraudon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "A first family of methods aims at quantifying the presence of a boundary at a given image location through local measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14909083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "449cac591cd5418ed2896c5a49e9c77048e58bb5",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Corners and vertexes are strong and useful features in computer vision for scene analysis, stereo matching, and motion analysis. Here, we deal with the development of a computational approach to these important features. We consider first a corner model and study analytically its behavior once it has been smoothed using the well-known Gaussian filter. This allows us to clarify the behavior of some well-knowncornerness measure based approaches used to detect these points of interest. Most of these classical approaches appear to detect points that do not correspond to the exact position of the corner. A new scale-space based approach that combines useful properties from the Laplacian and Beaudet's measure (Beaudet 1978) is then proposed in order to correct and detect exactly the corner position. An extension of this approach is then developed to solve the problem of trihedral vertex characterization and detection. In particular, it is shown that a trihedral vertex has two elliptic maxima on extremal contrast surfaces if the contrast is sufficient, and this allows us to classify trihedral vertexes in 2 classes: \u201cvertex,\u201d and \u201cvertex as corner.\u201d The corner-detection approach developed is applied to accurately detect trihedral vertexes using an additional test in order to make a distinction between trihedral vertexes and corners. Many experiments have been carried out using noisy synthetic data and real images containing corners and vertexes. Most of the promising results obtained are used to illustrate the experimental section of this paper."
            },
            "slug": "A-computational-approach-for-corner-and-vertex-Deriche-Giraudon",
            "title": {
                "fragments": [],
                "text": "A computational approach for corner and vertex detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new scale-space based approach that combines useful properties from the Laplacian and Beaudet's measure (Beaudet 1978) is proposed in order to correct and detect exactly the corner position and an extension of this approach is developed to solve the problem of trihedral vertex characterization and detection."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778133"
                        ],
                        "name": "Pablo Arbel\u00e1ez",
                        "slug": "Pablo-Arbel\u00e1ez",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Arbel\u00e1ez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Arbel\u00e1ez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A thinned, real-valued contour image can be obtained from gPb by considering the maximal response over orientations at each location and applying non-maximum suppression [3, 12]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rather, we choose the support of the neighborhood large enough with respect to the support of the boundary operator so that our algorithm may recover from errors in contour detection near a junction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4474066,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8463e6acd5b03dc6f4c13858a8aed980cf2fed31",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a low-level system for boundary extraction and segmentation of natural images and the evaluation of its performance. We study the problem in the framework of hierarchical classification, where the geometric structure of an image can be represented by an ultrametric contour map, the soft boundary image associated to a family of nested segmentations. We define generic ultrametric distances by integrating local contour cues along the regions boundaries and combining this information with region attributes. Then, we evaluate quantitatively our results with respect to ground-truth segmentation data, proving that our system outperforms significantly two widely used hierarchical segmentation techniques, as well as the state of the art in local edge detection."
            },
            "slug": "Boundary-Extraction-in-Natural-Images-Using-Contour-Arbel\u00e1ez",
            "title": {
                "fragments": [],
                "text": "Boundary Extraction in Natural Images Using Ultrametric Contour Maps"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper presents a low-level system for boundary extraction and segmentation of natural images and the evaluation of its performance proves that this system outperforms significantly two widely used hierarchical segmentation techniques, as well as the state of the art in local edge detection."
            },
            "venue": {
                "fragments": [],
                "text": "2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "We then reshape each vj in the size of the original image and extract its contours using Gaussian directional derivatives at multiple orientations \u03b8, obtaining an oriented signal sPbvj(x, y, \u03b8)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17582380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34d4eb4666a20f7e3fad689d7862959bd128130b",
            "isKey": false,
            "numCitedBy": 1296,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture. Natural images contain both textured and untextured regions, so the cues of contour and texture differences are exploited simultaneously. Contours are treated in the intervening contour framework, while texture is analyzed using textons. Each of these cues has a domain of applicability, so to facilitate cue combination we introduce a gating operator based on the texturedness of the neighborhood at a pixel. Having obtained a local measure of how likely two nearby pixels are to belong to the same region, we use the spectral graph theoretic framework of normalized cuts to find partitions of the image into regions of coherent texture and brightness. Experimental results on a wide range of images are shown."
            },
            "slug": "Contour-and-Texture-Analysis-for-Image-Segmentation-Malik-Belongie",
            "title": {
                "fragments": [],
                "text": "Contour and Texture Analysis for Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper provides an algorithm for partitioning grayscale images into disjoint regions of coherent brightness and texture, and introduces a gating operator based on the texturedness of the neighborhood at a pixel to facilitate cue combination."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40696794"
                        ],
                        "name": "Song Wang",
                        "slug": "Song-Wang",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49711057"
                        ],
                        "name": "Toshiro Kubota",
                        "slug": "Toshiro-Kubota",
                        "structuredName": {
                            "firstName": "Toshiro",
                            "lastName": "Kubota",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiro Kubota"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737754"
                        ],
                        "name": "J. Siskind",
                        "slug": "J.-Siskind",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Siskind",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Siskind"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152809873"
                        ],
                        "name": "Jun Wang",
                        "slug": "Jun-Wang",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "Note that, by extracting an oriented contour signal from the eigenvectors instead of producing hard segmentations, we eliminate the problem of large uniform regions sometimes being broken up by the Normalized Cuts algorithm."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4765426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25c0e113dceebf329000dfde1621a777dd9bcef3",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "We present ratio contour, a novel graph-based method for extracting salient closed boundaries from noisy images. This method operates on a set of boundary fragments that are produced by edge detection. Boundary extraction identifies a subset of these fragments and connects them sequentially to form a closed boundary with the largest saliency. We encode the Gestalt laws of proximity and continuity in a novel boundary-saliency measure based on the relative gap length and average curvature when connecting fragments to form a closed boundary. This new measure attempts to remove a possible bias toward short boundaries. We present a polynomial-time algorithm for finding the most-salient closed boundary. We also present supplementary preprocessing steps that facilitate the application of ratio contour to real images. We compare ratio contour to two closely related methods for extracting closed boundaries: Elder and Zucker's method based on the shortest-path algorithm and Williams and Thornber's method based on spectral analysis and a strongly-connected-components algorithm. This comparison involves both theoretic analysis and experimental evaluation on both synthesized data and real images."
            },
            "slug": "Salient-closed-boundary-extraction-with-ratio-Wang-Kubota",
            "title": {
                "fragments": [],
                "text": "Salient closed boundary extraction with ratio contour"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The Gestalt laws of proximity and continuity are encoded in a novel boundary-saliency measure based on the relative gap length and average curvature when connecting fragments to form a closed boundary."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 187
                            }
                        ],
                        "text": "\u2026a single multiscale oriented signal:\nmPb(x, y, \u03b8) =\n9 \u2211\ni=1\n\u03b1i \u00b7 Gi(x, y, \u03b8) (2)\nIn order to introduce global information, we consider the first k + 1 generalized eigenvectors of the system (1), noted {v0, ...,vk}, where the corresponding eigenvalues {\u03bb0, ..., \u03bbk} are such that 0 = \u03bb0 \u2264 ... \u2264 \u03bbk ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rather, we choose the support of the neighborhood large enough with respect to the support of the boundary operator so that our algorithm may recover from errors in contour detection near a junction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6382669,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be305b0684f1a6ec8407c107187d28502b48f993",
            "isKey": false,
            "numCitedBy": 464,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Edge detection is one of the most studied problems in computer vision, yet it remains a very challenging task. It is difficult since often the decision for an edge cannot be made purely based on low level cues such as gradient, instead we need to engage all levels of information, low, middle, and high, in order to decide where to put edges. In this paper we propose a novel supervised learning algorithm for edge and object boundary detection which we refer to as Boosted Edge Learning or BEL for short. A decision of an edge point is made independently at each location in the image; a very large aperture is used providing significant context for each decision. In the learning stage, the algorithm selects and combines a large number of features across different scales in order to learn a discriminative model using an extended version of the Probabilistic Boosting Tree classification algorithm. The learning based framework is highly adaptive and there are no parameters to tune. We show applications for edge detection in a number of specific image domains as well as on natural images. We test on various datasets including the Berkeley dataset and the results obtained are very good."
            },
            "slug": "Supervised-Learning-of-Edges-and-Object-Boundaries-Doll\u00e1r-Tu",
            "title": {
                "fragments": [],
                "text": "Supervised Learning of Edges and Object Boundaries"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes a novel supervised learning algorithm for edge and object boundary detection which it refers to as Boosted Edge Learning or BEL for short and shows applications for edge detection in a number of specific image domains as well as on natural images."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A thinned, real-valued contour image can be obtained from gPb by considering the maximal response over orientations at each location and applying non-maximum suppression [3, 12]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rather, we choose the support of the neighborhood large enough with respect to the support of the boundary operator so that our algorithm may recover from errors in contour detection near a junction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6425029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8df48e3d8ad8d5684f26c8f9c2611b85b7b2bd1d",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of deriving a global interpretation of an image in terms of a small set of smooth curves. The problem is posed using a statistical model for images with multiple curves. Besides having important applications to edge detection and grouping the curve finding task is a special case of a more general problem, where we want to explain the whole image in terms of a small set of objects. We describe a novel approach for estimating the content of scenes with multiple objects using a min-cover framework that is simple and powerful. The min-cover problem is NP-hard but there is a good approximation algorithm that sequentially selects objects minimizing a \"cost per pixel\" measure. In the case of curve detection we use a type of best-first search to quickly find good curves for the covering algorithm. The method integrates image data over long curves without relying on binary feature detection. We have applied the curve detection method for finding object boundaries in natural scenes and measured its performance using the Berkeley segmentation dataset."
            },
            "slug": "A-Min-Cover-Approach-for-Finding-Salient-Curves-Felzenszwalb-McAllester",
            "title": {
                "fragments": [],
                "text": "A Min-Cover Approach for Finding Salient Curves"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel approach is described for estimating the content of scenes with multiple objects using a min-cover framework that is simple and powerful and integrates image data over long curves without relying on binary feature detection."
            },
            "venue": {
                "fragments": [],
                "text": "2006 Conference on Computer Vision and Pattern Recognition Workshop (CVPRW'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 12168498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1ca62714f8086af1d7be12aa0cb6d9c25bf4bcd",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Region-based image segmentation techniques make use of similarity in intensity, color and texture to determine the partitioning of an image. The powerful cue of contour continuity is not exploited at all. In this paper, we provide a way of incorporating curvilinear grouping into region-based image segmentation. Soft contour information is obtained through orientation energy. Weak contrast gaps and subjective contours are completed by contour propagation. The normalized cut approach proposed by Shi and Malik is used for the segmentation. Results on a large variety of images are shown."
            },
            "slug": "Contour-Continuity-in-Region-Based-Image-Leung-Malik",
            "title": {
                "fragments": [],
                "text": "Contour Continuity in Region Based Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A way of incorporating curvilinear grouping into region-based image segmentation through normalized cut approach and results on a large variety of images are shown."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107881808"
                        ],
                        "name": "Stella X. Yu",
                        "slug": "Stella-X.-Yu",
                        "structuredName": {
                            "firstName": "Stella",
                            "lastName": "Yu",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stella X. Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rather, we choose the support of the neighborhood large enough with respect to the support of the boundary operator so that our algorithm may recover from errors in contour detection near a junction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "Note that, by extracting an oriented contour signal from the eigenvectors instead of producing hard segmentations, we eliminate the problem of large uniform regions sometimes being broken up by the Normalized Cuts algorithm."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2791772,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1a288bbaa785ca17a98c3a6d242cf2321e2dc997",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Perceptual organization is scale-invariant. In turn, a segmentation that separates features consistently at all scales is the desired one that reveals the underlying structural organization of an image. Addressing cross-scale correspondence with interior pixels, we develop this intuition into a general segmenter that handles texture and illusory contours through edges entirely without any explicit characterization of texture or curvilinearity. Experimental results demonstrate that our method not only performs on par with either texture segmentation or boundary completion methods on their specialized examples, but also works well on a variety of real images."
            },
            "slug": "Segmentation-induced-by-scale-invariance-Yu",
            "title": {
                "fragments": [],
                "text": "Segmentation induced by scale invariance"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work develops cross-scale correspondence with interior pixels into a general segmenter that handles texture and illusory contours through edges entirely without any explicit characterization of texture or curvilinearity."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40309692"
                        ],
                        "name": "C. G. Harris",
                        "slug": "C.-G.-Harris",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Harris",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. G. Harris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40365651"
                        ],
                        "name": "M. Stephens",
                        "slug": "M.-Stephens",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Stephens",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stephens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "A first family of methods aims at quantifying the presence of a boundary at a given image location through local measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1694378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6818668fb895d95861a2eb9673ddc3a41e27b3b3",
            "isKey": false,
            "numCitedBy": 14111,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed."
            },
            "slug": "A-Combined-Corner-and-Edge-Detector-Harris-Stephens",
            "title": {
                "fragments": [],
                "text": "A Combined Corner and Edge Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem the authors are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work."
            },
            "venue": {
                "fragments": [],
                "text": "Alvey Vision Conference"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "A first family of methods aims at quantifying the presence of a boundary at a given image location through local measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 723210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b02f474196fb9bd61fa3d418a7ba8ac500e8d422",
            "isKey": false,
            "numCitedBy": 2940,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of \u03b3-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure.Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation.In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments."
            },
            "slug": "Feature-Detection-with-Automatic-Scale-Selection-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Feature Detection with Automatic Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation and how it can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2955375"
                        ],
                        "name": "L. Williams",
                        "slug": "L.-Williams",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Williams",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "A thinned, real-valued contour image can be obtained from gPb by considering the maximal response over orientations at each location and applying non-maximum suppression [3, 12]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12429143,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0fd62892dc5919d48ed03e7874bab66fb9d7e5ca",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an algorithm and representation-level theory of illusory contour shape and salience. Unlike previous theories, our model is derived from a single assumption: that the prior probability distribution of boundary completion shape can be modeled by a random walk in a lattice whose points are positions and orientations in the image plane (i.e., the space that one can reasonably assume is represented by neurons of the mammalian visual cortex). Our model does not employ numerical relaxation or other explicit minimization, but instead relies on the fact that the probability that a particle following a random walk will pass through a given position and orientation on a path joining two boundary fragments can be computed directly as the product of two vector-field convolutions. We show that for the random walk we define, the maximum likelihood paths are curves of least energy, that is, on average, random walks follow paths commonly assumed to model the shape of illusory contours. A computer model is demonstrated on numerous illusory contour stimuli from the literature."
            },
            "slug": "Stochastic-Completion-Fields:-A-Neural-Model-of-and-Williams-Jacobs",
            "title": {
                "fragments": [],
                "text": "Stochastic Completion Fields: A Neural Model of Illusory Contour Shape and Salience"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "An algorithm and representation-level theory of illusory contour shape and salience that relies on the fact that the probability that a particle following a random walk will pass through a given position and orientation on a path joining two boundary fragments can be computed directly as the product of two vector-field convolutions."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "We then reshape each vj in the size of the original image and extract its contours using Gaussian directional derivatives at multiple orientations \u03b8, obtaining an oriented signal sPbvj(x, y, \u03b8)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": false,
            "numCitedBy": 12812,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34261820"
                        ],
                        "name": "Qihui Zhu",
                        "slug": "Qihui-Zhu",
                        "structuredName": {
                            "firstName": "Qihui",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qihui Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145349654"
                        ],
                        "name": "G. Song",
                        "slug": "G.-Song",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Rather, we choose the support of the neighborhood large enough with respect to the support of the boundary operator so that our algorithm may recover from errors in contour detection near a junction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "Note that, by extracting an oriented contour signal from the eigenvectors instead of producing hard segmentations, we eliminate the problem of large uniform regions sometimes being broken up by the Normalized Cuts algorithm."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1297614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0c3b858afcbe291dec3f43149927d31286207e9",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel topological formulation for contour grouping. Our grouping criterion, called untangling cycles, exploits the inherent topological 1D structure of salient contours to extract them from the otherwise 2D image clutter. To define a measure for topological classification robust to clutter and broken edges, we use a graph formulation instead of the standard computational topology. The key insight is that a pronounced ID contour should have a clear ordering of edges, to which all graph edges adhere, and no long range entanglements persist. Finding the contour grouping by optimizing these topological criteria is challenging. We introduce a novel concept of circular embedding to encode this combinatorial task. Our solution leads to computing the dominant complex eigenvectors/eigenvalues of the random walk matrix of the contour grouping graph. We demonstrate major improvements over state-of-the-art approaches on challenging real images."
            },
            "slug": "Untangling-Cycles-for-Contour-Grouping-Zhu-Song",
            "title": {
                "fragments": [],
                "text": "Untangling Cycles for Contour Grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel concept of circular embedding is introduced to encode this combinatorial task that leads to computing the dominant complex eigenvectors/eigenvalues of the random walk matrix of the contour grouping graph."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80271822"
                        ],
                        "name": "J. Shah",
                        "slug": "J.-Shah",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 222243846,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a1067e837c7cbbefb30f8324c1eacb1afde39fc6",
            "isKey": false,
            "numCitedBy": 5156,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This reprint will introduce and study the most basic properties of three new variational problems which are suggested by applications to computer vision. In computer vision, a fundamental problem is to appropriately decompose the domain R of a function g (x,y) of two variables. This problem starts by describing the physical situation which produces images: assume that a three-dimensional world is observed by an eye or camera from some point P and that g1(rho) represents the intensity of the light in this world approaching the point sub 1 from a direction rho. If one has a lens at P focusing this light on a retina or a film-in both cases a plane domain R in which we may introduce coordinates x, y then let g(x,y) be the strength of the light signal striking R at a point with coordinates (x,y); g(x,y) is essentially the same as sub 1 (rho) -possibly after a simple transformation given by the geometry of the imaging syste. The function g(x,y) defined on the plane domain R will be called an image. What sort of function is g? The light reflected off the surfaces Si of various solid objects O sub i visible from P will strike the domain R in various open subsets R sub i. When one object O1 is partially in front of another object O2 as seen from P, but some of object O2 appears as the background to the sides of O1, then the open sets R1 and R2 will have a common boundary (the 'edge' of object O1 in the image defined on R) and one usually expects the image g(x,y) to be discontinuous along this boundary. (JHD)"
            },
            "slug": "Optimal-approximations-by-piecewise-smooth-and-Mumford-Shah",
            "title": {
                "fragments": [],
                "text": "Optimal approximations by piecewise smooth functions and associated variational problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087960"
                        ],
                        "name": "M. Morrone",
                        "slug": "M.-Morrone",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Morrone",
                            "middleNames": [
                                "Concetta"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Morrone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689848"
                        ],
                        "name": "R. Owens",
                        "slug": "R.-Owens",
                        "structuredName": {
                            "firstName": "Robyn",
                            "lastName": "Owens",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Owens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "An example is the Oriented Energy approach [19, 21], in which the filterbank is composed of quadrature pairs of even and odd symmetric filters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10529158,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d29ff76d83d7055e6a8be39ea42ea7e04b21e6b2",
            "isKey": false,
            "numCitedBy": 688,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-detection-from-local-energy-Morrone-Owens",
            "title": {
                "fragments": [],
                "text": "Feature detection from local energy"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000933"
                        ],
                        "name": "David Tolliver",
                        "slug": "David-Tolliver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tolliver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Tolliver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144985503"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Miller",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "Note that, by extracting an oriented contour signal from the eigenvectors instead of producing hard segmentations, we eliminate the problem of large uniform regions sometimes being broken up by the Normalized Cuts algorithm."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16967230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47b0c6b290669e1927e5aa9c11d9e1f8321d8797",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a family of spectral partitioning methods. Edge separators of a graph are produced by iteratively reweighting the edges until the graph disconnects into the prescribed number of components. At each iteration a small number of eigenvectors with small eigenvalue are computed and used to determine the reweighting. In this way spectral rounding directly produces discrete solutions where as current spectral algorithms must map the continuous eigenvectors to discrete solutions by employing a heuristic geometric separator (e.g. k-means). We show that spectral rounding compares favorably to current spectral approximations on the Normalized Cut criterion (NCut). Results are given for natural image segmentation, medical image segmentation, and clustering. A practical version is shown to converge."
            },
            "slug": "Graph-Partitioning-by-Spectral-Rounding:-in-Image-Tolliver-Miller",
            "title": {
                "fragments": [],
                "text": "Graph Partitioning by Spectral Rounding: Applications in Image Segmentation and Clustering"
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750170"
                        ],
                        "name": "R. Galloway",
                        "slug": "R.-Galloway",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Galloway",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Galloway"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31001309"
                        ],
                        "name": "B. McDermott",
                        "slug": "B.-McDermott",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "McDermott",
                            "middleNames": [
                                "A."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. McDermott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4756395"
                        ],
                        "name": "F. Thurstone",
                        "slug": "F.-Thurstone",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Thurstone",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Thurstone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21037374,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "44b741c792167dd19e25d5ab08bdc2dd11b252c8",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A pair of concurrent real-time B-mode image lines has been formed using a parallel processing system. In this system a wideband received echo is partitioned by a frequency diversity process and separate image lines are formed. Due to their differing constituent frequencies, these image lines have decorrelated speckle patterns. Upon averaging these filtered lines, the amount of speckle in the resultant displayed image is reduced. The reduction in image speckle and its accompanying improvement in perceived resolution is accomplished with no sacrifice of temporal resolution or real-time format. The effects of filter separation and filter quality factor (Q) are investigated through statistical analysis of images containing speckle-producing targets. A measurable improvement in image signal-to-noise ratio has been achieved.<<ETX>>"
            },
            "slug": "A-frequency-diversity-process-for-speckle-reduction-Galloway-McDermott",
            "title": {
                "fragments": [],
                "text": "A frequency diversity process for speckle reduction in real-time ultrasonic images"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The effects of filter separation and filter quality factor (Q) are investigated through statistical analysis of images containing speckle-producing targets and a measurable improvement in image signal-to-noise ratio has been achieved."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Ultrasonics, Ferroelectrics and Frequency Control"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684495"
                        ],
                        "name": "U. Feige",
                        "slug": "U.-Feige",
                        "structuredName": {
                            "firstName": "Uriel",
                            "lastName": "Feige",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Feige"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "We then reshape each vj in the size of the original image and extract its contours using Gaussian directional derivatives at multiple orientations \u03b8, obtaining an oriented signal sPbvj(x, y, \u03b8)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12268734,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9de3f1ed6352262b24c63c3dad62e15a3ef5a653",
            "isKey": false,
            "numCitedBy": 2335,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "With every graph (or digraph) one can associate several different matrices. We have already seen the vertex-edge incidence matrix, the Laplacian and the adjacency matrix of a graph. Here we shall concentrate mainly on the adjacency matrix of (undirected) graphs, and also discuss briefly the Laplacian. We shall show that spectral properies (the eigenvalues and eigenvectors) of these matrices provide useful information about the structure of the graph. It turns out that for regular graphs, the information one can deduce from one matrix representation (e.g., the adjacency matrix) is similar to the information one can deduce from other representations (such as the Laplacian). We remark that for nonregular graphs, this is not the case, and the choice of matrix representation may make a significant difference. We shall not elaborate on this issue further, as our main concern here will be either with regular or nearly regular graph. The adjacency matrix of a connected undirected graph is nonnegative, symmetric and irreducible (namely, it cannot be decomposed into two diagonal blocks and two off-diagonal blocks, one of which is all-0). As such, standard results n linear algebra, including the Perron-Frobenius theorem, imply that:"
            },
            "slug": "Spectral-graph-theory-Feige",
            "title": {
                "fragments": [],
                "text": "Spectral graph theory"
            },
            "venue": {
                "fragments": [],
                "text": "Zeta and \ud835\udc3f-functions in Number Theory and\n                    Combinatorics"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9397819"
                        ],
                        "name": "J. Sethian",
                        "slug": "J.-Sethian",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Sethian",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sethian"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "A thinned, real-valued contour image can be obtained from gPb by considering the maximal response over orientations at each location and applying non-maximum suppression [3, 12]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60873075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfdb7324a90b5bc11b5c8b39bff6cfa498587c86",
            "isKey": false,
            "numCitedBy": 4128,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Level-Set-Methods-and-Fast-Marching-Methods-Sethian",
            "title": {
                "fragments": [],
                "text": "Level Set Methods and Fast Marching Methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The central and right panels of Figure 2 show that gPb compares favorably with the leading contour detection techniques evaluated on the BSDS [1, 3, 6, 7, 17, 22, 29, 30]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matlab and octave functions for computer vision and image processing"
            },
            "venue": {
                "fragments": [],
                "text": "Matlab and octave functions for computer vision and image processing"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "A thinned, real-valued contour image can be obtained from gPb by considering the maximal response over orientations at each location and applying non-maximum suppression [3, 12]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimal approximations by piecewise smooth functions and variational problems"
            },
            "venue": {
                "fragments": [],
                "text": "Communications on Pure and Applied Mathematics"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "www.cs.berkeley.edu/projects/vision/grouping/segbench"
            },
            "venue": {
                "fragments": [],
                "text": "www.cs.berkeley.edu/projects/vision/grouping/segbench"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "We then combine linearly the local cues, denoted {Gi}, in a single multiscale oriented signal:\nmPb(x, y, \u03b8) =\n9 \u2211\ni=1\n\u03b1i \u00b7 Gi(x, y, \u03b8) (2)\nIn order to introduce global information, we consider the first k + 1 generalized eigenvectors of the system (1), noted {v0, ...,vk}, where the corresponding\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Owens Feature detection from local energy"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition Letters"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "A first family of methods aims at quantifying the presence of a boundary at a given image location through local measurements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A fast operator for detection and precise localization of distinct corners"
            },
            "venue": {
                "fragments": [],
                "text": "ISPRS"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 9,
            "result": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 33,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Using-contours-to-detect-and-localize-junctions-in-Maire-Arbel\u00e1ez/4bb0f3a570936826401b4d1d322725bec3267dce?sort=total-citations"
}