{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797063"
                        ],
                        "name": "S. Agarwal",
                        "slug": "S.-Agarwal",
                        "structuredName": {
                            "firstName": "Shivani",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "6The improvements in computation time over [29] are mainly due to two factors: a faster method for computing correlations, and the observation that image patches in test images need not be compared to vocabulary parts that are not seen during training."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "The above criterion is more strict than the criterion used in [29], and we have found that it corresponds more closely with human judgement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "8The reason for the lower numbers in Table II compared to [29] is the use of a more rigorous evaluation criterion; see section III-B."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 262977,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d081b80b1850df9b1e382f97a7a244890d6485e",
            "isKey": false,
            "numCitedBy": 638,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach for learning to detect objects in still gray images, that is based on a sparse, part-based representation of objects. A vocabulary of information-rich object parts is automatically constructed from a set of sample images of the object class of interest. Images are then represented using parts from this vocabulary, along with spatial relations observed among them. Based on this representation, a feature-efficient learning algorithm is used to learn to detect instances of the object class. The framework developed can be applied to any object with distinguishable parts in a relatively fixed spatial configuration. We report experiments on images of side views of cars. Our experiments show that the method achieves high detection accuracy on a difficult test set of real-world images, and is highly robust to partial occlusion and background variation.In addition, we discuss and offer solutions to several methodological issues that are significant for the research community to be able to evaluate object detection approaches."
            },
            "slug": "Learning-a-Sparse-Representation-for-Object-Agarwal-Roth",
            "title": {
                "fragments": [],
                "text": "Learning a Sparse Representation for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An approach for learning to detect objects in still gray images, that is based on a sparse, part-based representation of objects, that achieves high detection accuracy on a difficult test set of real-world images, and is highly robust to partial occlusion and background variation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35195550"
                        ],
                        "name": "E. Sali",
                        "slug": "E.-Sali",
                        "structuredName": {
                            "firstName": "Erez",
                            "lastName": "Sali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sali"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398995671"
                        ],
                        "name": "Michel Vidal-Naquet",
                        "slug": "Michel-Vidal-Naquet",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Vidal-Naquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Vidal-Naquet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We identify some important issues in this regard that have not been satisfactorily addressed in previous work, and propose possible solutions to them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12923066,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2809b20aea8d2a15ac655e17b47fd5dfb304aa4c",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The task of visual classification is thce recognition of an object in the image as belonging to a general class of similar objects, such as a face, a car, a dog, and the like. This is a fundamental and natural task for biological visual systems, but it has proven difficult to perform visual classification by artificial computer vision systems. The main reason for this difficulty is the variability of shape within a class: different objects vary widely in appearance, and it is difficult to capture the essential shape features that characterize the members of one category and distinguish them from another, such as dogs from cats. \n \nIn this paper we describe an approach to classification using a fragment-based representation. In this approach, objects within a class are represented in terms of common image fragments that are used as building blocks for representing a large variety of different objects that belong to a common class. The fragments are selected from a training set of images based on a criterion of maximizing the mutual information of the fragments and the class they represent. For the purpose of classification the fragments are also organized into types, where each type is a collection of alternative fragments, such as different hairline or eye regions for face classification. During classification, the algorithm detects fragments of the different types, and then combines the evidence for the detected fragments to reach a final decision. Experiments indicate that it is possible to trade off the complexity of fragments with the complexity of the combination and decision stage, and this tradeoff is discussed. \n \nThe method is different from previous part-based methods in using class-specific object fragments of varying complexity, the method of selecting fragments, and the organization into fragment types. Experimental results of detecting face and car views show that the fragment-based approach can generalize well to a variety of novel image views within a class while maintaining low mis-classification error rates. We briefly discuss relationships between the proposed method and properties of parts of the primate visual system involved in object perception"
            },
            "slug": "A-Fragment-Based-Approach-to-Object-Representation-Ullman-Sali",
            "title": {
                "fragments": [],
                "text": "A Fragment-Based Approach to Object Representation and Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Experimental results of detecting face and car views show that the fragment-based approach can generalize well to a variety of novel image views within a class while maintaining low mis-classification error rates."
            },
            "venue": {
                "fragments": [],
                "text": "IWVF"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2124866301"
                        ],
                        "name": "A. Mohan",
                        "slug": "A.-Mohan",
                        "structuredName": {
                            "firstName": "Anuj",
                            "lastName": "Mohan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mohan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "For an area that is increasingly becoming an active focus of research, it is necessary to have standardized and meaningful methods for evaluating and comparing different approaches."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "A critical evaluation of our approach under the proposed standards is presented."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "We identify some important issues in this regard that have not been satisfactorily addressed in previous work, and propose possible solutions to them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2559322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "448bd4e124175ad358078a7b930ecad994c97812",
            "isKey": false,
            "numCitedBy": 1137,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a general example-based framework for detecting objects in static images by components. The technique is demonstrated by developing a system that locates people in cluttered scenes. The system is structured with four distinct example-based detectors that are trained to separately find the four components of the human body: the head, legs, left arm, and right arm. After ensuring that these components are present in the proper geometric configuration, a second example-based classifier combines the results of the component detectors to classify a pattern as either a \"person\" or a \"nonperson.\" We call this type of hierarchical architecture, in which learning occurs at multiple stages, an adaptive combination of classifiers (ACC). We present results that show that this system performs significantly better than a similar full-body person detector. This suggests that the improvement in performance is due to the component-based approach and the ACC data classification architecture. The algorithm is also more robust than the full-body person detection method in that it is capable of locating partially occluded views of people and people whose body parts have little contrast with the background."
            },
            "slug": "Example-Based-Object-Detection-in-Images-by-Mohan-Papageorgiou",
            "title": {
                "fragments": [],
                "text": "Example-Based Object Detection in Images by Components"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results suggest that the improvement in performance is due to the component-based approach and the ACC data classification architecture, which is capable of locating partially occluded views of people and people whose body parts have little contrast with the background."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145319478"
                        ],
                        "name": "Michael J. Jones",
                        "slug": "Michael-J.-Jones",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jones",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 232
                            }
                        ],
                        "text": "A successful object detection approach must therefore be able to represent images in a manner that renders them invariant to such intraclass variations, but at the same time distinguishes images of the object class from all other images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2715202,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63",
            "isKey": false,
            "numCitedBy": 17882,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the \"integral image\" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a \"cascade\" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection."
            },
            "slug": "Rapid-object-detection-using-a-boosted-cascade-of-Viola-Jones",
            "title": {
                "fragments": [],
                "text": "Rapid object detection using a boosted cascade of simple features"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates and the introduction of a new image representation called the \"integral image\" which allows the features used by the detector to be computed very quickly."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We identify some important issues in this regard that have not been satisfactorily addressed in previous work, and propose possible solutions to them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3011571,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d622d6cb7687f8fb138c24b1e4adfecc4c66af1",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "A learning account for the problem of object recognition is developed within the probably approximately correct (PAC) model of learnability. The key assumption underlying this work is that objects can be recognized (or discriminated) using simple representations in terms of syntactically simple relations over the raw image. Although the potential number of these simple relations could be huge, only a few of them are actually present in each observed image, and a fairly small number of those observed are relevant to discriminating an object. We show that these properties can be exploited to yield an efficient learning approach in terms of sample and computational complexity within the PAC model. No assumptions are needed on the distribution of the observed objects, and the learning performance is quantified relative to its experience. Most important, the success of learning an object representation is naturally tied to the ability to represent it as a function of some intermediate representations extracted from the image. We evaluate this approach in a large-scale experimental study in which the SNoW learning architecture is used to learn representations for the 100 objects in the Columbia Object Image Library. Experimental results exhibit good generalization and robustness properties of the SNoW-based method relative to other approaches. SNoW's recognition rate degrades more gracefully when the training data contains fewer views, and it shows similar behavior in some preliminary experiments with partially occluded objects."
            },
            "slug": "Learning-to-Recognize-Three-Dimensional-Objects-Roth-Yang",
            "title": {
                "fragments": [],
                "text": "Learning to Recognize Three-Dimensional Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work evaluates this approach in a large-scale experimental study in which the SNoW learning architecture is used to learn representations for the 100 objects in the Columbia Object Image Library, exhibiting good generalization and robustness properties of the S noW-based method relative to other approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145030811"
                        ],
                        "name": "C. Papageorgiou",
                        "slug": "C.-Papageorgiou",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Papageorgiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papageorgiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "In this paper, we present an approach for learning to detect objects in images using a sparse, part-based representation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13308232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6c20ed0c3f375f403ab5d750a6e9699d5c3af6a",
            "isKey": false,
            "numCitedBy": 1404,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a general, trainable system for object detection in unconstrained, cluttered scenes. The system derives much of its power from a representation that describes an object class in terms of an overcomplete dictionary of local, oriented, multiscale intensity differences between adjacent regions, efficiently computable as a Haar wavelet transform. This example-based learning approach implicitly derives a model of an object class by training a support vector machine classifier using a large set of positive and negative examples. We present results on face, people, and car detection tasks using the same architecture. In addition, we quantify how the representation affects detection performance by considering several alternate representations including pixels and principal components. We also describe a real-time application of our person detection system as part of a driver assistance system."
            },
            "slug": "A-Trainable-System-for-Object-Detection-Papageorgiou-Poggio",
            "title": {
                "fragments": [],
                "text": "A Trainable System for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A general, trainable system for object detection in unconstrained, cluttered scenes that derives much of its power from a representation that describes an object class in terms of an overcomplete dictionary of local, oriented, multiscale intensity differences between adjacent regions, efficiently computable as a Haar wavelet transform."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110604335"
                        ],
                        "name": "Markus Weber",
                        "slug": "Markus-Weber",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Weber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We identify some important issues in this regard that have not been satisfactorily addressed in previous work, and propose possible solutions to them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8970876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cf1527807ebb16020b04d4166e7ba8d27652302",
            "isKey": false,
            "numCitedBy": 757,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features). The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. The method achieves very good classification results on human faces and rear views of cars."
            },
            "slug": "Unsupervised-Learning-of-Models-for-Recognition-Weber-Welling",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Models for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method to learn object class models from unlabeled and unsegmented cluttered cluttered scenes for the purpose of visual object recognition that achieves very good classification results on human faces and rear views of cars."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4801654"
                        ],
                        "name": "Y. Amit",
                        "slug": "Y.-Amit",
                        "structuredName": {
                            "firstName": "Yali",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Amit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "A successful object detection approach must therefore be able to represent images in a manner that renders them invariant to such intraclass variations, but at the same time distinguishes images of the object class from all other images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7784637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61b2d0383b186c4d634c5f51421cab67c16d90a1",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a computational model for detecting and localizing instances from an object class in static gray-level images. We divide detection into visual selection and final classification, concentrating on the former: drastically reducing the number of candidate regions that require further, usually more intensive, processing, but with a minimum of computation and missed detections. Bottom-up processing is based on local groupings of edge fragments constrained by loose geometrical relationships. They have no a priori semantic or geometric interpretation. The role of training is to select special groupings that are moderately likely at certain places on the object but rare in the background. We show that the statistics in both populations are stable. The candidate regions are those that contain global arrangements of several local groupings. Whereas our model was not conceived to explain brain functions, it does cohere with evidence about the functions of neurons in V1 and V2, such as responses to coarse or incomplete patterns (e.g., illusory contours) and to scale and translation invariance in IT. Finally, the algorithm is applied to face and symbol detection."
            },
            "slug": "A-Computational-Model-for-Visual-Selection-Amit-Geman",
            "title": {
                "fragments": [],
                "text": "A Computational Model for Visual Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The model was not conceived to explain brain functions, but it does cohere with evidence about the functions of neurons in V1 and V2, such as responses to coarse or incomplete patterns and to scale and translation invariance in IT."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082093"
                        ],
                        "name": "M. Tarr",
                        "slug": "M.-Tarr",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tarr",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tarr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423436"
                        ],
                        "name": "Q. Vuong",
                        "slug": "Q.-Vuong",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Vuong",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Vuong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "A secondary focus of this paper is to highlight these issues and to develop rigorous evaluation standards for the object detection problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5427717,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "f8b8b4204a87c263e71e571e411894b0f17e296e",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "Object recognition concerns itself with two questions: What is the form of object representation? and How do observers match object percepts to object representations? Many objects look similar and most contain no single feature that uniquely identifies them. Furthermore, objects are rarely seen under identical viewing conditions: Objects change their size, position, orientation, and relations between parts, viewers move about, and sources of illumination turn on and off or move. Successful object recognition requires generalizing across such changes. Two different approaches to these issues have been adopted. Viewpoint-invariant theories assume that there are specific invariant cues to object identity that may be recovered under almost all viewing conditions. Viewpoint-dependent theories suggest that no such general invariants exist and that object features are represented much as they appeared when originally viewed, thereby preserving shape information and surface appearance. Despite many differences, theories of object recognition include some common principles. These include the decomposition of an image into component features, the coding of the spatial relations between such features, multiple views to represent feature sets arising from different object viewpoints, generalization mechanisms to normalize over changes in viewing conditions, and the flexibility to support recognition tasks ranging from item-specific individuation to basic-level categorization. \n \n \nKeywords: \n \nframes of reference; \nimage normalization; \nimage-based models; \nstructural description models; \nviewpoint-dependent recognition; \nviewpoint-invariant recognition"
            },
            "slug": "Visual-object-recognition-Tarr-Vuong",
            "title": {
                "fragments": [],
                "text": "Visual Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "On the learning side, methods for classifying the feature space have ranged from simple nearest-neighbor schemes to more complex approaches such as neural networks [8], convolutional neural networks [17], probabilistic methods [11], [18], and linear or higher degree polynomial classifiers [13], [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37392765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a5ea367f0fb05805acaa84a402f5d036eea37dc",
            "isKey": false,
            "numCitedBy": 744,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Finding an appropriate set of features is an essential problem in the design of shape recognition systems. This paper attempts to show that for recognizing simple objects with high shape variability such as handwritten characters, it is possible, and even advantageous, to feed the system directly with minimally processed images and to rely on learning to extract the right set of features. Convolutional Neural Networks are shown to be particularly well suited to this task. We also show that these networks can be used to recognize multiple objects without requiring explicit segmentation of the objects from their surrounding. The second part of the paper presents the Graph Transformer Network model which extends the applicability of gradient-based learning to systems that use graphs to represents features, objects, and their combinations."
            },
            "slug": "Object-Recognition-with-Gradient-Based-Learning-LeCun-Haffner",
            "title": {
                "fragments": [],
                "text": "Object Recognition with Gradient-Based Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper attempts to show that for recognizing simple objects with high shape variability such as handwritten characters, it is possible, and even advantageous, to feed the system directly with minimally processed images and to rely on learning to extract the right set of features."
            },
            "venue": {
                "fragments": [],
                "text": "Shape, Contour and Grouping in Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 122
                            }
                        ],
                        "text": "A secondary focus of this paper is to highlight these issues and to develop rigorous evaluation standards for the object detection problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8054340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b37258659bcdbc380b1e6c4e22cce9ea06397a1",
            "isKey": false,
            "numCitedBy": 5632,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into an arrangement of simple geometric components, such as blocks, cylinders, wedges, and cones. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of generalized-cone components, called geons (N \u00a3 36), can be derived from contrasts of five readily detectable properties of edges in a two-dimensiona l image: curvature, collinearity, symmetry, parallelism, and cotermination. The detection of these properties is generally invariant over viewing position an$ image quality and consequently allows robust object perception when the image is projected from a novel viewpoint or is degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition: The constraints toward regularization (Pragnanz) characterize not the complete object but the object's components. Representational power derives from an allowance of free combinations of the geons. A Principle of Componential Recovery can account for the major phenomena of object recognition: If an arrangement of two or three geons can be recovered from the input, objects can be quickly recognized even when they are occluded, novel, rotated in depth, or extensively degraded. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory. Any single object can project an infinity of image configurations to the retina. The orientation of the object to the viewer can vary continuously, each giving rise to a different two-dimensional projection. The object can be occluded by other objects or texture fields, as when viewed behind foliage. The object need not be presented as a full-colored textured image but instead can be a simplified line drawing. Moreover, the object can even be missing some of its parts or be a novel exemplar of its particular category. But it is only with rare exceptions that an image fails to be rapidly and readily classified, either as an instance of a familiar object category or as an instance that cannot be so classified (itself a form of classification)."
            },
            "slug": "Recognition-by-components:-a-theory-of-human-image-Biederman",
            "title": {
                "fragments": [],
                "text": "Recognition-by-components: a theory of human image understanding."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Recognition-by-components (RBC) provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "The approach can be applied to any object with distinguishable parts in a relatively fixed spatial configuration; it is evaluated here on difficult sets of real-world images containing side views of cars, and is seen to successfully detect objects in varying conditions amidst background clutter and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 142949003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b95bb08703c92d3429865cdc4b8a0910e4ed7059",
            "isKey": false,
            "numCitedBy": 410,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Object recognition: shape-based recognition what is recognition? why object recognition is difficult. Approaches to object recognition: invariant properties and feature spaces parts and structural descriptions the alignment approach which is the correct approach?. The alignment of pictorial descriptions: using corresponding features the use of multiple models for 3-D objects aligning pictorial descriptions transforming the image or the models? before and after alignment. The alignment of smooth bounding contours: the curvate method accuracy of the curvature method empirical testing. Recognition by the combination of views: modelling objects by view combinations objects with sharp edges using two views only using a single view the use of depth values summary of the basic scheme objects with smooth boundaries recognition by image combinations extensions to the view-combination scheme psychophysical and physiological evidence interim conclusions: recognition by multiple views. Classifications: classification and identification the role of object classification class-based processing using class prototypes pictorial classification evidence from psychology and biology are classes in the world or in our head? the organization of recognition memory. Image and model correspondence: feature correspondence contour matching correspondence-less methods correspondence processes in human vision model construction compensating for illumination changes. Segmentation and saliency: is segmentation feasible? bottom-up and top-down segmentation extracting globally salient structures saliency, selection, and completion what can bottom-up segmentation achieve? Visual cognition and visual routines: perceiving \"inside\" and \"outside\" spatial analysis by visual routines conclusions and open problems the elemental operations the assembly and storage of routines routines and recognition. Sequence seeking and counter streams - a model for visual cortex: the sequence-seeking scheme biological embodiment summary. Appendices: alignment by feature the curvature method errors of the curvature method locally affine matching definitions."
            },
            "slug": "High-Level-Vision:-Object-Recognition-and-Visual-Ullman",
            "title": {
                "fragments": [],
                "text": "High-Level Vision: Object Recognition and Visual Cognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "A successful object detection approach must therefore be able to represent images in a manner that renders them invariant to such intraclass variations, but at the same time distinguishes images of the object class from all other images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9242811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e49ad8354bdd2fd6e8babd348df9e9a5b30bf3a6",
            "isKey": false,
            "numCitedBy": 461,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for a unimodal distributions) and a multivariate Mixture-of-Gaussians model (for multimodal distributions). These probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition. This learning technique is tested in experiments with modeling and subsequent detection of human faces and non-rigid objects such as hands.<<ETX>>"
            },
            "slug": "Probabilistic-visual-learning-for-object-detection-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic visual learning for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "An unsupervised technique for visual learning which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and a multivariate Mixture-of-Gaussians model is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783224"
                        ],
                        "name": "A. Colmenarez",
                        "slug": "A.-Colmenarez",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Colmenarez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Colmenarez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "A successful object detection approach must therefore be able to represent images in a manner that renders them invariant to such intraclass variations, but at the same time distinguishes images of the object class from all other images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9192390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e744c3eef4fbc4ac52b2458eb2d545a4432bcb86",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a visual learning technique that maximizes the discrimination between positive and negative examples in a training set. We demonstrate our technique in the context of face detection with complex background without color or motion information, which has proven to be a challenging problem. We use a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics. Then, we convert the learning process into an optimization, selecting the Markov process that optimizes the information-based discrimination between the two classes. The detection process is carried out by computing the likelihood ratio using the probability model obtained from the learning procedure. We show that because of the discrete nature of these models, the detection process is at least two orders of magnitude less computationally expensive than neural network approaches. However, no improvement in terms of correct-answer/false-alarm tradeoff is achieved."
            },
            "slug": "Face-detection-with-information-based-maximum-Colmenarez-Huang",
            "title": {
                "fragments": [],
                "text": "Face detection with information-based maximum discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A visual learning technique that maximizes the discrimination between positive and negative examples in a training set by using a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 179
                            }
                        ],
                        "text": "Part-based representations for object detection form the basis for a number of theories of biological vision [2], [3], [4], [5], and have also been shown to offer advantages in computational approaches [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12209481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3565c5a65842f26091578b9d71d496cc1561239d",
            "isKey": false,
            "numCitedBy": 1292,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints."
            },
            "slug": "A-statistical-method-for-3D-object-detection-to-and-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "A statistical method for 3D object detection applied to faces and cars"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Using this method, this work has developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithms thatCan reliably detect passenger cars over a wide range of viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237406"
                        ],
                        "name": "N. Ahuja",
                        "slug": "N.-Ahuja",
                        "structuredName": {
                            "firstName": "Narendra",
                            "lastName": "Ahuja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahuja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 207
                            }
                        ],
                        "text": "A successful object detection approach must therefore be able to represent images in a manner that renders them invariant to such intraclass variations, but at the same time distinguishes images of the object class from all other images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We identify some important issues in this regard that have not been satisfactorily addressed in previous work, and propose possible solutions to them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1709452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23234a0f211a44d9706b2570d474427b8f899ec1",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel learning approach for human face detection using a network of linear units is presented. The SNoW learning architecture is a sparse network of linear functions over a pre-defined or incrementally learned feature space and is specifically tailored for learning in the presence of a very large number of features. A wide range of face images in different poses, with different expressions and under different lighting conditions are used as a training set to capture the variations of human faces. Experimental results on commonly used benchmark data sets of a wide range of face images show that the SNoW-based approach outperforms methods that use neural networks, Bayesian methods, support vector machines and others. Furthermore, learning and evaluation using the SNoW-based method are significantly more efficient than with other methods."
            },
            "slug": "A-SNoW-Based-Face-Detector-Yang-Roth",
            "title": {
                "fragments": [],
                "text": "A SNoW-Based Face Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results on commonly used benchmark data sets of a wide range of face images show that the SNoW-based approach outperforms methods that use neural networks, Bayesian methods, support vector machines and others."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "A successful object detection approach must therefore be able to represent images in a manner that renders them invariant to such intraclass variations, but at the same time distinguishes images of the object class from all other images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14954,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398995671"
                        ],
                        "name": "Michel Vidal-Naquet",
                        "slug": "Michel-Vidal-Naquet",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Vidal-Naquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michel Vidal-Naquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35195550"
                        ],
                        "name": "E. Sali",
                        "slug": "E.-Sali",
                        "structuredName": {
                            "firstName": "Erez",
                            "lastName": "Sali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sali"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We identify some important issues in this regard that have not been satisfactorily addressed in previous work, and propose possible solutions to them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205441432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d52be22dc0033293d335b6dc5cf3e3588c1fc0bc",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system analyzes shapes and objects in a series of stages in which stimulus features of increasing complexity are extracted and analyzed. The first stages use simple local features, and the image is subsequently represented in terms of larger and more complex features. These include features of intermediate complexity and partial object views. The nature and use of these higher-order representations remains an open question in the study of visual processing by the primate cortex. Here we show that intermediate complexity (IC) features are optimal for the basic visual task of classification. Moderately complex features are more informative for classification than very simple or very complex ones, and so they emerge naturally by the simple coding principle of information maximization with respect to a class of images. Our findings suggest a specific role for IC features in visual processing and a principle for their extraction."
            },
            "slug": "Visual-features-of-intermediate-complexity-and-use-Ullman-Vidal-Naquet",
            "title": {
                "fragments": [],
                "text": "Visual features of intermediate complexity and their use in classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that intermediate complexity (IC) features are optimal for the basic visual task of classification and suggest a specific role for IC features in visual processing and a principle for their extraction."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "They have been used in a variety of problems in computer vision, including stereo matching [23], object recognition, and image retrieval [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": false,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "advantage of this sparseness property, we train our classifier using the Sparse Network of Winnows (SNoW) learning architecture [26], [27], which is especially wellsuited for such sparse feature representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ed17a1114e2dc48597ab17cc8d5234006f525c9",
            "isKey": false,
            "numCitedBy": 222,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze a few of the commonly used statistics based and machine learning algorithms for natural language disambiguation tasks and observe that they can be recast as learning linear separators in the feature space. Each of the methods makes a priori assumptions which it employs, given the data, when searching for its hypothesis. Nevertheless, as we show, it searches a space that is as rich as the space of all linear separators. We use this to build an argument for a data driven approach which merely searches for a good linear separator in the feature space, without further assumptions on the domain or a specific problem.We present such an approach - a sparse network of linear separators, utilizing the Winnow learning algorithm - and show how to use it in a variety of ambiguity resolution problems. The learning approach presented is attribute-efficient and, therefore, appropriate for domains having very large number of attributes.In particular, we present an extensive experimental comparison of our approach with other methods on several well studied lexical disambiguation tasks such as context-sensitive spelling correction, prepositional phrase attachment and part of speech tagging. In all cases we show that our approach either outperforms other methods tried for these tasks or performs comparably to the best."
            },
            "slug": "Learning-to-Resolve-Natural-Language-Ambiguities:-A-Roth",
            "title": {
                "fragments": [],
                "text": "Learning to Resolve Natural Language Ambiguities: A Unified Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An extensive experimental comparison of the approach with other methods on several well studied lexical disambiguation tasks such as context-sensitive spelling correction, prepositional phrase attachment and part of speech tagging shows that it outperforms other methods tried for these tasks or performs comparably to the best."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1604429801"
                        ],
                        "name": "Robert M. Haralock",
                        "slug": "Robert-M.-Haralock",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralock",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert M. Haralock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809809"
                        ],
                        "name": "L. Shapiro",
                        "slug": "L.-Shapiro",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Shapiro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We apply the F\u00a8orstner interest operator [ 25 ], [21] to a set of representative images of the object class; this detects intersection points of lines and centers of circular patterns."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61087042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9eaaecf23f3a4b7822e4bcca924e02cd5b4dc4e",
            "isKey": false,
            "numCitedBy": 3344,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach. The discussion in \"Volume I\" focuses on image in, and image out or feature set out. \"Volume II\" covers the higher level techniques of illumination, perspective projection, analytical photogrammetry, motion, image matching, consistent labeling, model matching, and knowledge-based vision systems."
            },
            "slug": "Computer-and-Robot-Vision-Haralock-Shapiro",
            "title": {
                "fragments": [],
                "text": "Computer and Robot Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This two-volume set is an authoritative, comprehensive, modern work on computer vision that covers all of the different areas of vision with a balanced and unified approach."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781874"
                        ],
                        "name": "E. Osuna",
                        "slug": "E.-Osuna",
                        "structuredName": {
                            "firstName": "Edgar",
                            "lastName": "Osuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Osuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771659"
                        ],
                        "name": "R. Freund",
                        "slug": "R.-Freund",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Freund",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "A successful object detection approach must therefore be able to represent images in a manner that renders them invariant to such intraclass variations, but at the same time distinguishes images of the object class from all other images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2845602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9008cdacbdcff8a218a6928e94fe7c6dfc237b24",
            "isKey": false,
            "numCitedBy": 2841,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the application of Support Vector Machines (SVMs) in computer vision. SVM is a learning technique developed by V. Vapnik and his team (AT&T Bell Labs., 1985) that can be seen as a new method for training polynomial, neural network, or Radial Basis Functions classifiers. The decision surfaces are found by solving a linearly constrained quadratic programming problem. This optimization problem is challenging because the quadratic form is completely dense and the memory requirements grow with the square of the number of data points. We present a decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of optimality conditions which are used both to generate improved iterative values, and also establish the stopping criteria for the algorithm. We present experimental results of our implementation of SVM, and demonstrate the feasibility of our approach on a face detection problem that involves a data set of 50,000 data points."
            },
            "slug": "Training-support-vector-machines:-an-application-to-Osuna-Freund",
            "title": {
                "fragments": [],
                "text": "Training support vector machines: an application to face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A decomposition algorithm that guarantees global optimality, and can be used to train SVM's over very large data sets is presented, and the feasibility of the approach on a face detection problem that involves a data set of 50,000 data points is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "A successful object detection approach must therefore be able to represent images in a manner that renders them invariant to such intraclass variations, but at the same time distinguishes images of the object class from all other images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2359839"
                        ],
                        "name": "S. Palmer",
                        "slug": "S.-Palmer",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Palmer",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Palmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": "A secondary focus of this paper is to highlight these issues and to develop rigorous evaluation standards for the object detection problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54296649,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "e2eef466573de571ad5621e4780dc0a465b9a253",
            "isKey": false,
            "numCitedBy": 654,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hierarchical-structure-in-perceptual-representation-Palmer",
            "title": {
                "fragments": [],
                "text": "Hierarchical structure in perceptual representation"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47063975"
                        ],
                        "name": "E. Wachsmuth",
                        "slug": "E.-Wachsmuth",
                        "structuredName": {
                            "firstName": "Elisabeth",
                            "lastName": "Wachsmuth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Wachsmuth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808846"
                        ],
                        "name": "M. Oram",
                        "slug": "M.-Oram",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Oram",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695074"
                        ],
                        "name": "D. Perrett",
                        "slug": "D.-Perrett",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Perrett",
                            "middleNames": [
                                "Ian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Perrett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 137
                            }
                        ],
                        "text": "A secondary focus of this paper is to highlight these issues and to develop rigorous evaluation standards for the object detection problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8156691,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "cd5a48558380c81f29ba9de6b64b561aed0657b5",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigated the role that different component parts play in the neural encoding of the visual appearance of one complex object in the temporal cortex. Cells responsive to the sight of the entire human body (but no to control stimuli) were tested with two subregions (head alone with the body occluded from sight and the body alone with the head occluded). Forty-two percent (22 of 53) of cells responded to the whole body and to one of the two body regions tested separately: 72% (17 of 22) responding to the head and 28% (5 of 22) to the rest of the body. Forty-two percent (22 of 53) of cells responded independently to both regions of the body when tested in isolation. The remaining cells (17%, 9 of 53) were selective for the entire body and unresponsive to component parts. The majority of cells tested (90%, 35 of 39) were selective for perspective view (e.g., some cells respond optimally to the side view of the body, others to the back view). Comparable levels of view sensitivity were found for responses to the whole body and its parts. Results indicate (1) separate neuronal analysis of body parts and (2) extensive integration of information from different parts. Contrary to influential models of object recognition (Marr and Nishihara, 1978; Biederman, 1987), the results indicate view-specific processing both for the appearance of separate object components and for integration of information across components."
            },
            "slug": "Recognition-of-objects-and-their-component-parts:-Wachsmuth-Oram",
            "title": {
                "fragments": [],
                "text": "Recognition of objects and their component parts: responses of single units in the temporal cortex of the macaque."
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Contrary to influential models of object recognition, the results indicate view-specific processing both for the appearance of separate object components and for integration of information across components."
            },
            "venue": {
                "fragments": [],
                "text": "Cerebral cortex"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "SNoW learns a linear function over the feature space using a variation of the feature-efficient Winnow learning algorithm [28]; it allows input vectors to specify only active features, and as is the case for Winnow, its sample complexity grows linearly with the number of relevant features and only logarithmically with the total number of potential features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6334230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1dace286582d91916fe470d08f30381cf453f20",
            "isKey": false,
            "numCitedBy": 1612,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant (1984) and others have studied the problem of learning various classes of Boolean functions from examples. Here we discuss incremental learning of these functions. We consider a setting in which the learner responds to each example according to a current hypothesis. Then the learner updates the hypothesis, if necessary, based on the correct classification of the example. One natural measure of the quality of learning in this setting is the number of mistakes the learner makes. For suitable classes of functions, learning algorithms are available that make a bounded number of mistakes, with the bound independent of the number of examples seen by the learner. We present one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions. The basic method can be expressed as a linear-threshold algorithm. A primary advantage of this algorithm is that the number of mistakes grows only logarithmically with the number of irrelevant attributes in the examples. At the same time, the algorithm is computationally efficient in both time and space."
            },
            "slug": "Learning-Quickly-When-Irrelevant-Attributes-Abound:-Littlestone",
            "title": {
                "fragments": [],
                "text": "Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions."
            },
            "venue": {
                "fragments": [],
                "text": "28th Annual Symposium on Foundations of Computer Science (sfcs 1987)"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72629875"
                        ],
                        "name": "Hans P. Morevec",
                        "slug": "Hans-P.-Morevec",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Morevec",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hans P. Morevec"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "They have been used in a variety of problems in computer vision, including stereo matching [23], object recognition, and image retrieval [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62213506,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "272a80e9c8039489a235236ac0cea3beeeb6734b",
            "isKey": false,
            "numCitedBy": 662,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This report describes ongoing research on a working system which drives a vehicle through cluttered environments under computer control, guided by images perceived through an onboard television camera. The emphasis is on reliable and fast low level visual techniques which determine the existence and location of objects in the world, but do not identify them"
            },
            "slug": "Towards-automatic-visual-obstacle-avoidance-Morevec",
            "title": {
                "fragments": [],
                "text": "Towards automatic visual obstacle avoidance"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report describes ongoing research on a working system which drives a vehicle through cluttered environments under computer control, guided by images perceived through an onboard television camera."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI 1977"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066894"
                        ],
                        "name": "Hans P. Moravec",
                        "slug": "Hans-P.-Moravec",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Moravec",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hans P. Moravec"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "They have been used in a variety of problems in computer vision, including stereo matching [23], object recognition, and image retrieval [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15630760,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "3b4a713d67a0a4f7099bdc40d818311b8827b8b7",
            "isKey": false,
            "numCitedBy": 738,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This report describes ongoing research on a working system which drives a vehicle through cluttered environments under computer control, guided by images perceived through an onboard television camera. The emphasis is on reliable and fast low level visual techniques which determine the existence and location of objects in the world, but do not identify them"
            },
            "slug": "Towards-Automatic-Visual-Obstacle-Avoidance-Moravec",
            "title": {
                "fragments": [],
                "text": "Towards Automatic Visual Obstacle Avoidance"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This report describes ongoing research on a working system which drives a vehicle through cluttered environments under computer control, guided by images perceived through an onboard television camera."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 164
                            }
                        ],
                        "text": "On the learning side, methods for classifying the feature space have ranged from simple nearest neighbor schemes to more complex approaches such as neural networks [8], convolutional neural networks [17], probabilistic methods [11], [18] and linear or higher degree polynomial classifiers [13], [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "The system in [8] uses the very property of multiple detections to its advantage, taking the number of detections in a small neighborhood as a measure of the detector\u2019s confidence in the presence of an object within the neighborhood; if a high confidence is obtained, the multiple detections are collapsed into a single detection located at the centroid of the original detections."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "In addition, our approach offers a more systematic method for dealing with overlaps; like [14], [8] also uses a zero-overlap strategy, which is too restrictive for general object classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "Image features used in learning-based approaches to object detection have included raw pixel intensities [7], [8], [9], features obtained via global image transformations [10], [11], and local features such as edge fragments [12], [13], rectangle features [14], Gabor filter based representations [15] and wavelet features [16]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 170
                            }
                        ],
                        "text": "Note that our training set is relatively small and all images in our data set are natural; we do not use any synthetic training images, as has been done, for example, in [8], [13], [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural networkbased face detection"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 20, no. 1, pp. 23\u201338, 1998."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "In this paper, we present an approach for learning to detect objects in images using a sparse, part-based representation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Gabor-Based Features for Face Detection"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. World Congress in Neural Networks, Int'l Neural Network Soc"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Below, we describe each of these stages in detail."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer and Robot Vision II"
            },
            "venue": {
                "fragments": [],
                "text": "Computer and Robot Vision II"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "advantage of this sparseness property, we train our classifier using the Sparse Network of Winnows (SNoW) learning architecture [26], [27], which is especially wellsuited for such sparse feature representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The SNoW Learning Architecture"
            },
            "venue": {
                "fragments": [],
                "text": "The SNoW Learning Architecture"
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 24,
            "methodology": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 32,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-to-detect-objects-in-images-via-a-sparse,-Agarwal-Awan/b82d251ed367593366680acebc81fdb070b04a18?sort=total-citations"
}