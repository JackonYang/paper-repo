{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727567"
                        ],
                        "name": "R. Solomonoff",
                        "slug": "R.-Solomonoff",
                        "structuredName": {
                            "firstName": "Ray",
                            "lastName": "Solomonoff",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Solomonoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1898103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bef2ae523cd4447af687fae13bfbb606e4a4a5ca",
            "isKey": false,
            "numCitedBy": 1585,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Formal-Theory-of-Inductive-Inference.-Part-II-Solomonoff",
            "title": {
                "fragments": [],
                "text": "A Formal Theory of Inductive Inference. Part II"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2762877"
                        ],
                        "name": "A. Zvonkin",
                        "slug": "A.-Zvonkin",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Zvonkin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zvonkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27941605"
                        ],
                        "name": "L. Levin",
                        "slug": "L.-Levin",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Levin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Levin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16016127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e8681658fae750c14be7a58e6e284ecdad83b9",
            "isKey": false,
            "numCitedBy": 662,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "In 1964 Kolmogorov introduced the concept of the complexity of a finite object (for instance, the words in a certain alphabet). He defined complexity as the minimum number of binary signs containing all the information about a given object that are sufficient for its recovery (decoding). This definition depends essentially on the method of decoding. However, by means of the general theory of algorithms, Kolmogorov was able to give an invariant (universal) definition of complexity. Related concepts were investigated by Solomonoff (U.S.A.) and Markov. Using the concept of complexity, Kolmogorov gave definitions of the quantity of information in finite objects and of the concept of a random sequence (which was then defined more precisely by Martin-Lof). Afterwards, this circle of questions developed rapidly. In particular, an interesting development took place of the ideas of Markov on the application of the concept of complexity to the study of quantitative questions in the theory of algorithms. The present article is a survey of the fundamental results connected with the brief remarks above."
            },
            "slug": "THE-COMPLEXITY-OF-FINITE-OBJECTS-AND-THE-OF-THE-OF-Zvonkin-Levin",
            "title": {
                "fragments": [],
                "text": "THE COMPLEXITY OF FINITE OBJECTS AND THE DEVELOPMENT OF THE CONCEPTS OF INFORMATION AND RANDOMNESS BY MEANS OF THE THEORY OF ALGORITHMS"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The present article is a survey of the fundamental results connected with the concept of complexity as the minimum number of binary signs containing all the information about a given object that are sufficient for its recovery (decoding)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84317115"
                        ],
                        "name": "B. Kurtz",
                        "slug": "B.-Kurtz",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Kurtz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kurtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710805"
                        ],
                        "name": "P. Caines",
                        "slug": "P.-Caines",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Caines",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Caines"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 25548654,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "a5572ca3779e7b191de1cac9d6290b21204c64cc",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Consider a siscrete time system or process with i.i.d. outputs, X1,X2,... The distribution of Xi's is characterized by some unknown parameter, \u00bf which is an element of \u00bf, a subset of Z+, the positive integers. We propose to identify the parameter \u00bf with an automaton which is realized by the following algorithm: The Xi's are observed sequentially. At instant i, a current best estimate (CBE) of \u00bf\u00bf\u00bf is generated, based on Xi alone. The best estimate to date (BED) of \u00bf, at any instant, will be the particular element of \u00bf which was previously the CBE of \u00bf for the greatest number of consecutive instants. In the implementation of the algorithm, the state of te automaton will consist of the following four elements: the best estimate to date; the maximum number of consecutive times that this BED was the CBE of \u00bf; the current best estimate of \u00bf based on the latest value of Xi (= candidate for BED); and the number of consecutive times to date that this value has been the CBE of \u00bf. It is shown that the BED converges strongly to the correct parameter. The following three specific applications are discussed: 1) Identification of the most probable value of a single sample from a set of discrete i.i.d. random variables. 2) Identification of the parameter of an observed sequence of i.i.d. Bernoulli random variables. 3) Identification of the parameters of a moving average process. (Notice that the observations of the system output in this case are not i.i.d.). The rate of convergence of the algorithm is shown to exceed that of other proposed recursive algorithms [1] for parameter identification. Furthermore, the amount of memory required is shown to grow as log log i, a rate significantly slower than that required by other algorithms. It is also shown that for a very large class of systems, convergence of parameter estimates is impossible without acess to an unbounded memory."
            },
            "slug": "A-new-algorithm-for-the-recursive-identification-of-Kurtz-Caines",
            "title": {
                "fragments": [],
                "text": "A new algorithm for the recursive identification of stochastic systems using an automaton with slowly growing memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that the BED converges strongly to the correct parameter and for a very large class of systems, convergence of parameter estimates is impossible without acess to an unbounded memory."
            },
            "venue": {
                "fragments": [],
                "text": "1976 IEEE Conference on Decision and Control including the 15th Symposium on Adaptive Processes"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29613361"
                        ],
                        "name": "D. G. Willis",
                        "slug": "D.-G.-Willis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Willis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G. Willis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 117
                            }
                        ],
                        "text": "In addiTherefore tion to developing many of the concepts upon which the\n-ii1 \u2018txitn)> k PLf(xi(n>)\npaper is based, D. Willis has been helpful in his discussion of the definition of H* and the implied properties of Ph."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 27
                            }
                        ],
                        "text": "The ratio of the geometric\nWillis [2, p. 256, Th. 171 has shown that if P is any cpm, yield per bet of Ph to that of P is 2-k/\u201c."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 16
                            }
                        ],
                        "text": "(3)\nThe work of Willis (2), however, suggested a rigorous interpretation of (1) that made it possible to demonstrate the convergence of these sums and other important properties."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 163
                            }
                        ],
                        "text": "Since the measure PA is not effectively computable, for practical induction it is necessary to use computable approximations, such as those investigated by Willis [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Willis\u2019 measure is defined by the equation\nPR(~(,.,))= 2 2-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 62
                            }
                        ],
                        "text": "The term computable probability measure (cpm) will be used in Willis\u2019 sense [2, pp. 249-2511."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 24
                            }
                        ],
                        "text": "It can be obtained from Willis\u2019 measure by using Mr. and letting T approach infinity:\nTheorem I: The limit in (5) exists."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 10
                            }
                        ],
                        "text": "[2] D. G. Willis, \u201cComputational complexity and probability constructions,\u201d J. Ass."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 13
                            }
                        ],
                        "text": "Paraphrasing Willis, we say a probability measure P on finite strings is computable if it satisfies (2) and (3) and there exists a UIO machine with the following properties: a) it has two input symbols (0 and 1) and a special input punctuation symbol, b (blank); b) when the input to the machine is x(n)b, its output is the successive bits of a binary expansion of P(x(n))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Willis avoids the computability difficulties by defining a set of measures based on specially limited machines that have no \u201chalting problem.\u201d"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 45
                            }
                        ],
                        "text": "Sections II and III show the relationship of Willis\u2019 work on computable probability measures and the machines associated with them to the incomputable measure Ph and its associated universal machine."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 10
                            }
                        ],
                        "text": "Following Willis [2, Section 4, pp. 249-2541 we define\nH*(x) k -1g PA(x)\nH*(x,Y) A -k P&,Y>\nH,*(Y) A -k f\u2019.k,x(~)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 61
                            }
                        ],
                        "text": "Our definitions of P,&(x), Ph(x,y), and PAX(v) correspond to Willis\u2019 definitions of PR(x), PR(x,y), and P:(y), respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "Willis regards PR(x(n)) as a measure on the set of all infinite strings that have the common prefix x(n)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 37
                            }
                        ],
                        "text": "Its proof will be similar to that of Willis\u2019 Theorem 16 [2, p. 2561\nProof of Lemma I: From Willis ([2, p. 252, Theorem 121, but also see [4, Lemma of the last Theorem] for a more transparent proof), we note that there constructively exists a FOR R, such that for all x(n)\nPRO(x(n))= x 2-"
                    },
                    "intents": []
                }
            ],
            "corpusId": 7371404,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4b0ac97e4666d4b210cc7362f7fcd3d6947a873",
            "isKey": true,
            "numCitedBy": 47,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "There exist cons t ruc t ive correspondences be tween Tur ing machines hav ing finitely de te rminable behav ior and computable p robab i l i ty measures on thei r o u t p u t sequences. These correspondences de termine l imits on the re la t ive accuracies wi th which different computable p robab i l i ty measures predic t events . Using any universal Tur ing machine as a basis, i t is possible to cons t ruc t an infinite h ie ra rchy of increas ingly accurate computable probabil i ty measures which are independen t of any p robab i l i ty assumpt ions . The re la t ionship of such measures to real events is considered."
            },
            "slug": "Computational-Complexity-and-Probability-Willis",
            "title": {
                "fragments": [],
                "text": "Computational Complexity and Probability Constructions"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Using any universal Tur ing machine as a basis, it is possible to cons t ruc t an infinite number of increas ingly accurate computable probabil i ty measures which are independen t of any p robab i l i ty assumpt ions."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16577978,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "45816c0d862424afe526e3151bef109a545a8183",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A complexity approach is used to decide whether or not the mean of a sequence of independent identically distributed random variables lies in a n arbitrary specified countable subset of the real line. A procedure is described that makes only a finite number of mistakes with probability one. This leads to some speculations on inference of the laws of physics and the computability of the physical constants."
            },
            "slug": "On-Determining-the-Irrationality-of-the-Mean-of-a-Cover",
            "title": {
                "fragments": [],
                "text": "On Determining the Irrationality of the Mean of a Random Variable"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135764"
                        ],
                        "name": "A. Kolmogorov",
                        "slug": "A.-Kolmogorov",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Kolmogorov",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kolmogorov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "Chaitin [3] has defined two kinds of probability measure and two kinds of entropy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 106
                            }
                        ],
                        "text": "Q.E.D.\nCover [5] has devised a probability measure based on Theorem 5: If P is any computable probability\nChaitin\u2019s unconditional entropy HC that is directly COmmeasure and F(n) is any recursive function from integers\nparable to P,& Let us define the measure to integers such that lim ,,, F(n)= o. then there exists a 9 constant k such that for all x(n)\nB*(x(n)) 4 x 2-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 73
                            }
                        ],
                        "text": "Then independently of T we can construct a program for s with respect to Chaitin\u2019s U that is k\u2019 bits longer than r."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 145
                            }
                        ],
                        "text": "The rate of approach is about the same as that of E(HC(X(n)/n))/n and perhaps faster than that of E(H\u2019(x(n)))/n where H\u2019(X(n)/n) and H \u2019 (X (n)) are Chaitin\u2019s conditional and unconditional entropies, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 76
                            }
                        ],
                        "text": "H* is found to satisfy the equation\nH*(w) = H*(x) + H,*(Y)\nexactly, whereas Chaitin\u2019s entropy definition requires a nonvanishing error term."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "Section V deals with Chaitin\u2019s [3] probability measure and entropy definitions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 129
                            }
                        ],
                        "text": "Though H* is close to the H of information theory, certain of its properties differ considerably from those of Kolmogorov\u2019s K and Chaitin\u2019s H\u2019."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "Chaitin [3] has shown that his entropy satisfies"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 67
                            }
                        ],
                        "text": "Section VI discusses Cover\u2019s [5] b*, a probability measure based on Chaitin\u2019s unconditional entropy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 88
                            }
                        ],
                        "text": "Then\nBz(x(n)) > x 2TH;@(\u201c)\u201c) lzj=n\u2019--n\n> 2-kl-k,-m-2 2 21-[-lgP(x(n)\u201c)]\nlzl=n\u2019-n\nwhere Hi is Chaitin\u2019s unconditional entropy with respect to machine C."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11402549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d30f781ab26886f4d19170d31dfd072a297dd312",
            "isKey": true,
            "numCitedBy": 542,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A new logical basis for information theory as well as probability theory is proposed, based on computing complexity."
            },
            "slug": "Logical-basis-for-information-theory-and-theory-Kolmogorov",
            "title": {
                "fragments": [],
                "text": "Logical basis for information theory and probability theory"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A new logical basis for information theory as well as probability theory is proposed, based on computing complexity, according to a new approach to computing complexity."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 7
                            }
                        ],
                        "text": "Q.E.D.\nCover [5] has devised a probability measure based on Theorem 5: If P is any computable probability\nChaitin\u2019s unconditional entropy HC that is directly COmmeasure and F(n) is any recursive function from integers\nparable to P,& Let us define the measure to integers such that lim ,,, F(n)= o. then there exists a 9 constant k such that for all x(n)\nB*(x(n)) 4 x 2-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "LeungYan-Cheong and Cover [4] used a variant of his conditional probability that appears to be very close to P&, but there is some uncertainty about the effect of normalization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 40
                            }
                        ],
                        "text": "P\u2019(s/lsl), however, is comparable to Ph. LeungYan-Cheong and Cover have shown [4, proof of the last theorem] that\nP\u2019(s/lsl) > 2-&P (s) (27) where P is any computable probability measure and k is a constant independent of the string s."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 16
                            }
                        ],
                        "text": "- \u2019 * , [5] T. M. Cover, \u201cUniversal gambling schemes and the complexity measures of Kohnogorov and Chaitin,\u201d Rep. 12, Statistics Dept., Stanford Univ., Stanford, CA, 1974."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 53
                            }
                        ],
                        "text": "Moreover, Koplowitz [7], Kurtz and Caines [I I], and Cover [12] have shown that if one considers only a countable number of hypotheses, the statistical error converges much more rapidly than if the set of hypotheses is uncountable."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 21
                            }
                        ],
                        "text": "Leung-Yan-Cheong and Cover [4, last Theorem] have shown that for any stochastic process definable by a computable probability measure P,\nH,,   E,H\u2019(X(n)/n)   H,, + k (43) where H,, is the entropy of the set of strings of length n:\nHn \u2019 ;!"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 70
                            }
                        ],
                        "text": "One interpretation of Theorem 2 is given by the work of M(v) = K,(x), Cover [5]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 57
                            }
                        ],
                        "text": "To prove this we will exhibit a specific prefix computer Cover defines the conditional probability that the finite C such that (36) holds when Bz is computed with respect string x(n) will be followed by the symbol xn+ i to be to C."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 37
                            }
                        ],
                        "text": "[4] S. K. Leung-Yan-Cheong and T. M. Cover, \u201cSome inequalities [lo] A. N. Kohnogordv, humiztiom of the Theory of Probability."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 28
                            }
                        ],
                        "text": "Similarly, if b* is used in Cover\u2019s gambling scheme, the ratio of its yield to the maximum feasible yield is 2-k-F(n), in which F(n) approaches infinity arbitrarily slowly."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 11
                            }
                        ],
                        "text": "[12] T. M. Cover, \u201cOn the determination of the irrationality of the\n[6] R. J. Solomonoff, \u201cInductive inference research status,\u201d RTB-154; mean of a random variable,\u201d Ann."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 292
                            }
                        ],
                        "text": "If the conditional probabillties of Ph are used to approxhnate those of P, then tbe expected value of the total squared error in these conditional probabilities is bounded by -(l/2) la C. Witb this error criterion, and when used as the basii of a universal gambling scheme, Ph is superior to Cover\u2019s measure b*."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 214
                            }
                        ],
                        "text": "E.D. yield using Ph to that using the best possible information is then P,&(x(n))/P(x(n)), which as we have shown is\nTo obtain the best possible bound on PA/P, we would ) 2-k. like to choose the prefix set so that Cover also shows that if P is used in betting, then for\n?"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 21
                            }
                        ],
                        "text": "Section VI discusses Cover\u2019s [5] b*, a probability measure based on Chaitin\u2019s unconditional entropy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "Cover has shown [5] that if (42) is true then it follows that for an ergodic process\nJ&c i H\u201d(x(n))= H with Pr 1."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Some inequalities [lo] A. N. Kohnogordv, humiztiom of the Theory of Probability. New York: Chelsea. 1950. between Shr&on entropy and Kolmogorov, Chaitin and extension comnlexities"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Reo. Statistics Dem.. Stanford Univ"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "One interpretation of Theorem 2 is given by the work of M(v) = K,(x), Cover [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "Cover [5] has devised a probability measure based on Theorem 5: If P is any computable probability"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 28
                            }
                        ],
                        "text": "Similarly, if b* is used in Cover\u2019s gambling scheme, the ratio of its yield to the maximum feasible yield is 2-k-F(n), in which F(n) approaches infinity arbitrarily slowly."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "Cover has shown [5] that if (42) is true then it follows that for an ergodic process"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 292
                            }
                        ],
                        "text": "If the conditional probabillties of Ph are used to approxhnate those of P, then tbe expected value of the total squared error in these conditional probabilities is bounded by -(l/2) la C. Witb this error criterion, and when used as the basii of a universal gambling scheme, Ph is superior to Cover\u2019s measure b*."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "Section VI discusses Cover\u2019s [5] b*, a probability measure based on Chaitin\u2019s unconditional entropy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The recursive indentification of stochastic systems using an automaton with slowly growing memory"
            },
            "venue": {
                "fragments": [],
                "text": "presented at IEEE Sym. Inform. Theory, Cornell Univ., Oct. 1977. [12] T. M. Cover, \u201cOn the determination of the irrationality of the"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727567"
                        ],
                        "name": "R. Solomonoff",
                        "slug": "R.-Solomonoff",
                        "structuredName": {
                            "firstName": "Ray",
                            "lastName": "Solomonoff",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Solomonoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 41503687,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "40b5e2fa3eaae17886c066c9f107c8c865b4808b",
            "isKey": false,
            "numCitedBy": 1286,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Formal-Theory-of-Inductive-Inference.-Part-I-Solomonoff",
            "title": {
                "fragments": [],
                "text": "A Formal Theory of Inductive Inference. Part I"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756533"
                        ],
                        "name": "G. Chaitin",
                        "slug": "G.-Chaitin",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Chaitin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Chaitin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14133389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "294ee566e35418f9257bb3477dd1502f8751f165",
            "isKey": false,
            "numCitedBy": 921,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "A new definition of program-size complexity is made. H(A,B/C,D) is defined to be the size in bits of the shortest self-delimiting program for calculating strings A and B if one is given a minimal-size self-delimiting program for calculating strings C and D. This differs from previous definitions: (1) programs are required to be self-delimiting, i.e. no program is a prefix of another, and (2) instead of being given C and D directly, one is given a program for calculating them that is minimal in size. Unlike previous definitions, this one has precisely the formal properties of the entropy concept of information theory. For example, H(A,B) = H(A) + H(B/A) -~ 0(1). Also, if a program of length k is assigned measure 2 -k, then H(A) = -log2 (the probability that the standard universal computer will calculate A) -{- 0(1)."
            },
            "slug": "A-Theory-of-Program-Size-Formally-Identical-to-Chaitin",
            "title": {
                "fragments": [],
                "text": "A Theory of Program Size Formally Identical to Information Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new definition of program-size complexity is made, which has precisely the formal properties of the entropy concept of information theory."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In the preceding, we mean (x,x') to represent the sequence of length m+ n obtained by writing first the terms of x, then the terms of x'. Equivalently, R 1 says"
            },
            "venue": {
                "fragments": [],
                "text": "In the preceding, we mean (x,x') to represent the sequence of length m+ n obtained by writing first the terms of x, then the terms of x'. Equivalently, R 1 says"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The complexity of finite objects 77-2"
            },
            "venue": {
                "fragments": [],
                "text": "The complexity of finite objects 77-2"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the determination of the irrationality of the"
            },
            "venue": {
                "fragments": [],
                "text": "On the determination of the irrationality of the"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 7
                            }
                        ],
                        "text": "[7] J. Koplowitz, \u201cOn countably infinite hypothesis testing,\u201d presented [13] T. L. Fine, Personal correspondence.\nat IEEE Sym."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Moreover, Koplowitz [7], Kurtz and Caines [I I], and Cover [12] have shown that if one considers only a countable number of hypotheses, the statistical error converges much more rapidly than if the set of hypotheses is uncountable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Predictability and randomness"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Rep. TR"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The recursive indentification of stochastic systems using an automaton with slowly growing memory"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Sym. Inform. Theory"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "Later [6] is was shown that these models form two equivalence classes: those based on a general universal Turing machine and those based on a universal Turing machine with unidirectional input and output tapes and a bidirectional work tape."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inductive inference research status RTB-154; mean of a random variable"
            },
            "venue": {
                "fragments": [],
                "text": "Ann. Stafis"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Block Coding for an Ergodic Sourtie Relative to a Zero-One Valued Fidelity Criterion JOHN C"
            },
            "venue": {
                "fragments": [],
                "text": "Block Coding for an Ergodic Sourtie Relative to a Zero-One Valued Fidelity Criterion JOHN C"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On countably infinite hypothesis testing"
            },
            "venue": {
                "fragments": [],
                "text": "On countably infinite hypothesis testing"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Universal gambling schemes and the complexity measures of Kohnogorov and Chaitin"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics Dept"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Predictability and randomness"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. Rep"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the algorithmic theory of informationExample given is from the lecture notes of Logical basis for information theory and probability theory"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture, Int. Symp. Inform. Theory J. J. Bussgang. Kolmogorov's paper IEEE Trans. Inform. Theory"
            },
            "year": 1967
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 21,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Complexity-based-induction-systems:-Comparisons-and-Solomonoff/0453028e68581624ec68cfec70214231da8dbce7?sort=total-citations"
}