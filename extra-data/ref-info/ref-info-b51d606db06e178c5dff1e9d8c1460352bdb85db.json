{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984136"
                        ],
                        "name": "A. Agarwal",
                        "slug": "A.-Agarwal",
                        "structuredName": {
                            "firstName": "Ankur",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Tracking is then formulated either as a single fully regressive model or by using the regression estimates in a multiple hypothesis tracker based on Condensation [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 302682,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3845d9e62540b8e2406343f801e026b562299ae0",
            "isKey": false,
            "numCitedBy": 464,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a learning based method for recovering 3D human body pose from single images and monocular image sequences. Our approach requires neither an explicit body model nor prior labelling of body pans in the image. Instead, it recovers pose by direct nonlinear regression against shape descriptor vectors extracted automatically from image silhouettes. For robustness against local silhouette segmentation errors, silhouette shape is encoded by histogram-of-shape-contexts descriptors. For the main regression, we evaluate both regularized least squares and relevance vector machine (RVM) regressors over both linear and kernel bases. The RVM's provide much sparser regressors without compromising performance, and kernel bases give a small but worthwhile improvement in performance. For realism and good generalization with respect to viewpoints, we train the regressors on images resynthesized from real human motion capture data, and test it both quantitatively on similar independent test data, and qualitatively on a real image sequence. Mean angular errors of 6-7 degrees are obtained - a factor of 3 better than the current state of the art for the much simpler upper body problem."
            },
            "slug": "3D-human-pose-from-silhouettes-by-relevance-vector-Agarwal-Triggs",
            "title": {
                "fragments": [],
                "text": "3D human pose from silhouettes by relevance vector regression"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work describes a learning based method for recovering 3D human body pose by direct nonlinear regression against shape descriptor vectors extracted automatically from image silhouettes, and results are a factor of 3 better than the current state of the art for the much simpler upper body problem."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984136"
                        ],
                        "name": "A. Agarwal",
                        "slug": "A.-Agarwal",
                        "structuredName": {
                            "firstName": "Ankur",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Tracking is then formulated either as a single fully regressive model or by using the regression estimates in a multiple hypothesis tracker based on Condensation [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7563707,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "954db9aa9f141ce9719d9ffc76c7677b27d9e45f",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a sparse Bayesian regression method for recovering 3D human body motion directly from silhouettes extracted from monocular video sequences. No detailed body shape model is needed, and realism is ensured by training on real human motion capture data. The tracker estimates 3D body pose by using Relevance Vector Machine regression to combine a learned autoregressive dynamical model with robust shape descriptors extracted automatically from image silhouettes. We studied several different combination methods, the most effective being to learn a nonlinear observation-update correction based on joint regression with respect to the predicted state and the observations. We demonstrate the method on a 54-parameter full body pose model, both quantitatively using motion capture based test sequences, and qualitatively on a test video sequence."
            },
            "slug": "Learning-to-track-3D-human-motion-from-silhouettes-Agarwal-Triggs",
            "title": {
                "fragments": [],
                "text": "Learning to track 3D human motion from silhouettes"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A sparse Bayesian regression method for recovering 3D human body motion directly from silhouettes extracted from monocular video sequences, and demonstrates the method on a 54-parameter full body pose model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[24]) or label-ambiguities (disambiguating the left and right arms/legs)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1842570,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "2d0b50d3df26b64ec5a2f949bc241b4fce515fa9",
            "isKey": false,
            "numCitedBy": 356,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for recovering 3D human body motion from monocular video sequences using robust image matching, joint limits and non-self-intersection constraints, and a new sample-and-refine search strategy guided by rescaled cost-function covariances. Monocular 3D body tracking is challenging: for reliable tracking at least 30 joint parameters need to be estimated, subject to highly nonlinear physical constraints; the problem is chronically ill conditioned as about 1/3 of the d.o.f. (the depth-related ones) are almost unobservable in any given monocular image; and matching an imperfect, highly flexible self-occluding model to cluttered image features is intrinsically hard. To reduce correspondence ambiguities we use a carefully designed robust matching-cost metric that combines robust optical flow, edge energy, and motion boundaries. Even so, the ambiguity, nonlinearity and non-observability make the parameter-space cost surface multi-modal, unpredictable and ill conditioned, so minimizing it is difficult. We discuss the limitations of CONDENSATION-like samplers, and introduce a novel hybrid search algorithm that combines inflated-covariance-scaled sampling and continuous optimization subject to physical constraints. Experiments on some challenging monocular sequences show that robust cost modelling, joint and self-intersection constraints, and informed sampling are all essential for reliable monocular 3D body tracking."
            },
            "slug": "Covariance-scaled-sampling-for-monocular-3D-body-Sminchisescu-Triggs",
            "title": {
                "fragments": [],
                "text": "Covariance scaled sampling for monocular 3D body tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Experiments on some challenging monocular sequences show that robust cost modelling, joint and self-intersection constraints, and informed sampling are all essential for reliable monocular 3D body tracking."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144956884"
                        ],
                        "name": "R\u00f3mer Rosales",
                        "slug": "R\u00f3mer-Rosales",
                        "structuredName": {
                            "firstName": "R\u00f3mer",
                            "lastName": "Rosales",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00f3mer Rosales"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "Our solutions are well-regularized in the sense that the weight vectors ak are damped to control overfitting and sparse in the sense that many of them are zero."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "An important subcase is model-based tracking, which focuses on tracking the pose estimate from one time step to the next starting from a known initialization based on an approximate dynamical model [9], [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12126519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fc6c277261a004b378f2feec3310fa86bc0b91b",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel approach for estimating articulated body posture and motion from monocular video sequences is proposed. Human pose is defined as the instantaneous two dimensional configuration (i.e. the projection onto the image plane) of a single articulated body in terms of the position of a predetermined sets of joints. First, statistical segmentation of the human bodies from the background is performed and low-level visual features are found given the segmented body shape. The goal is to be able to map these generally low level visual features to body configurations. The system estimates different mappings, each one with a specific cluster in the visual feature space. Given a set of body motion sequences for training, unsupervised clustering is obtained via the Expectation Maximization algorithm. For each of the clusters, a function is estimated to build the mapping between low-level features to 2D pose. Given new visual features, a mapping from each cluster is performed to yield a set of possible poses. From this set, the system selects the most likely pose given the learned probability distribution and the visual feature of the proposed approach is characterized using real and artificially generated body postures, showing promising results."
            },
            "slug": "Inferring-body-pose-without-tracking-body-parts-Rosales-Sclaroff",
            "title": {
                "fragments": [],
                "text": "Inferring body pose without tracking body parts"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A novel approach for estimating articulated body posture and motion from monocular video sequences is proposed, characterized using real and artificially generated body postures, showing promising results."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490189"
                        ],
                        "name": "Gregory Shakhnarovich",
                        "slug": "Gregory-Shakhnarovich",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Shakhnarovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Shakhnarovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "In this paper, we take a learning-based approach, but instead of explicitly storing and searching for similar training examples, we use sparse Bayesian nonlinear regression to distill a large training database into a compact model that has good generalization to unseen examples."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8298534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd4a61eae6b7eb2501a53ed05ccb0313d62cb0d8",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an image-based approach to infer 3D structure parameters using a probabilistic \"shape+structure\" model. The 3D shape of an object class is represented by sets of contours from silhouette views simultaneously observed from multiple calibrated cameras, while structural features of interest on the object are denoted by a number of 3D locations. A prior density over the multiview shape and corresponding structure is constructed with a mixture of probabilistic principal components analyzers. Given a novel set of contours, we infer the unknown structure parameters from the new shape's Bayesian reconstruction. Model matching and parameter inference are done entirely in the image domain and require no explicit 3D construction. Our shape model enables accurate estimation of structure despite segmentation errors or missing views in the input silhouettes, and it works even with only a single input view. Using a training set of thousands of pedestrian images generated from a synthetic model, we can accurately infer the 3D locations of 19 joints on the body based on observed silhouette contours from real images."
            },
            "slug": "Inferring-3D-structure-with-a-statistical-shape-Grauman-Shakhnarovich",
            "title": {
                "fragments": [],
                "text": "Inferring 3D structure with a statistical image-based shape model"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The shape model enables accurate estimation of structure despite segmentation errors or missing views in the input silhouettes, and it works even with only a single input view, using a training set of thousands of pedestrian images generated from a synthetic model."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720747"
                        ],
                        "name": "V. Athitsos",
                        "slug": "V.-Athitsos",
                        "structuredName": {
                            "firstName": "Vassilis",
                            "lastName": "Athitsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Athitsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "Index Terms\u2014Computer vision, human motion estimation, machine learning, multivariate regression."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10005005,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b9213651d939b8195b0f4225fe409af6459effb",
            "isKey": false,
            "numCitedBy": 453,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is proposed that can generate a ranked list of plausible three-dimensional hand configurations that best match an input image. Hand pose estimation is formulated as an image database indexing problem, where the closest matches for an input hand image are retrieved from a large database of synthetic hand images. In contrast to previous approaches, the system can function in the presence of clutter, thanks to two novel clutter-tolerant indexing methods. First, a computationally efficient approximation of the image-to-model chamfer distance is obtained by embedding binary edge images into a high-dimensional Euclidean space. Second, a general-purpose, probabilistic line matching method identifies those line segment correspondences between model and input images that are the least likely to have occurred by chance. The performance of this clutter tolerant approach is demonstrated in quantitative experiments with hundreds of real hand images."
            },
            "slug": "Estimating-3D-hand-pose-from-a-cluttered-image-Athitsos-Sclaroff",
            "title": {
                "fragments": [],
                "text": "Estimating 3D hand pose from a cluttered image"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A method is proposed that can generate a ranked list of plausible three-dimensional hand configurations that best match an input image that can function in the presence of clutter, thanks to two novel clutter-tolerant indexing methods."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10771328"
                        ],
                        "name": "Greg Mori",
                        "slug": "Greg-Mori",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "RVMs have been used, e.g., to build kernel regressors for 2D displacement updates in correlation-based patch tracking [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "In contrast, learning-based approaches try to avoid the need for explicit initialization and accurate 3D modeling and rendering, instead capitalizing on the fact that the set of typical human poses is far smaller than the set of kinematically possible ones and learning a model that directly\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "Index Terms\u2014Computer vision, human motion estimation, machine learning, multivariate regression."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10716734,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cc1b4ca121fef59517f24863b113bce3e5acd1a",
            "isKey": false,
            "numCitedBy": 429,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem we consider in this paper is to take a single two-dimensional image containing a human body, locate the joint positions, and use these to estimate the body configuration and pose in three-dimensional space. The basic approach is to store a number of exemplar 2D views of the human body in a variety of different configurations and viewpoints with respect to the camera. On each of these stored views, the locations of the body joints (left elbow, right knee, etc.) are manually marked and labelled for future use. The test shape is then matched to each stored view, using the technique of shape context matching in conjunction with a kinematic chain-based deformation model. Assuming that there is a stored view sufficiently similar in configuration and pose, the correspondence process will succeed. The locations of the body joints are then transferred from the exemplar view to the test shape. Given the joint locations, the 3D body configuration and pose are then estimated. We can apply this technique to video by treating each frame independently - tracking just becomes repeated recognition! We present results on a variety of datasets."
            },
            "slug": "Estimating-Human-Body-Configurations-Using-Shape-Mori-Malik",
            "title": {
                "fragments": [],
                "text": "Estimating Human Body Configurations Using Shape Context Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "The problem is to take a single two-dimensional image containing a human body, locate the joint positions, and use these to estimate the body configuration and pose in three-dimensional space."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144549270"
                        ],
                        "name": "M. Brand",
                        "slug": "M.-Brand",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Brand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "In contrast, learning-based approaches try to avoid the need for explicit initialization and accurate 3D modeling and rendering, instead capitalizing on the fact that the set of typical human poses is far smaller than the set of kinematically possible ones and learning a model that directly\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 141
                            }
                        ],
                        "text": "WE consider the problem of estimating and tracking3D configurations of complex articulated objects from monocular images, e.g., for applications requiring 3D human body pose and hand gesture analysis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "Our solutions are well-regularized in the sense that the weight vectors ak are damped to control overfitting and sparse in the sense that many of them are zero."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45365612,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13a1d20381ef248068a881ebab27d1fe60cf3228",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The mapping between 3D body poses and 2D shadows is fundamentally many-to-many and defeats regression methods, even with windowed context. We show how to learn a function between paths in the two systems, resolving ambiguities by integrating information over the entire length of a sequence. The basis of this function is a configural and dynamical manifold that summarizes the target system's behaviour. This manifold can be modeled from data with a hidden Markov model having special topological properties that we obtain via entropy minimization. Inference is then a matter of solving for the geodesic on the manifold that best explains the evidence in the cue sequence. We give a closed-form maximum a posteriori solution for geodesics through the learned density space, thereby obtaining optimal paths over the dynamical manifold. These methods give a completely general way to perform inference over time-series; in vision they support analysis, recognition, classification and synthesis of behaviours in linear time. We demonstrate with a prototype that infers 3D from monocular monochromatic sequences (e.g., back-subtractions), without using any articulatory body model. The framework readily accommodates multiple cameras and other sources of evidence such as optical flow or feature tracking."
            },
            "slug": "Shadow-puppetry-Brand",
            "title": {
                "fragments": [],
                "text": "Shadow puppetry"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "A closed-form maximum a posteriori solution for geodesics through the learned density space, thereby obtaining optimal paths over the dynamical manifold gives a completely general way to perform inference over time-series."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704879"
                        ],
                        "name": "H. Kjellstr\u00f6m",
                        "slug": "H.-Kjellstr\u00f6m",
                        "structuredName": {
                            "firstName": "Hedvig",
                            "lastName": "Kjellstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kjellstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144398147"
                        ],
                        "name": "L. Sigal",
                        "slug": "L.-Sigal",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Sigal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sigal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "Tracking is then formulated either as a single fully regressive model or by using the regression estimates in a multiple hypothesis tracker based on Condensation [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "To handle this, the method is embedded in a novel regressive tracking framework, using dynamics from the previous state estimate together with a learned regression value to disambiguate the pose."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6017383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7776d0a6bf3cdf9b3cd18b13d32c6babed84614b",
            "isKey": false,
            "numCitedBy": 376,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of probabilistically modeling 3D human motion for synthesis and tracking. Given the high dimensional nature of human motion, learning an explicit probabilistic model from available training data is currently impractical. Instead we exploit methods from texture synthesis that treat images as representing an implicit empirical distribution. These methods replace the problem of representing the probability of a texture pattern with that of searching the training data for similar instances of that pattern. We extend this idea to temporal data representing 3D human motion with a large database of example motions. To make the method useful in practice, we must address the problem of efficient search in a large training set; efficiency is particularly important for tracking. Towards that end, we learn a low dimensional linear model of human motion that is used to structure the example motion database into a binary tree. An approximate probabilistic tree search method exploits the coefficients of this low-dimensional representation and runs in sub-linear time. This probabilistic tree search returns a particular sample human motion with probability approximating the true distribution of human motions in the database. This sampling method is suitable for use with particle filtering techniques and is applied to articulated 3D tracking of humans within a Bayesian framework. Successful tracking results are presented, along with examples of synthesizing human motion using the model."
            },
            "slug": "Implicit-Probabilistic-Models-of-Human-Motion-for-Kjellstr\u00f6m-Black",
            "title": {
                "fragments": [],
                "text": "Implicit Probabilistic Models of Human Motion for Synthesis and Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A low dimensional linear model of human motion is learned that is used to structure the example motion database into a binary tree and an approximate probabilistic tree search method exploits the coefficients of this low-dimensional representation and runs in sub-linear time."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "To handle this, the method is embedded in a novel regressive tracking framework, using dynamics from the previous state estimate together with a learned regression value to disambiguate the pose."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2751624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f6a3dea66b539d75c30fb24ecefe627bbb0c3a9",
            "isKey": false,
            "numCitedBy": 882,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences. We introduce the use of a novel mathematical technique, the product of exponential maps and twist motions, and its integration into a differential motion estimation. This results in solving simple linear systems, and enables us to recover robustly the kinematic degrees-of-freedom in noise and complex self occluded configurations. We demonstrate this on several image sequences of people doing articulated full body movements, and visualize the results in re-animating an artificial 3D human model. We are also able to recover and re-animate the famous movements of Eadweard Muybridge's motion studies from the last century. To the best of our knowledge, this is the first computer vision based system that is able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "slug": "Tracking-people-with-twists-and-exponential-maps-Bregler-Malik",
            "title": {
                "fragments": [],
                "text": "Tracking people with twists and exponential maps"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences, and is the first computer vision based system able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "The loss of depth and limb labeling information often makes the recovery of 3D pose from single silhouettes ambiguous."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5283941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2069e28d8e1619093bfa2f00577f8b0d69f6837c",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A major difficulty for 3D (three-dimensional) human body tracking from monocular image sequences is the near nonobservability of kinematic degrees of freedom that generate motion in depth. For known link (body segment) lengths, the strict nonobservabilities reduce to twofold 'forwards/backwards flipping' ambiguities for each link. These imply 2/sup # links/ formal inverse kinematics solutions for the full model, and hence linked groups of O(2/sup # links/) local minima in the model-image matching cost function. Choosing the wrong minimum leads to rapid mistracking, so for reliable tracking, rapid methods of investigating alternative minima within a group are needed. Previous approaches to this have used generic search methods that do not exploit the specific problem structure. Here, we complement these by using simple kinematic reasoning to enumerate the tree of possible forwards/backwards flips, thus greatly speeding the search within each linked group of minima. Our methods can be used either deterministically, or within stochastic 'jump-diffusion' style search processes. We give experimental results on some challenging monocular human tracking sequences, showing how the new kinematic-flipping based sampling method improves and complements existing ones."
            },
            "slug": "Kinematic-jump-processes-for-monocular-3D-human-Sminchisescu-Triggs",
            "title": {
                "fragments": [],
                "text": "Kinematic jump processes for monocular 3D human tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This work uses simple kinematic reasoning to enumerate the tree of possible forwards/backwards flips, thus greatly speeding the search within each linked group of minima in the model-image matching cost function."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144609496"
                        ],
                        "name": "Oliver Williams",
                        "slug": "Oliver-Williams",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oliver Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Computer vision, human motion estimation, machine learning, multivariate regression."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2237129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3731d20583197b98ef1f3c070c592000d572b214",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of applying powerful pattern recognition algorithms based on kernels to efficient visual tracking. Recently S. Avidan, (2001) has shown that object recognizers using kernel-SVMs can be elegantly adapted to localization by means of spatial perturbation of the SVM, using optic flow. Whereas Avidan's SVM applies to each frame of a video independently of other frames, the benefits of temporal fusion of data are well known. Using a fully probabilistic 'relevance vector machine' (RVM) to generate observations with Gaussian distributions that can be fused over time is addressed. To improve performance further, rather than adapting a recognizer, we build a localizer directly using the regression form of the RVM. A classification SVM is used in tandem, for object verification, and this provides the capability of automatic initialization and recovery. The approach is demonstrated in real-time face and vehicle tracking systems. The 'sparsity' of the RVMs means that only a fraction of CPU time is required to track at frame rate. Tracker output is demonstrated in a camera management task in which zoom and pan are controlled in response to speaker/vehicle position and orientation, over an extended period. The advantages of temporal fusion in this system are demonstrated."
            },
            "slug": "A-sparse-probabilistic-learning-algorithm-for-Williams-Blake",
            "title": {
                "fragments": [],
                "text": "A sparse probabilistic learning algorithm for real-time tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The problem of applying powerful pattern recognition algorithms based on kernels to efficient visual tracking using a fully probabilistic 'relevance vector machine' (RVM) to generate observations with Gaussian distributions that can be fused over time is addressed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38388395"
                        ],
                        "name": "N. Howe",
                        "slug": "N.-Howe",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Howe",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Howe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1956966"
                        ],
                        "name": "M. Leventon",
                        "slug": "M.-Leventon",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Leventon",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leventon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "We are not aware of previous work on pose estimation that directly addresses these issues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1010343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71afe994133786f9f8865a68e6d4c065bc8101ed",
            "isKey": false,
            "numCitedBy": 329,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The three-dimensional motion of humans is underdetermined when the observation is limited to a single camera, due to the inherent 3D ambiguity of 2D video. We present a system that reconstructs the 3D motion of human subjects from single-camera video, relying on prior knowledge about human motion, learned from training data, to resolve those ambiguities. After initialization in 2D, the tracking and 3D reconstruction is automatic; we show results for several video sequences. The results show the power of treating 3D body tracking as an inference problem."
            },
            "slug": "Bayesian-Reconstruction-of-3D-Human-Motion-from-Howe-Leventon",
            "title": {
                "fragments": [],
                "text": "Bayesian Reconstruction of 3D Human Motion from Single-Camera Video"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A system that reconstructs the 3D motion of human subjects from single-camera video, relying on prior knowledge about human motion, learned from training data, to resolve those ambiguities."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769685"
                        ],
                        "name": "K. Toyama",
                        "slug": "K.-Toyama",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Toyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Toyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "Tracking is then formulated either as a single fully regressive model or by using the regression estimates in a multiple hypothesis tracker based on Condensation [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5637383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7bfe222d83e9dd9117bc4f8508962a01fb0b1626",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "A new exemplar-based, probabilistic paradigm for visual tracking is presented. Probabilistic mechanisms are attractive because they handle fusion of information, especially temporal fusion, in a principled manner. Exemplars are selected representatives of raw training data, used here to represent probabilistic mixture distributions of object configurations. Their use avoids tedious hand-construction of object models and problems with changes of topology. Using exemplars in place of a parameterized model poses several challenges, addressed here with what we call the \"Metric Mixture\" (M/sup 2/) approach. The M/sup 2/ model has several valuable properties. Principally, it provides alternatives to standard learning algorithms by allowing the use of metrics that are not embedded in a vector space. Secondly, it uses a noise model that is learned from training data. Lastly, it eliminates any need for an assumption of probabilistic pixelwise independence. Experiments demonstrate the effectiveness of the M/sup 2/ model in two domains tracking walking people using chamfer distances on binary edge images and tracking mouth movements by means of a shuffle distance."
            },
            "slug": "Probabilistic-tracking-in-a-metric-space-Toyama-Blake",
            "title": {
                "fragments": [],
                "text": "Probabilistic tracking in a metric space"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A new exemplar-based, probabilistic paradigm for visual tracking is presented, which provides alternatives to standard learning algorithms by allowing the use of metrics that are not embedded in a vector space and eliminates any need for an assumption of probabilistically pixelwise independence."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": false,
            "numCitedBy": 16258,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984136"
                        ],
                        "name": "A. Agarwal",
                        "slug": "A.-Agarwal",
                        "structuredName": {
                            "firstName": "Ankur",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[3])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17325134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad2e647372d8d57e5606da7d14c0bf195fea3b6d",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to modelling the non-linear and time- varying dynamics of human motion, using statistical methods to capture the char- acteristic motion patterns that exist in typical human activities. Our method is based on automatically clustering the body pose space into connected regions ex- hibiting similar dynamical characteristics, modelling the dynamics in each region as a Gaussian autoregressive process. Activities that would require large numbers of exemplars in example based methods are covered by comparatively few mo- tion models. Different regions correspond roughly to different action-fragments and our class inference scheme allows for smooth transitions between these, thus making it useful for activity recognition tasks. The method is used to track activi- ties including walking, running, etc., using a planar 2D body model. Its effective- ness is demonstrated by its success in tracking complicated motions like turns, without any key frames or 3D information."
            },
            "slug": "Tracking-Articulated-Motion-with-Piecewise-Learned-Agarwal-Triggs",
            "title": {
                "fragments": [],
                "text": "Tracking Articulated Motion with Piecewise Learned Dynamical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A novel approach to modelling the non-linear and time- varying dynamics of human motion, using statistical methods to capture the char- acteristic motion patterns that exist in typical human activities, based on automatically clustering the body pose space into connected regions with similar dynamical characteristics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490189"
                        ],
                        "name": "Gregory Shakhnarovich",
                        "slug": "Gregory-Shakhnarovich",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Shakhnarovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Shakhnarovich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "Index Terms\u2014Computer vision, human motion estimation, machine learning, multivariate regression."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 176
                            }
                        ],
                        "text": "An important subcase is model-based tracking, which focuses on tracking the pose estimate from one time step to the next starting from a known initialization based on an approximate dynamical model [9], [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2051403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e1556aea42601df3f457ad43dfb059498931a33",
            "isKey": false,
            "numCitedBy": 906,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Example-based methods are effective for parameter estimation problems when the underlying system is simple or the dimensionality of the input is low. For complex and high-dimensional problems such as pose estimation, the number of required examples and the computational complexity rapidly become prohibitively high. We introduce a new algorithm that learns a set of hashing functions that efficiently index examples relevant to a particular estimation task. Our algorithm extends locality-sensitive hashing, a recently developed method to find approximate neighbors in time sublinear in the number of examples. This method depends critically on the choice of hash functions that are optimally relevant to a particular estimation problem. Experiments demonstrate that the resulting algorithm, which we call parameter-sensitive hashing, can rapidly and accurately estimate the articulated pose of human figures from a large database of example images."
            },
            "slug": "Fast-pose-estimation-with-parameter-sensitive-Shakhnarovich-Viola",
            "title": {
                "fragments": [],
                "text": "Fast pose estimation with parameter-sensitive hashing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new algorithm is introduced that learns a set of hashing functions that efficiently index examples relevant to a particular estimation task, and can rapidly and accurately estimate the articulated pose of human figures from a large database of example images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82117876"
                        ],
                        "name": "F. Jurie",
                        "slug": "F.-Jurie",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Jurie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jurie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756828"
                        ],
                        "name": "M. Dhome",
                        "slug": "M.-Dhome",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Dhome",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dhome"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8813507,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f06d3fc49dca2e6380969b3d8f377b33c6001e7a",
            "isKey": false,
            "numCitedBy": 245,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Hager and Belhumeur (1998) proposed a general framework for object tracking in video images. It consists of low-order parametric models for the image motion of a target region. These models are used to predict movement and to track the target. The difference in intensity between the pixels belonging to the current region and the pixels of the selected target (learned during an offline stage) allows a straightforward prediction of the region position in the current image. The main aim of the article is to propose an important improvement within this framework, making the convergence faster with the same amount of online computation."
            },
            "slug": "Hyperplane-Approximation-for-Template-Matching-Jurie-Dhome",
            "title": {
                "fragments": [],
                "text": "Hyperplane Approximation for Template Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The main aim of the article is to propose an important improvement within this framework for object tracking in video images, making the convergence faster with the same amount of online computation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984136"
                        ],
                        "name": "A. Agarwal",
                        "slug": "A.-Agarwal",
                        "structuredName": {
                            "firstName": "Ankur",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206717449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e6fc8de73137fad8dabd348a5e88ba6ae341cf8",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to modelling the non-linear and time-varying dynamics of human motion, using statistical methods to capture the characteristic motion patterns that exist in typical human activities. Our method is based on automatically clustering the body pose space into connected regions exhibiting similar dynamical characteristics, modelling the dynamics in each region as a Gaussian autoregressive process. Activities that would require large numbers of exemplars in example based methods are covered by comparatively few motion models. Different regions correspond roughly to different action-fragments and our class inference scheme allows for smooth transitions between these, thus making it useful for activity recognition tasks. The method is used to track activities including walking, running, etc., using a planar 2D body model. Its effectiveness is demonstrated by its success in tracking complicated motions like turns, without any key frames or 3D information."
            },
            "slug": "Tracking-Articulated-Motion-Using-a-Mixture-of-Agarwal-Triggs",
            "title": {
                "fragments": [],
                "text": "Tracking Articulated Motion Using a Mixture of Autoregressive Models"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel approach to modelling the non-linear and time-varying dynamics of human motion, using statistical methods to capture the characteristic motion patterns that exist in typical human activities, based on automatically clustering the body pose space into connected regions exhibiting similar dynamical characteristics."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746940"
                        ],
                        "name": "B. Stenger",
                        "slug": "B.-Stenger",
                        "structuredName": {
                            "firstName": "Bj\u00f6rn",
                            "lastName": "Stenger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Stenger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707867"
                        ],
                        "name": "A. Thayananthan",
                        "slug": "A.-Thayananthan",
                        "structuredName": {
                            "firstName": "Arasanathan",
                            "lastName": "Thayananthan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Thayananthan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143635539"
                        ],
                        "name": "P. Torr",
                        "slug": "P.-Torr",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Torr",
                            "middleNames": [
                                "H.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Torr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5419171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8851b427f4b8a5cb2e91ed3ce2f19aa79529e64",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Within this paper a new framework for Bayesian tracking is presented, which approximates the posterior distribution at multiple resolutions. We propose a tree-based representation of the distribution, where the leaves define a partition of the state space with piecewise constant density. The advantage of this representation is that regions with low probability mass can be rapidly discarded in a hierarchical search, and the distribution can be approximated to arbitrary precision. We demonstrate the effectiveness of the technique by using it for tracking 3D articulated and nonrigid motion in front of cluttered background. More specifically, we are interested in estimating the joint angles, position and orientation of a 3D hand model in order to drive an avatar."
            },
            "slug": "Filtering-using-a-tree-based-estimator-Stenger-Thayananthan",
            "title": {
                "fragments": [],
                "text": "Filtering using a tree-based estimator"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A tree-based representation of the distribution, where the leaves define a partition of the state space with piecewise constant density is proposed, where regions with low probability mass can be rapidly discarded in a hierarchical search, and the distribution can be approximated to arbitrary precision."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Ninth IEEE International Conference on Computer Vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775672"
                        ],
                        "name": "Dirk Ormoneit",
                        "slug": "Dirk-Ormoneit",
                        "structuredName": {
                            "firstName": "Dirk",
                            "lastName": "Ormoneit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dirk Ormoneit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704879"
                        ],
                        "name": "H. Kjellstr\u00f6m",
                        "slug": "H.-Kjellstr\u00f6m",
                        "structuredName": {
                            "firstName": "Hedvig",
                            "lastName": "Kjellstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kjellstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Tracking is then formulated either as a single fully regressive model or by using the regression estimates in a multiple hypothesis tracker based on Condensation [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2217697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3470656ac8e8cd50661bf908e94e1125d49134cd",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present methods for learning and tracking human motion in video. We estimate a statistical model of typical activities from a large set of 3D periodic human motion data by segmenting these data automatically into \"cycles\". Then the mean and the principal components of the cycles are computed using a new algorithm that accounts for missing information and enforces smooth transitions between cycles. The learned temporal model provides a prior probability distribution over human motions that can be used in a Bayesian framework for tracking human subjects in complex monocular video sequences and recovering their 3D motion."
            },
            "slug": "Learning-and-Tracking-Cyclic-Human-Motion-Ormoneit-Kjellstr\u00f6m",
            "title": {
                "fragments": [],
                "text": "Learning and Tracking Cyclic Human Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The learned temporal model provides a prior probability distribution over human motions that can be used in a Bayesian framework for tracking human subjects in complex monocular video sequences and recovering their 3D motion."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31979282"
                        ],
                        "name": "Aaron D'Souza",
                        "slug": "Aaron-D'Souza",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "D'Souza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron D'Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144575699"
                        ],
                        "name": "S. Vijayakumar",
                        "slug": "S.-Vijayakumar",
                        "structuredName": {
                            "firstName": "Sethu",
                            "lastName": "Vijayakumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vijayakumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745219"
                        ],
                        "name": "S. Schaal",
                        "slug": "S.-Schaal",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Schaal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Schaal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8177462,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "18b76ef9b4a3abcca14efcf0da16dc8ff3b1e12d",
            "isKey": false,
            "numCitedBy": 291,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Real-time control of the end-effector of a humanoid robot in external coordinates requires computationally efficient solutions of the inverse kinematics problem. In this context, this paper investigates inverse kinematics learning for resolved motion rate control (RMRC) employing an optimization criterion to resolve kinematic redundancies. Our learning approach is based on the key observations that learning an inverse of a nonuniquely invertible function can be accomplished by augmenting the input representation to the inverse model and by using a spatially localized learning approach. We apply this strategy to inverse kinematics learning and demonstrate how a recently developed statistical learning algorithm, locally weighted projection regression, allows efficient learning of inverse kinematic mappings in an incremental fashion even when input spaces become rather high dimensional. Our results are illustrated with a 30-DOF humanoid robot."
            },
            "slug": "Learning-inverse-kinematics-D'Souza-Vijayakumar",
            "title": {
                "fragments": [],
                "text": "Learning inverse kinematics"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper investigates inverse kinematics learning for resolved motion rate control (RMRC) employing an optimization criterion to resolve kinematic redundancies and demonstrates how a recently developed statistical learning algorithm, locally weighted projection regression, allows efficient learning of inverse k Cinematic mappings in an incremental fashion even when input spaces become rather high dimensional."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829696"
                        ],
                        "name": "Y. Rubner",
                        "slug": "Y.-Rubner",
                        "structuredName": {
                            "firstName": "Yossi",
                            "lastName": "Rubner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Rubner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744254"
                        ],
                        "name": "L. Guibas",
                        "slug": "L.-Guibas",
                        "structuredName": {
                            "firstName": "Leonidas",
                            "lastName": "Guibas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Guibas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18648233,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "b7934a6f3a23940b7562df4cf58366b1adce55a3",
            "isKey": false,
            "numCitedBy": 1779,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new distance between two distributions that we call the Earth Mover's Distance (EMD), which reflects the minimal amount of work that must be performed to transform one distribution into the other by moving \"distribution mass\" around. This is a special case of the transportation problem from linear optimization, for which efficient algorithms are available. The EMD also allows for partial matching. When used to compare distributions that have the same overall mass, the EMD is a true metric, and has easy-to-compute lower bounds. In this paper we focus on applications to image databases, especially color and texture. We use the EMD to exhibit the structure of color-distribution and texture spaces by means of Multi-Dimensional Scaling displays. We also propose a novel approach to the problem of navigating through a collection of color images, which leads to a new paradigm for image database search."
            },
            "slug": "A-metric-for-distributions-with-applications-to-Rubner-Tomasi",
            "title": {
                "fragments": [],
                "text": "A metric for distributions with applications to image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper uses the Earth Mover's Distance to exhibit the structure of color-distribution and texture spaces by means of Multi-Dimensional Scaling displays, and proposes a novel approach to the problem of navigating through a collection of color images, which leads to a new paradigm for image database search."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144658464"
                        ],
                        "name": "V. Pavlovic",
                        "slug": "V.-Pavlovic",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Pavlovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Pavlovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698422"
                        ],
                        "name": "J. MacCormick",
                        "slug": "J.-MacCormick",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "MacCormick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacCormick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "Tracking is then formulated either as a single fully regressive model or by using the regression estimates in a multiple hypothesis tracker based on Condensation [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2930990,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8267434d8c9b188fc9f39f8a451b28b98d2233d",
            "isKey": false,
            "numCitedBy": 362,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The human figure exhibits complex and rich dynamic behavior that is both nonlinear and time-varying. Effective models of human dynamics can be learned from motion capture data using switching linear dynamic system (SLDS) models. We present results for human motion synthesis, classification, and visual tracking using learned SLDS models. Since exact inference in SLDS is intractable, we present three approximate inference algorithms and compare their performance. In particular, a new variational inference algorithm is obtained by casting the SLDS model as a Dynamic Bayesian Network. Classification experiments show the superiority of SLDS over conventional HMM's for our problem domain."
            },
            "slug": "Learning-Switching-Linear-Models-of-Human-Motion-Pavlovic-Rehg",
            "title": {
                "fragments": [],
                "text": "Learning Switching Linear Models of Human Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new variational inference algorithm is obtained by casting the SLDS model as a Dynamic Bayesian Network, and classification experiments show the superiority of SLDS over conventional HMM's for the problem domain."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12018209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4c47ebf6454e3c5a8417c580c8ecf694e34ad49",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "I examine two approximate methods for computational implementation of Bayesian hierarchical models, that is, models that include unknown hyperparameters such as regularization constants and noise levels. In the evidence framework, the model parameters are integrated over, and the resulting evidence is maximized over the hyperparameters. The optimized hyperparameters are used to define a gaussian approximation to the posterior distribution. In the alternative MAP method, the true posterior probability is found by integrating over the hyperparameters. The true posterior is then maximized over the model parameters, and a gaussian approximation is made. The similarities of the two approaches and their relative merits are discussed, and comparisons are made with the ideal hierarchical Bayesian solution. In moderately ill-posed problems, integration over hyperparameters yields a probability distribution with a skew peak, which causes signifi-cant biases to arise in the MAP method. In contrast, the evidence framework is shown to introduce negligible predictive error under straightforward conditions. General lessons are drawn concerning inference in many dimensions."
            },
            "slug": "Comparison-of-Approximate-Methods-for-Handling-Mackay",
            "title": {
                "fragments": [],
                "text": "Comparison of Approximate Methods for Handling Hyperparameters"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Two approximate methods for computational implementation of Bayesian hierarchical models that include unknown hyperparameters such as regularization constants and noise levels are examined, and the evidence framework is shown to introduce negligible predictive error under straightforward conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Computer vision, human motion estimation, machine learning, multivariate regression."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6821810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "963dddc907f56bd1d6c98dd40f560eb8786e49ea",
            "isKey": false,
            "numCitedBy": 5523,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of tracking curves in dense visual clutter is challenging. Kalman filtering is inadequate because it is based on Gaussian densities which, being unimo dal, cannot represent simultaneous alternative hypotheses. The Condensation algorithm uses \u201cfactored sampling\u201d, previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set. Condensation uses learned dynamical models, together with visual observations, to propagate the random set over time. The result is highly robust tracking of agile motion. Notwithstanding the use of stochastic methods, the algorithm runs in near real-time."
            },
            "slug": "CONDENSATION\u2014Conditional-Density-Propagation-for-Isard-Blake",
            "title": {
                "fragments": [],
                "text": "CONDENSATION\u2014Conditional Density Propagation for Visual Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Condensation algorithm uses \u201cfactored sampling\u201d, previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144215175"
                        ],
                        "name": "R. Jacobs",
                        "slug": "R.-Jacobs",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jacobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802785"
                        ],
                        "name": "S. Nowlan",
                        "slug": "S.-Nowlan",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Nowlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "from section IV to a mixture of regressors (often known as a mixture of experts [14])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 572361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8d90974c3f3b40fa05e322df2905fc16204aa56",
            "isKey": false,
            "numCitedBy": 4007,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new supervised learning procedure for systems composed of many separate networks, each of which learns to handle a subset of the complete set of training cases. The new procedure can be viewed either as a modular version of a multilayer supervised network, or as an associative version of competitive learning. It therefore provides a new link between these two apparently different approaches. We demonstrate that the learning procedure divides up a vowel discrimination task into appropriate subtasks, each of which can be solved by a very simple expert network."
            },
            "slug": "Adaptive-Mixtures-of-Local-Experts-Jacobs-Jordan",
            "title": {
                "fragments": [],
                "text": "Adaptive Mixtures of Local Experts"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A new supervised learning procedure for systems composed of many separate networks, each of which learns to handle a subset of the complete set of training cases, which is demonstrated to be able to be solved by a very simple expert network."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831141"
                        ],
                        "name": "Michael E. Tipping",
                        "slug": "Michael-E.-Tipping",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tipping",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael E. Tipping"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Computer vision, human motion estimation, machine learning, multivariate regression."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14209424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cff64a222dc659e9d23705e6e63b3d405a897287",
            "isKey": false,
            "numCitedBy": 959,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The support vector machine (SVM) is a state-of-the-art technique for regression and classification, combining excellent generalisation properties with a sparse kernel representation. However, it does suffer from a number of disadvantages, notably the absence of probabilistic outputs, the requirement to estimate a trade-off parameter and the need to utilise 'Mercer' kernel functions. In this paper we introduce the Relevance Vector Machine (RVM), a Bayesian treatment of a generalised linear model of identical functional form to the SVM. The RVM suffers from none of the above disadvantages, and examples demonstrate that for comparable generalisation performance, the RVM requires dramatically fewer kernel functions."
            },
            "slug": "The-Relevance-Vector-Machine-Tipping",
            "title": {
                "fragments": [],
                "text": "The Relevance Vector Machine"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The Relevance Vector Machine is introduced, a Bayesian treatment of a generalised linear model of identical functional form to the SVM, and examples demonstrate that for comparable generalisation performance, the RVM requires dramatically fewer kernel functions."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06bb5771e6b8a9356c5f4ae28c98b4397c043349",
            "isKey": false,
            "numCitedBy": 9316,
            "numCiting": 282,
            "paperAbstract": {
                "fragments": [],
                "text": "In this tutorial we give an overview of the basic ideas underlying Support Vector (SV) machines for function estimation. Furthermore, we include a summary of currently used algorithms for training SV machines, covering both the quadratic (or convex) programming part and advanced methods for dealing with large datasets. Finally, we mention some modifications and extensions that have been applied to the standard SV algorithm, and discuss the aspect of regularization from a SV perspective."
            },
            "slug": "A-tutorial-on-support-vector-regression-Smola-Sch\u00f6lkopf",
            "title": {
                "fragments": [],
                "text": "A tutorial on support vector regression"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This tutorial gives an overview of the basic ideas underlying Support Vector (SV) machines for function estimation, and includes a summary of currently used algorithms for training SV machines, covering both the quadratic programming part and advanced methods for dealing with large datasets."
            },
            "venue": {
                "fragments": [],
                "text": "Stat. Comput."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The results shown here use the SVM-light [15] for implementation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61116019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7550a05bf00f7b24aed9c1ac3ef000575388d21c",
            "isKey": false,
            "numCitedBy": 5454,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Training a support vector machine SVM leads to a quadratic optimization problem with bound constraints and one linear equality constraint. Despite the fact that this type of problem is well understood, there are many issues to be considered in designing an SVM learner. In particular, for large learning tasks with many training examples on the shelf optimization techniques for general quadratic programs quickly become intractable in their memory and time requirements. SVM light is an implementation of an SVM learner which addresses the problem of large tasks. This chapter presents algorithmic and computational results developed for SVM light V 2.0, which make large-scale SVM training more practical. The results give guidelines for the application of SVMs to large domains."
            },
            "slug": "Making-large-scale-SVM-learning-practical-Joachims",
            "title": {
                "fragments": [],
                "text": "Making large scale SVM learning practical"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This chapter presents algorithmic and computational results developed for SVM light V 2.0, which make large-scale SVM training more practical and give guidelines for the application of SVMs to large domains."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113861474"
                        ],
                        "name": "C. Bishop",
                        "slug": "C.-Bishop",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bishop"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60563397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9b1b1654ce0eea729c4160bfedcbb3246460b1d",
            "isKey": false,
            "numCitedBy": 8594,
            "numCiting": 250,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis is the first comprehensive treatment of feed-forward neural networks from the perspective of statistical pattern recognition. After introducing the basic concepts, the book examines techniques for modelling probability density functions and the properties and merits of the multi-layer perceptron and radial basis function network models. Also covered are various forms of error functions, principal algorithms for error function minimalization, learning and generalization in neural networks, and Bayesian techniques and their applications. Designed as a text, with over 100 exercises, this fully up-to-date work will benefit anyone involved in the fields of neural computation and pattern recognition."
            },
            "slug": "Neural-networks-for-pattern-recognition-Bishop",
            "title": {
                "fragments": [],
                "text": "Neural networks for pattern recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This is the first comprehensive treatment of feed-forward neural networks from the perspective of statistical pattern recognition, and is designed as a text, with over 100 exercises, to benefit anyone involved in the fields of neural computation and pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38756,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Not all of these degrees of freedom are independent, but they correspond to the motion capture data that we use to train the system (see Section 2.2)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Computer vision, human motion estimation, machine learning, multivariate regression."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 165
                            }
                        ],
                        "text": "At each time step, a state estimate xt is obtained from the previous two pose vectors using an autoregressive dynamical model, and this is used to compute r\u00f0 x; z\u00de, whose basis functions now take the form f k\u00f0 x; z\u00de j k \u00bc 1 . . . pg."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Int. Conf. Computer Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Int. Conf. Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[32] based regression methods on linear and kernel bases with the functional form given in section III:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59752996,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "5451278e1a11cf3f1be28a05f38d36c8641e68f7",
            "isKey": false,
            "numCitedBy": 4580,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Nature-of-Statistical-Learning-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60502900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c4da62e9e89e65ac78ee271e424e8b498053e8c",
            "isKey": false,
            "numCitedBy": 5544,
            "numCiting": 260,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction to support vector learning roadmap. Part 1 Theory: three remarks on the support vector method of function estimation, Vladimir Vapnik generalization performance of support vector machines and other pattern classifiers, Peter Bartlett and John Shawe-Taylor Bayesian voting schemes and large margin classifiers, Nello Cristianini and John Shawe-Taylor support vector machines, reproducing kernel Hilbert spaces, and randomized GACV, Grace Wahba geometry and invariance in kernel based methods, Christopher J.C. Burges on the annealed VC entropy for margin classifiers - a statistical mechanics study, Manfred Opper entropy numbers, operators and support vector kernels, Robert C. Williamson et al. Part 2 Implementations: solving the quadratic programming problem arising in support vector classification, Linda Kaufman making large-scale support vector machine learning practical, Thorsten Joachims fast training of support vector machines using sequential minimal optimization, John C. Platt. Part 3 Applications: support vector machines for dynamic reconstruction of a chaotic system, Davide Mattera and Simon Haykin using support vector machines for time series prediction, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel. Part 4 Extensions of the algorithm: reducing the run-time complexity in support vector machines, Edgar E. Osuna and Federico Girosi support vector regression with ANOVA decomposition kernels, Mark O. Stitson et al support vector density estimation, Jason Weston et al combining support vector and mathematical programming methods for classification, Bernhard Scholkopf et al."
            },
            "slug": "Advances-in-kernel-methods:-support-vector-learning-Sch\u00f6lkopf-Burges",
            "title": {
                "fragments": [],
                "text": "Advances in kernel methods: support vector learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Support vector machines for dynamic reconstruction of a chaotic system, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31589308"
                        ],
                        "name": "C. J. Taylor",
                        "slug": "C.-J.-Taylor",
                        "structuredName": {
                            "firstName": "Camillo",
                            "lastName": "Taylor",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "Human pose recovery is significantly harder\u2014more ill-conditioned and nonlinear and much higher dimensional \u2014but, by selecting a sufficiently rich set of image descriptors, it turns out that we can still obtain enough information for successful regression."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "We evaluate several different regression methods: ridge regression, Relevance Vector Machine (RVM) regression, and Support Vector Machine (SVM) regression over both linear and kernel bases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11364178,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "59719c9a2be9a5b4e2c5d4183926a3ad66b96486",
            "isKey": false,
            "numCitedBy": 373,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the problem of recovering information about the configuration of an articulated object, such as a human figure, from point correspondences in a single-image. Unlike previous approaches, the proposed reconstruction method does not assume that the imagery was acquired with a calibrated camera. An analysis is presented which demonstrates that there are a family of solutions to this reconstruction problem parameterized by a single variable. A simple and effective algorithm is proposed for recovering the entire set of solutions by considering the foreshortening of the segments of the model in the image. Results obtained by applying this algorithm to real images are presented."
            },
            "slug": "Reconstruction-of-articulated-objects-from-point-in-Taylor",
            "title": {
                "fragments": [],
                "text": "Reconstruction of Articulated Objects from Point Correspondences in a Single Uncalibrated Image"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "This paper investigates the problem of recovering information about the configuration of an articulated object, such as a human figure, from point correspondences in a single image by considering the foreshortening of the segments of the model in the image."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70345806"
                        ],
                        "name": "George Eastman House",
                        "slug": "George-Eastman-House",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "House",
                            "middleNames": [
                                "Eastman"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George Eastman House"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117676260"
                        ],
                        "name": "Guildhall StreetCambridge",
                        "slug": "Guildhall-StreetCambridge",
                        "structuredName": {
                            "firstName": "Guildhall",
                            "lastName": "StreetCambridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guildhall StreetCambridge"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 217295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d68725804eadecf83d707d89e12c5132bf376187",
            "isKey": false,
            "numCitedBy": 4411,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sparse-Bayesian-Learning-and-the-Relevance-Vector-House-StreetCambridge",
            "title": {
                "fragments": [],
                "text": "Sparse Bayesian Learning and the Relevance Vector Machine"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u2014Computer vision, human motion estimation, machine learning, multivariate regression."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "We evaluate several different regression methods: ridge regression, Relevance Vector Machine (RVM) regression, and Support Vector Machine (SVM) regression over both linear and kernel bases."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17098029,
            "fieldsOfStudy": [],
            "id": "37056506546e89011cf69cd32cabb5993f5e65a7",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reconstruction of articulated objects from point correspondences in a single uncalibrated image"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "Ridge and RVM regression use quadratic loss functions to measure x-space prediction errors, as described in Section 3, while SVM regression [31], [25] uses the -insensitive loss function and a linear programming method for training."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sch\u00f6lkpof, \u201cA Tutorial on Support Vector Regression,"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report NC2-TR-1998-030,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 166
                            }
                        ],
                        "text": "A single-valued least squares regressor tends to either zigzag erratically between different training poses, or (if highly damped) to reproduce their arithmetic mean [7], neither of which is desirable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Networks for Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "from section IV to amixtureof regressors (often known as a mixture of experts [14])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptive Mixtures of Local Experts.Neural Computation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Outline of our RVM training algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Fig"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural Networks for Pattern Recognition, chapter 6"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Pattern Recognition, chapter 6"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Inverse Kinematics. In Int. Conf. on Intelligent Robots and Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Learning Inverse Kinematics. In Int. Conf. on Intelligent Robots and Systems"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Outline of our RVM training algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Outline of our RVM training algorithm"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 188
                            }
                        ],
                        "text": "Ridge regression and RVM regression use quadratic loss functions to measurex-space prediction errors, as described in section III, while SVM regression uses the -insensitive loss function [26] and a linear programming method for training."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sc\u1e27  olkpof. A Tutorial on Support Vector Regression.NeuroCOLT2 Technical Report NC2-TR-1998-030"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/publications/dlib"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE"
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 16
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 47,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Recovering-3D-human-pose-from-monocular-images-Agarwal-Triggs/b51d606db06e178c5dff1e9d8c1460352bdb85db?sort=total-citations"
}