{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144720379"
                        ],
                        "name": "Alexandre Passos",
                        "slug": "Alexandre-Passos",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "Passos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandre Passos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112232561"
                        ],
                        "name": "Vineet Kumar",
                        "slug": "Vineet-Kumar",
                        "structuredName": {
                            "firstName": "Vineet",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vineet Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Passos et al. (2014) extend the Skip-Gram language model (Mikolov et al., 2013) to produce phrase embeddings that are more suitable to be used in a linear-chain CRF to perform NER."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 119
                            }
                        ],
                        "text": "Some recent work on deep learning for named entity recognition include Chen et al. (2010), Collobert et al. (2011) and Passos et al. (2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 171
                            }
                        ],
                        "text": "On the other hand, some recent work on NER have used deep learning strategies which minimize the need of these costly features (Chen et al., 2010; Collobert et al., 2011; Passos et al., 2014; Tang et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9345583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d53d878cf1a3f0bed5d9c68c925994cb72f47304",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Most state-of-the-art approaches for named-entity recognition (NER) use semi supervised information in the form of word clusters and lexicons. Recently neural network-based language models have been explored, as they as a byproduct generate highly informative vector representations for words, known as word embeddings. In this paper we present two contributions: a new form of learning word embeddings that can leverage information from relevant lexicons to improve the representations, and the first system to use neural word embeddings to achieve state-of-the-art results on named-entity recognition in both CoNLL and Ontonotes NER. Our system achieves an F1 score of 90.90 on the test set for CoNLL 2003---significantly better than any previous system trained on public data, and matching a system employing massive private industrial query-log data."
            },
            "slug": "Lexicon-Infused-Phrase-Embeddings-for-Named-Entity-Passos-Kumar",
            "title": {
                "fragments": [],
                "text": "Lexicon Infused Phrase Embeddings for Named Entity Resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new form of learning word embeddings that can leverage information from relevant lexicons to improve the representations, and the first system to use neural word embedDings to achieve state-of-the-art results on named-entity recognition in both CoNLL and Ontonotes NER are presented."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790831"
                        ],
                        "name": "C. D. Santos",
                        "slug": "C.-D.-Santos",
                        "structuredName": {
                            "firstName": "C\u00edcero",
                            "lastName": "Santos",
                            "middleNames": [
                                "Nogueira",
                                "dos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Santos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735228"
                        ],
                        "name": "B. Zadrozny",
                        "slug": "B.-Zadrozny",
                        "structuredName": {
                            "firstName": "Bianca",
                            "lastName": "Zadrozny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Zadrozny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2834402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f70391f9a6aeec75bc52b9fe38588b9d0b4d40c6",
            "isKey": false,
            "numCitedBy": 528,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Distributed word representations have recently been proven to be an invaluable resource for NLP. These representations are normally learned using neural networks and capture syntactic and semantic information about words. Information about word morphology and shape is normally ignored when learning word representations. However, for tasks like part-of-speech tagging, intra-word information is extremely useful, specially when dealing with morphologically rich languages. In this paper, we propose a deep neural network that learns character-level representation of words and associate them with usual word representations to perform POS tagging. Using the proposed approach, while avoiding the use of any handcrafted feature, we produce state-of-the-art POS taggers for two languages: English, with 97.32% accuracy on the Penn Treebank WSJ corpus; and Portuguese, with 97.47% accuracy on the Mac-Morpho corpus, where the latter represents an error reduction of 12.2% on the best previous known result."
            },
            "slug": "Learning-Character-level-Representations-for-Santos-Zadrozny",
            "title": {
                "fragments": [],
                "text": "Learning Character-level Representations for Part-of-Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A deep neural network is proposed that learns character-level representation of words and associate them with usual word representations to perform POS tagging and produces state-of-the-art POS taggers for two languages."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790831"
                        ],
                        "name": "C. D. Santos",
                        "slug": "C.-D.-Santos",
                        "structuredName": {
                            "firstName": "C\u00edcero",
                            "lastName": "Santos",
                            "middleNames": [
                                "Nogueira",
                                "dos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Santos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735228"
                        ],
                        "name": "B. Zadrozny",
                        "slug": "B.-Zadrozny",
                        "structuredName": {
                            "firstName": "Bianca",
                            "lastName": "Zadrozny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Zadrozny"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4696410,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef978c7eb38fda38d8734928c845148b2da68b02",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Part-of-speech (POS) tagging for morphologically rich languages normally requires the use of handcrafted features that encapsulate clues about the language\u2019s morphology. In this work, we tackle Portuguese POS tagging using a deep neural network that employs a convolutional layer to learn character-level representation of words. We apply the network to three different corpora: the original Mac-Morpho corpus; a revised version of the Mac-Morpho corpus; and the Tycho Brahe corpus. Using the proposed approach, while avoiding the use of any handcrafted feature, we produce state-of-the-art POS taggers for the three corpora: 97.47% accuracy on the Mac-Morpho corpus; 97.31% accuracy on the revised Mac-Morpho corpus; and 97.17% accuracy on the Tycho Brahe corpus. These results represent an error reduction of 12.2%, 23.6% and 15.8%, respectively, on the best previous known result for each corpus."
            },
            "slug": "Training-State-of-the-Art-Portuguese-POS-Taggers-Santos-Zadrozny",
            "title": {
                "fragments": [],
                "text": "Training State-of-the-Art Portuguese POS Taggers without Handcrafted Features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work tackles Portuguese POS tagging using a deep neural network that employs a convolutional layer to learn character-level representation of words and produces state-of-the-art POS taggers for three corpora."
            },
            "venue": {
                "fragments": [],
                "text": "PROPOR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987453"
                        ],
                        "name": "Buzhou Tang",
                        "slug": "Buzhou-Tang",
                        "structuredName": {
                            "firstName": "Buzhou",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Buzhou Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114854927"
                        ],
                        "name": "Hongxin Cao",
                        "slug": "Hongxin-Cao",
                        "structuredName": {
                            "firstName": "Hongxin",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongxin Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709719"
                        ],
                        "name": "Xiaolong Wang",
                        "slug": "Xiaolong-Wang",
                        "structuredName": {
                            "firstName": "Xiaolong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaolong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144159781"
                        ],
                        "name": "Qingcai Chen",
                        "slug": "Qingcai-Chen",
                        "structuredName": {
                            "firstName": "Qingcai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qingcai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49507401"
                        ],
                        "name": "Hua Xu",
                        "slug": "Hua-Xu",
                        "structuredName": {
                            "firstName": "Hua",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hua Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 192
                            }
                        ],
                        "text": "On the other hand, some recent work on NER have used deep learning strategies which minimize the need of these costly features (Chen et al., 2010; Collobert et al., 2011; Passos et al., 2014; Tang et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17102024,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "523f255f90be3f1ae0f151c60cac50467e965ed0",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Biomedical Named Entity Recognition (BNER), which extracts important entities such as genes and proteins, is a crucial step of natural language processing in the biomedical domain. Various machine learning-based approaches have been applied to BNER tasks and showed good performance. In this paper, we systematically investigated three different types of word representation (WR) features for BNER, including clustering-based representation, distributional representation, and word embeddings. We selected one algorithm from each of the three types of WR features and applied them to the JNLPBA and BioCreAtIvE II BNER tasks. Our results showed that all the three WR algorithms were beneficial to machine learning-based BNER systems. Moreover, combining these different types of WR features further improved BNER performance, indicating that they are complementary to each other. By combining all the three types of WR features, the improvements in F-measure on the BioCreAtIvE II GM and JNLPBA corpora were 3.75% and 1.39%, respectively, when compared with the systems using baseline features. To the best of our knowledge, this is the first study to systematically evaluate the effect of three different types of WR features for BNER tasks."
            },
            "slug": "Evaluating-Word-Representation-Features-in-Named-Tang-Cao",
            "title": {
                "fragments": [],
                "text": "Evaluating Word Representation Features in Biomedical Named Entity Recognition Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper systematically investigated three different types of word representation (WR) features for BNER, including clustering-based representation, distributional representation, and word embeddings, and showed that all the three WR algorithms were beneficial to machine learning-based BNER systems."
            },
            "venue": {
                "fragments": [],
                "text": "BioMed research international"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8756311"
                        ],
                        "name": "R. Milidi\u00fa",
                        "slug": "R.-Milidi\u00fa",
                        "structuredName": {
                            "firstName": "Ruy",
                            "lastName": "Milidi\u00fa",
                            "middleNames": [
                                "Luiz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Milidi\u00fa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145833966"
                        ],
                        "name": "J. C. Duarte",
                        "slug": "J.-C.-Duarte",
                        "structuredName": {
                            "firstName": "Julio",
                            "lastName": "Duarte",
                            "middleNames": [
                                "Cesar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. Duarte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145330403"
                        ],
                        "name": "R. Cavalcante",
                        "slug": "R.-Cavalcante",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cavalcante",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cavalcante"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9532287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c2cf68e49df90bff81f2a7c457ce38c73f9cb98",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Named Entity Recognition (NER) is an important task in Natu- ral Language Processing. It provides key features that help on more ela- borated document management and information extraction tasks. In this paper, we propose seven machine learning approaches that use HMM, TBL and SVM to solve Portuguese NER. The performance of each model- ing approach is empirically evaluated. The SVM-based extractor shows a 88.11%F-score, which is our best observed value, slightly better than TBL. This is very competitive when compared to state-of-the-art extractors for similar Portuguese NER problems. Our HMM has reasonable precision and accuracy and does not require any additional expert knowledge. This is an advantage for our HMM over the other approaches. The experimen- tal results suggest that Machine Learning can be useful in Portuguese NER. They also indicate that HMM, TBL and SVM perform well in this natural language processing task."
            },
            "slug": "Machine-Learning-Algorithms-for-Portuguese-Named-Milidi\u00fa-Duarte",
            "title": {
                "fragments": [],
                "text": "Machine Learning Algorithms for Portuguese Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The results suggest that Machine Learning can be useful in Portuguese NER and indicate that HMM, TBL and SVM perform well in this natural language processing task."
            },
            "venue": {
                "fragments": [],
                "text": "Inteligencia Artif."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21432929"
                        ],
                        "name": "Michael Karlen",
                        "slug": "Michael-Karlen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Karlen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Karlen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46283650"
                        ],
                        "name": "P. Kuksa",
                        "slug": "P.-Kuksa",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Kuksa",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kuksa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Collobert et al. (2011) propose a deep neural network which is equivalent to the WNN architecture described in Section 3.3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 23
                            }
                        ],
                        "text": "In the same way as in (Collobert et al., 2011), we interpret the sentence score (3) as a conditional probability over a path."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 29
                            }
                        ],
                        "text": "We follow Collobert et al.\u2019s (Collobert et al., 2011) window approach to score all tags T for each word in a sentence."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 37
                            }
                        ],
                        "text": "Additionally, in the same way as in (Collobert et al., 2011), we check the impact of adding to WNN two handcrafted features that contain character-level information, namely capitalization and suffix."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 9
                            }
                        ],
                        "text": "Like in (Collobert et al., 2011), CharWNN uses a prediction scheme that takes into account the sentence structure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "After scoring each word in the sentence, the predicted sequence is inferred with the Viterbi algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 91
                            }
                        ],
                        "text": "Some recent work on deep learning for named entity recognition include Chen et al. (2010), Collobert et al. (2011) and Passos et al. (2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 147
                            }
                        ],
                        "text": "On the other hand, some recent work on NER have used deep learning strategies which minimize the need of these costly features (Chen et al., 2010; Collobert et al., 2011; Passos et al., 2014; Tang et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 351666,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc1022b031dc6c7019696492e8116598097a8c12",
            "isKey": true,
            "numCitedBy": 6658,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements."
            },
            "slug": "Natural-Language-Processing-(Almost)-from-Scratch-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "Natural Language Processing (Almost) from Scratch"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144838082"
                        ],
                        "name": "Yu Chen",
                        "slug": "Yu-Chen",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144763097"
                        ],
                        "name": "Y. Ouyang",
                        "slug": "Y.-Ouyang",
                        "structuredName": {
                            "firstName": "You",
                            "lastName": "Ouyang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ouyang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50135338"
                        ],
                        "name": "Wenjie Li",
                        "slug": "Wenjie-Li",
                        "structuredName": {
                            "firstName": "Wenjie",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenjie Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37032041"
                        ],
                        "name": "Dequan Zheng",
                        "slug": "Dequan-Zheng",
                        "structuredName": {
                            "firstName": "Dequan",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dequan Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145382463"
                        ],
                        "name": "T. Zhao",
                        "slug": "T.-Zhao",
                        "structuredName": {
                            "firstName": "Tiejun",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 71
                            }
                        ],
                        "text": "Some recent work on deep learning for named entity recognition include Chen et al. (2010), Collobert et al. (2011) and Passos et al. (2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 128
                            }
                        ],
                        "text": "On the other hand, some recent work on NER have used deep learning strategies which minimize the need of these costly features (Chen et al., 2010; Collobert et al., 2011; Passos et al., 2014; Tang et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Chen et al. (2010) employ deep belief networks (DBN) to perform named entity categorization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7795530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "afacd9d2048902a8faf82c4f79584d6a05170ba6",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Identifying named entities is essential in understanding plain texts. Moreover, the categories of the named entities are indicative of their roles in the texts. In this paper, we propose a novel approach, Deep Belief Nets (DBN), for the Chinese entity mention categorization problem. DBN has very strong representation power and it is able to elaborately self-train for discovering complicated feature combinations. The experiments conducted on the Automatic Context Extraction (ACE) 2004 data set demonstrate the effectiveness of DBN. It outperforms the state-of-the-art learning models such as SVM or BP neural network."
            },
            "slug": "Using-Deep-Belief-Nets-for-Chinese-Named-Entity-Chen-Ouyang",
            "title": {
                "fragments": [],
                "text": "Using Deep Belief Nets for Chinese Named Entity Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a novel approach, Deep Belief Nets (DBN), for the Chinese entity mention categorization problem, which has very strong representation power and it is able to elaborately self-train for discovering complicated feature combinations."
            },
            "venue": {
                "fragments": [],
                "text": "NEWS@ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 251
                            }
                        ],
                        "text": "Taking the log, we arrive at the following conditional log-probability:\nlog p ( [t]N1 |[w]N1 , \u03b8 ) = S ( [w]N1 , [t] N 1 , \u03b8 ) \u2212log\n \u2211 \u2200[u]N1 \u2208TN eS([w] N 1 ,[u] N 1 ,\u03b8)  (4) The log-likelihood in Equation 4 can be computed efficiently using dynamic programming (Collobert, 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11135765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6d931fe9bfe7223165b14ec85d79d56e406e38a",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new fast purely discriminative algorithm for natural language parsing, based on a \u201cdeep\u201d recurrent convolutional graph transformer network (GTN). Assuming a decomposition of a parse tree into a stack of \u201clevels\u201d, the network predicts a level of the tree taking into account predictions of previous levels. Using only few basic text features which leverage word representations from Collobert and Weston (2008), we show similar performance (in F1 score) to existing pure discriminative parsers and existing \u201cbenchmark\u201d parsers (like Collins parser, probabilistic context-free grammars based), with a huge speed advantage."
            },
            "slug": "Deep-Learning-for-Efficient-Discriminative-Parsing-Collobert",
            "title": {
                "fragments": [],
                "text": "Deep Learning for Efficient Discriminative Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A new fast purely discriminative algorithm for natural language parsing, based on a \u201cdeep\u201d recurrent convolutional graph transformer network (GTN) and assuming a decomposition of a parse tree into a stack of \"levels\u201d, the network predicts a level of the tree taking into account predictions of previous levels."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 58
                            }
                        ],
                        "text": "Passos et al. (2014) extend the Skip-Gram language model (Mikolov et al., 2013) to produce phrase embeddings that are more suitable to be used in a linear-chain CRF to perform NER."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 85
                            }
                        ],
                        "text": "We perform pre-training of wordlevel embeddings using the skip-gram NN architecture (Mikolov et al., 2013) available in the word2vec 1 tool."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5959482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "330da625c15427c6e42ccfa3b747fb29e5835bf0",
            "isKey": false,
            "numCitedBy": 21887,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose two novel model architectures for computing continuous vector\nrepresentations of words from very large data sets. The quality of these\nrepresentations is measured in a word similarity task, and the results are\ncompared to the previously best performing techniques based on different types\nof neural networks. We observe large improvements in accuracy at much lower\ncomputational cost, i.e. it takes less than a day to learn high quality word\nvectors from a 1.6 billion words data set. Furthermore, we show that these\nvectors provide state-of-the-art performance on our test set for measuring\nsyntactic and semantic word similarities."
            },
            "slug": "Efficient-Estimation-of-Word-Representations-in-Mikolov-Chen",
            "title": {
                "fragments": [],
                "text": "Efficient Estimation of Word Representations in Vector Space"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Two novel model architectures for computing continuous vector representations of words from very large data sets are proposed and it is shown that these vectors provide state-of-the-art performance on the authors' test set for measuring syntactic and semantic word similarities."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862682"
                        ],
                        "name": "G. Doddington",
                        "slug": "G.-Doddington",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Doddington",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Doddington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2449760"
                        ],
                        "name": "A. Mitchell",
                        "slug": "A.-Mitchell",
                        "structuredName": {
                            "firstName": "Alexis",
                            "lastName": "Mitchell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2282719"
                        ],
                        "name": "Mark A. Przybocki",
                        "slug": "Mark-A.-Przybocki",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Przybocki",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark A. Przybocki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754963"
                        ],
                        "name": "S. Strassel",
                        "slug": "S.-Strassel",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "Strassel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Strassel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 225
                            }
                        ],
                        "text": "\u2026approach to achieve state-of-the-art results for NER, most of these NER systems rely on the use of costly handcrafted features and on the output of other NLP tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003; Doddington et al., 2004; Finkel et al., 2005; Milidiu\u0301 et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9776219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0617dd6924df7a3491c299772b70e90507b195dc",
            "isKey": false,
            "numCitedBy": 933,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of the ACE program is to develop technology to automatically infer from human language data the entities being mentioned, the relations among these entities that are directly expressed, and the events in which these entities participate. Data sources include audio and image data in addition to pure text, and Arabic and Chinese in addition to English. The effort involves defining the research tasks in detail, collecting and annotating data needed for training, development, and evaluation, and supporting the research with evaluation tools and research workshops. This program began with a pilot study in 1999. The next evaluation is scheduled for September 2004. Introduction and Background Today\u2019s global web of electronic information, including most notably the www, provides a resource of unbounded information-bearing potential. But to fully exploit this potential requires the ability to extract content from human language automatically. That is the objective of the ACE program \u2013 to develop the capability to extract meaning from multimedia sources. These sources include text, audio and image data. The ACE program is a \u201ctechnocentric\u201d research effort, meaning that the emphasis is on developing core enabling technologies rather than solving the application needs that motivate the research. The program began in 1999 with a study intended to identify those key content extraction tasks to serve as the research targets for the remainder of the program. These tasks were identified in general as the extraction of the entities, relations and events being discussed in the language. In general objective, the ACE program is motivated by and addresses the same issues as the MUC program that preceded it (NIST 1999). The ACE program, however, attempts to take the task \u201coff the page\u201d in the sense that the research objectives are defined in terms of the target objects (i.e., the entities, the relations, and the events) rather than in terms of the words in the text. For example, the so-called \u201cnamed entity\u201d task, as defined in MUC, is to identify those words (on the page) that are names of entities. In ACE, on the other hand, the corresponding task is to identify the entity so named. This is a different task, one that is more abstract and that involves inference more explicitly in producing an answer. In a real sense, the task is to detect things that \u201caren\u2019t there\u201d. Reference resolution thus becomes an integral and critical part of solving the problem. During the period 2000-2001, the ACE effort was devoted solely to entity detection and tracking. During the period 2002-2003, relations were explored and added. 1 While the ACE program is directed toward extraction of information from audio and image sources in addition to pure text, the research effort is restricted to information extraction from text. The actual transduction of audio and image data into text is not part of the ACE research effort, although the processing of ASR and OCR output from such transducers is. Now, starting in 2004, events are being explored and added as the third of the three original tasks."
            },
            "slug": "The-Automatic-Content-Extraction-(ACE)-Program-and-Doddington-Mitchell",
            "title": {
                "fragments": [],
                "text": "The Automatic Content Extraction (ACE) Program - Tasks, Data, and Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The objective of the ACE program is to develop technology to automatically infer from human language data the entities being mentioned, the relations among these entities that are directly expressed, and the events in which these entities participate."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 11
                            }
                        ],
                        "text": "In Figure 1, we illustrate the construction of the character-level embedding for the word Bennett, but the same process is used to construct the character-level embedding of each word in the input."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 105
                            }
                        ],
                        "text": "The character-level embedding of each word is computed using a convolutional layer (Waibel et al., 1989; Lecun et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35264,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105414"
                        ],
                        "name": "F. D. Meulder",
                        "slug": "F.-D.-Meulder",
                        "structuredName": {
                            "firstName": "Fien",
                            "lastName": "Meulder",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. Meulder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2470716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10f97f1fb4f5c2c8e6c44d4a33da46d331dd4aeb",
            "isKey": false,
            "numCitedBy": 2960,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the CoNLL-2003 shared task: language-independent named entity recognition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their performance."
            },
            "slug": "Introduction-to-the-CoNLL-2003-Shared-Task:-Named-Sang-Meulder",
            "title": {
                "fragments": [],
                "text": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The CoNLL-2003 shared task: language-independent named entity recognition is described and a general overview of the systems that have taken part in the task and discuss their performance is presented."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40396597"
                        ],
                        "name": "Toshiyuki Hanazawa",
                        "slug": "Toshiyuki-Hanazawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Hanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiyuki Hanazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 84
                            }
                        ],
                        "text": "The character-level embedding of each word is computed using a convolutional layer (Waibel et al., 1989; Lecun et al., 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9563026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd62c9976534a6a2096a38244f6cbb03635a127e",
            "isKey": false,
            "numCitedBy": 2787,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: (1) using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation; and (2) the time-delay arrangement enables the network to discover acoustic-phonetic features and the temporal relationships between them independently of position in time and therefore not blurred by temporal shifts in the input. As a recognition task, the speaker-dependent recognition of the phonemes B, D, and G in varying phonetic contexts was chosen. For comparison, several discrete hidden Markov models (HMM) were trained to perform the same task. Performance evaluation over 1946 testing tokens from three speakers showed that the TDNN achieves a recognition rate of 98.5% correct while the rate obtained by the best of the HMMs was only 93.7%. >"
            },
            "slug": "Phoneme-recognition-using-time-delay-neural-Waibel-Hanazawa",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition using time-delay neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784228"
                        ],
                        "name": "J. Finkel",
                        "slug": "J.-Finkel",
                        "structuredName": {
                            "firstName": "Jenny",
                            "lastName": "Finkel",
                            "middleNames": [
                                "Rose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Finkel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050250"
                        ],
                        "name": "Trond Grenager",
                        "slug": "Trond-Grenager",
                        "structuredName": {
                            "firstName": "Trond",
                            "lastName": "Grenager",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trond Grenager"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 250
                            }
                        ],
                        "text": "\u2026approach to achieve state-of-the-art results for NER, most of these NER systems rely on the use of costly handcrafted features and on the output of other NLP tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003; Doddington et al., 2004; Finkel et al., 2005; Milidiu\u0301 et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10977241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f410ab5c8b12b34b38421241366ee456bbebab9",
            "isKey": false,
            "numCitedBy": 3246,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Most current statistical natural language processing models use only local features so as to permit dynamic programming in inference, but this makes them unable to fully account for the long distance structure that is prevalent in language use. We show how to solve this dilemma with Gibbs sampling, a simple Monte Carlo method used to perform approximate inference in factored probabilistic models. By using simulated annealing in place of Viterbi decoding in sequence models such as HMMs, CMMs, and CRFs, it is possible to incorporate non-local structure while preserving tractable inference. We use this technique to augment an existing CRF-based information extraction system with long-distance dependency models, enforcing label consistency and extraction template consistency constraints. This technique results in an error reduction of up to 9% over state-of-the-art systems on two established information extraction tasks."
            },
            "slug": "Incorporating-Non-local-Information-into-Extraction-Finkel-Grenager",
            "title": {
                "fragments": [],
                "text": "Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "By using simulated annealing in place of Viterbi decoding in sequence models such as HMMs, CMMs, and CRFs, it is possible to incorporate non-local structure while preserving tractable inference."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157221"
                        ],
                        "name": "E. T. K. Sang",
                        "slug": "E.-T.-K.-Sang",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Sang",
                            "middleNames": [
                                "Tjong",
                                "Kim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. T. K. Sang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3262157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "502858989368adae91e0f4a643ebc2aa6efd5738",
            "isKey": false,
            "numCitedBy": 660,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the CoNLL-2002 shared task: language-independent named entity recognition. We give background information on the data sets and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their performance."
            },
            "slug": "Introduction-to-the-CoNLL-2002-Shared-Task:-Named-Sang",
            "title": {
                "fragments": [],
                "text": "Introduction to the CoNLL-2002 Shared Task: Language-Independent Named Entity Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The CoNLL-2002 shared task: language-independent named entity recognition is described and a general overview of the systems that have taken part in the task and discuss their performance is presented."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790831"
                        ],
                        "name": "C. D. Santos",
                        "slug": "C.-D.-Santos",
                        "structuredName": {
                            "firstName": "C\u00edcero",
                            "lastName": "Santos",
                            "middleNames": [
                                "Nogueira",
                                "dos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Santos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8756311"
                        ],
                        "name": "R. Milidi\u00fa",
                        "slug": "R.-Milidi\u00fa",
                        "structuredName": {
                            "firstName": "Ruy",
                            "lastName": "Milidi\u00fa",
                            "middleNames": [
                                "Luiz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Milidi\u00fa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37061504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3dd898e34469df448ec1cc1dab3a25374291ac7b",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface.- Acknowledgements.- Acronyms.- Part I Entropy Guided Transformation Learning: Algorithms.- Introduction.- Entropy Guided Transformation Learning.- ETL Committee.- Part II Entropy Guided Transformation Learning: Applications.- General ETL Modeling for NLP Tasks.- Part-of-Speech Tagging.- Phrase Chunking.- Named Entity Recognition.- Semantic Role Labeling.- Conclusions.- Appendices."
            },
            "slug": "Entropy-Guided-Transformation-Learning:-Algorithms-Santos-Milidi\u00fa",
            "title": {
                "fragments": [],
                "text": "Entropy Guided Transformation Learning: Algorithms and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "General ETL Modeling for NLP Tasks and Phrase Chunking for Named Entity Recognition and Semantic Role Labeling are modeled."
            },
            "venue": {
                "fragments": [],
                "text": "SpringerBriefs in Computer Science"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701734"
                        ],
                        "name": "X. Carreras",
                        "slug": "X.-Carreras",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Carreras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Carreras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3049328"
                        ],
                        "name": "Llu\u00eds M\u00e0rquez i Villodre",
                        "slug": "Llu\u00eds-M\u00e0rquez-i-Villodre",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Villodre",
                            "middleNames": [
                                "M\u00e0rquez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llu\u00eds M\u00e0rquez i Villodre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778523"
                        ],
                        "name": "Llu\u00eds Padr\u00f3",
                        "slug": "Llu\u00eds-Padr\u00f3",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Padr\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llu\u00eds Padr\u00f3"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 60
                            }
                        ],
                        "text": "This system was trained using AdaBoost and is described in (Carreras et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5249216,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f54adfd6d6959e0c9ae8953ac00ea675087085f",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a Named Entity Extraction (NEE) system for the CoNLL 2002 competition. The two main sub-tasks of the problem, recognition (NER) and classification (NEC), are performed sequentially and independently with separate modules. Both modules are machine learning based systems, which make use of binary AdaBoost classifiers."
            },
            "slug": "Named-Entity-Extraction-using-AdaBoost-Carreras-Villodre",
            "title": {
                "fragments": [],
                "text": "Named Entity Extraction using AdaBoost"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper presents a Named Entity Extraction (NEE) system for the CoNLL 2002 competition, which makes use of binary AdaBoost classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500689"
                        ],
                        "name": "A. Viterbi",
                        "slug": "A.-Viterbi",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Viterbi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Viterbi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 81
                            }
                        ],
                        "text": "The output for the whole sentence is then processed using the Viterbi algorithm (Viterbi, 1967) to perform structured prediction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "After scoring each word in the sentence, the predicted sequence is inferred with the Viterbi algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15843983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "145c0b53514b02bdc3dadfb2e1cea124f2abd99b",
            "isKey": false,
            "numCitedBy": 5209,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates above R_{0} , the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "slug": "Error-bounds-for-convolutional-codes-and-an-optimum-Viterbi",
            "title": {
                "fragments": [],
                "text": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060794808"
                        ],
                        "name": "W. Carvalho",
                        "slug": "W.-Carvalho",
                        "structuredName": {
                            "firstName": "Wesley",
                            "lastName": "Carvalho",
                            "middleNames": [
                                "Seidel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Carvalho"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 51
                            }
                        ],
                        "text": "We use the corpus from the first HAREM evaluation (Santos and Cardoso, 2007) in our experiments on Portuguese NER."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58811045,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73f7a12dd60b6140765c5818cd4b333cd21b7a48",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Reconhecimento-de-entidades-mencionadas-em-de-Carvalho",
            "title": {
                "fragments": [],
                "text": "Reconhecimento de entidades mencionadas em portugu\u00eas utilizando aprendizado de m\u00e1quina"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 48
                            }
                        ],
                        "text": "We implemented CharWNN using the Theano library (Bergstra et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theano: a CPU and GPU math expression compiler"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Python for Scientific Computing Conference ( SciPy )"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Xavier Carreras, Llu\u00eds M` arques, and Llu\u00eds Padr\u00f3 Named entity extraction using adaboost"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of CoNLL-2002"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 49
                            }
                        ],
                        "text": "We implemented CharWNN using the Theano library (Bergstra et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "After scoring each word in the sentence, the predicted sequence is inferred with the Viterbi algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theano: a CPU and GPU math expression compiler"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Python for Scientific Computing Conference"
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 22,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Boosting-Named-Entity-Recognition-with-Neural-Santos-Guimar\u00e3es/91a93f751f912b2f96d6771018d8f06c41e11152?sort=total-citations"
}