{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107988"
                        ],
                        "name": "K. Abend",
                        "slug": "K.-Abend",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Abend",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Abend"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16998148"
                        ],
                        "name": "T. Harley",
                        "slug": "T.-Harley",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Harley",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Harley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2597670"
                        ],
                        "name": "L. Kanal",
                        "slug": "L.-Kanal",
                        "structuredName": {
                            "firstName": "Laveen",
                            "lastName": "Kanal",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kanal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1], [25] for the classification of binary random patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41486449,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "ac96d3aa381f6cbe05156c0030ae28082d3868bd",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "In various pattern-recognition problems such as classification of photographic data, preprocessing operations result in a two-dimensional array of binary random variables. An optimal recipe for classifying such patterns is described. It combines the use of an orthonormal expansion for the logarithm of probability functions, with the generation of a joint probability distribution from lower-order marginals. The unwieldy nature of the optimal recipe leads to the consideration of dependence represented by a Markov chain and a two-dimensional analog called a Markov mesh. The Markov chain has a \"reflecting\" property in that the r th order nonstationary chain implies that a point depends on its r nearest neighbors on each side. By scanning along a grid-filling curve so that the 2r neighbors of a point are geometrically close to it, certain spatial dependencies are obtained. The grid-filling curves are sequences of functions which have Hilbert \"space-filling\" curves as their limit. This simple approach does not provide for many of the spatial dependencies that should be considered. A novel extension of Markov chain methods into two dimensions leads to the Markov mesh which economically takes care of a much larger class of spatial dependencies. Likelihood ratio classification based on Markov chain and Markov mesh assumptions requires the estimation of a much smaller number of parameters than the general case. The development presented in this paper is new and need not be restricted to binary variables."
            },
            "slug": "Classification-of-binary-random-patterns-Abend-Harley",
            "title": {
                "fragments": [],
                "text": "Classification of binary random patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "A novel extension of Markov chain methods into two dimensions leads to the Markov mesh which economically takes care of a much larger class of spatial dependencies."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2038713"
                        ],
                        "name": "Chinching Yen",
                        "slug": "Chinching-Yen",
                        "structuredName": {
                            "firstName": "Chinching",
                            "lastName": "Yen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chinching Yen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071412"
                        ],
                        "name": "S. Kuo",
                        "slug": "S.-Kuo",
                        "structuredName": {
                            "firstName": "Shyh-shiaw",
                            "lastName": "Kuo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kuo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "To apply the HMM to images, previous work extended the 1-D HMM to a pseudo 2-D HMM [29], [51]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62711059,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d97639a8c37d4d155fa1a7d16a18a2300f9df298",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The Pseudo 2D Hidden Markov Model (PHMM), which is an extension of the 1D HMM, has been shown to be an effective approach in recognition of highly degraded and connected text. In this paper, the PHMM is extended to directly recognize poorly-printed gray-level document images. The performance of the system is further enhanced by the N-best hypotheses search, coupled with duration constraint. Experimental results show that the new system has significantly improved the performance when compared to a similar system using threshold binary images as inputs. The recognition rate improves from 97.7% in binary system to 99.9% in gray-level with modified N-best search, over a testing set with similar blur and noise condition as the training set. For a much more degraded testing set, it improves from 89.59% to 98.51%. This also demonstrates the robustness of the proposed system."
            },
            "slug": "Degraded-documents-recognition-using-pseudo-2D-in-Yen-Kuo",
            "title": {
                "fragments": [],
                "text": "Degraded documents recognition using pseudo-2D hidden Markov models in gray-scale images"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The Pseudo 2D Hidden Markov Model is extended to directly recognize poorly-printed gray-level document images to improve the performance when compared to a similar system using threshold binary images as inputs."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830639"
                        ],
                        "name": "K. Oehler",
                        "slug": "K.-Oehler",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Oehler",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Oehler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "I. INTRODUCTION\nFOR MOST block-based image classification algorithms,such as BVQ [43], images are divided into blocks, and decisions are made independently for the class of each block."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 11
                            }
                        ],
                        "text": "[36] K. L. Oehler and R. M. Gray, \u201cCombining image classification and image compression using vector quantization,\u201d inProc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "The segmentation of aerial images was also studied by Oehler [35] and Perlmutter [41]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "In both cases, the Bayes vector quantizer (BVQ) [35]\u2013[37], [41] is used as a classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 77
                            }
                        ],
                        "text": "[43] K. O. Perlmutter, S. M. Perlmutter, R. M. Gray, R. A. Olshen, and K. L. Oehler, \u201cBayes risk weighted vector quantization with posterior estimation for image compression and classification,\u201dIEEE Trans."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 11
                            }
                        ],
                        "text": "[35] K. L. Oehler, \u201cImage compression and classification using vector quantization,\u201d Ph.D. dissertation, Stanford Univ., Stanford, CA, 1993."
                    },
                    "intents": []
                }
            ],
            "corpusId": 117755978,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f84ddd123cf39413745f5ce90355daca5f79539",
            "isKey": true,
            "numCitedBy": 17,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Vector quantization is a lossy compression technique based on principles from statistical clustering. In this thesis, we present several vector quantization methods for compression and combined compression and classification of images. After a review of the basic ideas of image compression and vector quantization, we describe an image compression technique involving product vector quantization that uses three tree-structured codebooks to encode the mean, gain and shape features of vectors. Joint pruning of the codebooks is shown to provide optimal bit allocation among the features. The method provides low encoding complexity and reduced memory requirements while producing good coding performance. \nNext, the application of vector quantization to image classification is discussed. Vector quantization can perform block-based classification and compression simultaneously by associating a class label with each codeword. We present two methods of modifying traditional vector quantizer design algorithms to improve the classification ability of the quantizer. One approach modifies the tree-growing algorithm used for constructing tree-structured codebooks by incorporating classification information into the splitting criterion. The second approach explicitly incorporates a Bayes risk component into the distortion measure used for quantizer design, permitting a flexible trade-off between compression and classification priorities. These approaches are used to analyze simulated data, identify tumors in computerized tomography (CT) lung images, and identify man-made regions in aerial images."
            },
            "slug": "Image-compression-and-classification-using-vector-Oehler",
            "title": {
                "fragments": [],
                "text": "Image compression and classification using vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An image compression technique involving product vector quantization that uses three tree-structured codebooks to encode the mean, gain and shape features of vectors and presents two methods of modifying traditional vector quantizer design algorithms to improve the classification ability of the quantizer."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922810"
                        ],
                        "name": "P. Devijver",
                        "slug": "P.-Devijver",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Devijver",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Devijver"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123597688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0143529ecf5170561c1e42a9fde37459e8178c89",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The image modeling problem is discussed under the assumption that images can be represented by third-order. hidden Markov mesh random field models. The modeling applications comprise restoration of binary images, compression of image data, and segmentation of gray-level images and image sequences under the short-range motion hypothesis. Coherent approaches to the problems of image modeling and estimation of model parameters are outlined. A labeling algorithm based on a maximum marginal a posteriori probability criterion is proposed. Critical aspects of the computer simulation of a real-time implementation are discussed in detail. A learning technique by which the model parameters can be estimated without ground truth information is developed. Extensive experimentation with both static and dynamic images from a variety of sources is discussed.<<ETX>>"
            },
            "slug": "Real-time-modeling-of-image-sequences-based-on-mesh-Devijver",
            "title": {
                "fragments": [],
                "text": "Real-time modeling of image sequences based on hidden Markov mesh random field models"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The image modeling problem is discussed under the assumption that images can be represented by third-order models, and a labeling algorithm based on a maximum marginal a posteriori probability criterion is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings. 10th International Conference on Pattern Recognition"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071412"
                        ],
                        "name": "S. Kuo",
                        "slug": "S.-Kuo",
                        "structuredName": {
                            "firstName": "Shyh-shiaw",
                            "lastName": "Kuo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kuo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752802"
                        ],
                        "name": "O. Agazzi",
                        "slug": "O.-Agazzi",
                        "structuredName": {
                            "firstName": "Oscar",
                            "lastName": "Agazzi",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Agazzi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "In particular applications, this model works better than the 1-D HMM [29], but we expect the pseudo 2-D HMM to be much"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "To apply the HMM to images, previous work extended the 1-D HMM to a pseudo 2-D HMM [29], [51]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 57574959,
            "fieldsOfStudy": [
                "Economics",
                "Computer Science"
            ],
            "id": "b19cc31a6afa210fbc7fe2cb6239a480bf7b212a",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for robust machine recognition of keywords embedded in a poorly printed document is presented. For each keyword, two statistical models, called pseudo-2D hidden Markov models (P2-DHMMs), are created for representing the actual keyword and all the other extraneous words, respectively. Dynamic programming is then used for matching an unknown input word with the two models and making a maximum likelihood decision. Although the models are pseudo 2-D in the sense that they are not fully connected 2-D networks, they are shown to be general enough to characterize printed words efficiently. These models facilitate a nice 'elastic matching' property in both horizontal and vertical directions, which makes the recognizer not only independent of size and slant but also tolerant of highly deformed and noisy words. The system is evaluated on a synthetically created database which contains about 26000 words. A recognition accuracy of 99% is achieved when words in testing and training sets are in the same font size. An accuracy of 96% is achieved when they are in different sizes. In the latter case, the conventional 1-D HMM approach achieves only 70% accuracy rate.<<ETX>>"
            },
            "slug": "Machine-vision-for-keyword-spotting-using-pseudo-2D-Kuo-Agazzi",
            "title": {
                "fragments": [],
                "text": "Machine vision for keyword spotting using pseudo 2D hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "An algorithm for robust machine recognition of keywords embedded in a poorly printed document is presented, where two statistical models, called pseudo-2D hidden Markov models (P2-DHMMs), are created for representing the actual keyword and all the other extraneous words, respectively."
            },
            "venue": {
                "fragments": [],
                "text": "1993 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830639"
                        ],
                        "name": "K. Oehler",
                        "slug": "K.-Oehler",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Oehler",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Oehler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20716245,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff10f5d4595a8d0e5a8e4b4bde2bf0afe2498482",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal is to produce codes where the compressed image incorporates classification information without further signal processing. This technique can provide direct low level classification or an efficient front end to more sophisticated full-frame recognition algorithms. Vector quantization is a natural choice because two of its design components, clustering and tree-structured classification methods, have obvious applications to the pure classification problem as well as to the compression problem. The authors explicitly incorporate a Bayes risk component into the distortion measure used for code design in order to permit a tradeoff of mean squared error with classification error. This method is used to analyze simulated data, identify tumors in computerized tomography lung images, and identify man-made regions in aerial images.<<ETX>>"
            },
            "slug": "Combining-image-classification-and-image-using-Oehler-Gray",
            "title": {
                "fragments": [],
                "text": "Combining image classification and image compression using vector quantization"
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] DCC `93: Data Compression Conference"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145058181"
                        ],
                        "name": "H. Hon",
                        "slug": "H.-Hon",
                        "structuredName": {
                            "firstName": "Hsiao-Wuen",
                            "lastName": "Hon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144091892"
                        ],
                        "name": "M. Hwang",
                        "slug": "M.-Hwang",
                        "structuredName": {
                            "firstName": "Mei-Yuh",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hwang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144531812"
                        ],
                        "name": "Xuedong Huang",
                        "slug": "Xuedong-Huang",
                        "structuredName": {
                            "firstName": "Xuedong",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuedong Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12811393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23f4d6cb373c00df5a6f8eb35a47ba1906a28940",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speech-recognition-using-hidden-Markov-models:-A-Lee-Hon",
            "title": {
                "fragments": [],
                "text": "Speech recognition using hidden Markov models: A CMU perspective"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13983488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9109aea1c445de7a607c6c17736209bc7d897cef",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an algorithm to segment text and picture in an image using two features based on the statistical distribution of the wavelet coefficients in high frequency bands. The algorithm breaks the image into blocks and classifies every block as background, text or picture according to the two features. The block size is variable so that the segmentation can be accurate at the boundary of two types and avoids misclassifying due to over-localized region analysis."
            },
            "slug": "Text-and-picture-segmentation-by-the-distribution-Li-Gray",
            "title": {
                "fragments": [],
                "text": "Text and picture segmentation by the distribution analysis of wavelet coefficients"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents an algorithm to segment text and picture in an image using two features based on the statistical distribution of the wavelet coefficients in high frequency bands that can be accurate at the boundary of two types and avoids misclassifying due to over-localized region analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1998 International Conference on Image Processing. ICIP98 (Cat. No.98CB36269)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2437784"
                        ],
                        "name": "K. Perlmutter",
                        "slug": "K.-Perlmutter",
                        "structuredName": {
                            "firstName": "Keren",
                            "lastName": "Perlmutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Perlmutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693680"
                        ],
                        "name": "N. Chaddha",
                        "slug": "N.-Chaddha",
                        "structuredName": {
                            "firstName": "Navin",
                            "lastName": "Chaddha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Chaddha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2895664"
                        ],
                        "name": "J. B. Buckheit",
                        "slug": "J.-B.-Buckheit",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Buckheit",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. B. Buckheit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "In [41] and [42], the Bayes VQ algorithm is applied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "Previous work on gray-scale document image segmentation includes Chaddha [11], Williams [49], Perlmutter [41], [42], and"
                    },
                    "intents": []
                }
            ],
            "corpusId": 15833968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4da525d97a3468f4406e4b80130cc6d356a73c5d",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Multimedia applications such as educational videos and color facsimile contain images that are rich in both textual and continuous tone data. Because these two types of data have different properties, segmentation of the images into text and continuous tone data can improve compression by allowing different compression parameters or even algorithms to be employed on the different types. We propose and compare algorithms that use classification trees (CLTR) or tree-structured vector quantization (TSVQ) for block-based classification in mixed-mode images. We also examine different types of features that can be used in these classifiers. The results show that using linear transform features with either the CLTR or TSVQ can be effective for accurate text classification. In addition, the results indicate that combining these classifiers with another TSVQ that is designed simultaneously to minimize both compression and classification error can provide better classification than does either system alone."
            },
            "slug": "Text-segmentation-in-mixed-mode-images-using-trees-Perlmutter-Chaddha",
            "title": {
                "fragments": [],
                "text": "Text segmentation in mixed-mode images using classification trees and transform tree-structured vector quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Algorithms that use classification trees (CLTR) or tree-structured vector quantization (TSVQ) for block-based classification in mixed-mode images and results indicate that combining these classifiers with another TSVQ that is designed simultaneously to minimize both compression and classification error can provide better classification than does either system alone."
            },
            "venue": {
                "fragments": [],
                "text": "1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16388265,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "515966ebc3adec9a7740526fbee997937aaa234f",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A variety of computer vision problems can be optimally posed as Bayesian labeling in which the solution of a problem is defined as the maximum a posteriori (MAP) probability estimate of the true labeling. The posterior probability is usually derived from a prior model and a likelihood model. The latter relates to how data is observed and is problem domain dependent. The former depends on how various prior constraints are expressed. Markov Random Field Models (MRF) theory is a tool to encode contextual constraints into the prior probability. This paper presents a unified approach for MRF modeling in low and high level computer vision. The unification is made possible due to a recent advance in MRF modeling for high level object recognition. Such unification provides a systematic approach for vision modeling based on sound mathematical principles."
            },
            "slug": "Markov-Random-Field-Models-in-Computer-Vision-Li",
            "title": {
                "fragments": [],
                "text": "Markov Random Field Models in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A unified approach for Markov Random Field Models modeling in low and high level computer vision is presented, made possible due to a recent advance in MRF modeling for high level object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40116905"
                        ],
                        "name": "Jia Li",
                        "slug": "Jia-Li",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Previous work [19], [31] has looked into ways of taking advantage of context information to improve classification performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16659414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ddb1c0aeab01f9756b6998b709080aaee1da70d0",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an algorithm to segment images into four classes: background, photograph, text and graph. There are two important aspects about the algorithm. The first is that the algorithm takes a multiscale approach, which adaptively classifies an image at different resolutions. The multiscale structure enables accurate classification at class boundaries as well as fast classification overall. The second is that the context information, which is accumulated in the process of classification, is used to improve the classification accuracy."
            },
            "slug": "Context-based-multiscale-classification-of-images-Li-Gray",
            "title": {
                "fragments": [],
                "text": "Context based multiscale classification of images"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "An algorithm to segment images into four classes: background, photograph, text and graph is presented, which adaptively classifies an image at different resolutions and helps improve the classification accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1998 International Conference on Image Processing. ICIP98 (Cat. No.98CB36269)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113099456"
                        ],
                        "name": "Moonseo Park",
                        "slug": "Moonseo-Park",
                        "structuredName": {
                            "firstName": "Moonseo",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Moonseo Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145780619"
                        ],
                        "name": "David J. Miller",
                        "slug": "David-J.-Miller",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Miller",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Miller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 158
                            }
                        ],
                        "text": "D HMM\u2019s includes an algorithm for character recognition developed by Levin and Pieraccini [30] and an image decoding system over noisy channels constructed by Park and Miller [39]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 23
                            }
                        ],
                        "text": "[39] M. Park and D. J. Miller, \u201cImage decoding over noisy channels using minimum mean-squared estimation and a Markov mesh,\u201d inProc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [39], 2-D HMM\u2019s with Markov meshes are used to model noisy channels, in which case, un-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 197
                            }
                        ],
                        "text": "Other work based on 2-D HMM\u2019s includes an algorithm for character recognition developed by Levin and Pieraccini [30] and an image decoding system over noisy channels constructed by Park and Miller [39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45307048,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a14e4a1abf4cf767e51c39202b70833887fb61ab",
            "isKey": true,
            "numCitedBy": 9,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, we developed a sequence-based minimum mean-squared error (MMSE) estimator for decoding quantized data transmitted over noisy channels. The method effectively views the encoder and noisy channel tandem as a discrete hidden Markov model (HMM), with transmitted indices the unknown states and received indices the observable symbols. Here, we extend this 1D approach to images, using a Markov mesh random field to model the encoded image. Our decoder is based on an approximate forward/backward algorithm for calculating pixel \"label probabilities\" in Markov meshes which may also have application to image labeling and segmentation. For a DPCM-based image coding system and a high error-rate channel, the new decoder obtains significant performance gains, both objective and visually discernable, over the standard decoder, as well as over several other competing techniques."
            },
            "slug": "Image-decoding-over-noisy-channels-using-minimum-a-Park-Miller",
            "title": {
                "fragments": [],
                "text": "Image decoding over noisy channels using minimum mean-squared estimation and a Markov mesh"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work extends the 1D approach to images, using a Markov mesh random field to model the encoded image, and develops a sequence-based minimum mean-squared error estimator for decoding quantized data transmitted over noisy channels."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119559470"
                        ],
                        "name": "J. Hynninen",
                        "slug": "J.-Hynninen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Hynninen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hynninen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145800809"
                        ],
                        "name": "J. Kangas",
                        "slug": "J.-Kangas",
                        "structuredName": {
                            "firstName": "Jari",
                            "lastName": "Kangas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kangas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708642"
                        ],
                        "name": "Jorma T. Laaksonen",
                        "slug": "Jorma-T.-Laaksonen",
                        "structuredName": {
                            "firstName": "Jorma",
                            "lastName": "Laaksonen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorma T. Laaksonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770190"
                        ],
                        "name": "K. Torkkola",
                        "slug": "K.-Torkkola",
                        "structuredName": {
                            "firstName": "Kari",
                            "lastName": "Torkkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Torkkola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "To compare with LVQ1, we used programs provided by the LVQ_PAK software package [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "[10] and the first version of Kohonen's learning vector quantization (LVQ) algorithm [27], [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61074380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd5823a0d1edd6d913f0531874174ff548495b5f",
            "isKey": false,
            "numCitedBy": 333,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning Vector Quantization (LVQ) is a group of algorithms applicable to statistical pattern recognition, in which the classes are described by a relatively small number of codebook vectors, properly placed within each zone such that the decision borders are approximated by the nearest-neighbor rule. The LVQ PAK program package contains all programs necessary for the correct application of certain Learning Vector Quantization algorithms in an arbitrary statistical classiication or pattern recognition task, as well as a program for the monitoring of the codebook vectors at any time during the learning process. The rst version 1.0 of this program package was published in 1991 and since then the package has been updated regularly to include latest improvements in the LVQ implementations. This report that contains the last documentation was prepared for bibliographical purposes."
            },
            "slug": "LVQ_PAK:-The-Learning-Vector-Quantization-Program-Kohonen-Hynninen",
            "title": {
                "fragments": [],
                "text": "LVQ_PAK: The Learning Vector Quantization Program Package"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The LVQ PAK program package contains all programs necessary for the correct application of certain Learning Vector Quantization algorithms in an arbitrary statistical classiication or pattern recognition task, as well as a program for the monitoring of the codebook vectors at any time during the learning process."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830639"
                        ],
                        "name": "K. Oehler",
                        "slug": "K.-Oehler",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Oehler",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Oehler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30174001,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bde43668a483bb270e79dcfe6e57e62d8b9fc3cd",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method of combining classification and compression into a single vector quantizer by incorporating a Bayes risk term into the distortion measure used in the quantizer design algorithm. Once trained, the quantizer can operate to minimize the Bayes risk weighted distortion measure if there is a model providing the required posterior probabilities, or it can operate in a suboptimal fashion by minimizing the squared error only. Comparisons are made with other vector quantizer based classifiers, including the independent design of quantization and minimum Bayes risk classification and Kohonen's LVQ. A variety of examples demonstrate that the proposed method can provide classification ability close to or superior to learning VQ while simultaneously providing superior compression performance. >"
            },
            "slug": "Combining-Image-Compression-and-Classification-Oehler-Gray",
            "title": {
                "fragments": [],
                "text": "Combining Image Compression and Classification Using Vector Quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A variety of examples demonstrate that the proposed method can provide classification ability close to or superior to learning VQ while simultaneously providing superior compression performance."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748118"
                        ],
                        "name": "J. Bilmes",
                        "slug": "J.-Bilmes",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Bilmes",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bilmes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 822242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a5fa1ea14cea5e55e4e1f844f78332fccefa285",
            "isKey": false,
            "numCitedBy": 2912,
            "numCiting": 187,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the maximum-likelihood parameter estimation problem and how the ExpectationMaximization (EM) algorithm can be used for its solution. We first describe the abstract form of the EM algorithm as it is often given in the literature. We then develop the EM parameter estimation procedure for two applications: 1) finding the parameters of a mixture of Gaussian densities, and 2) finding the parameters of a hidden Markov model (HMM) (i.e., the Baum-Welch algorithm) for both discrete and Gaussian mixture observation models. We derive the update equations in fairly explicit detail but we do not prove any convergence properties. We try to emphasize intuition rather than mathematical rigor."
            },
            "slug": "A-gentle-tutorial-of-the-em-algorithm-and-its-to-Bilmes",
            "title": {
                "fragments": [],
                "text": "A gentle tutorial of the em algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The abstract form of the EM algorithm as it is often given in the literature is described and the EM parameter estimation procedure is developed for two applications: 1) finding the parameters of a mixture of Gaussian densities, and 2) finding a hidden Markov model (HMM) for both discrete and Gaussian mixture observation models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693680"
                        ],
                        "name": "N. Chaddha",
                        "slug": "N.-Chaddha",
                        "structuredName": {
                            "firstName": "Navin",
                            "lastName": "Chaddha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Chaddha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153216710"
                        ],
                        "name": "R. Sharma",
                        "slug": "R.-Sharma",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075308385"
                        ],
                        "name": "A. Agrawal",
                        "slug": "A.-Agrawal",
                        "structuredName": {
                            "firstName": "Avneesh",
                            "lastName": "Agrawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041740460"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 26
                            }
                        ],
                        "text": "[42] K. O. Perlmutter, N. Chaddha, J. B. Buckheit, R. M. Gray, and R. A. Olshen, \u201cText segmentation in mixed-mode images using classification trees and transform tree-structured vector quantization,\u201d inProc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "Previous work on gray-scale document image segmentation includes Chaddha [11], Williams [49], Perlmutter [41], [42], and Ohuchi [38]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "Previous work on gray-scale document image segmentation includes Chaddha [11], Williams [49], Perlmutter [41], [42], and"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 8
                            }
                        ],
                        "text": "[11] N. Chaddha, R. Sharma, A. Agrawal, and A. Gupta, \u201cText segmentation in mixed-mode images,\u201d inProc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "Thresholding is used to distinguish image types in [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58358347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9754dba62f5a329c9dd64b7d091c7900f489f5f0",
            "isKey": true,
            "numCitedBy": 50,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Block based algorithms have found widespread use in image and video compression. However, popular algorithms such as JPEG, which are very effective in compressing continuous tone images, do not perform well with mixed-mode images which have a substantial text component. With a growing number of applications where such images occur, e.g., color facsimile, digital libraries and educational videos, there are advantages in being able to classify each block as being text or continuous tone. With such a classification, different compression parameters or even algorithms may be employed for the two kinds of data to obtain high compression with minimal loss in visual quality. In this paper we analyze and compare four methods for block classification in mixed mode images, namely variance, absolute-deviation, edge, and DCT based methods. Our evaluation of each scheme is based on the accuracy of segmentation, robustness across different types of images and sensitivity to the threshold used for segmentation. Our results show that DCT based segmentation offers the best accuracy and robustness. Another advantage of DCT is that it is compatible with standards like JPEG, MPEG and H.261.<<ETX>>"
            },
            "slug": "Text-segmentation-in-mixed-mode-images-Chaddha-Sharma",
            "title": {
                "fragments": [],
                "text": "Text segmentation in mixed-mode images"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This paper analyzes and compares four methods for block classification in mixed mode images, namely variance, absolute-deviation, edge, and DCT based methods, and shows that DCTbased segmentation offers the best accuracy and robustness."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1994 28th Asilomar Conference on Signals, Systems and Computers"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2437784"
                        ],
                        "name": "K. Perlmutter",
                        "slug": "K.-Perlmutter",
                        "structuredName": {
                            "firstName": "Keren",
                            "lastName": "Perlmutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Perlmutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48274852"
                        ],
                        "name": "S. Perlmutter",
                        "slug": "S.-Perlmutter",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Perlmutter",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Perlmutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830639"
                        ],
                        "name": "K. Oehler",
                        "slug": "K.-Oehler",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Oehler",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Oehler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "FOR MOST block-based image classification algorithms, such as BVQ [43], images are divided into blocks, and decisions are made independently for the class of each block."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "I. INTRODUCTION\nFOR MOST block-based image classification algorithms,such as BVQ [43], images are divided into blocks, and decisions are made independently for the class of each block."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "In both cases, the Bayes vector quantizer (BVQ) [35]\u2013[37], [41] is used as a classifier."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18812014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f44a167893fc94fea47d7156413745550b4a68ba",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification and compression play important roles in communicating digital information. Their combination is useful in many applications, including the detection of abnormalities in compressed medical images. In view of the similarities of compression and low-level classification, it is not surprising that there are many similar methods for their design. Because some of these methods are useful for designing vector quantizers, it seems natural that vector quantization (VQ) is explored for the combined goal. We investigate several VQ-based algorithms that seek to minimize both the distortion of compressed images and errors in classifying their pixel blocks. These algorithms are investigated with both full search and tree-structured codes. We emphasize a nonparametric technique that minimizes both error measures simultaneously by incorporating a Bayes risk component into the distortion measure used for the design and encoding. We introduce a tree-structured posterior estimator to produce the class posterior probabilities required for the Bayes risk computation in this design. For two different image sources, we demonstrate that this system provides superior classification while maintaining compression close or superior to that of several other VQ-based designs, including Kohonen's (1992) \"learning vector quantizer\" and a sequential quantizer/classifier design."
            },
            "slug": "Bayes-risk-weighted-vector-quantization-with-for-Perlmutter-Perlmutter",
            "title": {
                "fragments": [],
                "text": "Bayes risk weighted vector quantization with posterior estimation for image compression and classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work investigates several VQ-based algorithms that seek to minimize both the distortion of compressed images and errors in classifying their pixel blocks and introduces a tree-structured posterior estimator to produce the class posterior probabilities required for the Bayes risk computation in this design."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107182763"
                        ],
                        "name": "P. S. Williams",
                        "slug": "P.-S.-Williams",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Williams",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. S. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35739641"
                        ],
                        "name": "M. Alder",
                        "slug": "M.-Alder",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Alder",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Alder"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 11
                            }
                        ],
                        "text": "[49] P. S. Williams and M. D. Alder, \u201cGeneric texture analysis applied to newspaper segmentation,\u201d inProc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [49], a modified quadratic neural network [34] is used for classifying features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "Previous work on gray-scale document image segmentation includes Chaddha [11], Williams [49], Perlmutter [41], [42], and"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 79
                            }
                        ],
                        "text": "Previous work on gray-scale document image segmentation includes Chaddha [11], Williams [49], Perlmutter [41], [42], and Ohuchi [38]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16115695,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "60f9a70b46a4f1007bb04144da0a92e3033de419",
            "isKey": true,
            "numCitedBy": 25,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper deals with the segmentation of grey-scale newspaper images into the distinct regions of text, picture and background. Feature vectors are obtained from the image by analysing localised textual characteristics and textual variation. Analysis is performed in a generic way making few contextual assumptions. The contrast, size, orientation and resolution of the image are accounted for by a combination of this feature extraction process and subsequent parametrisation. Given such implicit invariance we are able to perform an initial point based classification through the use of a modified quadratic neural network. The use of a simple flood fill based algorithm allows the successful segmentation of newspaper images into distinct rectangular regions. Results of newspaper segmentation show the effectiveness of these methods."
            },
            "slug": "Generic-texture-analysis-applied-to-newspaper-Williams-Alder",
            "title": {
                "fragments": [],
                "text": "Generic texture analysis applied to newspaper segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper deals with the segmentation of grey-scale newspaper images into the distinct regions of text, picture and background through the use of a modified quadratic neural network and results show the effectiveness of these methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Neural Networks (ICNN'96)"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992604"
                        ],
                        "name": "E. Levin",
                        "slug": "E.-Levin",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115311"
                        ],
                        "name": "R. Pieraccini",
                        "slug": "R.-Pieraccini",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Pieraccini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pieraccini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 68
                            }
                        ],
                        "text": "D HMM\u2019s includes an algorithm for character recognition developed by Levin and Pieraccini [30] and an image decoding system over noisy channels constructed by Park and Miller [39]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Other work based on 2-D HMM\u2019s includes an algorithm for character recognition developed by Levin and Pieraccini [30] and an image decoding system over noisy channels constructed by Park and Miller [39]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 21
                            }
                        ],
                        "text": "[30] E. Levin and R. Pieraccini, \u201cDynamic planar warping for optical character recognition,\u201d inProc."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61529100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69f361375d71c8f4663f70f47bada4cedd7254a0",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors extend the dynamic time warping (DTW) algorithm, widely used in automatic speech recognition (ASR), to a dynamic plane warping (DPW) algorithm, for application in the field of optical character recognition (OCR) or similar applications. Although direct application of the optimality principle reduced the computational complexity somewhat, the DPW (or image alignment) problem is exponential in the dimensions of the image. It is shown that by applying constraints to the image alignment problem, e.g., limiting the class of possible distortions, one can reduce the computational complexity dramatically, and find the optimal solution to the constrained problem in linear time. A statistical model, the planar hidden Markov model (PHMM), describing statistical properties of images is proposed. The PHMM approach was evaluated using a set of isolated handwritten digits. An overall digit recognition accuracy of 95% was achieved. It is expected that the advantage of this approach will be even more significant for harder tasks, such cursive-writing recognition and spotting.<<ETX>>"
            },
            "slug": "Dynamic-planar-warping-for-optical-character-Levin-Pieraccini",
            "title": {
                "fragments": [],
                "text": "Dynamic planar warping for optical character recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The authors extend the dynamic time warping algorithm, widely used in automatic speech recognition (ASR), to a dynamic plane warping (DPW) algorithm, for application in the field of optical character recognition (OCR) or similar applications."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922810"
                        ],
                        "name": "P. Devijver",
                        "slug": "P.-Devijver",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Devijver",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Devijver"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117976876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93e573990a777deff02399406e953a268beecf28",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "PROBABILISTIC-LABELING-IN-A-HIDDEN-SECOND-ORDER-Devijver",
            "title": {
                "fragments": [],
                "text": "PROBABILISTIC LABELING IN A HIDDEN SECOND ORDER MARKOV MESH"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "We point out that the underlying state process defined is a special case of a Markov random field (MRF) [21], [26], which was referred to as Markov mesh and proposed by Abend et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5837272,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "459b30a9a960080f3b313e41886b1aa0e51e882c",
            "isKey": false,
            "numCitedBy": 18710,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios."
            },
            "slug": "Stochastic-Relaxation,-Gibbs-Distributions,-and-the-Geman-Geman",
            "title": {
                "fragments": [],
                "text": "Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The analogy between images and statistical mechanics systems is made and the analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations, creating a highly parallel ``relaxation'' algorithm for MAP estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17743203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df682aa90fbbbf665a8b273a57ca87d6cea9ff99",
            "isKey": false,
            "numCitedBy": 1561,
            "numCiting": 117,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of hidden Markov models for speech recognition has become predominant in the last several years, as evidenced by the number of published papers and talks at major speech conferences. The reasons this method has become so popular are the inherent statistical (mathematically precise) framework; the ease and availability of training algorithms for cstimating the parameters of the models from finite training sets of speech data; the flexibility of the resulting recognition system in which one can easily change the size, type, or architecture of the models to suit particular words, sounds, and so forth; and the ease of implementation of the overall recognition system. In this expository article, we address the role of statistical methods in this powerful technology as applied to speech recognition and discuss a range of theoretical and practical issues that are as yet unsolved in terms of their importance and their effect on performance for different system implementations."
            },
            "slug": "Hidden-Markov-Models-for-Speech-Recognition-Juang-Rabiner",
            "title": {
                "fragments": [],
                "text": "Hidden Markov Models for Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The role of statistical methods in this powerful technology as applied to speech recognition is addressed and a range of theoretical and practical issues that are as yet unsolved in terms of their importance and their effect on performance for different system implementations are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2597670"
                        ],
                        "name": "L. Kanal",
                        "slug": "L.-Kanal",
                        "structuredName": {
                            "firstName": "Laveen",
                            "lastName": "Kanal",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kanal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "[1], [25] for the classification of binary random patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "The Markov mesh is called a \u201ccausal\u201d MRF [7], [25], [44] because"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62588662,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b887804561c6ea880fc7bad899272c3a06b9dfa",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Markov-mesh-models-Kanal",
            "title": {
                "fragments": [],
                "text": "Markov mesh models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5768521"
                        ],
                        "name": "G. Barna",
                        "slug": "G.-Barna",
                        "structuredName": {
                            "firstName": "Gy\u00f6rgy",
                            "lastName": "Barna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Barna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693259"
                        ],
                        "name": "Ron Chrisley",
                        "slug": "Ron-Chrisley",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Chrisley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ron Chrisley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "[10] and the first version of Kohonen's learning vector quantization (LVQ) algorithm [27], [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17154105,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6666e8358eed45caf93ada4272f8d63bb1b6b705",
            "isKey": false,
            "numCitedBy": 512,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Three basic types of neural-like networks (backpropagation network, Boltzmann machine, and learning vector quantization), were applied to two representative artificial statistical pattern recognition tasks, each with varying dimensionality. The performance of each network's approach to solving the tasks was evaluated and compared, both to the performance of the other two networks and to the theoretical limit. The learning vector quantization was further benchmarked against the parametric Bayes classifier and the k-nearest-neighbor classifier using natural speech data. A novel learning vector quantization classifier called LVQ2 is introduced.<<ETX>>"
            },
            "slug": "Statistical-pattern-recognition-with-neural-studies-Kohonen-Barna",
            "title": {
                "fragments": [],
                "text": "Statistical pattern recognition with neural networks: benchmarking studies"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Three basic types of neural-like networks, backpropagation network, Boltzmann machine, and learning vector quantization, were applied to two representative artificial statistical pattern recognition tasks, each with varying dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE 1988 International Conference on Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111535467"
                        ],
                        "name": "C. F. Wu",
                        "slug": "C.-F.-Wu",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Wu",
                            "middleNames": [
                                "F.",
                                "Jeff"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. F. Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18275955,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "acd7d08468e6dd7234d474860ab64d5a33cacfdc",
            "isKey": false,
            "numCitedBy": 3271,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Two convergence aspects of the EM algorithm are studied: (i) does the EM algorithm find a local maximum or a stationary value of the (incompletedata) likelihood function? (ii) does the sequence of parameter estimates generated by EM converge? Several convergence results are obtained under conditions that are applicable to many practical situations. Two useful special cases are: (a) if the unobserved complete-data specification can be described by a curved exponential family with compact parameter space, all the limit points of any EM sequence are stationary points of the likelihood function; (b) if the likelihood function is unimodal and a certain differentiability condition is satisfied, then any EM sequence converges to the unique maximum likelihood estimate. A list of key properties of the algorithm is included."
            },
            "slug": "ON-THE-CONVERGENCE-PROPERTIES-OF-THE-EM-ALGORITHM-Wu",
            "title": {
                "fragments": [],
                "text": "ON THE CONVERGENCE PROPERTIES OF THE EM ALGORITHM"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2910083"
                        ],
                        "name": "C. H. Fosgate",
                        "slug": "C.-H.-Fosgate",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fosgate",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. H. Fosgate"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145087510"
                        ],
                        "name": "H. Krim",
                        "slug": "H.-Krim",
                        "structuredName": {
                            "firstName": "Hamid",
                            "lastName": "Krim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Krim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701607"
                        ],
                        "name": "A. Willsky",
                        "slug": "A.-Willsky",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Willsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Willsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145325413"
                        ],
                        "name": "W. Karl",
                        "slug": "W.-Karl",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Karl",
                            "middleNames": [
                                "Clem"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Karl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Previous work [19], [31] has looked into ways of taking advantage of context information to improve classification performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5884115,
            "fieldsOfStudy": [
                "Mathematics",
                "Environmental Science"
            ],
            "id": "516041eadcd7c6701b0e18247df411a2dddd77cd",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an efficient multiscale approach to the segmentation of natural clutter, specifically grass and forest, in synthetic aperture imagery (SAR) and to the enhancement of anomalous image regions therein. The methods we propose exploit the coherent nature of SAR sensors. In particular, they characterize the scale-to-scale statistical differences in imagery of various terrain categories due to radar speckle. To achieve this, we employ a recently introduced class of multiscale stochastic processes that provide a powerful framework for describing random processes and fields that evolve in scale. We build models representative of each relevant category of terrain and use them to direct subsequent decisions on pixel classification, segmentation, and anomaly presence."
            },
            "slug": "Multiscale-segmentation-and-anomaly-enhancement-of-Fosgate-Krim",
            "title": {
                "fragments": [],
                "text": "Multiscale segmentation and anomaly enhancement of SAR imagery"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "An efficient multiscale approach to the segmentation of natural clutter in synthetic aperture imagery (SAR) and to the enhancement of anomalous image regions therein is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd IEEE International Conference on Image Processing"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "For details, see any of the references on speech recognition [23], [40], [45], [52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "HMM\u2019s have earned their popularity in large part from successful application to speech recognition [2], [12], [23], [40], [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59739469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0be6ab93a635f1582f32dd9cc255cc7450ee581d",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The Lincoln robust hidden Markov model speech recognizer currently provides state-of-the-art performance for both speaker-dependent and speaker-independent large-vocabulary continuous-speech recognition. An early isolated-word version similarly improved the state of the art on a speaker-stress-robustness isolated-word task. This article combines hidden Markov model and speech recognition tutorials with a description of the above recognition systems."
            },
            "slug": "Speech-Recognition-Using-Hidden-Markov-Models-Paul",
            "title": {
                "fragments": [],
                "text": "Speech Recognition Using Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The Lincoln robust hidden Markov model speech recognizer currently provides state-of-the-art performance for both speaker-dependent and speaker-independent large-vocabulary continuous-speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103072546"
                        ],
                        "name": "J. Eagon",
                        "slug": "J.-Eagon",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Eagon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eagon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14153120,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "69fc8c03d21e22e30d6642824c37158b314f36c3",
            "isKey": false,
            "numCitedBy": 1122,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Summary. The object of this note is to prove the theorem below and sketch two applications, one to statistical estimation for (proba-bilistic) functions of Markov processes [l] and one to Blakley's model for ecology [4]. 2. Result. THEOREM. Let P(x)=P({xij}) be a polynomial with nonnegative coefficients homogeneous of degree d in its variables {##}. Let x= {##} be any point of the domain D: ## \u00a7:(), ]pLi ## = 1, i = l, \u2022 \u2022 \u2022 , p, j=l, \u2022 \u2022 \u2022 , q%. For x= {xij} \u00a3\u00a3> let 3(#) = 3{##} denote the point of D whose i, j coordinate is (dP\\ \\ f \u00ab dP 3(*)<i = (Xij 7\u2014) / 2* *<i \u2014 \\ dXij\\(X)// ,-i dXij (\u00bb> Then P(3(x))>P(x) unless 3(x)=x. Notation, fi will denote a doubly indexed array of nonnegative integers: fx= {M#}> i = l> \u2022 \u2022 \u2022 > <lu i=l, \u2022 \u2022 \u2022 , A #* then denotes Ilf-iH\u00ee-i^* Similarly, c M is an abbreviation for C[ MiJ }. The polynomial P({xij}) is then written P(x) = ]CM V^-In our notation : (1) 3(&)*i = (Z) \u00abWnys*) / JLH CpiiijX\u00bb."
            },
            "slug": "An-inequality-with-applications-to-statistical-for-Baum-Eagon",
            "title": {
                "fragments": [],
                "text": "An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678771"
                        ],
                        "name": "P. Bickel",
                        "slug": "P.-Bickel",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bickel",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2934481"
                        ],
                        "name": "K. Doksum",
                        "slug": "K.-Doksum",
                        "structuredName": {
                            "firstName": "Kjell",
                            "lastName": "Doksum",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Doksum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 166
                            }
                        ],
                        "text": "It is known that for Gaussian distributions, the ML estimate of is the sample average of the data, and the ML estimate of is the sample covariance matrix of the data [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120450474,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "92d92fd3de1af6a46e8cd9ca841d5433e659179f",
            "isKey": false,
            "numCitedBy": 1456,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "(NOTE: Each chapter concludes with Problems and Complements, Notes, and References.) 1. Statistical Models, Goals, and Performance Criteria. Data, Models, Parameters, and Statistics. Bayesian Models. The Decision Theoretic Framework. Prediction. Sufficiency. Exponential Families. 2. Methods of Estimation. Basic Heuristics of Estimation. Minimum Contrast Estimates and Estimating Equations. Maximum Likelihood in Multiparameter Exponential Families. Algorithmic Issues. 3. Measures of Performance. Introduction. Bayes Procedures. Minimax Procedures. Unbiased Estimation and Risk Inequalities. Nondecision Theoretic Criteria. 4. Testing and Confidence Regions. Introduction. Choosing a Test Statistic: The Neyman-Pearson Lemma. Uniformly Most Powerful Tests and Monotone Likelihood Ratio Models. Confidence Bounds, Intervals and Regions. The Duality between Confidence Regions and Tests. Uniformly Most Accurate Confidence Bounds. Frequentist and Bayesian Formulations. Prediction Intervals. Likelihood Ratio Procedures. 5. Asymptotic Approximations. Introduction: The Meaning and Uses of Asymptotics. Consistency. First- and Higher-Order Asymptotics: The Delta Method with Applications. Asymptotic Theory in One Dimension. Asymptotic Behavior and Optimality of the Posterior Distribution. 6. Inference in the Multiparameter Case. Inference for Gaussian Linear Models. Asymptotic Estimation Theory in p Dimensions. Large Sample Tests and Confidence Regions. Large Sample Methods for Discrete Data. Generalized Linear Models. Robustness Properties and Semiparametric Models. Appendix A: A Review of Basic Probability Theory. The Basic Model. Elementary Properties of Probability Models. Discrete Probability Models. Conditional Probability and Independence. Compound Experiments. Bernoulli and Multinomial Trials, Sampling with and without Replacement. Probabilities on Euclidean Space. Random Variables and Vectors: Transformations. Independence of Random Variables and Vectors. The Expectation of a Random Variable. Moments. Moment and Cumulant Generating Functions. Some Classical Discrete and Continuous Distributions. Modes of Convergence of Random Variables and Limit Theorems. Further Limit Theorems and Inequalities. Poisson Process. Appendix B: Additional Topics in Probability and Analysis. Conditioning by a Random Variable or Vector. Distribution Theory for Transformations of Random Vectors. Distribution Theory for Samples from a Normal Population. The Bivariate Normal Distribution. Moments of Random Vectors and Matrices. The Multivariate Normal Distribution. Convergence for Random Vectors: Op and Op Notation. Multivariate Calculus. Convexity and Inequalities. Topics in Matrix Theory and Elementary Hilbert Space Theory. Appendix C: Tables. The Standard Normal Distribution. Auxiliary Table of the Standard Normal Distribution. t Distribution Critical Values. X 2 Distribution Critical Values. F Distribution Critical Values. Index."
            },
            "slug": "Mathematical-Statistics:-Basic-Ideas-and-Selected-Bickel-Doksum",
            "title": {
                "fragments": [],
                "text": "Mathematical Statistics: Basic Ideas and Selected Topics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2608771"
                        ],
                        "name": "A. Gersho",
                        "slug": "A.-Gersho",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Gersho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gersho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118950728,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c564aa7639a08c280423489e52b6e32055c9aa7f",
            "isKey": false,
            "numCitedBy": 7028,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Introduction.- 1.1 Signals, Coding, and Compression.- 1.2 Optimality.- 1.3 How to Use this Book.- 1.4 Related Reading.- I Basic Tools.- 2 Random Processes and Linear Systems.- 2.1 Introduction.- 2.2 Probability.- 2.3 Random Variables and Vectors.- 2.4 Random Processes.- 2.5 Expectation.- 2.6 Linear Systems.- 2.7 Stationary and Ergodic Properties.- 2.8 Useful Processes.- 2.9 Problems.- 3 Sampling.- 3.1 Introduction.- 3.2 Periodic Sampling.- 3.3 Noise in Sampling.- 3.4 Practical Sampling Schemes.- 3.5 Sampling Jitter.- 3.6 Multidimensional Sampling.- 3.7 Problems.- 4 Linear Prediction.- 4.1 Introduction.- 4.2 Elementary Estimation Theory.- 4.3 Finite-Memory Linear Prediction.- 4.4 Forward and Backward Prediction.- 4.5 The Levinson-Durbin Algorithm.- 4.6 Linear Predictor Design from Empirical Data.- 4.7 Minimum Delay Property.- 4.8 Predictability and Determinism.- 4.9 Infinite Memory Linear Prediction.- 4.10 Simulation of Random Processes.- 4.11 Problems.- II Scalar Coding.- 5 Scalar Quantization I.- 5.1 Introduction.- 5.2 Structure of a Quantizer.- 5.3 Measuring Quantizer Performance.- 5.4 The Uniform Quantizer.- 5.5 Nonuniform Quantization and Companding.- 5.6 High Resolution: General Case.- 5.7 Problems.- 6 Scalar Quantization II.- 6.1 Introduction.- 6.2 Conditions for Optimality.- 6.3 High Resolution Optimal Companding.- 6.4 Quantizer Design Algorithms.- 6.5 Implementation.- 6.6 Problems.- 7 Predictive Quantization.- 7.1 Introduction.- 7.2 Difference Quantization.- 7.3 Closed-Loop Predictive Quantization.- 7.4 Delta Modulation.- 7.5 Problems.- 8 Bit Allocation and Transform Coding.- 8.1 Introduction.- 8.2 The Problem of Bit Allocation.- 8.3 Optimal Bit Allocation Results.- 8.4 Integer Constrained Allocation Techniques.- 8.5 Transform Coding.- 8.6 Karhunen-Loeve Transform.- 8.7 Performance Gain of Transform Coding.- 8.8 Other Transforms.- 8.9 Sub-band Coding.- 8.10 Problems.- 9 Entropy Coding.- 9.1 Introduction.- 9.2 Variable-Length Scalar Noiseless Coding.- 9.3 Prefix Codes.- 9.4 Huffman Coding.- 9.5 Vector Entropy Coding.- 9.6 Arithmetic Coding.- 9.7 Universal and Adaptive Entropy Coding.- 9.8 Ziv-Lempel Coding.- 9.9 Quantization and Entropy Coding.- 9.10 Problems.- III Vector Coding.- 10 Vector Quantization I.- 10.1 Introduction.- 10.2 Structural Properties and Characterization.- 10.3 Measuring Vector Quantizer Performance.- 10.4 Nearest Neighbor Quantizers.- 10.5 Lattice Vector Quantizers.- 10.6 High Resolution Distortion Approximations.- 10.7 Problems.- 11 Vector Quantization II.- 11.1 Introduction.- 11.2 Optimality Conditions for VQ.- 11.3 Vector Quantizer Design.- 11.4 Design Examples.- 11.5 Problems.- 12 Constrained Vector Quantization.- 12.1 Introduction.- 12.2 Complexity and Storage Limitations.- 12.3 Structurally Constrained VQ.- 12.4 Tree-Structured VQ.- 12.5 Classified VQ.- 12.6 Transform VQ.- 12.7 Product Code Techniques.- 12.8 Partitioned VQ.- 12.9 Mean-Removed VQ.- 12.10 Shape-Gain VQ.- 12.11 Multistage VQ.- 12.12 Constrained Storage VQ.- 12.13 Hierarchical and Multiresolution VQ.- 12.14 Nonlinear Interpolative VQ.- 12.15 Lattice Codebook VQ.- 12.16 Fast Nearest Neighbor Encoding.- 12.17 Problems.- 13 Predictive Vector Quantization.- 13.1 Introduction.- 13.2 Predictive Vector Quantization.- 13.3 Vector Linear Prediction.- 13.4 Predictor Design from Empirical Data.- 13.5 Nonlinear Vector Prediction.- 13.6 Design Examples.- 13.7 Problems.- 14 Finite-State Vector Quantization.- 14.1 Recursive Vector Quantizers.- 14.2 Finite-State Vector Quantizers.- 14.3 Labeled-States and Labeled-Transitions.- 14.4 Encoder/Decoder Design.- 14.5 Next-State Function Design.- 14.6 Design Examples.- 14.7 Problems.- 15 Tree and Trellis Encoding.- 15.1 Delayed Decision Encoder.- 15.2 Tree and Trellis Coding.- 15.3 Decoder Design.- 15.4 Predictive Trellis Encoders.- 15.5 Other Design Techniques.- 15.6 Problems.- 16 Adaptive Vector Quantization.- 16.1 Introduction.- 16.2 Mean Adaptation.- 16.3 Gain-Adaptive Vector Quantization.- 16.4 Switched Codebook Adaptation.- 16.5 Adaptive Bit Allocation.- 16.6 Address VQ.- 16.7 Progressive Code Vector Updating.- 16.8 Adaptive Codebook Generation.- 16.9 Vector Excitation Coding.- 16.10 Problems.- 17 Variable Rate Vector Quantization.- 17.1 Variable Rate Coding.- 17.2 Variable Dimension VQ.- 17.3 Alternative Approaches to Variable Rate VQ.- 17.4 Pruned Tree-Structured VQ.- 17.5 The Generalized BFOS Algorithm.- 17.6 Pruned Tree-Structured VQ.- 17.7 Entropy Coded VQ.- 17.8 Greedy Tree Growing.- 17.9 Design Examples.- 17.10 Bit Allocation Revisited.- 17.11 Design Algorithms.- 17.12 Problems."
            },
            "slug": "Vector-quantization-and-signal-compression-Gersho-Gray",
            "title": {
                "fragments": [],
                "text": "Vector quantization and signal compression"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The author explains the design and implementation of the Levinson-Durbin Algorithm, which automates the very labor-intensive and therefore time-heavy and expensive process of designing and implementing a Quantizer."
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24804,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "For details, see any of the references on speech recognition [23], [40], [45], [52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "HMM\u2019s have earned their popularity in large part from successful application to speech recognition [2], [12], [23], [40], [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7788300,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "df50c6e1903b1e2d657f78c28ab041756baca86a",
            "isKey": false,
            "numCitedBy": 8924,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Fundamentals of Speech Recognition. 2. The Speech Signal: Production, Perception, and Acoustic-Phonetic Characterization. 3. Signal Processing and Analysis Methods for Speech Recognition. 4. Pattern Comparison Techniques. 5. Speech Recognition System Design and Implementation Issues. 6. Theory and Implementation of Hidden Markov Models. 7. Speech Recognition Based on Connected Word Models. 8. Large Vocabulary Continuous Speech Recognition. 9. Task-Oriented Applications of Automatic Speech Recognition."
            },
            "slug": "Fundamentals-of-speech-recognition-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "Fundamentals of speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book presents a meta-modelling framework for speech recognition that automates the very labor-intensive and therefore time-heavy and therefore expensive and expensive process of manually modeling speech."
            },
            "venue": {
                "fragments": [],
                "text": "Prentice Hall signal processing series"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 99
                            }
                        ],
                        "text": "HMM\u2019s have earned their popularity in large part from successful application to speech recognition [2], [12], [23], [40], [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61904772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c180f387357d9302a558bcd643209831744c639b",
            "isKey": false,
            "numCitedBy": 604,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system. DRAGON makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech. The model--that of a probabilistic function of a Markov process--is very flexible and leads to features which allow DRAGON to function despite high error rates from individual knowledge sources. Repeated use of a simple abstract model produces a system which is simple in structure, but powerful in capabilities."
            },
            "slug": "The-DRAGON-system--An-overview-Baker",
            "title": {
                "fragments": [],
                "text": "The DRAGON system--An overview"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system, which makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8089863"
                        ],
                        "name": "R. Cole",
                        "slug": "R.-Cole",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cole",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145148360"
                        ],
                        "name": "L. Hirschman",
                        "slug": "L.-Hirschman",
                        "structuredName": {
                            "firstName": "Lynette",
                            "lastName": "Hirschman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Hirschman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705299"
                        ],
                        "name": "L. Atlas",
                        "slug": "L.-Atlas",
                        "structuredName": {
                            "firstName": "Les",
                            "lastName": "Atlas",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Atlas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2415420"
                        ],
                        "name": "M. Beckman",
                        "slug": "M.-Beckman",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Beckman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Beckman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727680"
                        ],
                        "name": "A. Biermann",
                        "slug": "A.-Biermann",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Biermann",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Biermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144959145"
                        ],
                        "name": "M. Bush",
                        "slug": "M.-Bush",
                        "structuredName": {
                            "firstName": "Marcia",
                            "lastName": "Bush",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bush"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793320"
                        ],
                        "name": "M. Clements",
                        "slug": "M.-Clements",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Clements",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Clements"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670760"
                        ],
                        "name": "Jordan Cohen",
                        "slug": "Jordan-Cohen",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jordan Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061142963"
                        ],
                        "name": "Oscar Garcia",
                        "slug": "Oscar-Garcia",
                        "structuredName": {
                            "firstName": "Oscar",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oscar Garcia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50305884"
                        ],
                        "name": "B. Hanson",
                        "slug": "B.-Hanson",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Hanson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hanson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3106255"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Levinson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47263765"
                        ],
                        "name": "D. Novick",
                        "slug": "D.-Novick",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Novick",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Novick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144339506"
                        ],
                        "name": "Mari Ostendorf",
                        "slug": "Mari-Ostendorf",
                        "structuredName": {
                            "firstName": "Mari",
                            "lastName": "Ostendorf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mari Ostendorf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2807460"
                        ],
                        "name": "S. Oviatt",
                        "slug": "S.-Oviatt",
                        "structuredName": {
                            "firstName": "Sharon",
                            "lastName": "Oviatt",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Oviatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48258694"
                        ],
                        "name": "P. Price",
                        "slug": "P.-Price",
                        "structuredName": {
                            "firstName": "Patti",
                            "lastName": "Price",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Price"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748100"
                        ],
                        "name": "H. Silverman",
                        "slug": "H.-Silverman",
                        "structuredName": {
                            "firstName": "Harvey",
                            "lastName": "Silverman",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Silverman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144676794"
                        ],
                        "name": "J. Spitz",
                        "slug": "J.-Spitz",
                        "structuredName": {
                            "firstName": "Judith",
                            "lastName": "Spitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Spitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35112668"
                        ],
                        "name": "C. Weinstein",
                        "slug": "C.-Weinstein",
                        "structuredName": {
                            "firstName": "Clifford",
                            "lastName": "Weinstein",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Weinstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144157305"
                        ],
                        "name": "S. Zahorian",
                        "slug": "S.-Zahorian",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Zahorian",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zahorian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710543"
                        ],
                        "name": "V. Zue",
                        "slug": "V.-Zue",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Zue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zue"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "HMM\u2019s have earned their popularity in large part from successful application to speech recognition [2], [12], [23], [40], [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3082215,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13c526d88a63be5b34f391725f069a867f202011",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 260,
            "paperAbstract": {
                "fragments": [],
                "text": "A spoken language system combines speech recognition, natural language processing and human interface technology. It functions by recognizing the person's words, interpreting the sequence of words to obtain a meaning in terms of the application, and providing an appropriate response back to the user. Potential applications of spoken language systems range from simple tasks, such as retrieving information from an existing database (traffic reports, airline schedules), to interactive problem solving tasks involving complex planning and reasoning (travel planning, traffic routing), to support for multilingual interactions. We examine eight key areas in which basic research is needed to produce spoken language systems: (1) robust speech recognition; (2) automatic training and adaptation; (3) spontaneous speech; (4) dialogue models; (5) natural language response generation; (6) speech synthesis and speech generation; (7) multilingual systems; and (8) interactive multimodal systems. In each area, we identify key research challenges, the infrastructure needed to support research, and the expected benefits. We conclude by reviewing the need for multidisciplinary research, for development of shared corpora and related resources, for computational support and far rapid communication among researchers. The successful development of this technology will increase accessibility of computers to a wide range of users, will facilitate multinational communication and trade, and will create new research specialties and jobs in this rapidly expanding area. >"
            },
            "slug": "The-challenge-of-spoken-language-systems:-research-Cole-Hirschman",
            "title": {
                "fragments": [],
                "text": "The challenge of spoken language systems: research directions for the nineties"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The need for multidisciplinary research is reviewed, for development of shared corpora and related resources, for computational support and far rapid communication among researchers, and the expected benefits of this technology are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500689"
                        ],
                        "name": "A. Viterbi",
                        "slug": "A.-Viterbi",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Viterbi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Viterbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30752333"
                        ],
                        "name": "J. Omura",
                        "slug": "J.-Omura",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Omura",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Omura"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "The Viterbi algorithm [48] is applied to maximize since can be computed by the recursive formulae"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32784911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7561b47ecb4398527f4a6079a3f0188778b30688",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "For memoryless discrete-time sources and bounded single-letter distortion measures, we derive a bound on the average per-letter distortion achievable by a trellis source code of fixed constraint length. For any fixed code rate greater than R(D^{\\ast}) , the rate-distortion function at D^{\\ast} , this bound decreases toward D^{\\ast} exponentially with constraint length."
            },
            "slug": "Trellis-Encoding-of-memoryless-discrete-time-with-a-Viterbi-Omura",
            "title": {
                "fragments": [],
                "text": "Trellis Encoding of memoryless discrete-time sources with a fidelity criterion"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A bound on the average per-letter distortion achievable by a trellis source code of fixed constraint length is derived for any fixed code rate greater than R(D) , and this bound decreases toward D^{\\ast} exponentially with constraint length."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110842402"
                        ],
                        "name": "John B. Anderson",
                        "slug": "John-B.-Anderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Anderson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John B. Anderson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 80
                            }
                        ],
                        "text": "This algorithm is different from the -algorithm introduced for source coding by Jelinek and Anderson [24] since\n(20)\nA fast algorithm is developed for choosing suchsequences of states."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 26
                            }
                        ],
                        "text": "[24] F. Jelinek and J. B. Anderson, \u201cInstrumentable tree encoding of information sources,\u201dIEEE Trans."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "This algorithm is different from the -algorithm introduced for source coding by Jelinek and Anderson [24] since"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 22528680,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1a44df49c1bdbb7eb9e202e1e3a5cc431892888",
            "isKey": true,
            "numCitedBy": 139,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "We study here the use of tree codes to encode time-discrete memoryless sources with respect to a fidelity criterion. An easily instrumented scheme is proposed for use with binary sources and the Hamming distortion metric. Results of simulation with random and convolutional codes are given."
            },
            "slug": "Instrumentable-tree-encoding-of-information-sources-Jelinek-Anderson",
            "title": {
                "fragments": [],
                "text": "Instrumentable tree encoding of information sources (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "An easily instrumented scheme is proposed for use with binary sources and the Hamming distortion metric, using tree codes to encode time-discrete memoryless sources with respect to a fidelity criterion."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "Applications to image segmentation, restoration, and compression were explored [16]\u2013[18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "Instead, computationally feasible algorithms [14]\u2013[16] were developed by making additional assumptions regarding models or using locally optimal solutions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "The effort devoted to applying a truly 2-D HMM to image segmentation was first made by Devijver [14]\u2013[16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Devijver, \u201cModeling of digital images using hidden Markov mesh random fields,\u201dSignal"
            },
            "venue": {
                "fragments": [],
                "text": "Processing IV: Theories and Applications (Proc"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "The segmentation of aerial images was also studied by Oehler [35] and Perlmutter [41]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 11
                            }
                        ],
                        "text": "[42] K. O. Perlmutter, N. Chaddha, J. B. Buckheit, R. M. Gray, and R. A. Olshen, \u201cText segmentation in mixed-mode images using classification trees and transform tree-structured vector quantization,\u201d inProc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 94
                            }
                        ],
                        "text": "Previous work on gray-scale document image segmentation includes Chaddha [11], Williams [49], Perlmutter [41], [42], and Ohuchi [38]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "5% [41], which is comparable to CART 1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "Previous work on gray-scale document image segmentation includes Chaddha [11], Williams [49], Perlmutter [41], [42], and"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 11
                            }
                        ],
                        "text": "[41] K. O. Perlmutter, \u201cCompression and classification of images using vector quantization and decision trees,\u201d Ph.D. dissertation, Stanford Univ., Stanford, CA, 1995."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "In both cases, the Bayes vector quantizer (BVQ) [35]\u2013[37], [41] is used as a classifier."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [41] and [42], the Bayes VQ algorithm is applied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 11
                            }
                        ],
                        "text": "[43] K. O. Perlmutter, S. M. Perlmutter, R. M. Gray, R. A. Olshen, and K. L. Oehler, \u201cBayes risk weighted vector quantization with posterior estimation for image compression and classification,\u201dIEEE Trans."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Compression and classification of images using vector quantization and decision trees,"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. dissertation,"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94244478"
                        ],
                        "name": "D. K. Pickard",
                        "slug": "D.-K.-Pickard",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pickard",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. K. Pickard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "The Markov mesh is called a \u201ccausal\u201d MRF [7], [25], [44] because"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 125071806,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c4ba00c1733bdc759ea242ae9caae3dab9e4c8ed",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-curious-binary-lattice-process-Pickard",
            "title": {
                "fragments": [],
                "text": "A curious binary lattice process"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102329511"
                        ],
                        "name": "George W. Soules",
                        "slug": "George-W.-Soules",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Soules",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George W. Soules"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063108982"
                        ],
                        "name": "Norman Weiss",
                        "slug": "Norman-Weiss",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norman Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122568650,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3092a4929bdb3d6a8fe53f162586b7431b5ff8a4",
            "isKey": false,
            "numCitedBy": 4551,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Maximization-Technique-Occurring-in-the-Analysis-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120208815,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "603bdbb17ba1f909280405a076455ac4f878fbf3",
            "isKey": false,
            "numCitedBy": 2773,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-Inference-for-Probabilistic-Functions-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "Statistical Inference for Probabilistic Functions of Finite State Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14942773"
                        ],
                        "name": "M. Stone",
                        "slug": "M.-Stone",
                        "structuredName": {
                            "firstName": "Mervyn",
                            "lastName": "Stone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2) Results: Six-fold cross-validation [ 47 ] was used to evaluate algorithms."
                    },
                    "intents": []
                }
            ],
            "corpusId": 119852865,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "3c429ad74f9f4cf2ad65b7fb292c34f78569da20",
            "isKey": false,
            "numCitedBy": 189,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cross-validation:a-review-2-Stone",
            "title": {
                "fragments": [],
                "text": "Cross-validation:a review 2"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3166057"
                        ],
                        "name": "J. Boyett",
                        "slug": "J.-Boyett",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Boyett",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Boyett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117559829,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "74c485bf114e10fdac57b78898b29cd3de30c5f0",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Random-RxC-tables-with-given-row-and-column-totals-Boyett",
            "title": {
                "fragments": [],
                "text": "Random RxC tables with given row and column totals"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143834737"
                        ],
                        "name": "D. A. Bell",
                        "slug": "D.-A.-Bell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bell",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. A. Bell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 75
                            }
                        ],
                        "text": "In fact, an HMM is simply a \u201cMarkov Ssource,\u201d as defined by Shannon [46] and Gallager [20]: a conditionally independent process on a Markov chain or, equivalently, a Markov chain viewed through a memoryless noisy channel."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 11
                            }
                        ],
                        "text": "[20] R. G. Gallager, Information Theory and Reliable Communication."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "[46] and Gallager [20]: a conditionally independent process on a Markov chain or, equivalently, a Markov chain viewed through a memoryless noisy channel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 109410157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e163fb03f549ab2bb1dbbf746005553ea15a575",
            "isKey": false,
            "numCitedBy": 2797,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-Theory-and-Reliable-Communication-Bell",
            "title": {
                "fragments": [],
                "text": "Information Theory and Reliable Communication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144497046"
                        ],
                        "name": "N. Nilsson",
                        "slug": "N.-Nilsson",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nilsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "In [49], a modified quadratic neural network [34] is used for classifying features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 54132942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d725045ed29d69b7a503896841ef637383376043",
            "isKey": false,
            "numCitedBy": 445,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Machines:-Foundations-of-Trainable-Systems-Nilsson",
            "title": {
                "fragments": [],
                "text": "Learning Machines: Foundations of Trainable Pattern-Classifying Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "The theory of hidden Markov models in one dimension (1-D HMM\u2019s) was developed in the 1960s by Baum et al.[3]\u2013[6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 43148643,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "afb8908aff1d2c5917a40bd3d6d4c6f4f2f401bf",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "These papers* are statistically motivated; the content is mathematical. The motivation is this: Given is an s X s stochastic matrix A = ((aij)) and an s X r stochastic matrix B = ((bj0)) where A generates a stationary Mlarkov process IXt} according to a1j = P[X,\u00b11 = A Xr = i] and B generates a process I Y1} described by P[Yt = k|Xt = j] = bj,, so if R is the set of integers 1, 2 ... .r and R' = H' 1R, R, = R (a point Y E R' has coordinates Y,), then the matrices A and B define a measure P(AB) on R', for kf ie R P(A, B){ Y1 = ki, 1 2 = k2 n =n. V 2 in = laj0aj01bik1alb22* ain-linbin where {ai0} is the stationary absolute distribution for A. The resulting process Y0} is called a probabilistic function of the MIarkov process {Xt}. Let Al be the space of s X s ergodic stochastic matrices, A2 the space of s X r stochastic matrices and H = Al X A2. The above associates to r = (A, B) E H and a stationary vector a for A a measure P7r on Re. The Problem.-Fix 7ro E H and let a sample Y1, Y2... Y. be generated according to the distribution PR0. From the sample Y... Y,, obtain an estimate HI(Y) of 7ro so that HI,(Y) Tro a.e., P7.0. Throughout this paper ro is fixed and 7r varies in HI. The Mathematics.--Part I (classification of equivalent processes) demonstrates that the problem has a solution in the following sense: Let AIM [ro] = { TELIIPr = P7.0 as measures on Ro }. Clearly the points of M[ro] cannot be distinguished by any finite or infinite sample. The description of M[7ro] is crucial in our study. Let (E be the symmetric group of degree s operating on the integers 1 through s. (is acts on H by -(A,B) = (aA,o-B), (oA)Xj = aa(i),7(j) (aB) j = b,(j)k for ue G5 Observe that Porr = P7. as measures on R'. The main result of part I is THEOREM 1. There is an open subset Ho of H of Euclidean measure 1 such that for To E 1oM [7ro] = GSro, i.e., 7rO is distinguishable up to permutation by the measure P0(rSTro = {I ToIa eU~} ). Part II (limit theorems and statistical analysis) extends and generalizes the results of reference 1. For each n and each Y E R there is a function H. [Tr, Y] on H 1 defined by H, [T, Y] = log Pal Y1, Y2... Y4}; thus, each H, [T ] is a random n variable on the probability space (R',P7.0). The value Hn [7r, Y] is a function on I. These random variables hold the solution to our problem, as the following shows. THEOREM 2. lim Hn[,Y] = H7 (7r) exists a.e., P7r., nf'a THEOREM 3. H7r (T) < Hro(To) and H7.(T) = H710(To) iff T E M [To] Define H,,(Y) = I 7r' e I 7r' maximizes H,,[,Y]}. THEOREM 4. Hn(Y) M[Tro] a.e., P,. Theorems 1 through 4 theoretically solve our problem. Note in particular the importance of the function H.0(7r) in view of Theorems 1 and 3. 1'art III (AMorse theory) makes a further study of the function H,,(r) for r e11 ="
            },
            "slug": "Probabilistic-functions-of-finite-state-markov-Petrie",
            "title": {
                "fragments": [],
                "text": "Probabilistic functions of finite-state markov chains."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072213"
                        ],
                        "name": "J. Besag",
                        "slug": "J.-Besag",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Besag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Besag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "The Markov mesh is called a \u201ccausal\u201d MRF [7], [25], [44] because"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42087677,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8bf730243ed967afd5349bef053641a6043517a0",
            "isKey": false,
            "numCitedBy": 6165,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Spatial-Interaction-and-the-Statistical-Analysis-of-Besag",
            "title": {
                "fragments": [],
                "text": "Spatial Interaction and the Statistical Analysis of Lattice Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102278025"
                        ],
                        "name": "Ross Kindermann",
                        "slug": "Ross-Kindermann",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Kindermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross Kindermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34296841"
                        ],
                        "name": "J. Snell",
                        "slug": "J.-Snell",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Snell",
                            "middleNames": [
                                "Laurie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Snell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "We point out that the underlying state process defined is a special case of a Markov random field (MRF) [21], [26], which was referred to as Markov mesh and proposed by Abend et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117120661,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "870234e41be333eb8ab128cbd1ca1623838b8d7f",
            "isKey": false,
            "numCitedBy": 1314,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Markov-Random-Fields-and-Their-Applications-Kindermann-Snell",
            "title": {
                "fragments": [],
                "text": "Markov Random Fields and Their Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modeling of digital images using hidden Markov mesh random fields"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Processing IV : Theories and Applications ( Proc"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "This is what is called Viterbi training in [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 107
                            }
                        ],
                        "text": "Hidden Markov models have earned their popularity mostly from successful application to speech recognition [4, 5, 6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 139
                            }
                        ],
                        "text": "In the case of one dimensional HMM as used in speech recognition, computationally e cient formulas exist for calculating Lm(k) and Hm;l(k) [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "HTK - Hidden Markov Model Toolkit"
            },
            "venue": {
                "fragments": [],
                "text": "Cambridge University"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classiication and Regression Trees"
            },
            "venue": {
                "fragments": [],
                "text": "Classiication and Regression Trees"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classiication and Regression Trees"
            },
            "venue": {
                "fragments": [],
                "text": "Classiication and Regression Trees"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "For most block based image classi cation algorithms, such as CART [1], images are divided into blocks and decisions are made independently for the class of each block."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "We compare the 2-D HMM result with that obtained by CART [1]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classi cation and Regression Trees"
            },
            "venue": {
                "fragments": [],
                "text": "Chapman & Hall"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "Trellis coding [2] in image compression is such an example."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vector Quantization  and Signal Compression, pages 555-585"
            },
            "venue": {
                "fragments": [],
                "text": "Kluwer Aca-  demic Publishers,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gray , \\ Context Based MultiscaleClassi cation of Images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "Underlying an HMM is a basic Markov chain [33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An example of statistical investigation in the text of \u2018Eugene Onyegin\u2019 illustrating coupling of \u2018tests"
            },
            "venue": {
                "fragments": [],
                "text": "in chains,\u201d Proc. Acad. Sci.,"
            },
            "year": 1913
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An example of statistical investigation in the text of \u2018 Eugene Onyegin \u2019 illustrating coupling of \u2018 tests \u2019 in chains"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . Acad . Sci . Learning Machines : Foundations of Trainable PatternClassifying Systems"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "2) Results: Six-fold cross-validation [47] was used to eval-"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cross-validation: A review,"
            },
            "venue": {
                "fragments": [],
                "text": "Math. Oper. Statist.  ,"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Expectation Maximization, An approach to parameter estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Expectation Maximization, An approach to parameter estimation"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Devijver, \u201cReal-time modeling of image sequences based on hidden Markov mesh random field models,"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 10th Int. Conf. Pattern Recogn"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gray , \\ Context Based Multiscale Classi cation of Images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Segmentation of binary images using third order Markov mesh image models,"
            },
            "venue": {
                "fragments": [],
                "text": "inProc. 8th Int. Conf. Pattern Recogn"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood estimation from incomplete data via the EM algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov mesh models, \" in Image Modeling"
            },
            "venue": {
                "fragments": [],
                "text": "Markov mesh models, \" in Image Modeling"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "The EM iteration is defined in [13] as follows."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Before describing the algorithm, we introduce a function [13]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "Estimation of 1-D HMM model parameters is usually performed using the Baum-Welch algorithm [6] (which is a special case of the EM algorithm [13]), which performs maximum likelihood estimation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "B. Rubin, \u201cMaximum likelihood from incomplete data via the EM algorithm,\u201d  J. R. Stat. Soc. , vol. 39, no. 1, pp. 1\u201321"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 49
                            }
                        ],
                        "text": "The parameters are estimated by the EM algorithm [7, 8, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "N"
            },
            "venue": {
                "fragments": [],
                "text": "M. Laird and D. B. Rubin, \\Maxi-  mum Likelihood from Incomplete Data via the EM Al-  gorithm,\" J. Roy. Statist. Soc."
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Eagon, \u201cAn inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology,\u201dBull"
            },
            "venue": {
                "fragments": [],
                "text": "Amer. Math. Stat.  ,"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "The deterministic relaxation algorithm [14] for searching maximuma posterioristates [23] is worth noting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "For details, see any of the references on speech recognition [23], [40], [45], [52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "HMM\u2019s have earned their popularity in large part from successful application to speech recognition [2], [12], [23], [40], [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and M"
            },
            "venue": {
                "fragments": [],
                "text": "A. Jack,Hidden Markov Models for Speech Recognition  . Edinburgh, U.K.: Edinburgh Univ. Press"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 93
                            }
                        ],
                        "text": "The parameters are estimated by the maximum likelihood (ML) criterion using the EM algorithm [6], Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "This is done efficiently by the so-calledforward-backwardalgorithm [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "Estimation of 1-D HMM model parameters is usually performed using the Baum-Welch algorithm [6] (which is a special case of the EM algorithm [13]), which performs maximum likelihood estimation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and N"
            },
            "venue": {
                "fragments": [],
                "text": "Weiss, \u201cA maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains,\u201dAnn. Math. Stat. , vol. 41, no. 1, pp. 164\u2013171"
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Segmentation method for documents containing text/picture (screened halftone, continuous tone),"
            },
            "venue": {
                "fragments": [],
                "text": "Trans. Inst. Electron., Inform., Commun. Eng. D-II , vol. J75D-II,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "D HMM\u2019s) was developed in the 1960s by Baumet al.[3]\u2013[6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An inequality and associated maximization technique in statistical estimation for probabilistic functions of finite state Markov chains, \" in Inequalities III"
            },
            "venue": {
                "fragments": [],
                "text": "An inequality and associated maximization technique in statistical estimation for probabilistic functions of finite state Markov chains, \" in Inequalities III"
            },
            "year": 1972
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 24,
            "methodology": 21,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 72,
        "totalPages": 8
    },
    "page_url": "https://www.semanticscholar.org/paper/Image-classification-by-a-two-dimensional-hidden-Li-Najmi/79368bfbeab606c13c29f59492b88af4e031220d?sort=total-citations"
}