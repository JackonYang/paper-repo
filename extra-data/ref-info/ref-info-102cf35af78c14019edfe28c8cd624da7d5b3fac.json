{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9204636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "044779db85dc83e2633951791b29bc311cfbae53",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new framework for recognizing planar object classes, which is based on local feature detectors and a probabilistic model of the spatial arrangement of the features. The allowed object deformations are represented through shape statistics, which are learned from examples. Instances of an object in an image are detected by finding the appropriate features in the correct spatial configuration. The algorithm is robust with respect to partial occlusion, detector false alarms, and missed features. A 94% success rate was achieved for the problem of locating quasi-frontal views of faces in cluttered scenes."
            },
            "slug": "Recognition-of-planar-object-classes-Burl-Perona",
            "title": {
                "fragments": [],
                "text": "Recognition of planar object classes"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new framework for recognizing planar object classes is presented, which is based on local feature detectors and a probabilistic model of the spatial arrangement of the features, and the allowed object deformations are represented through shape statistics, which are learned from examples."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8989489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d781d5e651e12bf666cf993ae307db785113b9ae",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >"
            },
            "slug": "Recognition-by-Linear-Combinations-of-Models-Ullman-Basri",
            "title": {
                "fragments": [],
                "text": "Recognition by Linear Combinations of Models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed and it is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39877209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de6f7d242b78bf5e87966fb72565ba43d277084e",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Most deformable models use a local optimisation scheme to locate their targets in images, and require a 'good enough' starting point. This paper describes an approach for generating such starting points automatically given no prior knowledge of the pose of the target(s) in the image. It relies upon choosing a suitable set of features, candidates for which can be found in the image. Hypotheses are formed from sets of candidates, and their plausibility tested using the statistics of their relative positions and orientations. The most plausible are used as the initial position of an Active Shape Model, which can then accurately locate the target object. The approach is demonstrated for two different image interpretation problems."
            },
            "slug": "Locating-Objects-of-Varying-Shape-Using-Statistical-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Locating Objects of Varying Shape Using Statistical Feature Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This paper describes an approach for generating starting points automatically given no prior knowledge of the pose of the target(s) in the image, which relies upon choosing a suitable set of features, candidates for which can be found in theimage, which is demonstrated for two different image interpretation problems."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27534351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54780ad3a1d5924df6ce0afbf2d2193415ca9fdd",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The Geometric Hashing paradigm for model-based recognition of objects in cluttered scenes is discussed. This paradigm enables a unified approach to rigid object recognition under different viewing transformation assumptions both for 2-D and 3-D objects obtained by different sensors, e.g. vision, range, tactile. It is based on an intensive off-line model preprocessing (learning) stage, where model information is indexed into a hash-table using minimal, transformation invariant features. This enables the on-line recognition algorithm to be particularly efficient. The algorithm is straightforwardly parallelizable. Initial experimentation of the technique has led to successful recognition of both 2-D and 3-D objects in cluttered scenes from an arbitrary viewpoint. We, also, compare the Geometric Hashing with the Hough Transform and the alignment techniques. Extensions of the basic paradigm which reduce its worst case recognition complexity are discussed."
            },
            "slug": "Model-Based-Object-Recognition-by-Geometric-Hashing-Wolfson",
            "title": {
                "fragments": [],
                "text": "Model-Based Object Recognition by Geometric Hashing"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Extensions of the basic paradigm which reduce its worst case recognition complexity are discussed, and the Geometric Hashing with the Hough Transform and the alignment techniques are compared."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080791815"
                        ],
                        "name": "C. Burly",
                        "slug": "C.-Burly",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Burly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087868060"
                        ],
                        "name": "T. K. Leungz",
                        "slug": "T.-K.-Leungz",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Leungz",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. K. Leungz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1226614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2052cab4162051486813b7ed0c2c5f6f4c0667ee",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a face localization system is proposed in which local detectors are coupled with a statistical model of the spatial arrangement of facial features to yield robust performance. The outputs from the local detectors are treated as candidate locations and constellations are formed from these. The eeects of translation, rotation, and scale are eliminated by mapping to a set of shape variables. The constellations are then ranked according to the likelihood that the shape variables correspond to a face versus an alternative model. Incomplete constellations , which occur when some of the true features are missed, are handled in a principled way."
            },
            "slug": "Face-Localization-via-Shape-Statistics-Burly-Leungz",
            "title": {
                "fragments": [],
                "text": "Face Localization via Shape Statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A face localization system is proposed in which local detectors are coupled with a statistical model of the spatial arrangement of facial features to yield robust performance and incomplete constellations are handled in a principled way."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16413347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37d46a2355a95abee6576986a460399adbebf6b9",
            "isKey": false,
            "numCitedBy": 421,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach for extracting facial features from images and for determining the spatial organization between these features using the concept of a deformable template. This is a parameterized geometric model of the object to be recognized together with a measure of how well it fits the image data. Variations in the parameters correspond to allowable deformations of the object and can be specified by a probabilistic model. After the extraction stage the parameters of the deformable template can be used for object description and recognition."
            },
            "slug": "Deformable-Templates-for-Face-Recognition-Yuille",
            "title": {
                "fragments": [],
                "text": "Deformable Templates for Face Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An approach for extracting facial features from images and for determining the spatial organization between these features using the concept of a deformable template using a parameterized geometric model of the object to be recognized together with a measure of how well it fits the image data."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738392"
                        ],
                        "name": "Arthur R. Pope",
                        "slug": "Arthur-R.-Pope",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Pope",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arthur R. Pope"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14564388,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a19b5edb497cdb2ab9821950643dcff67e63343",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Iterative alignment is one method for feature-based matching of an image and a model for the purpose of object recognition. The method alternately hypothesizes feature pairings and estimates a viewpoint transformation from those pairings; at each stage a refined transformation estimate is used to suggest additional pairings. This paper extends iterative alignment in the domain of 2D similarity transformations so that it represents the uncertainty in the position of each model and image feature, and that of the transformation estimate. A model describes probabilistically the significance, position, and intrinsic attributes of each feature, plus topological relations among features. A measure of the match between a model and an image integrates all four of these, and leads to an efficient matching procedure called probabilistic alignment. That procedure supports both recognition and a learning procedure for acquiring models from training images. By explicitly representing uncertainty, one model can satisfactorily describe appearance over a wider range of viewing conditions. Thus, when models represent 2D characteristic views of a 3D object, fewer models are needed. Experiments demonstrating the effectiveness of this approach are reported."
            },
            "slug": "Modeling-Positional-Uncertainty-in-Object-Pope-Lowe",
            "title": {
                "fragments": [],
                "text": "Modeling Positional Uncertainty in Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper extends iterative alignment in the domain of 2D similarity transformations so that it represents the uncertainty in the position of each model and image feature, and that of the transformation estimate."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35146156"
                        ],
                        "name": "M. Lades",
                        "slug": "M.-Lades",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Lades",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lades"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3189439"
                        ],
                        "name": "J. Vorbr\u00fcggen",
                        "slug": "J.-Vorbr\u00fcggen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Vorbr\u00fcggen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vorbr\u00fcggen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075388397"
                        ],
                        "name": "J. Lange",
                        "slug": "J.-Lange",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Lange",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lange"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038814"
                        ],
                        "name": "R. W\u00fcrtz",
                        "slug": "R.-W\u00fcrtz",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "W\u00fcrtz",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. W\u00fcrtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34993891"
                        ],
                        "name": "W. Konen",
                        "slug": "W.-Konen",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Konen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Konen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1266405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb52984078d75ec5655962dc94dc7848182286b",
            "isKey": false,
            "numCitedBy": 2069,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented. The dynamic link architecture exploits correlations in the fine-scale temporal structure of cellular signals to group neurons dynamically into higher-order entities. These entities represent a rich structure and can code for high-level objects. To demonstrate the capabilities of the dynamic link architecture, a program was implemented that can recognize human faces and other objects from video images. Memorized objects are represented by sparse graphs, whose vertices are labeled by a multiresolution description in terms of a local power spectrum, and whose edges are labeled by geometrical distance vectors. Object recognition can be formulated as elastic graph matching, which is performed here by stochastic optimization of a matching cost function. The implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images. The performance of the program is evaluated by a statistical analysis of recognition results from a portrait gallery comprising images of 87 persons. >"
            },
            "slug": "Distortion-Invariant-Object-Recognition-in-the-Link-Lades-Vorbr\u00fcggen",
            "title": {
                "fragments": [],
                "text": "Distortion Invariant Object Recognition in the Dynamic Link Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An object recognition system based on the dynamic link architecture, an extension to classical artificial neural networks (ANNs), is presented and the implementation on a transputer network achieved recognition of human faces and office objects from gray-level camera images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computers"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704573"
                        ],
                        "name": "C. Malsburg",
                        "slug": "C.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "von",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Malsburg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1325911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e4ba33f614ae0578b3d6c2015df536a2795048f",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for the interpretation of camera images of scenes composed of several known objects with mutual occlusion. The scenes are analyzed by the recognition of the objects present and by the determination of their occlusion relations. Objects are internally represented by stored model graphs. These are formed in a semi-automatic way by showing objects against a varying background. Objects are recognized by dynamic link matching. Our experiments show that our system is very successful in analyzing cluttered scenes. The system architecture goes beyond classical neural networks by making extensive use of flexible links between units, as proposed in the dynamic link architecture. The present implementation is, however, rather algorithmic in style and is to be regarded as a pilot study that is preparing the way for a detailed implementation of the architecture."
            },
            "slug": "A-Neural-System-for-the-Recognition-of-Partially-in-Wiskott-Malsburg",
            "title": {
                "fragments": [],
                "text": "A Neural System for the Recognition of Partially Occluded Objects in Cluttered Scenes: A Pilot Study"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The system architecture goes beyond classical neural networks by making extensive use of flexible links between units, as proposed in the dynamic link architecture, and is to be regarded as a pilot study that is preparing the way for a detailed implementation of the architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": false,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60512564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "345a64f103a3c13584f4dd5cdefb6c9f27a88534",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans can look at a scene or a photograph and easily recognize objects. Outside my window I can see cars, people walking a dog on a brick pathway, trees, buildings, etc. This perception is so effortless that it belies the difficulty of the task. Visual perception begins with light that is reflected from the scene into the eye. The light impinges upon the retina and is transduced by a two-dimensional array of photoreceptors into noisy electrical signals. The brain must then accomplish the difficult task of transforming from this low-level representation to a higher-level understanding of the scene in terms of regions, surfaces, textures, and objects. For computer vision the problem is the same, but the hardware is different. A camera approximates the function of the eye and retina; that is, the camera produces a two-dimensional array of numbers (pixel values) representing the intensity of light reflected from the scene. The fundamental question addressed in this thesis is the following: what mathematical processing should be applied to the pixel values in order for a computer to recognize objects? The methods we propose are not intended as a model of human brain function, although they may provide some insight. We are simply trying to solve the same visual recognition problems as the brain without concern for whether (or how) our algorithms could be realized in neuronal \"hardware.\" We have developed a new framework for recognizing visual object classes in which the class members consist of characteristic parts in a deformable spatial configuration. Human faces are an object class of this type, since faces consist of eyes, nose, and mouth arranged in a configuration that varies depending on expression and pose and also from one person to another. A second object class is cursive handwriting, which consists of loops, cusps, crossings, etc. arranged in a deformable pattern. In our approach, the allowed object deformations are represented through shape statistics, which are learned from examples. Instances of an object in an image are detected by finding the appropriate features in the correct spatial configuration. Our algorithm is robust with respect to partial occlusion, detector false alarms, and missed features. Potential applications include intelligent tools for finding objects in image data-bases, human-machine interfaces, user authentication, intelligent data gathering and compression, signature verification, and keyword spotting. Experimental results will be presented for two problems: (1) locating quasi-frontal views of human faces in cluttered scenes and with occlusions and (2) spotting keywords in on-line cursive handwriting data."
            },
            "slug": "Recognition-of-visual-object-classes-Burl",
            "title": {
                "fragments": [],
                "text": "Recognition of visual object classes"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new framework for recognizing visual object classes in which the class members consist of characteristic parts in a deformable spatial configuration, which is robust with respect to partial occlusion, detector false alarms, and missed features is developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14954,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16859093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "239beb3861ceceb4c7c7f229234d97198d5c7697",
            "isKey": false,
            "numCitedBy": 2828,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching, are presented. The results obtained for the testing sets show about 90% correct recognition using geometrical features and perfect recognition using template matching. >"
            },
            "slug": "Face-Recognition:-Features-Versus-Templates-Brunelli-Poggio",
            "title": {
                "fragments": [],
                "text": "Face Recognition: Features Versus Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1835233"
                        ],
                        "name": "I. Dryden",
                        "slug": "I.-Dryden",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Dryden",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Dryden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3209910"
                        ],
                        "name": "K. Mardia",
                        "slug": "K.-Mardia",
                        "structuredName": {
                            "firstName": "Kanti",
                            "lastName": "Mardia",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mardia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120455101,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9aeb70824923b3acc9f97ef22b988cb07e667e14",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we investigate the exact shape distribution for general Gaussian labelled point configurations in two dimensions. The shape density is written in a closed form, in terms of Kendall's or Bookstein's shape variables. The distribution simplifies considerably in certain cases, including the complex normal, isotropic, circular Markov and equal means cases. Various asymptotic properties of the distribution are investigated, including a large variation distribution and the normal approximation for small variations. The triangle case is considered in particular detail, and we compare the density with simulated densities for some examples. Finally, we consider inference problems, with an application in biology."
            },
            "slug": "General-shape-distributions-in-a-plane-Dryden-Mardia",
            "title": {
                "fragments": [],
                "text": "General shape distributions in a plane"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Applied Probability"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140335"
                        ],
                        "name": "A. Shashua",
                        "slug": "A.-Shashua",
                        "structuredName": {
                            "firstName": "Amnon",
                            "lastName": "Shashua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shashua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14079205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea8cd3dc29f3904f3fbc5fc9e089a6391900bb45",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the differences \u2014 conceptually and algorithmically \u2014 between affine and projective frameworks for the tasks of visual recognition and reconstruction from perspective views. The study is made by first proposing an affine framework for perspective views, captured by a single remarkably simple equation, which is based on a viewer-centered invariant we call relative affine structure. Via corollaries of the main result we make connections to previous work and show that Euclidean, affine and projective structure representations can be obtained by simple specializations and generalizations of our main results."
            },
            "slug": "On-Geomatric-and-Algebraic-Aspects-of-3D-Affine-and-Shashua",
            "title": {
                "fragments": [],
                "text": "On Geomatric and Algebraic Aspects of 3D Affine and Projective Structures from Perspective 2D Views"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes an affine framework for perspective views, captured by a single remarkably simple equation, based on a viewer-centered invariant the authors call relative affine structure, and shows that Euclidean, affine and projective structure representations can be obtained by simple specializations and generalizations of the main results."
            },
            "venue": {
                "fragments": [],
                "text": "Applications of Invariance in Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16925,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1422996,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "ebb59eb40608b9e37b3c8233351762c9a1228d54",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Combining-point-distribution-models-with-shape-on-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Combining point distribution models with shape models based on finite element analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 570648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66d75a5fe9e1b6511c5135d68e9ce8c0da5a7374",
            "isKey": false,
            "numCitedBy": 2852,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion. This results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix, without increasing the complexity of the calculation. The resulting approximation of faces projected from outside of the data set onto this optimal basis is improved on average. >"
            },
            "slug": "Application-of-the-Karhunen-Loeve-Procedure-for-the-Kirby-Sirovich",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen-Loeve Procedure for the Characterization of Human Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion, which results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 14
                            }
                        ],
                        "text": "Pope and Lowe [17, 18] used probability theory to model the variation in shape of triples of features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Arthur R. Pope and David G. Lowe."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Pope and Lowe [17, 18] used probability theory to modelthe variation in shape of triples of features."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Feature Uncertainty Models for  Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "In IEEE International Symposium on Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830709"
                        ],
                        "name": "A. Lanitis",
                        "slug": "A.-Lanitis",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Lanitis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lanitis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104934211"
                        ],
                        "name": "T. Ahmad",
                        "slug": "T.-Ahmad",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Ahmad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ahmad"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14997432,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3a4ea697d2affa227c69ab7608428bf76cc51214",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "d b y b y T u r k a n d P e n t l a n d [ 6 ] a n d C r a w e t a l [ 1 2 ] ."
            },
            "slug": "Automatic-interpretation-of-human-faces-and-hand-Lanitis-Taylor",
            "title": {
                "fragments": [],
                "text": "Automatic interpretation of human faces and hand gestures using flexible models."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "d b y b y T u r k a n d P e n t l a nD [ 6 ] a nd C r a w e t a l [ 1 2 ] ."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695784"
                        ],
                        "name": "U. Fayyad",
                        "slug": "U.-Fayyad",
                        "structuredName": {
                            "firstName": "Usama",
                            "lastName": "Fayyad",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Fayyad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50860274"
                        ],
                        "name": "Padhraic Smyth",
                        "slug": "Padhraic-Smyth",
                        "structuredName": {
                            "firstName": "Padhraic",
                            "lastName": "Smyth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Padhraic Smyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5647595,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7aeb1fd1d15173b3b0ce389993494e5d7d95960d",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Our long-term goal is to develop a trainable tool for locating patterns of interest in large image databases. Toward this goal we have developed a prototype system, based on classical filtering and statistical pattern recognition techniques, for automatically locating volcanoes in the Magellan SAR database of Venus. Training for the specific volcano-detection task is obtained by synthesizing feature templates (via normalization and principal components analysis) from a small number of examples provided by experts. Candidate regions identified by a focus of attention (FOA) algorithm are classified based on correlations with the feature templates. Preliminary tests show performance comparable to trained human observers.<<ETX>>"
            },
            "slug": "Automating-the-hunt-for-volcanoes-on-Venus-Burl-Fayyad",
            "title": {
                "fragments": [],
                "text": "Automating the hunt for volcanoes on Venus"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A prototype system, based on classical filtering and statistical pattern recognition techniques, for automatically locating volcanoes in the Magellan SAR database of Venus, and preliminary tests show performance comparable to trained human observers."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "Methods such as alignment [11], geometric invariants [15], combinations of views [24, 21], and geometric hashing [26, 19] t within this category."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208784962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ff65ac698013cdd9d61326cab49a1d75404e001",
            "isKey": false,
            "numCitedBy": 18722,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Editors",
            "title": {
                "fragments": [],
                "text": "Editors"
            },
            "venue": {
                "fragments": [],
                "text": "Brain Research Bulletin"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 14
                            }
                        ],
                        "text": "Pope and Lowe [17, 18] used probability theory to model the variation in shape of triples of features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Arthur R. Pope and David G. Lowe."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Pope and Lowe [17, 18] used probability theory to modelthe variation in shape of triples of features."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Feature Uncertainty Models for  Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "In IEEE International Symposium on Computer Vision,"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64312660,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46e9d543485bbe943b82d1365f28e64e85663868",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Networks-for-Visual-Pattern-Recognition-Fukushima",
            "title": {
                "fragments": [],
                "text": "Neural Networks for Visual Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "A technique known as \\Fisher's Linear Discriminant\" [9] provides us with the direction which maximizes the separability of the two classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 186248191,
            "fieldsOfStudy": [],
            "id": "f7725ec3cbf99605ec4f6e5a8d2ebf11eb407933",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern Classi cation and Scene Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2598854"
                        ],
                        "name": "I. Rigoutsos",
                        "slug": "I.-Rigoutsos",
                        "structuredName": {
                            "firstName": "Isidore",
                            "lastName": "Rigoutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Rigoutsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30489560"
                        ],
                        "name": "R. Hummel",
                        "slug": "R.-Hummel",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Hummel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hummel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206561182,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7fc1c85bf41266762623a81abaad8cbf19c48e4",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Bayesian-Approach-to-Model-Matching-with-Hashing-Rigoutsos-Hummel",
            "title": {
                "fragments": [],
                "text": "A Bayesian Approach to Model Matching with Geometric Hashing"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 39
                            }
                        ],
                        "text": "Lades, von der Malsburg and colleagues [13, 25] proposed to use jet-based detectors and deformable meshes for encoding shape."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and C"
            },
            "venue": {
                "fragments": [],
                "text": "von der Malsburg. \\A Neural System for the Recognition of  Partially Occluded Objects in Cluttered Scenes\". Int. J. of Pattern Recognition  and Arti cial Intelligence, 7(4):935{948,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Learning Feature Uncertainty Models for Object Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Symposium on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 39
                            }
                        ],
                        "text": "Lades, von der Malsburg and colleagues [13, 25] proposed to use jet-based detectors and deformable meshes for encoding shape."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural System for the Recognition of  Partially Occluded Objects in Cluttered Scenes"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. of Pattern Recognition  and Arti cial Intelligence,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "From Segmentation to Interpretation and Back: Mathematical Methods in Computer Vision, chapter \\Recognition of Visual Object Classes"
            },
            "venue": {
                "fragments": [],
                "text": "From Segmentation to Interpretation and Back: Mathematical Methods in Computer Vision, chapter \\Recognition of Visual Object Classes"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\\Object Recognition Using Alignment"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 1 st Int. Conf. Computer Vision"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 3,
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 32,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Probabilistic-Approach-to-Object-Recognition-and-Burl-Weber/102cf35af78c14019edfe28c8cd624da7d5b3fac?sort=total-citations"
}