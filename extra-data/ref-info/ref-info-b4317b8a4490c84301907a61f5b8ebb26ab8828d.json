{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3278929"
                        ],
                        "name": "Stephen D. Richardson",
                        "slug": "Stephen-D.-Richardson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Richardson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen D. Richardson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58411801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02e2589ef2c1541fd15a92bc3831a45e28db6fc9",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation describes the creation of a large-scale, richly structured lexical knowledge base (LKB) from complex structures of labeled semantic relations. These structures were automatically extracted using a natural language parser from the definitions and example sentences contained in two machine readable dictionaries. The structures were then completely inverted and propagated across all of the relevant headwords in the dictionaries to create the LKB. \nA method is described for efficiently accessing salient paths of semantic relations between words in the LKB using weights assigned to those paths. The weights are based on a unique computation called averaged vertex probability. Extended paths, created by joining sub-paths from two different semantic relation structures, are allowed in order to increase the coverage of the information in the LKB. \nA novel procedure is used to determine the similarity between words in the LKB based on the patterns of the semantic relation paths connecting those words. The patterns were obtained by extensive training using word pairs from an online thesaurus and a specially created anti-thesaurus. \nThe similarity procedure and the path accessing mechanism are used in a procedure to infer semantic relations that are not explicitly stored in the LKB. In particular, the utility of such inferences is discussed in the context of disambiguating phrasal attachments in a natural language understanding system. \nQuantitative results indicate that the size and coverage of the LKB created in this research and the effectiveness of the methods for accessing explicit and implicit information contained therein represent significant progress toward the development of a truly broad-coverage semantic component for natural language processing."
            },
            "slug": "Determining-similarity-and-inferring-relations-in-a-Richardson",
            "title": {
                "fragments": [],
                "text": "Determining similarity and inferring relations in a lexical knowledge base"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Quantitative results indicate that the size and coverage of the LKB created in this research and the effectiveness of the methods for accessing explicit and implicit information contained therein represent significant progress toward the development of a truly broad-coverage semantic component for natural language processing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145175167"
                        ],
                        "name": "J. Robin",
                        "slug": "J.-Robin",
                        "structuredName": {
                            "firstName": "Jacques",
                            "lastName": "Robin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Robin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19091184,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b947f31028c542bbbc75f64773f5e8488977109",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatically summarizing vast amounts of on-line quantitative data with a short natural language paragraph has a wide range of real-world applications. However, this specific task raises a number of difficult issues that are quite distinct from the generic task of language generation: conciseness, complex sentences, floating concepts, historical background, paraphrasing power and implicit content. \nIn this thesis, I address these specific issues by proposing a new generation model in which a first pass builds a draft containing only the essential new facts to report and a second pass incrementally revises this draft to opportunistically add as many background facts as can fit within the space limit. This model requires a new type of linguistic knowledge: revision operations, which specifies the various ways a draft can be transformed in order to concisely accommodate a new piece of information. I present an in-depth corpus analysis of human-written sports summaries that resulted in an extensive set of such revision operations. I also present the implementation, based on functional unification grammars, of the system scSTREAK, which relies on these operations to incrementally generate complex sentences summarizing basketball games. This thesis also contains two quantitative evaluations. The first shows that the new revision-based generation model is far more robust than the one-pass model of previous generators. The second evaluation demonstrates that the revision operations acquired during the corpus analysis and implemented in scSTREAK are, for the most part, portable to at least one other quantitative domain (the stock market). \nscSTREAK is the first report generator that systematically places the facts which it summarizes in their historical perspective. It is more concise than previous systems thanks to its ability to generate more complex sentences and to opportunistically convey facts by adding a few words to carefully chosen draft constituents. The revision operations on which scSTREAK is based constitute the first set of corpus-based linguistic knowledge geared towards incremental generation. The evaluation presented in this thesis is also the first attempt to quantitatively assess the robustness of a new generation model and the portability of a new type of linguistic knowledge."
            },
            "slug": "Revision-based-generation-of-natural-language-and-Robin",
            "title": {
                "fragments": [],
                "text": "Revision-based generation of natural language summaries providing historical background: corpus-based analysis, design, implementation and evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This thesis presents a new generation model in which a first pass builds a draft containing only the essential new facts to report and a second pass incrementally revises this draft to opportunistically add as many background facts as can fit within the space limit."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716902"
                        ],
                        "name": "Marti A. Hearst",
                        "slug": "Marti-A.-Hearst",
                        "structuredName": {
                            "firstName": "Marti",
                            "lastName": "Hearst",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marti A. Hearst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The generation community focused mainly on rule-based text transformations in order to meet external constraints such as length and readability (Meteer and Shaked, 1988; Iordanskaja et al., 1991; Robin, 1994;  Dras, 1997 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15763200,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "dbfd191afbbc8317577cbc44afe7156df546e143",
            "isKey": false,
            "numCitedBy": 3648,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for the automatic acquisition of the hyponymy lexical relation from unrestricted text. Two goals motivate the approach: (i) avoidance of the need for pre-encoded knowledge and (ii) applicability across a wide range of text. We identify a set of lexico-syntactic patterns that are easily recognizable, that occur frequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest. We describe a method for discovering these patterns and suggest that other lexical relations will also be acquirable in this way. A subset of the acquisition algorithm is implemented and the results are used to augment and critique the structure of a large hand-built thesaurus. Extensions and applications to areas such as information retrieval are suggested."
            },
            "slug": "Automatic-Acquisition-of-Hyponyms-from-Large-Text-Hearst",
            "title": {
                "fragments": [],
                "text": "Automatic Acquisition of Hyponyms from Large Text Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A set of lexico-syntactic patterns that are easily recognizable, that occur frequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest are identified."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35400286"
                        ],
                        "name": "Z. Harris",
                        "slug": "Z.-Harris",
                        "structuredName": {
                            "firstName": "Zellig",
                            "lastName": "Harris",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 165
                            }
                        ],
                        "text": "Algorithms for finding similar words assume the Distributional Hypothesis, which states that words that occurred in the same contexts tend to have similar meanings (Harris, 1985)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 127
                            }
                        ],
                        "text": "Most algorithms for computing word similarity from text corpus are based on a principle known as the Distributional Hypothesis (Harris, 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 158
                            }
                        ],
                        "text": "4.1 The Underlying Assumption\nMost algorithms for computing word similarity from text corpus are based on a principle known as the Distributional Hypothesis (Harris, 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 86680084,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "decd9bc0385612bdf936928206d83730718e737e",
            "isKey": true,
            "numCitedBy": 2644,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "For the purposes of the present discussion, the term structure will be used in the following non-rigorous sense: A set of phonemes or a set of data is structured in respect to some feature, to the extent that we can form in terms of that feature some organized system of statements which describes the members of the set and their interrelations (at least up to some limit of complexity). In this sense, language can be structured in respect to various independent features. And whether it is structured (to more than a trivial extent) in respect to, say, regular historical change, social intercourse, meaning, or distribution - or to what extent it is structured in any of these respects - is a matter decidable by investigation. Here we will discuss how each language can be described in terms of a distributional structure, i.e. in terms of the occurrence of parts (ultimately sounds) relative to other parts, and how this description is complete without intrusion of other features such as history or meaning. It goes without saying that other studies of language - historical, psychological, etc.-are also possible, both in relation to distributional structure and independently of it."
            },
            "slug": "Distributional-Structure-Harris",
            "title": {
                "fragments": [],
                "text": "Distributional Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This discussion will discuss how each language can be described in terms of a distributional structure, i.e. in Terms of the occurrence of parts relative to other parts, and how this description is complete without intrusion of other features such as history or meaning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 84
                            }
                        ],
                        "text": "This accuracy is comparable to other broad-coverage English parsers (Collins, 1996; Charniak, 2000)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 538122,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76d5e3fa888bee872b7adb7fa810089aa8ab1d58",
            "isKey": false,
            "numCitedBy": 1855,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new parser for parsing down to Penn tree-bank style parse trees that achieves 90.1% average precision/recall for sentences of length 40 and less, and 89.5% for sentences of length 100 and less when trained and tested on the previously established [5, 9, 10, 15, 17] \"standard\" sections of the Wall Street Journal treebank. This represents a 13% decrease in error rate over the best single-parser results on this corpus [9]. The major technical innovation is the use of a \"maximum-entropy-inspired\" model for conditioning and smoothing that let us successfully to test and combine many different conditioning events. We also present some partial results showing the effects of different conditioning information, including a surprising 2% improvement due to guessing the lexical head's pre-terminal before guessing the lexical head."
            },
            "slug": "A-Maximum-Entropy-Inspired-Parser-Charniak",
            "title": {
                "fragments": [],
                "text": "A Maximum-Entropy-Inspired Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A new parser for parsing down to Penn tree-bank style parse trees that achieves 90.1% average precision/recall for sentences of length 40 and less and 89.5% when trained and tested on the previously established sections of the Wall Street Journal treebank is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990190"
                        ],
                        "name": "P. Pantel",
                        "slug": "P.-Pantel",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Pantel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pantel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 17
                            }
                        ],
                        "text": "In another work (Lin and Pantel, 2001), we constructed semantic classes from text corpus with an unsupervised algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17715808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "788bc1801215c8eb9b466ad4db00fec5832534de",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Many applications dealing with textual information require classification of words into semantic classes (or concepts). However, manually constructing semantic classes is a tedious task. In this paper, we present an algorithm, UNICON, for UNsupervised Induction of CONcepts. Some advantages of UNICON over previous approaches include the ability to classify words with low frequency counts, the ability to cluster a large number of elements in a high-dimensional space, and the ability to classify previously unknown words into existing clusters. Furthermore, since the algorithm is unsupervised, a set of concepts may be constructed for any corpus."
            },
            "slug": "Induction-of-semantic-classes-from-natural-language-Lin-Pantel",
            "title": {
                "fragments": [],
                "text": "Induction of semantic classes from natural language text"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents an algorithm, UNICON, for UNsupervised Induction of CONcepts, which has some advantages over previous approaches, including the ability to classify words with low frequency counts, the able to cluster a large number of elements in a high-dimensional space, and theAbility to classify previously unknown words into existing clusters."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 69
                            }
                        ],
                        "text": "This accuracy is comparable to other broad-coverage English parsers (Collins, 1996; Charniak, 2000)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12615602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3764baa7465201f054083d02b58fa75f883c4461",
            "isKey": false,
            "numCitedBy": 736,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new statistical parser which is based on probabilities of dependencies between head-words in the parse tree. Standard bigram probability estimation techniques are extended to calculate probabilities of dependencies between pairs of words. Tests using Wall Street Journal data show that the method performs at least as well as SPATTER (Magerman 95; Jelinek et al. 94), which has the best published results for a statistical parser on this task. The simplicity of the approach means the model trains on 40,000 sentences in under 15 minutes. With a beam search strategy parsing speed can be improved to over 200 sentences a minute with negligible loss in accuracy."
            },
            "slug": "A-New-Statistical-Parser-Based-on-Bigram-Lexical-Collins",
            "title": {
                "fragments": [],
                "text": "A New Statistical Parser Based on Bigram Lexical Dependencies"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new statistical parser which is based on probabilities of dependencies between head-words in the parse tree, which trains on 40,000 sentences in under 15 minutes and can be improved to over 200 sentences a minute with negligible loss in accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145165877"
                        ],
                        "name": "P. Hanks",
                        "slug": "P.-Hanks",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Hanks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hanks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 93
                            }
                        ],
                        "text": "Mutual information is a commonly used measure for the association strength between two words (Church and Hanks, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 117
                            }
                        ],
                        "text": "4.3 Mutual Information\nMutual information is a commonly used measure for the association strength between two words (Church and Hanks, 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9558665,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "9e2caa39ac534744a180972a30a320ad0ae41ea3",
            "isKey": true,
            "numCitedBy": 4363,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The term word association is used in a very particular sense in the psycholinguistic literature. (Generally speaking, subjects respond quicker than normal to the word nurse if it follows a highly associated word such as doctor. ) We will extend the term to provide the basis for a statistical description of a variety of interesting linguistic phenomena, ranging from semantic relations of the doctor/nurse type (content word/content word) to lexico-syntactic co-occurrence constraints between verbs and prepositions (content word/function word). This paper will propose an objective measure based on the information theoretic notion of mutual information, for estimating word association norms from computer readable corpora. (The standard method of obtaining word association norms, testing a few thousand subjects on a few hundred words, is both costly and unreliable.) The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "slug": "Word-Association-Norms,-Mutual-Information-and-Church-Hanks",
            "title": {
                "fragments": [],
                "text": "Word Association Norms, Mutual Information and Lexicography"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed measure, the association ratio, estimates word association norms directly from computer readable corpora, making it possible to estimate norms for tens of thousands of words."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1923461"
                        ],
                        "name": "Shian-Hua Lin",
                        "slug": "Shian-Hua-Lin",
                        "structuredName": {
                            "firstName": "Shian-Hua",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shian-Hua Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145667265"
                        ],
                        "name": "C. Shih",
                        "slug": "C.-Shih",
                        "structuredName": {
                            "firstName": "Chi-Sheng",
                            "lastName": "Shih",
                            "middleNames": [
                                "Daniel"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Shih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125046394"
                        ],
                        "name": "M. Chen",
                        "slug": "M.-Chen",
                        "structuredName": {
                            "firstName": "Meng",
                            "lastName": "Chen",
                            "middleNames": [
                                "Chang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143608739"
                        ],
                        "name": "Jan-Ming Ho",
                        "slug": "Jan-Ming-Ho",
                        "structuredName": {
                            "firstName": "Jan-Ming",
                            "lastName": "Ho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan-Ming Ho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689992"
                        ],
                        "name": "M. Ko",
                        "slug": "M.-Ko",
                        "structuredName": {
                            "firstName": "Ming-Tat",
                            "lastName": "Ko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143515968"
                        ],
                        "name": "Yueh-Ming Huang",
                        "slug": "Yueh-Ming-Huang",
                        "structuredName": {
                            "firstName": "Yueh-Ming",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yueh-Ming Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13341735,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "c9b9915851e89c4a54fe63eb85c6974c4c704576",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a system that extracts and generalizes terms from Internet documents to represent classification knowledge of a given class hierarchy. We propose a measurement to evaluate the importance of a term with respect to a class in the class hierarchy, and denote it as support. With a given threshold, terms with high supports are sifted as keywords of a class, and terms with low supports are filtered out. To further enhance the recall of this approach, Mining Association Rules technique is applied to mine the association between terms. An inference model is composed of these association relations and the previously computed supports of the terms in the class. To increase the recall rate of the keyword selection process. we then present a polynomialtime inference algorithm to promote a term, strongly associated to a known keyword, to a keyword. According to our experiment results on the collected Internet documents from Yam search engine, we show that the proposed methods In the paper contribute to refine the classification knowledge and increase the recall of keyword selection."
            },
            "slug": "Extracting-classification-knowledge-of-Internet-a-Lin-Shih",
            "title": {
                "fragments": [],
                "text": "Extracting classification knowledge of Internet documents with mining term associations: a semantic approach"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A system that extracts and generalizes terms from Internet documents to represent classification knowledge of a given class hierarchy and presents a polynomialtime inference algorithm to promote a term, strongly associated to a known keyword, to a keyword."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3227843"
                        ],
                        "name": "M. Meteer",
                        "slug": "M.-Meteer",
                        "structuredName": {
                            "firstName": "Marie",
                            "lastName": "Meteer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Meteer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2729817"
                        ],
                        "name": "V. Shaked",
                        "slug": "V.-Shaked",
                        "structuredName": {
                            "firstName": "Varda",
                            "lastName": "Shaked",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Shaked"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5076418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16fcf74245d98ff681c336edbf6f2af5c18664a8",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new dimension to paraphrasing text in which characteristics of the original text motivate strategies for effective paraphrasing. Our system combines two existing robust components: the IRUS-II natural language understanding system and the SPOKESMAN generation system. We describe the architecture of the system and enhancements made to these components to facilitate paraphrasing. We particularly look at how levels of representation in these two systems are used by specialists in the paraphraser which define potential problems and paraphrasing strategies. Finally, we look at the role of paraphrasing in a cooperative dialog system. We will focus here on paraphrasing in the context of natural language interfaces and particularly on how multiple interpretations introduced by various kinds of ambiguity can be conbasted in paraphrases using both sentence structure and highlighting and formating the text itself."
            },
            "slug": "Strategies-for-Effective-Paraphrasing-Meteer-Shaked",
            "title": {
                "fragments": [],
                "text": "Strategies for Effective Paraphrasing"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new dimension to paraphrasing text in which characteristics of the original text motivate strategies for effective paraphrase is presented, which combines two existing robust components: the IRUS-II natural language understanding system and the SPOKESMAN generation system."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713428"
                        ],
                        "name": "S. Harabagiu",
                        "slug": "S.-Harabagiu",
                        "structuredName": {
                            "firstName": "Sanda",
                            "lastName": "Harabagiu",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Harabagiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724629"
                        ],
                        "name": "Marius Pasca",
                        "slug": "Marius-Pasca",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Pasca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marius Pasca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2248349"
                        ],
                        "name": "Steven J. Maiorano",
                        "slug": "Steven-J.-Maiorano",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Maiorano",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven J. Maiorano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 29
                            }
                        ],
                        "text": "In the LASSO/FALCON systems (Harabagiu et al., 2000), the most successful QA systems in TREC-8 and TREC-9, a theorem prover is used to justify the answers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5544341,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53073cf42228f7e1d23c513eb474c7e599f82c02",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the integration of several knowledge-based natural language processing techniques into a Question Answering system, capable of mining textual answers from large collections of texts. Surprizing quality is achieved when several lightweight knowledge-based NLP techniques complement mostly shallow, surface-based approaches."
            },
            "slug": "Experiments-with-Open-Domain-Textual-Question-Harabagiu-Pasca",
            "title": {
                "fragments": [],
                "text": "Experiments with Open-Domain Textual Question Answering"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper describes the integration of several knowledge-based natural language processing techniques into a Question Answering system, capable of mining textual answers from large collections of texts."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723684"
                        ],
                        "name": "Peter G. Anick",
                        "slug": "Peter-G.-Anick",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Anick",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter G. Anick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2554782"
                        ],
                        "name": "S. Tipirneni",
                        "slug": "S.-Tipirneni",
                        "structuredName": {
                            "firstName": "Suresh",
                            "lastName": "Tipirneni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tipirneni"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 103
                            }
                        ],
                        "text": "It has been shown that such query expansion does promote effective retrieval (Arampatzis et al., 1998; Anick and Tipirneni, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6058816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "019ef56f6b2147d0fa05a19e2972e6cecc73d956",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new linguistic approach to the construction of terminological feedback for use in interactive query refinement. The method exploits the tendency for key domain concepts within result sets to participate in families of semantically related lexical compounds. We outline an algorithm for computing a ranked list of result set \u201cthemes\u201d and describe a web application, the Paraphrase Search Assistant, designed to make use of the theme extraction algorithm to support a recognition-based, iterative information seeking dialog."
            },
            "slug": "The-paraphrase-search-assistant:-terminological-for-Anick-Tipirneni",
            "title": {
                "fragments": [],
                "text": "The paraphrase search assistant: terminological feedback for iterative information seeking"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An algorithm for computing a ranked list of result set \u201cthemes\u201d and a web application designed to make use of the theme extraction algorithm to support a recognition-based, iterative information seeking dialog are described."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145212976"
                        ],
                        "name": "C\u00e9cile Paris",
                        "slug": "C\u00e9cile-Paris",
                        "structuredName": {
                            "firstName": "C\u00e9cile",
                            "lastName": "Paris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C\u00e9cile Paris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69036062"
                        ],
                        "name": "W. Swartout",
                        "slug": "W.-Swartout",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Swartout",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Swartout"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847871"
                        ],
                        "name": "W. Mann",
                        "slug": "W.-Mann",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Mann",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Mann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13355900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "572cb39ec0eb6e61e29d4a9c109ab943df82ea2e",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the aims of Natural Language Processing is to facilitate .the use of computers by allowing their users to communicate in natural language. There are two important aspects to person-machine communication: understanding and generating. While natural language understanding has been a major focus of research, natural language generation is a relatively new and increasingly active field of research. This book presents an overview of the state of the art in natural language generation, describing both new results and directions for new research. The principal emphasis of natural language generation is not only to facili tate the use of computers but also to develop a computational theory of human language ability. In doing so, it is a tool for extending, clarifying and verifying theories that have been put forth in linguistics, psychology and sociology about how people communicate. A natural language generator will typically have access to a large body of knowledge from which to select information to present to users as well as numer of expressing it. Generating a text can thus be seen as a problem of ous ways decision-making under multiple constraints: constraints from the propositional knowledge at hand, from the linguistic tools available, from the communicative goals and intentions to be achieved, from the audience the text is aimed at and from the situation and past discourse. Researchers in generation try to identify the factors involved in this process and determine how best to represent the factors and their dependencies."
            },
            "slug": "Natural-Language-Generation-in-Artificial-and-Paris-Swartout",
            "title": {
                "fragments": [],
                "text": "Natural Language Generation in Artificial Intelligence and Computational Linguistics"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This book presents an overview of the state of the art in natural language generation, describing both new results and directions for new research."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744669"
                        ],
                        "name": "U. Hahn",
                        "slug": "U.-Hahn",
                        "structuredName": {
                            "firstName": "Udo",
                            "lastName": "Hahn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Hahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2003934"
                        ],
                        "name": "Klemens Schnattinger",
                        "slug": "Klemens-Schnattinger",
                        "structuredName": {
                            "firstName": "Klemens",
                            "lastName": "Schnattinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klemens Schnattinger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2864310,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "bc93e1f6b651ee99895526406ae1fc4c741ae161",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an approach to the automatic acquisition of new concepts from natural language texts which is tightly integrated with the underlying text understanding process. The learning model is centered around the 'quality' of different forms of linguistic and conceptual evidence which underlies the incremental generation and refinement of alternative concept hypotheses, each one capturing a different conceptual reading for an unknown lexical item."
            },
            "slug": "A-Text-Understander-that-Learns-Hahn-Schnattinger",
            "title": {
                "fragments": [],
                "text": "A Text Understander that Learns"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "An approach to the automatic acquisition of new concepts from natural language texts which is tightly integrated with the underlying text understanding process and centered around the 'quality' of different forms of linguistic and conceptual evidence."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 98
                            }
                        ],
                        "text": "We used Minipar to parse about 1GB of newspaper text (San Jose Mercury, Wall Street Journal and AP Newswire from the TREC collection)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6713452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5eb328cf7e94995199e4c82a1f4d0696430a80b5",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data."
            },
            "slug": "Distributional-Clustering-of-English-Words-Pereira-Tishby",
            "title": {
                "fragments": [],
                "text": "Distributional Clustering of English Words"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deterministic annealing is used to find lowest distortion sets of clusters: as the annealed parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3215185"
                        ],
                        "name": "G. Sampson",
                        "slug": "G.-Sampson",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Sampson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sampson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 52
                            }
                        ],
                        "text": "Evaluation with the manually parsed SUSANNE corpus (Sampson, 1995) shows that about 89% of the dependency relationships in Minipar outputs are correct."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12621734,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "9cdbb0be2f0a9bdd9b69e044f0680affb373a507",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer processing of natural language is a burgeoning field, but until now there has been no agreement on a standardized classification of the diverse structural elements that occur in real-life language material. This book attempts to define a \"Linnaean taxonomy\" for the English language: an annotation scheme, the SUSANNE scheme, which yields a labelled constituency structure for any string of English, comprehensively identifying all of its surface and logical structural properties. The structure is specified with sufficient rigour that analysts working independently must produce identical annotations for a given example. The scheme is based on large sample of real-life use of British and American written and spoken English. The book also describes the SUSANNE electronic corpus of English which is annotated in accordance with the scheme. It is freely available as a research resource to anyone working at a computer conected to Internet, and since 1992 has come into widespread use in academic and commerical research environments on four continents."
            },
            "slug": "English-for-the-Computer:-The-SUSANNE-Corpus-and-Sampson",
            "title": {
                "fragments": [],
                "text": "English for the Computer: The SUSANNE Corpus and Analytic Scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This book attempts to define a \"Linnaean taxonomy\" for the English language: an annotation scheme, the SUSANNE scheme, which yields a labelled constituency structure for any string of English, comprehensively identifying all of its surface and logical structural properties."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145864794"
                        ],
                        "name": "Ronen Feldman",
                        "slug": "Ronen-Feldman",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Feldman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronen Feldman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716503"
                        ],
                        "name": "M. Fresko",
                        "slug": "M.-Fresko",
                        "structuredName": {
                            "firstName": "Moshe",
                            "lastName": "Fresko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fresko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097208827"
                        ],
                        "name": "Yakkov Kinar",
                        "slug": "Yakkov-Kinar",
                        "structuredName": {
                            "firstName": "Yakkov",
                            "lastName": "Kinar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yakkov Kinar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682750"
                        ],
                        "name": "Yehuda Lindell",
                        "slug": "Yehuda-Lindell",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Lindell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yehuda Lindell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346879"
                        ],
                        "name": "Orly Liphstat",
                        "slug": "Orly-Liphstat",
                        "structuredName": {
                            "firstName": "Orly",
                            "lastName": "Liphstat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Orly Liphstat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763338"
                        ],
                        "name": "M. Rajman",
                        "slug": "M.-Rajman",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Rajman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rajman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2012715"
                        ],
                        "name": "Jonathan Schler",
                        "slug": "Jonathan-Schler",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Schler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Schler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360279"
                        ],
                        "name": "Oren Zamir",
                        "slug": "Oren-Zamir",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Zamir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Zamir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14785458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "776111bab0b15da9067484a96f4b1f621c5d5364",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowledge Discovery in Databases (KDD) focuses on the computerized exploration of large amounts of data and on the discovery of interesting patterns within them. While most work on KDD has been concerned with structured databases, there has been little work on handling the huge amount of information that is available only in unstructured textual form. Previous work in text mining focused at the word or the tag level. This paper presents an approach to performing text mining at the term level. The mining process starts by preprocessing the document collection and extracting terms from the documents. Each document is then represented by a set of terms and annotations characterizing the document. Terms and additional higher-level entities are then organized in a hierarchical taxonomy. In this paper we will describe the Term Extraction module of the Document Explorer system, and provide experimental evaluation performed on a set of 52,000 documents published by Reuters in the years 1995\u20131996."
            },
            "slug": "Text-Mining-at-the-Term-Level-Feldman-Fresko",
            "title": {
                "fragments": [],
                "text": "Text Mining at the Term Level"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes the Term Extraction module of the Document Explorer system, and provides experimental evaluation performed on a set of 52,000 documents published by Reuters in the years 1995\u20131996."
            },
            "venue": {
                "fragments": [],
                "text": "PKDD"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35575984"
                        ],
                        "name": "A. Arampatzis",
                        "slug": "A.-Arampatzis",
                        "structuredName": {
                            "firstName": "Avi",
                            "lastName": "Arampatzis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Arampatzis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2775549"
                        ],
                        "name": "T. Tsoris",
                        "slug": "T.-Tsoris",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Tsoris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tsoris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713642"
                        ],
                        "name": "C. Koster",
                        "slug": "C.-Koster",
                        "structuredName": {
                            "firstName": "Cornelis",
                            "lastName": "Koster",
                            "middleNames": [
                                "H.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149432"
                        ],
                        "name": "T. V. D. Weide",
                        "slug": "T.-V.-D.-Weide",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Weide",
                            "middleNames": [
                                "P.",
                                "van",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. V. D. Weide"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 78
                            }
                        ],
                        "text": "It has been shown that such query expansion does promote effective retrieval (Arampatzis et al., 1998; Anick and Tipirneni, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2867324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c27efb0a11860755960929d9d4f168734cf3180f",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Phase-Based-Information-Retrieval-Arampatzis-Tsoris",
            "title": {
                "fragments": [],
                "text": "Phase-Based Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717038"
                        ],
                        "name": "C. Jacquemin",
                        "slug": "C.-Jacquemin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Jacquemin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacquemin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761739"
                        ],
                        "name": "Judith L. Klavans",
                        "slug": "Judith-L.-Klavans",
                        "structuredName": {
                            "firstName": "Judith",
                            "lastName": "Klavans",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Judith L. Klavans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2601166"
                        ],
                        "name": "E. Tzoukermann",
                        "slug": "E.-Tzoukermann",
                        "structuredName": {
                            "firstName": "Evelyne",
                            "lastName": "Tzoukermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Tzoukermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 136
                            }
                        ],
                        "text": "Morphological variant query expansion was treated by Sparck Jones and Tait (1984) using a semantic interpreter and by the Fastr system (Jacquemin et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Morphological variant query expansion was treated by Sparck Jones and Tait (1984) using a semantic interpreter and by the Fastr system ( Jacquemin et al., 1997 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9497766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e75b898ff6e74465871dc20ca2a202dcb7e6bb0",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for the automatic production of controlled index terms is presented using linguistically-motivated techniques. This includes a finite-state part of speech tagger, a derivational morphological processor for analysis and generation, and a unification-based shallow-level parser using transformational rules over syntactic patterns. The contribution of this research is the successful combination of parsing over a seed term list coupled with derivational morphology to achieve greater coverage of multi-word terms for indexing and retrieval. Final results are evaluated for precision and recall, and implications for indexing and retrieval are discussed."
            },
            "slug": "Expansion-of-Multi-Word-Terms-for-Indexing-and-and-Jacquemin-Klavans",
            "title": {
                "fragments": [],
                "text": "Expansion of Multi-Word Terms for Indexing and Retrieval Using Morphology and Syntax"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The contribution of this research is the successful combination of parsing over a seed term list coupled with derivational morphology to achieve greater coverage of multi-word terms for indexing and retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767307"
                        ],
                        "name": "H. Alshawi",
                        "slug": "H.-Alshawi",
                        "structuredName": {
                            "firstName": "Hiyan",
                            "lastName": "Alshawi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Alshawi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35408831"
                        ],
                        "name": "D. Carter",
                        "slug": "D.-Carter",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Carter",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Carter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Alshawi and Carter (1994) generalized Equation (1) to handle three events:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Alshawi and Carter (1994) generalized Equation (1) to handle three events:\n( ) ( )( ) ( ) ( )zPyPxP zyxPzyxmi ,,log,, = (3)\nEquation (3) compares the MLE of the joint probability of x, y, and z with the model that assumes independence between x, y, and z."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1714108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3376bc52798561e74f82ae92d2ea55bdf8b2bcce",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an automatic method for weighting the contributions of preference functions used in disambiguation. Initial scaling factors are derived as the solution to a least squares minimization problem, and improvements are then made by hill climbing. The method is applied to disambiguating sentences in the Air Travel Information System corpus, and the performance of the resulting scaling factors is compared with hand-tuned factors. We then focus on one class of preference function, those based on semantic lexical collocations. Experimental results are presented showing that such functions vary considerably in selecting correct analyses. In particular, we define a function that performs significantly better than ones based on mutual information and likelihood ratios of lexical associations."
            },
            "slug": "Training-and-Scaling-Preference-Functions-for-Alshawi-Carter",
            "title": {
                "fragments": [],
                "text": "Training and Scaling Preference Functions for Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "An automatic method for weighting the contributions of preference functions used in disambiguation is presented, and a function that performs significantly better than ones based on mutual information and likelihood ratios of lexical associations is defined."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744669"
                        ],
                        "name": "U. Hahn",
                        "slug": "U.-Hahn",
                        "structuredName": {
                            "firstName": "Udo",
                            "lastName": "Hahn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Hahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2003934"
                        ],
                        "name": "Klemens Schnattinger",
                        "slug": "Klemens-Schnattinger",
                        "structuredName": {
                            "firstName": "Klemens",
                            "lastName": "Schnattinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klemens Schnattinger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 148
                            }
                        ],
                        "text": "Most previous efforts on knowledge engineering have focused on creating tools for helping knowledge engineers transfer their knowledge to machines (Hahn and Schnattinger, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 519,
                                "start": 490
                            }
                        ],
                        "text": "For example, while it is quite trivial to come up with the rule \u0093X wrote Y \u2248 X is the author of Y\u0094, it seems hard to dream up a rule like \u0093X manufactures Y \u2248 X\u2019s Y factory\u0094, which can be used to infer that \u0093Chr\u00e9tien visited Peugot\u2019s newly renovated car factory in the afternoon\u0094 contains an answer to the query \u0093What does Peugot manufacture?\u0094 Most previous efforts on knowledge engineering have focused on creating tools for helping knowledge engineers transfer their knowledge to machines (Hahn and Schnattinger, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1743489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4adef6d5951172dfce9d49e8672d960d11b6f8de",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a methodology for automating the maintenance of domain-specific taxonomies based on natural language text understanding. A given ontology is incrementally updated as new concepts are acquired from real-world texts. The acquisition process is centered around the linguistic and conceptual \"quality\" of various forms of evidence underlying the generation and refinement of concept hypotheses. On the basis of the quality of evidence, concept hypotheses are ranked according to credibility and the most credible ones are selected for assimilation into the domain knowledge base."
            },
            "slug": "Towards-Text-Knowledge-Engineering-Hahn-Schnattinger",
            "title": {
                "fragments": [],
                "text": "Towards Text Knowledge Engineering"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work introduces a methodology for automating the maintenance of domain-specific taxonomies based on natural language text understanding and ranks concept hypotheses according to credibility and the most credible ones are selected for assimilation into the domain knowledge base."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795294"
                        ],
                        "name": "M. Dras",
                        "slug": "M.-Dras",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 209
                            }
                        ],
                        "text": "The generation community focused mainly on rule-based text transformations in order to meet external constraints such as length and readability (Meteer and Shaked, 1988; Iordanskaja et al., 1991; Robin, 1994; Dras, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 569,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d0541e7c0befb22a0c7bed90f28b77901f3635f5",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper develops a computational model of paraphrase under which text modification is carried out reluctantly; that is, there are external constraints, such as length or readability, on an otherwise ideal text, and modifications to the text are necessary to ensure conformance to these constraints. This problem is analogous to a mathematical optimisation problem: the textual constraints can be described as a set of constraint equations, and the requirement for minimal change to the text can be expressed as a function to be minimised; so techniques from this domain can be used to solve the problem. \nThe work is done as part of a computational paraphrase system using the XTAG system as a base. The paper will present a theoretical computational framework for working within the Reluctant Paraphrase paradigm: three types of textual constraints are specified, effects of paraphrase on text are described, and a model incorporating mathematical optimisation techniques is outlined."
            },
            "slug": "Reluctant-Paraphrase:-Textual-Restructuring-under-Dras",
            "title": {
                "fragments": [],
                "text": "Reluctant Paraphrase: Textual Restructuring under an Optimisation Model"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The paper will present a theoretical computational framework for working within the Reluctant Paraphrase paradigm: three types of textual constraints are specified, effects of paraphrase on text are described, and a model incorporating mathematical optimisation techniques is outlined."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795294"
                        ],
                        "name": "M. Dras",
                        "slug": "M.-Dras",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Dras (1999)\ndescribed syntactic paraphrases using a meta-grammar with a synchronous Tree Adjoining Grammar (TAG) formalism."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14483333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aed8f80672e77b0d2470e2999d3d8caf1a364093",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In applications such as translation and paraphrase, operations are carried out on grammars at the meta level. This paper shows how a meta-grammar, defining structure at the meta level, is useful in the case of such operations; in particular, how it solves problems in the current definition of Synchronous TAG (Shieber, 1994) caused by ignoring such structure in mapping between grammars, for applications such as translation. Moreover, essential properties of the formalism remain unchanged."
            },
            "slug": "A-Meta-Level-Grammar:-Redefining-Synchronous-TAG-Dras",
            "title": {
                "fragments": [],
                "text": "A Meta-Level Grammar: Redefining Synchronous TAG for Translation and Paraphrase"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This paper shows how a meta-grammar, defining structure at the meta level, is useful in the case of such operations; in particular, how it solves problems in the current definition of Synchronous TAG caused by ignoring such structure in mapping between grammars."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763338"
                        ],
                        "name": "M. Rajman",
                        "slug": "M.-Rajman",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Rajman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rajman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740190"
                        ],
                        "name": "Romaric Besan\u00e7on",
                        "slug": "Romaric-Besan\u00e7on",
                        "structuredName": {
                            "firstName": "Romaric",
                            "lastName": "Besan\u00e7on",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Romaric Besan\u00e7on"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60960056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eba5bcf2676112eeff0d953754ffde515e69031b",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In the general framework of knowledge discovery, Data Mining techniques are usually dedicated to information extraction from structured databases. Text Mining techniques, on the other hand, are dedicated to information extraction from unstructured textual data and Natural Language Processing (NLP) can then be seen as an interesting tool for the enhancement of information extraction procedures. In this paper, we present two examples of Text Mining tasks, association extraction and prototypical document extraction, along with several related NLP techniques."
            },
            "slug": "Text-Mining:-Natural-Language-techniques-and-Text-Rajman-Besan\u00e7on",
            "title": {
                "fragments": [],
                "text": "Text Mining: Natural Language techniques and Text Mining applications"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents two examples of Text Mining tasks, association extraction and prototypical document extraction, along with several related NLP techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21169546"
                        ],
                        "name": "Donald Hindle",
                        "slug": "Donald-Hindle",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hindle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Hindle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 84
                            }
                        ],
                        "text": "Our algorithm is a generalization of previous algorithms for finding similar words (Hindle, 1990; Pereira, 1993; Lin, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15862538,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "f3f3dcfcaa960ec201e0381f4d026e57e64bea76",
            "isKey": false,
            "numCitedBy": 689,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of determining the similarity of nouns on the basis of a metric derived from the distribution of subject, verb and object in a large text corpus is described. The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification."
            },
            "slug": "Noun-Classification-from-Predicate-Argument-Hindle",
            "title": {
                "fragments": [],
                "text": "Noun Classification from Predicate-Argument Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The resulting quasi-semantic classification of nouns demonstrates the plausibility of the distributional hypothesis, and has potential application to a variety of tasks, including automatic indexing, resolving nominal compounds, and determining the scope of modification."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717038"
                        ],
                        "name": "C. Jacquemin",
                        "slug": "C.-Jacquemin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Jacquemin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacquemin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2601166"
                        ],
                        "name": "E. Tzoukermann",
                        "slug": "E.-Tzoukermann",
                        "structuredName": {
                            "firstName": "Evelyne",
                            "lastName": "Tzoukermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Tzoukermann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60778670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7ad1f9b668befa797095a30e9c73210ee98c2dc",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a natural language processing (NLP) approach to automatic indexing over controlled vocabulary which accounts for term variation. The approach combines a part of speech tagger, a generator of morphologically related forms, and a shallow transformational parser. The system is applied to the French language; it is trained on newspaper articles and tested on scientific literature."
            },
            "slug": "NLP-for-Term-Variant-Extraction:-Synergy-Between-Jacquemin-Tzoukermann",
            "title": {
                "fragments": [],
                "text": "NLP for Term Variant Extraction: Synergy Between Morphology, Lexicon, and Syntax"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A natural language processing (NLP) approach to automatic indexing over controlled vocabulary which accounts for term variation is presented, applied to the French language."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060439347"
                        ],
                        "name": "C\u00e9cile Fabre",
                        "slug": "C\u00e9cile-Fabre",
                        "structuredName": {
                            "firstName": "C\u00e9cile",
                            "lastName": "Fabre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C\u00e9cile Fabre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717038"
                        ],
                        "name": "C. Jacquemin",
                        "slug": "C.-Jacquemin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Jacquemin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacquemin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 108
                            }
                        ],
                        "text": "Motivated by the fact that morpho-syntactic features inadequately separated correct and incorrect variants, Fabre and Jacquemin (2000) later extended this model using lexical semantics for obtaining noun-to-verb variants."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 116
                            }
                        ],
                        "text": "In previous work, such relationships have been referred to as paraphrases or variants (Sparck Jones and Tait, 1984; Fabre and Jacquemin, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3243536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62688039261ec175c9a0b4d983531ce33c70a9c8",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A reasonably simple, domain-independent, large-scale approach of lexical semantics to paraphrase recognition is presented in this paper. It relies on the enrichment of morphosyntactic rules and the addition of four boolean syntactico-semantic features to a set of 1,023 words. It results in a significant enhancement of precision of 30% with a slight decrease in recall of 10%."
            },
            "slug": "Boosting-Variant-Recognition-with-Light-Semantics-Fabre-Jacquemin",
            "title": {
                "fragments": [],
                "text": "Boosting Variant Recognition with Light Semantics"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A reasonably simple, domain-independent, large-scale approach of lexical semantics to paraphrase recognition is presented, which results in a significant enhancement of precision of 30% with a slight decrease in recall of 10%."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 16
                            }
                        ],
                        "text": "Like Principar (Lin, 1993), Minipar represents its grammar as a network where nodes represent grammatical categories and links represent types of syntactic (dependency) relationships."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9541345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d431d03433275a68bd4ccd6b97af665bb979294d",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Overgeneration is the main source of computational complexity in previous principle-based parsers. This paper presents a message passing algorithm for principle-based parsing that avoids the overgeneration problem. This algorithm has been implemented in C++ and successfully tested with example sentences from (van Riemsdijk and Williams, 1986)."
            },
            "slug": "Principle-Based-Parsing-without-Overgeneration-Lin",
            "title": {
                "fragments": [],
                "text": "Principle-Based Parsing without Overgeneration"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A message passing algorithm for principle-based parsing that avoids the overgeneration problem is presented and has been implemented in C++ and successfully tested with example sentences from (van Riemsdijk and Williams, 1986)."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104341046"
                        ],
                        "name": "L. Dekang",
                        "slug": "L.-Dekang",
                        "structuredName": {
                            "firstName": "Lu",
                            "lastName": "Dekang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Dekang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 113
                            }
                        ],
                        "text": "Our algorithm is a generalization of previous algorithms for finding similar words (Hindle, 1990; Pereira, 1993; Lin, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 285
                            }
                        ],
                        "text": "\u2026SlotpSlot\nwSlotp\nwSlotpmi ,*,,*, ,**,,, log\n,**, ,*, ,**, ,*, *,*,* ,**,\n*,*,* ,,\nlog,, \u00d7\n\u00d7 == (5)\n4.4 Similarity between Two Paths\nOnce the triple database is created, the similarity between two paths can be computed in the same way that the similarity between two words is computed in (Lin, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 155
                            }
                        ],
                        "text": "Once the triple database is created, the similarity between two paths can be computed in the same way that the similarity between two words is computed in (Lin, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 171
                            }
                        ],
                        "text": "Some algorithms use the words that occurred in a fixed window of a given word as its context while others use the dependency relationships of a given word as its context (Lin, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 36
                            }
                        ],
                        "text": "The similarity measure proposed in (Lin, 1998) takes this into account by computing the mutual information between a feature and a path."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14760279,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a432b8036514ab8d54ea9a5cc3771702522e6afb",
            "isKey": true,
            "numCitedBy": 180,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A collocation is a habitual word combination. Collocational knowledge is essential for many tasks in natural language processing. We present a method for extracting collocations from text corpora. By comparison with the SUSANNE corpus, we show that both high precision and broad coverage can be achieved with our method. Finally, we describe an application of the automatically extracted collocations for computing word similarities."
            },
            "slug": "Extracting-collocations-from-text-corpora-Dekang",
            "title": {
                "fragments": [],
                "text": "Extracting collocations from text corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A method for extracting collocations from text corpora with high precision and broad coverage is presented and an application of the automatically extracted collocations for computing word similarities is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145216926"
                        ],
                        "name": "B. Larsen",
                        "slug": "B.-Larsen",
                        "structuredName": {
                            "firstName": "Bjornar",
                            "lastName": "Larsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Larsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939759"
                        ],
                        "name": "Chinatsu Aone",
                        "slug": "Chinatsu-Aone",
                        "structuredName": {
                            "firstName": "Chinatsu",
                            "lastName": "Aone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chinatsu Aone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207587242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc34c28ee40356b4d7bbe7be7d173a2436a89688",
            "isKey": false,
            "numCitedBy": 969,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Clustering is a powerful technique for large-scale topic discovery from text. It involves two phases: first, feature extraction maps each document or record to a point in high-dimensional space, then clustering algorithms automatically group the points into a hierarchy of clusters. We describe an unsupervised, near-linear time text clustering system that offers a number of algorithm choices for each phase. We introduce a methodology for measuring the quality of a cluster hierarchy in terms of FMeasure, and present the results of experiments comparing different algorithms. The evaluation considers some feature selection parameters (tfidfand feature vector length) but focuses on the clustering algorithms, namely techniques from Scatter/Gather (buckshot, fractionation, and split/join) and kmeans. Our experiments suggest that continuous center adjustment contributes more to cluster quality than seed selection does. It follows that using a simpler seed selection algorithm gives a better time/quality tradeoff. We describe a refinement to center adjustment, \u201cvector average damping,\u201d that further improves cluster quality. We also compare the near-linear time algorithms to a group average greedy agglomerative clustering algorithm to demonstrate the time/quality tradeoff quantitatively."
            },
            "slug": "Fast-and-effective-text-mining-using-linear-time-Larsen-Aone",
            "title": {
                "fragments": [],
                "text": "Fast and effective text mining using linear-time document clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An unsupervised, near-linear time text clustering system that offers a number of algorithm choices for each phase, and a refinement to center adjustment, \u201cvector average damping,\u201d that further improves cluster quality."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1412391493"
                        ],
                        "name": "L. Ungar",
                        "slug": "L.-Ungar",
                        "structuredName": {
                            "firstName": "Lyle",
                            "lastName": "Ungar",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ungar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207699574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8856b09c032ed4f10ef8367a8f7088fbb891ec2b",
            "isKey": false,
            "numCitedBy": 1152,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "important problems involve clustering large datasets. Although naive implementations of clustering are computa- tionally expensive, there are established ecient techniques for clustering when the dataset has either (1) a limited num- ber of clusters, (2) a low feature dimensionality, or (3) a small number of data points. However, there has been much less work on methods of eciently clustering datasets that are large in all three ways at once|for example, having millions of data points that exist in many thousands of di- mensions representing many thousands of clusters. We present a new technique for clustering these large, high- dimensional datasets. The key idea involves using a cheap, approximate distance measure to eciently divide the data into overlapping subsets we call canopies .T hen cluster- ing is performed by measuring exact distances only between points that occur in a common canopy. Using canopies, large clustering problems that were formerly impossible become practical. Under reasonable assumptions about the cheap distance metric, this reduction in computational cost comes without any loss in clustering accuracy. Canopies can be applied to many domains and used with a variety of cluster- ing approaches, including Greedy Agglomerative Clustering, K-means and Expectation-Maximization. We present ex- perimental results on grouping bibliographic citations from the reference sections of research papers. Here the canopy approach reduces computation time over a traditional clus- tering approach by more than an order of magnitude and decreases error in comparison to a previously used algorithm by 25%."
            },
            "slug": "Efficient-clustering-of-high-dimensional-data-sets-McCallum-Nigam",
            "title": {
                "fragments": [],
                "text": "Efficient clustering of high-dimensional data sets with application to reference matching"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents a new technique for clustering large datasets, using a cheap, approximate distance measure to eciently divide the data into overlapping subsets the authors call canopies, and presents ex- perimental results on grouping bibliographic citations from the reference sections of research papers."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754680"
                        ],
                        "name": "Michael Elhadad",
                        "slug": "Michael-Elhadad",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Elhadad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Elhadad"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Barzilay et al. (1999) analyzed 200 two-sentence themes from a corpus and extracted seven lexico-syntactic paraphrasing rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Barzilay et al. (1999)  analyzed 200 two-sentence themes from a corpus and extracted seven lexico-syntactic paraphrasing rules."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7031344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f13d65762d257230438e4661fe9ba8962727521",
            "isKey": false,
            "numCitedBy": 470,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to automatically generate a concise summary by identifying and synthesizing similar elements across related text from a set of multiple documents. Our approach is unique in its usage of language generation to reformulate the wording of the summary."
            },
            "slug": "Information-Fusion-in-the-Context-of-Multi-Document-Barzilay-McKeown",
            "title": {
                "fragments": [],
                "text": "Information Fusion in the Context of Multi-Document Summarization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This approach is unique in its usage of language generation to reformulate the wording of the summary by identifying and synthesizing similar elements across related text from a set of multiple documents."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3086368"
                        ],
                        "name": "R. Berwick",
                        "slug": "R.-Berwick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Berwick",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Berwick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 45
                            }
                        ],
                        "text": "Minipar1 is a principle-based English parser (Berwick, 1991)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 58
                            }
                        ],
                        "text": "3.1 Minipar\nMinipar1 is a principle-based English parser (Berwick, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59897293,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "8802bbab5e725d01c47d8080bbb54301a85f50ea",
            "isKey": true,
            "numCitedBy": 41,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This book chronicles the first stirrings of a revolution in the study of natural language processing, language variation, and psycholinguistics\u2014what some have called principle-based parsing."
            },
            "slug": "Principles-of-Principle-Based-Parsing-Berwick",
            "title": {
                "fragments": [],
                "text": "Principles of Principle-Based Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This book chronicles the first stirrings of a revolution in the study of natural language processing, language variation, and psycholinguistics\u2014what some have called principle-based parsing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145848824"
                        ],
                        "name": "Karen Sp\u00e4rck Jones",
                        "slug": "Karen-Sp\u00e4rck-Jones",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Sp\u00e4rck Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Sp\u00e4rck Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144959176"
                        ],
                        "name": "J. Tait",
                        "slug": "J.-Tait",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tait"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 60
                            }
                        ],
                        "text": "Morphological variant query expansion was treated by Sparck Jones and Tait (1984) using a semantic interpreter and by the Fastr system (Jacquemin et al., 1997)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 94
                            }
                        ],
                        "text": "In previous work, such relationships have been referred to as paraphrases or variants (Sparck Jones and Tait, 1984; Fabre and Jacquemin, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33551203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af75c2df0281280792e1fd486d41ddf23dc8127e",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes research designed to improve automatic pre\u2010coordinate term indexing by applying powerful general\u2010purpose language analysis techniques to identify term sources in requests, and to generate variant expressions of the concepts involved for document text searching."
            },
            "slug": "Automatic-Search-Term-variant-Generation-Jones-Tait",
            "title": {
                "fragments": [],
                "text": "Automatic Search Term variant Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The paper describes research designed to improve automatic pre\u2010coordinate term indexing by applying powerful general\u2010purpose language analysis techniques to identify term sources in requests, and to generate variant expressions of the concepts involved for document text searching."
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 165
                            }
                        ],
                        "text": "Algorithms for finding similar words assume the Distributional Hypothesis, which states that words that occurred in the same contexts tend to have similar meanings (Harris, 1985)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 55
                            }
                        ],
                        "text": "We make an assumption that this is an extension to the Distributional Hypothesis:\nExtended Distributional Hypothesis: If two paths tend to occur in similar contexts, the meanings of the\npaths tend to be similar."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 13
                            }
                        ],
                        "text": "The Extended Distributional Hypothesis, as with the original Distributional Hypothesis, is a statement about general trend instead of individual instances."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 24
                            }
                        ],
                        "text": "Instead of applying the Distributional Hypothesis to words, we apply it to paths in dependency trees."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 27
                            }
                        ],
                        "text": "We introduced the Extended Distributional Hypothesis, which states that paths in dependency trees have similar meanings if they tend to connect similar sets of words."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 8
                            }
                        ],
                        "text": "5.2 Results\nThe second column of Table 5 shows the paths that Minipar identified from the TREC-8 questions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 16
                            }
                        ],
                        "text": "By the Extended Distributional Hypothesis, we can then claim that the two paths have similar meanings."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 48
                            }
                        ],
                        "text": "Our experimental results show that the Extended Distributional Hypothesis can indeed be used to discover very useful inference rules, many of which, though easily recognizable, are difficult for humans to recall."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 62
                            }
                        ],
                        "text": "4.2 Triples\nTo compute the path similarity using the Extended Distributional Hypothesis, we need to collect the frequency counts of all paths in a corpus and the slot fillers for the paths."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "5 Experimental Results Ideally, we would evaluate our system by injecting the inference rules into a fullfledged question-answering system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 158
                            }
                        ],
                        "text": "4.1 The Underlying Assumption\nMost algorithms for computing word similarity from text corpus are based on a principle known as the Distributional Hypothesis (Harris, 1985)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distributional Structure The Philosophy of Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "Distributional Structure The Philosophy of Linguistics"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2246473"
                        ],
                        "name": "D. G. Hays",
                        "slug": "D.-G.-Hays",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hays",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G. Hays"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 145050024,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "17cb4f318dc53b3c09dab637bd46897039d88046",
            "isKey": false,
            "numCitedBy": 462,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Dependency-Theory:-A-Formalism-and-Some-Hays",
            "title": {
                "fragments": [],
                "text": "Dependency Theory: A Formalism and Some Observations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405337742"
                        ],
                        "name": "I. Mel'cuk",
                        "slug": "I.-Mel'cuk",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Mel'cuk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Mel'cuk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 203672231,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "1215415ac4e5abb82d7596538bc81e6247d4f020",
            "isKey": false,
            "numCitedBy": 1326,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Dependency-Syntax:-Theory-and-Practice-Mel'cuk",
            "title": {
                "fragments": [],
                "text": "Dependency Syntax: Theory and Practice"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NLP for Term Variant Extraction: A Synergy of Morphology, Lexicon, and Syntax"
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Information Retrieval, T. Strzalkowski, editor. pp. 25-74. Kluwer. Boston, MA."
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NLP for term variant extraction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 117
                            }
                        ],
                        "text": "The lexicon in Minipar is derived from syntactic features (parts of speech and subcategorization frames) in WordNet (Miller, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "WordNet: An Online Lexical Database"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Lexicography, 1990."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 29
                            }
                        ],
                        "text": "In the LASSO/FALCON systems (Harabagiu et al., 2000), the most successful QA systems in TREC-8 and TREC-9, a theorem prover is used to justify the answers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "COLING/ACL-1998, pp. 476\u2013482"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Extracting classification knowledge of Internet"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 4
                            }
                        ],
                        "text": "In (Richardson, 1997), Richardson extracted semantic relationships (e.g., hypernym, location, material and purpose) from dictionary definitions using a parser and constructed a semantic network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Determining Similarity and the Infering Relations in a Lexical"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast and effective text mining using linear-time document"
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Natural Language Generation in Artificial Intelligence and Computational Linguistics. Kluwer"
            },
            "venue": {
                "fragments": [],
                "text": "Natural Language Generation in Artificial Intelligence and Computational Linguistics. Kluwer"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 78
                            }
                        ],
                        "text": "It has been shown that such query expansion does promote effective retrieval (Arampatzis et al., 1998; Anick and Tipirneni, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phrase-based infase-bas retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Information Processing & Management,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient clustering of high-dimensional"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 16
                            }
                        ],
                        "text": "Like Principar (Lin, 1993), Minipar represents its grammar as a network where nodes represent grammatical categories and links represent types of syntactic (dependency) relationships."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parsing Without OverGeneration"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings ACL-93. pp. 112-120. Columbus, OH."
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NLP for Term Variant Extraction: A Synergy of Morphology, Lexicon, and Syntax. Natural Language Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 15
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 49,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Discovery-of-inference-rules-for-question-answering-Lin-Pantel/b4317b8a4490c84301907a61f5b8ebb26ab8828d?sort=total-citations"
}