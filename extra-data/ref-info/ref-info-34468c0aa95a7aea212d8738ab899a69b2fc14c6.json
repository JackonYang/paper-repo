{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14711886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce9a21b93ba29d4145a8ef6bf401e77f261848de",
            "isKey": false,
            "numCitedBy": 3832,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks. These algorithms have (1) the advantage that they do not require a precisely defined training interval, operating while the network runs; and (2) the disadvantage that they require nonlocal communication in the network being trained and are computationally expensive. These algorithms allow networks having recurrent connections to learn complex tasks that require the retention of information over time periods having either fixed or indefinite length."
            },
            "slug": "A-Learning-Algorithm-for-Continually-Running-Fully-Williams-Zipser",
            "title": {
                "fragments": [],
                "text": "A Learning Algorithm for Continually Running Fully Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48429353"
                        ],
                        "name": "Pineda",
                        "slug": "Pineda",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Pineda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pineda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "We use the same class of networks used by Pineda [11], but he is concerned only with the limit behavior of these networks, and completely suppresses all other temporal behavior."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Pineda [11] has shown how to train the fixpoints of a recurrent temporally continuous generalization of backpropagation networks [8,12,14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Aside from the addition of time constants, the network topology was that used by Pineda in [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40994937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6602985bd326d9996c68627b56ed389e2c90fd08",
            "isKey": false,
            "numCitedBy": 905,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "An adaptive neural network with asymmetric connections is introduced. This network is related to the Hopfield network with graded neurons and uses a recurrent generalization of the \\ensuremath{\\delta} rule of Rumelhart, Hinton, and Williams to modify adaptively the synaptic weights. The new network bears a resemblance to the master/slave network of Lapedes and Farber but it is architecturally simpler."
            },
            "slug": "Generalization-of-back-propagation-to-recurrent-Pineda",
            "title": {
                "fragments": [],
                "text": "Generalization of back-propagation to recurrent neural networks."
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "An adaptive neural network with asymmetric connections is introduced that bears a resemblance to the master/slave network of Lapedes and Farber but it is architecturally simpler."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review letters"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700974"
                        ],
                        "name": "Barak A. Pearlmutter",
                        "slug": "Barak-A.-Pearlmutter",
                        "structuredName": {
                            "firstName": "Barak",
                            "lastName": "Pearlmutter",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barak A. Pearlmutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 873,
                                "start": 39
                            }
                        ],
                        "text": "We use the same class of networks used by Pineda (19871, but he is concerned only with the limit behavior of these networks, and completely suppresses all other temporal behavior. His learning technique is applicable only when the network has a simple fixpoint; limit cycles or other non-point attractors violate a mathematical assumption upon which his technique is based. We can derive Pineda\u2018s equations from ours. Let I , be held constant, assume that the network settles to a fixpoint, let the initial conditions be this fixpoint, that is, yi(to) = yi(oo), and let E measure Pineda\u2019s error integrated over a short interval after t o , with an appropriate normalization constant. As tl tends to infinity, (2.2) and (2.3) reduce to Pineda\u2019s equations, so in a sense our equations are a generalization of Pineda\u2019s; but these assumptions strain the analogy. Jordan (1986) uses a conventional backpropagation network with the outputs clocked back to the inputs to generate temporal sequences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 542,
                                "start": 18
                            }
                        ],
                        "text": "This approach can be used to learn modifiable time delays. We can avoid the backwards pass by using a shooting method to update guesses for the correct values of z,(to) such that z,(t l) = 0 and integrating everything in the forward direction. Regretably, the computation required to compute the derivatives required by the shooting method seems excessive, and numeric stability is poor. We can derive a \u201dteacher forced\u201d variant of our learning algorithm, presumably obtaining speedups similar to those reported by Williams and Zipser (1989). It would be useful to have some characterization of the class of trajectories that a network can learn as a function of the number of hidden units."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 62139126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8ba8ef00d46170cf608e0e76f468cd3a348c6af",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : We describe a procedure for finding learning state space trajectories in recurrent neural networks. Keywords: Connectionism; Learning algorithm; Trajectories following; Minimizing functionals."
            },
            "slug": "Learning-state-space-trajectories-in-recurrent-:-a-Pearlmutter",
            "title": {
                "fragments": [],
                "text": "Learning state space trajectories in recurrent neural networks : a preliminary report."
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A procedure for finding learning state space trajectories in recurrent neural networks by minimizing functionals and connectionism is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47055692"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205118721,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "266e07d0dd9a75b61e3632e9469993dbaf063f1c",
            "isKey": false,
            "numCitedBy": 882,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generalization-of-backpropagation-with-application-Werbos",
            "title": {
                "fragments": [],
                "text": "Generalization of backpropagation with application to a recurrent gas market model"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2705981"
                        ],
                        "name": "M. Ottaway",
                        "slug": "M.-Ottaway",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Ottaway",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ottaway"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "Figure 2: A lattice representation of (4)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 139
                            }
                        ],
                        "text": "By substituting IUJOI) = 0 and into the resulting equation we eliminate i and end up with dE 1 / ^ ) ^ (8) If we substitute pt = Tf ! into (4), find dE/dpt by proceeding analogously, and substitute 7\\ back in we get"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "or At) \u00bb 1 (4) which is exact in the limit as At \u2014\u2022 0."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60690437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0882e54463c5d20269318185cfcdd6b73748d157",
            "isKey": true,
            "numCitedBy": 16,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper attempts a systematic analysis of the recurrent backpropagation (RBP) algorithm, introducing a number of new results. We first show that there is a potential problem in that RBP doesn't necessarily converge to a stable fixed point. This means that the system could backpropagate incorrect error signals and fail to learn properly. We show by experiment and eigenvalue analysis on a small network that this is not the case if the learning rate is chosen to be sufficiently small. On the other hand, standard backpropagation is shown to be more robust to a high learning rate than RBP. Next we examine the advantages of RBP over the standard backpropagation algorithm. RBP is shown to build stable fixed points corresponding to the input patterns. This makes it an appropriate tool for content addressable memory. Finally, we show that the introduction of a non\u00ad local search technique such as simulated annealing has a dramatic effect on a network's ability to learn patterns. This work was funded by NIH grant NS22407"
            },
            "slug": "Analysis-of-Recurrent-Backpropagation-Simard-Ottaway",
            "title": {
                "fragments": [],
                "text": "Analysis of Recurrent Backpropagation"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This paper attempts a systematic analysis of the recurrent backpropagation (RBP) algorithm, introducing a number of new results, and shows that the introduction of a non\u00ad local search technique such as simulated annealing has a dramatic effect on a network's ability to learn patterns."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308302"
                        ],
                        "name": "D. Ackley",
                        "slug": "D.-Ackley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ackley",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ackley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12174018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0d16f0e99f7ce5e6fb70b1a68c685e9ad610657",
            "isKey": false,
            "numCitedBy": 3393,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Learning-Algorithm-for-Boltzmann-Machines-Ackley-Hinton",
            "title": {
                "fragments": [],
                "text": "A Learning Algorithm for Boltzmann Machines"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40396597"
                        ],
                        "name": "Toshiyuki Hanazawa",
                        "slug": "Toshiyuki-Hanazawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Hanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiyuki Hanazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 89
                            }
                        ],
                        "text": "Such \"time delay neural networks\" have proven useful in the domain of speech recognition [7,13], Having more than one connection from one unit to another requires us to modify our notation somewhat; weights and time delays are modified to take a single index, and we introduce some external apparatus to specity the source and destination of each connection."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9563026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd62c9976534a6a2096a38244f6cbb03635a127e",
            "isKey": false,
            "numCitedBy": 2786,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: (1) using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation; and (2) the time-delay arrangement enables the network to discover acoustic-phonetic features and the temporal relationships between them independently of position in time and therefore not blurred by temporal shifts in the input. As a recognition task, the speaker-dependent recognition of the phonemes B, D, and G in varying phonetic contexts was chosen. For comparison, several discrete hidden Markov models (HMM) were trained to perform the same task. Performance evaluation over 1946 testing tokens from three speakers showed that the TDNN achieves a recognition rate of 98.5% correct while the rate obtained by the best of the HMMs was only 93.7%. >"
            },
            "slug": "Phoneme-recognition-using-time-delay-neural-Waibel-Hanazawa",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition using time-delay neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5721376"
                        ],
                        "name": "A. Bryson",
                        "slug": "A.-Bryson",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Bryson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bryson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70473089"
                        ],
                        "name": "W. Denham",
                        "slug": "W.-Denham",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Denham",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Denham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 209
                            }
                        ],
                        "text": "m , - 7 , h \u00ab i * < One can also derive (8), (9) and (10) using the calculus of variations and Lagrange multipliers (William Skaggs, personal communication), or from the continuous form of dynamic programming [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120635375,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "90470d612cc0d749b3ecdcfd914bdd592d9500bf",
            "isKey": false,
            "numCitedBy": 423,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "SYSTEMATIC and rapid steepest-ascent numerical procedure is described for determining optimum programs for nonlinear systems with terminal constraints. The procedure uses the concept of local linearization around a nominal (nonoptimum) path. The effect on the terminal conditions of a small change in the control variable program is determined by numerical integration of the adjoint differential equations for small perturbations about the nominal path. Having these adjoint (or influence) functions, it is then possible to determine the change in the control variable program that gives maximum increase in the pay-off function for a given mean-square perturbation of the control variable program while simultaneously changing the terminal quantities by desired amounts. By repeating this process in small steps, a control variable program that minimizes one quantity and yields specified values of other terminal quantities can be approached as closely as desired. Three numerical examples are presented: (a) The angle-of-attack program for a typical supersonic interceptor to climb to altitude in minimum time is determined with and without specified terminal velocity and heading. (6) The angle-of-attack program for the same interceptor to climb to maximum altitude is determined, (c) The angle-of-attack program is determined for a hypersonic orbital glider to obtain maximum surface range starting from satellite speed at 300,000 ft altitude."
            },
            "slug": "A-Steepest-Ascent-Method-for-Solving-Optimum-Bryson-Denham",
            "title": {
                "fragments": [],
                "text": "A Steepest-Ascent Method for Solving Optimum Programming Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "By repeating this process in small steps, a control variable program that minimizes one quantity and yields specified values of other terminal quantities can be approached as closely as desired."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145847131"
                        ],
                        "name": "S. Kirkpatrick",
                        "slug": "S.-Kirkpatrick",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Kirkpatrick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kirkpatrick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5882723"
                        ],
                        "name": "C. D. Gelatt",
                        "slug": "C.-D.-Gelatt",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Gelatt",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Gelatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "88645967"
                        ],
                        "name": "M. Vecchi",
                        "slug": "M.-Vecchi",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Vecchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vecchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 67
                            }
                        ],
                        "text": "Two competing techniques for such problems are simulated annealing [6,1] and mean field theory [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205939,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dd5061631a4d11fa394f4421700ebf7e78dcbc59",
            "isKey": false,
            "numCitedBy": 39631,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods."
            },
            "slug": "Optimization-by-Simulated-Annealing-Kirkpatrick-Gelatt",
            "title": {
                "fragments": [],
                "text": "Optimization by Simulated Annealing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145031933"
                        ],
                        "name": "J. Blom",
                        "slug": "J.-Blom",
                        "structuredName": {
                            "firstName": "Joke",
                            "lastName": "Blom",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Blom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399510610"
                        ],
                        "name": "J. M. Sanz-Serna",
                        "slug": "J.-M.-Sanz-Serna",
                        "structuredName": {
                            "firstName": "Jes\u00fas",
                            "lastName": "Sanz-Serna",
                            "middleNames": [
                                "Mar\u00eda"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Sanz-Serna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690674"
                        ],
                        "name": "J. Verwer",
                        "slug": "J.-Verwer",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Verwer",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Verwer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "Variable grid methods [2] can reduce s by dynamically varying At."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122729649,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f05debe71ab89dc5bd612cc4e9f498b09419d532",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-simple-moving-grid-methods-for-one-dimensional-Blom-Sanz-Serna",
            "title": {
                "fragments": [],
                "text": "On simple moving grid methods for one-dimensional evolutionary partial differential equations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "(3) where y'\u2022'^ is the same as y except that dfyjdt has a Dirac delta function of magnitude <J added to it at time f."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19355,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319833"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 129
                            }
                        ],
                        "text": "Pineda [11] has shown how to train the fixpoints of a recurrent temporally continuous generalization of backpropagation networks [8,12,14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207975157,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "56623a496727d5c71491850e04512ddf4152b487",
            "isKey": false,
            "numCitedBy": 4468,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Beyond-Regression-:-\"New-Tools-for-Prediction-and-Werbos",
            "title": {
                "fragments": [],
                "text": "Beyond Regression : \"New Tools for Prediction and Analysis in the Behavioral Sciences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56723681,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d76aafbeb54575859441a442376766c597f6bb52",
            "isKey": false,
            "numCitedBy": 1102,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Attractor-dynamics-and-parallelism-in-a-sequential-Jordan",
            "title": {
                "fragments": [],
                "text": "Attractor dynamics and parallelism in a connectionist sequential machine"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055557361"
                        ],
                        "name": "C. Peterson",
                        "slug": "C.-Peterson",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Peterson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Peterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110869996"
                        ],
                        "name": "James R. Anderson",
                        "slug": "James-R.-Anderson",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Anderson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Anderson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "Two competing techniques for such problems are simulated annealing [6,1] and mean field theory [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3851750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "607802a4067cb7738bac85d3ca3386f859e637b9",
            "isKey": false,
            "numCitedBy": 500,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Mean-Field-Theory-Learning-Algorithm-for-Neural-Peterson-Anderson",
            "title": {
                "fragments": [],
                "text": "A Mean Field Theory Learning Algorithm for Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gelatt , Jr . , and M . P . Vecchi . Optimization by simulated annealing"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalization of backpropagation to recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Physical Review Letters"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A l e a r k g algorithm for Boltzmann Machines"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Science,"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A steepest ascent method for solving optimum programFurst, M"
            },
            "venue": {
                "fragments": [],
                "text": "1988. Personal communication. Jordan, M.I. 1986. Attractor dynamics and parallelism in a connectionist se-"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalization of backpropagation to recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Physical Review Letters"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Williams and David Zipser . A Learning Algorithm for Continually Running Fully Recurrent Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 89
                            }
                        ],
                        "text": "Such \"time delay neural networks\" have proven useful in the domain of speech recognition [7,13], Having more than one connection from one unit to another requires us to modify our notation somewhat; weights and time delays are modified to take a single index, and we introduce some external apparatus to specity the source and destination of each connection."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Development of the Time-Delay Neural Network Architecture for Speech Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report CMU-CS-88- 152,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Learning Afgorithm for Continually Running Fully Recurrent Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report ICs Report 8805,"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 129
                            }
                        ],
                        "text": "Pineda [11] has shown how to train the fixpoints of a recurrent temporally continuous generalization of backpropagation networks [8,12,14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning-Logic. Technical Report TR-47, MIT Center for Research in Computational Economics and Management"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Manipulator control using a connectionist network Unpublished thesis proposal"
            },
            "venue": {
                "fragments": [],
                "text": "Manipulator control using a connectionist network Unpublished thesis proposal"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Verwer . On Simple Moving Grid Methods for One - Dimensional Evolutionary Partial Differential Equations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Verwer . On Simple Moving Grid Methods for One - Dimensional Evolutionary Partial Differential Equations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 19
                            }
                        ],
                        "text": "We can approximate (1) with the difference equation"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "(1) at where j is the total input to unit i, yt is the state of unit z, T, is the time constant of unit /, a is an arbitrary differentiable function(1), wly- are the weights, and the boundary conditions y(to) and driving functions I are the input to the system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Manipulator control using a connectionist network"
            },
            "venue": {
                "fragments": [],
                "text": "Unpublished thesis proposal"
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 6,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-State-Space-Trajectories-in-Recurrent-Pearlmutter/34468c0aa95a7aea212d8738ab899a69b2fc14c6?sort=total-citations"
}