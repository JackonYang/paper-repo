{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399142941"
                        ],
                        "name": "Jos\u00e9 A. Rodr\u00edguez-Serrano",
                        "slug": "Jos\u00e9-A.-Rodr\u00edguez-Serrano",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Rodr\u00edguez-Serrano",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 A. Rodr\u00edguez-Serrano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 62
                            }
                        ],
                        "text": "This paper is an extension of preliminary conference version (Rodriguez-Serrano and Perronnin 2013), which, to our knowledge, constitutes the first publishedwork that proposed to leverage label embedding for text recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 69
                            }
                        ],
                        "text": "This was state-of-the-art when the conference version of this paper (Rodriguez-Serrano and Perronnin 2013) was published."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 53
                            }
                        ],
                        "text": "As presented in the preliminary version of the paper Rodriguez-Serrano and Perronnin (2013), the label embedding approach cannot handle queries with wildcards effectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1187241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16358e79921964be7607f6371f88e8a06d97432c",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The standard approach to recognizing text in images consists in first classifying local image regions into candidate characters and then combining them with high-level word models such as conditional random fields (CRF). This paper explores a new paradigm that departs from this bottom-up view. We propose to embed word labels and word images into a common Euclidean space. Given a word image to be recognized, the text recognition problem is cast as one of retrieval: find the closest word label in this space. This common space is learned using the Structured SVM (SSVM) framework by enforcing matching label-image pairs to be closer than non-matching pairs. This method presents the following advantages: it does not require costly preor post-processing operations, it allows for the recognition of never-seen-before words and the recognition process is efficient. Experiments are performed on two challenging datasets (one of license plates and one of scene text) and show that the proposed method is competitive with standard bottom-up approaches to text recognition."
            },
            "slug": "Label-embedding-for-text-recognition-Rodr\u00edguez-Serrano-Perronnin",
            "title": {
                "fragments": [],
                "text": "Label embedding for text recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes to embed word labels and word images into a common Euclidean space and presents the following advantages: it does not require costly preor post-processing operations, it allows for the recognition of never-seen-before words and the recognition process is efficient."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467588"
                        ],
                        "name": "Jon Almaz\u00e1n",
                        "slug": "Jon-Almaz\u00e1n",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Almaz\u00e1n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jon Almaz\u00e1n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821267"
                        ],
                        "name": "Albert Gordo",
                        "slug": "Albert-Gordo",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Gordo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Gordo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686569"
                        ],
                        "name": "A. Forn\u00e9s",
                        "slug": "A.-Forn\u00e9s",
                        "structuredName": {
                            "firstName": "Alicia",
                            "lastName": "Forn\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Forn\u00e9s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864362"
                        ],
                        "name": "Ernest Valveny",
                        "slug": "Ernest-Valveny",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Valveny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ernest Valveny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10057476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e61061b2ddd5e789a071e0681f4eb405bf811339",
            "isKey": false,
            "numCitedBy": 385,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problems of word spotting and word recognition on images. In word spotting, the goal is to find all instances of a query word in a dataset of images. In recognition, the goal is to recognize the content of the word image, usually aided by a dictionary or lexicon. We describe an approach in which both word images and text strings are embedded in a common vectorial subspace. This is achieved by a combination of label embedding and attributes learning, and a common subspace regression. In this subspace, images and strings that represent the same word are close together, allowing one to cast recognition and retrieval tasks as a nearest neighbor problem. Contrary to most other existing methods, our representation has a fixed length, is low dimensional, and is very fast to compute and, especially, to compare. We test our approach on four public datasets of both handwritten documents and natural images showing results comparable or better than the state-of-the-art on spotting and recognition tasks."
            },
            "slug": "Word-Spotting-and-Recognition-with-Embedded-Almaz\u00e1n-Gordo",
            "title": {
                "fragments": [],
                "text": "Word Spotting and Recognition with Embedded Attributes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An approach in which both word images and text strings are embedded in a common vectorial subspace, allowing one to cast recognition and retrieval tasks as a nearest neighbor problem and is very fast to compute and, especially, to compare."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39719398"
                        ],
                        "name": "Anand Mishra",
                        "slug": "Anand-Mishra",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Mishra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Mishra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72492981"
                        ],
                        "name": "Alahari Karteek",
                        "slug": "Alahari-Karteek",
                        "structuredName": {
                            "firstName": "Alahari",
                            "lastName": "Karteek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alahari Karteek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 121
                            }
                        ],
                        "text": "5.2 Scene Text Recognition on the IIIT-5K Dataset\nDataset and settings We perform experiments on the public IIIT-5K set (Mishra et al. 2012a), which is the largest existing dataset of scene text recognitionwith a total of 5,000 cropped word images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 46
                            }
                        ],
                        "text": "Baseline For this database we compare against Mishra et al. (2012a), which uses a system based on a high-order CRF built over candidate character detections, and that represents the state-of-the-art results at the time of the submission of this paper."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 143
                            }
                        ],
                        "text": "One important remark is that the FV we extract does not rely on pre-processing the image with standard operations such as binarization, unlike Mishra et al. (2012a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 232
                            }
                        ],
                        "text": "\u2026are sensitive to the character detection and classification step, and that this usually implies pre-processing (e.g. binarize the image to improve character classification) and post-processing (e.g. apply a string edit correction (Mishra et al. 2012a) of the output to the closest lexicon word)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 159
                            }
                        ],
                        "text": "\u2026task, the label embedding outperforms a dedicated OCR system; in a challenging scene text recognition task, we obtain results comparable to a CRF-based model Mishra et al. (2012a) in moderate-sized lexicons (1K words) and significantly higher in small-lexicon word-spotting tasks (50 words)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 148
                            }
                        ],
                        "text": "Table 3 Results of text recognition: accuracyof recognition (i.e. imageto-text) methods on the IIIT-5K dataset\nMethod Accuracy\n|Y| = 50 |Y| = 1,000 Mishra et al. (2012a) 64.1 % 57.5 %\nLabel embedding 76.1 % 57.4 %\nADVERTISING\nAFTER\nDROPPED\nHOURS\nREGENCY\nRESEARCH\nVILLA\nWEBS\nWISTERIA\n11 AM\n172\nFig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 149
                            }
                        ],
                        "text": "Yet it achieves an accuracy comparable to existing systems such as an industrial OCR and a recent approach based on conditional random fields (CRF) (Mishra et al. 2012a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 69
                            }
                        ],
                        "text": "2 (Wang and Belongie 2010; Wang et al. 2011; Neumann and Matas 2012; Mishra et al. 2012a, b; Novikova et al. 2012) fit into this framework (see\nTable 1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 34
                            }
                        ],
                        "text": "We use the evaluation protocol of Mishra et al. (2012a), with a training/test split of 2,000/3,000 images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 187
                            }
                        ],
                        "text": "Scene text recognition Scene text recognition has gained increasing attention since 2010 in the computer vision community (Wang and Belongie 2010; Wang et al. 2011; Neumann andMatas 2012;Mishra et al. 2012a, b; Novikova et al. 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "Again, this is a surprisingly high result for a method that is based on direct similarities between image and text descriptors: as a comparison, Mishra et al. (2012a) obtain 73.3% by using a CRF on explicitly detected characters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "In a license plate recognition task, the label embedding outperforms a dedicated OCR system; in a challenging scene text recognition task, we obtain results comparable to a CRF-based model Mishra et al. (2012a) in moderate-sized lexicons (1K words) and significantly higher in small-lexicon word-spotting tasks (50 words)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9695967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb5b2df137a4d54c3a9145fa363e66531b491580",
            "isKey": true,
            "numCitedBy": 548,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of recognizing text in images taken in the wild has gained significant attention from the computer vision community in recent years. Contrary to recognition of printed documents, recognizing scene text is a challenging problem. We focus on the problem of recognizing text extracted from natural scene images and the web. Significant attempts have been made to address this problem in the recent past. However, many of these works benefit from the availability of strong context, which naturally limits their applicability. In this work we present a framework that uses a higher order prior computed from an English dictionary to recognize a word, which may or may not be a part of the dictionary. We show experimental results on publicly available datasets. Furthermore, we introduce a large challenging word dataset with five thousand words to evaluate various steps of our method exhaustively. The main contributions of this work are: (1) We present a framework, which incorporates higher order statistical language models to recognize words in an unconstrained manner (i.e. we overcome the need for restricted word lists, and instead use an English dictionary to compute the priors). (2) We achieve significant improvement (more than 20%) in word recognition accuracies without using a restricted word list. (3) We introduce a large word recognition dataset (atleast 5 times larger than other public datasets) with character level annotation and benchmark it."
            },
            "slug": "Scene-Text-Recognition-using-Higher-Order-Language-Mishra-Karteek",
            "title": {
                "fragments": [],
                "text": "Scene Text Recognition using Higher Order Language Priors"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A framework is presented that uses a higher order prior computed from an English dictionary to recognize a word, which may or may not be a part of the dictionary, and achieves significant improvement in word recognition accuracies without using a restricted word list."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148896777"
                        ],
                        "name": "Kai Wang",
                        "slug": "Kai-Wang",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490700"
                        ],
                        "name": "Boris Babenko",
                        "slug": "Boris-Babenko",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Babenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Babenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 14
                            }
                        ],
                        "text": "Wang, ICCV\u201911 (Wang et al. 2011) Sliding window HOG + random ferns Pictorial structure"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 147
                            }
                        ],
                        "text": "Scene text recognition Scene text recognition has gained increasing attention since 2010 in the computer vision community (Wang and Belongie 2010; Wang et al. 2011; Neumann andMatas 2012;Mishra et al. 2012a, b; Novikova et al. 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 27
                            }
                        ],
                        "text": "2 (Wang and Belongie 2010; Wang et al. 2011; Neumann and Matas 2012; Mishra et al. 2012a, b; Novikova et al. 2012) fit into this framework (see\nTable 1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 196
                            }
                        ],
                        "text": "\u2026et al. 1999; Nagy 2000), understanding text in natural scenes, as opposed to text in clean documents, still poses significant challenges as pointed out by recent papers Wang and Belongie (2010), Wang et al. (2011), Neumann and Matas (2012), Mishra et al. (2012a, b), and Novikova et al. (2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14136313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32b8f58a038df83138435b12a499c8bf0de13811",
            "isKey": true,
            "numCitedBy": 908,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper focuses on the problem of word detection and recognition in natural images. The problem is significantly more challenging than reading text in scanned documents, and has only recently gained attention from the computer vision community. Sub-components of the problem, such as text detection and cropped image word recognition, have been studied in isolation [7, 4, 20]. However, what is unclear is how these recent approaches contribute to solving the end-to-end problem of word recognition. We fill this gap by constructing and evaluating two systems. The first, representing the de facto state-of-the-art, is a two stage pipeline consisting of text detection followed by a leading OCR engine. The second is a system rooted in generic object recognition, an extension of our previous work in [20]. We show that the latter approach achieves superior performance. While scene text recognition has generally been treated with highly domain-specific methods, our results demonstrate the suitability of applying generic computer vision methods. Adopting this approach opens the door for real world scene text recognition to benefit from the rapid advances that have been taking place in object recognition."
            },
            "slug": "End-to-end-scene-text-recognition-Wang-Babenko",
            "title": {
                "fragments": [],
                "text": "End-to-end scene text recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "While scene text recognition has generally been treated with highly domain-specific methods, the results demonstrate the suitability of applying generic computer vision methods."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061483996"
                        ],
                        "name": "Tatiana G. Novikova",
                        "slug": "Tatiana-G.-Novikova",
                        "structuredName": {
                            "firstName": "Tatiana",
                            "lastName": "Novikova",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tatiana G. Novikova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144649144"
                        ],
                        "name": "O. Barinova",
                        "slug": "O.-Barinova",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Barinova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Barinova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967473"
                        ],
                        "name": "Pushmeet Kohli",
                        "slug": "Pushmeet-Kohli",
                        "structuredName": {
                            "firstName": "Pushmeet",
                            "lastName": "Kohli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pushmeet Kohli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740145"
                        ],
                        "name": "V. Lempitsky",
                        "slug": "V.-Lempitsky",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lempitsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lempitsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 211
                            }
                        ],
                        "text": "Scene text recognition Scene text recognition has gained increasing attention since 2010 in the computer vision community (Wang and Belongie 2010; Wang et al. 2011; Neumann andMatas 2012;Mishra et al. 2012a, b; Novikova et al. 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 18
                            }
                        ],
                        "text": "Novikova, ECCV\u201912 (Novikova et al. 2012) MSER HOG + nearest-neighbor Weighted finite-state transducer"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 93
                            }
                        ],
                        "text": "2 (Wang and Belongie 2010; Wang et al. 2011; Neumann and Matas 2012; Mishra et al. 2012a, b; Novikova et al. 2012) fit into this framework (see\nTable 1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 272
                            }
                        ],
                        "text": "\u2026et al. 1999; Nagy 2000), understanding text in natural scenes, as opposed to text in clean documents, still poses significant challenges as pointed out by recent papers Wang and Belongie (2010), Wang et al. (2011), Neumann and Matas (2012), Mishra et al. (2012a, b), and Novikova et al. (2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6699564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fef57f42188519899a3653872803445210cac857",
            "isKey": true,
            "numCitedBy": 122,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new model for the task of word recognition in natural images that simultaneously models visual and lexicon consistency of words in a single probabilistic model. Our approach combines local likelihood and pairwise positional consistency priors with higher order priors that enforce consistency of characters (lexicon) and their attributes (font and colour). Unlike traditional stage-based methods, word recognition in our framework is performed by estimating the maximum a posteriori (MAP) solution under the joint posterior distribution of the model. MAP inference in our model is performed through the use of weighted finite-state transducers (WFSTs). We show how the efficiency of certain operations on WFSTs can be utilized to find the most likely word under the model in an efficient manner. We evaluate our method on a range of challenging datasets (ICDAR'03, SVT, ICDAR'11). Experimental results demonstrate that our method outperforms state-of-the-art methods for cropped word recognition."
            },
            "slug": "Large-Lexicon-Attribute-Consistent-Text-Recognition-Novikova-Barinova",
            "title": {
                "fragments": [],
                "text": "Large-Lexicon Attribute-Consistent Text Recognition in Natural Images"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A new model for the task of word recognition in natural images that simultaneously models visual and lexicon consistency of words in a single probabilistic model is proposed and outperforms state-of-the-art methods for cropped word recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145537764"
                        ],
                        "name": "K. Sankar",
                        "slug": "K.-Sankar",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Sankar",
                            "middleNames": [
                                "Pramod"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sankar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 191
                            }
                        ],
                        "text": "These approaches tend to perform matching at full-image level, employing global features (Jain and Jawahar 2010) or feature sequences (Rath et al. 2003; Rodr\u00edguez-Serrano and Perronnin 2012; Sankar et al. 2010) and using a distance-based classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1508626,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dac3cf11624be87c025087d8ba2e94e949f70e80",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Conventional optical character recognition (OCR) systems operate on individual characters and words, and do not normally exploit document or collection context. We describe a Collection OCR which takes advantage of the fact that multiple examples of the same word (often in the same font) may occur in a document or collection. The idea here is that an OCR or a reCAPTCHA like process generates a partial set of recognized words. In the second stage, a nearest neighbor algorithm compares the remaining word-images to those already recognized and propagates labels from the nearest neighbors. It is shown that by using an approximate fast nearest neighbor algorithm based on Hierarchical K-Means (HKM), we can do this accurately and efficiently. It is also shown that profile based features perform much better than SIFT and Pyramid Histogram of Gradient (PHOG) features. We believe that this is because profile features are more robust to word degradations (common in our documents). This approach is applied to a collection of Telugu books - a language for which no commercial OCR exists. We show from a selection of 33 Telugu books that starting with OCR labels for only 30% of the collection we can recognize the remaining 70% of the words in the collection with 70% accuracy using this approach. Since the approach makes no language specific assumptions, it should be applicable to a large number of languages. In particular we are interested in its applicability to Indic languages and scripts."
            },
            "slug": "Nearest-neighbor-based-collection-OCR-Sankar-Jawahar",
            "title": {
                "fragments": [],
                "text": "Nearest neighbor based collection OCR"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A Collection OCR which takes advantage of the fact that multiple examples of the same word may occur in a document or collection, and makes no language specific assumptions, and should be applicable to a large number of languages."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39719398"
                        ],
                        "name": "Anand Mishra",
                        "slug": "Anand-Mishra",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Mishra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Mishra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72492981"
                        ],
                        "name": "Alahari Karteek",
                        "slug": "Alahari-Karteek",
                        "structuredName": {
                            "firstName": "Alahari",
                            "lastName": "Karteek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alahari Karteek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 121
                            }
                        ],
                        "text": "5.2 Scene Text Recognition on the IIIT-5K Dataset\nDataset and settings We perform experiments on the public IIIT-5K set (Mishra et al. 2012a), which is the largest existing dataset of scene text recognitionwith a total of 5,000 cropped word images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 46
                            }
                        ],
                        "text": "Baseline For this database we compare against Mishra et al. (2012a), which uses a system based on a high-order CRF built over candidate character detections, and that represents the state-of-the-art results at the time of the submission of this paper."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 143
                            }
                        ],
                        "text": "One important remark is that the FV we extract does not rely on pre-processing the image with standard operations such as binarization, unlike Mishra et al. (2012a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 232
                            }
                        ],
                        "text": "\u2026are sensitive to the character detection and classification step, and that this usually implies pre-processing (e.g. binarize the image to improve character classification) and post-processing (e.g. apply a string edit correction (Mishra et al. 2012a) of the output to the closest lexicon word)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 159
                            }
                        ],
                        "text": "\u2026task, the label embedding outperforms a dedicated OCR system; in a challenging scene text recognition task, we obtain results comparable to a CRF-based model Mishra et al. (2012a) in moderate-sized lexicons (1K words) and significantly higher in small-lexicon word-spotting tasks (50 words)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 148
                            }
                        ],
                        "text": "Table 3 Results of text recognition: accuracyof recognition (i.e. imageto-text) methods on the IIIT-5K dataset\nMethod Accuracy\n|Y| = 50 |Y| = 1,000 Mishra et al. (2012a) 64.1 % 57.5 %\nLabel embedding 76.1 % 57.4 %\nADVERTISING\nAFTER\nDROPPED\nHOURS\nREGENCY\nRESEARCH\nVILLA\nWEBS\nWISTERIA\n11 AM\n172\nFig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 149
                            }
                        ],
                        "text": "Yet it achieves an accuracy comparable to existing systems such as an industrial OCR and a recent approach based on conditional random fields (CRF) (Mishra et al. 2012a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 69
                            }
                        ],
                        "text": "2 (Wang and Belongie 2010; Wang et al. 2011; Neumann and Matas 2012; Mishra et al. 2012a, b; Novikova et al. 2012) fit into this framework (see\nTable 1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 34
                            }
                        ],
                        "text": "We use the evaluation protocol of Mishra et al. (2012a), with a training/test split of 2,000/3,000 images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 187
                            }
                        ],
                        "text": "Scene text recognition Scene text recognition has gained increasing attention since 2010 in the computer vision community (Wang and Belongie 2010; Wang et al. 2011; Neumann andMatas 2012;Mishra et al. 2012a, b; Novikova et al. 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "Again, this is a surprisingly high result for a method that is based on direct similarities between image and text descriptors: as a comparison, Mishra et al. (2012a) obtain 73.3% by using a CRF on explicitly detected characters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "In a license plate recognition task, the label embedding outperforms a dedicated OCR system; in a challenging scene text recognition task, we obtain results comparable to a CRF-based model Mishra et al. (2012a) in moderate-sized lexicons (1K words) and significantly higher in small-lexicon word-spotting tasks (50 words)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5728901,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66b71064b99331f908b60cb6d138f2ebea5bdcca",
            "isKey": true,
            "numCitedBy": 306,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Scene text recognition has gained significant attention from the computer vision community in recent years. Recognizing such text is a challenging problem, even more so than the recognition of scanned documents. In this work, we focus on the problem of recognizing text extracted from street images. We present a framework that exploits both bottom-up and top-down cues. The bottom-up cues are derived from individual character detections from the image. We build a Conditional Random Field model on these detections to jointly model the strength of the detections and the interactions between them. We impose top-down cues obtained from a lexicon-based prior, i.e. language statistics, on the model. The optimal word represented by the text image is obtained by minimizing the energy function corresponding to the random field model. We show significant improvements in accuracies on two challenging public datasets, namely Street View Text (over 15%) and ICDAR 2003 (nearly 10%)."
            },
            "slug": "Top-down-and-bottom-up-cues-for-scene-text-Mishra-Karteek",
            "title": {
                "fragments": [],
                "text": "Top-down and bottom-up cues for scene text recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents a framework that exploits both bottom-up and top-down cues in the problem of recognizing text extracted from street images, and shows significant improvements in accuracies on two challenging public datasets, namely Street View Text and ICDAR 2003."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148896777"
                        ],
                        "name": "Kai Wang",
                        "slug": "Kai-Wang",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 14
                            }
                        ],
                        "text": "Wang, ECCV\u201910 (Wang and Belongie 2010) Sliding window HOG + nearest-neighbor Pictorial structure"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 166
                            }
                        ],
                        "text": "5.3 Scene Text Recognition on the SVT Dataset\nDataset and Settings For completeness, we also report results on thewell-knownbut smaller StreetViewText (SVT) dataset (Wang and Belongie 2010), which consists of word images extracted from Google Street View."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 119
                            }
                        ],
                        "text": "Dataset and Settings For completeness, we also report results on thewell-knownbut smaller StreetViewText (SVT) dataset (Wang and Belongie 2010), which consists of word images extracted from Google Street View."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 170
                            }
                        ],
                        "text": "\u2026et al. 1999; Nagy 2000), understanding text in natural scenes, as opposed to text in clean documents, still poses significant challenges as pointed out by recent papers Wang and Belongie (2010), Wang et al. (2011), Neumann and Matas (2012), Mishra et al. (2012a, b), and Novikova et al. (2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 3
                            }
                        ],
                        "text": "2 (Wang and Belongie 2010; Wang et al. 2011; Neumann and Matas 2012; Mishra et al. 2012a, b; Novikova et al. 2012) fit into this framework (see\nTable 1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 85
                            }
                        ],
                        "text": "The first situation (|Y| = 50) corresponds to a word-spotting scenario as defined in Wang and Belongie (2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 123
                            }
                        ],
                        "text": "Scene text recognition Scene text recognition has gained increasing attention since 2010 in the computer vision community (Wang and Belongie 2010; Wang et al. 2011; Neumann andMatas 2012;Mishra et al. 2012a, b; Novikova et al. 2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14911813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d307221fa52e3939d46180cb5921ebbd92c8adb",
            "isKey": true,
            "numCitedBy": 425,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for spotting words in the wild, i.e., in real images taken in unconstrained environments. Text found in the wild has a surprising range of difficulty. At one end of the spectrum, Optical Character Recognition (OCR) applied to scanned pages of well formatted printed text is one of the most successful applications of computer vision to date. At the other extreme lie visual CAPTCHAs - text that is constructed explicitly to fool computer vision algorithms. Both tasks involve recognizing text, yet one is nearly solved while the other remains extremely challenging. In this work, we argue that the appearance of words in the wild spans this range of difficulties and propose a new word recognition approach based on state-of-the-art methods from generic object recognition, in which we consider object categories to be the words themselves. We compare performance of leading OCR engines - one open source and one proprietary - with our new approach on the ICDAR Robust Reading data set and a new word spotting data set we introduce in this paper: the Street View Text data set. We show improvements of up to 16% on the data sets, demonstrating the feasibility of a new approach to a seemingly old problem."
            },
            "slug": "Word-Spotting-in-the-Wild-Wang-Belongie",
            "title": {
                "fragments": [],
                "text": "Word Spotting in the Wild"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is argued that the appearance of words in the wild spans this range of difficulties and a new word recognition approach based on state-of-the-art methods from generic object recognition is proposed, in which object categories are considered to be the words themselves."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061270"
                        ],
                        "name": "S. Dutta",
                        "slug": "S.-Dutta",
                        "structuredName": {
                            "firstName": "Shrey",
                            "lastName": "Dutta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dutta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065649369"
                        ],
                        "name": "Naveen Sankaran",
                        "slug": "Naveen-Sankaran",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Sankaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naveen Sankaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145537764"
                        ],
                        "name": "K. Sankar",
                        "slug": "K.-Sankar",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Sankar",
                            "middleNames": [
                                "Pramod"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sankar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 10
                            }
                        ],
                        "text": "Recently, Dutta et al. (2012) proposes to detect and classify n-grams rather than individual characters, but theymerge the detected n-grams using a high-level model, so it is also considered a bottom-up approach."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11363617,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f31af55dc7a0e804b2ce779353f1e4218e68fde2",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a novel recognition approach that results in a 15% decrease in word error rate on heavily degraded Indian language document images. OCRs have considerably good performance on good quality documents, but fail easily in presence of degradations. Also, classical OCR approaches perform poorly over complex scripts such as those for Indian languages. We address these issues by proposing to recognize character n-gram images, which are basically groupings of consecutive character/component segments. Our approach is unique, since we use the character n-grams as a primitive for recognition rather than for post processing. By exploiting the additional context present in the character n-gram images, we enable better disambiguation between confusing characters in the recognition phase. The labels obtained from recognizing the constituent n-grams are then fused to obtain a label for the word that emitted them. Our method is inherently robust to degradations such as cuts and merges which are common in digital libraries of scanned documents. We also present a reliable and scalable scheme for recognizing character n-gram images. Tests on English and Malayalam document images show considerable improvement in recognition in the case of heavily degraded documents."
            },
            "slug": "Robust-Recognition-of-Degraded-Documents-Using-Dutta-Sankaran",
            "title": {
                "fragments": [],
                "text": "Robust Recognition of Degraded Documents Using Character N-Grams"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A novel recognition approach that results in a 15% decrease in word error rate on heavily degraded Indian language document images by exploiting the additional context present in the character n-gram images, which enables better disambiguation between confusing characters in the recognition phase."
            },
            "venue": {
                "fragments": [],
                "text": "2012 10th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467588"
                        ],
                        "name": "Jon Almaz\u00e1n",
                        "slug": "Jon-Almaz\u00e1n",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Almaz\u00e1n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jon Almaz\u00e1n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821267"
                        ],
                        "name": "Albert Gordo",
                        "slug": "Albert-Gordo",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Gordo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Gordo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686569"
                        ],
                        "name": "A. Forn\u00e9s",
                        "slug": "A.-Forn\u00e9s",
                        "structuredName": {
                            "firstName": "Alicia",
                            "lastName": "Forn\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Forn\u00e9s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864362"
                        ],
                        "name": "Ernest Valveny",
                        "slug": "Ernest-Valveny",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Valveny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ernest Valveny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 34
                            }
                        ],
                        "text": "The proposed approach and that of Almaz\u00e1n et al. (2013) are very closely related."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 57
                            }
                        ],
                        "text": "The main difference between the two works is that, while Almaz\u00e1n et al. (2013) attempt to explicitly detect characters in a word-image (which makes (Almaz\u00e1n et al. 2013) more similar to standard OCR-based approaches to text recognition), the proposed approach only does so implicitly."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 16
                            }
                        ],
                        "text": "An extension of Almaz\u00e1n et al. (2013) not yet published but available online reports 88.57% (Almazan et al. 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 76
                            }
                        ],
                        "text": "(2013) attempt to explicitly detect characters in a word-image (which makes (Almaz\u00e1n et al. 2013) more similar to standard OCR-based approaches to text recognition), the proposed approach only does so implicitly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 40
                            }
                        ],
                        "text": "An exception is the very recent work by Almaz\u00e1n et al. (2013), which is more carefully analyzed in Sect."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 46
                            }
                        ],
                        "text": "In this sense, the attributebased approach of Almaz\u00e1n et al. (2013) is closely related to our own approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2256040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e0dd12f2bff234a4df71641bc95068733506858",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to multi-writer word spotting, where the goal is to find a query word in a dataset comprised of document images. We propose an attributes-based approach that leads to a low-dimensional, fixed-length representation of the word images that is fast to compute and, especially, fast to compare. This approach naturally leads to an unified representation of word images and strings, which seamlessly allows one to indistinctly perform query-by-example, where the query is an image, and query-by-string, where the query is a string. We also propose a calibration scheme to correct the attributes scores based on Canonical Correlation Analysis that greatly improves the results on a challenging dataset. We test our approach on two public datasets showing state-of-the-art results."
            },
            "slug": "Handwritten-Word-Spotting-with-Corrected-Attributes-Almaz\u00e1n-Gordo",
            "title": {
                "fragments": [],
                "text": "Handwritten Word Spotting with Corrected Attributes"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "An attributes-based approach to multi-writer word spotting that leads to a low-dimensional, fixed-length representation of the word images that is fast to compute and, especially, fast to compare is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Computer Vision"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146721"
                        ],
                        "name": "C. Yao",
                        "slug": "C.-Yao",
                        "structuredName": {
                            "firstName": "Cong",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145905113"
                        ],
                        "name": "X. Bai",
                        "slug": "X.-Bai",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276155"
                        ],
                        "name": "Baoguang Shi",
                        "slug": "Baoguang-Shi",
                        "structuredName": {
                            "firstName": "Baoguang",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Baoguang Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743698"
                        ],
                        "name": "Wenyu Liu",
                        "slug": "Wenyu-Liu",
                        "structuredName": {
                            "firstName": "Wenyu",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyu Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Yao et al. (2014) reports 80.2% using strokelets for the small vocabulary task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11341313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca0eb5d81484f62af7b10f18aa4ed65d7856c106",
            "isKey": true,
            "numCitedBy": 243,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Driven by the wide range of applications, scene text detection and recognition have become active research topics in computer vision. Though extensively studied, localizing and reading text in uncontrolled environments remain extremely challenging, due to various interference factors. In this paper, we propose a novel multi-scale representation for scene text recognition. This representation consists of a set of detectable primitives, termed as strokelets, which capture the essential substructures of characters at different granularities. Strokelets possess four distinctive advantages: (1) Usability: automatically learned from bounding box labels, (2) Robustness: insensitive to interference factors, (3) Generality: applicable to variant languages, and (4) Expressivity: effective at describing characters. Extensive experiments on standard benchmarks verify the advantages of strokelets and demonstrate the effectiveness of the proposed algorithm for text recognition."
            },
            "slug": "Strokelets:-A-Learned-Multi-scale-Representation-Yao-Bai",
            "title": {
                "fragments": [],
                "text": "Strokelets: A Learned Multi-scale Representation for Scene Text Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a novel multi-scale representation for scene text recognition that consists of a set of detectable primitives, termed as strokelets, which capture the essential substructures of characters at different granularities."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726358"
                        ],
                        "name": "A. Bissacco",
                        "slug": "A.-Bissacco",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bissacco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bissacco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152710625"
                        ],
                        "name": "M. Cummins",
                        "slug": "M.-Cummins",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Cummins",
                            "middleNames": [
                                "Joseph"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cummins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34180232"
                        ],
                        "name": "Yuval Netzer",
                        "slug": "Yuval-Netzer",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Netzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Netzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2665814"
                        ],
                        "name": "H. Neven",
                        "slug": "H.-Neven",
                        "structuredName": {
                            "firstName": "Hartmut",
                            "lastName": "Neven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Neven"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 17
                            }
                        ],
                        "text": "Bisacco, ICCV\u201913 (Bissacco et al. 2013) HOG-based Deep learning n-gram model + re-ranking heuristics"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 66
                            }
                        ],
                        "text": "For instance, the recent works Almazan et al. (2014) and PhotoOCR Bissacco et al. (2013), which have appeared during the revision of this manuscript, report 87.0 and 90.4% respectively."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3149088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31a8803d7e2618bfa44c472d003055bb5961b9de",
            "isKey": true,
            "numCitedBy": 402,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe Photo OCR, a system for text extraction from images. Our particular focus is reliable text extraction from smartphone imagery, with the goal of text recognition as a user input modality similar to speech recognition. Commercially available OCR performs poorly on this task. Recent progress in machine learning has substantially improved isolated character classification, we build on this progress by demonstrating a complete OCR system using these techniques. We also incorporate modern data center-scale distributed language modelling. Our approach is capable of recognizing text in a variety of challenging imaging conditions where traditional OCR systems fail, notably in the presence of substantial blur, low resolution, low contrast, high image noise and other distortions. It also operates with low latency, mean processing time is 600 ms per image. We evaluate our system on public benchmark datasets for text extraction and outperform all previously reported results, more than halving the error rate on multiple benchmarks. The system is currently in use in many applications at Google, and is available as a user input modality in Google Translate for Android."
            },
            "slug": "PhotoOCR:-Reading-Text-in-Uncontrolled-Conditions-Bissacco-Cummins",
            "title": {
                "fragments": [],
                "text": "PhotoOCR: Reading Text in Uncontrolled Conditions"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This work describes Photo OCR, a system for text extraction from images that is capable of recognizing text in a variety of challenging imaging conditions where traditional OCR systems fail, notably in the presence of substantial blur, low resolution, low contrast, high image noise and other distortions."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Computer Vision"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145532509"
                        ],
                        "name": "Luk\u00e1s Neumann",
                        "slug": "Luk\u00e1s-Neumann",
                        "structuredName": {
                            "firstName": "Luk\u00e1s",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luk\u00e1s Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 17
                            }
                        ],
                        "text": "Neumann, CVPR\u201912 (Neumann and Matas 2012) Extremal regions Shape + AdaBoost Pairwise rules"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 45
                            }
                        ],
                        "text": "2 (Wang and Belongie 2010; Wang et al. 2011; Neumann and Matas 2012; Mishra et al. 2012a, b; Novikova et al. 2012) fit into this framework (see\nTable 1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 216
                            }
                        ],
                        "text": "\u2026et al. 1999; Nagy 2000), understanding text in natural scenes, as opposed to text in clean documents, still poses significant challenges as pointed out by recent papers Wang and Belongie (2010), Wang et al. (2011), Neumann and Matas (2012), Mishra et al. (2012a, b), and Novikova et al. (2012)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206591895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8b595c9e969e5605f62da51b6c16dad8aad3e0e",
            "isKey": false,
            "numCitedBy": 790,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "An end-to-end real-time scene text localization and recognition method is presented. The real-time performance is achieved by posing the character detection problem as an efficient sequential selection from the set of Extremal Regions (ERs). The ER detector is robust to blur, illumination, color and texture variation and handles low-contrast text. In the first classification stage, the probability of each ER being a character is estimated using novel features calculated with O(1) complexity per region tested. Only ERs with locally maximal probability are selected for the second stage, where the classification is improved using more computationally expensive features. A highly efficient exhaustive search with feedback loops is then applied to group ERs into words and to select the most probable character segmentation. Finally, text is recognized in an OCR stage trained using synthetic fonts. The method was evaluated on two public datasets. On the ICDAR 2011 dataset, the method achieves state-of-the-art text localization results amongst published methods and it is the first one to report results for end-to-end text recognition. On the more challenging Street View Text dataset, the method achieves state-of-the-art recall. The robustness of the proposed method against noise and low contrast of characters is demonstrated by \u201cfalse positives\u201d caused by detected watermark text in the dataset."
            },
            "slug": "Real-time-scene-text-localization-and-recognition-Neumann-Matas",
            "title": {
                "fragments": [],
                "text": "Real-time scene text localization and recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "The proposed end-to-end real-time scene text localization and recognition method achieves state-of-the-art text localization results amongst published methods and it is the first one to report results for end- to-end text recognition."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3420471"
                        ],
                        "name": "Raman Jain",
                        "slug": "Raman-Jain",
                        "structuredName": {
                            "firstName": "Raman",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raman Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694502"
                        ],
                        "name": "C. Jawahar",
                        "slug": "C.-Jawahar",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Jawahar",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jawahar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 89
                            }
                        ],
                        "text": "These approaches tend to perform matching at full-image level, employing global features (Jain and Jawahar 2010) or feature sequences (Rath et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 90
                            }
                        ],
                        "text": "These approaches tend to perform matching at full-image level, employing global features (Jain and Jawahar 2010) or feature sequences (Rath et al. 2003; Rodr\u00edguez-Serrano and Perronnin 2012; Sankar et al. 2010) and using a distance-based classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15852880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f6e0402c516813bd0a82891266a8bf660485829",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Matching word images has many applications in document recognition and retrieval systems. Dynamic Time Warping (DTW) is popularly used to estimate the similarity between word images. Word images are represented as sequences of feature vectors, and the cost associated with dynamic programming based alignment is considered as the dissimilarity between them. However, such approaches are computationally costly when compared to fixed length matching schemes. In this paper, we explore systematic methods for identifying appropriate distance metrics for a given database or language. This is achieved by learning query specific distance functions which can be computed online efficiently. We show that a weighted Euclidean distance can outperform DTW for matching word images. This class of distance functions are also ideal for scalability and large scale matching. Our results are validated with mean Average Precision (mAP) on a fully annotated data set of 160K word images. We then show that the learnt distance functions can even be extended to a new database to obtain accurate retrieval."
            },
            "slug": "Towards-more-effective-distance-functions-for-word-Jain-Jawahar",
            "title": {
                "fragments": [],
                "text": "Towards more effective distance functions for word image matching"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that a weighted Euclidean distance can outperform DTW for matching word images, and the learnt distance functions can be extended to a new database to obtain accurate retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3344005"
                        ],
                        "name": "C. Dance",
                        "slug": "C.-Dance",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Dance",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dance"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 69
                            }
                        ],
                        "text": "The search is based on a global image descriptor: the Fisher vector (Perronnin and Dance 2007; Perronnin et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 23
                            }
                        ],
                        "text": "We use Fisher vectors (Perronnin and Dance 2007; Perronnin et al. 2010) in this work, but other image descriptors could be used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12795415,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23694b6d61668e62bb11f17c1d75dde3b4951948",
            "isKey": false,
            "numCitedBy": 1613,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Within the field of pattern classification, the Fisher kernel is a powerful framework which combines the strengths of generative and discriminative approaches. The idea is to characterize a signal with a gradient vector derived from a generative probability model and to subsequently feed this representation to a discriminative classifier. We propose to apply this framework to image categorization where the input signals are images and where the underlying generative model is a visual vocabulary: a Gaussian mixture model which approximates the distribution of low-level features in images. We show that Fisher kernels can actually be understood as an extension of the popular bag-of-visterms. Our approach demonstrates excellent performance on two challenging databases: an in-house database of 19 object/scene categories and the recently released VOC 2006 database. It is also very practical: it has low computational needs both at training and test time and vocabularies trained on one set of categories can be applied to another set without any significant loss in performance."
            },
            "slug": "Fisher-Kernels-on-Visual-Vocabularies-for-Image-Perronnin-Dance",
            "title": {
                "fragments": [],
                "text": "Fisher Kernels on Visual Vocabularies for Image Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work shows that Fisher kernels can actually be understood as an extension of the popular bag-of-visterms, and proposes to apply this framework to image categorization where the input signals are images and where the underlying generative model is a visual vocabulary: a Gaussian mixture model which approximates the distribution of low-level features in images."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711505"
                        ],
                        "name": "A. Brakensiek",
                        "slug": "A.-Brakensiek",
                        "structuredName": {
                            "firstName": "Anja",
                            "lastName": "Brakensiek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Brakensiek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145512909"
                        ],
                        "name": "G. Rigoll",
                        "slug": "G.-Rigoll",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Rigoll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Rigoll"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 118
                            }
                        ],
                        "text": "Specifically, for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 221
                            }
                        ],
                        "text": "\u2026open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34231915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02965cf604b51a64e9bbdb8741f1e317b4620464",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper several aspects of a recognition system for cursive handwritten German address words (cities and streets) are described. The recognition system is based on Hidden Markov Models (HMMs), whereat the focus is on two main problems: the changes in the writing style depending on time or regional differences and the difficulty to select the correct (complete) dictionary for address reading. The first problem leads to the examination of three different adaptation techniques: Maximum Likelihood (ML), Maximum Likelihood Linear Regression (MLLR) and Scaled Likelihood Linear Regression (SLLR). To handle the second problem language models based on backoff character n-grams are examined to evaluate the performance of an open vocabulary recognition (without dictionary). For both problems the determination of confidence measures (based on the frame-normalized likelihood, a garbage model, a two-best recognition or an unconstrained character decoding) is important, either for an unsupervised adaptation or the detection of out of vocabulary words (OOV). The databases, which are used for recognition, are provided by Siemens Dematic (SD) within the Adaptive READ project."
            },
            "slug": "Handwritten-Address-Recognition-Using-Hidden-Markov-Brakensiek-Rigoll",
            "title": {
                "fragments": [],
                "text": "Handwritten Address Recognition Using Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The recognition system is based on Hidden Markov Models (HMMs), whereat the focus is on two main problems: the changes in the writing style depending on time or regional differences and the difficulty to select the correct dictionary for address reading."
            },
            "venue": {
                "fragments": [],
                "text": "Reading and Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398811"
                        ],
                        "name": "Yan Liu",
                        "slug": "Yan-Liu",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995438"
                        ],
                        "name": "Jorge S\u00e1nchez",
                        "slug": "Jorge-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50228329"
                        ],
                        "name": "H. Poirier",
                        "slug": "H.-Poirier",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Poirier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Poirier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 49
                            }
                        ],
                        "text": "We use Fisher vectors (Perronnin and Dance 2007; Perronnin et al. 2010) in this work, but other image descriptors could be used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 4
                            }
                        ],
                        "text": "See Perronnin et al. (2010) for more details about the FV.\n3.3 Text Embedding\nWe now seek a function \u03d5 : Y \u2192 RE to embed text labels into a Euclidean space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 81
                            }
                        ],
                        "text": "For the statistics computation and aggregation, we choose the Fisher vector (FV) (Perronnin et al. 2010), since it has demonstrated state-of-the-art results in image retrieval (J\u00e9gou et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 95
                            }
                        ],
                        "text": "The search is based on a global image descriptor: the Fisher vector (Perronnin and Dance 2007; Perronnin et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 124
                            }
                        ],
                        "text": "This is an approximate explicit embedding of the Fisher kernel, which obtained state-of-the-art results in image retrieval (Perronnin et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 73
                            }
                        ],
                        "text": "To extract image signatures, we adopt again the Fisher vector framework (Perronnin et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 82
                            }
                        ],
                        "text": "For the statistics computation and aggregation, we choose the Fisher vector (FV) (Perronnin et al. 2010), since it has demonstrated state-of-the-art results in image retrieval (J\u00e9gou et al. 2012) and classification (Chatfield et al. 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 207
                            }
                        ],
                        "text": "Other normalizations can also be applied such as a square-rooting which is beneficial on histogram representations when measures such as the dot-product or Euclidean distance are subsequently used (see e.g. Perronnin et al. (2010))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16161770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48257a889a9aa61998ae20fa52b25d90c441f63a",
            "isKey": false,
            "numCitedBy": 763,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of large-scale image search has been traditionally addressed with the bag-of-visual-words (BOV). In this article, we propose to use as an alternative the Fisher kernel framework. We first show why the Fisher representation is well-suited to the retrieval problem: it describes an image by what makes it different from other images. One drawback of the Fisher vector is that it is high-dimensional and, as opposed to the BOV, it is dense. The resulting memory and computational costs do not make Fisher vectors directly amenable to large-scale retrieval. Therefore, we compress Fisher vectors to reduce their memory footprint and speed-up the retrieval. We compare three binarization approaches: a simple approach devised for this representation and two standard compression techniques. We show on two publicly available datasets that compressed Fisher vectors perform very well using as little as a few hundreds of bits per image, and significantly better than a very recent compressed BOV approach."
            },
            "slug": "Large-scale-image-retrieval-with-compressed-Fisher-Perronnin-Liu",
            "title": {
                "fragments": [],
                "text": "Large-scale image retrieval with compressed Fisher vectors"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article shows why the Fisher representation is well-suited to the retrieval problem: it describes an image by what makes it different from other images, and why it should be compressed to reduce their memory footprint and speed-up the retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352980"
                        ],
                        "name": "T. Rath",
                        "slug": "T.-Rath",
                        "structuredName": {
                            "firstName": "Toni",
                            "lastName": "Rath",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15554170,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e20e64661424bee772c7f002d45c1ac79578fb03",
            "isKey": false,
            "numCitedBy": 658,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Libraries and other institutions are interested in providing access to scanned versions of their large collections of handwritten historical manuscripts on electronic media. Convenient access to a collection requires an index, which is manually created at great labor and expense. Since current handwriting recognizers do not perform well on historical documents, a technique called word spotting has been developed: clusters with occurrences of the same word in a collection are established using image matching. By annotating \"interesting\" clusters, an index can be built automatically. We present an algorithm for matching handwritten words in noisy historical documents. The segmented word images are preprocessed to create sets of 1-dimensional features, which are then compared using dynamic time warping. We present experimental results on two different data sets from the George Washington collection. Our experiments show that this algorithm performs better and is faster than competing matching techniques."
            },
            "slug": "Word-image-matching-using-dynamic-time-warping-Rath-Manmatha",
            "title": {
                "fragments": [],
                "text": "Word image matching using dynamic time warping"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents an algorithm for matching handwritten words in noisy historical documents that performs better and is faster than competing matching techniques and presents experimental results on two different data sets from the George Washington collection."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399142941"
                        ],
                        "name": "Jos\u00e9 A. Rodr\u00edguez-Serrano",
                        "slug": "Jos\u00e9-A.-Rodr\u00edguez-Serrano",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Rodr\u00edguez-Serrano",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 A. Rodr\u00edguez-Serrano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 153
                            }
                        ],
                        "text": "These approaches tend to perform matching at full-image level, employing global features (Jain and Jawahar 2010) or feature sequences (Rath et al. 2003; Rodr\u00edguez-Serrano and Perronnin 2012; Sankar et al. 2010) and using a distance-based classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 155
                            }
                        ],
                        "text": "The similarity computed by dynamic time warping on sequences of local gradient histogram features, which is state-of-the-art in image-based word-spotting (Rodr\u00edguez-Serrano and Perronnin 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6677464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e117b2a79a1c25f7894d1ee3787d2b70cd5fcf4d",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a novel similarity measure between vector sequences. We work in the framework of model-based approaches, where each sequence is first mapped to a Hidden Markov Model (HMM) and then a measure of similarity is computed between the HMMs. We propose to model sequences with semicontinuous HMMs (SC-HMMs). This is a particular type of HMM whose emission probabilities in each state are mixtures of shared Gaussians. This crucial constraint provides two major benefits. First, the a priori information contained in the common set of Gaussians leads to a more accurate estimate of the HMM parameters. Second, the computation of a similarity between two SC-HMMs can be simplified to a Dynamic Time Warping (DTW) between their mixture weight vectors, which significantly reduces the computational cost. Experiments are carried out on a handwritten word retrieval task in three different datasets-an in-house dataset of real handwritten letters, the George Washington dataset, and the IFN/ENIT dataset of Arabic handwritten words. These experiments show that the proposed similarity outperforms the traditional DTW between the original sequences, and the model-based approach which uses ordinary continuous HMMs. We also show that this increase in accuracy can be traded against a significant reduction of the computational cost."
            },
            "slug": "A-Model-Based-Sequence-Similarity-with-Application-Rodr\u00edguez-Serrano-Perronnin",
            "title": {
                "fragments": [],
                "text": "A Model-Based Sequence Similarity with Application to Handwritten Word Spotting"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The proposed similarity outperforms the traditional DTW between the original sequences, and the model-based approach which uses ordinary continuous HMMs, and it is shown that this increase in accuracy can be traded against a significant reduction of the computational cost."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681054"
                        ],
                        "name": "H. J\u00e9gou",
                        "slug": "H.-J\u00e9gou",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "J\u00e9gou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. J\u00e9gou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271933"
                        ],
                        "name": "M. Douze",
                        "slug": "M.-Douze",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Douze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Douze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995443"
                        ],
                        "name": "Jorge S\u00e1nchez",
                        "slug": "Jorge-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144565371"
                        ],
                        "name": "P. P\u00e9rez",
                        "slug": "P.-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. P\u00e9rez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 84
                            }
                        ],
                        "text": "The dot product between Fisher vectors is a standard way to perform the comparison (J\u00e9gou et al. 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 77
                            }
                        ],
                        "text": "2010), since it has demonstrated state-of-the-art results in image retrieval (J\u00e9gou et al. 2012) and classification (Chatfield et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 177
                            }
                        ],
                        "text": "For the statistics computation and aggregation, we choose the Fisher vector (FV) (Perronnin et al. 2010), since it has demonstrated state-of-the-art results in image retrieval (J\u00e9gou et al. 2012) and classification (Chatfield et al. 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 203
                            }
                        ],
                        "text": "Since we use a retrieval-based approach for text recognition, there is abundant literature on large-scale retrieval that can be leveraged for this task, for example on compressing histogram descriptors (J\u00e9gou et al. 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9437674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5183230b706b72f6f6c19415c423d93c79ddde53",
            "isKey": false,
            "numCitedBy": 1431,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of large-scale image search. Three constraints have to be taken into account: search accuracy, efficiency, and memory usage. We first present and evaluate different ways of aggregating local image descriptors into a vector and show that the Fisher kernel achieves better performance than the reference bag-of-visual words approach for any given vector dimension. We then jointly optimize dimensionality reduction and indexing in order to obtain a precise vector comparison as well as a compact representation. The evaluation shows that the image representation can be reduced to a few dozen bytes while preserving high accuracy. Searching a 100 million image data set takes about 250 ms on one processor core."
            },
            "slug": "Aggregating-Local-Image-Descriptors-into-Compact-J\u00e9gou-Perronnin",
            "title": {
                "fragments": [],
                "text": "Aggregating Local Image Descriptors into Compact Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper first presents and evaluates different ways of aggregating local image descriptors into a vector and shows that the Fisher kernel achieves better performance than the reference bag-of-visual words approach for any given vector dimension."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995438"
                        ],
                        "name": "Jorge S\u00e1nchez",
                        "slug": "Jorge-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722052"
                        ],
                        "name": "Thomas Mensink",
                        "slug": "Thomas-Mensink",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Mensink",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Mensink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 49
                            }
                        ],
                        "text": "We use Fisher vectors (Perronnin and Dance 2007; Perronnin et al. 2010) in this work, but other image descriptors could be used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 4
                            }
                        ],
                        "text": "See Perronnin et al. (2010) for more details about the FV.\n3.3 Text Embedding\nWe now seek a function \u03d5 : Y \u2192 RE to embed text labels into a Euclidean space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 95
                            }
                        ],
                        "text": "The search is based on a global image descriptor: the Fisher vector (Perronnin and Dance 2007; Perronnin et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 124
                            }
                        ],
                        "text": "This is an approximate explicit embedding of the Fisher kernel, which obtained state-of-the-art results in image retrieval (Perronnin et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 73
                            }
                        ],
                        "text": "To extract image signatures, we adopt again the Fisher vector framework (Perronnin et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 82
                            }
                        ],
                        "text": "For the statistics computation and aggregation, we choose the Fisher vector (FV) (Perronnin et al. 2010), since it has demonstrated state-of-the-art results in image retrieval (J\u00e9gou et al. 2012) and classification (Chatfield et al. 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 207
                            }
                        ],
                        "text": "Other normalizations can also be applied such as a square-rooting which is beneficial on histogram representations when measures such as the dot-product or Euclidean distance are subsequently used (see e.g. Perronnin et al. (2010))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10402702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39f3b1804b8df5be645a1dcb4a876e128385d9be",
            "isKey": false,
            "numCitedBy": 2662,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "The Fisher kernel (FK) is a generic framework which combines the benefits of generative and discriminative approaches. In the context of image classification the FK was shown to extend the popular bag-of-visual-words (BOV) by going beyond count statistics. However, in practice, this enriched representation has not yet shown its superiority over the BOV. In the first part we show that with several well-motivated modifications over the original framework we can boost the accuracy of the FK. On PASCAL VOC 2007 we increase the Average Precision (AP) from 47.9% to 58.3%. Similarly, we demonstrate state-of-the-art accuracy on CalTech 256. A major advantage is that these results are obtained using only SIFT descriptors and costless linear classifiers. Equipped with this representation, we can now explore image classification on a larger scale. In the second part, as an application, we compare two abundant resources of labeled images to learn classifiers: ImageNet and Flickr groups. In an evaluation involving hundreds of thousands of training images we show that classifiers learned on Flickr groups perform surprisingly well (although they were not intended for this purpose) and that they can complement classifiers learned on more carefully annotated datasets."
            },
            "slug": "Improving-the-Fisher-Kernel-for-Large-Scale-Image-Perronnin-S\u00e1nchez",
            "title": {
                "fragments": [],
                "text": "Improving the Fisher Kernel for Large-Scale Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "In an evaluation involving hundreds of thousands of training images, it is shown that classifiers learned on Flickr groups perform surprisingly well and that they can complement classifier learned on more carefully annotated datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722052"
                        ],
                        "name": "Thomas Mensink",
                        "slug": "Thomas-Mensink",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Mensink",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Mensink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721683"
                        ],
                        "name": "J. Verbeek",
                        "slug": "J.-Verbeek",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Verbeek",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Verbeek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808423"
                        ],
                        "name": "G. Csurka",
                        "slug": "G.-Csurka",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Csurka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 144
                            }
                        ],
                        "text": "In fact, many existing machine learning algorithms compute a match between an input example and a class template (e.g. nearest mean classifier (Mensink et al. 2012), support vector machines), which could be interpreted as a label embedding."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 24
                            }
                        ],
                        "text": "nearest mean classifier (Mensink et al. 2012), support vector machines), which could be interpreted as a label embedding."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9296691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a4a53fe47036ac89dad070ab87a9d8795b139b1",
            "isKey": false,
            "numCitedBy": 260,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We are interested in large-scale image classification and especially in the setting where images corresponding to new or existing classes are continuously added to the training set. Our goal is to devise classifiers which can incorporate such images and classes on-the-fly at (near) zero cost. We cast this problem into one of learning a metric which is shared across all classes and explore k-nearest neighbor (k-NN) and nearest class mean (NCM) classifiers. We learn metrics on the ImageNet 2010 challenge data set, which contains more than 1.2M training images of 1K classes. Surprisingly, the NCM classifier compares favorably to the more flexible k-NN classifier, and has comparable performance to linear SVMs. We also study the generalization performance, among others by using the learned metric on the ImageNet-10K dataset, and we obtain competitive performance. Finally, we explore zero-shot classification, and show how the zero-shot model can be combined very effectively with small training datasets."
            },
            "slug": "Metric-Learning-for-Large-Scale-Image-Generalizing-Mensink-Verbeek",
            "title": {
                "fragments": [],
                "text": "Metric Learning for Large Scale Image Classification: Generalizing to New Classes at Near-Zero Cost"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The goal is to devise classifiers which can incorporate images and classes on-the-fly at (near) zero cost and to explore k-nearest neighbor (k-NN) and nearest class mean (NCM) classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995438"
                        ],
                        "name": "Jorge S\u00e1nchez",
                        "slug": "Jorge-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398811"
                        ],
                        "name": "Yan Liu",
                        "slug": "Yan-Liu",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 49
                            }
                        ],
                        "text": "We use Fisher vectors (Perronnin and Dance 2007; Perronnin et al. 2010) in this work, but other image descriptors could be used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 4
                            }
                        ],
                        "text": "See Perronnin et al. (2010) for more details about the FV.\n3.3 Text Embedding\nWe now seek a function \u03d5 : Y \u2192 RE to embed text labels into a Euclidean space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 95
                            }
                        ],
                        "text": "The search is based on a global image descriptor: the Fisher vector (Perronnin and Dance 2007; Perronnin et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 124
                            }
                        ],
                        "text": "This is an approximate explicit embedding of the Fisher kernel, which obtained state-of-the-art results in image retrieval (Perronnin et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 73
                            }
                        ],
                        "text": "To extract image signatures, we adopt again the Fisher vector framework (Perronnin et al. 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 82
                            }
                        ],
                        "text": "For the statistics computation and aggregation, we choose the Fisher vector (FV) (Perronnin et al. 2010), since it has demonstrated state-of-the-art results in image retrieval (J\u00e9gou et al. 2012) and classification (Chatfield et al. 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 207
                            }
                        ],
                        "text": "Other normalizations can also be applied such as a square-rooting which is beneficial on histogram representations when measures such as the dot-product or Euclidean distance are subsequently used (see e.g. Perronnin et al. (2010))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11943675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b282b22975e7220059616d6b08eb87482926db3",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Kernel machines rely on an implicit mapping of the data such that non-linear classification in the original space corresponds to linear classification in the new space. As kernel machines are difficult to scale to large training sets, it has been proposed to perform an explicit mapping of the data and to learn directly linear classifiers in the new space. In this paper, we consider the problem of learning image categorizers on large image sets (e.g. > 100k images) using bag-of-visual-words (BOV) image representations and Support Vector Machine classifiers. We experiment with three approaches to BOV embedding: 1) kernel PCA (kPCA) [15], 2) a modified kPCA we propose for additive kernels and 3) random projections for shift-invariant kernels [14]. We report experiments on 3 datasets: Cal-tech101, VOC07 and ImageNet. An important conclusion is that simply square-rooting BOV vectors \u2013 which corresponds to an exact mapping for the Bhattacharyya kernel \u2013 already leads to large improvements, often quite close to the best results obtained with additive kernels. Another conclusion is that, although it is possible to go beyond additive kernels, the embedding comes at a much higher cost."
            },
            "slug": "Large-scale-image-categorization-with-explicit-data-Perronnin-S\u00e1nchez",
            "title": {
                "fragments": [],
                "text": "Large-scale image categorization with explicit data embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper considers the problem of learning image categorizers on large image sets (e.g. > 100k images) using bag-of-visual-words (BOV) image representations and Support Vector Machine classifiers and experiments with three approaches to BOV embedding."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2234121"
                        ],
                        "name": "S. Madhvanath",
                        "slug": "S.-Madhvanath",
                        "structuredName": {
                            "firstName": "Sriganesh",
                            "lastName": "Madhvanath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Madhvanath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 168
                            }
                        ],
                        "text": "The holistic approach \u201ctreats the word as a single, indivisible entity and attempts to recognize words from their overall shape, as opposed to their character contents\u201d (Madhvanath and Govindaraju 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6466839,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ad8d39a926082bf52d3f407e7d384680158ee0cb",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 117,
            "paperAbstract": {
                "fragments": [],
                "text": "The holistic paradigm in handwritten word recognition treats the word as a single, indivisible entity and attempts to recognize words from their overall shape, as opposed to their character contents. In this survey, we have attempted to take a fresh look at the potential role of the holistic paradigm in handwritten word recognition. The survey begins with an overview of studies of reading which provide evidence for the existence of a parallel holistic reading process,in both developing and skilled readers. In what we believe is a fresh perspective on handwriting recognition, approaches to recognition are characterized as forming a continuous spectrum based on the visual complexity of the unit of recognition employed and an attempt is made to interpret well-known paradigms of word recognition in this framework. An overview of features, methodologies, representations, and matching techniques employed by holistic approaches is presented."
            },
            "slug": "The-Role-of-Holistic-Paradigms-in-Handwritten-Word-Madhvanath-Govindaraju",
            "title": {
                "fragments": [],
                "text": "The Role of Holistic Paradigms in Handwritten Word Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A fresh look is taken at the potential role of the holistic paradigm in handwritten word recognition and an attempt is made to interpret well-known paradigms of word recognition in this framework."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711505"
                        ],
                        "name": "A. Brakensiek",
                        "slug": "A.-Brakensiek",
                        "structuredName": {
                            "firstName": "Anja",
                            "lastName": "Brakensiek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Brakensiek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1887555"
                        ],
                        "name": "J. Rottland",
                        "slug": "J.-Rottland",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Rottland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rottland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3027904"
                        ],
                        "name": "A. Kosmala",
                        "slug": "A.-Kosmala",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Kosmala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kosmala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145512909"
                        ],
                        "name": "G. Rigoll",
                        "slug": "G.-Rigoll",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Rigoll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Rigoll"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 130
                            }
                        ],
                        "text": "This is in contrast with some works in text recognition, especially handwriting recognition, able to deal with open vocabularies (Brakensiek et al. 2000)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 5628034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df0b420cb429ef6678b75e13242c8b0d7be10794",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a system for on-line cursive handwriting recognition is described. The system is based on Hidden Markov Models (HMMs) using discrete and hybrid modeling techniques. Here, we focus on two aspects of the recognition system. First, we present different hybrid modeling techniques, whereas one depends on an information theory-based neural network (MMI-criterion) used as a vector quantizer and the other uses a neural net for estimating the a posteriori probabilities to replace the codebook of a tied-mixture HMM system. This is the first paper where we present this novel approach -called tied posteriors- for handwriting recognition. Second, we demonstrate the usage of a language model, that consists of character n-grams, as an alternative to the recognition with a large dictionary of German words. Our resulting system for character recognition yields significantly better recognition results using an unlimited vocabulary."
            },
            "slug": "OFF-LINE-HANDWRITING-RECOGNITION-USING-VARIOUS-AND-Brakensiek-Rottland",
            "title": {
                "fragments": [],
                "text": "OFF-LINE HANDWRITING RECOGNITION USING VARIOUS HYBRID MODELING TECHNIQUES AND CHARACTER N-GRAMS"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This is the first paper where this novel approach -called tied posteriors- for handwriting recognition is presented, and the usage of a language model, that consists of character n-grams, as an alternative to the recognition with a large dictionary of German words is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120567545"
                        ],
                        "name": "M. Roth",
                        "slug": "M.-Roth",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Roth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403379723"
                        ],
                        "name": "E. G. Schukat-Talamazzini",
                        "slug": "E.-G.-Schukat-Talamazzini",
                        "structuredName": {
                            "firstName": "Ernst",
                            "lastName": "Schukat-Talamazzini",
                            "middleNames": [
                                "G\u00fcnter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. G. Schukat-Talamazzini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18871413,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbb152d521161fba45b4f306188adfefa8c69977",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Off-line-cursive-handwriting-recognition-using-Bunke-Roth",
            "title": {
                "fragments": [],
                "text": "Off-line cursive handwriting recognition using hidden markov models"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398821307"
                        ],
                        "name": "M. El-Yacoubi",
                        "slug": "M.-El-Yacoubi",
                        "structuredName": {
                            "firstName": "Moun\u00eem",
                            "lastName": "El-Yacoubi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. El-Yacoubi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2787007"
                        ],
                        "name": "M. Gilloux",
                        "slug": "M.-Gilloux",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Gilloux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gilloux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744351"
                        ],
                        "name": "R. Sabourin",
                        "slug": "R.-Sabourin",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Sabourin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sabourin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 118
                            }
                        ],
                        "text": "Specifically, for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 175
                            }
                        ],
                        "text": "\u2026open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16688674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4375f08528e3326280210f95215237db637f199",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a hidden Markov model-based approach designed to recognize off-line unconstrained handwritten words for large vocabularies. After preprocessing, a word image is segmented into letters or pseudoletters and represented by two feature sequences of equal length, each consisting of an alternating sequence of shape-symbols and segmentation-symbols, which are both explicitly modeled. The word model is made up of the concatenation of appropriate letter models consisting of elementary HMMs and an HMM-based interpolation technique is used to optimally combine the two feature sets. Two rejection mechanisms are considered depending on whether or not the word image is guaranteed to belong to the lexicon. Experiments carried out on real-life data show that the proposed approach can be successfully used for handwritten word recognition."
            },
            "slug": "An-HMM-Based-Approach-for-Off-Line-Unconstrained-El-Yacoubi-Gilloux",
            "title": {
                "fragments": [],
                "text": "An HMM-Based Approach for Off-Line Unconstrained Handwritten Word Modeling and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A hidden Markov model-based approach designed to recognize off-line unconstrained handwritten words for large vocabularies and can be successfully used for handwritten word recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727076"
                        ],
                        "name": "H. Lodhi",
                        "slug": "H.-Lodhi",
                        "structuredName": {
                            "firstName": "Huma",
                            "lastName": "Lodhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lodhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144884649"
                        ],
                        "name": "C. Saunders",
                        "slug": "C.-Saunders",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Saunders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Saunders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4562073"
                        ],
                        "name": "C. Watkins",
                        "slug": "C.-Watkins",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Watkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Watkins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 146
                            }
                        ],
                        "text": "We note that we could make use of unsupervised techniques to embed word labels in a Euclidean space, for example by defining string kernels (e.g. Lodhi et al. (2002)), and employ Kernel PCA (Sch\u00f6lkopf et al. 1998) for the actual embedding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 669209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f330f1f472f860212b980bb9be81eff884f7f0e1",
            "isKey": false,
            "numCitedBy": 1643,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel kernel for comparing two text documents. The kernel is an inner product in the feature space consisting of all subsequences of length k. A subsequence is any ordered sequence of k characters occurring in the text though not necessarily contiguously. The subsequences are weighted by an exponentially decaying factor of their full length in the text, hence emphasising those occurrences which are close to contiguous. A direct computation of this feature vector would involve a prohibitive amount of computation even for modest values of k, since the dimension of the feature space grows exponentially with k. The paper describes how despite this fact the inner product can be efficiently evaluated by a dynamic programming technique. A preliminary experimental comparison of the performance of the kernel compared with a standard word feature space kernel [6] is made showing encouraging results."
            },
            "slug": "Text-Classification-using-String-Kernels-Lodhi-Saunders",
            "title": {
                "fragments": [],
                "text": "Text Classification using String Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A novel kernel is introduced for comparing two text documents consisting of an inner product in the feature space consisting of all subsequences of length k, which can be efficiently evaluated by a dynamic programming technique."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764761"
                        ],
                        "name": "K. Chatfield",
                        "slug": "K.-Chatfield",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Chatfield",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chatfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740145"
                        ],
                        "name": "V. Lempitsky",
                        "slug": "V.-Lempitsky",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lempitsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lempitsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 216
                            }
                        ],
                        "text": "For the statistics computation and aggregation, we choose the Fisher vector (FV) (Perronnin et al. 2010), since it has demonstrated state-of-the-art results in image retrieval (J\u00e9gou et al. 2012) and classification (Chatfield et al. 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13126996,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b7908f71188b89adf62ce9126a0466e1a34338f",
            "isKey": false,
            "numCitedBy": 932,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "A large number of novel encodings for bag of visual words models have been proposed in the past two years to improve on the standard histogram of quantized local features. Examples include locality-constrained linear encoding [23], improved Fisher encoding [17], super vector encoding [27], and kernel codebook encoding [20]. While several authors have reported very good results on the challenging PASCAL VOC classification data by means of these new techniques, differences in the feature computation and learning algorithms, missing details in the description of the methods, and different tuning of the various components, make it impossible to compare directly these methods and hard to reproduce the results reported. This paper addresses these shortcomings by carrying out a rigorous evaluation of these new techniques by: (1) fixing the other elements of the pipeline (features, learning, tuning); (2) disclosing all the implementation details, and (3) identifying both those aspects of each method which are particularly important to achieve good performance, and those aspects which are less critical. This allows a consistent comparative analysis of these encoding methods. Several conclusions drawn from our analysis cannot be inferred from the original publications."
            },
            "slug": "The-devil-is-in-the-details:-an-evaluation-of-Chatfield-Lempitsky",
            "title": {
                "fragments": [],
                "text": "The devil is in the details: an evaluation of recent feature encoding methods"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A rigorous evaluation of novel encodings for bag of visual words models by identifying both those aspects of each method which are particularly important to achieve good performance, and those aspects which are less critical, which allows a consistent comparative analysis of these encoding methods."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 243
                            }
                        ],
                        "text": "To include spatial information about the word image into the signature, we can partition the image into regions, aggregate the per-patch statistics at a region level and then concatenate the region-level signatures as proposed for instance in Lazebnik et al. (2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 10
                            }
                        ],
                        "text": "Following Lazebnik et al. (2006), we generate regions by initially considering the whole word as a region, and then recursively splitting regions into 2 regular halves."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 43
                            }
                        ],
                        "text": "To overcome this, we draw inspiration from Lazebnik et al. (2006) and propose to use spatial pyramids."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": true,
            "numCitedBy": 8328,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808423"
                        ],
                        "name": "G. Csurka",
                        "slug": "G.-Csurka",
                        "structuredName": {
                            "firstName": "Gabriela",
                            "lastName": "Csurka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Csurka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17606900,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b91180d8853d00e8f2df7ee3532e07d3d0cce2af",
            "isKey": false,
            "numCitedBy": 5008,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Naive Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for simultaneously classifying seven semantic visual categories. These results clearly demonstrate that the method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information."
            },
            "slug": "Visual-categorization-with-bags-of-keypoints-Csurka",
            "title": {
                "fragments": [],
                "text": "Visual categorization with bags of keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches and shows that it is simple, computationally efficient and intrinsically invariant."
            },
            "venue": {
                "fragments": [],
                "text": "eccv 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15058655"
                        ],
                        "name": "S. Knerr",
                        "slug": "S.-Knerr",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Knerr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Knerr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39933279"
                        ],
                        "name": "E. Augustin",
                        "slug": "E.-Augustin",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "Augustin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Augustin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2953853"
                        ],
                        "name": "O. Baret",
                        "slug": "O.-Baret",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Baret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Baret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085271779"
                        ],
                        "name": "David Price",
                        "slug": "David-Price",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Price",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Price"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 118
                            }
                        ],
                        "text": "Specifically, for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 156
                            }
                        ],
                        "text": "\u2026open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8468286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8436db8545d8277f9ff56b2738c6e29f344e9c45",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A hidden Markov model (HMM) based word recognition algorithm for the recognition of legal amounts from French bank checks is presented. This algorithm is part of the A2iA INTERCHEQUE recognition system. The algorithm starts from images of handwritten words which have been automatically segmented from binary check images. After finding the lower-case zone on the complete amount, words are slant corrected and then segmented into graphemes. Then, features are extracted from the graphemes, and the feature vectors are vector quantized resulting in a sequence of symbols for each word. Likelihoods of all word classes are computed by a set of HMMs, which have been previously trained using either the Viterbi algorithm or the Baum?Welch algorithm. The various parameters of the system have been identified and their importance evaluated. Results have been obtained on large real-life data bases of French handwritten checks. The HMM-based system has been shown to outperform a holistic word recognizer and another HMM-type word recognizer from the A2iA INTERCHEQUE recognition system. Word recognition rates of about 89% for the 26-word vocabulary relevant for legal amount recognition on French bank checks have been obtained. More recently, a Neural Network?HMM hybrid has been designed, which produces even better recognition rates."
            },
            "slug": "Hidden-Markov-Model-Based-Word-Recognition-and-Its-Knerr-Augustin",
            "title": {
                "fragments": [],
                "text": "Hidden Markov Model Based Word Recognition and Its Application to Legal Amount Reading on French Checks"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A hidden Markov model (HMM) based word recognition algorithm for the recognition of legal amounts from French bank checks is presented and has been shown to outperform a holistic word Recognizer and another HMM-type word recognizer from the A2iA INTERCHEQUE recognition system."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2554435"
                        ],
                        "name": "Issam Bazzi",
                        "slug": "Issam-Bazzi",
                        "structuredName": {
                            "firstName": "Issam",
                            "lastName": "Bazzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Issam Bazzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 278
                            }
                        ],
                        "text": "\u20261987), in many cases character segmentation is not reliable and the systems had to produce character hypotheses and find the most likely word using a high-level model, for instance dynamic programming (Breuel 2001) or in a more principled way with hidden Markov models (HMMs) (Bazzi et al. 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 397,
                                "start": 378
                            }
                        ],
                        "text": "While the early systems relied on explicit character separation and classification (Cash and Hatamian 1987), in many cases character segmentation is not reliable and the systems had to produce character hypotheses and find the most likely word using a high-level model, for instance dynamic programming (Breuel 2001) or in a more principled way with hidden Markov models (HMMs) (Bazzi et al. 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11815403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6272317b62292deb6f342f499f36e6ecf7b9c1b",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an omnifont, unlimited-vocabulary OCR system for English and Arabic. The system is based on hidden Markov models (HMM), an approach that has proven to be very successful in the area of automatic speech recognition. We focus on two aspects of the OCR system. First, we address the issue of how to perform OCR on omnifont and multi-style data, such as plain and italic, without the need to have a separate model for each style. The amount of training data from each style, which is used to train a single model, becomes an important issue in the face of the conditional independence assumption inherent in the use of HMMs. We demonstrate mathematically and empirically how to allocate training data among the different styles to alleviate this problem. Second, we show how to use a word-based HMM system to perform character recognition with unlimited vocabulary. The method includes the use of a trigram language model on character sequences. Using all these techniques, we have achieved character error rates of 1.1 percent on data from the University of Washington English Document Image Database and 3.3 percent on data from the DARPA Arabic OCR Corpus."
            },
            "slug": "An-Omnifont-Open-Vocabulary-OCR-System-for-English-Bazzi-Schwartz",
            "title": {
                "fragments": [],
                "text": "An Omnifont Open-Vocabulary OCR System for English and Arabic"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "An omnifont, unlimited-vocabulary OCR system for English and Arabic based on hidden Markov models (HMM), an approach that has proven to be very successful in the area of automatic speech recognition, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719436"
                        ],
                        "name": "A. Vinciarelli",
                        "slug": "A.-Vinciarelli",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Vinciarelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vinciarelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 118
                            }
                        ],
                        "text": "Specifically, for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 249
                            }
                        ],
                        "text": "\u2026open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8717387,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc7b170fafcd44b4db939306c66a2799ae9b27b3",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a system for the offline recognition of large vocabulary unconstrained handwritten texts. The only assumption made about the data is that it is written in English. This allows the application of statistical language models in order to improve the performance of our system. Several experiments have been performed using both single and multiple writer data. Lexica of variable size (from 10,000 to 50,000 words) have been used. The use of language models is shown to improve the accuracy of the system (when the lexicon contains 50,000 words, the error rate is reduced by /spl sim/50 percent for single writer data and by /spl sim/25 percent for multiple writer data). Our approach is described in detail and compared with other methods presented in the literature to deal with the same problem. An experimental setup to correctly deal with unconstrained text recognition is proposed."
            },
            "slug": "Offline-recognition-of-unconstrained-handwritten-Vinciarelli-Bengio",
            "title": {
                "fragments": [],
                "text": "Offline recognition of unconstrained handwritten texts using HMMs and statistical language models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The use of language models is shown to improve the accuracy of the system and the approach is described in detail and compared with other methods presented in the literature to deal with the same problem."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746841"
                        ],
                        "name": "Nicolas Usunier",
                        "slug": "Nicolas-Usunier",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Usunier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Usunier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 30
                            }
                        ],
                        "text": "This is to be contrasted with Weston et al. (2010) where the label embeddings are learned."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7587705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aea0f946e8dcddb65cc2e907456c42453f246a50",
            "isKey": false,
            "numCitedBy": 419,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Image annotation datasets are becoming larger and larger, with tens of millions of images and tens of thousands of possible annotations. We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at k of the ranked list of annotations for a given image and learning a low-dimensional joint embedding space for both images and annotations. Our method both outperforms several baseline methods and, in comparison to them, is faster and consumes less memory. We also demonstrate how our method learns an interpretable model, where annotations with alternate spellings or even languages are close in the embedding space. Hence, even when our model does not predict the exact annotation given by a human labeler, it often predicts similar annotations, a fact that we try to quantify by measuring the newly introduced \u201csibling\u201d precision metric, where our method also obtains excellent results."
            },
            "slug": "Large-scale-image-annotation:-learning\u00a0to\u00a0rank-Weston-Bengio",
            "title": {
                "fragments": [],
                "text": "Large scale image annotation: learning\u00a0to\u00a0rank with\u00a0joint word-image embeddings"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This work proposes a strongly performing method that scales to image annotation datasets by simultaneously learning to optimize precision at k of the ranked list of annotations for a given image and learning a low-dimensional joint embedding space for both images and annotations."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2835432"
                        ],
                        "name": "G. Cash",
                        "slug": "G.-Cash",
                        "structuredName": {
                            "firstName": "Glenn",
                            "lastName": "Cash",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cash"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14915648"
                        ],
                        "name": "M. Hatamian",
                        "slug": "M.-Hatamian",
                        "structuredName": {
                            "firstName": "Mehdi",
                            "lastName": "Hatamian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hatamian"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 84
                            }
                        ],
                        "text": "While the early systems relied on explicit character separation and classification (Cash and Hatamian 1987), in many cases character segmentation is not reliable and the systems had to produce character hypotheses and find the most likely word using a high-level model, for instance dynamic\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 83
                            }
                        ],
                        "text": "While the early systems relied on explicit character separation and classification (Cash and Hatamian 1987), in many cases character segmentation is not reliable and the systems had to produce character hypotheses and find the most likely word using a high-level model, for instance dynamic programming (Breuel 2001) or in a more principled way with hidden Markov models (HMMs) (Bazzi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123043060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b18c68425157ac4533b15ecd98115e8bcdbc264d",
            "isKey": false,
            "numCitedBy": 157,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optical-character-recognition-by-the-method-of-Cash-Hatamian",
            "title": {
                "fragments": [],
                "text": "Optical character recognition by the method of moments"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108266956"
                        ],
                        "name": "Mou-Yen Chen",
                        "slug": "Mou-Yen-Chen",
                        "structuredName": {
                            "firstName": "Mou-Yen",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mou-Yen Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34320269"
                        ],
                        "name": "A. Kundu",
                        "slug": "A.-Kundu",
                        "structuredName": {
                            "firstName": "Amlan",
                            "lastName": "Kundu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kundu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108782767"
                        ],
                        "name": "Jian Zhou",
                        "slug": "Jian-Zhou",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Zhou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 118
                            }
                        ],
                        "text": "Specifically, for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 119
                            }
                        ],
                        "text": "Specifically, for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 43403727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a6d63e8f15f219b747930de1cf52c80e7c6e802",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Because of large variations involved in handwritten words, the recognition problem is very difficult. Hidden Markov models (HMM) have been widely and successfully used in speech processing and recognition. Recently HMM has also been used with some success in recognizing handwritten words with presegmented letters. In this paper, a complete scheme for totally unconstrained handwritten word recognition based on a single contextual hidden Markov model type stochastic network is presented. Our scheme includes a morphology and heuristics based segmentation algorithm, a training algorithm that can adapt itself with the changing dictionary, and a modified Viterbi algorithm which searches for the (l+1)th globally best path based on the previous l best paths. Detailed experiments are carried out and successful recognition results are reported. >"
            },
            "slug": "Off-Line-Handwritten-Word-Recognition-Using-a-Model-Chen-Kundu",
            "title": {
                "fragments": [],
                "text": "Off-Line Handwritten Word Recognition Using a Hidden Markov Model Type Stochastic Network"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A complete scheme for totally unconstrained handwritten word recognition based on a single contextual hidden Markov model type stochastic network is presented, which includes a morphology and heuristics based segmentation algorithm, a training algorithm that can adapt itself with the changing dictionary."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33666044"
                        ],
                        "name": "A. Senior",
                        "slug": "A.-Senior",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Senior",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Senior"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40268570"
                        ],
                        "name": "A. J. Robinson",
                        "slug": "A.-J.-Robinson",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Robinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Robinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 134
                            }
                        ],
                        "text": "\u2026and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46516403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a56aa5ce50e6756206ec61c29c7bc1e1b579d8c",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a complete system for the recognition of off-line handwriting. Preprocessing techniques are described, including segmentation and normalization of word images to give invariance to scale, slant, slope and stroke thickness. Representation of the image is discussed and the skeleton and stroke features used are described. A recurrent neural network is used to estimate probabilities for the characters represented in the skeleton. The operation of the hidden Markov model that calculates the best word in the lexicon is also described. Issues of vocabulary choice, rejection, and out-of-vocabulary word recognition are discussed."
            },
            "slug": "An-Off-Line-Cursive-Handwriting-Recognition-System-Senior-Robinson",
            "title": {
                "fragments": [],
                "text": "An Off-Line Cursive Handwriting Recognition System"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "Describes a complete system for the recognition of off-line handwriting, including segmentation and normalization of word images to give invariance to scale, slant, slope and stroke thickness."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 17
                            }
                        ],
                        "text": "See for instance Mikolov et al. (2013) for a recent reference on word embedding that reflects such semantic similarity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16447573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "isKey": false,
            "numCitedBy": 26037,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. \n \nAn inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."
            },
            "slug": "Distributed-Representations-of-Words-and-Phrases-Mikolov-Sutskever",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Words and Phrases and their Compositionality"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a simple method for finding phrases in text, and shows that learning good vector representations for millions of phrases is possible and describes a simple alternative to the hierarchical softmax called negative sampling."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808179"
                        ],
                        "name": "Alessandro Lameiras Koerich",
                        "slug": "Alessandro-Lameiras-Koerich",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Lameiras Koerich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Lameiras Koerich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744351"
                        ],
                        "name": "R. Sabourin",
                        "slug": "R.-Sabourin",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Sabourin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sabourin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 207
                            }
                        ],
                        "text": "It is interesting to observe, however, that while this is an advantage it is generally acknowledged that systems supporting open vocabulary yield worse results than systems which operate on closed lexicons (Koerich et al. 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12497958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a3e253f187182d85ed80503618678dadaf95616",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 154,
            "paperAbstract": {
                "fragments": [],
                "text": "Considerable progress has been made in handwriting recognition technology over the last few years. Thus far, handwriting recognition systems have been limited to small and medium vocabulary applications, since most of them often rely on a lexicon during the recognition process. The capability of dealing with large lexicons, however, opens up many more applications. This article will discuss the methods and principles that have been proposed to handle large vocabularies and identify the key issues affecting their future deployment. To illustrate some of the points raised, a large vocabulary off-line handwritten word recognition system will be described."
            },
            "slug": "Large-vocabulary-off-line-handwriting-recognition:-Koerich-Sabourin",
            "title": {
                "fragments": [],
                "text": "Large vocabulary off-line handwriting recognition: A survey"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This article will discuss the methods and principles that have been proposed to handle large vocabularies and identify the key issues affecting their future deployment."
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Analysis & Applications"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37526757"
                        ],
                        "name": "Urs-Viktor Marti",
                        "slug": "Urs-Viktor-Marti",
                        "structuredName": {
                            "firstName": "Urs-Viktor",
                            "lastName": "Marti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs-Viktor Marti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 118
                            }
                        ],
                        "text": "Specifically, for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 199
                            }
                        ],
                        "text": "\u2026open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10207300,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e15725948c2ea8b190b825a0887e430dc4898428",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a system for the reading of totally unconstrained handwritten text is presented. The kernel of the system is a hidden Markov model (HMM) for handwriting recognition. The HMM is enhanced by a statistical language model. Thus linguistic knowledge beyond the lexicon level is incorporated in the recognition process. Another novel feature of the system is that the HMM is applied in such a way that the difficult problem of segmenting a line of text into individual words is avoided. A number of experiments with various language models and large vocabularies have been conducted. The language models used in the system were also analytically compared based on their perplexity."
            },
            "slug": "Using-a-Statistical-Language-Model-to-Improve-the-Marti-Bunke",
            "title": {
                "fragments": [],
                "text": "Using a Statistical Language Model to Improve the Performance of an HMM-Based Cursive Handwriting Recognition System"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel feature of the system is that the HMM is applied in such a way that the difficult problem of segmenting a line of text into individual words is avoided and linguistic knowledge beyond the lexicon level is incorporated in the recognition process."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399142941"
                        ],
                        "name": "Jos\u00e9 A. Rodr\u00edguez-Serrano",
                        "slug": "Jos\u00e9-A.-Rodr\u00edguez-Serrano",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Rodr\u00edguez-Serrano",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 A. Rodr\u00edguez-Serrano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772969"
                        ],
                        "name": "Harsimrat Sandhawalia",
                        "slug": "Harsimrat-Sandhawalia",
                        "structuredName": {
                            "firstName": "Harsimrat",
                            "lastName": "Sandhawalia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harsimrat Sandhawalia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145652623"
                        ],
                        "name": "R. Bala",
                        "slug": "R.-Bala",
                        "structuredName": {
                            "firstName": "Raja",
                            "lastName": "Bala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723883"
                        ],
                        "name": "F. Perronnin",
                        "slug": "F.-Perronnin",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Perronnin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Perronnin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144884649"
                        ],
                        "name": "C. Saunders",
                        "slug": "C.-Saunders",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Saunders",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Saunders"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 17
                            }
                        ],
                        "text": "The first one is Rodr\u00edguez-Serrano et al. (2012) which proposes a system to recognize license plates using a holistic approach, where a nearest-neighbor search is performed against an annotated dataset."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 76
                            }
                        ],
                        "text": "For evaluation we measure the accuracy vs. reject characteristic as done in Rodr\u00edguez-Serrano et al. (2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 185
                            }
                        ],
                        "text": "5.1 License Plate Recognition\nDataset and settings For the license plate recognition experiments, we use a dataset of 45,000 annotated license plate images obtained from the authors of Rodr\u00edguez-Serrano et al. (2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 93
                            }
                        ],
                        "text": "Although image synthesis has been proposed as a technicalworkaround (Larochelle et al. 2008; Rodr\u00edguez-Serrano et al. 2012), synthesizing realistic scene text images is a challenge by itself, involves costly rendering operations, and poses difficulties to scale to large lexicons."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 91
                            }
                        ],
                        "text": "Baselines We compare the proposed method against two baselines: (i) the \u201cglobal\u201d approach of Rodr\u00edguez-Serrano et al. (2012), where recognition is based on a nearest neighbor (NN), and (ii) a bottom-up approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9986702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29525793633c96e59ed6e7953a98b4d0f7898522",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Vehicle identification from images has been predominantly addressed through automatic license plate recognition (ALPR) techniques which detect and recognize the characters in the plate region of the image. We move away from traditional ALPR techniques and advocate for a data-driven approach for vehicle identification. Here, given a plate image region, the idea is to search for a near-duplicate image in an annotated database; if found, the identity of the near-duplicate is transferred to the input region. Although this approach could be perceived as impractical, we actually demonstrate that it is feasible with state-of-the-art image representations, and that it presents some advantages in terms of speed, and time-to-deploy. To overcome the issue of identifying previously unseen identities, we propose an image simulation approach where photo-realistic images of license plates are generated for desired plate numbers. We demonstrate that there is no perceivable performance difference between using synthetic and real plates. We also improve the matching accuracy using similarity learning, which is in the spirit of domain adaptation."
            },
            "slug": "Data-Driven-Vehicle-Identification-by-Image-Rodr\u00edguez-Serrano-Sandhawalia",
            "title": {
                "fragments": [],
                "text": "Data-Driven Vehicle Identification by Image Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "To overcome the issue of identifying previously unseen identities, this work proposes an image simulation approach where photo-realistic images of license plates are generated for desired plate numbers and demonstrates that there is no perceivable performance difference between using synthetic and real plates."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV Workshops"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153312185"
                        ],
                        "name": "S. Mori",
                        "slug": "S.-Mori",
                        "structuredName": {
                            "firstName": "Shunji",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724069"
                        ],
                        "name": "H. Nishida",
                        "slug": "H.-Nishida",
                        "structuredName": {
                            "firstName": "Hirobumi",
                            "lastName": "Nishida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nishida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10639741"
                        ],
                        "name": "H. Yamada",
                        "slug": "H.-Yamada",
                        "structuredName": {
                            "firstName": "Hiromitsu",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Yamada"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 74
                            }
                        ],
                        "text": "Despite building on themature field ofOptical Character Recognition (OCR) (Mori et al. 1999; Nagy 2000), understanding text in natural scenes, as opposed to text in clean documents, still poses significant challenges as pointed out by recent papers Wang and Belongie (2010), Wang et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 75
                            }
                        ],
                        "text": "Despite building on themature field ofOptical Character Recognition (OCR) (Mori et al. 1999; Nagy 2000), understanding text in natural scenes, as opposed to text in clean documents, still poses significant challenges as pointed out by recent papers Wang and Belongie (2010), Wang et al. (2011),\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 123
                            }
                        ],
                        "text": "Classical OCR and handwriting recognition The problem of text recognition is mature and has been well-studied for decades (Mori et al. 1999; Nagy 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 198327346,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "9a88471c88a56e58bbeec2f265554590ca625a8c",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nOptical Character Recognition (OCR) has become an important and widely used technology. Among its many practical applications are the scanners used at store check-out counters, money changing machines, office scanning machines, and the efforts to automate the postal system. Research is particularly active in Japan where one important goal is to develop economical machines that can read Kanji characters. Such machines will be widely used in offices as man-machine interfaces. Dr. Mori from the Ricoh R&D Center in Japan has used his experience in optical character recognition to create a thorough reference to this widely used but still growing technology."
            },
            "slug": "Optical-Character-Recognition-Mori-Nishida",
            "title": {
                "fragments": [],
                "text": "Optical Character Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Dr. Mori from the Ricoh R&D Center in Japan has used his experience in optical character recognition to create a thorough reference to this widely used but still growing technology."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2203954"
                        ],
                        "name": "Markus Junker",
                        "slug": "Markus-Junker",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Junker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Junker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2933102"
                        ],
                        "name": "A. Weisbecker",
                        "slug": "A.-Weisbecker",
                        "structuredName": {
                            "firstName": "Anette",
                            "lastName": "Weisbecker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Weisbecker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34949928,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d9f5c1245f9d165aece64b5587ac6832ae5ea43",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of angled feeds happens mainly with fast production scanners. This is a mechanical problem of most feeders when feeding pages in high speed. To improve the image quality, it is necessary to have a high speed deskew algorithm that eliminates the skew in an electronic way. First the skew of the document must be found. After this, the skew can be corrected. This chapter shows how to find the skew, even if the document is damaged. It also shows several methods to deskew the document. 1 How to Find Out the Skew Angle Before a skew can be corrected, first the skew angle must be found out. There are two methods: Method 1: Searching the image contents for horizontal or vertical structures Advantages: No brightness difference is required between document and background. Also documents without any scanned background can be processed. Disadvantages: A very complicated algorithm is required in order to securely find horizontal or vertical structures on different originals; but eventually still wrong angles remain. The algorithm returns just an angle, but not the outer borders of the scanned document. Method 2: Searching for the borders of the scanned document. Advantages: Finding the borders of a document is far easier, faster and more reliable than finding structures in the document. In addition to the angle, also the outer borders of the scanned document are recognized. Disadvantages: The document must be scanned in \"oversize\". It makes sense to scan an additional rim of about 2cm. There must be a difference in brightness or colour between scanner background and document. When scanning with production scanners, the method to find the borders suggests itself as its advantages predominate. The alleged disadvantage of scanning in oversize is often seen as advantage. On one hand, a slightly larger image format must be captured if tilted documents must be expected and no information shall get lost at the rim. If for example A4 documents are scanned exactly with A4, their corners will be cut if the document had a skew. 2 D. Woitha and D. Janich On the other hand, a larger image format may be set, and all smaller image formats can be scanned without changing the parameters. Finding the borders and subsequent deskew will then deliver what in principle is wanted: \"A straight document without any additional rim\". The necessary difference between background and document can usually be realized without problems. A black background mostly gives enough contrast to the original. If search for borders is started from a bitonal document, problems may arise if dark elements exist at the rim of the image. In this case, precautions have to be taken when searching for borders. 2 The Practice of Border Finding The sample image below serves for illustrating the border finding; it shows the detected border pixels and the rectangle resulting from it. Fig. 1. Skewed Document Below follows a closer description of the realized algorithm for border finding. This algorithm bases on a light document on a black background as this is the case most often occurring in practice. The document has some typical problem areas; their processing will be detailed later: Non-clean background (dust, for example) Black beam at the document border Torn corner Non-interrupted white line (dust or CCD error, for example) Dust Black Beam White Line"
            },
            "slug": "Reading-and-Learning-Dengel-Junker",
            "title": {
                "fragments": [],
                "text": "Reading and Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This chapter shows how to find the skew, even if the document is damaged, and several methods to deskew the document, and a closer description of the realized algorithm for border finding."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747181"
                        ],
                        "name": "J. Hartmanis",
                        "slug": "J.-Hartmanis",
                        "structuredName": {
                            "firstName": "Juris",
                            "lastName": "Hartmanis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hartmanis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143817739"
                        ],
                        "name": "J. V. Leeuwen",
                        "slug": "J.-V.-Leeuwen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Leeuwen",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Leeuwen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 44
                            }
                        ],
                        "text": "For efficiency, we use the bound B2 and SGD (LeCun et al. 1998) for optimization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "Note that, since our our objective function is convex inW , the initialization does not impact the end results provided that SGD runs for a sufficient number of iterations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 62
                            }
                        ],
                        "text": "3.5 Optimization\nFor efficiency, we use the bound B2 and SGD (LeCun et al. 1998) for optimization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 201
                            }
                        ],
                        "text": "This has two negative effects: i) the objective is typically non-smooth and ii) training can be slow when the cardinality of Y is large, even with techniques such as Stochastic Gradient Descent (SGD) (LeCun et al. 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "To perform optimization, we use Stochastic Gradient Descent (SGD) with averaging over the last epochs."
                    },
                    "intents": []
                }
            ],
            "corpusId": 26661612,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b1a5961609c623fc816aaa77565ba38b25531a8e",
            "isKey": true,
            "numCitedBy": 1302,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Many algorithms are available to learn deep hierarchies of features from unlabeled data, especially images. In many cases, these algorithms involve multi-layered networks of features (eg, neural networks) that are sometimes tricky to train and tune and are difficult. Abstract A commonly encountered problem in MLP (multi-layer perceptron) classification problems is related to the prior probabilities of the individual classes-if the number of training examples that correspond to each class varies significantly between the classes, then. Abstract Validation can be used to detect when overfitting starts during supervised training of a neural network; training is then stopped before convergence to avoid the overfitting (\u00e2 \u0153early stopping\u00e2 ). The exact criterion used for validation-based early stopping, however, is usually. Abstract Reservoir computing has emerged in the last decade as an alternative to gradient descent methods for training recurrent neural networks. Echo State Network (ESN) is one of the key reservoir computing \u00e2 \u0153flavors\u00e2 . While being practical, conceptually simple, and easy. Preface In many cases, the amount of labeled data is limited and does not allow for fully identifying the function that needs to be learned. When labeled data is scarce, the learning algorithm is exposed to simultaneous underfitting and overfitting. The learning algorithm. Abstract Restricted Boltzmann machines (RBMs) have been used as generative models of many different types of data. RBMs are usually trained using the contrastive divergence learning procedure. This requires a certain amount of practical experience to decide.A commonly encountered problem in MLP (multi-layer perceptron) classification problems is related to the prior probabilities of the individual classes-if the number of training examples that correspond to each class varies significantly between the classes, then. Abstract Validation can be used to detect when overfitting starts during supervised training of a neural network; training is then stopped before convergence to avoid the overfitting (\u00e2 \u0153early stopping\u00e2 ). The exact criterion used for validation-based early stopping, however, is usually. Abstract Reservoir computing has emerged in the last decade as an alternative to gradient descent methods for training recurrent neural networks. Echo State Network (ESN) is one of the key reservoir computing \u00e2 \u0153flavors\u00e2 . While being practical, conceptually simple, and easy. Preface In many cases, the amount of labeled data is limited and does not allow for fully identifying the function that needs to be learned. When labeled data is scarce, the learning algorithm is exposed to simultaneous underfitting and overfitting. The learning algorithm. Abstract Restricted Boltzmann machines (RBMs) have been used as generative models of many different types of data. RBMs are usually trained using the contrastive divergence learning procedure. This requires a certain amount of practical experience to decide. It is our belief that researchers and practitioners acquire, through experience and word-ofmouth, techniques and heuristics that help them successfully apply neural networks to di cult real world problems. Often these\\ tricks\" are theo-tically well motivated. Sometimes they. Abstract The convergence of back-propagation learning is analyzed so as to explain common phenomenon observed by practitioners. Many undesirable behaviors of backprop can be avoided with tricks that are rarely exposed in serious technical publications. This. Abstract Chapter 1 strongly advocates the stochastic back-propagation method to train neural networks. This is in fact an instance of a more general technique called stochastic gradient descent (SGD). This chapter provides background material, explains why SGD is a. Abstract WeChapter 1 strongly advocates the stochastic back-propagation method to train neural networks. This is in fact an instance of a more general technique called stochastic gradient descent (SGD). This chapter provides background material, explains why SGD is a. Abstract We show how nonlinear semi-supervised embedding algorithms popular for use with \u00e2 \u0153shallow\u00e2 learning techniques such as kernel methods can be easily applied to deep multi-layer architectures, either as a regularizer at the output layer, or on each layer."
            },
            "slug": "Neural-Networks:-Tricks-of-the-Trade-Hartmanis-Leeuwen",
            "title": {
                "fragments": [],
                "text": "Neural Networks: Tricks of the Trade"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown how nonlinear semi-supervised embedding algorithms popular for use with \u00e2 \u0153shallow\u00e2 learning techniques such as kernel methods can be easily applied to deep multi-layer architectures."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207605508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfd4259d305a00f13d5f08841230389f61322422",
            "isKey": false,
            "numCitedBy": 4304,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an approach to automatically optimizing the retrieval quality of search engines using clickthrough data. Intuitively, a good information retrieval system should present relevant documents high in the ranking, with less relevant documents following below. While previous approaches to learning retrieval functions from examples exist, they typically require training data generated from relevance judgments by experts. This makes them difficult and expensive to apply. The goal of this paper is to develop a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking. Such clickthrough data is available in abundance and can be recorded at very low cost. Taking a Support Vector Machine (SVM) approach, this paper presents a method for learning retrieval functions. From a theoretical perspective, this method is shown to be well-founded in a risk minimization framework. Furthermore, it is shown to be feasible even for large sets of queries and features. The theoretical results are verified in a controlled experiment. It shows that the method can effectively adapt the retrieval function of a meta-search engine to a particular group of users, outperforming Google in terms of retrieval quality after only a couple of hundred training examples."
            },
            "slug": "Optimizing-search-engines-using-clickthrough-data-Joachims",
            "title": {
                "fragments": [],
                "text": "Optimizing search engines using clickthrough data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The goal of this paper is to develop a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038033"
                        ],
                        "name": "Dor Kedem",
                        "slug": "Dor-Kedem",
                        "structuredName": {
                            "firstName": "Dor",
                            "lastName": "Kedem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dor Kedem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2342481"
                        ],
                        "name": "Stephen Tyree",
                        "slug": "Stephen-Tyree",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Tyree",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Tyree"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145757665"
                        ],
                        "name": "Fei Sha",
                        "slug": "Fei-Sha",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Sha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Sha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725533"
                        ],
                        "name": "G. Lanckriet",
                        "slug": "G.-Lanckriet",
                        "structuredName": {
                            "firstName": "Gert",
                            "lastName": "Lanckriet",
                            "middleNames": [
                                "R.",
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lanckriet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 50
                            }
                        ],
                        "text": "Similarly, non-linear metric learningworks exist (Kedem et al. 2012) that could be directly applied here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 262323,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc8ed6612230114c2cdd5c9351b4c2555c15eb77",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we introduce two novel metric learning algorithms, \u03a72-LMNN and GB-LMNN, which are explicitly designed to be non-linear and easy-to-use. The two approaches achieve this goal in fundamentally different ways: \u03a72-LMNN inherits the computational benefits of a linear mapping from linear metric learning, but uses a non-linear \u03a72-distance to explicitly capture similarities within histogram data sets; GB-LMNN applies gradient-boosting to learn non-linear mappings directly in function space and takes advantage of this approach's robustness, speed, parallelizability and insensitivity towards the single additional hyper-parameter. On various benchmark data sets, we demonstrate these methods not only match the current state-of-the-art in terms of kNN classification error, but in the case of \u03a72-LMNN, obtain best results in 19 out of 20 learning settings."
            },
            "slug": "Non-linear-Metric-Learning-Kedem-Tyree",
            "title": {
                "fragments": [],
                "text": "Non-linear Metric Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "These methods not only match the current state-of-the-art in terms of kNN classification error, but in the case of \u03a72-LMNN, obtain best results in 19 out of 20 learning settings."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388416"
                        ],
                        "name": "S. Nowozin",
                        "slug": "S.-Nowozin",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Nowozin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowozin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787591"
                        ],
                        "name": "Christoph H. Lampert",
                        "slug": "Christoph-H.-Lampert",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Lampert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoph H. Lampert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 148
                            }
                        ],
                        "text": "In the SSVM framework, ones chooses as a convex upper-bound on (yn, f (xn)) the following loss which generalizes the hinge loss to multiple outputs (Nowozin and Lampert 2011):"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 68
                            }
                        ],
                        "text": "Note that (3) takes the form of the compatibility functions used by SSVMs (Nowozin and Lampert 2011), therefore we can find the elements of W (or w) by training a SSVM.\n3.2 Image Embedding\nThe function \u03b8 : X \u2192 RD is a feature extraction function that accepts an image and outputs a D-dimensional vectorial image signature."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 95
                            }
                        ],
                        "text": "To that end, we formulate the problem in a structured support vector machine (SSVM) framework (Nowozin and Lampert 2011) and learn the linear projection that optimizes a proximity criterion between word images and their corresponding labels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 75
                            }
                        ],
                        "text": "Note that (3) takes the form of the compatibility functions used by SSVMs (Nowozin and Lampert 2011), therefore we can find the elements of W (or w) by training a SSVM.\n3.2 Image Embedding\nThe function \u03b8 : X \u2192 RD is a feature extraction function that accepts an image and outputs a D-dimensional\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 74
                            }
                        ],
                        "text": "Note that (3) takes the form of the compatibility functions used by SSVMs (Nowozin and Lampert 2011), therefore we can find the elements of W (or w) by training a SSVM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 51
                            }
                        ],
                        "text": "To learn the parameters w, we use a SSVM framework (Nowozin and Lampert 2011), as pointed out in Sect."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 75
                            }
                        ],
                        "text": "3.4 Learning Objective\nTo learn the parameters w, we use a SSVM framework (Nowozin and Lampert 2011), as pointed out in Sect."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 149
                            }
                        ],
                        "text": "In the SSVM framework, ones chooses as a convex upper-bound on (yn, f (xn)) the following loss which generalizes the hinge loss to multiple outputs (Nowozin and Lampert 2011):\nB1(yn, f (xn)) = max y\u2208Y (yn, y)\n\u2212 F(xn, yn;w) + F(xn, y;w)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 5
                            }
                        ],
                        "text": "See (Nowozin and Lampert, 2011, p.120) for more details."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 51862717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "916ad37eb897b3858141874e290e20eae5076f5b",
            "isKey": true,
            "numCitedBy": 345,
            "numCiting": 203,
            "paperAbstract": {
                "fragments": [],
                "text": "Powerful statistical models that can be learned efficiently from large amounts of data are currently revolutionizing computer vision. These models possess a rich internal structure reflecting task-specific relations and constraints. This monograph introduces the reader to the most popular classes of structured models in computer vision. Our focus is discrete undirected graphical models which we cover in detail together with a description of algorithms for both probabilistic inference and maximum a posteriori inference. We discuss separately recently successful techniques for prediction in general structured models. In the second part of this monograph we describe methods for parameter learning where we distinguish the classic maximum likelihood based methods from the more recent prediction-based parameter learning methods. We highlight developments to enhance current models and discuss kernelized models and latent variable models. To make the monograph more practical and to provide links to further study we provide examples of successful application of many methods in the computer vision literature."
            },
            "slug": "Structured-Learning-and-Prediction-in-Computer-Nowozin-Lampert",
            "title": {
                "fragments": [],
                "text": "Structured Learning and Prediction in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This monograph introduces the reader to the most popular classes of structured models in computer vision including discrete undirected graphical models and methods for parameter learning where the classic maximum likelihood based methods are distinguished from the more recent prediction-based parameter learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Comput. Graph. Vis."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 69
                            }
                        ],
                        "text": "Although image synthesis has been proposed as a technicalworkaround (Larochelle et al. 2008; Rodr\u00edguez-Serrano et al. 2012), synthesizing realistic scene text images is a challenge by itself, involves costly rendering operations, and poses difficulties to scale to large lexicons."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7249642,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fabb43426ead447305c9186f54d5124863730e47",
            "isKey": false,
            "numCitedBy": 359,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the problem of zero-data learning, where a model must generalize to classes or tasks for which no training data are available and only a description of the classes or tasks are provided. Zero-data learning is useful for problems where the set of classes to distinguish or tasks to solve is very large and is not entirely covered by the training data. The main contributions of this work lie in the presentation of a general formalization of zero-data learning, in an experimental analysis of its properties and in empirical evidence showing that generalization is possible and significant in this context. The experimental work of this paper addresses two classification problems of character recognition and a multitask ranking problem in the context of drug discovery. Finally, we conclude by discussing how this new framework could lead to a novel perspective on how to extend machine learning towards AI, where an agent can be given a specification for a learning problem before attempting to solve it (with very few or even zero examples)."
            },
            "slug": "Zero-data-Learning-of-New-Tasks-Larochelle-Erhan",
            "title": {
                "fragments": [],
                "text": "Zero-data Learning of New Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The main contributions of this work lie in the presentation of a general formalization of zero-data learning, in an experimental analysis of its properties and in empirical evidence showing that generalization is possible and significant in this context."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897313"
                        ],
                        "name": "Nitish Srivastava",
                        "slug": "Nitish-Srivastava",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 102
                            }
                        ],
                        "text": "See for instance the classic reference Bishop (1995) in the case of Gaussian noise or the more recent Hinton et al. (2012) in the case of drop-out noise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14832074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1366de5bb112746a555e9c0cd00de3ad8628aea8",
            "isKey": false,
            "numCitedBy": 6189,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This \"overfitting\" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random \"dropout\" gives big improvements on many benchmark tasks and sets new records for speech and object recognition."
            },
            "slug": "Improving-neural-networks-by-preventing-of-feature-Hinton-Srivastava",
            "title": {
                "fragments": [],
                "text": "Improving neural networks by preventing co-adaptation of feature detectors"
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 203
                            }
                        ],
                        "text": "\u20261987), in many cases character segmentation is not reliable and the systems had to produce character hypotheses and find the most likely word using a high-level model, for instance dynamic programming (Breuel 2001) or in a more principled way with hidden Markov models (HMMs) (Bazzi et al. 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 316,
                                "start": 303
                            }
                        ],
                        "text": "While the early systems relied on explicit character separation and classification (Cash and Hatamian 1987), in many cases character segmentation is not reliable and the systems had to produce character hypotheses and find the most likely word using a high-level model, for instance dynamic programming (Breuel 2001) or in a more principled way with hidden Markov models (HMMs) (Bazzi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3132858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff21e5f41eade5d48e30e61081bf17df65cee100",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmentation of handwritten input into individual characters is a crucial step in many connected handwriting recognition systems. This paper describes a segmentation algorithm for letters in Roman alphabets, curved pre-stroke cut (CPSC) segmentation. The CPSC algorithm evaluates a large set of curved cuts through the image of the input string using dynamic programming and selects a small \"optimal\" subset of cuts for segmentation. It usually generates pixel accurate segmentations, indistinguishable from characters written in isolation. At four times oversegmentation, segmentation points are missed with an undetectable frequency on real-world databases. The CPSC algorithm has been used as part of a high-performance handwriting recognition system."
            },
            "slug": "Segmentation-of-handprinted-letter-strings-using-a-Breuel",
            "title": {
                "fragments": [],
                "text": "Segmentation of handprinted letter strings using a dynamic programming algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A segmentation algorithm for letters in Roman alphabets, curved pre-stroke cut (CPSC) segmentation, which evaluates a large set of curved cuts through the image of the input string using dynamic programming and selects a small \"optimal\" subset of cuts for segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059876008"
                        ],
                        "name": "Matthijs C. Dorst",
                        "slug": "Matthijs-C.-Dorst",
                        "structuredName": {
                            "firstName": "Matthijs",
                            "lastName": "Dorst",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthijs C. Dorst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 68
                            }
                        ],
                        "text": "In our implementation, the low-level features are SIFT descriptors (Lowe 2004) whose dimensionality is reduced from 128 down to 32 dimensions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 130535382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcae70dce393c1796d4f15c7b8bbf0ed6f468be1",
            "isKey": false,
            "numCitedBy": 15908,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images. These features can then be used to reliably match objects in diering images. The algorithm was rst proposed by Lowe [12] and further developed to increase performance resulting in the classic paper [13] that served as foundation for SIFT which has played an important role in robotic and machine vision in the past decade."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-Dorst",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The Scale-Invariant Feature Transform (or SIFT) algorithm is a highly robust method to extract and consequently match distinctive invariant features from images that can then be used to reliably match objects in diering images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145138506"
                        ],
                        "name": "M. Mohamed",
                        "slug": "M.-Mohamed",
                        "structuredName": {
                            "firstName": "Magdi",
                            "lastName": "Mohamed",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750102"
                        ],
                        "name": "P. Gader",
                        "slug": "P.-Gader",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Gader",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gader"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 118
                            }
                        ],
                        "text": "Specifically, for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 143
                            }
                        ],
                        "text": "\u2026for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24465500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb320c8c4706e0698ea95b9522733d7889ad5109",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A lexicon-based, handwritten word recognition system combining segmentation-free and segmentation-based techniques is described. The segmentation-free technique constructs a continuous density hidden Markov model for each lexicon string. The segmentation-based technique uses dynamic programming to match word images and strings. The combination module uses differences in classifier capabilities to achieve significantly better performance."
            },
            "slug": "Handwritten-Word-Recognition-Using-Hidden-Markov-Mohamed-Gader",
            "title": {
                "fragments": [],
                "text": "Handwritten Word Recognition Using Segmentation-Free Hidden Markov Modeling and Segmentation-Based Dynamic Programming Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A lexicon-based, handwritten word recognition system combining segmentation-free and segmentations-based techniques is described that uses dynamic programming to match word images and strings."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792884"
                        ],
                        "name": "Charles M. Bishop",
                        "slug": "Charles-M.-Bishop",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles M. Bishop"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 39
                            }
                        ],
                        "text": "See for instance the classic reference Bishop (1995) in the case of Gaussian noise or the more recent Hinton et al. (2012) in the case of drop-out noise."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16096318,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c3ecd8e19e016d15670c8953b4b9afaa5186b0f3",
            "isKey": false,
            "numCitedBy": 993,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "It is well known that the addition of noise to the input data of a neural network during training can, in some circumstances, lead to significant improvements in generalization performance. Previous work has shown that such training with noise is equivalent to a form of regularization in which an extra term is added to the error function. However, the regularization term, which involves second derivatives of the error function, is not bounded below, and so can lead to difficulties if used directly in a learning algorithm based on error minimization. In this paper we show that for the purposes of network training, the regularization term can be reduced to a positive semi-definite form that involves only first derivatives of the network mapping. For a sum-of-squares error function, the regularization term belongs to the class of generalized Tikhonov regularizers. Direct minimization of the regularized error function provides a practical alternative to training with noise."
            },
            "slug": "Training-with-Noise-is-Equivalent-to-Tikhonov-Bishop",
            "title": {
                "fragments": [],
                "text": "Training with Noise is Equivalent to Tikhonov Regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper shows that for the purposes of network training, the regularization term can be reduced to a positive semi-definite form that involves only first derivatives of the network mapping."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054206556"
                        ],
                        "name": "Matthias Zimmermann",
                        "slug": "Matthias-Zimmermann",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Zimmermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Zimmermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1874188"
                        ],
                        "name": "Jean-C\u00e9dric Chappelier",
                        "slug": "Jean-C\u00e9dric-Chappelier",
                        "structuredName": {
                            "firstName": "Jean-C\u00e9dric",
                            "lastName": "Chappelier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-C\u00e9dric Chappelier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 118
                            }
                        ],
                        "text": "Specifically, for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 274
                            }
                        ],
                        "text": "\u2026open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1363996,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "047f8e5d493fa7043dedb2679e120bd8acb682a1",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a sequential coupling of a hidden Markov model (HMM) recognizer for offline handwritten English sentences with a probabilistic bottom-up chart parser using stochastic context-free grammars (SCFG) extracted from a text corpus. Based on extensive experiments, we conclude that syntax analysis helps to improve recognition rates significantly."
            },
            "slug": "Offline-grammar-based-recognition-of-handwritten-Zimmermann-Chappelier",
            "title": {
                "fragments": [],
                "text": "Offline grammar-based recognition of handwritten sentences"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This paper proposes a sequential coupling of a hidden Markov model (HMM) recognizer for offline handwritten English sentences with a probabilistic bottom-up chart parser using stochastic context-free grammars extracted from a text corpus and concludes that syntax analysis helps to improve recognition rates significantly."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764325"
                        ],
                        "name": "Radford M. Neal",
                        "slug": "Radford-M.-Neal",
                        "structuredName": {
                            "firstName": "Radford",
                            "lastName": "Neal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radford M. Neal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 128
                            }
                        ],
                        "text": "We refer to that step as \u201cmarginalization\u201d, since (abusing the language) it is reminiscent of the sum rule in probability theory (Bishop 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31993898,
            "fieldsOfStudy": [
                "Mathematics",
                "Art"
            ],
            "id": "3bb5a439a0d610a7eac68f73068cdd278b8c9775",
            "isKey": false,
            "numCitedBy": 20996,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "the selection of symmetric factorial designs, that is, a design where all factors have the same number of levels. Chapter 3 focuses on selection of two-level factorial designs and discusses complementary design theory and related topics in the selection of designs. Chapter 4 covers the selection of three level designs followed by the general case of s-levels. Chapter 5 discusses estimation capacity, presenting the connections with complementary designs followed by the estimation capacity for two-level and s-level designs. Chapter 6 discusses and presents results for the construction of mixed-level designs. Giving many examples of the use of mixed two and four-level designs. The final unit of the book discusses designs where there are two-different groups of factors. Chapters 7 and 8 discuss factorial designs with restricted randomization. Focusing first on blocked designs for full factorials as well as blocked fractional factorial designs. Chapter 8 focuses on split-plot designs. The booked is concluded with a chapter on robust parameter designs. This book covers a broad range of topics for regular factorial designs and presents all of the material in very mathematical fashion. However, the authors do a wonderful job of keeping the statistical methodology at the forefront of the book and the mathematical detail is presented as the necessary tool to study these designs. The book will serve as a great text for an advanced graduate level course in design theory for students with the necessary mathematical background. The book will surely become an invaluable resource for researchers and graduate students doing research in the design of factorial experiments. In addition, practitioners will also find the book useful for the comprehensive collection of optimal designs presented at the end of many chapters. Overall, this is a very well written book and a necessary addition to the existing literature on the design of factorial experiments."
            },
            "slug": "Pattern-Recognition-and-Machine-Learning-Neal",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition and Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This book covers a broad range of topics for regular factorial designs and presents all of the material in very mathematical fashion and will surely become an invaluable resource for researchers and graduate students doing research in the design of factorial experiments."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113861474"
                        ],
                        "name": "C. Bishop",
                        "slug": "C.-Bishop",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bishop"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 128
                            }
                        ],
                        "text": "We refer to that step as \u201cmarginalization\u201d, since (abusing the language) it is reminiscent of the sum rule in probability theory (Bishop 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60688891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "932a106c21a1db1e1876459c1521d27fd152caac",
            "isKey": false,
            "numCitedBy": 8458,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Looking for competent reading resources? We have pattern recognition and machine learning information science and statistics to read, not only read, but also download them or even check out online. Locate this fantastic book writtern by by now, simply here, yeah just here. Obtain the reports in the kinds of txt, zip, kindle, word, ppt, pdf, as well as rar. Once again, never ever miss to review online and download this book in our site right here. Click the link."
            },
            "slug": "Pattern-Recognition-and-Machine-Learning-Science-Bishop",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition and Machine Learning (Information Science and Statistics)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "On the other hand, since the OCR system is specifically designed for US plates, it is reasonable to assume that it handles prior information of the specific fonts and plate designs, and that it involves optimized\npre- and post-processing steps, which is an unfair advantage over label embedding."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 195
                            }
                        ],
                        "text": "The main difference between the two works is that, while Almaz\u00e1n et al. (2013) attempt to explicitly detect characters in a word-image (which makes (Almaz\u00e1n et al. 2013) more similar to standard OCR-based approaches to text recognition), the proposed approach only does so implicitly."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "We highlight that, on the one hand, the proposed approach has an unfair advantage to the OCR, since it searches in a lexicon of 5K labels while the OCR software does not have the means to specify a lexicon."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "This is similar to typical OCR errors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 93
                            }
                        ],
                        "text": "Despite building on themature field ofOptical Character Recognition (OCR) (Mori et al. 1999; Nagy 2000), understanding text in natural scenes, as opposed to text in clean documents, still poses significant challenges as pointed out by recent papers Wang and Belongie (2010), Wang et al. (2011),\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 141
                            }
                        ],
                        "text": "Classical OCR and handwriting recognition The problem of text recognition is mature and has been well-studied for decades (Mori et al. 1999; Nagy 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "Despite building on themature field ofOptical Character Recognition (OCR) (Mori et al. 1999; Nagy 2000), understanding text in natural scenes, as opposed to text in clean documents, still poses significant challenges as pointed out by recent papers Wang and Belongie (2010), Wang et al. (2011), Neumann and Matas (2012), Mishra et al. (2012a, b), and Novikova et al. (2012)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "First, we observe that the OCR obtains accuracies of 80\u201395% for moderate reject rates, which confirms that the dataset is challenging."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 131
                            }
                        ],
                        "text": "Usually, the sequence of characters is constrained to be an element from a list of valid words, which is referred to as lexicon in OCR terminology."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "For instance, the recent works Almazan et al. (2014) and PhotoOCR Bissacco et al. (2013), which have appeared during the revision of this manuscript, report 87.0 and 90.4% respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "This type of errors is not usual in OCRs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Yet it achieves an accuracy comparable to existing systems such as an industrial OCR and a recent approach based on conditional random fields (CRF) (Mishra et al. 2012a)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 138
                            }
                        ],
                        "text": "Holistic methods Importantly for our discussion, as an alternative to the bottom-up approach, a number of previous works in the domain of OCR or handwriting recognition have attempted to recognize words without explicitly detecting characters, using instead global image representations, a notion sometimes denoted as holistic in the literature."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "In a license plate recognition task, the label embedding outperforms a dedicated OCR system; in a challenging scene text recognition task, we obtain results comparable to a CRF-based model Mishra et al. (2012a) in moderate-sized lexicons (1K words) and significantly higher in small-lexicon word-spotting tasks (50 words)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "The latter is a state-ofthe-art Automatic License Plate Recognition system (ALPR) based on OCR for the recognition of US plates."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 74
                            }
                        ],
                        "text": "Despite building on themature field ofOptical Character Recognition (OCR) (Mori et al. 1999; Nagy 2000), understanding text in natural scenes, as opposed to text in clean documents, still poses significant challenges as pointed out by recent papers Wang and Belongie (2010), Wang et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 620082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce3b569e18670f6c10e61aa9a8bda7c30fd37411",
            "isKey": true,
            "numCitedBy": 554,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "The contributions to document image analysis of 99 papers published in the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) are clustered, summarized, interpolated, interpreted, and evaluated."
            },
            "slug": "Twenty-Years-of-Document-Image-Analysis-in-PAMI-Nagy",
            "title": {
                "fragments": [],
                "text": "Twenty Years of Document Image Analysis in PAMI"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The contributions to document image analysis of 99 papers published in the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) are clustered, summarized, interpolated, interpreted, and evaluated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388546388"
                        ],
                        "name": "Grgoire Montavon",
                        "slug": "Grgoire-Montavon",
                        "structuredName": {
                            "firstName": "Grgoire",
                            "lastName": "Montavon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Grgoire Montavon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1382473772"
                        ],
                        "name": "Genevive Orr",
                        "slug": "Genevive-Orr",
                        "structuredName": {
                            "firstName": "Genevive",
                            "lastName": "Orr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Genevive Orr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068918803"
                        ],
                        "name": "Klaus-Robert Mller",
                        "slug": "Klaus-Robert-Mller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "Mller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaus-Robert Mller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39578794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b305c18d17fd6a17e8e52a21bcd680220d322cc3",
            "isKey": false,
            "numCitedBy": 601,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "The twenty last years have been marked by an increase in available data and computing power. In parallel to this trend, the focus of neural network research and the practice of training neural networks has undergone a number of important changes, for example, use of deep learning machines. The second edition of the book augments the first edition with more tricks, which have resulted from 14 years of theory and experimentation by some of the world's most prominent neural network researchers. These tricks can make a substantial difference (in terms of speed, ease of implementation, and accuracy) when it comes to putting algorithms to work on real problems."
            },
            "slug": "Neural-Networks:-Tricks-of-the-Trade-Montavon-Orr",
            "title": {
                "fragments": [],
                "text": "Neural Networks: Tricks of the Trade"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The second edition of the book augments the first edition with more tricks, which have resulted from 14 years of theory and experimentation by some of the world's most prominent neural network researchers."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "We reduce the dimensionality of the 128-dim SIFT descriptors to 32 dim with PCA."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 31
                            }
                        ],
                        "text": "(2002)), and employ Kernel PCA (Sch\u00f6lkopf et al. 1998) for the actual embedding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 202
                            }
                        ],
                        "text": "We follow the same experimental protocol for feature extraction and learning, with the following specific parameters: Fisher vectorswith 64Gaussians, dimension of the SIFT descriptor reduced to 64 with PCA, and spatial pyramid of 4\u00d72; BOC histograms with 4 levels, metric learning using 3,000 iterations with \u03b7 = 10\u22121 and \u03bb = 0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 191
                            }
                        ],
                        "text": "We note that we could make use of unsupervised techniques to embed word labels in a Euclidean space, for example by defining string kernels (e.g. Lodhi et al. (2002)), and employ Kernel PCA (Sch\u00f6lkopf et al. 1998) for the actual embedding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6674407,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3f600e6c6cf93e78c9e6e690443d6d22c4bf18b9",
            "isKey": true,
            "numCitedBy": 7878,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear mapfor instance, the space of all possible five-pixel products in 16 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition."
            },
            "slug": "Nonlinear-Component-Analysis-as-a-Kernel-Eigenvalue-Sch\u00f6lkopf-Smola",
            "title": {
                "fragments": [],
                "text": "Nonlinear Component Analysis as a Kernel Eigenvalue Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new method for performing a nonlinear form of principal component analysis by the use of integral operator kernel functions is proposed and experimental results on polynomial feature extraction for pattern recognition are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144490441"
                        ],
                        "name": "Bing Bai",
                        "slug": "Bing-Bai",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529182"
                        ],
                        "name": "David Grangier",
                        "slug": "David-Grangier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grangier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Grangier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 51
                            }
                        ],
                        "text": "An advantage of this approach is that, unlike SSI (Bai et al. 2009), the label embedding does not require the training set to contain pairs of images with the same labels, thus typically smaller sets are needed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 12
                            }
                        ],
                        "text": "We use SSI (Bai et al. 2009) whose objective function is related our RSSVM objective."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 174
                            }
                        ],
                        "text": "5) show that this similarity is more accurate than the dot product and other explicit methods for learning a similarity function, such as supervised semantic indexing (SSI) (Bai et al. 2009), in a retrieval task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "We observe that learning a metric with SSI improves over the FV and DTW baselines, but that the metric learned by label embedding provides higher accuracy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 137
                            }
                        ],
                        "text": "Initialization We initialize w with values sampled from a 0-mean normal distribution with a variance of 1, and divide by \u221a E , inspired by Bai et al. (2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 57705748,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1e6ee20aa6f730b8be50a8c8784aead4af57599",
            "isKey": true,
            "numCitedBy": 29,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a class of models that are discriminatively trained to directly map from the word content in a query-document or document- document pair to a ranking score. Like Latent Semantic Indexing (LSI), our models take account of correlations between words (synonymy, pol- ysemy). However, unlike LSI our models are trained with a supervised signal directly on the task of interest, which we argue is the reason for our superior results. We provide an empirical study on Wikipedia documents, using the links to define document-document or query-document pairs, where we obtain state-of-the-art performance using our method."
            },
            "slug": "Supervised-Semantic-Indexing-Bai-Weston",
            "title": {
                "fragments": [],
                "text": "Supervised Semantic Indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A class of models that are discriminatively trained to directly map from the word content in a query-document or document- document pair to a ranking score are presented."
            },
            "venue": {
                "fragments": [],
                "text": "ECIR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680574"
                        ],
                        "name": "M. Seeger",
                        "slug": "M.-Seeger",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Seeger",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seeger"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 47
                            }
                        ],
                        "text": "For instance, using the Nystr\u00f6m approximation (Williams and Seeger 2001) would require computing the string kernel between the new word and each element in Y ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42041158,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6fff8b8ea77f157913986e7af53951d9fc1128e",
            "isKey": false,
            "numCitedBy": 2166,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A major problem for kernel-based predictors (such as Support Vector Machines and Gaussian processes) is that the amount of computation required to find the solution scales as O(n3), where n is the number of training examples. We show that an approximation to the eigendecomposition of the Gram matrix can be computed by the Nystrom method (which is used for the numerical solution of eigenproblems). This is achieved by carrying out an eigendecomposition on a smaller system of size m < n, and then expanding the results back up to n dimensions. The computational complexity of a predictor using this approximation is O(m2n). We report experiments on the USPS and abalone data sets and show that we can set m \u226a n without any significant decrease in the accuracy of the solution."
            },
            "slug": "Using-the-Nystr\u00f6m-Method-to-Speed-Up-Kernel-Williams-Seeger",
            "title": {
                "fragments": [],
                "text": "Using the Nystr\u00f6m Method to Speed Up Kernel Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that an approximation to the eigendecomposition of the Gram matrix can be computed by the Nystrom method (which is used for the numerical solution of eigenproblems) and the computational complexity of a predictor using this approximation is O(m2n)."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34782608"
                        ],
                        "name": "G. Orr",
                        "slug": "G.-Orr",
                        "structuredName": {
                            "firstName": "Genevieve",
                            "lastName": "Orr",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20158889,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b87274e6d9aa4e6ba5148898aa92941617d2b6ed",
            "isKey": false,
            "numCitedBy": 2630,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Efficient-BackProp-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Efficient BackProp"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks: Tricks of the Trade"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 118
                            }
                        ],
                        "text": "Specifically, for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004; Vinciarelli et al. 2004; Zimmermann et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 137
                            }
                        ],
                        "text": "Specifically, for the task of large-vocabulary and open handwriting recognition, HMMs have become a de-facto standard (Chen et al. 1994; Bunke et al. 1995; Mohamed and Gader 1996; Senior and Robinson 1998; Knerr et al. 1998; El-Yacoubi et al. 1999; Marti and Bunke 2001; Brakensiek and Rigoll 2004;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1995).Off-line cursive handwriting recognition"
            },
            "venue": {
                "fragments": [],
                "text": "using hiddenMarkovmodels.Pattern Recognition,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 132
                            }
                        ],
                        "text": "While the proposed framework is independent of the specific features extracted, we use the widely adopted bag-of-patches framework (Csurka et al. 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual categorizationwith bags of keypoints. InECCVSLCVworkshop"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 30
                            }
                        ],
                        "text": "This is to be contrasted with Weston et al. (2010) where the label embeddings are learned."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to rank with joint word-image embeddings. ECML: Large scale image annotation"
            },
            "venue": {
                "fragments": [],
                "text": "Learning to rank with joint word-image embeddings. ECML: Large scale image annotation"
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 44,
            "methodology": 28,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 66,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Label-Embedding:-A-Frugal-Baseline-for-Text-Rodr\u00edguez-Serrano-Gordo/c08694d52741fe68a2010c0f836f24d1bfa0ab04?sort=total-citations"
}